<!doctype html><html lang=fr class=no-js><head><meta name=robots content="noindex, nofollow"><link rel=alternate hreflang=en href=https://kubernetes.io/docs/><link rel=alternate hreflang=zh-cn href=https://kubernetes.io/zh-cn/docs/><link rel=alternate hreflang=ko href=https://kubernetes.io/ko/docs/><link rel=alternate hreflang=ja href=https://kubernetes.io/ja/docs/><link rel=alternate hreflang=it href=https://kubernetes.io/it/docs/><link rel=alternate hreflang=de href=https://kubernetes.io/de/docs/><link rel=alternate hreflang=es href=https://kubernetes.io/es/docs/><link rel=alternate hreflang=pt-br href=https://kubernetes.io/pt-br/docs/><link rel=alternate hreflang=id href=https://kubernetes.io/id/docs/><link rel=alternate hreflang=hi href=https://kubernetes.io/hi/docs/><link rel=alternate hreflang=vi href=https://kubernetes.io/vi/docs/><link rel=alternate hreflang=ru href=https://kubernetes.io/ru/docs/><link rel=alternate hreflang=pl href=https://kubernetes.io/pl/docs/><link rel=alternate hreflang=uk href=https://kubernetes.io/uk/docs/><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=generator content="Hugo 0.110.0"><link rel=canonical type=text/html href=https://kubernetes.io/fr/docs/><link rel="shortcut icon" type=image/png href=/images/favicon.png><link rel=apple-touch-icon href=/favicons/apple-touch-icon-180x180.png sizes=180x180><link rel=manifest href=/manifest.webmanifest><link rel=apple-touch-icon href=/images/kubernetes-192x192.png><title>Documentation | Kubernetes</title><meta property="og:title" content="Documentation"><meta property="og:description" content="Documentation francophone de Kubernetes"><meta property="og:type" content="website"><meta property="og:url" content="https://kubernetes.io/fr/docs/"><meta property="og:site_name" content="Kubernetes"><meta itemprop=name content="Documentation"><meta itemprop=description content="Documentation francophone de Kubernetes"><meta name=twitter:card content="summary"><meta name=twitter:title content="Documentation"><meta name=twitter:description content="Documentation francophone de Kubernetes"><link href=/scss/main.css rel=stylesheet><script type=application/ld+json>{"@context":"https://schema.org","@type":"Organization","url":"https://kubernetes.io","logo":"https://kubernetes.io/images/favicon.png","potentialAction":{"@type":"SearchAction","target":"https://kubernetes.io/search/?q={search_term_string}","query-input":"required name=search_term_string"}}</script><meta name=theme-color content="#326ce5"><link rel=stylesheet href=/css/feature-states.css><meta name=description content="Documentation francophone de Kubernetes"><meta property="og:description" content="Documentation francophone de Kubernetes"><meta name=twitter:description content="Documentation francophone de Kubernetes"><meta property="og:url" content="https://kubernetes.io/fr/docs/"><meta property="og:title" content="Documentation"><meta name=twitter:title content="Documentation"><meta name=twitter:image content="https://kubernetes.io/images/favicon.png"><meta name=twitter:image:alt content="Kubernetes"><meta property="og:image" content="/images/kubernetes-horizontal-color.png"><meta property="og:type" content="article"><script src=/js/jquery-3.6.0.min.js intregrity=sha384-vtXRMe3mGCbOeY7l30aIg8H9p3GdeSe4IFlP6G8JMa7o7lXvnz3GFKzPxzJdPfGK crossorigin=anonymous></script></head><body class=td-section><header><nav class="js-navbar-scroll navbar navbar-expand navbar-dark flex-column flex-md-row td-navbar" data-auto-burger=primary><a class=navbar-brand href=/fr/></a><div class="td-navbar-nav-scroll ml-md-auto" id=main_navbar><ul class="navbar-nav mt-2 mt-lg-0"><li class="nav-item mr-2 mb-lg-0"><a class="nav-link active" href=/fr/docs/>Documentation</a></li><li class="nav-item mr-2 mb-lg-0"><a class=nav-link href=/fr/blog/>Blog de Kubernetes</a></li><li class="nav-item mr-2 mb-lg-0"><a class=nav-link href=/fr/partners/>Partenaires</a></li><li class="nav-item mr-2 mb-lg-0"><a class=nav-link href=/fr/community/>Communauté</a></li><li class="nav-item mr-2 mb-lg-0"><a class=nav-link href=/fr/case-studies/>Études de cas</a></li><li class="nav-item dropdown"><a class="nav-link dropdown-toggle" href=# id=navbarDropdown role=button data-toggle=dropdown aria-haspopup=true aria-expanded=false>Versions</a><div class="dropdown-menu dropdown-menu-right" aria-labelledby=navbarDropdownMenuLink><a class=dropdown-item href=/fr/releases>Release Information</a>
<a class=dropdown-item href=https://kubernetes.io/fr/docs/>v1.25</a>
<a class=dropdown-item href=https://v1-24.docs.kubernetes.io/fr/docs/>v1.24</a>
<a class=dropdown-item href=https://v1-23.docs.kubernetes.io/fr/docs/>v1.23</a>
<a class=dropdown-item href=https://v1-22.docs.kubernetes.io/fr/docs/>v1.22</a>
<a class=dropdown-item href=https://v1-21.docs.kubernetes.io/fr/docs/>v1.21</a></div></li><li class="nav-item dropdown"><a class="nav-link dropdown-toggle" href=# id=navbarDropdownMenuLink role=button data-toggle=dropdown aria-haspopup=true aria-expanded=false>Français (French)</a><div class="dropdown-menu dropdown-menu-right" aria-labelledby=navbarDropdownMenuLink><a class=dropdown-item href=/docs/>English</a>
<a class=dropdown-item href=/zh-cn/docs/>中文 (Chinese)</a>
<a class=dropdown-item href=/ko/docs/>한국어 (Korean)</a>
<a class=dropdown-item href=/ja/docs/>日本語 (Japanese)</a>
<a class=dropdown-item href=/it/docs/>Italiano (Italian)</a>
<a class=dropdown-item href=/de/docs/>Deutsch (German)</a>
<a class=dropdown-item href=/es/docs/>Español (Spanish)</a>
<a class=dropdown-item href=/pt-br/docs/>Português (Portuguese)</a>
<a class=dropdown-item href=/id/docs/>Bahasa Indonesia</a>
<a class=dropdown-item href=/hi/docs/>हिन्दी (Hindi)</a>
<a class=dropdown-item href=/vi/docs/>Tiếng Việt (Vietnamese)</a>
<a class=dropdown-item href=/ru/docs/>Русский (Russian)</a>
<a class=dropdown-item href=/pl/docs/>Polski (Polish)</a>
<a class=dropdown-item href=/uk/docs/>Українська (Ukrainian)</a></div></li></ul></div><button id=hamburger onclick=kub.toggleMenu() data-auto-burger-exclude><div></div></button></nav></header><div class="container-fluid td-outer"><div class=td-main><div class="row flex-xl-nowrap"><main class="col-12 col-md-9 col-xl-8 pl-md-5" role=main><div class=td-content><div class="pageinfo pageinfo-primary d-print-none"><p>Version imprimable multipages.
<a href=# onclick="return print(),!1">Cliquer ici pour imprimer</a>.</p><p><a href=/fr/docs/>Retour à la version par défaut</a>.</p></div><h1 class=title>Documentation</h1><div class=lead>Documentation francophone de Kubernetes</div><ul><li>1: <a href=#pg-e735cee7e913aa88bc0aa10594d12966>Documentation de Kubernetes</a></li><ul><li>1.1: <a href=#pg-92dfff0ca612d0bff40171aa9df6c4ae>Versions supportées de la documentation Kubernetes</a></li></ul><li>2: <a href=#pg-66b565805ca1061be35ff2c0165f13c1>Installation</a></li><ul><li>2.1: <a href=#pg-0b597086a9d1382f86abadcfeab657d6>Environnement d'apprentissage</a></li><ul><li>2.1.1: <a href=#pg-8b996bf57bd8e67340235da1a1fb8e95>Installer Kubernetes avec Minikube</a></li></ul><li>2.2: <a href=#pg-d33663ac044e1981b406949f9124cc04>Télécharger Kubernetes</a></li><ul><li>2.2.1: <a href=#pg-10b7970741f3e4925d298f965641410e>Construire une release</a></li></ul><li>2.3: <a href=#pg-4e14853fdaa3bd273f31a60112b9b5ac>Environnement de production</a></li><ul><li>2.3.1: <a href=#pg-00e1646f68aeb89f9722cf6f6cfcad94>Installer Kubernetes avec les outils de déploiement</a></li><ul><li>2.3.1.1: <a href=#pg-a16f59f325a17cdeed324d5c889f7f73>Déploiement d'un cluster avec kubeadm</a></li><ul><li>2.3.1.1.1: <a href=#pg-29e59491dd6118b23072dfe9ebb93323>Installer kubeadm</a></li><li>2.3.1.1.2: <a href=#pg-134ed1f6142a98e6ac681a1ba4920e53>Création d'un Cluster a master unique avec kubeadm</a></li><li>2.3.1.1.3: <a href=#pg-4c656c5eda3e1c06ad1aedebdc04a211>Personnalisation de la configuration du control plane avec kubeadm</a></li><li>2.3.1.1.4: <a href=#pg-015edbc7cc688d31b1d1edce7c186135>Options pour la topologie en haute disponibilité</a></li><li>2.3.1.1.5: <a href=#pg-3941d5c3409342219bf7e03128b8ecb6>Création de clusters hautement disponibles avec kubeadm</a></li><li>2.3.1.1.6: <a href=#pg-8160424c22d24f7d2d63c521e107dbf8>Configurer un cluster etcd en haute disponibilité avec kubeadm</a></li><li>2.3.1.1.7: <a href=#pg-07709e71de6b4ac2573041c31213dbeb>Configuration des kubelet de votre cluster avec kubeadm</a></li><li>2.3.1.1.8: <a href=#pg-c3689df4b0c61a998e79d91a865aa244>Dépanner kubeadm</a></li></ul></ul><li>2.3.2: <a href=#pg-e2eb3029b668b1713d0dc8bea296ba9c>Solutions Cloud clés en main</a></li><ul></ul><li>2.3.3: <a href=#pg-1b751cdddc397a65edb7bcf703bc0414>On-Premises VMs</a></li><ul></ul><li>2.3.4: <a href=#pg-acce7e24090fea04715a7a516ba3e69b>Windows dans Kubernetes</a></li><ul></ul></ul><li>2.4: <a href=#pg-89cb5486440b5e96f31dbb3956f2ad9e>Solutions Cloud personnalisées</a></li><ul><li>2.4.1: <a href=#pg-296711f0f3b239d2d549acc6ba48190e>CoreOS sur AWS ou GCE</a></li><li>2.4.2: <a href=#pg-b5fede6c0a528c69bb32a7bf68641aa1>Installer Kubernetes avec Kubespray (on-premises et fournisseurs de cloud)</a></li><li>2.4.3: <a href=#pg-750e22dae37d8ac366b101811e01cc34>Installer Kubernetes sur AWS avec kops</a></li></ul></ul><li>3: <a href=#pg-dd948255948d6b59b32c471abcb62997>Concepts</a></li><ul><li>3.1: <a href=#pg-0554ac387412eaf4e6e89b2f847dacde>Vue d'ensemble</a></li><ul><li>3.1.1: <a href=#pg-45bdca6129cf540121623e903c18ba46>Qu'est-ce-que Kubernetes ?</a></li><li>3.1.2: <a href=#pg-13b0f1dbe89228e3d76d2ac231e245f1>Composants de Kubernetes</a></li><li>3.1.3: <a href=#pg-110f33530cf761140cb1dab536baef04>Utilisation des objets Kubernetes</a></li><ul><li>3.1.3.1: <a href=#pg-1127165f472b7181b9c1d5a0b187d620>Namespaces</a></li></ul></ul><li>3.2: <a href=#pg-2bf36ccd6b3dbeafecf87c39761b07c7>Architecture de Kubernetes</a></li><ul><li>3.2.1: <a href=#pg-9ef2890698e773b6c0d24fd2c20146f5>Noeuds</a></li><li>3.2.2: <a href=#pg-63e7fdf87ba61eb2586bb8c625c23506>Communication Master-Node</a></li><li>3.2.3: <a href=#pg-bc804b02614d67025b4c788f1ca87fbc>Concepts sous-jacents au Cloud Controller Manager</a></li></ul><li>3.3: <a href=#pg-a5f7383c83ab9eb9cd0e3c4c020b3ae6>Les conteneurs</a></li><ul><li>3.3.1: <a href=#pg-16042b4652ad19e565c7263824029a43>Images</a></li><li>3.3.2: <a href=#pg-a858027489648786a3b16264e451272b>Classe d'exécution (Runtime Class)</a></li><li>3.3.3: <a href=#pg-643212488f778acf04bebed65ba34441>L'environnement du conteneur</a></li><li>3.3.4: <a href=#pg-e6941d969d81540208a3e78bc56f43bc>Hooks de cycle de vie de conteneurs</a></li></ul><li>3.4: <a href=#pg-d52aadda80edd9f8c514cfe2321363c2>Workloads</a></li><ul><li>3.4.1: <a href=#pg-4d68b0ccf9c683e6368ffdcc40c838d4>Pods</a></li><ul><li>3.4.1.1: <a href=#pg-37afa6c66c74400d1579f10faf55e5b6>Aperçu du Pod</a></li><li>3.4.1.2: <a href=#pg-99cce294fe789317ee684a6e1f07f20f>Pods</a></li><li>3.4.1.3: <a href=#pg-c3c2b9cf30915ec9d46c147201da3332>Cycle de vie d'un Pod</a></li><li>3.4.1.4: <a href=#pg-c8d62295ca703fdcef1aaf89fb4c916a>Contraintes de propagation de topologie pour les Pods</a></li><li>3.4.1.5: <a href=#pg-1ccbd4eeded6ab138d98b59175bd557e>Init Containers</a></li></ul><li>3.4.2: <a href=#pg-89637410cacae45a36ab1cc278c482eb>Contrôleurs</a></li><ul><li>3.4.2.1: <a href=#pg-d459b930218774655fa7fd1620625539>ReplicaSet</a></li><li>3.4.2.2: <a href=#pg-a2dc0393e0c4079e1c504b6429844e86>Déploiements</a></li><li>3.4.2.3: <a href=#pg-6d72299952c37ca8cc61b416e5bdbcd4>StatefulSets</a></li></ul></ul><li>3.5: <a href=#pg-0a0a7eca3e302a3c08f8c85e15d337fd>Services, Equilibreur de charge, et Réseau</a></li><ul><li>3.5.1: <a href=#pg-f51db1097575de8072afe1f5b156a70c>EndpointSlices</a></li><li>3.5.2: <a href=#pg-5701136fd2ce258047b6ddc389112352>Service</a></li><li>3.5.3: <a href=#pg-91cb8a4438b003df11bc1c426a81b756>DNS pour les services et les pods</a></li><li>3.5.4: <a href=#pg-199bcc92443dbc9bed44819467d7eb75>Ingress</a></li></ul><li>3.6: <a href=#pg-f018f568c6723865753f150c3c59bdda>Stockage</a></li><ul><li>3.6.1: <a href=#pg-27795584640a03bd2024f1fe3b3ab754>Volumes</a></li><li>3.6.2: <a href=#pg-ffd12528a12882b282e1bd19e29f9e75>Volumes persistants</a></li></ul><li>3.7: <a href=#pg-275bea454e1cf4c5adeca4058b5af988>Configuration</a></li><ul><li>3.7.1: <a href=#pg-e511ed821ada65d0053341dbd8ad2bb5>Secrets</a></li></ul><li>3.8: <a href=#pg-712cb3c03ff14a39e5a83a6d9b71d203>Sécurité</a></li><ul></ul><li>3.9: <a href=#pg-ac9161c6d952925b083ad9602b4e8e7f>Politiques</a></li><ul></ul><li>3.10: <a href=#pg-285a3785fd3d20f437c28d87ca4dadca>Administration d'un cluster</a></li><ul><li>3.10.1: <a href=#pg-fb494ea3b1874bd753dcd11c3f35c2dc>Vue d'ensemble de l'administration d'un cluster</a></li><li>3.10.2: <a href=#pg-2bf9a93ab5ba014fb6ff70b22c29d432>Certificats</a></li><li>3.10.3: <a href=#pg-c4b1e87a84441f8a90699a345ce48d68>Architecture de Journalisation d'évènements (logging)</a></li></ul><li>3.11: <a href=#pg-7e0d97616b15e2c383c6a0a96ec442cb>Extensions Kubernetes</a></li><ul><li>3.11.1: <a href=#pg-0af41d3bd7c785621b58b7564793396a>Extensions de l'API Kubernetes</a></li><ul></ul><li>3.11.2: <a href=#pg-c8937cdc9df96f3328becf04f8211292>Extensions compute, stockage et réseau</a></li><ul></ul></ul></ul><li>4: <a href=#pg-43f3f6f898190163fe7314de24b1dd1c>Solutions indépendantes</a></li><ul><li>4.1: <a href=#pg-9d8860326aa0a9106035ce48c98feb47>Serveurs physiques</a></li><ul></ul></ul><li>5: <a href=#pg-f8918f697450c2009b75913f9e9317a5>Tâches</a></li><ul><li>5.1: <a href=#pg-57bf66f59d9a642b82eebeabbc66470b>Outils d'installation</a></li><ul><li>5.1.1: <a href=#pg-bbdc530b292ab4074d1dfe69feafb3e7>Installer et configurer kubectl</a></li><li>5.1.2: <a href=#pg-2142bfe0834f1bf8f47887f85adba495>Installer Minikube</a></li></ul><li>5.2: <a href=#pg-34a810f1516ad9d99b2697e36e9b0d0f>Administration d'un cluster</a></li><ul><li>5.2.1: <a href=#pg-8e16d69617b175d61e2e7a6e1642c9d6>Administration avec kubeadm</a></li><ul></ul><li>5.2.2: <a href=#pg-47be5dd51f686017f1766e6ec7aa6f41>Gestion de la mémoire du CPU et des ressources d'API</a></li><ul></ul><li>5.2.3: <a href=#pg-8c31aafd38fad5b0de0bd191758d6f93>Installation d'un fournisseur de politiques de réseau</a></li><ul></ul><li>5.2.4: <a href=#pg-9585dc0efb0450fd68728e7511754717>Développer un Cloud Controller Manager</a></li><li>5.2.5: <a href=#pg-ce4cd28c8feb9faa783e79b48af37961>Kubernetes cloud-controller-manager</a></li></ul><li>5.3: <a href=#pg-f5da33b976758a9183018c421eb83f58>Configuration des Pods et des conteneurs</a></li><ul><li>5.3.1: <a href=#pg-e6dd9300cf3a955f7cdfe77fb5d15292>Allouer des ressources mémoire aux conteneurs et aux pods</a></li><li>5.3.2: <a href=#pg-8555af270ae7122cc0464bab3f5d1609>Allouer des ressources CPU aux conteneurs et aux pods</a></li><li>5.3.3: <a href=#pg-904cea8c8efd5c0d33adbfe579ec2dd2>Configurer la qualité de service pour les pods</a></li><li>5.3.4: <a href=#pg-4219ac6ab56a3b88d20305083d57d03c>Affecter des ressources supplémentaires à un conteneur</a></li><li>5.3.5: <a href=#pg-484833fb880d1e179cc2965d15f84da5>Configurer un pod en utilisant un volume pour le stockage</a></li><li>5.3.6: <a href=#pg-2c0d882359718c4c69c67099bed2156c>Configurer les comptes de service pour les pods</a></li><li>5.3.7: <a href=#pg-d385b86a7cb496d3b1c3b2a47280ca70>Récupération d'une image d'un registre privé</a></li><li>5.3.8: <a href=#pg-eb54daf87df373096b5e830680194dfc>Configurer les Liveness, Readiness et Startup Probes</a></li><li>5.3.9: <a href=#pg-bbc17480da6d051c696489654c64064a>Assigner des pods aux nœuds</a></li><li>5.3.10: <a href=#pg-1e7baac1825631a5af5d2aebcf059249>Configurer l'initialisation du pod</a></li><li>5.3.11: <a href=#pg-ed34e761c3dbd00fa79577fa78e30020>Configurer un pod pour utiliser une ConfigMap</a></li><li>5.3.12: <a href=#pg-3d7b9cb24a647c36ba63f7a02ec49010>Partager l'espace de nommage des processus entre les conteneurs d'un Pod</a></li><li>5.3.13: <a href=#pg-1bb997c61a85de753d9994e7a312a291>Convertir un fichier Docker Compose en ressources Kubernetes</a></li></ul><li>5.4: <a href=#pg-aa0731e8aa8e2f6cc9e3c1a5e9895863>Gérez vos objets Kubernetes</a></li><ul></ul><li>5.5: <a href=#pg-866924fa095f897ede8dfdcab9e97942>Injection des données dans les applications</a></li><ul></ul><li>5.6: <a href=#pg-a78a5e7e765fd8c49c8f7c0d72499f72>Exécution des applications</a></li><ul></ul><li>5.7: <a href=#pg-ca3bc4e31dfe46d5044a3b93eb804ee9>Exécution des jobs</a></li><ul></ul><li>5.8: <a href=#pg-b74b959f5a531003dd0653dfbfc2e88b>Accès aux applications dans un cluster</a></li><ul><li>5.8.1: <a href=#pg-777447042cd4e81df3fa5beb3357a485>Tableau de bord (Dashboard)</a></li><li>5.8.2: <a href=#pg-5a233e14205d77fe1294917d2da6f876>Configurer l'accès à plusieurs clusters</a></li><li>5.8.3: <a href=#pg-48e8f306f919c5b81265e265a2b76ab4>Lister toutes les images de conteneur exécutées dans un cluster</a></li></ul><li>5.9: <a href=#pg-f6a755efe831d24956501e4bcd49ff96>Monitoring, Logging et Debugging</a></li><ul><li>5.9.1: <a href=#pg-9713ac27b6d9e3034033200d968221f2>Obtenez un shell dans un conteneur en cours d'exécution</a></li></ul><li>5.10: <a href=#pg-fd78dc15c135dedc24438431769d4d5b>Extensions de Kubernetes</a></li><ul><li>5.10.1: <a href=#pg-5b9d7df11699e8cb1a5a4414ff770efe>Utilisation des ressources personnalisées</a></li><ul></ul></ul><li>5.11: <a href=#pg-d3c88a8663f58e9ec0bed73faff5b670>TLS</a></li><ul></ul><li>5.12: <a href=#pg-40e9293a348cfa50147082afc09ff77f>Fédération</a></li><ul><li>5.12.1: <a href=#pg-b61e5206fb2a30cabe2857ed4aaf7944>Administration du Control Plane de la fédération</a></li><ul></ul></ul><li>5.13: <a href=#pg-ba58efa15c6d46f10e34d799be220965>Gestion des démons du cluster</a></li><ul></ul><li>5.14: <a href=#pg-5266308e17490aeee8b018316bf47e03>Installation du catalogue de services</a></li><ul></ul></ul><li>6: <a href=#pg-68ec2370d0409cc27325be36693f9368>Tutoriels</a></li><ul><li>6.1: <a href=#pg-5e3051fff9e84735871d9fb5e7b93f33>Hello Minikube</a></li><li>6.2: <a href=#pg-3c83f53a74233ace9b289ac5e24c3e62>Apprendre les bases de Kubernetes</a></li><ul><li>6.2.1: <a href=#pg-7df66040311338d6098ebeab43ba9afb>Créer un cluster</a></li><ul><li>6.2.1.1: <a href=#pg-de49316920e97a82e36763cb66781ada>Utiliser Minikube pour créer un cluster</a></li><li>6.2.1.2: <a href=#pg-323b75976001e8dfe35d67d61bc74f1a>Didacticiel interactif - Création d'un cluster</a></li></ul><li>6.2.2: <a href=#pg-76d78b3fba507f7ed33cef14a35b631d>Déployer une application</a></li><ul><li>6.2.2.1: <a href=#pg-2b1bba431989008c7493109a0f049ece>Utiliser kubectl pour créer un déploiement</a></li><li>6.2.2.2: <a href=#pg-f8997ec143b382fa6c9621941ea62ca3>Tutoriel interactif - Déploiement d'une application</a></li></ul><li>6.2.3: <a href=#pg-250d620a73ec8be7e1f7d835574c4596>Explorez vos applications</a></li><ul><li>6.2.3.1: <a href=#pg-2771f4e8c45321b17cb0114a2d266453>Affichage des pods et des nœuds</a></li></ul><li>6.2.4: <a href=#pg-4b0e31c9e0eae68bbb0a358b4042ada9>Rendre publique votre application</a></li><ul></ul><li>6.2.5: <a href=#pg-be4996c93fb39c459a30b6669569d423>Mise à l'échelle des applications</a></li><ul></ul><li>6.2.6: <a href=#pg-62b8b17dadfb55f1801cf8439e944e58>Mise à jour des applications</a></li><ul></ul></ul><li>6.3: <a href=#pg-327beaa8e74d617d5ed749137ae5dfd9>Formations en ligne</a></li><ul></ul><li>6.4: <a href=#pg-a3a0f1c6af19fc89ce24d8cd42c0249f>Configuration</a></li><ul></ul><li>6.5: <a href=#pg-1efbbc2c3015389f835b1661d5effb29>Applications sans états</a></li><ul></ul><li>6.6: <a href=#pg-d6336d9712aa433eb5f0fb8cbed6bef7>Applications avec états</a></li><ul></ul><li>6.7: <a href=#pg-1ea281893eade34904c0cbd26b4228cb>Clusters</a></li><ul></ul><li>6.8: <a href=#pg-97489f0aa8ac2df31a0d6b444a7bde62>Services</a></li><ul></ul></ul><li>7: <a href=#pg-b00a88a07ceb21b1a83e5822e0c86c1d>Documents de Référence</a></li><ul><li>7.1: <a href=#pg-2b03679960950df772fb4fe7d78427b9>Glossary</a></li><li>7.2: <a href=#pg-af7c1f9168ec67f957edc504f43faf9a>Problèmes et alertes de sécurité de Kubernetes</a></li><ul></ul><li>7.3: <a href=#pg-882c82a32bfb4d7946585a93a966b442>Utilisation de l'API Kubernetes</a></li><ul></ul><li>7.4: <a href=#pg-99b26586d8a33ec06996dcf7892a9683>Accéder à l'API</a></li><ul></ul><li>7.5: <a href=#pg-60a16da3955f1de774f1f8dd756f2251>Référence de l'API</a></li><ul></ul><li>7.6: <a href=#pg-5bbbc5163b35431b3bff029ab9ec57d3>Référence des outils d'installation</a></li><ul><li>7.6.1: <a href=#pg-f351ced098abbb076bc8c4be1053672b>Kubeadm</a></li><ul><li>7.6.1.1: <a href=#pg-ac27ec04cad4f711698a27637c3c8300>Aperçu de kubeadm</a></li><li>7.6.1.2: <a href=#pg-36c22b52e8447eb3d2452d4f56fbea9b>Kubeadm généré</a></li><ul><li>7.6.1.2.1: <a href=#pg-dcfffcaafb438cd650475945ddc129ee></a></li></ul><li>7.6.1.3: <a href=#pg-82b2fcf985bae77dcb754387a9fcc64f>kubeadm init</a></li></ul><li>7.6.2: <a href=#pg-d8df553bae844c94dada72f2d4a75485>kubefed</a></li><ul></ul></ul><li>7.7: <a href=#pg-03460a7254c6c73eb2a1bb3dd7d25910>CLI kubectl</a></li><ul><li>7.7.1: <a href=#pg-f14fe15ecc2d41b5e901ef5e872ca657>Aperçu de kubectl</a></li><li>7.7.2: <a href=#pg-a938176c695852fe70362c29cf615f1c>Support de JSONPath</a></li><li>7.7.3: <a href=#pg-8aba901ac13f124e5782b90ddb166ee2>Aide-mémoire kubectl</a></li><li>7.7.4: <a href=#pg-d7ffbf04ffbefb241fd0722423b80f5a>Commandes kubectl</a></li><li>7.7.5: <a href=#pg-8de6aceb8bf692c06cced446bac5bc92>Conventions d'utilisation de kubectl</a></li><li>7.7.6: <a href=#pg-4d3e62632c189fcc3c1357cd8fb8799c>kubectl</a></li></ul><li>7.8: <a href=#pg-54e562dd1441d0195970a6526b0055cc>Référence sur les outils en ligne de commande</a></li><ul></ul></ul><li>8: <a href=#pg-4985cb55ddfb184639d767ec54b9f0f7>Contribuer à la documentation Kubernetes</a></li><ul><li>8.1: <a href=#pg-3609b0e10614f1dc39ed781858319204>Commencez à contribuer</a></li><li>8.2: <a href=#pg-8111429863728051b460e1f3a75b6fea>Contributions avancées</a></li><li>8.3: <a href=#pg-a2d946282df02cdeb47d9f54dfef198e>Aperçu du style de documentation</a></li><ul><li>8.3.1: <a href=#pg-75de610057816ac48210db20ec633217>Documentation Style Guide</a></li><li>8.3.2: <a href=#pg-4f09c4b708d2dd4ac9eac1080dab6728>Rédiger une nouveau sujet</a></li><li>8.3.3: <a href=#pg-6d95158118c9a27343edd2e6e23f0247>Utilisation des modèles de page</a></li><li>8.3.4: <a href=#pg-357f2ddd61035f18c2aa63fe86203f9c>Organisation du contenu</a></li><li>8.3.5: <a href=#pg-6d76d18115f82583d526bdaf5d05edbc>Hugo Shortcodes personnalisés</a></li></ul><li>8.4: <a href=#pg-29765496ca296ad24e34e5c0cd42a63f>Vue d'ensemble des documents de référence</a></li><ul><li>8.4.1: <a href=#pg-6e4e78f20e40bac9bcad59941e974af6>Génération de documentation de référence pour l'API Kubernetes</a></li><li>8.4.2: <a href=#pg-cb2951ff9bcf2a10d6658325c7a502c5>Génération de la documentation de référence pour l'API de fédération Kubernetes</a></li><li>8.4.3: <a href=#pg-28fc50a0072b0b2b444aa24e552d2e60>Génération de pages de référence pour les composants et les outils Kubernetes</a></li></ul><li>8.5: <a href=#pg-e1098d3fca853af3d9dd514e4309cbba>Participez au SIG Docs</a></li><li>8.6: <a href=#pg-849a2fdb87779db1c212fe5a9f88ff0d>Traduction de la documentation Kubernetes</a></li></ul></ul><div class=content></div></div><div class=td-content><h1 id=pg-e735cee7e913aa88bc0aa10594d12966>1 - Documentation de Kubernetes</h1><div class=lead>Documentation francophone de Kubernetes</div></div><div class=td-content><h1 id=pg-92dfff0ca612d0bff40171aa9df6c4ae>1.1 - Versions supportées de la documentation Kubernetes</h1><div class=lead>Documentation de Kubernetes</div><p>Ce site contient la documentation de la version actuelle de Kubernetes et les quatre versions précédentes de Kubernetes.</p><h2 id=version-courante>Version courante</h2><p>La version actuelle est <a href=/>v1.25</a>.</p><h2 id=versions-précédentes>Versions précédentes</h2><ul><li><a href=https://v1-24.docs.kubernetes.io>v1.24</a></li><li><a href=https://v1-23.docs.kubernetes.io>v1.23</a></li><li><a href=https://v1-22.docs.kubernetes.io>v1.22</a></li><li><a href=https://v1-21.docs.kubernetes.io>v1.21</a></li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-66b565805ca1061be35ff2c0165f13c1>2 - Installation</h1><div class=lead>Panorama de solution Kubernetes</div><p>Utilisez cette page pour trouver le type de solution qui correspond le mieux à vos besoins.</p><p>Le choix de distribution Kubernetes dépend des ressources dont vous disposez et de la flexibilité dont vous avez besoin.
Vous pouvez exécuter Kubernetes presque partout, de votre ordinateur portable aux machines virtuelles d'un fournisseur de cloud jusqu'à un rack de serveurs en bare metal.
Vous pouvez également mettre en place un cluster entièrement géré en exécutant une seule commande ou bien créer votre propre cluster personnalisé sur vos serveurs bare-metal.</p><h2 id=solutions-locales>Solutions locales</h2><p>La solution locale, installée sur votre machine, est un moyen facile de démarrer avec Kubernetes. Vous
pouvez créer et tester des clusters Kubernetes sans vous soucier de la consommation
des ressources et des quotas d'un cloud.</p><p>Vous devriez choisir une solution locale si vous souhaitez :</p><ul><li>Essayer ou commencer à apprendre Kubernetes</li><li>Développer et réaliser des tests sur des clusters locaux</li></ul><p>Choisissez une <a href=/fr/docs/setup/pick-right-solution/#solutions-locales>solution locale</a>.</p><h2 id=solutions-hébergées>Solutions hébergées</h2><p>Les solutions hébergées sont un moyen pratique de créer et de maintenir des clusters Kubernetes. Elles
permettent de gérer et d'exploiter vos clusters pour que vous n'ayez pas à le faire.</p><p>Vous devriez choisir une solution hébergée si vous :</p><ul><li>Voulez une solution entièrement gérée</li><li>Voulez vous concentrer sur le développement de vos applications ou services</li><li>N'avez pas d'équipe de Site Reliability Engineering (SRE) dédiée, mais que vous souhaitez une haute disponibilité.</li><li>Vous n'avez pas les ressources pour héberger et surveiller vos clusters</li></ul><p>Choisissez une <a href=/fr/docs/setup/pick-right-solution/#solutions-heberg%C3%A9es>solution hébergée</a>.</p><h2 id=solutions-cloud-clés-en-main>Solutions cloud clés en main</h2><p>Ces solutions vous permettent de créer des clusters Kubernetes avec seulement quelques commandes et
sont activement développées et bénéficient du soutien actif de la communauté. Elles peuvent également être hébergés sur
un ensemble de fournisseurs de Cloud de type IaaS, mais elles offrent plus de liberté et de flexibilité en contrepartie
d'un effort à fournir plus important.</p><p>Vous devriez choisir une solution cloud clés en main si vous :</p><ul><li>Voulez plus de contrôle sur vos clusters que ne le permettent les solutions hébergées</li><li>Voulez réaliser vous même un plus grand nombre d'operations</li></ul><p>Choisissez une <a href=/fr/docs/setup/pick-right-solution/#solutions-cl%C3%A9s-en-main>solution clé en main</a></p><h2 id=solutions-clés-en-main-sur-site>Solutions clés en main sur site</h2><p>Ces solutions vous permettent de créer des clusters Kubernetes sur votre cloud privé, interne et sécurisé,
avec seulement quelques commandes.</p><p>Vous devriez choisir une solution de cloud clé en main sur site si vous :</p><ul><li>Souhaitez déployer des clusters sur votre cloud privé</li><li>Disposez d'une équipe SRE dédiée</li><li>Avez les ressources pour héberger et surveiller vos clusters</li></ul><p>Choisissez une <a href=/fr/docs/setup/pick-right-solution/#solutions-on-premises-cl%C3%A9s-en-main>solution clé en main sur site</a>.</p><h2 id=solutions-personnalisées>Solutions personnalisées</h2><p>Les solutions personnalisées vous offrent le maximum de liberté sur vos clusters, mais elles nécessitent plus
d'expertise. Ces solutions vont du bare-metal aux fournisseurs de cloud sur
différents systèmes d'exploitation.</p><p>Choisissez une <a href=/fr/docs/setup/pick-right-solution/#solutions-personnalis%C3%A9es>solution personnalisée</a>.</p><h2 id=a-suivre>A suivre</h2><p>Allez à <a href=/fr/docs/setup/pick-right-solution/>Choisir la bonne solution</a> pour une liste complète de solutions.</p></div><div class=td-content style=page-break-before:always><h1 id=pg-0b597086a9d1382f86abadcfeab657d6>2.1 - Environnement d'apprentissage</h1></div><div class=td-content><h1 id=pg-8b996bf57bd8e67340235da1a1fb8e95>2.1.1 - Installer Kubernetes avec Minikube</h1><p>Minikube est un outil facilitant l’exécution locale de Kubernetes.
Minikube exécute un cluster Kubernetes à nœud unique dans une machine virtuelle (VM) de votre ordinateur portable pour les utilisateurs qui souhaitent essayer Kubernetes ou le développer au quotidien.</p><h2 id=fonctionnalités-de-minikube>Fonctionnalités de Minikube</h2><p>Minikube prend en charge les fonctionnalités Kubernetes suivantes:</p><ul><li>DNS</li><li>NodePorts</li><li>ConfigMaps et Secrets</li><li>Dashboards</li><li>Container Runtime: Docker, <a href=https://cri-o.io/>CRI-O</a>, et <a href=https://github.com/containerd/containerd>containerd</a></li><li>Activation de la CNI (Container Network Interface)</li><li>Ingress</li></ul><h2 id=installation>Installation</h2><p>Consultez <a href=/docs/tasks/tools/install-minikube/>Installation de Minikube</a>.</p><h2 id=démarrage-rapide>Démarrage rapide</h2><p>Cette brève démonstration vous explique comment démarrer, utiliser et supprimer les minikube localement.
Suivez les étapes ci-dessous pour commencer et explorer Minikube.</p><ol><li><p>Lancez Minikube et créez un cluster:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>minikube start
</span></span></code></pre></div><p>Le résultat est similaire à ceci:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-text data-lang=text><span style=display:flex><span>Starting local Kubernetes cluster...
</span></span><span style=display:flex><span>Running pre-create checks...
</span></span><span style=display:flex><span>Creating machine...
</span></span><span style=display:flex><span>Starting local Kubernetes cluster...
</span></span></code></pre></div><p>Pour plus d'informations sur le démarrage de votre cluster avec une version spécifique de Kubernetes, une machine virtuelle ou un environnement de conteneur, voir <a href=#starting-a-cluster>Démarrage d'un cluster</a>.</p></li><li><p>Vous pouvez maintenant interagir avec votre cluster à l'aide de kubectl.
Pour plus d'informations, voir <a href=#interacting-with-your-cluster>Interagir avec votre cluster</a>.</p><p>Créons un déploiement Kubernetes en utilisant une image existante nommée <code>echoserver</code>, qui est un serveur HTTP, et exposez-la sur le port 8080 à l’aide de <code>--port</code>.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl create deployment hello-minikube --image<span style=color:#666>=</span>k8s.gcr.io/echoserver:1.10
</span></span></code></pre></div><p>Le résultat est similaire à ceci:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-text data-lang=text><span style=display:flex><span>deployment.apps/hello-minikube created
</span></span></code></pre></div></li><li><p>Pour accéder au Deployment <code>hello-minikube</code>, exposez-le comme un Service:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl expose deployment hello-minikube --type<span style=color:#666>=</span>NodePort --port<span style=color:#666>=</span><span style=color:#666>8080</span>
</span></span></code></pre></div><p>L'option <code>--type=NodePort</code> spécifie le type du Service.</p><p>Le résultat est similaire à ceci:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-text data-lang=text><span style=display:flex><span>service/hello-minikube exposed
</span></span></code></pre></div></li><li><p>Le Pod <code>hello-minikube</code> est maintenant lancé, mais vous devez attendre que le Pod soit opérationnel avant d'y accéder via le Service.</p><p>Vérifiez si le Pod est opérationnel:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get pod
</span></span></code></pre></div><p>Si la sortie affiche le <code>STATUS</code> comme <code>ContainerCreating</code>, le Pod est toujours en cours de création:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-text data-lang=text><span style=display:flex><span>NAME                              READY     STATUS              RESTARTS   AGE
</span></span><span style=display:flex><span>hello-minikube-3383150820-vctvh   0/1       ContainerCreating   0          3s
</span></span></code></pre></div><p>Si la sortie indique le statut <code>STATUS</code> comme <code>Running</code>, le Pod est maintenant opérationnel:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-text data-lang=text><span style=display:flex><span>NAME                              READY     STATUS    RESTARTS   AGE
</span></span><span style=display:flex><span>hello-minikube-3383150820-vctvh   1/1       Running   0          13s
</span></span></code></pre></div></li><li><p>Obtenez l'URL du Service exposé pour afficher les détails du service:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>minikube service hello-minikube --url
</span></span></code></pre></div></li><li><p>Pour afficher les détails de votre cluster local, copiez et collez l’URL que vous avez obtenue en tant que sortie dans votre navigateur.</p><p>Le résultat est similaire à ceci:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-text data-lang=text><span style=display:flex><span>Hostname: hello-minikube-7c77b68cff-8wdzq
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>Pod Information:
</span></span><span style=display:flex><span>    -no pod information available-
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>Server values:
</span></span><span style=display:flex><span>    server_version=nginx: 1.13.3 - lua: 10008
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>Request Information:
</span></span><span style=display:flex><span>    client_address=172.17.0.1
</span></span><span style=display:flex><span>    method=GET
</span></span><span style=display:flex><span>    real path=/
</span></span><span style=display:flex><span>    query=
</span></span><span style=display:flex><span>    request_version=1.1
</span></span><span style=display:flex><span>    request_scheme=http
</span></span><span style=display:flex><span>    request_uri=http://192.168.99.100:8080/
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>Request Headers:
</span></span><span style=display:flex><span>    accept=*/*
</span></span><span style=display:flex><span>    host=192.168.99.100:30674
</span></span><span style=display:flex><span>    user-agent=curl/7.47.0
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>Request Body:
</span></span><span style=display:flex><span>    -no body in request-
</span></span></code></pre></div><p>Si vous ne souhaitez plus que le service et le cluster s'exécutent, vous pouvez les supprimer.</p></li><li><p>Supprimez le Service <code>hello-minikube</code>:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span> kubectl delete services hello-minikube
</span></span></code></pre></div><p>Le résultat est similaire à ceci:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-text data-lang=text><span style=display:flex><span>service &#34;hello-minikube&#34; deleted
</span></span></code></pre></div></li><li><p>Supprimez le Deployment <code>hello-minikube</code>:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl delete deployment hello-minikube
</span></span></code></pre></div><p>Le résultat est similaire à ceci:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-text data-lang=text><span style=display:flex><span>deployment.extensions &#34;hello-minikube&#34; deleted
</span></span></code></pre></div></li><li><p>Arrêtez le cluster de minikube local:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>minikube stop
</span></span></code></pre></div><p>Le résultat est similaire à ceci:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-text data-lang=text><span style=display:flex><span>Stopping &#34;minikube&#34;...
</span></span><span style=display:flex><span>&#34;minikube&#34; stopped.
</span></span></code></pre></div><p>Pour plus d'informations, voir <a href=#stopping-a-cluster>Arrêt d'un cluster</a>.</p></li><li><p>Supprimez le cluster de minikube local:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>minikube delete
</span></span></code></pre></div><p>Le résultat est similaire à ceci:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-text data-lang=text><span style=display:flex><span>Deleting &#34;minikube&#34; ...
</span></span><span style=display:flex><span>The &#34;minikube&#34; cluster has been deleted.
</span></span></code></pre></div><p>Pour plus d'informations, voir <a href=#deleting-a-cluster>Suppression d'un cluster</a>.</p></li></ol><h2 id=gérer-votre-cluster>Gérer votre cluster</h2><h3 id=démarrer-un-cluster>Démarrer un cluster</h3><p>La commande <code>minikube start</code> peut être utilisée pour démarrer votre cluster.
Cette commande crée et configure une machine virtuelle qui exécute un cluster Kubernetes à un seul nœud.
Cette commande configure également <a href=/docs/user-guide/kubectl-overview/>kubectl</a> pour communiquer avec ce cluster.</p><div class="alert alert-info note callout" role=alert><strong>Note:</strong><p>Si vous êtes derrière un proxy Web, vous devez transmettre ces informations à la commande <code>minikube start</code>:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span><span style=color:#b8860b>https_proxy</span><span style=color:#666>=</span>&lt;my proxy&gt; minikube start --docker-env <span style=color:#b8860b>http_proxy</span><span style=color:#666>=</span>&lt;my proxy&gt; --docker-env <span style=color:#b8860b>https_proxy</span><span style=color:#666>=</span>&lt;my proxy&gt; --docker-env <span style=color:#b8860b>no_proxy</span><span style=color:#666>=</span>192.168.99.0/24
</span></span></code></pre></div><p>Malheureusement, définir les seules variables d'environnement ne fonctionne pas.</p><p>Minikube crée également un contexte "minikube" et le définit par défaut dans kubectl.
Pour revenir à ce contexte, exécutez la commande suivante: <code>kubectl config use-context minikube</code>.</p></div><h4 id=spécifier-la-version-de-kubernetes>Spécifier la version de Kubernetes</h4><p>Vous pouvez spécifier la version de Kubernetes pour Minikube à utiliser en ajoutant la chaîne <code>--kubernetes-version</code> à la commande <code>minikube start</code>.
Par exemple, pour exécuter la version v1.25.0, procédez comme suit:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>minikube start --kubernetes-version v1.25.0
</span></span></code></pre></div><h4 id=spécification-du-pilote-de-machine-virtuelle>Spécification du pilote de machine virtuelle</h4><p>Vous pouvez changer le pilote de machine virtuelle en ajoutant l'indicateur <code>--vm-driver=&lt;nom_du_pilote></code> à <code>minikube start</code>.
Par exemple, la commande serait:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>minikube start --vm-driver<span style=color:#666>=</span>&lt;nom_du_pilote&gt;
</span></span></code></pre></div><p>Minikube prend en charge les pilotes suivants:<div class="alert alert-info note callout" role=alert><strong>Note:</strong> Voir <a href=https://minikube.sigs.k8s.io/docs/drivers/>DRIVERS</a> pour plus de détails sur les pilotes pris en charge et comment installer les plugins.</div></p><ul><li>virtualbox</li><li>vmwarefusion</li><li>kvm2 (<a href=https://minikube.sigs.k8s.io/docs/drivers/#kvm2-driver>installation du pilote</a>)</li><li>hyperkit (<a href=https://minikube.sigs.k8s.io/docs/drivers/#hyperkit-driver>installation du pilote</a>)</li><li>hyperv (<a href=https://minikube.sigs.k8s.io/docs/drivers/#hyperv-driver>installation du pilote</a>)
Notez que l'adresse IP ci-dessous est dynamique et peut changer. Il peut être récupéré avec <code>minikube ip</code>.</li><li>vmware (<a href=https://minikube.sigs.k8s.io/docs/drivers/#vmware-unified-driver>installation du pilote</a>) (VMware unified driver)</li><li>none (Exécute les composants Kubernetes sur l’hôte et non sur une machine virtuelle. Il n'est pas recommandé d'exécuter le pilote none sur des postes de travail personnels. L'utilisation de ce pilote nécessite Docker (<a href=https://docs.docker.com/install/linux/docker-ce/ubuntu/>docker installer</a>) et un environnement Linux)</li></ul><h4 id=démarrage-d-un-cluster-sur-des-exécutions-de-conteneur-alternatives>Démarrage d'un cluster sur des exécutions de conteneur alternatives</h4><p>Vous pouvez démarrer Minikube aux exécutions de conteneurs suivantes.<ul class="nav nav-tabs" id=container-runtimes role=tablist><li class=nav-item><a data-toggle=tab class="nav-link active" href=#container-runtimes-0 role=tab aria-controls=container-runtimes-0 aria-selected=true>containerd</a></li><li class=nav-item><a data-toggle=tab class=nav-link href=#container-runtimes-1 role=tab aria-controls=container-runtimes-1>CRI-O</a></li></ul><div class=tab-content id=container-runtimes><div id=container-runtimes-0 class="tab-pane show active" role=tabpanel aria-labelledby=container-runtimes-0><p><p>Pour utiliser <a href=https://github.com/containerd/containerd>containerd</a> en tant que moteur d'exécution du conteneur, exécutez:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>minikube start <span style=color:#b62;font-weight:700>\
</span></span></span><span style=display:flex><span><span style=color:#b62;font-weight:700></span>    --network-plugin<span style=color:#666>=</span>cni <span style=color:#b62;font-weight:700>\
</span></span></span><span style=display:flex><span><span style=color:#b62;font-weight:700></span>    --enable-default-cni <span style=color:#b62;font-weight:700>\
</span></span></span><span style=display:flex><span><span style=color:#b62;font-weight:700></span>    --container-runtime<span style=color:#666>=</span>containerd <span style=color:#b62;font-weight:700>\
</span></span></span><span style=display:flex><span><span style=color:#b62;font-weight:700></span>    --bootstrapper<span style=color:#666>=</span>kubeadm
</span></span></code></pre></div><p>Ou vous pouvez utiliser la version étendue:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>minikube start <span style=color:#b62;font-weight:700>\
</span></span></span><span style=display:flex><span><span style=color:#b62;font-weight:700></span>    --network-plugin<span style=color:#666>=</span>cni <span style=color:#b62;font-weight:700>\
</span></span></span><span style=display:flex><span><span style=color:#b62;font-weight:700></span>    --enable-default-cni <span style=color:#b62;font-weight:700>\
</span></span></span><span style=display:flex><span><span style=color:#b62;font-weight:700></span>    --extra-config<span style=color:#666>=</span>kubelet.container-runtime<span style=color:#666>=</span>remote <span style=color:#b62;font-weight:700>\
</span></span></span><span style=display:flex><span><span style=color:#b62;font-weight:700></span>    --extra-config<span style=color:#666>=</span>kubelet.container-runtime-endpoint<span style=color:#666>=</span>unix:///run/containerd/containerd.sock <span style=color:#b62;font-weight:700>\
</span></span></span><span style=display:flex><span><span style=color:#b62;font-weight:700></span>    --extra-config<span style=color:#666>=</span>kubelet.image-service-endpoint<span style=color:#666>=</span>unix:///run/containerd/containerd.sock <span style=color:#b62;font-weight:700>\
</span></span></span><span style=display:flex><span><span style=color:#b62;font-weight:700></span>    --bootstrapper<span style=color:#666>=</span>kubeadm
</span></span></code></pre></div></div><div id=container-runtimes-1 class=tab-pane role=tabpanel aria-labelledby=container-runtimes-1><p><p>Pour utiliser <a href=https://cri-o.io/>CRI-O</a> comme environnement d'exécution du conteneur, exécutez:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>minikube start <span style=color:#b62;font-weight:700>\
</span></span></span><span style=display:flex><span><span style=color:#b62;font-weight:700></span>    --network-plugin<span style=color:#666>=</span>cni <span style=color:#b62;font-weight:700>\
</span></span></span><span style=display:flex><span><span style=color:#b62;font-weight:700></span>    --enable-default-cni <span style=color:#b62;font-weight:700>\
</span></span></span><span style=display:flex><span><span style=color:#b62;font-weight:700></span>    --container-runtime<span style=color:#666>=</span>cri-o <span style=color:#b62;font-weight:700>\
</span></span></span><span style=display:flex><span><span style=color:#b62;font-weight:700></span>    --bootstrapper<span style=color:#666>=</span>kubeadm
</span></span></code></pre></div><p>Ou vous pouvez utiliser la version étendue:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>minikube start <span style=color:#b62;font-weight:700>\
</span></span></span><span style=display:flex><span><span style=color:#b62;font-weight:700></span>    --network-plugin<span style=color:#666>=</span>cni <span style=color:#b62;font-weight:700>\
</span></span></span><span style=display:flex><span><span style=color:#b62;font-weight:700></span>    --enable-default-cni <span style=color:#b62;font-weight:700>\
</span></span></span><span style=display:flex><span><span style=color:#b62;font-weight:700></span>    --extra-config<span style=color:#666>=</span>kubelet.container-runtime<span style=color:#666>=</span>remote <span style=color:#b62;font-weight:700>\
</span></span></span><span style=display:flex><span><span style=color:#b62;font-weight:700></span>    --extra-config<span style=color:#666>=</span>kubelet.container-runtime-endpoint<span style=color:#666>=</span>/var/run/crio.sock <span style=color:#b62;font-weight:700>\
</span></span></span><span style=display:flex><span><span style=color:#b62;font-weight:700></span>    --extra-config<span style=color:#666>=</span>kubelet.image-service-endpoint<span style=color:#666>=</span>/var/run/crio.sock <span style=color:#b62;font-weight:700>\
</span></span></span><span style=display:flex><span><span style=color:#b62;font-weight:700></span>    --bootstrapper<span style=color:#666>=</span>kubeadm
</span></span></code></pre></div></div></div></p><h4 id=utiliser-des-images-locales-en-réutilisant-le-démon-docker>Utiliser des images locales en réutilisant le démon Docker</h4><p>Lorsque vous utilisez une seule machine virtuelle pour Kubernetes, il est utile de réutiliser le démon Docker intégré de Minikube.
La réutilisation du démon intégré signifie que vous n’avez pas besoin de créer un registre Docker sur votre ordinateur hôte et d’y insérer l’image.
Au lieu de cela, vous pouvez créer le même démon Docker que Minikube, ce qui accélère les expériences locales.</p><div class="alert alert-info note callout" role=alert><strong>Note:</strong> Assurez-vous de marquer votre image Docker avec autre chose que la plus récente et utilisez cette balise pour extraire l'image.
Parce que <code>:latest</code> est la valeur par défaut, avec une stratégie d'extraction d'image par défaut correspondante de <code>Always</code>, une erreur d'extraction d'image (<code>ErrImagePull</code>) est éventuellement générée si vous n'avez pas l'image Docker dans le registre par défaut de Docker (généralement DockerHub). .</div><p>Pour travailler avec le démon Docker sur votre hôte Mac/Linux, utilisez la commande <code>docker-env</code> dans votre shell:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span><span style=color:#a2f>eval</span> <span style=color:#a2f;font-weight:700>$(</span>minikube docker-env<span style=color:#a2f;font-weight:700>)</span>
</span></span></code></pre></div><p>Vous pouvez maintenant utiliser Docker sur la ligne de commande de votre ordinateur hôte Mac/Linux pour communiquer avec le démon Docker dans la VM Minikube:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>docker ps
</span></span></code></pre></div><div class="alert alert-info note callout" role=alert><strong>Note:</strong><p>Sur Centos 7, Docker peut signaler l’erreur suivante:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-text data-lang=text><span style=display:flex><span>Could not read CA certificate &#34;/etc/docker/ca.pem&#34;: open /etc/docker/ca.pem: no such file or directory
</span></span></code></pre></div><p>Vous pouvez résoudre ce problème en mettant à jour <code>/etc/sysconfig/docker</code> pour vous assurer que les modifications de l'environnement de Minikube sont respectées:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>&lt; <span style=color:#b8860b>DOCKER_CERT_PATH</span><span style=color:#666>=</span>/etc/docker
</span></span><span style=display:flex><span>---
</span></span><span style=display:flex><span>&gt; <span style=color:#a2f;font-weight:700>if</span> <span style=color:#666>[</span> -z <span style=color:#b44>&#34;</span><span style=color:#b68;font-weight:700>${</span><span style=color:#b8860b>DOCKER_CERT_PATH</span><span style=color:#b68;font-weight:700>}</span><span style=color:#b44>&#34;</span> <span style=color:#666>]</span>; <span style=color:#a2f;font-weight:700>then</span>
</span></span><span style=display:flex><span>&gt;   <span style=color:#b8860b>DOCKER_CERT_PATH</span><span style=color:#666>=</span>/etc/docker
</span></span><span style=display:flex><span>&gt; <span style=color:#a2f;font-weight:700>fi</span>
</span></span></code></pre></div></div><h3 id=configuration-de-kubernetes>Configuration de Kubernetes</h3><p>Minikube a une fonction de "configurateur" qui permet aux utilisateurs de configurer les composants Kubernetes avec des valeurs arbitraires.
Pour utiliser cette fonctionnalité, vous pouvez utiliser l'indicateur <code>--extra-config</code> de la commande <code>minikube start</code>.</p><p>Cet indicateur est répété, vous pouvez donc le transmettre plusieurs fois avec plusieurs valeurs différentes pour définir plusieurs options.</p><p>Cet indicateur prend une chaîne de la forme <code>composant.key=valeur</code>, où <code>composant</code> est l'une des chaînes de la liste ci-dessous, <code>key</code> est une valeur de la structure de configuration et <code>valeur</code> est la valeur à définir.</p><p>Des clés valides peuvent être trouvées en examinant la documentation de Kubernetes <code>composantconfigs</code> pour chaque composant.
Voici la documentation pour chaque configuration prise en charge:</p><ul><li><a href=https://godoc.org/k8s.io/kubernetes/pkg/kubelet/apis/config#KubeletConfiguration>kubelet</a></li><li><a href=https://godoc.org/k8s.io/kubernetes/cmd/kube-apiserver/app/options#ServerRunOptions>apiserver</a></li><li><a href=https://godoc.org/k8s.io/kubernetes/pkg/proxy/apis/config#KubeProxyConfiguration>proxy</a></li><li><a href=https://godoc.org/k8s.io/kubernetes/pkg/controller/apis/config#KubeControllerManagerConfiguration>controller-manager</a></li><li><a href=https://godoc.org/github.com/coreos/etcd/etcdserver#ServerConfig>etcd</a></li><li><a href=https://godoc.org/k8s.io/kubernetes/pkg/scheduler/apis/config#KubeSchedulerConfiguration>scheduler</a></li></ul><h4 id=exemples>Exemples</h4><p>Pour changer le paramètre <code>MaxPods</code> en 5 sur le Kubelet, passez cet indicateur: <code>--extra-config=kubelet.MaxPods=5</code>.</p><p>Cette fonctionnalité prend également en charge les structures imbriquées.
Pour modifier le paramètre <code>LeaderElection.LeaderElect</code> sur <code>true</code> sur le planificateur, transmettez cet indicateur: <code>--extra-config=scheduler.LeaderElection.LeaderElect=true</code>.</p><p>Pour définir le <code>AuthorizationMode</code> du <code>apiserver</code> sur <code>RBAC</code>, vous pouvez utiliser: <code>--extra-config=apiserver.authorization-mode=RBAC</code>.</p><h3 id=arrêter-un-cluster>Arrêter un cluster</h3><p>La commande <code>minikube stop</code> peut être utilisée pour arrêter votre cluster.
Cette commande arrête la machine virtuelle Minikube, mais conserve tout l'état et les données du cluster.
Le redémarrage du cluster le restaurera à son état précédent.</p><h3 id=suppression-d-un-cluster>Suppression d'un cluster</h3><p>La commande <code>minikube delete</code> peut être utilisée pour supprimer votre cluster.
Cette commande ferme et supprime la machine virtuelle Minikube.
Aucune donnée ou état n'est conservé.</p><h3 id=mise-à-niveau-de-minikube>Mise à niveau de minikube</h3><p>Voir <a href=https://minikube.sigs.k8s.io/docs/start/macos/>upgrade minikube</a></p><h2 id=interagir-avec-votre-cluster>Interagir avec votre cluster</h2><h3 id=kubectl>Kubectl</h3><p>La commande <code>minikube start</code> crée <a href=/docs/reference/generated/kubectl/kubectl-commands#-em-set-context-em->un contexte kubectl</a> appelé "minikube".
Ce contexte contient la configuration pour communiquer avec votre cluster Minikube.</p><p>Minikube définit automatiquement ce contexte par défaut, mais si vous devez y revenir ultérieurement, exécutez:</p><p><code>kubectl config use-context minikube</code>,</p><p>Ou passez le contexte sur chaque commande comme ceci: <code>kubectl get pods --context=minikube</code>.</p><h3 id=dashboard>Dashboard</h3><p>Pour accéder au <a href=/docs/tasks/access-application-cluster/web-ui-dashboard/>Kubernetes Dashboard</a>, lancez cette commande dans un shell après avoir lancé Minikube pour obtenir l'adresse:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>minikube dashboard
</span></span></code></pre></div><h3 id=services>Services</h3><p>Pour accéder à un service exposé via un port de nœud, exécutez cette commande dans un shell après le démarrage de Minikube pour obtenir l'adresse:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>minikube service <span style=color:#666>[</span>-n NAMESPACE<span style=color:#666>]</span> <span style=color:#666>[</span>--url<span style=color:#666>]</span> NAME
</span></span></code></pre></div><h2 id=la-mise-en-réseau>La mise en réseau</h2><p>La machine virtuelle Minikube est exposée au système hôte via une adresse IP routable uniquement depuis le hôte, qui peut être obtenue à l'aide de la commande <code>minikube ip</code>.
Tous les services de type <code>NodePort</code> sont accessibles via cette adresse IP, sur le NodePort.</p><p>Pour déterminer le NodePort pour votre service, vous pouvez utiliser une commande <code>kubectl</code> comme celle-ci:</p><p><code>kubectl get service $SERVICE --output='jsonpath="{.spec.ports[0].nodePort}"'</code></p><h2 id=volumes-persistants>Volumes persistants</h2><p>Minikube supporte les <a href=/docs/concepts/storage/persistent-volumes/>PersistentVolumes</a> de type <code>hostPath</code>.
Ces volumes persistants sont mappés vers un répertoire à l'intérieur de la VM Minikube.</p><p>La machine virtuelle Minikube démarre dans un fichier tmpfs, de sorte que la plupart des répertoires ne seront pas conservés lors des redémarrages avec (<code>minikube stop</code>).
Toutefois, Minikube est configuré pour conserver les fichiers stockés dans les répertoires d’hôte suivants:</p><ul><li><code>/data</code></li><li><code>/var/lib/minikube</code></li><li><code>/var/lib/docker</code></li></ul><p>Voici un exemple de configuration PersistentVolume permettant de conserver des données dans le répertoire <code>/data</code>:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>PersistentVolume<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>pv0001<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>accessModes</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- ReadWriteOnce<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>capacity</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>storage</span>:<span style=color:#bbb> </span>5Gi<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>hostPath</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>path</span>:<span style=color:#bbb> </span>/data/pv0001/<span style=color:#bbb>
</span></span></span></code></pre></div><h2 id=dossiers-hôtes-montés>Dossiers hôtes montés</h2><p>Certains pilotes vont monter un dossier hôte dans la VM afin de pouvoir facilement partager des fichiers entre la VM et l'hôte.
Celles-ci ne sont pas configurables pour le moment et diffèrent selon le pilote et le système d'exploitation que vous utilisez.</p><div class="alert alert-info note callout" role=alert><strong>Note:</strong> Le partage de dossier hôte n'est pas encore implémenté dans le pilote KVM.</div><table><thead><tr><th>Pilote</th><th>OS</th><th>HostFolder</th><th>VM</th></tr></thead><tbody><tr><td>VirtualBox</td><td>Linux</td><td><code>/home</code></td><td><code>/hosthome</code></td></tr><tr><td>VirtualBox</td><td>macOS</td><td><code>/Users</code></td><td><code>/Users</code></td></tr><tr><td>VirtualBox</td><td>Windows</td><td><code>C:/Users</code></td><td><code>/c/Users</code></td></tr><tr><td>VMware Fusion</td><td>macOS</td><td><code>/Users</code></td><td><code>/Users</code></td></tr><tr><td>Xhyve</td><td>macOS</td><td><code>/Users</code></td><td><code>/Users</code></td></tr></tbody></table><h2 id=registres-de-conteneurs-privés>Registres de conteneurs privés</h2><p>Pour accéder à un registre de conteneurs privé, suivez les étapes de <a href=/docs/concepts/containers/images/>cette page</a>.</p><p>Nous vous recommandons d'utiliser <code>ImagePullSecrets</code>, mais si vous souhaitez configurer l'accès sur la VM Minikube, vous pouvez placer le <code>.dockercfg</code> dans le repertoire <code>/home/docker</code> ou le <code>config.json</code> dans le repertoire <code>/home/docker/.docker</code>.</p><h2 id=add-ons>Add-ons</h2><p>Pour que Minikube puisse démarrer ou redémarrer correctement des addons personnalisés, placez les addons que vous souhaitez lancer avec Minikube dans le répertoire <code>~/.minikube/addons</code>.
Les extensions de ce dossier seront déplacées vers la VM Minikube et lancées à chaque démarrage ou redémarrage de Minikube.</p><h2 id=utilisation-de-minikube-avec-un-proxy-http>Utilisation de Minikube avec un proxy HTTP</h2><p>Minikube crée une machine virtuelle qui inclut Kubernetes et un démon Docker.
Lorsque Kubernetes tente de planifier des conteneurs à l'aide de Docker, le démon Docker peut nécessiter un accès réseau externe pour extraire les conteneurs.</p><p>Si vous êtes derrière un proxy HTTP, vous devrez peut-être fournir à Docker les paramètres de proxy.
Pour ce faire, transmettez les variables d’environnement requises en tant qu’indicateurs lors de la création de <code>minikube start</code>.</p><p>Par exemple:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>minikube start --docker-env <span style=color:#b8860b>http_proxy</span><span style=color:#666>=</span>http://<span style=color:#b8860b>$YOURPROXY</span>:PORT <span style=color:#b62;font-weight:700>\
</span></span></span><span style=display:flex><span><span style=color:#b62;font-weight:700></span>                 --docker-env <span style=color:#b8860b>https_proxy</span><span style=color:#666>=</span>https://<span style=color:#b8860b>$YOURPROXY</span>:PORT
</span></span></code></pre></div><p>Si l'adresse de votre machine virtuelle est 192.168.99.100, il est probable que vos paramètres de proxy empêcheront <code>kubectl</code> de l'atteindre directement.
Pour contourner la configuration du proxy pour cette adresse IP, vous devez modifier vos paramètres no_proxy.
Vous pouvez le faire avec:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span><span style=color:#a2f>export</span> <span style=color:#b8860b>no_proxy</span><span style=color:#666>=</span><span style=color:#b8860b>$no_proxy</span>,<span style=color:#a2f;font-weight:700>$(</span>minikube ip<span style=color:#a2f;font-weight:700>)</span>
</span></span></code></pre></div><h2 id=problèmes-connus>Problèmes connus</h2><p>Les fonctionnalités nécessitant plusieurs nœuds ne fonctionneront pas dans Minikube.</p><h2 id=conception>Conception</h2><p>Minikube utilise <a href=https://github.com/docker/machine/tree/master/libmachine>libmachine</a> pour le provisionnement de machines virtuelles, et <a href=https://github.com/kubernetes/kubeadm>kubeadm</a> mettre en service un cluster Kubernetes.</p><p>Pour plus d'informations sur Minikube, voir la <a href=https://git.k8s.io/community/contributors/design-proposals/cluster-lifecycle/local-cluster-ux.md>proposition</a>.</p><h2 id=liens-supplémentaires>Liens supplémentaires</h2><ul><li><strong>Objectifs et non-objectifs</strong>: Pour les objectifs et non-objectifs du projet Minikube, veuillez consulter notre <a href=https://git.k8s.io/minikube/docs/contributors/roadmap.md>roadmap</a>.</li><li><strong>Guide de développement</strong>: Voir <a href=https://git.k8s.io/minikube/CONTRIBUTING.md>CONTRIBUTING.md</a> pour avoir un aperçu de comment envoyer des pull requests.</li><li><strong>Construire Minikube</strong>: Pour obtenir des instructions sur la création / test de Minikube à partir des sources, voir le <a href=https://git.k8s.io/minikube/docs/contributors/build_guide.md>guide de build</a>.</li><li><strong>Ajout d'une nouvelle dépendance</strong>: Pour savoir comment ajouter une nouvelle dépendance à Minikube, voir la section <a href=https://git.k8s.io/minikube/docs/contributors/adding_a_dependency.md>guide d'ajout de dépendances</a>.</li><li><strong>Ajout d'un nouvel addon</strong>: Pour savoir comment ajouter un nouvel addon pour Minikube, reportez-vous au <a href=https://git.k8s.io/minikube/docs/contributors/adding_an_addon.md>Ajout d’un addon</a>.</li><li><strong>MicroK8s</strong>: Les utilisateurs de Linux qui souhaitent éviter d’exécuter une machine virtuelle peuvent envisager <a href=https://microk8s.io/>MicroK8s</a>.</li></ul><h2 id=communauté>Communauté</h2><p>Les contributions, questions et commentaires sont les bienvenus et sont encouragés !
Les développeurs de minikube sont dans le canal #minikube du <a href=https://kubernetes.slack.com>Slack</a> de Kubernetes (recevoir une invitation <a href=http://slack.kubernetes.io/>ici</a>).
Nous avons également la liste de diffusion <a href=https://groups.google.com/a/kubernetes.io/g/dev/>dev@kubernetes Google Groupes</a>.
Si vous publiez sur la liste, veuillez préfixer votre sujet avec "minikube:".</p></div><div class=td-content style=page-break-before:always><h1 id=pg-d33663ac044e1981b406949f9124cc04>2.2 - Télécharger Kubernetes</h1><div class=lead>Téléchargement Kubernetes release</div></div><div class=td-content><h1 id=pg-10b7970741f3e4925d298f965641410e>2.2.1 - Construire une release</h1><div class=lead>Construire une release de la documentation Kubernetes</div><p>Vous pouvez soit compiler une version à partir des sources, soit télécharger une version pré-compilée. Si vous ne
prévoyez pas de développer Kubernetes nous vous suggérons d'utiliser une version pré-compilée de la version actuelle,
que l'on peut trouver dans le répertoire <a href=/docs/setup/release/notes/>Release Notes</a>.</p><p>Le code source de Kubernetes peut être téléchargé sur le repo <a href=https://github.com/kubernetes/kubernetes>kubernetes/kubernetes</a>.</p><h2 id=installer-à-partir-des-sources>Installer à partir des sources</h2><p>Si vous installez simplement une version à partir des sources, il n'est pas nécessaire de mettre en place un environnement golang complet car tous les builds se font dans un conteneur Docker.</p><p>Construire une release est simple.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>git clone https://github.com/kubernetes/kubernetes.git
</span></span><span style=display:flex><span><span style=color:#a2f>cd</span> kubernetes
</span></span><span style=display:flex><span>make release
</span></span></code></pre></div><p>Pour plus de détails sur le processus de release, voir le repertoire <a href=http://releases.k8s.io/master/build/><code>build</code></a> dans kubernetes/kubernetes.</p></div><div class=td-content style=page-break-before:always><h1 id=pg-4e14853fdaa3bd273f31a60112b9b5ac>2.3 - Environnement de production</h1></div><div class=td-content><h1 id=pg-00e1646f68aeb89f9722cf6f6cfcad94>2.3.1 - Installer Kubernetes avec les outils de déploiement</h1></div><div class=td-content><h1 id=pg-a16f59f325a17cdeed324d5c889f7f73>2.3.1.1 - Déploiement d'un cluster avec kubeadm</h1></div><div class=td-content><h1 id=pg-29e59491dd6118b23072dfe9ebb93323>2.3.1.1.1 - Installer kubeadm</h1><p><img src=/images/kubeadm-stacked-color.png align=right width=150px>Cette page vous apprend comment installer la boîte à outils <code>kubeadm</code>.
Pour plus d'informations sur la création d'un cluster avec kubeadm, une fois que vous avez effectué ce processus d'installation, voir la page: <a href=/fr/docs/setup/production-environment/tools/kubeadm/create-cluster-kubeadm/>Utiliser kubeadm pour créer un cluster</a>.</p><h2 id=pré-requis>Pré-requis</h2><ul><li>Une ou plusieurs machines exécutant:<ul><li>Ubuntu 16.04+</li><li>Debian 9+</li><li>CentOS 7</li><li>Red Hat Enterprise Linux (RHEL) 7</li><li>Fedora 25+</li><li>HypriotOS v1.0.1+</li><li>Flatcar Container Linux (testé avec 2512.3.0)</li></ul></li><li>2 Go ou plus de RAM par machine (toute quantité inférieure laissera peu de place à vos applications)</li><li>2 processeurs ou plus</li><li>Connectivité réseau complète entre toutes les machines du cluster (réseau public ou privé)</li><li>Nom d'hôte, adresse MAC et product_uuid uniques pour chaque nœud. Voir <a href=#verify-the-mac-address-and-product-uuid-are-unique-for-every-node>ici</a> pour plus de détails.</li><li>Certains ports doivent êtres ouverts sur vos machines. Voir <a href=#check-required-ports>ici</a> pour plus de détails.</li><li>Swap désactivé. Vous <strong>devez</strong> impérativement désactiver le swap pour que la kubelet fonctionne correctement.</li></ul><h2 id=verify-mac-address>Vérifiez que les adresses MAC et product_uuid sont uniques pour chaque nœud</h2><ul><li>Vous pouvez obtenir l'adresse MAC des interfaces réseau en utilisant la commande <code>ip link</code> ou<code> ifconfig -a</code></li><li>Le product_uuid peut être vérifié en utilisant la commande <code>sudo cat /sys/class/dmi/id/product_uuid</code></li></ul><p>Il est très probable que les périphériques matériels aient des adresses uniques, bien que
certaines machines virtuelles puissent avoir des valeurs identiques. Kubernetes utilise ces valeurs pour identifier de manière unique les nœuds du cluster.
Si ces valeurs ne sont pas uniques à chaque nœud, le processus d'installation
peut <a href=https://github.com/kubernetes/kubeadm/issues/31>échouer</a>.</p><h2 id=vérifiez-les-cartes-réseaux>Vérifiez les cartes réseaux</h2><p>Si vous avez plusieurs cartes réseaux et que vos composants Kubernetes ne sont pas accessibles par la route par défaut,
nous vous recommandons d’ajouter une ou plusieurs routes IP afin que les adresses de cluster Kubernetes soient acheminées via la carte approprié.</p><h2 id=permettre-à-iptables-de-voir-le-trafic-ponté>Permettre à iptables de voir le trafic ponté</h2><p>Assurez-vous que le module <code>br_netfilter</code> est chargé. Cela peut être fait en exécutant <code>lsmod | grep br_netfilter</code>. Pour le charger explicitement, appelez <code>sudo modprobe br_netfilter</code>.</p><p>Pour que les iptables de votre nœud Linux voient correctement le trafic ponté, vous devez vous assurer que <code>net.bridge.bridge-nf-call-iptables</code> est défini sur 1 dans votre configuration<code> sysctl</code>, par ex.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>cat <span style=color:#b44>&lt;&lt;EOF | sudo tee /etc/sysctl.d/k8s.conf
</span></span></span><span style=display:flex><span><span style=color:#b44>net.bridge.bridge-nf-call-ip6tables = 1
</span></span></span><span style=display:flex><span><span style=color:#b44>net.bridge.bridge-nf-call-iptables = 1
</span></span></span><span style=display:flex><span><span style=color:#b44>EOF</span>
</span></span><span style=display:flex><span>sudo sysctl --system
</span></span></code></pre></div><p>Pour plus de détails, veuillez consulter la page <a href=/docs/concepts/extend-kubernetes/compute-storage-net/network-plugins/#network-plugin-requirements>Configuration requise pour le plug-in réseau</a>.</p><h2 id=check-required-ports>Vérifiez les ports requis</h2><h3 id=nœuds-maîtres-masters>nœuds maîtres (masters)</h3><table><thead><tr><th>Protocole</th><th>Direction</th><th>Plage de Port</th><th>Utilisé pour</th><th>Utilisé par</th></tr></thead><tbody><tr><td>TCP</td><td>Entrant</td><td>6443*</td><td>Kubernetes API server</td><td>Tous</td></tr><tr><td>TCP</td><td>Entrant</td><td>2379-2380</td><td>Etcd server client API</td><td>kube-apiserver, etcd</td></tr><tr><td>TCP</td><td>Entrant</td><td>10250</td><td>Kubelet API</td><td>Lui-même, Control plane</td></tr><tr><td>TCP</td><td>Entrant</td><td>10251</td><td>kube-scheduler</td><td>Lui-même</td></tr><tr><td>TCP</td><td>Entrant</td><td>10252</td><td>kube-controller-manager</td><td>Lui-même</td></tr></tbody></table><h3 id=nœuds-workers>nœuds workers</h3><table><thead><tr><th>Protocole</th><th>Direction</th><th>Plage de Port</th><th>Utilisé pour</th><th>Utilisé par</th></tr></thead><tbody><tr><td>TCP</td><td>Entrant</td><td>10250</td><td>Kubelet API</td><td>Lui-même, Control plane</td></tr><tr><td>TCP</td><td>Entrant</td><td>30000-32767</td><td>NodePort Services**</td><td>Eux-mêmes</td></tr></tbody></table><p>** Plage de ports par défaut pour les <a href=/docs/concepts/services-networking/service/>Services NodePort</a>.</p><p>Tous les numéros de port marqués d'un * sont écrasables. Vous devrez donc vous assurer que
les ports personnalisés que vous utilisez sont également ouverts.</p><p>Bien que les ports etcd soient inclus dans les nœuds masters, vous pouvez également héberger
votre propre cluster etcd en externe ou sur des ports personnalisés.</p><p>Le plug-in de réseau de pod que vous utilisez (voir ci-dessous) peut également nécessiter certains ports à ouvrir.
Étant donné que cela diffère d’un plugin à l’autre, veuillez vous reporter à la
documentation des plugins sur le(s) port(s) requis(s).</p><h2 id=installing-runtime>Installation du runtime</h2><p>Pour exécuter des conteneurs dans des pods, Kubernetes utilise un
<a class=glossary-tooltip title="L'environnement d'exécution de conteneurs est le logiciel responsable de l'exécution des conteneurs." data-toggle=tooltip data-placement=top href=/docs/setup/production-environment/container-runtimes target=_blank aria-label='container runtime'>container runtime</a>.</p><ul class="nav nav-tabs" id=container-runtime role=tablist><li class=nav-item><a data-toggle=tab class="nav-link active" href=#container-runtime-0 role=tab aria-controls=container-runtime-0 aria-selected=true>Linux nodes</a></li><li class=nav-item><a data-toggle=tab class=nav-link href=#container-runtime-1 role=tab aria-controls=container-runtime-1>autres systèmes d'exploitation</a></li></ul><div class=tab-content id=container-runtime><div id=container-runtime-0 class="tab-pane show active" role=tabpanel aria-labelledby=container-runtime-0><p><p>Par défaut, Kubernetes utilise le
<a class=glossary-tooltip title='Une API pour les runtimes de conteneurs à intégrer avec kubelet' data-toggle=tooltip data-placement=top href=https://kubernetes.io/docs/concepts/overview/components/#container-runtime target=_blank aria-label='Container Runtime Interface'>Container Runtime Interface</a> (CRI)
pour s'interfacer avec votre environnement d'exécution de conteneur choisi.</p><p>Si vous ne spécifiez pas de runtime, kubeadm essaie automatiquement de détecter un
Runtime de conteneur en parcourant une liste de sockets de domaine Unix bien connus.
Le tableau suivant répertorie les environnements d'exécution des conteneurs et leurs chemins de socket associés:</p><table><caption style=display:none>Les environnements d'exécution des conteneurs et leurs chemins de socket</caption><thead><tr><th>Runtime</th><th>Chemin vers le socket de domaine Unix</th></tr></thead><tbody><tr><td>Docker</td><td><code>/var/run/docker.sock</code></td></tr><tr><td>containerd</td><td><code>/run/containerd/containerd.sock</code></td></tr><tr><td>CRI-O</td><td><code>/var/run/crio/crio.sock</code></td></tr></tbody></table><br>Si Docker et containerd sont détectés, Docker est prioritaire. C'est
nécessaire car Docker 18.09 est livré avec containerd et les deux sont détectables même si vous
installez Docker.
Si deux autres environnements d'exécution ou plus sont détectés, kubeadm se ferme avec une erreur.<p>Le kubelet s'intègre à Docker via l'implémentation CRI intégrée de <code>dockershim</code>.</p><p>Voir <a href=/docs/setup/production-environment/container-runtimes/>runtimes de conteneur</a>
pour plus d'informations.</p></div><div id=container-runtime-1 class=tab-pane role=tabpanel aria-labelledby=container-runtime-1><p><p>Par défaut, kubeadm utilise <a class=glossary-tooltip title="Docker est un logiciel fournissant une virtualisation au niveau du système d'exploitation, également connue sous le nom de conteneurs." data-toggle=tooltip data-placement=top href=https://docs.docker.com/engine/ target=_blank aria-label=Docker>Docker</a> comme environnement d'exécution du conteneur.
Le kubelet s'intègre à Docker via l'implémentation CRI intégrée de <code>dockershim</code>.</p><p>Voir <a href=/docs/setup/production-environment/container-runtimes/>runtimes de conteneur</a>
pour plus d'informations.</p></div></div><h2 id=installation-de-kubeadm-des-kubelets-et-de-kubectl>Installation de kubeadm, des kubelets et de kubectl</h2><p>Vous installerez ces paquets sur toutes vos machines:</p><ul><li><p><code>kubeadm</code>: la commande pour initialiser le cluster.</p></li><li><p>la <code>kubelet</code>: le composant qui s'exécute sur toutes les machines de votre cluster et fait des actions
comme le démarrage des pods et des conteneurs.</p></li><li><p><code>kubectl</code>: la ligne de commande utilisée pour parler à votre cluster.</p></li></ul><p>kubeadm <strong>n'installera pas</strong> ni ne gèrera les <code>kubelet</code> ou<code> kubectl</code> pour vous.
Vous devez vous assurer qu'ils correspondent à la version du control plane de Kubernetes que vous souhaitez que kubeadm installe pour vous. Si vous ne le faites pas, vous risquez qu'une
erreur de version se produise, qui pourrait conduire à un comportement inattendu.
Cependant, une version mineure entre les kubelets et le control plane est pris en charge,
mais la version de la kubelet ne doit jamais dépasser la version de l'API server.
Par exemple, les kubelets exécutant la version 1.7.0 devraient être entièrement compatibles avec un API server en 1.8.0,
mais pas l'inverse.</p><p>For information about installing <code>kubectl</code>, see <a href=/fr/docs/tasks/tools/install-kubectl/>Installation et configuration kubectl</a>.</p><div class="alert alert-danger warning callout" role=alert><strong>Attention:</strong> Ces instructions excluent tous les packages Kubernetes de toutes les mises à niveau du système d'exploitation.
C’est parce que kubeadm et Kubernetes ont besoin d'une
<a href=/docs/tasks/administer-cluster/kubeadm/kubeadm-upgrade-1-11/>attention particulière lors de la mise à niveau</a>.</div><p>Pour plus d'informations sur les compatibilités de version, voir:</p><ul><li>Kubernetes <a href=/docs/setup/version-skew-policy/>version et politique de compatibilité de version</a></li><li>Kubeadm-specific <a href=/fr/docs/setup/production-environment/tools/kubeadm/create-cluster-kubeadm/#version-skew-policy>politique de compatibilité de version</a></li></ul><ul class="nav nav-tabs" id=k8s-install role=tablist><li class=nav-item><a data-toggle=tab class="nav-link active" href=#k8s-install-0 role=tab aria-controls=k8s-install-0 aria-selected=true>Ubuntu, Debian or HypriotOS</a></li><li class=nav-item><a data-toggle=tab class=nav-link href=#k8s-install-1 role=tab aria-controls=k8s-install-1>CentOS, RHEL or Fedora</a></li><li class=nav-item><a data-toggle=tab class=nav-link href=#k8s-install-2 role=tab aria-controls=k8s-install-2>Fedora CoreOS ou Flatcar Container Linux</a></li></ul><div class=tab-content id=k8s-install><div id=k8s-install-0 class="tab-pane show active" role=tabpanel aria-labelledby=k8s-install-0><p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>sudo apt-get update <span style=color:#666>&amp;&amp;</span> sudo apt-get install -y apt-transport-https curl
</span></span><span style=display:flex><span>curl -s https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key add -
</span></span><span style=display:flex><span>cat <span style=color:#b44>&lt;&lt;EOF | sudo tee /etc/apt/sources.list.d/kubernetes.list
</span></span></span><span style=display:flex><span><span style=color:#b44>deb https://apt.kubernetes.io/ kubernetes-xenial main
</span></span></span><span style=display:flex><span><span style=color:#b44>EOF</span>
</span></span><span style=display:flex><span>sudo apt-get update
</span></span><span style=display:flex><span>sudo apt-get install -y kubelet kubeadm kubectl
</span></span><span style=display:flex><span>sudo apt-mark hold kubelet kubeadm kubectl
</span></span></code></pre></div></div><div id=k8s-install-1 class=tab-pane role=tabpanel aria-labelledby=k8s-install-1><p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>cat <span style=color:#b44>&lt;&lt;EOF | sudo tee /etc/yum.repos.d/kubernetes.repo
</span></span></span><span style=display:flex><span><span style=color:#b44>[kubernetes]
</span></span></span><span style=display:flex><span><span style=color:#b44>name=Kubernetes
</span></span></span><span style=display:flex><span><span style=color:#b44>baseurl=https://packages.cloud.google.com/yum/repos/kubernetes-el7-\$basearch
</span></span></span><span style=display:flex><span><span style=color:#b44>enabled=1
</span></span></span><span style=display:flex><span><span style=color:#b44>gpgcheck=1
</span></span></span><span style=display:flex><span><span style=color:#b44>repo_gpgcheck=1
</span></span></span><span style=display:flex><span><span style=color:#b44>gpgkey=https://packages.cloud.google.com/yum/doc/rpm-package-key.gpg
</span></span></span><span style=display:flex><span><span style=color:#b44>exclude=kubelet kubeadm kubectl
</span></span></span><span style=display:flex><span><span style=color:#b44>EOF</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#080;font-style:italic># Mettre SELinux en mode permissif (le désactiver efficacement)</span>
</span></span><span style=display:flex><span>sudo setenforce <span style=color:#666>0</span>
</span></span><span style=display:flex><span>sudo sed -i <span style=color:#b44>&#39;s/^SELINUX=enforcing$/SELINUX=permissive/&#39;</span> /etc/selinux/config
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>sudo yum install -y kubelet kubeadm kubectl --disableexcludes<span style=color:#666>=</span>kubernetes
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>sudo systemctl <span style=color:#a2f>enable</span> --now kubelet
</span></span></code></pre></div><p><strong>Note:</strong></p><ul><li><p>Mettre SELinux en mode permissif en lançant <code>setenforce 0</code> et <code>sed ... </code>le désactive efficacement.
C'est nécessaire pour permettre aux conteneurs d'accéder au système de fichiers hôte, qui est nécessaire par exemple pour les réseaux de pod.
Vous devez le faire jusqu'à ce que le support de SELinux soit amélioré dans Kubelet.</p></li><li><p>Vous pouvez laisser SELinux activé si vous savez comment le configurer, mais il peut nécessiter des paramètres qui ne sont pas pris en charge par kubeadm.</p></li></ul></div><div id=k8s-install-2 class=tab-pane role=tabpanel aria-labelledby=k8s-install-2><p><p>Installez les plugins CNI (requis pour la plupart des réseaux de pods) :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#b8860b>CNI_VERSION</span><span style=color:#666>=</span><span style=color:#b44>&#34;v0.8.2&#34;</span>
</span></span><span style=display:flex><span><span style=color:#b8860b>ARCH</span><span style=color:#666>=</span><span style=color:#b44>&#34;amd64&#34;</span>
</span></span><span style=display:flex><span>sudo mkdir -p /opt/cni/bin
</span></span><span style=display:flex><span>curl -L <span style=color:#b44>&#34;https://github.com/containernetworking/plugins/releases/download/</span><span style=color:#b68;font-weight:700>${</span><span style=color:#b8860b>CNI_VERSION</span><span style=color:#b68;font-weight:700>}</span><span style=color:#b44>/cni-plugins-linux-</span><span style=color:#b68;font-weight:700>${</span><span style=color:#b8860b>ARCH</span><span style=color:#b68;font-weight:700>}</span><span style=color:#b44>-</span><span style=color:#b68;font-weight:700>${</span><span style=color:#b8860b>CNI_VERSION</span><span style=color:#b68;font-weight:700>}</span><span style=color:#b44>.tgz&#34;</span> | sudo tar -C /opt/cni/bin -xz
</span></span></code></pre></div><p>Définissez le répertoire pour télécharger les fichiers de commande</p><div class="alert alert-info note callout" role=alert><strong>Note:</strong> La variable DOWNLOAD_DIR doit être définie sur un répertoire accessible en écriture.
Si vous exécutez Flatcar Container Linux, définissez DOWNLOAD_DIR=/opt/bin</div><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#b8860b>DOWNLOAD_DIR</span><span style=color:#666>=</span>/usr/local/bin
</span></span><span style=display:flex><span>sudo mkdir -p <span style=color:#b8860b>$DOWNLOAD_DIR</span>
</span></span></code></pre></div><p>Installez crictl (requis pour Kubeadm / Kubelet Container Runtime Interface (CRI))</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#b8860b>CRICTL_VERSION</span><span style=color:#666>=</span><span style=color:#b44>&#34;v1.22.0&#34;</span>
</span></span><span style=display:flex><span><span style=color:#b8860b>ARCH</span><span style=color:#666>=</span><span style=color:#b44>&#34;amd64&#34;</span>
</span></span><span style=display:flex><span>curl -L <span style=color:#b44>&#34;https://github.com/kubernetes-sigs/cri-tools/releases/download/</span><span style=color:#b68;font-weight:700>${</span><span style=color:#b8860b>CRICTL_VERSION</span><span style=color:#b68;font-weight:700>}</span><span style=color:#b44>/crictl-</span><span style=color:#b68;font-weight:700>${</span><span style=color:#b8860b>CRICTL_VERSION</span><span style=color:#b68;font-weight:700>}</span><span style=color:#b44>-linux-</span><span style=color:#b68;font-weight:700>${</span><span style=color:#b8860b>ARCH</span><span style=color:#b68;font-weight:700>}</span><span style=color:#b44>.tar.gz&#34;</span> | sudo tar -C <span style=color:#b8860b>$DOWNLOAD_DIR</span> -xz
</span></span></code></pre></div><p>Installez <code>kubeadm</code>, <code>kubelet</code>, <code>kubectl</code> et ajoutez un service systemd <code>kubelet</code>:</p><p>RELEASE_VERSION="v0.6.0"</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#b8860b>RELEASE</span><span style=color:#666>=</span><span style=color:#b44>&#34;</span><span style=color:#a2f;font-weight:700>$(</span>curl -sSL https://dl.k8s.io/release/stable.txt<span style=color:#a2f;font-weight:700>)</span><span style=color:#b44>&#34;</span>
</span></span><span style=display:flex><span><span style=color:#b8860b>ARCH</span><span style=color:#666>=</span><span style=color:#b44>&#34;amd64&#34;</span>
</span></span><span style=display:flex><span><span style=color:#a2f>cd</span> <span style=color:#b8860b>$DOWNLOAD_DIR</span>
</span></span><span style=display:flex><span>sudo curl -L --remote-name-all https://storage.googleapis.com/kubernetes-release/release/<span style=color:#b68;font-weight:700>${</span><span style=color:#b8860b>RELEASE</span><span style=color:#b68;font-weight:700>}</span>/bin/linux/<span style=color:#b68;font-weight:700>${</span><span style=color:#b8860b>ARCH</span><span style=color:#b68;font-weight:700>}</span>/<span style=color:#666>{</span>kubeadm,kubelet,kubectl<span style=color:#666>}</span>
</span></span><span style=display:flex><span>sudo chmod +x <span style=color:#666>{</span>kubeadm,kubelet,kubectl<span style=color:#666>}</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>curl -sSL <span style=color:#b44>&#34;https://raw.githubusercontent.com/kubernetes/release/</span><span style=color:#b68;font-weight:700>${</span><span style=color:#b8860b>RELEASE_VERSION</span><span style=color:#b68;font-weight:700>}</span><span style=color:#b44>/cmd/kubepkg/templates/latest/deb/kubelet/lib/systemd/system/kubelet.service&#34;</span> | sed <span style=color:#b44>&#34;s:/usr/bin:</span><span style=color:#b68;font-weight:700>${</span><span style=color:#b8860b>DOWNLOAD_DIR</span><span style=color:#b68;font-weight:700>}</span><span style=color:#b44>:g&#34;</span> | sudo tee /etc/systemd/system/kubelet.service
</span></span><span style=display:flex><span>sudo mkdir -p /etc/systemd/system/kubelet.service.d
</span></span><span style=display:flex><span>curl -sSL <span style=color:#b44>&#34;https://raw.githubusercontent.com/kubernetes/release/</span><span style=color:#b68;font-weight:700>${</span><span style=color:#b8860b>RELEASE_VERSION</span><span style=color:#b68;font-weight:700>}</span><span style=color:#b44>/cmd/kubepkg/templates/latest/deb/kubeadm/10-kubeadm.conf&#34;</span> | sed <span style=color:#b44>&#34;s:/usr/bin:</span><span style=color:#b68;font-weight:700>${</span><span style=color:#b8860b>DOWNLOAD_DIR</span><span style=color:#b68;font-weight:700>}</span><span style=color:#b44>:g&#34;</span> | sudo tee /etc/systemd/system/kubelet.service.d/10-kubeadm.conf
</span></span></code></pre></div><p>Activez et démarrez <code>kubelet</code> :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>sudo systemctl <span style=color:#a2f>enable</span> --now kubelet
</span></span></code></pre></div><div class="alert alert-info note callout" role=alert><strong>Note:</strong> La distribution Linux Flatcar Container monte le répertoire <code>/usr</code> comme un système de fichiers en lecture seule.
Avant de démarrer votre cluster, vous devez effectuer des étapes supplémentaires pour configurer un répertoire accessible en écriture.
Consultez le <a href=/docs/setup/production-environment/tools/kubeadm/troubleshooting-kubeadm/#usr-mounted-read-only/>Guide de dépannage de Kubeadm</a> pour savoir comment configurer un répertoire accessible en écriture.</div></div></div><p>Kubelet redémarre maintenant toutes les quelques secondes,
car il attend les instructions de kubeadm dans une boucle de crash.</p><h2 id=configurer-le-driver-de-cgroup-utilisé-par-la-kubelet-sur-un-nœud-master>Configurer le driver de cgroup utilisé par la kubelet sur un nœud master</h2><p>Lorsque vous utilisez Docker, kubeadm détecte automatiquement le pilote ( driver ) de cgroup pour kubelet
et le configure dans le fichier <code>/var/lib/kubelet/config.yaml</code> lors de son éxecution.</p><p>Si vous utilisez un autre CRI, vous devez passer votre valeur <code>cgroupDriver</code> avec <code>kubeadm init</code>, comme ceci :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>kubelet.config.k8s.io/v1beta1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>KubeletConfiguration<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>cgroupDriver</span>:<span style=color:#bbb> </span>&lt;value&gt;<span style=color:#bbb>
</span></span></span></code></pre></div><p>Pour plus de détails, veuillez lire <a href=/docs/reference/setup-tools/kubeadm/kubeadm-init/#config-file>Utilisation de kubeadm init avec un fichier de configuration</a>.</p><p>Veuillez noter que vous devez <strong>seulement</strong> le faire si le driver de cgroupe de votre CRI
n'est pas <code>cgroupfs</code>, car c'est déjà la valeur par défaut dans la kubelet.</p><div class="alert alert-info note callout" role=alert><strong>Note:</strong> Depuis que le paramètre <code>--cgroup-driver</code> est obsolète par kubelet, si vous l'avez dans<code>/var/lib/kubelet/kubeadm-flags.env</code>
ou <code>/etc/default/kubelet</code>(<code>/etc/sysconfig/kubelet</code> pour les RPM), veuillez le supprimer et utiliser à la place KubeletConfiguration
(stocké dans<code>/var/lib/kubelet/config.yaml</code> par défaut).</div><p>Il est nécessaire de redémarrer la kubelet:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>sudo systemctl daemon-reload
</span></span><span style=display:flex><span>sudo systemctl restart kubelet
</span></span></code></pre></div><p>La détection automatique du pilote cgroup pour d'autres runtimes de conteneur
comme CRI-O et containerd est un travail en cours.</p><h2 id=dépannage>Dépannage</h2><p>Si vous rencontrez des difficultés avec kubeadm, veuillez consulter notre <a href=/fr/docs/setup/production-environment/tools/kubeadm/troubleshooting-kubeadm/>documentation de dépannage</a>.</p><h2 id=a-suivre>A suivre</h2><ul><li><a href=/fr/docs/setup/production-environment/tools/kubeadm/create-cluster-kubeadm/>Utiliser kubeadm pour créer un cluster</a></li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-134ed1f6142a98e6ac681a1ba4920e53>2.3.1.1.2 - Création d'un Cluster a master unique avec kubeadm</h1><div class=lead>Création d'un Cluster a master unique avec kubeadm</div><p><img src=https://raw.githubusercontent.com/cncf/artwork/master/projects/kubernetes/certified-kubernetes/versionless/color/certified-kubernetes-color.png align=right width=150px><strong>kubeadm</strong> vous aide à démarrer un cluster Kubernetes minimum,
viable et conforme aux meilleures pratiques. Avec kubeadm, votre cluster
doit passer les <a href=https://kubernetes.io/blog/2017/10/software-conformance-certification>tests de Conformance Kubernetes</a>.
Kubeadm prend également en charge d'autres fonctions du cycle de vie, telles que les mises
à niveau, la rétrogradation et la gestion des
<a href=/docs/reference/access-authn-authz/bootstrap-tokens/>bootstrap tokens</a>.</p><p>Comme vous pouvez installer kubeadm sur différents types de machines (par exemple, un ordinateur
portable, un serveur,
Raspberry Pi, etc.), il est parfaitement adapté à l'intégration avec des systèmes d'approvisionnement
comme Terraform ou Ansible.</p><p>La simplicité de kubeadm lui permet d'être utilisé dans une large gamme de cas d'utilisation:</p><ul><li>Les nouveaux utilisateurs peuvent commencer par kubeadm pour essayer Kubernetes pour la première
fois.</li><li>Les utilisateurs familiarisés avec Kubernetes peuvent créer des clusters avec kubeadm et tester
leurs applications.</li><li>Les projets plus importants peuvent inclure kubeadm en tant que brique de base dans un système
plus complexe pouvant également inclure d'autres outils d'installation.</li></ul><p>Kubeadm est conçu pour être un moyen simple pour les nouveaux utilisateurs de commencer à essayer
Kubernetes, pour la première fois éventuellement. C'est un moyen pour les utilisateurs avancés de
tester leur application en même temps qu'un cluster facilement, et aussi être
une brique de base dans un autre écosystème et/ou un outil d’installation avec une plus grand
portée.</p><p>Vous pouvez installer très facilement <em>kubeadm</em> sur des systèmes d'exploitation prenant en charge
l'installation des paquets deb ou rpm. Le SIG responsable de kubeadm,
<a href=https://github.com/kubernetes/community/tree/master/sig-cluster-lifecycle>SIG Cluster Lifecycle</a>,
fournit ces paquets pré-construits pour vous,
mais vous pouvez également les construire à partir des sources pour d'autres systèmes d'exploitation.</p><h3 id=maturité-de-kubeadm>Maturité de kubeadm</h3><table><thead><tr><th>Elément</th><th>Niveau de maturité</th></tr></thead><tbody><tr><td>Command line UX</td><td>GA</td></tr><tr><td>Implementation</td><td>GA</td></tr><tr><td>Config file API</td><td>beta</td></tr><tr><td>CoreDNS</td><td>GA</td></tr><tr><td>kubeadm alpha subcommands</td><td>alpha</td></tr><tr><td>High availability</td><td>alpha</td></tr><tr><td>DynamicKubeletConfig</td><td>alpha</td></tr><tr><td>Self-hosting</td><td>alpha</td></tr></tbody></table><p>Les fonctionnalités globales de kubeadm sont <strong>GA</strong>. Quelques sous-fonctionnalités, comme
la configuration, les API de fichiers sont toujours en cours de développement. L'implémentation de la création du cluster
peut changer légèrement au fur et à mesure que l'outil évolue, mais la mise en œuvre globale devrait être assez stable.
Toutes les commandes sous <code>kubeadm alpha</code> sont par définition prises en charge au niveau alpha.</p><h3 id=calendrier-de-support>Calendrier de support</h3><p>Les versions de Kubernetes sont généralement prises en charge pendant neuf mois et pendant cette
période, une version de correctif peut être publiée à partir de la branche de publication si un bug grave ou un
problème de sécurité est trouvé. Voici les dernières versions de Kubernetes et le calendrier de support
qui s'applique également à <code>kubeadm</code>.</p><table><thead><tr><th>Version de Kubernetes</th><th>Date de sortie de la version</th><th>Fin de vie</th></tr></thead><tbody><tr><td>v1.6.x</td><td>Mars 2017</td><td>Décembre 2017</td></tr><tr><td>v1.7.x</td><td>Juin 2017</td><td>Mars 2018</td></tr><tr><td>v1.8.x</td><td>Septembre 2017</td><td>Juin 2018</td></tr><tr><td>v1.9.x</td><td>Décembre 2017</td><td>Septembre 2018</td></tr><tr><td>v1.10.x</td><td>Mars 2018</td><td>Décembre 2018</td></tr><tr><td>v1.11.x</td><td>Juin 2018</td><td>Mars 2019</td></tr><tr><td>v1.12.x</td><td>Septembre 2018</td><td>Juin 2019</td></tr><tr><td>v1.13.x</td><td>Décembre 2018</td><td>Septembre 2019</td></tr></tbody></table><h2 id=pré-requis>Pré-requis</h2><ul><li>Une ou plusieurs machines exécutant un système d'exploitation compatible deb/rpm, par exemple Ubuntu ou CentOS</li><li>2 Go ou plus de RAM par machine. Si vous essayez moins cela laissera trop peu de place pour vos applications.</li><li>2 processeurs ou plus sur le master</li><li>Connectivité réseau entre toutes les machines du cluster, qu'il soit public ou privé.</li></ul><h2 id=objectifs>Objectifs</h2><ul><li>Installer un cluster Kubernetes à master unique ou un
<a href=/fr/docs/setup/production-environment/tools/kubeadm/high-availability/>cluster à haute disponibilité</a></li><li>Installez un réseau de pods sur le cluster afin que vos pods puissent se parler</li></ul><h2 id=instructions>Instructions</h2><h3 id=installer-kubeadm-sur-vos-hôtes>Installer kubeadm sur vos hôtes</h3><p>Voir <a href=/fr/docs/setup/production-environment/tools/kubeadm/install-kubeadm/>"Installation de kubeadm"</a>.</p><div class="alert alert-info note callout" role=alert><strong>Note:</strong><p>Si vous avez déjà installé kubeadm, lancez <code>apt-get update && apt-get upgrade</code> ou <code>yum update</code> pour obtenir la dernière version de kubeadm.</p><p>Lorsque vous effectuez une mise à niveau, la kubelet redémarre plusieurs fois au bout de quelques
secondes car elle attend dans une boucle de blocage
kubeadm pour lui dire quoi faire. Ce fonctionnement est normal.
Une fois que vous avez initialisé votre master, la kubelet s'exécute normalement.</p></div><h3 id=initialiser-votre-master>Initialiser votre master</h3><p>Le master est la machine sur laquelle s'exécutent les composants du control plane, y compris
etcd (la base de données du cluster) et l'API serveur (avec lequel la CLI kubectl communique).</p><ol><li>Choisissez un add-on réseau pour les pods et vérifiez s’il nécessite des arguments à
passer à l'initialisation de kubeadm. Selon le
fournisseur tiers que vous choisissez, vous devrez peut-être définir le <code>--pod-network-cidr</code> sur
une valeur spécifique au fournisseur. Voir <a href=#pod-network>Installation d'un add-on réseau de pod</a>.</li><li>(Facultatif) Sauf indication contraire, kubeadm utilise l'interface réseau associée
avec la passerelle par défaut pour annoncer l’IP du master. Pour utiliser une autre
interface réseau, spécifiez l'option <code>--apiserver-advertise-address=&lt;ip-address></code>
à <code>kubeadm init</code>. Pour déployer un cluster Kubernetes en utilisant l’adressage IPv6, vous devez
spécifier une adresse IPv6, par exemple <code>--apiserver-advertise-address=fd00::101</code></li><li>(Optional) Lancez <code>kubeadm config images pull</code> avant de faire <code>kubeadm init</code> pour vérifier la
connectivité aux registres gcr.io.</li></ol><p>Maintenant, lancez:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>kubeadm init &lt;args&gt;
</span></span></code></pre></div><h3 id=plus-d-information>Plus d'information</h3><p>Pour plus d'informations sur les arguments de <code>kubeadm init</code>, voir le
<a href=/docs/reference/setup-tools/kubeadm/kubeadm/>guide de référence kubeadm</a>.</p><p>Pour une liste complète des options de configuration, voir la
<a href=/docs/reference/setup-tools/kubeadm/kubeadm-init/#config-file>documentation du fichier de configuration</a>.</p><p>Pour personnaliser les composants du control plane, y compris l'affectation facultative d'IPv6
à la sonde liveness, pour les composants du control plane et du serveur etcd, fournissez des arguments
supplémentaires à chaque composant, comme indiqué dans les <a href=/docs/admin/kubeadm#custom-args>arguments personnalisés</a>.</p><p>Pour lancer encore une fois <code>kubeadm init</code>, vous devez d'abord <a href=#tear-down>détruire le cluster</a>.</p><p>Si vous joignez un nœud avec une architecture différente par rapport à votre cluster, créez un
Déploiement ou DaemonSet pour <code>kube-proxy</code> et<code> kube-dns</code> sur le nœud. C’est nécéssaire car les images Docker pour ces
composants ne prennent actuellement pas en charge la multi-architecture.</p><p><code>kubeadm init</code> exécute d’abord une série de vérifications préalables pour s’assurer que la machine
est prête à exécuter Kubernetes. Ces vérifications préalables exposent des avertissements et se terminent
en cas d'erreur. Ensuite <code>kubeadm init</code> télécharge et installe les composants du control plane du cluster.
Cela peut prendre plusieurs minutes. l'output devrait ressembler à:</p><pre tabindex=0><code class=language-none data-lang=none>[init] Using Kubernetes version: vX.Y.Z
[preflight] Running pre-flight checks
[preflight] Pulling images required for setting up a Kubernetes cluster
[preflight] This might take a minute or two, depending on the speed of your internet connection
[preflight] You can also perform this action in beforehand using &#39;kubeadm config images pull&#39;
[kubelet-start] Writing kubelet environment file with flags to file &#34;/var/lib/kubelet/kubeadm-flags.env&#34;
[kubelet-start] Writing kubelet configuration to file &#34;/var/lib/kubelet/config.yaml&#34;
[kubelet-start] Activating the kubelet service
[certs] Using certificateDir folder &#34;/etc/kubernetes/pki&#34;
[certs] Generating &#34;etcd/ca&#34; certificate and key
[certs] Generating &#34;etcd/server&#34; certificate and key
[certs] etcd/server serving cert is signed for DNS names [kubeadm-master localhost] and IPs [10.138.0.4 127.0.0.1 ::1]
[certs] Generating &#34;etcd/healthcheck-client&#34; certificate and key
[certs] Generating &#34;etcd/peer&#34; certificate and key
[certs] etcd/peer serving cert is signed for DNS names [kubeadm-master localhost] and IPs [10.138.0.4 127.0.0.1 ::1]
[certs] Generating &#34;apiserver-etcd-client&#34; certificate and key
[certs] Generating &#34;ca&#34; certificate and key
[certs] Generating &#34;apiserver&#34; certificate and key
[certs] apiserver serving cert is signed for DNS names [kubeadm-master kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local] and IPs [10.96.0.1 10.138.0.4]
[certs] Generating &#34;apiserver-kubelet-client&#34; certificate and key
[certs] Generating &#34;front-proxy-ca&#34; certificate and key
[certs] Generating &#34;front-proxy-client&#34; certificate and key
[certs] Generating &#34;sa&#34; key and public key
[kubeconfig] Using kubeconfig folder &#34;/etc/kubernetes&#34;
[kubeconfig] Writing &#34;admin.conf&#34; kubeconfig file
[kubeconfig] Writing &#34;kubelet.conf&#34; kubeconfig file
[kubeconfig] Writing &#34;controller-manager.conf&#34; kubeconfig file
[kubeconfig] Writing &#34;scheduler.conf&#34; kubeconfig file
[control-plane] Using manifest folder &#34;/etc/kubernetes/manifests&#34;
[control-plane] Creating static Pod manifest for &#34;kube-apiserver&#34;
[control-plane] Creating static Pod manifest for &#34;kube-controller-manager&#34;
[control-plane] Creating static Pod manifest for &#34;kube-scheduler&#34;
[etcd] Creating static Pod manifest for local etcd in &#34;/etc/kubernetes/manifests&#34;
[wait-control-plane] Waiting for the kubelet to boot up the control plane as static Pods from directory &#34;/etc/kubernetes/manifests&#34;. This can take up to 4m0s
[apiclient] All control plane components are healthy after 31.501735 seconds
[uploadconfig] storing the configuration used in ConfigMap &#34;kubeadm-config&#34; in the &#34;kube-system&#34; Namespace
[kubelet] Creating a ConfigMap &#34;kubelet-config-X.Y&#34; in namespace kube-system with the configuration for the kubelets in the cluster
[patchnode] Uploading the CRI Socket information &#34;/var/run/dockershim.sock&#34; to the Node API object &#34;kubeadm-master&#34; as an annotation
[mark-control-plane] Marking the node kubeadm-master as control-plane by adding the label &#34;node-role.kubernetes.io/master=&#39;&#39;&#34;
[mark-control-plane] Marking the node kubeadm-master as control-plane by adding the taints [node-role.kubernetes.io/master:NoSchedule]
[bootstrap-token] Using token: &lt;token&gt;
[bootstrap-token] Configuring bootstrap tokens, cluster-info ConfigMap, RBAC Roles
[bootstraptoken] configured RBAC rules to allow Node Bootstrap tokens to post CSRs in order for nodes to get long term certificate credentials
[bootstraptoken] configured RBAC rules to allow the csrapprover controller automatically approve CSRs from a Node Bootstrap Token
[bootstraptoken] configured RBAC rules to allow certificate rotation for all node client certificates in the cluster
[bootstraptoken] creating the &#34;cluster-info&#34; ConfigMap in the &#34;kube-public&#34; namespace
[addons] Applied essential addon: CoreDNS
[addons] Applied essential addon: kube-proxy

Your Kubernetes master has initialized successfully!

To start using your cluster, you need to run the following as a regular user:

  mkdir -p $HOME/.kube
  sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
  sudo chown $(id -u):$(id -g) $HOME/.kube/config

You should now deploy a pod network to the cluster.
Run &#34;kubectl apply -f [podnetwork].yaml&#34; with one of the options listed at:
  https://kubernetes.io/fr/docs/concepts/cluster-administration/addons/

You can now join any number of machines by running the following on each node
as root:

  kubeadm join &lt;master-ip&gt;:&lt;master-port&gt; --token &lt;token&gt; --discovery-token-ca-cert-hash sha256:&lt;hash&gt;
</code></pre><p>Pour que kubectl fonctionne pour votre utilisateur non root, exécutez ces commandes, qui font
également partie du resultat de la commande <code>kubeadm init</code>:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>mkdir -p <span style=color:#b8860b>$HOME</span>/.kube
</span></span><span style=display:flex><span>sudo cp -i /etc/kubernetes/admin.conf <span style=color:#b8860b>$HOME</span>/.kube/config
</span></span><span style=display:flex><span>sudo chown <span style=color:#a2f;font-weight:700>$(</span>id -u<span style=color:#a2f;font-weight:700>)</span>:<span style=color:#a2f;font-weight:700>$(</span>id -g<span style=color:#a2f;font-weight:700>)</span> <span style=color:#b8860b>$HOME</span>/.kube/config
</span></span></code></pre></div><p>Alternativement, si vous êtes <code>root</code>, vous pouvez exécuter:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#a2f>export</span> <span style=color:#b8860b>KUBECONFIG</span><span style=color:#666>=</span>/etc/kubernetes/admin.conf
</span></span></code></pre></div><p>Faites un enregistrement du retour de la commande <code>kubeadm join</code> que <code>kubeadm init</code> génère. Vous avez
besoin de cette commande pour <a href=#join-nodes>joindre des noeuds à votre cluster</a>.</p><p>Le jeton est utilisé pour l'authentification mutuelle entre le master et les nœuds qui veulent le rejoindre.
Le jeton est secret. Gardez-le en sécurité, parce que n'importe qui avec ce
jeton peut ajouter des nœuds authentifiés à votre cluster. Ces jetons peuvent être listés,
créés et supprimés avec la commande <code>kubeadm token</code>. Voir le
<a href=/docs/reference/setup-tools/kubeadm/kubeadm-token/>Guide de référence kubeadm</a>.</p><h3 id=pod-network>Installation d'un add-on réseau</h3><div class="alert alert-warning caution callout" role=alert><strong>Avertissement:</strong> Cette section contient des informations importantes sur l’ordre d’installation et de déploiement. Lisez-la attentivement avant de continuer.</div><p>Vous devez installer un add-on réseau pour pod afin que vos pods puissent communiquer les uns
avec les autres.</p><p><strong>Le réseau doit être déployé avant toute application. De plus, CoreDNS ne démarrera pas avant
l’installation d’un réseau.
kubeadm ne prend en charge que les réseaux basés sur un CNI (et ne prend pas
en charge kubenet).</strong></p><p>Plusieurs projets fournissent des réseaux de pod Kubernetes utilisant CNI, dont certains
supportent les <a href=/docs/concepts/services-networking/networkpolicies/>network policies</a>.
Allez voir la <a href=/docs/concepts/cluster-administration/addons/>page des add-ons</a> pour une liste complète
des add-ons réseau disponibles.</p><ul><li>Le support IPv6 a été ajouté dans <a href=https://github.com/containernetworking/cni/releases/tag/v0.6.0>CNI v0.6.0</a>.</li><li><a href=https://github.com/containernetworking/plugins/blob/master/plugins/main/bridge/README.md>CNI bridge</a> et
<a href=https://github.com/containernetworking/plugins/blob/master/plugins/ipam/host-local/README.md>local-ipam</a>
sont les seuls plug-ins de réseau IPv6 pris en charge dans Kubernetes version 1.9.</li></ul><p>Notez que kubeadm configure un cluster sécurisé par défaut et impose l’utilisation de
<a href=/docs/reference/access-authn-authz/rbac/>RBAC</a>.
Assurez-vous que votre manifeste de réseau prend en charge RBAC.</p><p>Veuillez également à ce que votre réseau Pod ne se superpose à aucun des réseaux hôtes,
car cela pourrait entraîner des problèmes.
Si vous constatez une collision entre le réseau de pod de votre plug-in de réseau et certains
de vos réseaux hôtes,
vous devriez penser à un remplacement de CIDR approprié et l'utiliser lors de <code>kubeadm init</code> avec
<code>--pod-network-cidr</code> et en remplacement du YAML de votre plugin réseau.
Vous pouvez installer un add-on réseau de pod avec la commande suivante:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>kubectl apply -f &lt;add-on.yaml&gt;
</span></span></code></pre></div><p>Vous ne pouvez installer qu'un seul réseau de pod par cluster.</p><ul class="nav nav-tabs" id=tabs-pod-install role=tablist><li class=nav-item><a data-toggle=tab class="nav-link active" href=#tabs-pod-install-0 role=tab aria-controls=tabs-pod-install-0 aria-selected=true>Choisissez-en un...</a></li><li class=nav-item><a data-toggle=tab class=nav-link href=#tabs-pod-install-1 role=tab aria-controls=tabs-pod-install-1>Calico</a></li><li class=nav-item><a data-toggle=tab class=nav-link href=#tabs-pod-install-2 role=tab aria-controls=tabs-pod-install-2>Canal</a></li><li class=nav-item><a data-toggle=tab class=nav-link href=#tabs-pod-install-3 role=tab aria-controls=tabs-pod-install-3>Cilium</a></li><li class=nav-item><a data-toggle=tab class=nav-link href=#tabs-pod-install-4 role=tab aria-controls=tabs-pod-install-4>Flannel</a></li><li class=nav-item><a data-toggle=tab class=nav-link href=#tabs-pod-install-5 role=tab aria-controls=tabs-pod-install-5>Kube-router</a></li><li class=nav-item><a data-toggle=tab class=nav-link href=#tabs-pod-install-6 role=tab aria-controls=tabs-pod-install-6>Romana</a></li><li class=nav-item><a data-toggle=tab class=nav-link href=#tabs-pod-install-7 role=tab aria-controls=tabs-pod-install-7>Weave Net</a></li><li class=nav-item><a data-toggle=tab class=nav-link href=#tabs-pod-install-8 role=tab aria-controls=tabs-pod-install-8>JuniperContrail/TungstenFabric</a></li></ul><div class=tab-content id=tabs-pod-install><div id=tabs-pod-install-0 class="tab-pane show active" role=tabpanel aria-labelledby=tabs-pod-install-0><p><p>Sélectionnez l'un des onglets pour consulter les instructions d'installation du fournisseur
de réseau de pods.</p></div><div id=tabs-pod-install-1 class=tab-pane role=tabpanel aria-labelledby=tabs-pod-install-1><p><p>Pour plus d'informations sur l'utilisation de Calico, voir
<a href=https://docs.projectcalico.org/latest/getting-started/kubernetes/>Guide de démarrage rapide de Calico sur Kubernetes</a>,
<a href=https://docs.projectcalico.org/latest/getting-started/kubernetes/installation/calico>Installation de Calico pour les netpols ( network policies ) et le réseau</a>, ainsi que d'autres resources liées à ce sujet.</p><p>Pour que Calico fonctionne correctement, vous devez passer <code>--pod-network-cidr = 192.168.0.0 / 16</code>
à <code>kubeadm init</code> ou mettre à jour le fichier <code>calico.yml</code> pour qu'il corresponde à votre réseau de Pod.
Notez que Calico fonctionne uniquement sur <code>amd64</code>, <code>arm64</code>, <code>ppc64le</code> et <code>s390x</code>.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl apply -f https://docs.projectcalico.org/v3.8/manifests/calico.yaml
</span></span></code></pre></div></div><div id=tabs-pod-install-2 class=tab-pane role=tabpanel aria-labelledby=tabs-pod-install-2><p><p>Canal utilise Calico pour les netpols et Flannel pour la mise en réseau. Reportez-vous à la
documentation Calico pour obtenir le <a href=https://docs.projectcalico.org/latest/getting-started/kubernetes/installation/flannel>guide de démarrage officiel</a>.</p><p>Pour que Canal fonctionne correctement, <code>--pod-network-cidr = 10.244.0.0 / 16</code> doit être passé à
<code>kubeadm init</code>. Notez que Canal ne fonctionne que sur <code>amd64</code>.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl apply -f https://docs.projectcalico.org/v3.8/manifests/canal.yaml
</span></span></code></pre></div></div><div id=tabs-pod-install-3 class=tab-pane role=tabpanel aria-labelledby=tabs-pod-install-3><p><p>Pour plus d'informations sur l'utilisation de Cilium avec Kubernetes, voir
<a href=https://docs.cilium.io/en/stable/kubernetes/>Guide d'installation de Kubernetes pour Cilium</a>.</p><p>Ces commandes déploieront Cilium avec son propre etcd géré par l'opérateur etcd.</p><p>Note: Si vous utilisez kubeadm dans un seul noeud, veuillez enlever sa marque (taint) pour que
les pods etcd-operator puissent être déployés dans le nœud du control plane.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl taint nodes &lt;node-name&gt; node-role.kubernetes.io/master:NoSchedule-
</span></span></code></pre></div><p>Pour déployer Cilium, il vous suffit de lancer:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl create -f https://raw.githubusercontent.com/cilium/cilium/v1.4/examples/kubernetes/1.13/cilium.yaml
</span></span></code></pre></div><p>Une fois que tous les pods Cilium sont marqués «READY», vous commencez à utiliser votre cluster.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>$ kubectl get pods -n kube-system --selector<span style=color:#666>=</span>k8s-app<span style=color:#666>=</span>cilium
</span></span><span style=display:flex><span>NAME           READY   STATUS    RESTARTS   AGE
</span></span><span style=display:flex><span>cilium-drxkl   1/1     Running   <span style=color:#666>0</span>          18m
</span></span></code></pre></div></div><div id=tabs-pod-install-4 class=tab-pane role=tabpanel aria-labelledby=tabs-pod-install-4><p><p>Pour que <code>flannel</code> fonctionne correctement, vous devez passer <code>--pod-network-cidr = 10.244.0.0 / 16</code> à <code>kubeadm init</code>.
Paramétrez <code>/proc/sys/net/bridge/bridge-nf-call-iptables</code> à «1» en exécutant
<code>sysctl net.bridge.bridge-nf-call-iptables = 1</code>
passez le trafic IPv4 bridged à iptables. Ceci est nécessaire pour que certains plugins CNI
fonctionnent, pour plus d'informations
allez voir <a href=/docs/concepts/cluster-administration/network-plugins/#network-plugin-requirements>ici</a>.</p><p>Notez que <code>flannel</code> fonctionne sur <code>amd64</code>, <code>arm</code>, <code>arm64</code>, <code>ppc64le</code> et <code>s390x</code> sous Linux.
Windows (<code>amd64</code>) est annoncé comme supporté dans la v0.11.0 mais son utilisation n’est pas
documentée.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl apply -f https://raw.githubusercontent.com/coreos/flannel/a70459be0084506e4ec919aa1c114638878db11b/Documentation/kube-flannel.yml
</span></span></code></pre></div><p>Pour plus d’informations sur <code>flannel</code>, voir <a href=https://github.com/coreos/flannel>le dépôt CoreOS sur GitHub</a>.</p></div><div id=tabs-pod-install-5 class=tab-pane role=tabpanel aria-labelledby=tabs-pod-install-5><p><p>Paramétrez <code>/proc/sys/net/bridge/bridge-nf-call-iptables</code> à «1» en exécutant
<code>sysctl net.bridge.bridge-nf-call-iptables = 1</code>
Cette commande indiquera de passer le trafic IPv4 bridgé à iptables.
Ceci est nécessaire pour que certains plugins CNI fonctionnent, pour plus d'informations
s'il vous plaît allez voir <a href=/docs/concepts/cluster-administration/network-plugins/#network-plugin-requirements>ici</a>.</p><p>Kube-router s'appuie sur kube-controller-manager pour allouer le pod CIDR aux nœuds. Par conséquent,
utilisez <code>kubeadm init</code> avec l'option <code>--pod-network-cidr</code>.</p><p>Kube-router fournit un réseau de pod, une stratégie réseau et un proxy de service basé sur un
IP Virtual Server (IPVS) / Linux Virtual Server (LVS) hautement performant.</p><p>Pour plus d'informations sur la configuration du cluster Kubernetes avec Kube-router à l'aide de kubeadm,
veuillez consulter le <a href=https://github.com/cloudnativelabs/kube-router/blob/master/docs/kubeadm.md>guide d'installation</a>.</p></div><div id=tabs-pod-install-6 class=tab-pane role=tabpanel aria-labelledby=tabs-pod-install-6><p><p>Paramétrez <code>/proc/sys/net/bridge/bridge-nf-call-iptables</code> à <code>1</code> en exécutant
<code>sysctl net.bridge.bridge-nf-call-iptables = 1</code>
Cette commande indiquera de passer le trafic IPv4 bridged à iptables. Ceci est nécessaire pour que certains plugins CNI fonctionnent,
pour plus d'informations
veuillez consulter la documentation <a href=/docs/concepts/cluster-administration/network-plugins/#network-plugin-requirements>ici</a>.</p><p>Le guide d'installation officiel de Romana est <a href=https://github.com/romana/romana/tree/master/containerize#using-kubeadm>ici</a>.</p><p>Romana ne fonctionne que sur <code>amd64</code>.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl apply -f https://raw.githubusercontent.com/romana/romana/master/containerize/specs/romana-kubeadm.yml
</span></span></code></pre></div></div><div id=tabs-pod-install-7 class=tab-pane role=tabpanel aria-labelledby=tabs-pod-install-7><p><p>Paramétrez <code>/proc/sys/net/bridge/bridge-nf-call-iptables</code> à «1» en exécutant <code>sysctl net.bridge.bridge-nf-call-iptables = 1</code>
Cette commande indiquera de passer le trafic IPv4 bridged à iptables. Ceci est nécessaire pour que certains plugins CNI fonctionnent, pour plus d'informations
s'il vous plaît allez voir <a href=/docs/concepts/cluster-administration/network-plugins/#network-plugin-requirements>ici</a>.</p><p>Le guide de configuration officiel de Weave Net est <a href=https://www.weave.works/docs/net/latest/kube-addon/>ici</a>.</p><p>Weave Net fonctionne sur <code>amd64</code>, <code>arm</code>, <code>arm64</code> et <code>ppc64le</code> sans aucune action supplémentaire requise.
Weave Net paramètre le mode hairpin par défaut. Cela permet aux pods de se connecter via leur adresse IP de service
s'ils ne connaissent pas leur Pod IP.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl apply -f <span style=color:#b44>&#34;https://cloud.weave.works/k8s/net?k8s-version=</span><span style=color:#a2f;font-weight:700>$(</span>kubectl version | base64 | tr -d <span style=color:#b44>&#39;\n&#39;</span><span style=color:#a2f;font-weight:700>)</span><span style=color:#b44>&#34;</span>
</span></span></code></pre></div></div><div id=tabs-pod-install-8 class=tab-pane role=tabpanel aria-labelledby=tabs-pod-install-8><p><p>Fournit une solution SDN superposée, offrant un réseau multicouches, un réseau de cloud hybride,
prise en charge simultanée des couches superposées, application de la stratégie réseau, isolation du réseau,
chaînage de service et équilibrage de charge flexible.</p><p>Il existe de nombreuses manières flexibles d’installer JuniperContrail / TungstenFabric CNI.</p><p>Veuillez vous référer à ce guide de démarrage rapide: <a href=https://tungstenfabric.github.io/website/>TungstenFabric</a></p></div></div><p>Une fois qu'un réseau de pod a été installé, vous pouvez vérifier qu'il fonctionne en
vérifiant que le pod CoreDNS est en cours d’exécution dans l'output de <code>kubectl get pods --all-namespaces</code>.
Et une fois que le pod CoreDNS est opérationnel, vous pouvez continuer en joignant vos nœuds.</p><p>Si votre réseau ne fonctionne pas ou si CoreDNS n'est pas en cours d'exécution, vérifiez
notre <a href=/fr/docs/setup/production-environment/tools/kubeadm/troubleshooting-kubeadm/>documentation de dépannage</a>.</p><h3 id=isolation-des-nœuds-du-control-plane>Isolation des nœuds du control plane</h3><p>Par défaut, votre cluster ne déploie pas de pods sur le master pour des raisons de sécurité.
Si vous souhaitez pouvoir déployer des pods sur le master, par exemple, pour un
cluster Kubernetes mono-machine pour le développement, exécutez:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>kubectl taint nodes --all node-role.kubernetes.io/master-
</span></span></code></pre></div><p>Avec un resultat ressemblant à quelque chose comme:</p><pre tabindex=0><code>node &#34;test-01&#34; untainted
taint &#34;node-role.kubernetes.io/master:&#34; not found
taint &#34;node-role.kubernetes.io/master:&#34; not found
</code></pre><p>Cela supprimera la marque <code>node-role.kubernetes.io/master</code> de tous les nœuds qui
l'ont, y compris du nœud master, ce qui signifie que le scheduler sera alors capable
de déployer des pods partout.</p><h3 id=join-nodes>Faire rejoindre vos nœuds</h3><p>Les nœuds sont ceux sur lesquels vos workloads (conteneurs, pods, etc.) sont exécutées.
Pour ajouter de nouveaux nœuds à votre cluster, procédez comme suit pour chaque machine:</p><ul><li>SSH vers la machine</li><li>Devenir root (par exemple, <code>sudo su-</code>)</li><li>Exécutez la commande qui a été récupérée sur l'output de <code>kubeadm init</code>. Par exemple:</li></ul><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>kubeadm join --token &lt;token&gt; &lt;master-ip&gt;:&lt;master-port&gt; --discovery-token-ca-cert-hash sha256:&lt;hash&gt;
</span></span></code></pre></div><p>Si vous n'avez pas le jeton, vous pouvez l'obtenir en exécutant la commande suivante sur le nœud master:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>kubeadm token list
</span></span></code></pre></div><p>L'output est similaire à ceci:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-console data-lang=console><span style=display:flex><span><span style=color:#888>TOKEN                    TTL  EXPIRES              USAGES           DESCRIPTION            EXTRA GROUPS
</span></span></span><span style=display:flex><span><span style=color:#888>8ewj1p.9r9hcjoqgajrj4gi  23h  2018-06-12T02:51:28Z authentication,  The default bootstrap  system:
</span></span></span><span style=display:flex><span><span style=color:#888>                                                   signing          token generated by     bootstrappers:
</span></span></span><span style=display:flex><span><span style=color:#888>                                                                    &#39;kubeadm init&#39;.        kubeadm:
</span></span></span><span style=display:flex><span><span style=color:#888>                                                                                           default-node-token
</span></span></span></code></pre></div><p>Par défaut, les jetons expirent après 24 heures. Si vous joignez un nœud au cluster après
l’expiration du jeton actuel,
vous pouvez créer un nouveau jeton en exécutant la commande suivante sur le nœud maître:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>kubeadm token create
</span></span></code></pre></div><p>L'output est similaire à ceci:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-console data-lang=console><span style=display:flex><span><span style=color:#888>5didvk.d09sbcov8ph2amjw
</span></span></span></code></pre></div><p>Si vous n'avez pas la valeur <code>--discovery-token-ca-cert-hash</code>, vous pouvez l'obtenir en
exécutant la suite de commande suivante sur le nœud master:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>openssl x509 -pubkey -in /etc/kubernetes/pki/ca.crt | openssl rsa -pubin -outform der 2&gt;/dev/null | <span style=color:#b62;font-weight:700>\
</span></span></span><span style=display:flex><span><span style=color:#b62;font-weight:700></span>   openssl dgst -sha256 -hex | sed <span style=color:#b44>&#39;s/^.* //&#39;</span>
</span></span></code></pre></div><p>L'output est similaire à ceci:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-console data-lang=console><span style=display:flex><span><span style=color:#888>8cb2de97839780a412b93877f8507ad6c94f73add17d5d7058e91741c9d5ec78
</span></span></span></code></pre></div><div class="alert alert-info note callout" role=alert><strong>Note:</strong> Pour spécifier un tuple IPv6 pour <code>&lt;maître-ip>: &lt;maître-port></code>, l'adresse IPv6 doit être placée
entre crochets, par exemple: <code>[fd00 :: 101]: 2073</code>.</div><p>Le resultat devrait ressembler à quelque chose comme:</p><pre tabindex=0><code>[preflight] Running pre-flight checks

... (log output of join workflow) ...

Node join complete:
* Certificate signing request sent to master and response
  received.
* Kubelet informed of new secure connection details.

Run &#39;kubectl get nodes&#39; on the master to see this machine join.
</code></pre><p>Quelques secondes plus tard, vous remarquerez ce nœud dans l'output de <code>kubectl get node</code>.</p><h3 id=optionnel-contrôler-votre-cluster-à-partir-de-machines-autres-que-le-master>(Optionnel) Contrôler votre cluster à partir de machines autres que le master</h3><p>Afin d'utiliser kubectl sur une autre machine (par exemple, un ordinateur portable) pour communiquer avec votre
cluster, vous devez copier le fichier administrateur kubeconfig de votre master
sur votre poste de travail comme ceci:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>scp root@&lt;master ip&gt;:/etc/kubernetes/admin.conf .
</span></span><span style=display:flex><span>kubectl --kubeconfig ./admin.conf get nodes
</span></span></code></pre></div><div class="alert alert-info note callout" role=alert><strong>Note:</strong><p>L'exemple ci-dessus suppose que l'accès SSH est activé pour root. Si ce n'est pas le cas,
vous pouvez copier le fichier <code>admin.conf</code> pour qu'il soit accessible à un autre utilisateur.
et <code>scp</code> en utilisant cet autre utilisateur à la place.</p><p>Le fichier <code>admin.conf</code> donne à l'utilisateur <em>superuser</em> des privilèges sur le cluster.
Ce fichier doit être utilisé avec parcimonie. Pour les utilisateurs normaux, il est recommandé de
générer une information d'identification unique pour laquelle vous ajoutez des privilèges à la liste blanche
(whitelist).
Vous pouvez faire ceci avec <code>kubeadm alpha kubeconfig utilisateur --nom-client &lt;CN></code>.
Le resultat de cette commande génèrera un fichier KubeConfig qui sera envoyé sur STDOUT, que vous
devrez enregistrer dans un fichier et donner à votre utilisateur. Après cela, créez la whitelist des
privilèges en utilisant <code>kubectl create (cluster) rolebinding.</code></p></div><h3 id=facultatif-proxifier-l-api-server-vers-localhost>(Facultatif) Proxifier l'API Server vers localhost</h3><p>Si vous souhaitez vous connecter à l'API server à partir de l'éxterieur du cluster, vous pouvez utiliser
<code>kubectl proxy</code>:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>scp root@&lt;master ip&gt;:/etc/kubernetes/admin.conf .
</span></span><span style=display:flex><span>kubectl --kubeconfig ./admin.conf proxy
</span></span></code></pre></div><p>Vous pouvez maintenant accéder à l'API server localement à <code>http://localhost:8001/api/v1</code></p><h2 id=tear-down>Destruction</h2><p>Pour annuler ce que kubeadm a fait, vous devez d’abord
<a href=/docs/reference/generated/kubectl/kubectl-commands#drain>drainer le nœud</a>
et assurez-vous que le nœud est vide avant de l'arrêter.
En communiquant avec le master en utilisant les informations d'identification appropriées, exécutez:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>kubectl drain &lt;node name&gt; --delete-local-data --force --ignore-daemonsets
</span></span><span style=display:flex><span>kubectl delete node &lt;node name&gt;
</span></span></code></pre></div><p>Ensuite, sur le nœud en cours de suppression, réinitialisez l'état de tout ce qui concerne kubeadm:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>kubeadm reset
</span></span></code></pre></div><p>Le processus de réinitialisation ne réinitialise pas et ne nettoie pas les règles iptables ni les
tables IPVS. Si vous souhaitez réinitialiser iptables, vous devez le faire manuellement:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>iptables -F <span style=color:#666>&amp;&amp;</span> iptables -t nat -F <span style=color:#666>&amp;&amp;</span> iptables -t mangle -F <span style=color:#666>&amp;&amp;</span> iptables -X
</span></span></code></pre></div><p>Si vous souhaitez réinitialiser les tables IPVS, vous devez exécuter la commande suivante:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>ipvsadm -C
</span></span></code></pre></div><p>Si vous souhaitez recommencer Il suffit de lancer <code>kubeadm init</code> ou <code>kubeadm join</code> avec les
arguments appropriés.
Plus d'options et d'informations sur la
<a href=/docs/reference/setup-tools/kubeadm/kubeadm-reset/><code>commande de réinitialisation de kubeadm</code></a>.</p><h2 id=lifecycle>Maintenir un cluster</h2><p>Vous trouverez des instructions pour la maintenance des clusters kubeadm (mises à niveau,
rétrogradation, etc.) <a href=/docs/tasks/administer-cluster/kubeadm>ici</a></p><h2 id=other-addons>Explorer les autres add-ons</h2><p>Parcourez la <a href=/docs/concepts/cluster-administration/addons/>liste des add-ons</a>,
y compris des outils pour la journalisation, la surveillance, la stratégie réseau, la visualisation
et le contrôle de votre cluster Kubernetes.</p><h2 id=whats-next>Et après ?</h2><ul><li>Vérifiez que votre cluster fonctionne correctement avec <a href=https://github.com/heptio/sonobuoy>Sonobuoy</a></li><li>En savoir plus sur l'utilisation avancée de kubeadm dans la
<a href=/docs/reference/setup-tools/kubeadm/kubeadm>documentation de référence de kubeadm</a></li><li>En savoir plus sur Kubernetes <a href=/docs/concepts/>concepts</a> et <a href=/docs/user-guide/kubectl-overview/><code>kubectl</code></a>.</li><li>Configurez la rotation des logs. Vous pouvez utiliser <strong>logrotate</strong> pour cela. Lorsque vous utilisez Docker,
vous pouvez spécifier des options de rotation des logs pour le démon Docker, par exemple
<code>--log-driver = fichier_json --log-opt = taille_max = 10m --log-opt = fichier_max = 5</code>.
Consultez <a href=https://docs.docker.com/engine/admin/>Configurer et dépanner le démon Docker</a> pour plus de détails.</li></ul><h2 id=feedback>Feedback</h2><ul><li>Pour les bugs, visitez <a href=https://github.com/kubernetes/kubeadm/issues>kubeadm GitHub issue tracker</a></li><li>Pour le support, rendez vous sur le Channel Slack kubeadm:
<a href=https://kubernetes.slack.com/messages/kubeadm/>#kubeadm</a></li><li>Le Channel Slack: General SIG Cluster Lifecycle Development:
<a href=https://kubernetes.slack.com/messages/sig-cluster-lifecycle/>#sig-cluster-lifecycle</a></li><li><a href=#TODO>SIG Cluster Lifecycle SIG information</a></li><li>SIG Cluster Lifecycle Mailing List:
<a href=https://groups.google.com/forum/#!forum/kubernetes-sig-cluster-lifecycle>kubernetes-sig-cluster-lifecycle</a></li></ul><h2 id=version-skew-policy>Politique de compatibilité de versions</h2><p>L'outil CLI kubeadm de la version vX.Y peut déployer des clusters avec un control
plane de la version vX.Y ou vX. (Y-1).
kubeadm CLI vX.Y peut également mettre à niveau un cluster existant créé par kubeadm
de la version vX. (Y-1).</p><p>Pour cette raison, nous ne pouvons pas voir plus loin, kubeadm CLI vX.Y peut ou pas être
en mesure de déployer des clusters vX. (Y + 1).</p><p>Exemple: kubeadm v1.8 peut déployer des clusters v1.7 et v1.8 et mettre à niveau des
clusters v1.7 créés par kubeadm vers
v1.8.</p><p>Ces ressources fournissent plus d'informations sur le saut de version pris en
charge entre les kubelets et le control plane, ainsi que sur d'autres composants Kubernetes:</p><ul><li><a href=/docs/setup/version-skew-policy/>politique de compatibilité de versions</a> de Kubernetes</li><li><a href=/fr/docs/setup/production-environment/tools/kubeadm/install-kubeadm/#installing-kubeadm-kubelet-and-kubectl>Guide d'installation</a>
spécifique à Kubeadm</li></ul><h2 id=multi-platform>kubeadm fonctionne sur plusieurs plates-formes</h2><p>Les packages et fichiers binaires de kubeadm deb/rpm sont conçus pour amd64, arm (32 bits), arm64, ppc64le et s390x
suite à la <a href=https://github.com/kubernetes/community/blob/master/contributors/design-proposals/multi-platform.md>multiplateforme proposal</a>.</p><p>Les images de conteneur multiplatform pour le control plane et les addons sont également pris en charge depuis la v1.12.</p><p>Seuls certains fournisseurs de réseau proposent des solutions pour toutes les plateformes. Veuillez consulter la liste des
fournisseurs de réseau ci-dessus ou la documentation de chaque fournisseur pour déterminer si le fournisseur
prend en charge votre plate-forme.</p><h2 id=limitations>Limitations</h2><p>Remarque: kubeadm évolue continuellement et ces limitations seront résolues en temps voulu.</p><ul><li>Le cluster créé ici a un seul master, avec une seule base de données etcd. Cela signifie que
si le master est irrécupérable, votre cluster peut perdre ses données et peut avoir besoin d'être recréé à
partir de zéro. L'ajout du support HA (plusieurs serveurs etcd, plusieurs API servers, etc.)
à kubeadm est encore en cours de developpement.</li></ul><p>   Contournement: régulièrement <a href=https://coreos.com/etcd/docs/latest/admin_guide.html>sauvegarder etcd</a>.
le répertoire des données etcd configuré par kubeadm se trouve dans <code>/var/lib/etcd</code> sur le master.</p><h2 id=troubleshooting>Diagnostic</h2><p>Si vous rencontrez des difficultés avec kubeadm, veuillez consulter nos
<a href=/fr/docs/setup/production-environment/tools/kubeadm/troubleshooting-kubeadm/>troubleshooting docs</a>.</p></div><div class=td-content style=page-break-before:always><h1 id=pg-4c656c5eda3e1c06ad1aedebdc04a211>2.3.1.1.3 - Personnalisation de la configuration du control plane avec kubeadm</h1><div class=lead>Personnalisation de la configuration du control plane avec kubeadm</div><div style=margin-top:10px;margin-bottom:10px><b>FEATURE STATE:</b> <code>Kubernetes 1.12 [stable]</code></div><p>L'objet <code>ClusterConfiguration</code> de kubeadm expose le champ <code>extraArgs</code> qui peut
remplacer les indicateurs par défaut transmis au control plane à des composants
tels que l'APIServer, le ControllerManager et le Scheduler. Les composants sont
définis à l'aide des champs suivants:</p><ul><li><code>apiServer</code></li><li><code>controllerManager</code></li><li><code>scheduler</code></li></ul><p>Le champ <code>extraArgs</code> se compose de paires<code> clé: valeur</code>. Pour remplacer un indicateur
pour un composant du control plane:</p><ol><li>Ajoutez les champs appropriés à votre configuration.</li><li>Ajoutez les indicateurs à remplacer dans le champ.</li></ol><p>Pour plus de détails sur chaque champ de la configuration, vous pouvez accéder aux
<a href=https://godoc.org/k8s.io/kubernetes/cmd/kubeadm/app/apis/kubeadm#ClusterConfiguration>pages de référence de l'API</a>.</p><h2 id=paramètres-pour-l-api-server>Paramètres pour l'API Server</h2><p>Pour plus de détails, voir la <a href=/docs/reference/command-line-tools-reference/kube-apiserver/>documentation de référence pour kube-apiserver</a>.</p><p>Exemple d'utilisation:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>kubeadm.k8s.io/v1beta1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>ClusterConfiguration<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kubernetesVersion</span>:<span style=color:#bbb> </span>v1.13.0<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span><span style=color:#666>1.13</span>-sample<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>apiServer</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>extraArgs</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>advertise-address</span>:<span style=color:#bbb> </span><span style=color:#666>192.168.0.103</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>anonymous-auth</span>:<span style=color:#bbb> </span><span style=color:#a2f;font-weight:700>false</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>enable-admission-plugins</span>:<span style=color:#bbb> </span>AlwaysPullImages,DefaultStorageClass<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>audit-log-path</span>:<span style=color:#bbb> </span>/home/johndoe/audit.log<span style=color:#bbb>
</span></span></span></code></pre></div><h2 id=paramètres-pour-le-controllermanager>Paramètres pour le ControllerManager</h2><p>Pour plus de détails, voir la <a href=/docs/reference/command-line-tools-reference/kube-controller-manager/>documentation de référence pour kube-controller-manager</a>.</p><p>Exemple d'utilisation:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>kubeadm.k8s.io/v1beta1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>ClusterConfiguration<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kubernetesVersion</span>:<span style=color:#bbb> </span>v1.13.0<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span><span style=color:#666>1.13</span>-sample<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>controllerManager</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>extraArgs</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>cluster-signing-key-file</span>:<span style=color:#bbb> </span>/home/johndoe/keys/ca.key<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>bind-address</span>:<span style=color:#bbb> </span><span style=color:#666>0.0.0.0</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>deployment-controller-sync-period</span>:<span style=color:#bbb> </span><span style=color:#666>50</span><span style=color:#bbb>
</span></span></span></code></pre></div><h2 id=paramètres-pour-le-scheduler>Paramètres pour le Scheduler</h2><p>Pour plus de détails, voir la <a href=/docs/reference/command-line-tools-reference/kube-scheduler/>documentation de référence pour kube-scheduler</a>.</p><p>Example usage:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>kubeadm.k8s.io/v1beta1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>ClusterConfiguration<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kubernetesVersion</span>:<span style=color:#bbb> </span>v1.13.0<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span><span style=color:#666>1.13</span>-sample<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>scheduler</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>extraArgs</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>bind-address</span>:<span style=color:#bbb> </span><span style=color:#666>0.0.0.0</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>config</span>:<span style=color:#bbb> </span>/home/johndoe/schedconfig.yaml<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>kubeconfig</span>:<span style=color:#bbb> </span>/home/johndoe/kubeconfig.yaml<span style=color:#bbb>
</span></span></span></code></pre></div></div><div class=td-content style=page-break-before:always><h1 id=pg-015edbc7cc688d31b1d1edce7c186135>2.3.1.1.4 - Options pour la topologie en haute disponibilité</h1><div class=lead>Topologie haute-disponibilité Kubernetes</div><p>Cette page explique les deux options de configuration de topologie de vos clusters Kubernetes
pour la haute disponibilité.</p><p>Vous pouvez configurer un cluster en haute disponibilité:</p><ul><li>Avec des nœuds du control plane empilés, les nœuds etcd étant co-localisés avec des nœuds du control plane</li><li>Avec des nœuds etcd externes, où etcd s'exécute sur des nœuds distincts du control plane</li></ul><p>Vous devez examiner attentivement les avantages et les inconvénients de chaque topologie avant
de configurer un cluster en haute disponibilité.</p><h2 id=topologie-etcd-empilée>Topologie etcd empilée</h2><p>Un cluster HA empilé est une <a href=https://fr.wikipedia.org/wiki/Topologie_de_r%C3%A9seau>topologie réseau</a>
où le cluster de stockage de données distribuées est fourni par etcd et est superposé au
cluster formé par les noeuds gérés par kubeadm qui exécute les composants du control plane.</p><p>Chaque nœud du control plane exécute une instance de <code>kube-apiserver</code>, <code>kube-scheduler</code> et
<code>kube-controller-manager</code>.
Le <code>kube-apiserver</code> est exposé aux nœuds à l'aide d'un loadbalancer.</p><p>Chaque nœud du control plane crée un membre etcd local et ce membre etcd communique uniquement avec
le <code>kube-apiserver</code> de ce noeud. Il en va de même pour le <code>kube-controller-manager</code> local
et les instances de <code>kube-scheduler</code>.</p><p>Cette topologie couple les control planes et les membres etcd sur les mêmes nœuds. C'est
plus simple à mettre en place qu'un cluster avec des nœuds etcd externes et plus simple à
gérer pour la réplication.</p><p>Cependant, un cluster empilé présente un risque d'échec du couplage. Si un noeud tombe en panne,
un membre etcd et une instance du control plane sont perdus et la redondance est compromise. Vous
pouvez atténuer ce risque en ajoutant plus de nœuds au control plane.</p><p>Par conséquent, vous devez exécuter au moins trois nœuds de control plane empilés pour un cluster
en haute disponibilité.</p><p>C'est la topologie par défaut dans kubeadm. Un membre etcd local est créé automatiquement
sur les noeuds du control plane en utilisant <code>kubeadm init</code> et <code>kubeadm join --experimental-control-plane</code>.</p><p>Schéma de la <a href=/images/kubeadm/kubeadm-ha-topology-stacked-etcd.svg>Topologie etcd empilée</a></p><h2 id=topologie-etcd-externe>Topologie etcd externe</h2><p>Un cluster haute disponibilité avec un etcd externe est une
<a href=https://fr.wikipedia.org/wiki/Topologie_de_r%C3%A9seau>topologie réseau</a> où le cluster de stockage de données
distribuées fourni par etcd est externe au cluster formé par les nœuds qui exécutent les composants
du control plane.</p><p>Comme la topologie etcd empilée, chaque nœud du control plane d'une topologie etcd externe exécute
une instance de <code>kube-apiserver</code>, <code>kube-scheduler</code> et <code>kube-controller-manager</code>. Et le <code>kube-apiserver</code>
est exposé aux nœuds workers à l’aide d’un load-balancer. Cependant, les membres etcd s'exécutent sur
des hôtes distincts et chaque hôte etcd communique avec le <code>kube-apiserver</code> de chaque nœud du control plane.</p><p>Cette topologie dissocie le control plane et le membre etcd. Elle fournit donc une configuration HA où
perdre une instance de control plane ou un membre etcd a moins d'impact et n'affecte pas la redondance du
cluster autant que la topologie HA empilée.</p><p>Cependant, cette topologie requiert le double du nombre d'hôtes de la topologie HA integrée.
Un minimum de trois machines pour les nœuds du control plane et de trois machines
pour les nœuds etcd est requis pour un cluster HA avec cette topologie.</p><p>Schéma de la <a href=/images/kubeadm/kubeadm-ha-topology-external-etcd.svg>Topologie externe etcd</a></p><h2 id=a-suivre>A suivre</h2><ul><li><a href=/fr/docs/setup/production-environment/tools/kubeadm/high-availability/>Configurer un cluster hautement disponible avec kubeadm</a></li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-3941d5c3409342219bf7e03128b8ecb6>2.3.1.1.5 - Création de clusters hautement disponibles avec kubeadm</h1><div class=lead>Cluster Kubernetes haute-disponibilité kubeadm</div><p>Cette page explique deux approches différentes pour configurer un Kubernetes à haute disponibilité.
cluster utilisant kubeadm:</p><ul><li>Avec des nœuds de control plane empilés. Cette approche nécessite moins d'infrastructure.
Les membres etcd et les nœuds du control plane sont co-localisés.</li><li>Avec un cluster etcd externe cette approche nécessite plus d'infrastructure.
Les nœuds du control plane et les membres etcd sont séparés.</li></ul><p>Avant de poursuivre, vous devez déterminer avec soin quelle approche répond le mieux
aux besoins de vos applications et de l'environnement. <a href=/fr/docs/setup/production-environment/tools/kubeadm/ha-topology/>Cette comparaison</a>
décrit les avantages et les inconvénients de chacune.</p><p>Vos clusters doivent exécuter Kubernetes version 1.12 ou ultérieure. Vous devriez aussi savoir que
la mise en place de clusters HA avec kubeadm est toujours expérimentale et sera simplifiée davantage
dans les futures versions. Vous pouvez par exemple rencontrer des problèmes lors de la mise à niveau de vos clusters.
Nous vous encourageons à essayer l’une ou l’autre approche et à nous faire part de vos commentaires dans
<a href=https://github.com/kubernetes/kubeadm/issues/new>Suivi des problèmes Kubeadm</a>.</p><p>Notez que la fonctionnalité alpha <code>HighAvailability</code> est obsolète dans la version 1.12 et supprimée dans la version 1.13</p><p>Voir aussi <a href=/docs/tasks/administer-cluster/kubeadm/kubeadm-upgrade-ha-1-13>La documentation de mise à niveau HA</a>.</p><div class="alert alert-warning caution callout" role=alert><strong>Avertissement:</strong> Cette page ne traite pas de l'exécution de votre cluster sur un fournisseur de cloud. Dans un
environnement Cloud, les approches documentées ici ne fonctionnent ni avec des objets de type
load balancer, ni avec des volumes persistants dynamiques.</div><h2 id=pré-requis>Pré-requis</h2><p>Pour les deux méthodes, vous avez besoin de cette infrastructure:</p><ul><li>Trois machines qui répondent aux pré-requis des <a href=/fr/docs/setup/production-environment/tools/kubeadm/install-kubeadm/#before-you-begin>exigences de kubeadm</a> pour les maîtres (masters)</li><li>Trois machines qui répondent aux pré-requis des <a href=/fr/docs/setup/production-environment/tools/kubeadm/install-kubeadm/#before-you-begin>exigences de kubeadm</a> pour les workers</li><li>Connectivité réseau complète entre toutes les machines du cluster (public ou réseau privé)</li><li>Privilèges sudo sur toutes les machines</li><li>Accès SSH d'une machine à tous les nœuds du cluster</li><li><code>kubeadm</code> et une <code>kubelet</code> installés sur toutes les machines. <code>kubectl</code> est optionnel.</li></ul><p>Pour le cluster etcd externe uniquement, vous avez besoin également de:</p><ul><li>Trois machines supplémentaires pour les membres etcd</li></ul><div class="alert alert-info note callout" role=alert><strong>Note:</strong> Les exemples suivants utilisent Calico en tant que fournisseur de réseau de Pod. Si vous utilisez un autre
CNI, pensez à remplacer les valeurs par défaut si nécessaire.</div><h2 id=premières-étapes-pour-les-deux-méthodes>Premières étapes pour les deux méthodes</h2><div class="alert alert-info note callout" role=alert><strong>Note:</strong> Toutes les commandes d'un control plane ou d'un noeud etcd doivent être
éxecutées en tant que root.</div><ul><li>Certains plugins réseau CNI tels que Calico nécessitent un CIDR tel que <code>192.168.0.0 / 16</code> et 
certains comme Weave n'en ont pas besoin. Voir la
<a href=/fr/docs/setup/production-environment/tools/kubeadm/create-cluster-kubeadm/#pod-network>Documentation du CNI réseau</a>.
Pour ajouter un CIDR de pod, définissez le champ <code>podSubnet: 192.168.0.0 / 16</code> sous
  l'objet <code>networking</code> de<code> ClusterConfiguration</code>.</li></ul><h3 id=créez-un-load-balancer-pour-kube-apiserver>Créez un load balancer pour kube-apiserver</h3><div class="alert alert-info note callout" role=alert><strong>Note:</strong> Il existe de nombreuses configurations pour les équilibreurs de charge (load balancers).
L'exemple suivant n'est qu'un exemple. Vos exigences pour votre cluster peuvent nécessiter une configuration différente.</div><ol><li><p>Créez un load balancer kube-apiserver avec un nom résolu en DNS.</p><ul><li><p>Dans un environnement cloud, placez vos nœuds du control plane derrière un load balancer TCP.
Ce load balancer distribue le trafic à tous les nœuds du control plane sains dans sa liste.
La vérification de la bonne santé d'un apiserver est une vérification TCP sur le port que
kube-apiserver écoute (valeur par défaut: <code>6443</code>).</p></li><li><p>Il n'est pas recommandé d'utiliser une adresse IP directement dans un environnement cloud.</p></li><li><p>Le load balancer doit pouvoir communiquer avec tous les nœuds du control plane sur le
port apiserver. Il doit également autoriser le trafic entrant sur son réseau de port d'écoute.</p></li><li><p><a href=http://www.haproxy.org/>HAProxy</a> peut être utilisé comme load balancer.</p></li><li><p>Assurez-vous que l'adresse du load balancer correspond toujours à
      l'adresse de <code>ControlPlaneEndpoint</code> de kubeadm.</p></li></ul></li><li><p>Ajoutez les premiers nœuds du control plane au load balancer et testez la connexion:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh><span style=display:flex><span>nc -v LOAD_BALANCER_IP PORT
</span></span></code></pre></div><ul><li>Une erreur <code>connection refused</code> est attendue car l'apiserver n'est pas encore en fonctionnement.
Cependant, un timeout signifie que le load balancer ne peut pas communiquer avec le nœud du
control plane. Si un timeout survient, reconfigurez le load balancer pour communiquer avec le nœud du control plane.</li></ul></li><li><p>Ajouter les nœuds du control plane restants au groupe cible du load balancer.</p></li></ol><h3 id=configurer-ssh>Configurer SSH</h3><p>SSH est requis si vous souhaitez contrôler tous les nœuds à partir d'une seule machine.</p><ol><li><p>Activer ssh-agent sur votre machine ayant accès à tous les autres nœuds du cluster:</p><pre tabindex=0><code>eval $(ssh-agent)
</code></pre></li><li><p>Ajoutez votre clé SSH à la session:</p><pre tabindex=0><code>ssh-add ~/.ssh/path_to_private_key
</code></pre></li><li><p>SSH entre les nœuds pour vérifier que la connexion fonctionne correctement.</p><ul><li><p>Lorsque vous faites un SSH sur un noeud, assurez-vous d’ajouter l’option <code>-A</code>:</p><pre tabindex=0><code>ssh -A 10.0.0.7
</code></pre></li><li><p>Lorsque vous utilisez sudo sur n’importe quel nœud, veillez à préserver l’environnement afin que le SSH forwarding fonctionne:</p><pre tabindex=0><code>sudo -E -s
</code></pre></li></ul></li></ol><h2 id=control-plane-empilé-et-nœuds-etcd>Control plane empilé et nœuds etcd</h2><h3 id=étapes-pour-le-premier-nœud-du-control-plane>Étapes pour le premier nœud du control plane</h3><ol><li><p>Sur le premier nœud du control plane, créez un fichier de configuration appelé <code>kubeadm-config.yaml</code>:</p><pre><code>apiVersion: kubeadm.k8s.io/v1beta1
kind: ClusterConfiguration
kubernetesVersion: stable
apiServer:
  certSANs:
  - &quot;LOAD_BALANCER_DNS&quot;
controlPlaneEndpoint: &quot;LOAD_BALANCER_DNS:LOAD_BALANCER_PORT&quot;
</code></pre><ul><li><code>kubernetesVersion</code> doit représenter la version de Kubernetes à utiliser. Cet exemple utilise <code>stable</code>.</li><li><code>controlPlaneEndpoint</code> doit correspondre à l'adresse ou au DNS et au port du load balancer.</li><li>Il est recommandé que les versions de kubeadm, kubelet, kubectl et kubernetes correspondent.</li></ul></li><li><p>Assurez-vous que le nœud est dans un état sain:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh><span style=display:flex><span>sudo kubeadm init --config<span style=color:#666>=</span>kubeadm-config.yaml
</span></span></code></pre></div><p>Vous devriez voir quelque chose comme:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh><span style=display:flex><span>...
</span></span></code></pre></div></li></ol><p>Vous pouvez à présent joindre n'importe quelle machine au cluster en lancant la commande suivante sur
chaque nœeud en tant que root:</p><pre><code>kubeadm join 192.168.0.200:6443 --token j04n3m.octy8zely83cy2ts --discovery-token-ca-cert-hash    sha256:84938d2a22203a8e56a787ec0c6ddad7bc7dbd52ebabc62fd5f4dbea72b14d1f
```
</code></pre><ol><li><p>Copiez ce jeton dans un fichier texte. Vous en aurez besoin plus tard pour joindre
d’autres nœuds du control plane au cluster.</p></li><li><p>Activez l'extension CNI Weave:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh><span style=display:flex><span>kubectl apply -f <span style=color:#b44>&#34;https://cloud.weave.works/k8s/net?k8s-version=</span><span style=color:#a2f;font-weight:700>$(</span>kubectl version | base64 | tr -d <span style=color:#b44>&#39;\n&#39;</span><span style=color:#a2f;font-weight:700>)</span><span style=color:#b44>&#34;</span>
</span></span></code></pre></div></li><li><p>Tapez ce qui suit et observez les pods des composants démarrer:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh><span style=display:flex><span>kubectl get pod -n kube-system -w
</span></span></code></pre></div><ul><li>Il est recommandé de ne joindre les nouveaux nœuds du control plane qu'après l'initialisation du premier nœud.</li></ul></li><li><p>Copiez les fichiers de certificat du premier nœud du control plane dans les autres:</p><p>Dans l'exemple suivant, remplacez <code>CONTROL_PLANE_IPS</code> par les adresses IP des autres nœuds du control plane.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh><span style=display:flex><span><span style=color:#b8860b>USER</span><span style=color:#666>=</span>ubuntu <span style=color:#080;font-style:italic># customizable</span>
</span></span><span style=display:flex><span><span style=color:#b8860b>CONTROL_PLANE_IPS</span><span style=color:#666>=</span><span style=color:#b44>&#34;10.0.0.7 10.0.0.8&#34;</span>
</span></span><span style=display:flex><span><span style=color:#a2f;font-weight:700>for</span> host in <span style=color:#b68;font-weight:700>${</span><span style=color:#b8860b>CONTROL_PLANE_IPS</span><span style=color:#b68;font-weight:700>}</span>; <span style=color:#a2f;font-weight:700>do</span>
</span></span><span style=display:flex><span>    scp /etc/kubernetes/pki/ca.crt <span style=color:#b44>&#34;</span><span style=color:#b68;font-weight:700>${</span><span style=color:#b8860b>USER</span><span style=color:#b68;font-weight:700>}</span><span style=color:#b44>&#34;</span>@<span style=color:#b8860b>$host</span>:
</span></span><span style=display:flex><span>    scp /etc/kubernetes/pki/ca.key <span style=color:#b44>&#34;</span><span style=color:#b68;font-weight:700>${</span><span style=color:#b8860b>USER</span><span style=color:#b68;font-weight:700>}</span><span style=color:#b44>&#34;</span>@<span style=color:#b8860b>$host</span>:
</span></span><span style=display:flex><span>    scp /etc/kubernetes/pki/sa.key <span style=color:#b44>&#34;</span><span style=color:#b68;font-weight:700>${</span><span style=color:#b8860b>USER</span><span style=color:#b68;font-weight:700>}</span><span style=color:#b44>&#34;</span>@<span style=color:#b8860b>$host</span>:
</span></span><span style=display:flex><span>    scp /etc/kubernetes/pki/sa.pub <span style=color:#b44>&#34;</span><span style=color:#b68;font-weight:700>${</span><span style=color:#b8860b>USER</span><span style=color:#b68;font-weight:700>}</span><span style=color:#b44>&#34;</span>@<span style=color:#b8860b>$host</span>:
</span></span><span style=display:flex><span>    scp /etc/kubernetes/pki/front-proxy-ca.crt <span style=color:#b44>&#34;</span><span style=color:#b68;font-weight:700>${</span><span style=color:#b8860b>USER</span><span style=color:#b68;font-weight:700>}</span><span style=color:#b44>&#34;</span>@<span style=color:#b8860b>$host</span>:
</span></span><span style=display:flex><span>    scp /etc/kubernetes/pki/front-proxy-ca.key <span style=color:#b44>&#34;</span><span style=color:#b68;font-weight:700>${</span><span style=color:#b8860b>USER</span><span style=color:#b68;font-weight:700>}</span><span style=color:#b44>&#34;</span>@<span style=color:#b8860b>$host</span>:
</span></span><span style=display:flex><span>    scp /etc/kubernetes/pki/etcd/ca.crt <span style=color:#b44>&#34;</span><span style=color:#b68;font-weight:700>${</span><span style=color:#b8860b>USER</span><span style=color:#b68;font-weight:700>}</span><span style=color:#b44>&#34;</span>@<span style=color:#b8860b>$host</span>:etcd-ca.crt
</span></span><span style=display:flex><span>    scp /etc/kubernetes/pki/etcd/ca.key <span style=color:#b44>&#34;</span><span style=color:#b68;font-weight:700>${</span><span style=color:#b8860b>USER</span><span style=color:#b68;font-weight:700>}</span><span style=color:#b44>&#34;</span>@<span style=color:#b8860b>$host</span>:etcd-ca.key
</span></span><span style=display:flex><span>    scp /etc/kubernetes/admin.conf <span style=color:#b44>&#34;</span><span style=color:#b68;font-weight:700>${</span><span style=color:#b8860b>USER</span><span style=color:#b68;font-weight:700>}</span><span style=color:#b44>&#34;</span>@<span style=color:#b8860b>$host</span>:
</span></span><span style=display:flex><span><span style=color:#a2f;font-weight:700>done</span>
</span></span></code></pre></div></li></ol><div class="alert alert-warning caution callout" role=alert><strong>Avertissement:</strong> N'utilisez que les certificats de la liste ci-dessus. kubeadm se chargera de générer le reste des certificats avec les SANs requis pour les instances du control plane qui se joignent.
Si vous copiez tous les certificats par erreur, la création de noeuds supplémentaires pourrait
échouer en raison d'un manque de SANs requis.</div><h3 id=étapes-pour-le-reste-des-nœuds-du-control-plane>Étapes pour le reste des nœuds du control plane</h3><ol><li><p>Déplacer les fichiers créés à l'étape précédente où <code>scp</code> était utilisé:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh><span style=display:flex><span><span style=color:#b8860b>USER</span><span style=color:#666>=</span>ubuntu <span style=color:#080;font-style:italic># customizable</span>
</span></span><span style=display:flex><span>mkdir -p /etc/kubernetes/pki/etcd
</span></span><span style=display:flex><span>mv /home/<span style=color:#b68;font-weight:700>${</span><span style=color:#b8860b>USER</span><span style=color:#b68;font-weight:700>}</span>/ca.crt /etc/kubernetes/pki/
</span></span><span style=display:flex><span>mv /home/<span style=color:#b68;font-weight:700>${</span><span style=color:#b8860b>USER</span><span style=color:#b68;font-weight:700>}</span>/ca.key /etc/kubernetes/pki/
</span></span><span style=display:flex><span>mv /home/<span style=color:#b68;font-weight:700>${</span><span style=color:#b8860b>USER</span><span style=color:#b68;font-weight:700>}</span>/sa.pub /etc/kubernetes/pki/
</span></span><span style=display:flex><span>mv /home/<span style=color:#b68;font-weight:700>${</span><span style=color:#b8860b>USER</span><span style=color:#b68;font-weight:700>}</span>/sa.key /etc/kubernetes/pki/
</span></span><span style=display:flex><span>mv /home/<span style=color:#b68;font-weight:700>${</span><span style=color:#b8860b>USER</span><span style=color:#b68;font-weight:700>}</span>/front-proxy-ca.crt /etc/kubernetes/pki/
</span></span><span style=display:flex><span>mv /home/<span style=color:#b68;font-weight:700>${</span><span style=color:#b8860b>USER</span><span style=color:#b68;font-weight:700>}</span>/front-proxy-ca.key /etc/kubernetes/pki/
</span></span><span style=display:flex><span>mv /home/<span style=color:#b68;font-weight:700>${</span><span style=color:#b8860b>USER</span><span style=color:#b68;font-weight:700>}</span>/etcd-ca.crt /etc/kubernetes/pki/etcd/ca.crt
</span></span><span style=display:flex><span>mv /home/<span style=color:#b68;font-weight:700>${</span><span style=color:#b8860b>USER</span><span style=color:#b68;font-weight:700>}</span>/etcd-ca.key /etc/kubernetes/pki/etcd/ca.key
</span></span><span style=display:flex><span>mv /home/<span style=color:#b68;font-weight:700>${</span><span style=color:#b8860b>USER</span><span style=color:#b68;font-weight:700>}</span>/admin.conf /etc/kubernetes/admin.conf
</span></span></code></pre></div><p>Ce processus écrit tous les fichiers demandés dans le dossier <code>/etc/kubernetes</code>.</p></li><li><p>Lancez <code>kubeadm join</code> sur ce nœud en utilisant la commande de join qui vous avait été précédemment
donnée par<code> kubeadm init</code> sur le premier noeud. Ça devrait ressembler a quelque chose
comme ça:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh><span style=display:flex><span>sudo kubeadm join 192.168.0.200:6443 --token j04n3m.octy8zely83cy2ts --discovery-token-ca-cert-hash sha256:84938d2a22203a8e56a787ec0c6ddad7bc7dbd52ebabc62fd5f4dbea72b14d1f --experimental-control-plane
</span></span></code></pre></div><ul><li>Remarquez l'ajout de l'option <code>--experimental-control-plane</code>. Ce paramètre automatise l'adhésion au
control plane du cluster.</li></ul></li><li><p>Tapez ce qui suit et observez les pods des composants démarrer:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh><span style=display:flex><span>kubectl get pod -n kube-system -w
</span></span></code></pre></div></li><li><p>Répétez ces étapes pour le reste des nœuds du control plane.</p></li></ol><h2 id=noeuds-etcd-externes>Noeuds etcd externes</h2><h3 id=configurer-le-cluster-etcd>Configurer le cluster etcd</h3><ul><li>Suivez ces <a href=/fr/docs/setup/production-environment/tools/kubeadm/setup-ha-etcd-with-kubeadm/>instructions</a>
pour configurer le cluster etcd.</li></ul><h3 id=configurer-le-premier-nœud-du-control-plane>Configurer le premier nœud du control plane</h3><ol><li><p>Copiez les fichiers suivants de n’importe quel nœud du cluster etcd vers ce nœud.:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh><span style=display:flex><span><span style=color:#a2f>export</span> <span style=color:#b8860b>CONTROL_PLANE</span><span style=color:#666>=</span><span style=color:#b44>&#34;ubuntu@10.0.0.7&#34;</span>
</span></span><span style=display:flex><span>+scp /etc/kubernetes/pki/etcd/ca.crt <span style=color:#b44>&#34;</span><span style=color:#b68;font-weight:700>${</span><span style=color:#b8860b>CONTROL_PLANE</span><span style=color:#b68;font-weight:700>}</span><span style=color:#b44>&#34;</span>:
</span></span><span style=display:flex><span>+scp /etc/kubernetes/pki/apiserver-etcd-client.crt <span style=color:#b44>&#34;</span><span style=color:#b68;font-weight:700>${</span><span style=color:#b8860b>CONTROL_PLANE</span><span style=color:#b68;font-weight:700>}</span><span style=color:#b44>&#34;</span>:
</span></span><span style=display:flex><span>+scp /etc/kubernetes/pki/apiserver-etcd-client.key <span style=color:#b44>&#34;</span><span style=color:#b68;font-weight:700>${</span><span style=color:#b8860b>CONTROL_PLANE</span><span style=color:#b68;font-weight:700>}</span><span style=color:#b44>&#34;</span>:
</span></span></code></pre></div><ul><li>Remplacez la valeur de <code>CONTROL_PLANE</code> par l'<code>utilisateur@hostname</code> de cette machine.</li></ul></li><li><p>Créez un fichier YAML appelé <code>kubeadm-config.yaml</code> avec le contenu suivant:</p><pre><code>apiVersion: kubeadm.k8s.io/v1beta1
kind: ClusterConfiguration
kubernetesVersion: stable
apiServer:
  certSANs:
  - &quot;LOAD_BALANCER_DNS&quot;
controlPlaneEndpoint: &quot;LOAD_BALANCER_DNS:LOAD_BALANCER_PORT&quot;
etcd:
    external:
        endpoints:
        - https://ETCD_0_IP:2379
        - https://ETCD_1_IP:2379
        - https://ETCD_2_IP:2379
        caFile: /etc/kubernetes/pki/etcd/ca.crt
        certFile: /etc/kubernetes/pki/apiserver-etcd-client.crt
        keyFile: /etc/kubernetes/pki/apiserver-etcd-client.key
</code></pre><ul><li><p>La différence entre etcd empilé et externe, c’est que nous utilisons le champ <code>external</code>
pour <code>etcd</code> dans la configuration de kubeadm. Dans le cas de la topologie etcd empilée,
c'est géré automatiquement.</p></li><li><p>Remplacez les variables suivantes dans le modèle (template) par les valeurs appropriées
pour votre cluster:</p><ul><li><code>LOAD_BALANCER_DNS</code></li><li><code>LOAD_BALANCER_PORT</code></li><li><code>ETCD_0_IP</code></li><li><code>ETCD_1_IP</code></li><li><code>ETCD_2_IP</code></li></ul></li></ul></li><li><p>Lancez <code>kubeadm init --config kubeadm-config.yaml</code> sur ce nœud.</p></li><li><p>Ecrivez le résultat de la commande de join dans un fichier texte pour une utilisation ultérieure.</p></li><li><p>Appliquer le plugin CNI Weave:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh><span style=display:flex><span>kubectl apply -f <span style=color:#b44>&#34;https://cloud.weave.works/k8s/net?k8s-version=</span><span style=color:#a2f;font-weight:700>$(</span>kubectl version | base64 | tr -d <span style=color:#b44>&#39;\n&#39;</span><span style=color:#a2f;font-weight:700>)</span><span style=color:#b44>&#34;</span>
</span></span></code></pre></div></li></ol><h3 id=étapes-pour-le-reste-des-nœuds-du-control-plane-1>Étapes pour le reste des nœuds du control plane</h3><p>Pour ajouter le reste des nœuds du control plane, suivez <a href=#%C3%A9tapes-pour-le-reste-des-n%C5%93uds-du-control-plane>ces instructions</a>.
Les étapes sont les mêmes que pour la configuration etcd empilée, à l’exception du fait qu'un membre
etcd local n'est pas créé.</p><p>Pour résumer:</p><ul><li>Assurez-vous que le premier nœud du control plane soit complètement initialisé.</li><li>Copier les certificats entre le premier nœud du control plane et les autres nœuds du control plane.</li><li>Joignez chaque nœud du control plane à l'aide de la commande de join que vous avez enregistrée dans
un fichier texte, puis ajoutez l'option <code>--experimental-control-plane</code>.</li></ul><h2 id=tâches-courantes-après-l-amorçage-du-control-plane>Tâches courantes après l'amorçage du control plane</h2><h3 id=installer-un-réseau-de-pod>Installer un réseau de pod</h3><p><a href=/fr/docs/setup/production-environment/tools/kubeadm/create-cluster-kubeadm/#pod-network>Suivez ces instructions</a> afin
d'installer le réseau de pod. Assurez-vous que cela correspond au pod CIDR que vous avez fourni
dans le fichier de configuration principal.</p><h3 id=installer-les-workers>Installer les workers</h3><p>Chaque nœud worker peut maintenant être joint au cluster avec la commande renvoyée à partir du resultat
de n’importe quelle commande <code>kubeadm init</code>. L'option <code>--experimental-control-plane</code> ne doit pas
être ajouté aux nœuds workers.</p></div><div class=td-content style=page-break-before:always><h1 id=pg-8160424c22d24f7d2d63c521e107dbf8>2.3.1.1.6 - Configurer un cluster etcd en haute disponibilité avec kubeadm</h1><div class=lead>Configuration d'un cluster etcd en haute disponibilité avec kubeadm</div><p>Par défaut, Kubeadm exécute un cluster etcd mono nœud dans un pod statique géré
par la kubelet sur le nœud du plan de contrôle (control plane). Ce n'est pas une configuration haute disponibilité puisque le cluster etcd ne contient qu'un seul membre et ne peut donc supporter
qu'aucun membre ne devienne indisponible. Cette page vous accompagne dans le processus de création
d'un cluster etcd à trois membres en haute disponibilité, pouvant être utilisé en tant que cluster externe lors de l’utilisation de kubeadm pour configurer un cluster kubernetes.</p><h2 id=pré-requis>Pré-requis</h2><ul><li>Trois machines pouvant communiquer entre elles via les ports 2379 et 2380. Cette 
methode utilise ces ports par défaut. Cependant, ils sont configurables via 
le fichier de configuration kubeadm.</li><li>Chaque hôte doit avoir <a href=/fr/docs/setup/production-environment/tools/kubeadm/install-kubeadm/>docker, kubelet et kubeadm installés</a>.</li><li>Certains paquets pour copier des fichiers entre les hôtes. Par exemple, <code>ssh</code> et<code> scp</code>.</li></ul><h2 id=mise-en-place-du-cluster>Mise en place du cluster</h2><p>L’approche générale consiste à générer tous les certificats sur un nœud et à ne distribuer que
les fichiers <em>nécessaires</em> aux autres nœuds.</p><div class="alert alert-info note callout" role=alert><strong>Note:</strong> kubeadm contient tout ce qui est nécessaire pour générer les certificats décrits ci-dessous;
aucun autre outil de chiffrement n'est requis pour cet exemple.</div><ol><li><p>Configurez la kubelet pour qu'elle soit un gestionnaire de service pour etcd.</p><p>Etant donné qu'etcd a été créé en premier, vous devez remplacer la priorité de service en
créant un nouveau fichier unit qui a une priorité plus élevée que le fichier unit de la kubelet fourni
par kubeadm.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh><span style=display:flex><span>cat <span style=color:#b44>&lt;&lt; EOF &gt; /etc/systemd/system/kubelet.service.d/20-etcd-service-manager.conf
</span></span></span><span style=display:flex><span><span style=color:#b44>[Service]
</span></span></span><span style=display:flex><span><span style=color:#b44>ExecStart=
</span></span></span><span style=display:flex><span><span style=color:#b44>ExecStart=/usr/bin/kubelet --address=127.0.0.1 --pod-manifest-path=/etc/kubernetes/manifests
</span></span></span><span style=display:flex><span><span style=color:#b44>Restart=always
</span></span></span><span style=display:flex><span><span style=color:#b44>EOF</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>systemctl daemon-reload
</span></span><span style=display:flex><span>systemctl restart kubelet
</span></span></code></pre></div></li><li><p>Créez des fichiers de configuration pour kubeadm.</p><p>Générez un fichier de configuration kubeadm pour chaque machine qui éxécutera un membre etcd
en utilisant le script suivant.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh><span style=display:flex><span><span style=color:#080;font-style:italic># Update HOST0, HOST1, and HOST2 with the IPs or resolvable names of your hosts</span>
</span></span><span style=display:flex><span><span style=color:#a2f>export</span> <span style=color:#b8860b>HOST0</span><span style=color:#666>=</span>10.0.0.6
</span></span><span style=display:flex><span><span style=color:#a2f>export</span> <span style=color:#b8860b>HOST1</span><span style=color:#666>=</span>10.0.0.7
</span></span><span style=display:flex><span><span style=color:#a2f>export</span> <span style=color:#b8860b>HOST2</span><span style=color:#666>=</span>10.0.0.8
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#080;font-style:italic># Create temp directories to store files that will end up on other hosts.</span>
</span></span><span style=display:flex><span>mkdir -p /tmp/<span style=color:#b68;font-weight:700>${</span><span style=color:#b8860b>HOST0</span><span style=color:#b68;font-weight:700>}</span>/ /tmp/<span style=color:#b68;font-weight:700>${</span><span style=color:#b8860b>HOST1</span><span style=color:#b68;font-weight:700>}</span>/ /tmp/<span style=color:#b68;font-weight:700>${</span><span style=color:#b8860b>HOST2</span><span style=color:#b68;font-weight:700>}</span>/
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#b8860b>ETCDHOSTS</span><span style=color:#666>=(</span><span style=color:#b68;font-weight:700>${</span><span style=color:#b8860b>HOST0</span><span style=color:#b68;font-weight:700>}</span> <span style=color:#b68;font-weight:700>${</span><span style=color:#b8860b>HOST1</span><span style=color:#b68;font-weight:700>}</span> <span style=color:#b68;font-weight:700>${</span><span style=color:#b8860b>HOST2</span><span style=color:#b68;font-weight:700>}</span><span style=color:#666>)</span>
</span></span><span style=display:flex><span><span style=color:#b8860b>NAMES</span><span style=color:#666>=(</span><span style=color:#b44>&#34;infra0&#34;</span> <span style=color:#b44>&#34;infra1&#34;</span> <span style=color:#b44>&#34;infra2&#34;</span><span style=color:#666>)</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#a2f;font-weight:700>for</span> i in <span style=color:#b44>&#34;</span><span style=color:#b68;font-weight:700>${</span>!ETCDHOSTS[@]<span style=color:#b68;font-weight:700>}</span><span style=color:#b44>&#34;</span>; <span style=color:#a2f;font-weight:700>do</span>
</span></span><span style=display:flex><span><span style=color:#b8860b>HOST</span><span style=color:#666>=</span><span style=color:#b68;font-weight:700>${</span><span style=color:#b8860b>ETCDHOSTS</span>[<span style=color:#b8860b>$i</span>]<span style=color:#b68;font-weight:700>}</span>
</span></span><span style=display:flex><span><span style=color:#b8860b>NAME</span><span style=color:#666>=</span><span style=color:#b68;font-weight:700>${</span><span style=color:#b8860b>NAMES</span>[<span style=color:#b8860b>$i</span>]<span style=color:#b68;font-weight:700>}</span>
</span></span><span style=display:flex><span>cat <span style=color:#b44>&lt;&lt; EOF &gt; /tmp/${HOST}/kubeadmcfg.yaml
</span></span></span><span style=display:flex><span><span style=color:#b44>apiVersion: &#34;kubeadm.k8s.io/v1beta1&#34;
</span></span></span><span style=display:flex><span><span style=color:#b44>kind: ClusterConfiguration
</span></span></span><span style=display:flex><span><span style=color:#b44>etcd:
</span></span></span><span style=display:flex><span><span style=color:#b44>    local:
</span></span></span><span style=display:flex><span><span style=color:#b44>        serverCertSANs:
</span></span></span><span style=display:flex><span><span style=color:#b44>        - &#34;${HOST}&#34;
</span></span></span><span style=display:flex><span><span style=color:#b44>        peerCertSANs:
</span></span></span><span style=display:flex><span><span style=color:#b44>        - &#34;${HOST}&#34;
</span></span></span><span style=display:flex><span><span style=color:#b44>        extraArgs:
</span></span></span><span style=display:flex><span><span style=color:#b44>            initial-cluster: ${NAMES[0]}=https://${ETCDHOSTS[0]}:2380,${NAMES[1]}=https://${ETCDHOSTS[1]}:2380,${NAMES[2]}=https://${ETCDHOSTS[2]}:2380
</span></span></span><span style=display:flex><span><span style=color:#b44>            initial-cluster-state: new
</span></span></span><span style=display:flex><span><span style=color:#b44>            name: ${NAME}
</span></span></span><span style=display:flex><span><span style=color:#b44>            listen-peer-urls: https://${HOST}:2380
</span></span></span><span style=display:flex><span><span style=color:#b44>            listen-client-urls: https://${HOST}:2379
</span></span></span><span style=display:flex><span><span style=color:#b44>            advertise-client-urls: https://${HOST}:2379
</span></span></span><span style=display:flex><span><span style=color:#b44>            initial-advertise-peer-urls: https://${HOST}:2380
</span></span></span><span style=display:flex><span><span style=color:#b44>EOF</span>
</span></span><span style=display:flex><span><span style=color:#a2f;font-weight:700>done</span>
</span></span></code></pre></div></li><li><p>Générer l'autorité de certification</p><p>Si vous avez déjà une autorité de certification, alors la seule action qui est faite copie
les fichiers <code>crt</code> et <code>key</code> de la CA dans <code>/etc/kubernetes/pki/etcd/ca.crt</code> et
<code>/etc/kubernetes/pki/etcd/ca.key</code>. Une fois ces fichiers copiés,
    passez à l'étape suivante, "Créer des certificats pour chaque membre".</p><p>Si vous ne possédez pas déjà de CA, exécutez cette commande sur <code>$HOST0</code> (où vous
avez généré les fichiers de configuration pour kubeadm).</p><pre tabindex=0><code>kubeadm init phase certs etcd-ca
</code></pre><p>Cela crée deux fichiers</p><ul><li><code>/etc/kubernetes/pki/etcd/ca.crt</code></li><li><code>/etc/kubernetes/pki/etcd/ca.key</code></li></ul></li><li><p>Créer des certificats pour chaque membre</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh><span style=display:flex><span>kubeadm init phase certs etcd-server --config<span style=color:#666>=</span>/tmp/<span style=color:#b68;font-weight:700>${</span><span style=color:#b8860b>HOST2</span><span style=color:#b68;font-weight:700>}</span>/kubeadmcfg.yaml
</span></span><span style=display:flex><span>kubeadm init phase certs etcd-peer --config<span style=color:#666>=</span>/tmp/<span style=color:#b68;font-weight:700>${</span><span style=color:#b8860b>HOST2</span><span style=color:#b68;font-weight:700>}</span>/kubeadmcfg.yaml
</span></span><span style=display:flex><span>kubeadm init phase certs etcd-healthcheck-client --config<span style=color:#666>=</span>/tmp/<span style=color:#b68;font-weight:700>${</span><span style=color:#b8860b>HOST2</span><span style=color:#b68;font-weight:700>}</span>/kubeadmcfg.yaml
</span></span><span style=display:flex><span>kubeadm init phase certs apiserver-etcd-client --config<span style=color:#666>=</span>/tmp/<span style=color:#b68;font-weight:700>${</span><span style=color:#b8860b>HOST2</span><span style=color:#b68;font-weight:700>}</span>/kubeadmcfg.yaml
</span></span><span style=display:flex><span>cp -R /etc/kubernetes/pki /tmp/<span style=color:#b68;font-weight:700>${</span><span style=color:#b8860b>HOST2</span><span style=color:#b68;font-weight:700>}</span>/
</span></span><span style=display:flex><span><span style=color:#080;font-style:italic># cleanup non-reusable certificates</span>
</span></span><span style=display:flex><span>find /etc/kubernetes/pki -not -name ca.crt -not -name ca.key -type f -delete
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>kubeadm init phase certs etcd-server --config<span style=color:#666>=</span>/tmp/<span style=color:#b68;font-weight:700>${</span><span style=color:#b8860b>HOST1</span><span style=color:#b68;font-weight:700>}</span>/kubeadmcfg.yaml
</span></span><span style=display:flex><span>kubeadm init phase certs etcd-peer --config<span style=color:#666>=</span>/tmp/<span style=color:#b68;font-weight:700>${</span><span style=color:#b8860b>HOST1</span><span style=color:#b68;font-weight:700>}</span>/kubeadmcfg.yaml
</span></span><span style=display:flex><span>kubeadm init phase certs etcd-healthcheck-client --config<span style=color:#666>=</span>/tmp/<span style=color:#b68;font-weight:700>${</span><span style=color:#b8860b>HOST1</span><span style=color:#b68;font-weight:700>}</span>/kubeadmcfg.yaml
</span></span><span style=display:flex><span>kubeadm init phase certs apiserver-etcd-client --config<span style=color:#666>=</span>/tmp/<span style=color:#b68;font-weight:700>${</span><span style=color:#b8860b>HOST1</span><span style=color:#b68;font-weight:700>}</span>/kubeadmcfg.yaml
</span></span><span style=display:flex><span>cp -R /etc/kubernetes/pki /tmp/<span style=color:#b68;font-weight:700>${</span><span style=color:#b8860b>HOST1</span><span style=color:#b68;font-weight:700>}</span>/
</span></span><span style=display:flex><span>find /etc/kubernetes/pki -not -name ca.crt -not -name ca.key -type f -delete
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>kubeadm init phase certs etcd-server --config<span style=color:#666>=</span>/tmp/<span style=color:#b68;font-weight:700>${</span><span style=color:#b8860b>HOST0</span><span style=color:#b68;font-weight:700>}</span>/kubeadmcfg.yaml
</span></span><span style=display:flex><span>kubeadm init phase certs etcd-peer --config<span style=color:#666>=</span>/tmp/<span style=color:#b68;font-weight:700>${</span><span style=color:#b8860b>HOST0</span><span style=color:#b68;font-weight:700>}</span>/kubeadmcfg.yaml
</span></span><span style=display:flex><span>kubeadm init phase certs etcd-healthcheck-client --config<span style=color:#666>=</span>/tmp/<span style=color:#b68;font-weight:700>${</span><span style=color:#b8860b>HOST0</span><span style=color:#b68;font-weight:700>}</span>/kubeadmcfg.yaml
</span></span><span style=display:flex><span>kubeadm init phase certs apiserver-etcd-client --config<span style=color:#666>=</span>/tmp/<span style=color:#b68;font-weight:700>${</span><span style=color:#b8860b>HOST0</span><span style=color:#b68;font-weight:700>}</span>/kubeadmcfg.yaml
</span></span><span style=display:flex><span><span style=color:#080;font-style:italic># No need to move the certs because they are for HOST0</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#080;font-style:italic># clean up certs that should not be copied off this host</span>
</span></span><span style=display:flex><span>find /tmp/<span style=color:#b68;font-weight:700>${</span><span style=color:#b8860b>HOST2</span><span style=color:#b68;font-weight:700>}</span> -name ca.key -type f -delete
</span></span><span style=display:flex><span>find /tmp/<span style=color:#b68;font-weight:700>${</span><span style=color:#b8860b>HOST1</span><span style=color:#b68;font-weight:700>}</span> -name ca.key -type f -delete
</span></span></code></pre></div></li><li><p>Copier les certificats et les configurations kubeadm</p><p>Les certificats ont été générés et doivent maintenant être déplacés vers leur
hôtes respectifs.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh><span style=display:flex><span><span style=color:#b8860b>USER</span><span style=color:#666>=</span>ubuntu
</span></span><span style=display:flex><span><span style=color:#b8860b>HOST</span><span style=color:#666>=</span><span style=color:#b68;font-weight:700>${</span><span style=color:#b8860b>HOST1</span><span style=color:#b68;font-weight:700>}</span>
</span></span><span style=display:flex><span>scp -r /tmp/<span style=color:#b68;font-weight:700>${</span><span style=color:#b8860b>HOST</span><span style=color:#b68;font-weight:700>}</span>/* <span style=color:#b68;font-weight:700>${</span><span style=color:#b8860b>USER</span><span style=color:#b68;font-weight:700>}</span>@<span style=color:#b68;font-weight:700>${</span><span style=color:#b8860b>HOST</span><span style=color:#b68;font-weight:700>}</span>:
</span></span><span style=display:flex><span>ssh <span style=color:#b68;font-weight:700>${</span><span style=color:#b8860b>USER</span><span style=color:#b68;font-weight:700>}</span>@<span style=color:#b68;font-weight:700>${</span><span style=color:#b8860b>HOST</span><span style=color:#b68;font-weight:700>}</span>
</span></span><span style=display:flex><span>USER@HOST $ sudo -Es
</span></span><span style=display:flex><span>root@HOST $ chown -R root:root pki
</span></span><span style=display:flex><span>root@HOST $ mv pki /etc/kubernetes/
</span></span></code></pre></div></li><li><p>S'assurer que tous les fichiers attendus existent</p><p>La liste complète des fichiers requis sur <code>$HOST0</code> est la suivante:</p><pre tabindex=0><code>/tmp/${HOST0}
└── kubeadmcfg.yaml
---
/etc/kubernetes/pki
├── apiserver-etcd-client.crt
├── apiserver-etcd-client.key
└── etcd
    ├── ca.crt
    ├── ca.key
    ├── healthcheck-client.crt
    ├── healthcheck-client.key
    ├── peer.crt
    ├── peer.key
    ├── server.crt
    └── server.key
</code></pre><p>Sur <code>$HOST1</code>:</p><pre tabindex=0><code>$HOME
└── kubeadmcfg.yaml
---
/etc/kubernetes/pki
├── apiserver-etcd-client.crt
├── apiserver-etcd-client.key
└── etcd
    ├── ca.crt
    ├── healthcheck-client.crt
    ├── healthcheck-client.key
    ├── peer.crt
    ├── peer.key
    ├── server.crt
    └── server.key
</code></pre><p>Sur <code>$HOST2</code>:</p><pre tabindex=0><code>$HOME
└── kubeadmcfg.yaml
---
/etc/kubernetes/pki
├── apiserver-etcd-client.crt
├── apiserver-etcd-client.key
└── etcd
    ├── ca.crt
    ├── healthcheck-client.crt
    ├── healthcheck-client.key
    ├── peer.crt
    ├── peer.key
    ├── server.crt
    └── server.key
</code></pre></li><li><p>Créer les manifestes de pod statiques</p><p>Maintenant que les certificats et les configurations sont en place, il est temps de créer les
manifestes. Sur chaque hôte, exécutez la commande <code>kubeadm</code> pour générer un manifeste statique
pour etcd.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh><span style=display:flex><span>root@HOST0 $ kubeadm init phase etcd <span style=color:#a2f>local</span> --config<span style=color:#666>=</span>/tmp/<span style=color:#b68;font-weight:700>${</span><span style=color:#b8860b>HOST0</span><span style=color:#b68;font-weight:700>}</span>/kubeadmcfg.yaml
</span></span><span style=display:flex><span>root@HOST1 $ kubeadm init phase etcd <span style=color:#a2f>local</span> --config<span style=color:#666>=</span><span style=color:#b8860b>$HOME</span>/kubeadmcfg.yaml
</span></span><span style=display:flex><span>root@HOST2 $ kubeadm init phase etcd <span style=color:#a2f>local</span> --config<span style=color:#666>=</span><span style=color:#b8860b>$HOME</span>/kubeadmcfg.yaml
</span></span></code></pre></div></li><li><p>Facultatif: Vérifiez la santé du cluster</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh><span style=display:flex><span>docker run --rm -it <span style=color:#b62;font-weight:700>\
</span></span></span><span style=display:flex><span><span style=color:#b62;font-weight:700></span>--net host <span style=color:#b62;font-weight:700>\
</span></span></span><span style=display:flex><span><span style=color:#b62;font-weight:700></span>-v /etc/kubernetes:/etc/kubernetes quay.io/coreos/etcd:<span style=color:#b68;font-weight:700>${</span><span style=color:#b8860b>ETCD_TAG</span><span style=color:#b68;font-weight:700>}</span> etcdctl <span style=color:#b62;font-weight:700>\
</span></span></span><span style=display:flex><span><span style=color:#b62;font-weight:700></span>--cert-file /etc/kubernetes/pki/etcd/peer.crt <span style=color:#b62;font-weight:700>\
</span></span></span><span style=display:flex><span><span style=color:#b62;font-weight:700></span>--key-file /etc/kubernetes/pki/etcd/peer.key <span style=color:#b62;font-weight:700>\
</span></span></span><span style=display:flex><span><span style=color:#b62;font-weight:700></span>--ca-file /etc/kubernetes/pki/etcd/ca.crt <span style=color:#b62;font-weight:700>\
</span></span></span><span style=display:flex><span><span style=color:#b62;font-weight:700></span>--endpoints https://<span style=color:#b68;font-weight:700>${</span><span style=color:#b8860b>HOST0</span><span style=color:#b68;font-weight:700>}</span>:2379 cluster-health
</span></span><span style=display:flex><span>...
</span></span><span style=display:flex><span>cluster is healthy
</span></span></code></pre></div><ul><li>Configurez <code>${ETCD_TAG}</code> avec la version de votre image etcd. Par exemple <code>v3.2.24</code>.</li><li>Configurez <code>${HOST0}</code> avec l'adresse IP de l'hôte que vous testez.</li></ul></li></ol><h2 id=a-suivre>A suivre</h2><p>Une fois que vous avez un cluster de 3 membres etcd qui fonctionne, vous pouvez continuer à
configurer un control plane hautement disponible utilisant la
<a href=/fr/docs/setup/production-environment/tools/kubeadm/high-availability/>méthode etcd externe avec kubeadm</a>.</p></div><div class=td-content style=page-break-before:always><h1 id=pg-07709e71de6b4ac2573041c31213dbeb>2.3.1.1.7 - Configuration des kubelet de votre cluster avec kubeadm</h1><div class=lead>Configuration kubelet Kubernetes cluster kubeadm</div><div style=margin-top:10px;margin-bottom:10px><b>FEATURE STATE:</b> <code>Kubernetes 1.11 [stable]</code></div><p>Le cycle de vie de l’outil CLI kubeadm est découplé de celui de la
<a href=/docs/reference/command-line-tools-reference/kubelet>kubelet</a>, qui est un démon qui s'éxécute
sur chaque noeud du cluster Kubernetes. L'outil CLI de kubeadm est exécuté par l'utilisateur lorsque
Kubernetes est initialisé ou mis à niveau, alors que la kubelet est toujours exécutée en arrière-plan.</p><p>Comme la kubelet est un démon, elle doit être maintenue par une sorte d'init système ou un gestionnaire
de service. Lorsque la kubelet est installée à l'aide de DEB ou de RPM,
systemd est configuré pour gérer la kubelet. Vous pouvez utiliser un gestionnaire différent à la place,
mais vous devez le configurer manuellement.</p><p>Certains détails de configuration de la kubelet doivent être identiques pour
toutes les kubelets du cluster, tandis que d’autres aspects de la configuration
doivent être définis par nœud, pour tenir compte des différentes caractéristiques
d’une machine donnée, telles que le système d’exploitation, le stockage et la
mise en réseau. Vous pouvez gérer la configuration manuellement de vos kubelets,
mais <a href=#configure-kubelets-using-kubeadm>kubeadm fournit maintenant un type d’API <code>KubeletConfiguration</code> pour la gestion centralisée de vos configurations de kubelets</a>.</p><h2 id=patterns-de-configuration-des-kubelets>Patterns de configuration des Kubelets</h2><p>Les sections suivantes décrivent les modèles de configuration de kubelet simplifiés en
utilisant kubeadm, plutôt que de gérer manuellement la configuration des kubelets pour chaque nœud.</p><h3 id=propagating-cluster-level-configuration-to-each-kubelet>Propagation de la configuration niveau cluster à chaque kubelet</h3><p>Vous pouvez fournir à la kubelet les valeurs par défaut à utiliser par les commandes <code>kubeadm init</code> et
<code>kubeadm join</code>. Des exemples intéressants incluent l’utilisation d’un runtime CRI différent ou la
définition du sous-réseau par défaut utilisé par les services.</p><p>Si vous souhaitez que vos services utilisent le sous-réseau <code>10.96.0.0 / 12</code> par défaut pour les
services, vous pouvez passer le paramètre <code>--service-cidr</code> à kubeadm:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>kubeadm init --service-cidr 10.96.0.0/12
</span></span></code></pre></div><p>Les adresses IP virtuelles pour les services sont maintenant attribuées à partir de ce sous-réseau.
Vous devez également définir l'adresse DNS utilisée par la kubelet, en utilisant l'option
<code>--cluster-dns</code>. Ce paramètre doit être le même pour chaque kubelet sur chaque master et worker
du cluster. La kubelet fournit un objet API structuré versionné qui peut configurer la plupart des
paramètres dans la kubelet et pousser cette configuration à chaque exécution de la kubelet dans
le cluster. Cet objet s'appelle la <strong>ComponentConfig</strong> de la kubelet.
La ComponentConfig permet à l’utilisateur de spécifier des options tels que les adresses IP DNS du
cluster exprimées en une liste de valeurs pour une clé formatée en CamelCased, illustrée par l'exemple suivant:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>kubelet.config.k8s.io/v1beta1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>KubeletConfiguration<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>clusterDNS</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span>- <span style=color:#666>10.96.0.10</span><span style=color:#bbb>
</span></span></span></code></pre></div><p>Pour plus de détails sur ComponentConfig, jetez un œil à <a href=#configure-kubelets-using-kubeadm>cette section</a>.</p><h3 id=providing-instance-specific-configuration-details>Fournir des détails de configuration spécifiques à l'instance</h3><p>Certaines machines nécessitent des configurations de kubelet spécifiques, en raison de la différences de
matériel, de système d’exploitation, réseau ou d’autres paramètres spécifiques à l’hôte. La liste suivante
fournit quelques exemples.</p><ul><li><p>Le chemin d'accès au fichier de résolution DNS, tel que spécifié par l'option de configuration
de la kubelet <code>--resolv-conf</code>, peut différer selon les systèmes d'exploitation ou selon que vous utilisez
ou non <code>systemd-resolved</code>. Si ce chemin est incorrect, la résolution DNS échouera sur le nœud
dont la kubelet est configuré de manière incorrecte.</p></li><li><p>L'objet API de nœud <code>.metadata.name</code> est défini par défaut sur le hostname de la machine,
sauf si vous utilisez un fournisseur de cloud. Vous pouvez utiliser l’indicateur <code>--hostname-override</code>
pour remplacer le comportement par défaut si vous devez spécifier un nom de nœud différent du hostname
de la machine.</p></li><li><p>Actuellement, la kubelet ne peut pas détecter automatiquement le driver cgroup utilisé par le
runtime CRI, mais la valeur de <code>--cgroup-driver</code> doit correspondre au driver cgroup
utilisé par le runtime CRI pour garantir la santé de la kubelet.</p></li><li><p>En fonction du runtime du CRI utilisé par votre cluster, vous devrez peut-être spécifier des
options différentes pour la kubelet. Par exemple, lorsque vous utilisez Docker,
vous devez spécifier des options telles que
<code>--network-plugin = cni</code>, mais si vous utilisez un environnement d’exécution externe, vous devez spécifier
<code>--container-runtime = remote</code> et spécifier le CRI endpoint en utilisant l'option
<code>--container-runtime-path-endpoint = &lt;chemin></code>.</p></li></ul><p>Vous pouvez spécifier ces options en modifiant la configuration d’une kubelet individuelle dans
votre gestionnaire de service, tel que systemd.</p><h2 id=configure-kubelets-using-kubeadm>Configurer les kubelets en utilisant kubeadm</h2><p>Il est possible de configurer la kubelet que kubeadm va démarrer si un objet API personnalisé
<code>KubeletConfiguration</code> est passé en paramètre via un fichier de configuration comme
<code>kubeadm ... --config some-config-file.yaml</code>.</p><p>En appelant <code>kubeadm config print-default --api-objects KubeletConfiguration</code> vous
pouvez voir toutes les valeurs par défaut pour cette structure.</p><p>Regardez aussi la <a href=https://godoc.org/k8s.io/kubernetes/pkg/kubelet/apis/config#KubeletConfiguration>référence API pour le composant ComponentConfig des kubelets</a>
pour plus d'informations sur les champs individuels.</p><h3 id=workflow-lors-de-l-utilisation-de-kubeadm-init>Workflow lors de l'utilisation de <code>kubeadm init</code></h3><p>Lorsque vous appelez <code>kubeadm init</code>, la configuration de la kubelet est organisée sur le disque
sur <code>/var/lib/kubelet/config.yaml</code>, et également chargé sur une ConfigMap du cluster. La ConfigMap
est nommé <code>kubelet-config-1.X</code>, où <code>.X</code> est la version mineure de la version de Kubernetes
que vous êtes en train d'initialiser. Un fichier de configuration de kubelet est également écrit dans
<code>/etc/kubernetes/kubelet.conf</code> avec la configuration de base à l'échelle du cluster pour tous les
kubelets du cluster. Ce fichier de configuration pointe vers les certificats clients permettant aux
kubelets de communiquer avec l'API server. Ceci répond au besoin de
<a href=#propagating-cluster-level-configuration-to-each-kubelet>propager la configuration niveau cluster à chaque kubelet</a>.</p><p>Pour répondre au besoin de
<a href=#providing-instance-specific-configuration-details>fournir des détails de configuration spécifiques à l'instance de kubelet</a>,
kubeadm écrit un fichier d'environnement dans <code>/var/lib/kubelet/kubeadm-flags.env</code>, qui contient une liste
d'options à passer à la kubelet quand elle démarre. Les options sont représentées dans le fichier comme ceci:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#b8860b>KUBELET_KUBEADM_ARGS</span><span style=color:#666>=</span><span style=color:#b44>&#34;--flag1=value1 --flag2=value2 ...&#34;</span>
</span></span></code></pre></div><p>Outre les indicateurs utilisés lors du démarrage de la kubelet, le fichier contient également des
informations dynamiques comme des paramètres tels que le driver cgroup et s'il faut utiliser un autre
socket de runtime CRI (<code>--cri-socket</code>).</p><p>Après avoir rassemblé ces deux fichiers sur le disque, kubeadm tente d’exécuter ces deux commandes,
si vous utilisez systemd:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>systemctl daemon-reload <span style=color:#666>&amp;&amp;</span> systemctl restart kubelet
</span></span></code></pre></div><p>Si le rechargement et le redémarrage réussissent, le workflow normal de <code>kubeadm init</code> continue.</p><h3 id=workflow-en-utilisant-kubeadm-join>Workflow en utilisant <code>kubeadm join</code></h3><p>Lorsque vous exécutez <code>kubeadm join</code>, kubeadm utilise les informations d'identification du bootstrap
token pour faire un bootstrap TLS, qui récupère les informations d’identité nécessaires pour télécharger le
<code>kubelet-config-1.X</code> ConfigMap puis l'écrit dans <code>/var/lib/kubelet/config.yaml</code>. Le fichier d’environnement
dynamique est généré exactement de la même manière que <code>kubeadm init</code>.</p><p>Ensuite, <code>kubeadm</code> exécute les deux commandes suivantes pour charger la nouvelle configuration dans la kubelet:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>systemctl daemon-reload <span style=color:#666>&amp;&amp;</span> systemctl restart kubelet
</span></span></code></pre></div><p>Après le chargement de la nouvelle configuration par la kubelet, kubeadm écrit le fichier KubeConfig
<code>/etc/kubernetes/bootstrap-kubelet.conf</code>, qui contient un certificat de CA et un jeton Bootstrap.
Ceux-ci sont utilisés par la kubelet pour effectuer le TLS Bootstrap et obtenir une information
d'identification unique, qui est stocké dans <code>/etc/kubernetes/kubelet.conf</code>. Quand ce fichier est
écrit, la kubelet a terminé l'exécution du bootstrap TLS.</p><h2 id=the-kubelet-drop-in-file-for-systemd>Le fichier kubelet généré pour systemd</h2><p>Le fichier de configuration installé par le package DEB ou RPM de kubeadm est écrit dans
<code>/etc/systemd/system/kubelet.service.d/10-kubeadm.conf</code> et est utilisé par systemd.</p><pre tabindex=0><code class=language-none data-lang=none>[Service]
Environment=&#34;KUBELET_KUBECONFIG_ARGS=--bootstrap-kubeconfig=/etc/kubernetes/bootstrap-kubelet.conf
--kubeconfig=/etc/kubernetes/kubelet.conf&#34;
Environment=&#34;KUBELET_CONFIG_ARGS=--config=/var/lib/kubelet/config.yaml&#34;
# This is a file that &#34;kubeadm init&#34; and &#34;kubeadm join&#34; generates at runtime, populating
the KUBELET_KUBEADM_ARGS variable dynamically
EnvironmentFile=-/var/lib/kubelet/kubeadm-flags.env
# This is a file that the user can use for overrides of the kubelet args as a last resort. Preferably,
# the user should use the .NodeRegistration.KubeletExtraArgs object in the configuration files instead.
# KUBELET_EXTRA_ARGS should be sourced from this file.
EnvironmentFile=-/etc/default/kubelet
ExecStart=
ExecStart=/usr/bin/kubelet $KUBELET_KUBECONFIG_ARGS $KUBELET_CONFIG_ARGS $KUBELET_KUBEADM_ARGS $KUBELET_EXTRA_ARGS
</code></pre><p>Ce fichier spécifie les emplacements par défaut pour tous les fichiers gérés par kubeadm pour la kubelet.</p><ul><li>Le fichier KubeConfig à utiliser pour le TLS Bootstrap est <code>/etc/kubernetes/bootstrap-kubelet.conf</code>,
mais il n'est utilisé que si <code>/etc/kubernetes/kubelet.conf</code> n'existe pas.</li><li>Le fichier KubeConfig avec l’identité unique de la kubelet est <code>/etc/kubernetes/kubelet.conf</code>.</li><li>Le fichier contenant le ComponentConfig de la kubelet est <code>/var/lib/kubelet/config.yaml</code>.</li><li>Le fichier d'environnement dynamique qui contient <code>KUBELET_KUBEADM_ARGS</code> est sourcé à partir de
<code>/var/lib/kubelet/kubeadm-flags.env</code>.</li><li>Le fichier qui peut contenir les paramètres surchargés par l'utilisateur avec <code>KUBELET_EXTRA_ARGS</code>
provient de <code>/etc/default/kubelet</code> (pour les DEBs), ou <code>/etc/sysconfig/kubelet</code> (pour les RPMs)
<code>KUBELET_EXTRA_ARGS</code> est le dernier de la chaîne d'options et a la priorité la plus élevée en cas
de conflit de paramètres.</li></ul><h2 id=fichiers-binaires-de-kubernetes-et-contenu-du-package>Fichiers binaires de Kubernetes et contenu du package</h2><p>Les packages DEB et RPM fournis avec les versions de Kubernetes sont les suivants:</p><table><thead><tr><th>Nom du paquet</th><th>Description</th></tr></thead><tbody><tr><td><code>kubeadm</code></td><td>Installe l'outil CLI <code>/usr/bin/kubeadm</code> et <a href=#the-kubelet-drop-in-file-for-systemd>le fichier instantané de kubelet</a> pour la kubelet.</td></tr><tr><td><code>kubelet</code></td><td>Installe <code>/usr/bin/kubelet</code>.</td></tr><tr><td><code>kubectl</code></td><td>Installe <code>/usr/bin/kubectl</code>.</td></tr><tr><td><code>kubernetes-cni</code></td><td>Installe les binaires officiels du CNI dans le repertoire <code>/opt/cni/bin</code>.</td></tr><tr><td><code>cri-tools</code></td><td>Installe <code>/usr/bin/crictl</code> à partir de <a href=https://github.com/kubernetes-incubator/cri-tools>https://github.com/kubernetes-incubator/cri-tools</a>.</td></tr></tbody></table></div><div class=td-content style=page-break-before:always><h1 id=pg-c3689df4b0c61a998e79d91a865aa244>2.3.1.1.8 - Dépanner kubeadm</h1><div class=lead>Diagnostic pannes kubeadm debug</div><p>Comme avec n'importe quel programme, vous pourriez rencontrer une erreur lors de l'installation ou de
l'exécution de kubeadm.
Cette page répertorie certains scénarios d’échec courants et propose des étapes pouvant vous aider à
comprendre et résoudre le problème.</p><p>Si votre problème ne figure pas dans la liste ci-dessous, procédez comme suit:</p><ul><li><p>Si vous pensez que votre problème est un bug avec kubeadm:</p><ul><li>Aller à <a href=https://github.com/kubernetes/kubeadm/issues>github.com/kubernetes/kubeadm</a> et rechercher
les problèmes existants.</li><li>Si aucune issue n'existe, veuillez <a href=https://github.com/kubernetes/kubeadm/issues/new>en ouvrir une</a> et
suivez le modèle ( template ) d'issue</li></ul></li><li><p>Si vous ne savez pas comment fonctionne kubeadm, vous pouvez demander sur <a href=http://slack.k8s.io/>Slack</a>
dans le canal #kubeadm, ou posez une questions sur
<a href=https://stackoverflow.com/questions/tagged/kubernetes>StackOverflow</a>. Merci d'ajouter les tags pertinents
comme <code>#kubernetes</code> et <code>#kubeadm</code>, ainsi on pourra vous aider.</p></li></ul><h2 id=ebtables-ou-un-exécutable-similaire-introuvable-lors-de-l-installation><code>ebtables</code> ou un exécutable similaire introuvable lors de l'installation</h2><p>Si vous voyez les warnings suivants lors de l'exécution <code>kubeadm init</code></p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh><span style=display:flex><span><span style=color:#666>[</span>preflight<span style=color:#666>]</span> WARNING: ebtables not found in system path
</span></span><span style=display:flex><span><span style=color:#666>[</span>preflight<span style=color:#666>]</span> WARNING: ethtool not found in system path
</span></span></code></pre></div><p>Ensuite, il peut vous manquer <code>ebtables</code>, <code>ethtool</code> ou un exécutable similaire sur votre nœud. Vous
pouvez l'installer avec les commandes suivantes:</p><ul><li>For Ubuntu/Debian users, run <code>apt install ebtables ethtool</code>.</li><li>For CentOS/Fedora users, run <code>yum install ebtables ethtool</code>.</li></ul><h2 id=kubeadm-reste-bloqué-en-attente-du-control-plane-pendant-l-installation>kubeadm reste bloqué en attente du control plane pendant l'installation</h2><p>Si vous remarquez que <code>kubeadm init</code> se bloque après la ligne suivante:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh><span style=display:flex><span><span style=color:#666>[</span>apiclient<span style=color:#666>]</span> Created API client, waiting <span style=color:#a2f;font-weight:700>for</span> the control plane to become ready
</span></span></code></pre></div><p>Cela peut être causé par un certain nombre de problèmes. Les plus communs sont:</p><ul><li><p>problèmes de connexion réseau. Vérifiez que votre machine dispose d'une connectivité réseau
complète avant de continuer.</p></li><li><p>la configuration du driver cgroup par défaut pour la kubelet diffère de celle utilisée par Docker.
  Vérifiez le fichier journal du système (par exemple, <code>/var/log/message</code>) ou examinez le résultat
de <code>journalctl -u kubelet</code>. Si vous voyez quelque chose comme ce qui suit:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>error: failed to run Kubelet: failed to create kubelet:
</span></span><span style=display:flex><span>misconfiguration: kubelet cgroup driver: <span style=color:#b44>&#34;systemd&#34;</span> is different from docker cgroup driver: <span style=color:#b44>&#34;cgroupfs&#34;</span>
</span></span></code></pre></div><p>Il existe deux méthodes courantes pour résoudre le problème du driver cgroup:</p></li></ul><ol><li>Installez à nouveau Docker en suivant les instructions
<a href=/fr/docs/setup/production-environment/tools/kubeadm/install-kubeadm/#installing-docker>ici</a>.</li><li>Changez manuellement la configuration de la kubelet pour correspondre au driver Docker cgroup, vous pouvez vous référer à
    <a href=/fr/docs/setup/production-environment/tools/kubeadm/install-kubeadm/#configure-cgroup-driver-used-by-kubelet-on-master-node>Configurez le driver de cgroupe utilisé par la kubelet sur le Nœud Master</a>
pour des instruction détaillées.</li></ol><ul><li>Les conteneurs Docker du control plane sont en crashloop ou suspendus. Vous pouvez le vérifier en lançant <code>docker ps</code> et étudier chaque conteneur en exécutant <code>docker logs</code>.</li></ul><h2 id=kubeadm-bloque-lors-de-la-suppression-de-conteneurs-gérés>kubeadm bloque lors de la suppression de conteneurs gérés</h2><p>Les événements suivants peuvent se produire si Docker s'arrête et ne supprime pas les conteneurs gérés
par Kubernetes:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>sudo kubeadm reset
</span></span><span style=display:flex><span><span style=color:#666>[</span>preflight<span style=color:#666>]</span> Running pre-flight checks
</span></span><span style=display:flex><span><span style=color:#666>[</span>reset<span style=color:#666>]</span> Stopping the kubelet service
</span></span><span style=display:flex><span><span style=color:#666>[</span>reset<span style=color:#666>]</span> Unmounting mounted directories in <span style=color:#b44>&#34;/var/lib/kubelet&#34;</span>
</span></span><span style=display:flex><span><span style=color:#666>[</span>reset<span style=color:#666>]</span> Removing kubernetes-managed containers
</span></span><span style=display:flex><span><span style=color:#666>(</span>block<span style=color:#666>)</span>
</span></span></code></pre></div><p>Une solution possible consiste à redémarrer le service Docker, puis à réexécuter <code>kubeadm reset</code>:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>sudo systemctl restart docker.service
</span></span><span style=display:flex><span>sudo kubeadm reset
</span></span></code></pre></div><p>L'inspection des journaux de Docker peut également être utile:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh><span style=display:flex><span>journalctl -ul docker
</span></span></code></pre></div><h2 id=pods-dans-l-état-runcontainererror-crashloopbackoff-ou-error>Pods dans l'état <code>RunContainerError</code>, <code>CrashLoopBackOff</code> ou <code>Error</code></h2><p>Juste après <code>kubeadm init</code>, il ne devrait pas y avoir de pods dans ces états.</p><ul><li>S'il existe des pods dans l'un de ces états <em>juste après</em> <code>kubeadm init</code>, veuillez ouvrir un
issue dans le dépôt de Kubeadm. <code>coredns</code> (ou<code> kube-dns</code>) devrait être dans l'état <code>Pending</code>
  jusqu'à ce que vous ayez déployé la solution réseau.</li><li>Si vous voyez des pods dans les états <code>RunContainerError</code>, <code>CrashLoopBackOff</code> ou <code>Error</code>
  après le déploiement de la solution réseau et que rien ne se passe pour <code>coredns</code> (ou<code> kube-dns</code>),
  il est très probable que la solution Pod Network que vous avez installée est en quelque sorte
endommagée. Vous devrez peut-être lui accorder plus de privilèges RBAC ou utiliser une version
plus récente. S'il vous plaît créez une issue dans le dépôt du fournisseur de réseau de Pod.</li><li>Si vous installez une version de Docker antérieure à 1.12.1, supprimez l'option <code>MountFlags = slave</code>
  lors du démarrage de <code>dockerd</code> avec <code>systemd</code> et redémarrez <code>docker</code>. Vous pouvez voir les options
de montage dans <code>/usr/lib/systemd/system/docker.service</code>.
Les options de montage peuvent interférer avec les volumes montés par Kubernetes et mettre les
pods dans l'état <code>CrashLoopBackOff</code>. L'erreur se produit lorsque Kubernetes ne trouve pas les fichiers
<code>var/run/secrets/kubernetes.io/serviceaccount</code>.</li></ul><h2 id=coredns-ou-kube-dns-est-bloqué-dans-l-état-pending><code>coredns</code> (ou <code>kube-dns</code>) est bloqué dans l'état <code>Pending</code></h2><p>Ceci est <strong>prévu</strong> et fait partie du design. kubeadm est agnostique vis-à-vis du fournisseur
de réseau, ainsi l'administrateur devrait <a href=/docs/concepts/cluster-administration/addons/>installer la solution réseau pod</a>
de choix. Vous devez installer un réseau de pods avant que CoreDNS ne soit complètement déployé.
D'où l' état <code>Pending</code> avant la mise en place du réseau.</p><h2 id=les-services-hostport-ne-fonctionnent-pas>Les services <code>HostPort</code> ne fonctionnent pas</h2><p>Les fonctionnalités <code>HostPort</code> et <code>HostIP</code> sont disponibles en fonction de votre fournisseur
de réseau de pod. Veuillez contacter l’auteur de la solution de réseau de Pod pour savoir si
Les fonctionnalités <code>HostPort</code> et <code>HostIP</code> sont disponibles.</p><p>Les fournisseurs de CNI Calico, Canal, et Flannel supportent HostPort.</p><p>Pour plus d'informations, voir la <a href=https://github.com/containernetworking/plugins/blob/master/plugins/meta/portmap/README.md>CNI portmap documentation</a>.</p><p>Si votre fournisseur de réseau ne prend pas en charge le plug-in portmap CNI, vous devrez peut-être utiliser le
<a href=/docs/concepts/services-networking/service/#nodeport>NodePort feature of services</a> ou utiliser <code>HostNetwork=true</code>.</p><h2 id=les-pods-ne-sont-pas-accessibles-via-leur-ip-de-service>Les pods ne sont pas accessibles via leur IP de service</h2><ul><li><p>De nombreux add-ons réseau ne permettent pas encore
<a href=/docs/tasks/debug-application-cluster/debug-service/#a-pod-cannot-reach-itself-via-service-ip>hairpin mode</a>
qui permet aux pods d’accéder à eux-mêmes via leur IP de service. Ceci est un problème lié
au <a href=https://github.com/containernetworking/cni/issues/476>CNI</a>. S'il vous plaît contacter
le fournisseur d'add-on réseau afin d'obtenir des informations en matière de prise en charge du mode hairpin.</p></li><li><p>Si vous utilisez VirtualBox (directement ou via Vagrant), vous devrez vous assurez que
<code>hostname -i</code> renvoie une adresse IP routable. Par défaut la première interface est connectée
à un réseau d’ <code>hôte uniquement</code> non routable. En contournement vous pouvez modifier <code>/etc/hosts</code>,
jetez un œil à ce <a href=https://github.com/errordeveloper/k8s-playground/blob/22dd39dfc06111235620e6c4404a96ae146f26fd/Vagrantfile#L11>Vagrantfile</a> par exemple.</p></li></ul><h2 id=erreurs-de-certificats-tls>Erreurs de certificats TLS</h2><p>L'erreur suivante indique une possible incompatibilité de certificat.</p><pre tabindex=0><code class=language-none data-lang=none># kubectl get pods
Unable to connect to the server: x509: certificate signed by unknown authority (possibly because of
&#34;crypto/rsa: verification error&#34; while trying to verify candidate authority certificate &#34;kubernetes&#34;)
</code></pre><ul><li><p>Vérifiez que le fichier <code>$HOME/.kube/config</code> contient un certificat valide, et 
re-générer un certificat si nécessaire. Les certificats dans un fichier kubeconfig 
sont encodés en base64. La commande <code>base64 -d</code> peut être utilisée pour décoder le certificat 
et <code>openssl x509 -text -noout</code> peut être utilisé pour afficher les informations du certificat.</p></li><li><p>Une autre solution consiste à écraser le <code>kubeconfig</code> existant pour l'utilisateur" admin ":</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh><span style=display:flex><span>mv  <span style=color:#b8860b>$HOME</span>/.kube <span style=color:#b8860b>$HOME</span>/.kube.bak
</span></span><span style=display:flex><span>sudo cp -i /etc/kubernetes/admin.conf <span style=color:#b8860b>$HOME</span>/.kube/config
</span></span><span style=display:flex><span>sudo chown <span style=color:#a2f;font-weight:700>$(</span>id -u<span style=color:#a2f;font-weight:700>)</span>:<span style=color:#a2f;font-weight:700>$(</span>id -g<span style=color:#a2f;font-weight:700>)</span> <span style=color:#b8860b>$HOME</span>/.kube/config
</span></span></code></pre></div></li></ul><h2 id=carte-réseau-par-défaut-lors-de-l-utilisation-de-flannel-comme-réseau-de-pod-dans-vagrant>Carte réseau par défaut lors de l'utilisation de flannel comme réseau de pod dans Vagrant</h2><p>L'erreur suivante peut indiquer que quelque chose n'allait pas dans le réseau de pod:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh><span style=display:flex><span>Error from server <span style=color:#666>(</span>NotFound<span style=color:#666>)</span>: the server could not find the requested resource
</span></span></code></pre></div><ul><li>Si vous utilisez flannel comme réseau de pod dans Vagrant, vous devrez spécifier le
nom d'interface par défaut pour flannel.</li></ul><p>  Vagrant attribue généralement deux interfaces à tous les ordinateurs virtuels. La
première, pour laquel tous les hôtes se voient attribuer l’adresse IP <code>10.0.2.15</code>,
est pour le trafic externe qui est NATé.</p><p>  Cela peut entraîner des problèmes avec Flannel, qui utilise par défaut la première
interface sur un hôte. Ceci conduit au fait que tous les hôtes pensent qu'ils ont la
même adresse IP publique. Pour éviter cela, passez l'option <code>--iface eth1</code> sur Flannel
pour que la deuxième interface soit choisie.</p><h2 id=ip-non-publique-utilisée-pour-les-conteneurs>IP non publique utilisée pour les conteneurs</h2><p>Dans certaines situations, les commandes <code>kubectl logs</code> et <code>kubectl run</code> peuvent
renvoyer les erreurs suivantes dans un cluster par ailleurs fonctionnel:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh><span style=display:flex><span>Error from server: Get https://10.19.0.41:10250/containerLogs/default/mysql-ddc65b868-glc5m/mysql:
</span></span><span style=display:flex><span>dial tcp 10.19.0.41:10250: getsockopt: no route to host
</span></span></code></pre></div><ul><li><p>Cela peut être dû au fait que Kubernetes utilise une adresse IP qui ne peut pas communiquer
avec d’autres adresses IP même sous-réseau, éventuellement à cause d'une politique mise en place
par le fournisseur de la machine.</p></li><li><p>Digital Ocean attribue une adresse IP publique à <code>eth0</code> ainsi qu’une adresse privée à
utiliser en interne comme IP d'ancrage pour leur fonction IP flottante, mais <code>kubelet</code> choisira cette
dernière comme <code>InternalIP</code> du noeud au lieu du public.</p><p>Utilisez <code>ip addr show</code> pour verifier ce scénario au lieu de <code>ifconfig</code> car <code>ifconfig</code> n'affichera pas
l'alias de l'adresse IP incriminée. Sinon, une API spécifique à Digital Ocean 
permet de rechercher l'adresse IP d'ancrage à partir du droplet:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh><span style=display:flex><span>curl http://169.254.169.254/metadata/v1/interfaces/public/0/anchor_ipv4/address
</span></span></code></pre></div><p>La solution consiste à indiquer à la <code>kubelet</code> l'adresse IP à utiliser avec<code> --node-ip</code>. Lors de
l'utilisation de Digital Ocean, il peut être public (assigné à <code>eth0</code>) ou privé (assigné à<code> eth1</code>)
si vous voulez utiliser le réseau privé optionnel. la
<a href=https://github.com/kubernetes/kubernetes/blob/release-1.13/cmd/kubeadm/app/apis/kubeadm/v1beta1/types.go>la section <code>KubeletExtraArgs</code> de kubeadm <code>NodeRegistrationOptions</code> structure</a> peut être utilisé pour cela.</p><p>Puis redémarrer la <code>kubelet</code>:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh><span style=display:flex><span>systemctl daemon-reload
</span></span><span style=display:flex><span>systemctl restart kubelet
</span></span></code></pre></div></li></ul><h2 id=les-pods-coredns-sont-en-état-crashloopbackoff-ou-error>Les pods <code>coredns</code> sont en état<code> CrashLoopBackOff</code> ou <code>Error</code></h2><p>Si vous avez des nœuds qui exécutent SELinux avec une version plus ancienne de Docker, vous risquez
de rencontrer un problème ou les pods de <code>coredns</code> ne démarrent pas. Pour résoudre ce problème, vous pouvez essayer l'une des options suivantes:</p><ul><li>Mise à niveau vers une <a href=/fr/docs/setup/production-environment/tools/kubeadm/install-kubeadm/#installing-docker>nouvelle version de Docker</a>.</li><li><a href=https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/6/html/security-enhanced_linux/sect-security-enhanced_linux-enabling_and_disabling_selinux-disabling_selinux>Désactiver SELinux</a>.</li><li>Modifiez le déploiement de <code>coredns</code> pour définir<code> allowPrivilegeEscalation</code> à <code>true</code>:</li></ul><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>kubectl -n kube-system get deployment coredns -o yaml | <span style=color:#b62;font-weight:700>\
</span></span></span><span style=display:flex><span><span style=color:#b62;font-weight:700></span>  sed <span style=color:#b44>&#39;s/allowPrivilegeEscalation: false/allowPrivilegeEscalation: true/g&#39;</span> | <span style=color:#b62;font-weight:700>\
</span></span></span><span style=display:flex><span><span style=color:#b62;font-weight:700></span>  kubectl apply -f -
</span></span></code></pre></div><p>une autre raison pour laquelle CoreDNS peut se retrouver dans l'état <code>CrashLoopBackOff</code> est lorsqu'un
Pod de CoreDNS déployé dans Kubernetes détecte une boucle. <a href=https://github.com/coredns/coredns/tree/master/plugin/loop#troubleshooting-loops-in-kubernetes-clusters>Un certain nombre de solutions de contournement</a>
sont disponibles pour éviter que Kubernetes ne tente de redémarrer le pod CoreDNS chaque fois que CoreDNS détecte une boucle et s'arrête.</p><div class="alert alert-danger warning callout" role=alert><strong>Attention:</strong> Désactiver SELinux ou paramètrer <code>allowPrivilegeEscalation</code> sur <code>true</code> peut compromettre
la sécurité de votre cluster.</div><h2 id=les-pods-etcd-redémarrent-continuellement>Les pods etcd redémarrent continuellement</h2><p>Si vous rencontrez l'erreur suivante:</p><pre tabindex=0><code>rpc error: code = 2 desc = oci runtime error: exec failed: container_linux.go:247: starting container
process caused &#34;process_linux.go:110: decoding init error from pipe caused \&#34;read parent: connection
reset by peer\&#34;&#34;
</code></pre><p>ce problème apparaît si vous exécutez CentOS 7 avec Docker 1.13.1.84.
Cette version de Docker peut empêcher la kubelet de s'exécuter dans le conteneur etcd.</p><p>Pour contourner le problème, choisissez l'une de ces options.:</p><ul><li>Revenir à une version antérieure de Docker, telle que la 1.13.1-75:</li></ul><pre tabindex=0><code>yum downgrade docker-1.13.1-75.git8633870.el7.centos.x86_64 docker-client-1.13.1-75.git8633870.el7.centos.x86_64 docker-common-1.13.1-75.git8633870.el7.centos.x86_64
</code></pre><ul><li>Installez l'une des versions les plus récentes recommandées, telles que la 18.06:</li></ul><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>sudo yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo
</span></span><span style=display:flex><span>yum install docker-ce-18.06.1.ce-3.el7.x86_64
</span></span></code></pre></div></div><div class=td-content style=page-break-before:always><h1 id=pg-e2eb3029b668b1713d0dc8bea296ba9c>2.3.2 - Solutions Cloud clés en main</h1></div><div class=td-content style=page-break-before:always><h1 id=pg-1b751cdddc397a65edb7bcf703bc0414>2.3.3 - On-Premises VMs</h1></div><div class=td-content style=page-break-before:always><h1 id=pg-acce7e24090fea04715a7a516ba3e69b>2.3.4 - Windows dans Kubernetes</h1></div><div class=td-content style=page-break-before:always><h1 id=pg-89cb5486440b5e96f31dbb3956f2ad9e>2.4 - Solutions Cloud personnalisées</h1><div class=lead>Solutions Cloud personnalisées</div></div><div class=td-content><h1 id=pg-296711f0f3b239d2d549acc6ba48190e>2.4.1 - CoreOS sur AWS ou GCE</h1><div class=lead>Installation Kubernetes CoreOS sur AWS GCE</div><p>Il existe plusieurs guides permettant d'utiliser Kubernetes avec <a href=https://coreos.com/kubernetes/docs/latest/>CoreOS</a>.</p><h2 id=guides-officiels-coreos>Guides officiels CoreOS</h2><p>Ces guides sont maintenus par CoreOS et déploient Kubernetes à la "façon CoreOS" avec du TLS, le composant complémentaire pour le DNS interne, etc. Ces guides passent les tests de conformité Kubernetes et nous vous recommendons de [les tester vous-même] (<a href=https://coreos.com/kubernetes/docs/latest/conformance-tests.html)>https://coreos.com/kubernetes/docs/latest/conformance-tests.html)</a>.</p><ul><li><p><a href=https://coreos.com/kubernetes/docs/latest/kubernetes-on-aws.html><strong>Multi-noeuds sur AWS</strong></a></p><p>Guide et outil en ligne de commande pour créer un cluster multi-noeuds sur AWS.
CloudFormation est utilisé pour créer un noeud maitre ("master") et plusieurs noeuds de type "worker".</p></li><li><p><a href=https://coreos.com/kubernetes/docs/latest/kubernetes-on-baremetal.html#automated-provisioning><strong>Multi-noeuds sur serveurs physiques (Bare Metal)</strong></a></p><p>Guide et service HTTP / API pour l'initialisation et l'installation d’un cluster à plusieurs nœuds bare metal à partir d'un PXE.
<a href=https://coreos.com/ignition/docs/latest/>Ignition</a> est utilisé pour provisionner un cluster composé d'un master et de plusieurs workers lors du démarrage initial des serveurs.</p></li><li><p><a href=https://coreos.com/kubernetes/docs/latest/kubernetes-on-vagrant.html><strong>Multi-noeuds sur Vagrant</strong></a></p><p>Guide pour l'installation d'un cluster multi-noeuds sur Vagrant.
L'outil de déploiement permet de configurer indépendemment le nombre de noeuds etcd, masters et workers afin d'obtenir un control plane en haute disponibilité.</p></li><li><p><a href=https://coreos.com/kubernetes/docs/latest/kubernetes-on-vagrant-single.html><strong>Noeud unique sur Vagrant</strong></a></p><p>C'est la façon la plus rapide d'installer un environnement de développement local Kubernetes.
Il suffit simplement de <code>git clone</code>, <code>vagrant up</code> puis configurer <code>kubectl</code>.</p></li><li><p><a href=https://coreos.com/kubernetes/docs/latest/getting-started.html><strong>Guide complet pas à pas</strong></a></p><p>Un guide générique qui permet de déployer un cluster en haute disponibilité (avec du TLS) sur n'importe cloud ou sur du bare metal.
Répéter les étapes pour obtenir plus de noeuds master ou worker</p></li></ul><h2 id=guide-de-la-communauté>Guide de la communauté</h2><p>Ces guides sont maintenus par des membres de la communauté et couvrent des besoins et cas d'usages spécifiques. Ils proposent différentes manières de configurer Kubernetes sur CoreOS.</p><ul><li><p><a href=https://github.com/rimusz/coreos-multi-node-k8s-gce/blob/master/README.md><strong>Cluster multi-noeuds facile sur Google Compute Engine</strong></a></p><p>Installation scriptée d'un master unique et de plusieurs workers sur GCE.
Les composants Kubernetes sont gérés par <a href=https://github.com/coreos/fleet>fleet</a></p></li><li><p><a href=https://github.com/errordeveloper/weave-demos/blob/master/poseidon/README.md><strong>Cluster multi-noeuds en utilisant cloud-config et Weave sur Vagrant</strong></a></p><p>Configure un cluster de 3 machines sur Vagrant, le réseau du cluster étant fourni par Weave.</p></li><li><p><a href=https://github.com/pires/kubernetes-vagrant-coreos-cluster/blob/master/README.md><strong>Cluster multi-noeuds en utilisant cloud-config et Vagrant</strong></a></p><p>Configure un cluster local composé d'un master et de plusieurs workers sur l'hyperviseur de votre choix: VirtualBox, Parallels, ou VMware</p></li><li><p><a href=https://github.com/rimusz/kube-solo-osx/blob/master/README.md><strong>Cluster d'un seul noeud en utilisant une application macOS</strong></a></p><p>Guide permettant d'obtenir un cluster d'un seul noeud faisant office de master et worker et contrôlé par une application macOS menubar.
(basé sur xhyve et CoreOS)</p></li><li><p><a href=https://github.com/rimusz/coreos-osx-gui-kubernetes-cluster/blob/master/README.md><strong>Cluster multi-noeuds avec Vagrant et fleet en utilisant une petite application macOS</strong></a></p><p>Guide permettant d'obtenir un cluster composé d'un master, de plusieurs workers contrôlés par une application macOS menubar.</p></li><li><p><a href=https://github.com/xavierbaude/VMware-coreos-multi-nodes-Kubernetes><strong>Multi-node cluster using cloud-config, CoreOS and VMware ESXi</strong></a></p><p>Configure un cluster composé d'un master et de plusieurs workers sur VMWare ESXi</p></li><li><p><a href=https://github.com/johscheuer/theforeman-coreos-kubernetes><strong>Cluster Unique/Multi noeuds en utilisant cloud-config, CoreOS et Foreman</strong></a></p><p>Configure un cluster composé d'un ou de plusieurs noeuds avec <a href=https://theforeman.org>Foreman</a>.</p></li></ul><h2 id=niveau-de-support>Niveau de support</h2><table><thead><tr><th>IaaS Provider</th><th>Config. Mgmt</th><th>OS</th><th>Networking</th><th>Docs</th><th>Conforms</th><th>Support Level</th></tr></thead><tbody><tr><td>GCE</td><td>CoreOS</td><td>CoreOS</td><td>flannel</td><td><a href=/docs/getting-started-guides/coreos>docs</a></td><td></td><td>Community (<a href=https://github.com/pires>@pires</a>)</td></tr><tr><td>Vagrant</td><td>CoreOS</td><td>CoreOS</td><td>flannel</td><td><a href=/docs/getting-started-guides/coreos>docs</a></td><td></td><td>Community (<a href=https://github.com/pires>@pires</a>, <a href=https://github.com/AntonioMeireles>@AntonioMeireles</a>)</td></tr></tbody></table><p>Pour le niveau de support de toutes les solutions se référer au <a href=/docs/getting-started-guides/#table-of-solutions>Tableau des solutions</a>.</p></div><div class=td-content style=page-break-before:always><h1 id=pg-b5fede6c0a528c69bb32a7bf68641aa1>2.4.2 - Installer Kubernetes avec Kubespray (on-premises et fournisseurs de cloud)</h1><div class=lead>Installation de Kubernetes avec Kubespray</div><p>Cette documentation permet d'installer rapidement un cluster Kubernetes hébergé sur GCE, Azure, Openstack, AWS, vSphere, Oracle Cloud Infrastructure (expérimental) ou sur des serveurs physiques (bare metal) grâce à <a href=https://github.com/kubernetes-incubator/kubespray>Kubespray</a>.</p><p>Kubespray se base sur des outils de provisioning, des <a href=https://github.com/kubernetes-incubator/kubespray/blob/master/docs/ansible.md>paramètres</a> et playbooks <a href=https://docs.ansible.com/>Ansible</a> ainsi que sur des connaissances spécifiques à Kubernetes et l'installation de systèmes d'exploitation afin de fournir:</p><ul><li>Un cluster en haute disponibilité</li><li>des composants modulables</li><li>Le support des principales distributions Linux:<ul><li>Container Linux de CoreOS</li><li>Debian Jessie, Stretch, Wheezy</li><li>Ubuntu 16.04, 18.04, 20.04, 22.04</li><li>CentOS/RHEL 7, 8</li><li>Fedora/CentOS Atomic</li><li>openSUSE Leap 42.3/Tumbleweed</li></ul></li><li>des tests d'intégration continue</li></ul><p>Afin de choisir l'outil le mieux adapté à votre besoin, veuillez lire <a href=https://github.com/kubernetes-incubator/kubespray/blob/master/docs/comparisons.md>cette comparaison</a> avec <a href=/docs/admin/kubeadm/>kubeadm</a> et <a href=../kops>kops</a>.</p><h2 id=créer-un-cluster>Créer un cluster</h2><h3 id=1-5-prérequis>(1/5) Prérequis</h3><p>Les serveurs doivent être installés en s'assurant des éléments suivants:</p><ul><li><strong>Ansible v2.11 (ou version plus récente) et python-netaddr installés sur la machine qui exécutera les commandes Ansible</strong></li><li><strong>Jinja 2.11 (ou version plus récente) est nécessaire pour exécuter les playbooks Ansible</strong></li><li>Les serveurs cibles doivent avoir <strong>accès à Internet</strong> afin de télécharger les images Docker. Autrement, une configuration supplémentaire est nécessaire, (se référer à <a href=https://github.com/kubernetes-sigs/kubespray/blob/master/docs/downloads.md#offline-environment>Offline Environment</a>)</li><li>Les serveurs cibles doivent être configurés afin d'autoriser le transfert IPv4 (<strong>IPv4 forwarding</strong>)</li><li><strong>Votre clé ssh doit être copiée</strong> sur tous les serveurs faisant partie de votre inventaire Ansible.</li><li>La configuration du <strong>pare-feu n'est pas gérée</strong>. Vous devrez vous en charger en utilisant votre méthode habituelle. Afin d'éviter tout problème pendant l'installation nous vous conseillons de le désacttiver.</li><li>Si Kubespray est exécuté avec un utilisateur autre que "root", une méthode d'autorisation appropriée devra être configurée sur les serveurs cibles (exemple: sudo). Il faudra aussi utiliser le paramètre <code>ansible_become</code> ou ajouter <code>--become</code> ou <code>b</code> à la ligne de commande.</li></ul><p>Afin de vous aider à préparer votre de votre environnement, Kubespray fournit les outils suivants:</p><ul><li>Scripts <a href=https://www.terraform.io/>Terraform</a> pour les fournisseurs de cloud suivants:<ul><li><a href=https://github.com/kubernetes-incubator/kubespray/tree/master/contrib/terraform/aws>AWS</a></li><li><a href=https://github.com/kubernetes-incubator/kubespray/tree/master/contrib/terraform/openstack>OpenStack</a></li></ul></li></ul><h3 id=2-5-construire-un-fichier-d-inventaire-ansible>(2/5) Construire un fichier d'inventaire Ansible</h3><p>Lorsque vos serveurs sont disponibles, créez un fichier d'inventaire Ansible (<a href=https://docs.ansible.com/ansible/latest/network/getting_started/first_inventory.html>inventory</a>).
Vous pouvez le créer manuellement ou en utilisant un script d'inventaire dynamique. Pour plus d'informations se référer à <a href=https://github.com/kubernetes-incubator/kubespray/blob/master/docs/getting-started.md#building-your-own-inventory>Building your own inventory</a>.</p><h3 id=3-5-préparation-au-déploiement-de-votre-cluster>(3/5) Préparation au déploiement de votre cluster</h3><p>Kubespray permet de personnaliser de nombreux éléments:</p><ul><li>Choix du mode: kubeadm ou non-kubeadm</li><li>Plugins CNI (réseau)</li><li>Configuration du DNS</li><li>Choix du control plane: natif/binaire ou dans un conteneur docker/rkt</li><li>Version de chaque composant</li><li>"route reflectors" Calico</li><li>Moteur de conteneur<ul><li>docker</li><li>rkt</li><li>cri-o</li></ul></li><li>Méthode de génération des certificats (<strong>Vault n'étant plus maintenu</strong>)</li></ul><p>Ces paramètres Kubespray peuvent être définis dans un fichier de <a href=http://docs.ansible.com/ansible/playbooks_variables.html>variables</a>.
Si vous venez juste de commencer à utiliser Kubespray nous vous recommandons d'utiliser les paramètres par défaut pour déployer votre cluster et découvrir Kubernetes</p><h3 id=4-5-déployer-un-cluster>(4/5) Déployer un Cluster</h3><p>Vous pouvez ensuite lancer le déploiement de votre cluster:</p><p>Déploiement du cluster en utilisant l'outil en ligne de commande <a href=https://github.com/kubernetes-incubator/kubespray/blob/master/docs/getting-started.md#starting-custom-deployment>ansible-playbook</a>.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>ansible-playbook -i your/inventory/hosts.ini cluster.yml -b -v <span style=color:#b62;font-weight:700>\
</span></span></span><span style=display:flex><span><span style=color:#b62;font-weight:700></span>  --private-key<span style=color:#666>=</span>~/.ssh/private_key
</span></span></code></pre></div><p>Pour des déploiements plus importants (>100 noeuds) quelques <a href=https://github.com/kubernetes-incubator/kubespray/blob/master/docs/large-deployments.md>ajustements</a> peuvent être nécessaires afin d'obtenir de meilleurs résultats.</p><h3 id=5-5-vérifier-le-déploiement>(5/5) Vérifier le déploiement</h3><p>Kubespray fournit le moyen de vérifier la connectivité inter-pods ainsi que la résolution DNS grâce à <a href=https://github.com/kubernetes-incubator/kubespray/blob/master/docs/netcheck.md>Netchecker</a>.
Les pods netchecker-agents s'assurent que la résolution DNS (services Kubernetes) ainsi que le ping entre les pods fonctionnent correctement.
Ces pods reproduisent un comportement similaire à celui des autres applications et offrent un indicateur de santé du cluster.</p><h2 id=opérations-sur-le-cluster>Opérations sur le cluster</h2><p>Kubespray fournit des playbooks supplémentaires qui permettent de gérer votre cluster: <em>scale</em> et <em>upgrade</em>.</p><h3 id=mise-à-l-échelle-du-cluster>Mise à l'échelle du cluster</h3><p>Vous pouvez ajouter des noeuds à votre cluster en exécutant le playbook <code>scale</code>. Pour plus d'informations se référer à <a href=https://github.com/kubernetes-incubator/kubespray/blob/master/docs/getting-started.md#adding-nodes>Adding nodes</a>.
vous pouvez retirer des noeuds de votre cluster en exécutant le playbook <code>remove-node</code>. Se référer à <a href=https://github.com/kubernetes-incubator/kubespray/blob/master/docs/getting-started.md#remove-nodes>Remove nodes</a>.</p><h3 id=mise-à-jour-du-cluster>Mise à jour du cluster</h3><p>Vous pouvez mettre à jour votre cluster en exécutant le playbook <code>upgrade-cluster</code>. Pour plus d'informations se référer à <a href=https://github.com/kubernetes-incubator/kubespray/blob/master/docs/upgrades.md>Upgrades</a>.</p><h2 id=nettoyage>Nettoyage</h2><p>Vous pouvez réinitialiser vos noeuds et supprimer tous les composants installés par Kubespray en utilisant le playbook <a href=https://github.com/kubernetes-incubator/kubespray/blob/master/reset.yml>reset</a>.</p><div class="alert alert-warning caution callout" role=alert><strong>Avertissement:</strong> Quand vous utilisez le playbook <code>reset</code>, assurez-vous de ne pas cibler accidentellement un cluster de production !</div><h2 id=retours>Retours</h2><ul><li>Channel Slack: <a href=https://kubernetes.slack.com/messages/kubespray/>#kubespray</a></li><li><a href=https://github.com/kubernetes-incubator/kubespray/issues>Issues GitHub</a></li></ul><h2 id=a-suivre>A suivre</h2><p>Jetez un oeil aux travaux prévus sur Kubespray: <a href=https://github.com/kubernetes-incubator/kubespray/blob/master/docs/roadmap.md>roadmap</a>.</p></div><div class=td-content style=page-break-before:always><h1 id=pg-750e22dae37d8ac366b101811e01cc34>2.4.3 - Installer Kubernetes sur AWS avec kops</h1><div class=lead>Installation Kubernetes avec kops sur AWS</div><p>Cette documentation pour un démarrage rapide montre comment facilement installer un cluster Kubernetes sur AWS.
L'outil utilisé est <a href=https://github.com/kubernetes/kops><code>kops</code></a>.</p><p>kops est un système de provisionnement dont les principes sont:</p><ul><li>Une installation totalement automatisée</li><li>Utilisation du DNS pour identifier les clusters</li><li>Auto-guérison: tous les composants tournent dans des groupe de mise à l'échelle automatique (auto-scaling)</li><li>Support de plusieurs systèmes d'exploitation (Debian, Ubuntu 16.04 supportés, Centos & RHEL, Amazon Linux et CoreOS) - se référer à <a href=https://github.com/kubernetes/kops/blob/master/docs/images.md>images.md</a></li><li>Haute disponibilité - se référer à <a href=https://github.com/kubernetes/kops/blob/master/docs/high_availability.md>high_availability.md</a></li><li>Peut provisionner directement, ou générer des manifests terraform - se référer à <a href=https://github.com/kubernetes/kops/blob/master/docs/terraform.md>terraform.md</a></li></ul><p>Si ces principes ne vous conviennent pas, vous préférerez probablement construire votre propre cluster selon votre convenance grâce à <a href=/docs/admin/kubeadm/>kubeadm</a>.</p><h2 id=créer-un-cluster>Créer un cluster</h2><h3 id=1-5-installer-kops>(1/5) Installer kops</h3><h4 id=pré-requis>Pré-requis</h4><p>Il est nécessaire d'avoir <a href=/docs/tasks/tools/install-kubectl/>kubectl</a> d'installé pour que kops puisse fonctionner.</p><h4 id=installation>Installation</h4><p>Télécharger kops à partir de la <a href=https://github.com/kubernetes/kops/releases>page de releases</a> (Il est aussi facile à construire à partir des sources):</p><p>Sur macOS:</p><p>Téléchargez la dernière version avec la commande:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>curl -LO https://github.com/kubernetes/kops/releases/download/<span style=color:#a2f;font-weight:700>$(</span>curl -s https://api.github.com/repos/kubernetes/kops/releases/latest | grep tag_name | cut -d <span style=color:#b44>&#39;&#34;&#39;</span> -f 4<span style=color:#a2f;font-weight:700>)</span>/kops-darwin-amd64
</span></span></code></pre></div><p>Pour télécharger une version spécifique, remplacez le</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span><span style=color:#a2f;font-weight:700>$(</span>curl -s https://api.github.com/repos/kubernetes/kops/releases/latest | grep tag_name | cut -d <span style=color:#b44>&#39;&#34;&#39;</span> -f 4<span style=color:#a2f;font-weight:700>)</span>
</span></span></code></pre></div><p>partie de la commande avec la version spécifique.</p><p>Par exemple, pour télécharger la version 1.15.0 de kops, tapez:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>curl -LO  https://github.com/kubernetes/kops/releases/download/1.15.0/kops-darwin-amd64
</span></span></code></pre></div><p>Rendre le binaire exécutable kops.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>chmod +x kops-darwin-amd64
</span></span></code></pre></div><p>Déplacez le fichier binaire kops dans votre chemin.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>sudo mv kops-darwin-amd64 /usr/local/bin/kops
</span></span></code></pre></div><p>Vous pouvez également installer kops en utilisant [Homebrew] (<a href=https://brew.sh/)>https://brew.sh/)</a>.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>brew update <span style=color:#666>&amp;&amp;</span> brew install kops
</span></span></code></pre></div><p>Sur Linux:</p><p>Téléchargez la dernière version avec la commande:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>curl -LO https://github.com/kubernetes/kops/releases/download/<span style=color:#a2f;font-weight:700>$(</span>curl -s https://api.github.com/repos/kubernetes/kops/releases/latest | grep tag_name | cut -d <span style=color:#b44>&#39;&#34;&#39;</span> -f 4<span style=color:#a2f;font-weight:700>)</span>/kops-linux-amd64
</span></span></code></pre></div><p>Pour télécharger une version spécifique, remplacez le</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span><span style=color:#a2f;font-weight:700>$(</span>curl -s https://api.github.com/repos/kubernetes/kops/releases/latest | grep tag_name | cut -d <span style=color:#b44>&#39;&#34;&#39;</span> -f 4<span style=color:#a2f;font-weight:700>)</span>
</span></span></code></pre></div><p>partie de la commande avec la version spécifique.</p><p>Par exemple, pour télécharger la version 1.15.0 de kops, tapez:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>curl -LO  https://github.com/kubernetes/kops/releases/download/1.15.0/kops-linux-amd64
</span></span></code></pre></div><p>Rendre le binaire exécutable kops</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>chmod +x kops-linux-amd64
</span></span></code></pre></div><p>Déplacez le fichier binaire kops dans votre chemin.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>sudo mv kops-linux-amd64 /usr/local/bin/kops
</span></span></code></pre></div><p>Vous pouvez également installer kops en utilisant [Homebrew] (<a href=https://docs.brew.sh/Homebrew-on-Linux)>https://docs.brew.sh/Homebrew-on-Linux)</a>.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>brew update <span style=color:#666>&amp;&amp;</span> brew install kops
</span></span></code></pre></div><h3 id=2-5-créer-un-domaine-route53-pour-votre-cluster>(2/5) Créer un domaine route53 pour votre cluster</h3><p>kops utilise le DNS pour la découverte, que ce soit à l'intérieur du cluster ou pour pouvoir communiquer avec l'API de kubernetes à partir des clients.</p><p>Pour kops le nom du cluster doit impérativement être un nom de domaine valide.
De cette façon vous ne confondrez pas vos cluster et vous pourrez les partager avec vos collègues sans ambiguïté. Par ailleurs vous pourrez vous y connecter sans avoir à vous rappeler une adresse IP.</p><p>Vous pouvez, et vous devriez certainement, utiliser des sous-domaines afin de séparer vos clusters.
Dans notre exemple nous utiliserons <code>useast1.dev.example.com</code>. Le point d'accès au serveur API sera donc <code>api.useast1.dev.example.com</code>.</p><p>Une zone hébergée Route53 peut servir les sous-domaines. Votre zone hébergée pourrait être <code>useast1.dev.example.com</code>,
mais aussi <code>dev.example.com</code> ou même <code>example.com</code>. kops fonctionne avec n'importe lequel d'entre eux, le choix dépend de vos contraintes d'organisation (ex: Vous êtes autorisés à créer des enregistrements dns dans <code>dev.example.com</code> mais pas dans <code>example.com</code>)</p><p>Supposons que vous utilisiez <code>dev.example.com</code> comme zone hébergée. Vous créeriez cette zone hébergée en utilisant la <a href=http://docs.aws.amazon.com/Route53/latest/DeveloperGuide/CreatingNewSubdomain.html>méthode normal</a>, ou avec une ligne de commande telle que <code>aws route53 create-hosted-zone --name dev.example.com --caller-reference 1</code>.</p><p>Vous devrez ensuite configurer vos enregistrements NS dans le domaine parent afin que vous puissiez résoudre dans ce domaine.
Vous créeriez donc des enregistrements NS dans le domaine <code>example.com</code> pour <code>dev</code>.
S'il s'agit d'un nom de domaine racine, vous devrez configurer les enregistrements NS chez votre hébergeur de nom de domaine (là où vous avez acheté votre nom de domaine <code>example.com</code>).</p><p>Cette étape est délicate, soyez vigilants (c’est la première cause de problèmes !). Vous pouvez vérifier que
votre cluster est configuré correctement avec l'outil dig, en exécutant:</p><p><code>dig NS dev.example.com</code></p><p>Vous devriez voir les 4 enregistrements NS attribués à votre zone hébergée sur Route53.</p><h3 id=3-5-créez-un-conteneur-bucket-s3-pour-stocker-l-état-de-vos-clusters>(3/5) Créez un conteneur (bucket) S3 pour stocker l'état de vos clusters.</h3><p>kops vous permet de gérer vos clusters même lorsque ceux-ci sont déjà installés. Pour ce faire, il est nécessaire de conserver une trace des clusters que vous avez créé, avec leur configuration, les clés qu’ils utilisent, etc. Ces informations sont stockées dans un bucket S3. Les autorisations S3 sont utilisées pour contrôler l'accès au bucket.</p><p>Plusieurs clusters peuvent utiliser le même bucket S3 et vous pouvez aussi le partager avec vos collègues qui
administrer les mêmes clusters - c'est beaucoup plus facile que de faire circuler des fichiers kubecfg.
Cependant quiconque ayant accès au bucket S3 aura un accès complet (permissions élevées) à tous vos clusters. Vous souhaiterez donc limiter l'accès à l'équipe opérationnelle.</p><p>Plus généralement, vous auriez un bucket S3 pour chaque équipe ops (et le nom correspondrait souvent
au nom de la zone hébergée ci-dessus!)</p><p>Dans notre exemple, nous avons choisi <code>dev.example.com</code> comme zone hébergée. Nous allons donc choisir <code>clusters.dev.example.com</code> comm le nom du bucket S3.</p><ul><li><p>Exportez <code>AWS_PROFILE</code> (si vous devez sélectionner un profil pour que l'outil en ligne de commande d'AWS fonctionne).</p></li><li><p>Créez le compartiment S3 en utilisant <code>aws s3 mb s3://clusters.dev.example.com</code></p></li><li><p>Vous pouvez <code>export KOPS_STATE_STORE=s3://clusters.dev.example.com</code> afin que kops utilise cet emplacement par défaut.
  Nous vous suggérons de le mettre dans votre profil bash ou similaire.</p></li></ul><h3 id=4-5-construisez-votre-configuration-de-cluster>(4/5) Construisez votre configuration de cluster</h3><p>Exécutez "kops create cluster" pour créer votre configuration de cluster:</p><p><code>kops create cluster --zones=us-east-1c useast1.dev.example.com</code></p><p>kops créera la configuration pour votre cluster. Notez que cela génère uniquement la configuration, la création des ressources cloud se fait à l'étape suivante avec <code>kops update cluster</code>. Cela vous permettra d'analyser la configuration ou de la modifier avant de l'appliquer.</p><p>Voici quelques commandes qui vous permettent de visualiser ou éditer:</p><ul><li>Listez vos clusters avec: <code>kops get cluster</code></li><li>Éditez ce cluster avec: <code>kops edit cluster useast1.dev.example.com</code></li><li>Modifiez votre groupe d'instances de nœuds: <code>kops edit ig --name=useast1.dev.example.com nodes</code></li><li>Éditez votre groupe d'instances maître (master): <code>kops edit ig --name=useast1.dev.example.com master-us-east-1c</code></li></ul><p>Si vous utilisez kops pour la première fois, prenez quelques minutes pour les essayer! Un groupe d'instances est un
ensemble d'instances, qui seront enregistrées en tant que noeuds kubernetes. Sur AWS, cela est implémenté via des groupes de mise à l'échelle automatique (auto-scaling).
Vous pouvez avoir plusieurs groupes d'instances, par exemple si vous voulez des nœuds combinant des instances ponctuelles (spot instances) et à la demande, ou éventuellement des instances GPU et non-GPU.</p><h3 id=5-5-créer-le-cluster-dans-aws>(5/5) Créer le cluster dans AWS</h3><p>Exécutez "kops update cluster" pour créer votre cluster dans AWS :</p><p><code>kops update cluster useast1.dev.example.com --yes</code></p><p>Cela prend quelques secondes à s'exécuter, et ensuite votre cluster prendra probablement quelques minutes pour être réellement opérationnel.
<code>kops update cluster</code> sera l'outil que vous utiliserez à chaque fois que vous modifierez la configuration de votre cluster.
Il applique les modifications que vous avez apportées à la configuration sur votre cluster (reconfiguration d'AWS ou de kubernetes au besoin).</p><p>Par exemple, après un <code>kops edit ig nodes</code>, puis un <code>kops update cluster --yes</code> pour appliquer votre configuration, parfois, vous devrez également exécuter un <code>kops rolling-update cluster</code> pour déployer la configuration immédiatement.</p><p>Sans l'argument <code>--yes</code>, <code>kops update cluster</code> vous montrera un aperçu de ce qu’il va faire. C'est pratique
pour les clusters de production !</p><h3 id=explorer-d-autres-composants-additionnels-add-ons>Explorer d'autres composants additionnels (add-ons)</h3><p>Reportez-vous à la [liste des add-ons] (/docs/concepts/cluster-administration/addons/) pour explorer d'autres add-ons, y compris des outils de journalisation, de surveillance, de stratégie réseau, de visualisation ou de contrôle de votre cluster Kubernetes.</p><h2 id=nettoyer>Nettoyer</h2><ul><li>Pour supprimer votre cluster: <code>kops delete cluster useast1.dev.example.com --yes</code></li></ul><h2 id=retour-d-information>Retour d'information</h2><ul><li>Channel Slack: [#kops-users] (<a href=https://kubernetes.slack.com/messages/kops-users/>https://kubernetes.slack.com/messages/kops-users/</a>)</li><li>[Problèmes GitHub] (<a href=https://github.com/kubernetes/kops/issues>https://github.com/kubernetes/kops/issues</a>)</li></ul><h2 id=a-suivre>A suivre</h2><ul><li>En apprendre davantages sur les <a href=/docs/concepts/>concepts</a> Kubernetes et <a href=/docs/user-guide/kubectl-overview/><code>kubectl</code></a>.</li><li>En savoir plus sur les <a href=https://github.com/kubernetes/kops>utilisations avancées</a> de <code>kops</code>.</li><li>Pour les bonnes pratiques et les options de configuration avancées de <code>kops</code> se référer à la <a href=https://github.com/kubernetes/kops>documentation</a></li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-dd948255948d6b59b32c471abcb62997>3 - Concepts</h1><div class=lead>Concepts Kubernetes</div><p>La section Concepts vous aide à mieux comprendre les composants du système Kubernetes et les abstractions que Kubernetes utilise pour représenter votre cluster.
Elle vous aide également à mieux comprendre le fonctionnement de Kubernetes en général.</p><h2 id=vue-d-ensemble>Vue d'ensemble</h2><p>Pour utiliser Kubernetes, vous utilisez <em>les objets de l'API Kubernetes</em> pour décrire <em>l'état souhaité</em> de votre cluster: quelles applications ou autres processus que vous souhaitez exécuter, quelles images de conteneur elles utilisent, le nombre de réplicas, les ressources réseau et disque que vous mettez à disposition, et plus encore.
Vous définissez l'état souhaité en créant des objets à l'aide de l'API Kubernetes, généralement via l'interface en ligne de commande, <code>kubectl</code>.
Vous pouvez également utiliser l'API Kubernetes directement pour interagir avec le cluster et définir ou modifier l'état souhaité.</p><p>Une fois que vous avez défini l'état souhaité, le <em>plan de contrôle Kubernetes</em> (control plane en anglais) permet de faire en sorte que l'état actuel du cluster corresponde à l'état souhaité.
Pour ce faire, Kubernetes effectue automatiquement diverses tâches, telles que le démarrage ou le redémarrage de conteneurs, la mise à jour du nombre de réplicas d'une application donnée, etc.
Le control plane Kubernetes comprend un ensemble de processus en cours d'exécution sur votre cluster:</p><ul><li>Le <strong>maître Kubernetes</strong> (Kubernetes master en anglais) qui est un ensemble de trois processus qui s'exécutent sur un seul nœud de votre cluster, désigné comme nœud maître (master node en anglais). Ces processus sont: <a href=/docs/admin/kube-apiserver/>kube-apiserver</a>, <a href=/docs/admin/kube-controller-manager/>kube-controller-manager</a> et <a href=/docs/admin/kube-scheduler/>kube-scheduler</a>.</li><li>Chaque nœud non maître de votre cluster exécute deux processus:<ul><li><strong><a href=/docs/admin/kubelet/>kubelet</a></strong>, qui communique avec le Kubernetes master.</li><li><strong><a href=/docs/admin/kube-proxy/>kube-proxy</a></strong>, un proxy réseau reflétant les services réseau Kubernetes sur chaque nœud.</li></ul></li></ul><h2 id=objets-kubernetes>Objets Kubernetes</h2><p>Kubernetes contient un certain nombre d'abstractions représentant l'état de votre système: applications et processus conteneurisés déployés, leurs ressources réseau et disque associées, ainsi que d'autres informations sur les activités de votre cluster.
Ces abstractions sont représentées par des objets de l'API Kubernetes; consultez <a href=/docs/concepts/abstractions/overview/>Vue d'ensemble des objets Kubernetes</a> pour plus d'informations.</p><p>Les objets de base de Kubernetes incluent:</p><ul><li><a href=/docs/concepts/workloads/pods/pod-overview/>Pod</a></li><li><a href=/docs/concepts/services-networking/service/>Service</a></li><li><a href=/docs/concepts/storage/volumes/>Volume</a></li><li><a href=/docs/concepts/overview/working-with-objects/namespaces/>Namespace</a></li></ul><p>En outre, Kubernetes contient un certain nombre d'abstractions de niveau supérieur appelées Contrôleurs.
Les contrôleurs s'appuient sur les objets de base et fournissent des fonctionnalités supplémentaires.</p><p>Voici quelques exemples:</p><ul><li><a href=/docs/concepts/workloads/controllers/replicaset/>ReplicaSet</a></li><li><a href=/docs/concepts/workloads/controllers/deployment/>Deployment</a></li><li><a href=/docs/concepts/workloads/controllers/statefulset/>StatefulSet</a></li><li><a href=/docs/concepts/workloads/controllers/daemonset/>DaemonSet</a></li><li><a href=/docs/concepts/workloads/controllers/jobs-run-to-completion/>Job</a></li></ul><h2 id=kubernetes-control-plane>Kubernetes control plane</h2><p>Les différentes parties du control plane Kubernetes, telles que les processus Kubernetes master et kubelet, déterminent la manière dont Kubernetes communique avec votre cluster.
Le control plane conserve un enregistrement de tous les objets Kubernetes du système et exécute des boucles de contrôle continues pour gérer l'état de ces objets.
À tout moment, les boucles de contrôle du control plane répondent aux modifications du cluster et permettent de faire en sorte que l'état réel de tous les objets du système corresponde à l'état souhaité que vous avez fourni.</p><p>Par exemple, lorsque vous utilisez l'API Kubernetes pour créer un objet Deployment, vous fournissez un nouvel état souhaité pour le système.
Le control plane Kubernetes enregistre la création de cet objet et exécute vos instructions en lançant les applications requises et en les planifiant vers des nœuds de cluster, afin que l'état actuel du cluster corresponde à l'état souhaité.</p><h3 id=kubernetes-master>Kubernetes master</h3><p>Le Kubernetes master est responsable du maintien de l'état souhaité pour votre cluster.
Lorsque vous interagissez avec Kubernetes, par exemple en utilisant l'interface en ligne de commande <code>kubectl</code>, vous communiquez avec le master Kubernetes de votre cluster.</p><blockquote><p>Le "master" fait référence à un ensemble de processus gérant l'état du cluster.
En règle générale, tous les processus sont exécutés sur un seul nœud du cluster.
Ce nœud est également appelé master.
Le master peut également être répliqué pour la disponibilité et la redondance.</p></blockquote><h3 id=noeuds-kubernetes>Noeuds Kubernetes</h3><p>Les nœuds d’un cluster sont les machines (serveurs physiques, machines virtuelles, etc.) qui exécutent vos applications et vos workflows.
Le master node Kubernetes contrôle chaque noeud; vous interagirez rarement directement avec les nœuds.</p><h4 id=metadonnées-des-objets-kubernetes>Metadonnées des objets Kubernetes</h4><ul><li><a href=/docs/concepts/overview/working-with-objects/annotations/>Annotations</a></li></ul><h2 id=a-suivre>A suivre</h2><p>Si vous souhaitez écrire une page de concept, consultez
<a href=/docs/home/contribute/page-templates/>Utilisation de modèles de page</a>
pour plus d'informations sur le type de page pour la documentation d'un concept.</p></div><div class=td-content style=page-break-before:always><h1 id=pg-0554ac387412eaf4e6e89b2f847dacde>3.1 - Vue d'ensemble</h1><div class=lead>Vue d'ensemble Kubernetes</div></div><div class=td-content><h1 id=pg-45bdca6129cf540121623e903c18ba46>3.1.1 - Qu'est-ce-que Kubernetes ?</h1><div class=lead>Description de Kubernetes</div><p>Cette page est une vue d'ensemble de Kubernetes.</p><p>Kubernetes est une plate-forme open-source extensible et portable pour la gestion de charges de travail (workloads) et de services conteneurisés.
Elle favorise à la fois l'écriture de configuration déclarative (declarative configuration) et l'automatisation.
C'est un large écosystème en rapide expansion.
Les services, le support et les outils Kubernetes sont largement disponibles.</p><p>Google a rendu open-source le projet Kubernetes en 2014.
Le développement de Kubernetes est basé sur une <a href=https://research.google.com/pubs/pub43438.html>décennie et demie d’expérience de Google avec la gestion de la charge et de la mise à l'échelle (scale) en production</a>, associée aux meilleures idées et pratiques de la communauté.</p><h2 id=pourquoi-ai-je-besoin-de-kubernetes-et-que-peut-il-faire>Pourquoi ai-je besoin de Kubernetes et que peut-il faire ?</h2><p>Kubernetes a un certain nombre de fonctionnalités. Il peut être considéré comme:</p><ul><li>une plate-forme de conteneurs</li><li>une plate-forme de microservices</li><li>une plate-forme cloud portable
et beaucoup plus.</li></ul><p>Kubernetes fournit un environnement de gestion <strong>focalisé sur le conteneur</strong> (container-centric).
Il orchestre les ressources machines (computing), la mise en réseau et l’infrastructure de stockage sur les workloads des utilisateurs.
Cela permet de se rapprocher de la simplicité des Platform as a Service (PaaS) avec la flexibilité des solutions d'Infrastructure as a Service (IaaS), tout en gardant de la portabilité entre les différents fournisseurs d'infrastructures (providers).</p><h2 id=comment-kubernetes-est-il-une-plate-forme>Comment Kubernetes est-il une plate-forme ?</h2><p>Même si Kubernetes fournit de nombreuses fonctionnalités, il existe toujours de nouveaux scénarios qui bénéficieraient de fonctionnalités complémentaires.
Ces workflows spécifiques à une application permettent d'accélérer la vitesse de développement.
Si l'orchestration fournie de base est acceptable pour commencer, il est souvent nécessaire d'avoir une automatisation robuste lorsque l'on doit la faire évoluer.
C'est pourquoi Kubernetes a également été conçu pour servir de plate-forme et favoriser la construction d’un écosystème de composants et d’outils facilitant le déploiement, la mise à l’échelle et la gestion des applications.</p><p><a href=/docs/concepts/overview/working-with-objects/labels/>Les Labels</a> permettent aux utilisateurs d'organiser leurs ressources comme ils/elles le souhaitent.
<a href=/docs/concepts/overview/working-with-objects/annotations/>Les Annotations</a> autorisent les utilisateurs à définir des informations personnalisées sur les ressources pour faciliter leurs workflows et fournissent un moyen simple aux outils de gérer la vérification d'un état (checkpoint state).</p><p>De plus, le <a href=/docs/concepts/overview/components/>plan de contrôle Kubernetes (control
plane)</a> est construit sur les mêmes <a href=/docs/reference/using-api/api-overview/>APIs</a> que celles accessibles aux développeurs et utilisateurs.
Les utilisateurs peuvent écrire leurs propres contrôleurs (controllers), tels que les <a href=https://github.com/kubernetes/community/blob/master/contributors/devel/scheduler.md>ordonnanceurs (schedulers)</a>,
avec <a href=/docs/concepts/api-extension/custom-resources/>leurs propres APIs</a> qui peuvent être utilisés par un <a href=/docs/user-guide/kubectl-overview/>outil en ligne de commande</a>.</p><p>Ce choix de <a href=https://git.k8s.io/community/contributors/design-proposals/architecture/architecture.md>conception</a> a permis de construire un ensemble d'autres systèmes par dessus Kubernetes.</p><h2 id=ce-que-kubernetes-n-est-pas>Ce que Kubernetes n'est pas</h2><p>Kubernetes n’est pas une solution PaaS (Platform as a Service).
Kubernetes opérant au niveau des conteneurs plutôt qu'au niveau du matériel, il fournit une partie des fonctionnalités des offres PaaS, telles que le déploiement, la mise à l'échelle, l'équilibrage de charge (load balancing), la journalisation (logging) et la surveillance (monitoring).
Cependant, Kubernetes n'est pas monolithique.
Ces implémentations par défaut sont optionnelles et interchangeables. Kubernetes fournit les bases permettant de construire des plates-formes orientées développeurs, en laissant la possibilité à l'utilisateur de faire ses propres choix.</p><p>Kubernetes:</p><ul><li>Ne limite pas les types d'applications supportées. Kubernetes prend en charge des workloads extrêmement diverses, dont des applications stateless, stateful ou orientées traitement de données (data-processing).
Si l'application peut fonctionner dans un conteneur, elle devrait fonctionner correctement sur Kubernetes.</li><li>Ne déploie pas de code source et ne build pas d'application non plus. Les workflows d'Intégration Continue, de Livraison Continue et de Déploiement Continu (CI/CD) sont réalisés en fonction de la culture d'entreprise, des préférences ou des pré-requis techniques.</li><li>Ne fournit pas nativement de services au niveau applicatif tels que des middlewares (e.g., message buses), des frameworks de traitement de données (par exemple, Spark), des bases de données (e.g., mysql), caches, ou systèmes de stockage clusterisés (e.g., Ceph).
Ces composants peuvent être lancés dans Kubernetes et/ou être accessibles à des applications tournant dans Kubernetes via des mécaniques d'intermédiation tel que Open Service Broker.</li><li>N'impose pas de solutions de logging, monitoring, ou alerting.
Kubernetes fournit quelques intégrations primaires et des mécanismes de collecte et export de métriques.</li><li>Ne fournit ou n'impose un langague/système de configuration (e.g., <a href=https://github.com/google/jsonnet>jsonnet</a>).
Il fournit une API déclarative qui peut être ciblée par n'importe quelle forme de spécifications déclaratives.</li><li>Ne fournit ou n'adopte aucune mécanique de configuration des machines, de maintenance, de gestion ou de contrôle de la santé des systèmes.</li></ul><p>De plus, Kubernetes n'est pas vraiment un <em>système d'orchestration</em>. En réalité, il élimine le besoin d'orchestration.
Techniquement, l'<em>orchestration</em> se définit par l'exécution d'un workflow spécifié : premièrement faire A, puis B, puis C.
Kubernetes quant à lui est composé d'un ensemble de processus de contrôle qui pilotent l'état courant vers l'état désiré.
Peu importe comment on arrive du point A au point C.
Un contrôle centralisé n'est pas non plus requis.
Cela aboutit à un système plus simple à utiliser et plus puissant, robuste, résiliant et extensible.</p><h2 id=pourquoi-les-conteneurs>Pourquoi les conteneurs ?</h2><p>Vous cherchez des raisons d'utiliser des conteneurs ?</p><p><img src=/images/docs/why_containers.svg alt="Pourquoi les conteneurs ?"></p><p>L'<em>ancienne façon (old way)</em> de déployer des applications consistait à installer les applications sur un hôte en utilisant les systèmes de gestions de paquets natifs.
Cela avait pour principale inconvénient de lier fortement les exécutables, la configuration, les librairies et le cycle de vie de chacun avec l'OS.
Il est bien entendu possible de construire une image de machine virtuelle (VM) immuable pour arriver à produire des publications (rollouts) ou retours arrières (rollbacks), mais les VMs sont lourdes et non-portables.</p><p>La <em>nouvelle façon (new way)</em> consiste à déployer des conteneurs basés sur une virtualisation au niveau du système d'opération (operation-system-level) plutôt que de la virtualisation hardware.
Ces conteneurs sont isolés les uns des autres et de l'hôte :
ils ont leurs propres systèmes de fichiers, ne peuvent voir que leurs propres processus et leur usage des ressources peut être contraint.
Ils sont aussi plus faciles à construire que des VMs, et vu qu'ils sont décorrélés de l'infrastructure sous-jacente et du système de fichiers de l'hôte, ils sont aussi portables entre les différents fournisseurs de Cloud et les OS.</p><p>Étant donné que les conteneurs sont petits et rapides, une application peut être packagée dans chaque image de conteneurs.
Cette relation application-image tout-en-un permet de bénéficier de tous les bénéfices des conteneurs. Avec les conteneurs, des images immuables de conteneurs peuvent être créées au moment du build/release plutôt qu'au déploiement, vu que chaque application ne dépend pas du reste de la stack applicative et n'est pas liée à l'environnement de production.
La génération d'images de conteneurs au moment du build permet d'obtenir un environnement constant qui peut être déployé tant en développement qu'en production. De la même manière, les conteneurs sont bien plus transparents que les VMs, ce qui facilite le monitoring et le management.
Cela est particulièrement vrai lorsque le cycle de vie des conteneurs est géré par l'infrastructure plutôt que caché par un gestionnaire de processus à l'intérieur du conteneur. Avec une application par conteneur, gérer ces conteneurs équivaut à gérer le déploiement de son application.</p><p>Résumé des bénéfices des conteneurs :</p><ul><li><strong>Création et déploiement agile d'applications</strong> :
Augmente la simplicité et l'efficacité de la création d'images par rapport à l'utilisation d'images de VM.</li><li><strong>Développement, intégration et déploiement Continus</strong>:
Fournit un processus pour constuire et déployer fréquemment et de façon fiable avec la capacité de faire des rollbacks rapides et simples (grâce à l'immuabilité de l'image).</li><li><strong>Séparation des besoins entre Dev et Ops</strong>:
Création d'images applicatives au moment du build plutôt qu'au déploiement, tout en séparant l'application de l'infrastructure.</li><li><strong>Observabilité</strong>
Informations venant non seulement du système d'exploitation sous-jacent mais aussi des signaux propres de l'application.</li><li><strong>Consistance entre les environnements de développement, tests et production</strong>:
Fonctionne de la même manière que ce soit sur un poste local que chez un fournisseur d'hébergement / dans le Cloud.</li><li><strong>Portabilité entre Cloud et distribution système</strong>:
Fonctionne sur Ubuntu, RHEL, CoreOS, on-prem, Google Kubernetes Engine, et n'importe où.</li><li><strong>Gestion centrée Application</strong>:
Bascule le niveau d'abstraction d'une virtualisation hardware liée à l'OS à une logique de ressources orientée application.</li><li><strong><a href=https://martinfowler.com/articles/microservices.html>Micro-services</a> faiblement couplés, distribués, élastiques</strong>:
Les applications sont séparées en petits morceaux indépendants et peuvent être déployées et gérées dynamiquement -- pas une stack monolithique dans une seule machine à tout faire.</li><li><strong>Isolation des ressources</strong>:
Performances de l'application prédictibles.</li><li><strong>Utilisation des ressources</strong>:
Haute efficacité et densité.</li></ul><h2 id=qu-est-ce-que-kubernetes-signifie-k8s>Qu'est-ce-que Kubernetes signifie ? K8s ?</h2><p>Le nom <strong>Kubernetes</strong> tire son origine du grec ancien, signifiant <em>capitaine</em> ou <em>pilote</em> et est la racine de <em>gouverneur</em> et <a href="http://www.etymonline.com/index.php?term=cybernetics">cybernetic</a>. <em>K8s</em> est l'abbréviation dérivée par le remplacement des 8 lettres "ubernete" par "8".</p><h2 id=a-suivre>A suivre</h2><ul><li>Prêt à <a href=/docs/setup/>commencer</a> ?</li><li>Pour plus de détails, voir la <a href=/docs/home/>documentation Kubernetes</a>.</li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-13b0f1dbe89228e3d76d2ac231e245f1>3.1.2 - Composants de Kubernetes</h1><p>Ce document résume les divers composants binaires requis pour livrer
un cluster Kubernetes fonctionnel.</p><h2 id=composants-master>Composants Master</h2><p>Les composants Master fournissent le plan de contrôle (control plane) du cluster.
Les composants Master prennent des décisions globales à propos du cluster (par exemple, la planification (scheduling)).
Ils détectent et répondent aux événements du cluster (par exemple, démarrer un nouveau <a class=glossary-tooltip title='Le plus petit et le plus simple des objets Kubernetes. Un Pod est un ensemble de conteneurs fonctionnant sur votre cluster.' data-toggle=tooltip data-placement=top href=/fr/docs/concepts/workloads/pods/pod-overview/ target=_blank aria-label=Pod>Pod</a> lorsque le champ <code>replicas</code> d'un déploiement n'est pas satisfait).</p><p>Les composants Master peuvent être exécutés sur n'importe quelle machine du cluster. Toutefois,
par soucis de simplicité, les scripts de mise en route démarrent typiquement tous les composants master sur la
même machine et n'exécutent pas de conteneurs utilisateur sur cette machine.
Voir <a href=/docs/admin/high-availability/>Construire des Clusters en Haute Disponibilité</a> pour une configuration d'exemple en multi-master-VM.</p><h3 id=kube-apiserver>kube-apiserver</h3><p>Composant sur le master qui expose l'API Kubernetes. Il s'agit du front-end pour le plan de contrôle Kubernetes.</p><p>Il est conçu pour une mise à l'échelle horizontale, ce qui veut dire qu'il met à l'échelle en déployant des instances supplémentaires. Voir <a href=/docs/admin/high-availability/>Construire des Clusters en Haute Disponibilité</a>.</p><h3 id=etcd>etcd</h3><p>Base de données clé-valeur consistante et hautement disponible utilisée comme mémoire de sauvegarde pour toutes les données du cluster.</p><p>Si votre cluster Kubernetes utilise etcd comme mémoire de sauvegarde, assurez-vous d'avoir un plan de
<a href=/docs/tasks/administer-cluster/configure-upgrade-etcd/#backing-up-an-etcd-cluster>back up</a> pour ces données.</p><p>Vous pouvez trouver plus d'informations à propos d'etcd dans la <a href=https://etcd.io/docs/>documentation</a> officielle.</p><h3 id=kube-scheduler>kube-scheduler</h3><p>Composant sur le master qui surveille les pods nouvellement créés qui ne sont pas assignés à un nœud et sélectionne un nœud sur lequel ils vont s'exécuter.</p><p>Les facteurs pris en compte pour les décisions de planification (scheduling) comprennent les exigences individuelles et collectives en ressources, les contraintes matérielles/logicielles/politiques, les spécifications d'affinité et d'anti-affinité, la localité des données, les interférences entre charges de travail et les dates limites.</p><h3 id=kube-controller-manager>kube-controller-manager</h3><p>Composant du master qui exécute les <a class=glossary-tooltip title="Boucle de contrôle surveillant l'état partagé du cluster à travers l'apiserver et effectuant des changements en essayant de déplacer l'état actuel vers l'état désiré." data-toggle=tooltip data-placement=top href=/docs/admin/kube-controller-manager/ target=_blank aria-label=contrôleurs>contrôleurs</a>.</p><p>Logiquement, chaque <a class=glossary-tooltip title="Boucle de contrôle surveillant l'état partagé du cluster à travers l'apiserver et effectuant des changements en essayant de déplacer l'état actuel vers l'état désiré." data-toggle=tooltip data-placement=top href=/docs/admin/kube-controller-manager/ target=_blank aria-label=contrôleur>contrôleur</a> est un processus à part mais,
pour réduire la complexité, les contrôleurs sont tous compilés dans un seul binaire et s'exécutent dans un seul processus.</p><p>Ces contrôleurs incluent :</p><ul><li>Node Controller : Responsable de détecter et apporter une réponse lorsqu'un nœud tombe en panne.</li><li>Replication Controller : Responsable de maintenir le bon nombre de pods pour chaque objet
ReplicationController dans le système.</li><li>Endpoints Controller : Remplit les objets Endpoints (c'est-à-dire joint les Services et Pods).</li><li>Service Account & Token Controllers : Créent des comptes par défaut et des jetons d'accès à l'API
pour les nouveaux namespaces.</li></ul><h3 id=cloud-controller-manager>cloud-controller-manager</h3><p>Le <a href=/docs/tasks/administer-cluster/running-cloud-controller/>cloud-controller-manager</a> exécute les contrôleurs
qui interagissent avec les fournisseurs cloud sous-jacents. Le binaire du cloud-controller-manager est une
fonctionnalité alpha introduite dans la version 1.6 de Kubernetes.</p><p>Le cloud-controller-manager exécute seulement les boucles spécifiques des fournisseurs cloud.
Vous devez désactiver ces boucles de contrôleurs dans le kube-controller-manager.
Vous pouvez désactiver les boucles de contrôleurs en définissant la valeur du flag <code>--cloud-provider</code> à <code>external</code> lors du démarrage du kube-controller-manager.</p><p>Le cloud-controller-manager permet au code du fournisseur cloud et au code de Kubernetes d'évoluer indépendamment l'un de l'autre.
Dans des versions antérieures, le code de base de Kubernetes dépendait du code spécifique du fournisseur cloud pour la fonctionnalité. Dans des versions ultérieures, le code spécifique des fournisseurs cloud devrait être maintenu par les fournisseurs cloud eux-mêmes et lié au cloud-controller-manager lors de l'exécution de Kubernetes.</p><p>Les contrôleurs suivants ont des dépendances vers des fournisseurs cloud :</p><ul><li>Node Controller : Pour vérifier le fournisseur de cloud afin de déterminer si un nœud a été supprimé dans le cloud après avoir cessé de répondre</li><li>Route Controller : Pour mettre en place des routes dans l'infrastructure cloud sous-jacente</li><li>Service Controller : Pour créer, mettre à jour et supprimer les load balancers des fournisseurs cloud</li><li>Volume Controller : Pour créer, attacher et monter des Volumes, et interagir avec le fournisseur cloud pour orchestrer les volumes.</li></ul><h2 id=composants-de-nœud>Composants de nœud</h2><p>Les composants de nœud (Node components) s'exécutent sur chaque nœud, en maintenant les pods en exécution
et en fournissant l'environnement d'exécution Kubernetes.</p><h3 id=kubelet>kubelet</h3><p>Un agent qui s'exécute sur chaque nœud du cluster. Il s'assure que les conteneurs fonctionnent dans un pod.</p><p>Le kubelet prend un ensemble de PodSpecs fournis par divers mécanismes et s'assure du fonctionnement et de la santé des conteneurs décrits dans ces PodSpecs. Le kubelet ne gère que les conteneurs créés par Kubernetes.</p><h3 id=kube-proxy>kube-proxy</h3><p><a href=/docs/reference/command-line-tools-reference/kube-proxy/>kube-proxy</a> est un
proxy réseau qui s'exécute sur chaque nœud du cluster et implémente une partie du
concept Kubernetes de <a class=glossary-tooltip title="Un moyen d'exposer une application s'exécutant sur un ensemble de pods en tant que service réseau." data-toggle=tooltip data-placement=top href=/fr/docs/concepts/services-networking/service/ target=_blank aria-label=Service>Service</a>.</p><p>kube-proxy maintient les règles réseau sur les nœuds. Ces règles réseau permettent
une communication réseau vers les Pods depuis des sessions réseau à l'intérieur ou à l'extérieur
du cluster.</p><p>kube-proxy utilise la couche de filtrage de paquets du système d'exploitation s'il y en a une et qu'elle est disponible. Sinon, kube-proxy transmet le trafic lui-même.</p><h3 id=container-runtime>Container Runtime</h3><p>L'environnement d'exécution de conteneurs est le logiciel responsable de l'exécution des conteneurs.</p><p>Kubernetes est compatible avec plusieurs environnements d'exécution de conteneur: <a href=http://www.docker.com>Docker</a>,
<a href=https://containerd.io>containerd</a>, <a href=https://cri-o.io/>cri-o</a>,
<a href=https://github.com/kubernetes-incubator/rktlet>rktlet</a> ainsi que toute implémentation de <a href=https://github.com/kubernetes/community/blob/master/contributors/devel/sig-node/container-runtime-interface.md>Kubernetes CRI (Container Runtime Interface)</a>.</p><h2 id=addons>Addons</h2><p>Les addons utilisent les ressources Kubernetes (<a class=glossary-tooltip title="S'assure qu'une copie d'un Pod s'exécute sur un ensemble de nœuds d'un cluster." data-toggle=tooltip data-placement=top href=/docs/concepts/workloads/controllers/daemonset target=_blank aria-label=DaemonSet>DaemonSet</a>, <a class=glossary-tooltip title='Objet API gérant une application répliquée.' data-toggle=tooltip data-placement=top href=/docs/concepts/workloads/controllers/deployment/ target=_blank aria-label=Déploiement>Déploiement</a>, etc)
pour implémenter des fonctionnalités cluster. Comme ces derniers fournissent des fonctionnalités au niveau
du cluster, les ressources dans des namespaces pour les addons appartiennent au namespace <code>kube-system</code>.</p><p>Les addons sélectionnés sont décrits ci-dessous. Pour une liste étendue des addons disponibles, voir la page
<a href=/docs/concepts/cluster-administration/addons/>Addons</a>.</p><h3 id=dns>DNS</h3><p>Tandis que les autres addons ne sont pas strictement requis, tous les clusters Kubernetes devraient avoir un
<a href=/fr/docs/concepts/services-networking/dns-pod-service/>DNS cluster</a> car de nombreux exemples en dépendent.</p><p>Le DNS Cluster est un serveur DNS, en plus des autres serveurs DNS dans votre environnement, qui sert
les enregistrements DNS pour les services Kubernetes.</p><p>Les conteneurs démarrés par Kubernetes incluent automatiquement ce serveur DNS dans leurs recherches DNS.</p><h3 id=interface-utilisateur-web-dashboard>Interface utilisateur Web (Dashboard)</h3><p>Le <a href=/docs/tasks/access-application-cluster/web-ui-dashboard/>Dashboard</a> est une interface utilisateur web à but général pour les clusters Kubernetes. Il permet aux utilisateurs de gérer et de dépanner aussi bien des
applications s'exécutant dans le cluster que le cluster lui-même.</p><h3 id=la-surveillance-des-ressources-de-conteneur>La surveillance des ressources de conteneur</h3><p><a href=/docs/tasks/debug-application-cluster/resource-usage-monitoring/>La surveillance des ressources de conteneur</a> enregistre des métriques chronologiques génériques à propos des conteneurs dans une base de données centrale et
fournit une interface utilisateur pour parcourir ces données.</p><h3 id=le-logging-au-niveau-cluster>Le logging au niveau cluster</h3><p>Un mécanisme de <a href=/docs/concepts/cluster-administration/logging/>logging au niveau cluster</a> est chargé
de sauvegarder les logs des conteneurs dans un magasin de logs central avec une interface de recherche/navigation.</p><h2 id=a-suivre>A suivre</h2><ul><li>En savoir plus sur les <a href=/fr/docs/concepts/architecture/nodes/>Nœuds</a></li><li>En savoir plus sur <a href=/docs/concepts/scheduling/kube-scheduler/>kube-scheduler</a></li><li>Lire la <a href=https://etcd.io/docs/>documentation officielle d'etcd</a></li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-110f33530cf761140cb1dab536baef04>3.1.3 - Utilisation des objets Kubernetes</h1></div><div class=td-content><h1 id=pg-1127165f472b7181b9c1d5a0b187d620>3.1.3.1 - Namespaces</h1><p>Kubernetes prend en charge plusieurs clusters virtuels présents sur le même cluster physique.
Ces clusters virtuels sont appelés namespaces (espaces de nommage en français).</p><h2 id=quand-utiliser-plusieurs-namespaces>Quand utiliser plusieurs namespaces</h2><p>Les namespaces sont destinés à être utilisés dans les environnements ayant de nombreux utilisateurs répartis en plusieurs équipes ou projets. Pour les clusters de quelques dizaines d'utilisateurs, vous n'avez pas
besoin d'utiliser de namespaces. Commencez à utiliser des namespaces lorsque vous avez
besoin des fonctionnalités qu'ils fournissent.</p><p>Les namespaces sont des groupes de noms. Ils fournissent un modèle d'isolation de nommage des ressources. Les noms des ressources doivent être uniques dans un namespace,
mais pas dans l'ensemble des namespaces. Les namespaces ne peuvent pas être imbriqués les uns dans les autres et chaque ressource Kubernetes ne peut se trouver que dans un seul namespace.</p><p>Les namespaces sont un moyen de répartir les ressources d'un cluster entre plusieurs utilisateurs (via <a href=/docs/concepts/policy/resource-quotas/>quota de ressources</a>).</p><p>Dans les futures versions de Kubernetes, les objets du même namespace auront les mêmes
stratégies de contrôle d'accès par défaut.</p><p>Il n'est pas nécessaire d'utiliser plusieurs namespaces juste pour séparer des ressources légèrement différentes, telles que les versions du même logiciel: utiliser les <a href=/docs/user-guide/labels>labels</a> pour distinguer les
ressources dans le même namespace.</p><h2 id=utilisation-des-namespaces>Utilisation des namespaces</h2><p>La création et la suppression des namespaces sont décrites dans la <a href=/docs/admin/namespaces>Documentation du guide d'administration pour les namespaces</a>.</p><div class="alert alert-info note callout" role=alert><strong>Note:</strong> Évitez de créer des namespaces avec le préfixe <code>kube-</code>, car il est réservé aux namespaces système de Kubernetes.</div><h3 id=affichage-des-namespaces>Affichage des namespaces</h3><p>Dans un cluster vous pouvez lister les namespaces actuels à l'aide de :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get namespace
</span></span></code></pre></div><pre tabindex=0><code>NAME              STATUS   AGE
default           Active   1d
kube-node-lease   Active   1d
kube-public       Active   1d
kube-system       Active   1d
</code></pre><p>Kubernetes démarre avec quatre namespaces initiaux:</p><ul><li><code>default</code> Le namespace par défaut pour les objets sans mention d'autre namespace</li><li><code>kube-system</code> Le namespace pour les objets créés par Kubernetes lui-même</li><li><code>kube-public</code> Ce namespace est créé automatiquement et est visible par tous les utilisateurs (y compris ceux qui ne sont pas authentifiés). Ce namespace est principalement réservé à l'utilisation du cluster, au cas où certaines ressources devraient être disponibles publiquement dans l'ensemble du cluster. L'aspect public de ce namespace n'est qu'une convention, pas une exigence.</li><li><code>kube-node-lease</code> Ce namespace contient les objets de bail associés à chaque nœud, ce qui améliore les performances des pulsations du nœud à mesure que le cluster évolue.</li></ul><h3 id=définition-du-namespaces-pour-une-requête>Définition du namespaces pour une requête</h3><p>Pour définir le namespace pour une requête en cours, utilisez l'indicateur <code>--namespace</code>.</p><p>Par exemple:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl run nginx --image<span style=color:#666>=</span>nginx --namespace<span style=color:#666>=</span>&lt;insert-namespace-name-here&gt;
</span></span><span style=display:flex><span>kubectl get pods --namespace<span style=color:#666>=</span>&lt;insert-namespace-name-here&gt;
</span></span></code></pre></div><h3 id=spécifier-un-namespace>Spécifier un namespace</h3><p>Vous pouvez enregistrer de manière permanente le namespace à utiliser pour toutes les commandes kubectl à suivre.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl config set-context --current --namespace<span style=color:#666>=</span>&lt;insert-namespace-name-here&gt;
</span></span><span style=display:flex><span><span style=color:#080;font-style:italic># Validez-le</span>
</span></span><span style=display:flex><span>kubectl config view --minify | grep namespace:
</span></span></code></pre></div><h2 id=namespaces-et-dns>Namespaces et DNS</h2><p>Lorsque vous créez un <a href=/fr/docs/concepts/services-networking/service/>Service</a>, il crée une <a href=/fr/docs/concepts/services-networking/dns-pod-service/>entrée DNS</a> correspondante.
Cette entrée est de la forme <code>&lt;nom-service>.&lt;nom-namespace>.svc.cluster.local</code>, ce qui signifie
que si un conteneur utilise simplement <code>&lt;nom-service></code>, il résoudra le service qui
est local à son namespace. Ceci est utile pour utiliser la même configuration pour
plusieurs namespaces tels que le Développement, la Qualification et la Production. Si vous voulez naviguer
entre plusieurs namespaces, vous devez utiliser le nom de domaine complet (FQDN ou nom de domaine complètement qualifié en français).</p><h2 id=tous-les-objets-ne-se-trouvent-pas-dans-un-namespace>Tous les objets ne se trouvent pas dans un namespace</h2><p>La plupart des ressources Kubernetes (par exemple, pods, services, contrôleurs de réplication et autres) sont
dans des namespaces. Cependant, les ressources de type namespace ne sont pas elles-mêmes dans un namespace.
Et les ressources de bas niveau, telles que les <a href=/docs/admin/node>nœuds</a> et les volumes persistants, ne se trouvent dans aucun namespace.</p><p>Pour voir quelles ressources Kubernetes sont et ne sont pas dans un namespace:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span><span style=color:#080;font-style:italic># Dans un namespace</span>
</span></span><span style=display:flex><span>kubectl api-resources --namespaced<span style=color:#666>=</span><span style=color:#a2f>true</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#080;font-style:italic># Pas dans un namespace</span>
</span></span><span style=display:flex><span>kubectl api-resources --namespaced<span style=color:#666>=</span><span style=color:#a2f>false</span>
</span></span></code></pre></div><h2 id=a-suivre>A suivre</h2><ul><li>En savoir plus sur <a href=/docs/tasks/administer-cluster/namespaces/#creating-a-new-namespace>créer un nouveau namespace</a>.</li><li>En savoir plus sur <a href=/docs/tasks/administer-cluster/namespaces/#deleting-a-namespace>suppression d'un namespace</a>.</li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-2bf36ccd6b3dbeafecf87c39761b07c7>3.2 - Architecture de Kubernetes</h1><div class=lead>Architecture Kubernetes</div></div><div class=td-content><h1 id=pg-9ef2890698e773b6c0d24fd2c20146f5>3.2.1 - Noeuds</h1><div class=lead>Concept Noeud Kubernetes</div><p>Un nœud est une machine de travail dans Kubernetes, connue auparavant sous le nom de <code>minion</code>.
Un nœud peut être une machine virtuelle ou une machine physique, selon le cluster.
Chaque nœud contient les services nécessaires à l'exécution de <a href=/docs/concepts/workloads/pods/pod/>pods</a> et est géré par les composants du master.
Les services sur un nœud incluent le <a href=/docs/concepts/overview/components/#node-components>container runtime</a>, kubelet et kube-proxy.
Consultez la section <a href=https://git.k8s.io/community/contributors/design-proposals/architecture/architecture.md#the-kubernetes-node>Le Nœud Kubernetes</a> dans le document de conception de l'architecture pour plus de détails.</p><h2 id=statut-du-nœud>Statut du nœud</h2><p>Le statut d'un nœud contient les informations suivantes:</p><ul><li><a href=#addresses>Addresses</a></li><li><a href=#condition>Condition</a></li><li><a href=#capacity>Capacity</a></li><li><a href=#info>Info</a></li></ul><p>Chaque section est décrite en détail ci-dessous.</p><h3 id=adresses>Adresses</h3><p>L'utilisation de ces champs varie en fonction de votre fournisseur de cloud ou de votre configuration physique.</p><ul><li>HostName: Le nom d'hôte tel que rapporté par le noyau du nœud. Peut être remplacé via le paramètre kubelet <code>--hostname-override</code>.</li><li>ExternalIP: En règle générale, l'adresse IP du nœud pouvant être routé en externe (disponible de l'extérieur du cluster).</li><li>InternalIP: En règle générale, l'adresse IP du nœud pouvant être routé uniquement dans le cluster.</li></ul><h3 id=condition>Condition</h3><p>Le champ <code>conditions</code> décrit le statut de tous les nœuds <code>Running</code>.</p><table><thead><tr><th>Node Condition</th><th>Description</th></tr></thead><tbody><tr><td><code>OutOfDisk</code></td><td><code>True</code> si l'espace disponible sur le nœud est insuffisant pour l'ajout de nouveaux pods, sinon <code>False</code></td></tr><tr><td><code>Ready</code></td><td><code>True</code> si le noeud est sain et prêt à accepter des pods, <code>False</code> si le noeud n'est pas sain et n'accepte pas de pods, et <code>Unknown</code> si le contrôleur de noeud n'a pas reçu d'information du noeud depuis <code>node-monitor-grace-period</code> (la valeur par défaut est de 40 secondes)</td></tr><tr><td><code>MemoryPressure</code></td><td><code>True</code> s'il existe une pression sur la mémoire du noeud, c'est-à-dire si la mémoire du noeud est faible; autrement <code>False</code></td></tr><tr><td><code>PIDPressure</code></td><td><code>True</code> s'il existe une pression sur le nombre de processus, c'est-à-dire s'il y a trop de processus sur le nœud; autrement <code>False</code></td></tr><tr><td><code>DiskPressure</code></td><td><code>True</code> s'il existe une pression sur la taille du disque, c'est-à-dire si la capacité du disque est faible; autrement <code>False</code></td></tr><tr><td><code>NetworkUnavailable</code></td><td><code>True</code> si le réseau pour le noeud n'est pas correctement configuré, sinon <code>False</code></td></tr></tbody></table><p>La condition de noeud est représentée sous la forme d'un objet JSON.
Par exemple, la réponse suivante décrit un nœud sain.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-json data-lang=json><span style=display:flex><span><span style=color:#b44>&#34;conditions&#34;</span><span>:</span> [
</span></span><span style=display:flex><span>  {
</span></span><span style=display:flex><span>    <span style=color:green;font-weight:700>&#34;type&#34;</span>: <span style=color:#b44>&#34;Ready&#34;</span>,
</span></span><span style=display:flex><span>    <span style=color:green;font-weight:700>&#34;status&#34;</span>: <span style=color:#b44>&#34;True&#34;</span>
</span></span><span style=display:flex><span>  }
</span></span><span style=display:flex><span>]
</span></span></code></pre></div><p>Si le statut de l'état Ready reste <code>Unknown</code> ou <code>False</code> plus longtemps que <code>pod-eviction-timeout</code>, un argument est passé au <a href=/docs/admin/kube-controller-manager/>kube-controller-manager</a> et les pods sur le nœud sont programmés pour être supprimés par le contrôleur du nœud.
Le délai d’expulsion par défaut est de <strong>cinq minutes</strong>..
Dans certains cas, lorsque le nœud est inaccessible, l'apiserver est incapable de communiquer avec le kubelet sur le nœud.
La décision de supprimer les pods ne peut pas être communiquée au kublet tant que la communication avec l'apiserver n'est pas rétablie.
Entre-temps, les pods dont la suppression est planifiée peuvent continuer à s'exécuter sur le nœud inaccessible.</p><p>Dans les versions de Kubernetes antérieures à 1.5, le contrôleur de noeud <a href=/docs/concepts/workloads/pods/pod/#force-deletion-of-pods>forcait la suppression</a> de ces pods inaccessibles de l'apiserver.
Toutefois, dans la version 1.5 et ultérieure, le contrôleur de noeud ne force pas la suppression des pods tant qu'il n'est pas confirmé qu'ils ont cessé de fonctionner dans le cluster.
Vous pouvez voir que les pods en cours d'exécution sur un nœud inaccessible sont dans l'état <code>Terminating</code> ou<code> Unknown</code>.
Dans les cas où Kubernetes ne peut pas déduire de l'infrastructure sous-jacente si un nœud a définitivement quitté un cluster, l'administrateur du cluster peut avoir besoin de supprimer l'objet nœud à la main.
La suppression de l'objet nœud de Kubernetes entraîne la suppression de tous les objets Pod exécutés sur le nœud de l'apiserver et libère leurs noms.</p><p>Dans la version 1.12, la fonctionnalité <code>TaintNodesByCondition</code> est promue en version bêta, ce qui permet au contrôleur de cycle de vie du nœud de créer automatiquement des <a href=/docs/concepts/configuration/taint-and-toleration/>marquages</a> (taints en anglais) qui représentent des conditions.
De même, l'ordonnanceur ignore les conditions lors de la prise en compte d'un nœud; au lieu de cela, il regarde les taints du nœud et les tolérances d'un pod.</p><p>Les utilisateurs peuvent désormais choisir entre l'ancien modèle de planification et un nouveau modèle de planification plus flexible.
Un pod qui n’a aucune tolérance est programmé selon l’ancien modèle.
Mais un pod qui tolère les taints d'un nœud particulier peut être programmé sur ce nœud.</p><div class="alert alert-warning caution callout" role=alert><strong>Avertissement:</strong> L'activation de cette fonctionnalité crée un léger délai entre le moment où une condition est observée et le moment où une taint est créée.
Ce délai est généralement inférieur à une seconde, mais il peut augmenter le nombre de pods programmés avec succès mais rejetés par le kubelet.</div><h3 id=capacité>Capacité</h3><p>Décrit les ressources disponibles sur le nœud: CPU, mémoire et nombre maximal de pods pouvant être planifiés sur le nœud.</p><h3 id=info>Info</h3><p>Informations générales sur le noeud, telles que la version du noyau, la version de Kubernetes (versions de kubelet et kube-proxy), la version de Docker (si utilisée), le nom du système d'exploitation.
Les informations sont collectées par Kubelet à partir du noeud.</p><h2 id=gestion>Gestion</h2><p>Contrairement aux <a href=/docs/concepts/workloads/pods/>pods</a> et aux [services] (/docs/concepts/services-networking/service/), un nœud n'est pas créé de manière inhérente par Kubernetes: il est créé de manière externe par un cloud tel que Google Compute Engine, ou bien il existe dans votre pool de machines physiques ou virtuelles.
Ainsi, lorsque Kubernetes crée un nœud, il crée un objet qui représente le nœud.
Après la création, Kubernetes vérifie si le nœud est valide ou non.
Par exemple, si vous essayez de créer un nœud à partir du contenu suivant:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-json data-lang=json><span style=display:flex><span>{
</span></span><span style=display:flex><span>  <span style=color:green;font-weight:700>&#34;kind&#34;</span>: <span style=color:#b44>&#34;Node&#34;</span>,
</span></span><span style=display:flex><span>  <span style=color:green;font-weight:700>&#34;apiVersion&#34;</span>: <span style=color:#b44>&#34;v1&#34;</span>,
</span></span><span style=display:flex><span>  <span style=color:green;font-weight:700>&#34;metadata&#34;</span>: {
</span></span><span style=display:flex><span>    <span style=color:green;font-weight:700>&#34;name&#34;</span>: <span style=color:#b44>&#34;10.240.79.157&#34;</span>,
</span></span><span style=display:flex><span>    <span style=color:green;font-weight:700>&#34;labels&#34;</span>: {
</span></span><span style=display:flex><span>      <span style=color:green;font-weight:700>&#34;name&#34;</span>: <span style=color:#b44>&#34;my-first-k8s-node&#34;</span>
</span></span><span style=display:flex><span>    }
</span></span><span style=display:flex><span>  }
</span></span><span style=display:flex><span>}
</span></span></code></pre></div><p>Kubernetes crée un objet noeud en interne (la représentation) et valide le noeud en vérifiant son intégrité en fonction du champ <code>metadata.name</code>.
Si le nœud est valide, c'est-à-dire si tous les services nécessaires sont en cours d'exécution, il est éligible pour exécuter un pod.
Sinon, il est ignoré pour toute activité de cluster jusqu'à ce qu'il devienne valide.</p><div class="alert alert-info note callout" role=alert><strong>Note:</strong> Kubernetes conserve l'objet pour le nœud non valide et vérifie s'il devient valide.
Vous devez explicitement supprimer l'objet Node pour arrêter ce processus.</div><p>Actuellement, trois composants interagissent avec l'interface de noeud Kubernetes: le contrôleur de noeud, kubelet et kubectl.</p><h3 id=contrôleur-de-nœud>Contrôleur de nœud</h3><p>Le contrôleur de noeud (node controller en anglais) est un composant du master Kubernetes qui gère divers aspects des noeuds.</p><p>Le contrôleur de nœud a plusieurs rôles dans la vie d'un nœud.
La première consiste à affecter un bloc CIDR au nœud lorsqu’il est enregistré (si l’affectation CIDR est activée).</p><p>La seconde consiste à tenir à jour la liste interne des nœuds du contrôleur de nœud avec la liste des machines disponibles du fournisseur de cloud.
Lorsqu'il s'exécute dans un environnement de cloud, chaque fois qu'un nœud est en mauvaise santé, le contrôleur de nœud demande au fournisseur de cloud si la machine virtuelle de ce nœud est toujours disponible.
Sinon, le contrôleur de nœud supprime le nœud de sa liste de nœuds.</p><p>La troisième est la surveillance de la santé des nœuds.
Le contrôleur de noeud est responsable de la mise à jour de la condition NodeReady de NodeStatus vers ConditionUnknown lorsqu'un noeud devient inaccessible (le contrôleur de noeud cesse de recevoir des heartbeats pour une raison quelconque, par exemple en raison d'une panne du noeud), puis de l'éviction ultérieure de tous les pods du noeud. (en utilisant une terminaison propre) si le nœud continue d’être inaccessible.
(Les délais d'attente par défaut sont de 40 secondes pour commencer à signaler ConditionUnknown et de 5 minutes après cela pour commencer à expulser les pods.)</p><p>Le contrôleur de nœud vérifie l'état de chaque nœud toutes les <code>--node-monitor-period</code> secondes.</p><p>Dans les versions de Kubernetes antérieures à 1.13, NodeStatus correspond au heartbeat du nœud.
À partir de Kubernetes 1.13, la fonctionnalité de bail de nœud (node lease en anglais) est introduite en tant que fonctionnalité alpha (feature gate <code>NodeLease</code>, <a href=https://github.com/kubernetes/enhancements/blob/master/keps/sig-node/0009-node-heartbeat.md>KEP-0009</a>).
Lorsque la fonction de node lease est activée, chaque noeud a un objet <code>Lease</code> associé dans le namespace <code>kube-node-lease</code> qui est renouvelé périodiquement par le noeud, et NodeStatus et le node lease sont traités comme des heartbeat du noeud.
Les node leases sont renouvelés fréquemment lorsque NodeStatus est signalé de nœud à master uniquement lorsque des modifications ont été apportées ou que suffisamment de temps s'est écoulé (la valeur par défaut est 1 minute, ce qui est plus long que le délai par défaut de 40 secondes pour les nœuds inaccessibles).
Étant donné qu'un node lease est beaucoup plus léger qu'un NodeStatus, cette fonctionnalité rends le heartbeat d'un nœud nettement moins coûteux, tant du point de vue de l'évolutivité que des performances.</p><p>Dans Kubernetes 1.4, nous avons mis à jour la logique du contrôleur de noeud afin de mieux gérer les cas où un grand nombre de noeuds rencontrent des difficultés pour atteindre le master (par exemple parce que le master a un problème de réseau).
À partir de la version 1.4, le contrôleur de noeud examine l’état de tous les noeuds du cluster lorsqu’il prend une décision concernant l’éviction des pods.</p><p>Dans la plupart des cas, le contrôleur de noeud limite le taux d’expulsion à <code>--node-eviction-rate</code> (0,1 par défaut) par seconde, ce qui signifie qu’il n’expulsera pas les pods de plus d’un nœud toutes les 10 secondes.</p><p>Le comportement d'éviction de noeud change lorsqu'un noeud d'une zone de disponibilité donnée devient défaillant.
Le contrôleur de nœud vérifie quel pourcentage de nœuds de la zone est défaillant (la condition NodeReady est ConditionUnknown ou ConditionFalse) en même temps.
Si la fraction de nœuds défaillant est au moins <code>--unhealthy-zone-threshold</code> (valeur par défaut de 0,55), le taux d'expulsion est réduit: si le cluster est petit (c'est-à-dire inférieur ou égal à <code>--large-cluster-size-threshold</code> noeuds - valeur par défaut 50) puis les expulsions sont arrêtées, sinon le taux d'expulsion est réduit à <code>--secondary-node-eviction-rate</code> (valeur par défaut de 0,01) par seconde.</p><p>Ces stratégies sont implémentées par zone de disponibilité car une zone de disponibilité peut être partitionnée à partir du master, tandis que les autres restent connectées.
Si votre cluster ne s'étend pas sur plusieurs zones de disponibilité de fournisseur de cloud, il n'existe qu'une seule zone de disponibilité (la totalité du cluster).</p><p>L'une des principales raisons de la répartition de vos nœuds entre les zones de disponibilité est de pouvoir déplacer la charge de travail vers des zones saines lorsqu'une zone entière tombe en panne.
Par conséquent, si tous les nœuds d’une zone sont défaillants, le contrôleur de nœud expulse à la vitesse normale <code>--node-eviction-rate</code>.
Le cas pathologique se produit lorsque toutes les zones sont complètement défaillantes (c'est-à-dire qu'il n'y a pas de nœuds sains dans le cluster).
Dans ce cas, le contrôleur de noeud suppose qu'il existe un problème de connectivité au master et arrête toutes les expulsions jusqu'à ce que la connectivité soit restaurée.</p><p>À partir de Kubernetes 1.6, NodeController est également responsable de l'expulsion des pods s'exécutant sur des noeuds avec des marques <code>NoExecute</code>, lorsque les pods ne tolèrent pas ces marques.
De plus, en tant que fonctionnalité alpha désactivée par défaut, NodeController est responsable de l'ajout de marques correspondant aux problèmes de noeud tels que les noeuds inaccessibles ou non prêts.
Voir <a href=/docs/concepts/configuration/taint-and-toleration/>cette documentation</a> pour plus de détails sur les marques <code>NoExecute</code> et cette fonctionnalité alpha.</p><p>À partir de la version 1.8, le contrôleur de noeud peut être chargé de créer des tâches représentant les conditions de noeud.
Ceci est une fonctionnalité alpha de la version 1.8.</p><h3 id=auto-enregistrement-des-nœuds>Auto-enregistrement des nœuds</h3><p>Lorsque l'indicateur de kubelet <code>--register-node</code> est à true (valeur par défaut), le kubelet tente de s'enregistrer auprès du serveur d'API.
C'est le modèle préféré, utilisé par la plupart des distributions Linux.</p><p>Pour l'auto-enregistrement (self-registration en anglais), le kubelet est lancé avec les options suivantes:</p><ul><li><code>--kubeconfig</code> - Chemin d'accès aux informations d'identification pour s'authentifier auprès de l'apiserver.</li><li><code>--cloud-provider</code> - Comment lire les métadonnées d'un fournisseur de cloud sur lui-même.</li><li><code>--register-node</code> - Enregistrement automatique avec le serveur API.</li><li><code>--register-with-taints</code> - Enregistrez le noeud avec la liste donnée de marques (séparés par des virgules <code>&lt;key>=&lt;value>:&lt;effect></code>). Sans effet si <code>register-node</code> est à false.</li><li><code>--node-ip</code> - Adresse IP du noeud.</li><li><code>--node-labels</code> - Labels à ajouter lors de l’enregistrement du noeud dans le cluster (voir Restrictions des labels appliquées par le <a href=/docs/reference/access-authn-authz/admission-controllers/#noderestriction>plugin NodeRestriction admission</a> dans les versions 1.13+).</li><li><code>--node-status-update-frequency</code> - Spécifie la fréquence à laquelle kubelet publie le statut de nœud sur master.</li></ul><p>Quand le mode <a href=/docs/reference/access-authn-authz/node/>autorisation de nœud</a> et <a href=/docs/reference/access-authn-authz/admission-controllers/#noderestriction>plugin NodeRestriction admission</a> sont activés, les kubelets sont uniquement autorisés à créer / modifier leur propre ressource de noeud.</p><h4 id=administration-manuelle-de-noeuds>Administration manuelle de noeuds</h4><p>Un administrateur de cluster peut créer et modifier des objets de nœud.</p><p>Si l'administrateur souhaite créer des objets de noeud manuellement, définissez l'argument de kubelet: <code>--register-node=false</code>.</p><p>L'administrateur peut modifier les ressources du nœud (quel que soit le réglage de <code>--register-node</code>).
Les modifications comprennent la définition de labels sur le nœud et son marquage comme non programmable.</p><p>Les étiquettes sur les nœuds peuvent être utilisées avec les sélecteurs de nœuds sur les pods pour contrôler la planification. Par exemple, pour contraindre un pod à ne pouvoir s'exécuter que sur un sous-ensemble de nœuds.</p><p>Marquer un nœud comme non planifiable empêche la planification de nouveaux pods sur ce nœud, mais n'affecte pas les pods existants sur le nœud.
Ceci est utile comme étape préparatoire avant le redémarrage d'un nœud, etc. Par exemple, pour marquer un nœud comme non programmable, exécutez la commande suivante:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl cordon <span style=color:#b8860b>$NODENAME</span>
</span></span></code></pre></div><div class="alert alert-info note callout" role=alert><strong>Note:</strong> Les pods créés par un contrôleur DaemonSet contournent le planificateur Kubernetes et ne respectent pas l'attribut unschedulable sur un nœud.
Cela suppose que les démons appartiennent à la machine même si celle-ci est en cours de vidage des applications pendant qu'elle se prépare au redémarrage.</div><h3 id=capacité-de-nœud>Capacité de nœud</h3><p>La capacité du nœud (nombre de CPU et quantité de mémoire) fait partie de l’objet Node.
Normalement, les nœuds s'enregistrent et indiquent leur capacité lors de la création de l'objet Node.
Si vous faites une <a href=#manual-node-administration>administration manuelle de nœud</a>, alors vous devez définir la capacité du nœud lors de l'ajout d'un nœud.</p><p>Le scheduler Kubernetes veille à ce qu'il y ait suffisamment de ressources pour tous les pods d'un noeud.
Il vérifie que la somme des demandes des conteneurs sur le nœud n'est pas supérieure à la capacité du nœud.
Cela inclut tous les conteneurs lancés par le kubelet, mais pas les conteneurs lancés directement par le <a href=/docs/concepts/overview/components/#noeud-composants>conteneur runtime</a>, ni aucun processus exécuté en dehors des conteneurs.</p><p>Si vous souhaitez réserver explicitement des ressources pour des processus autres que Pod, suivez ce tutoriel pour: <a href=/docs/tasks/administer-cluster/reserve-compute-resources/#system-reserved>réserver des ressources pour les démons système</a>.</p><h2 id=api-object>API Object</h2><p>L'objet Node est une ressource de niveau supérieur dans l'API REST de Kubernetes.
Plus de détails sur l'objet API peuvent être trouvés à l'adresse suivante: <a href=/docs/reference/generated/kubernetes-api/v1.25/#node-v1-core>Node API object</a>.</p></div><div class=td-content style=page-break-before:always><h1 id=pg-63e7fdf87ba61eb2586bb8c625c23506>3.2.2 - Communication Master-Node</h1><div class=lead>Communication Master-Node Kubernetes</div><p>Ce document répertorie les canaux de communication entre l'API du noeud maître (apiserver of master node en anglais) et le reste du cluster Kubernetes.
L'objectif est de permettre aux utilisateurs de personnaliser leur installation afin de sécuriser la configuration réseau, de sorte que le cluster puisse être exécuté sur un réseau non approuvé (ou sur des adresses IP entièrement publiques d'un fournisseur de cloud).</p><h2 id=communication-du-cluster-vers-le-master>Communication du Cluster vers le Master</h2><p>Tous les canaux de communication du cluster au master se terminent à l'apiserver (aucun des autres composants principaux n'est conçu pour exposer des services distants).
Dans un déploiement typique, l'apiserver est configuré pour écouter les connexions distantes sur un port HTTPS sécurisé (443) avec un ou plusieurs types d'<a href=/docs/reference/access-authn-authz/authentication/>authentification</a> client.
Une ou plusieurs formes d'<a href=/docs/reference/access-authn-authz/authorization/>autorisation</a> devraient être activées, notamment si les <a href=/docs/reference/access-authn-authz/authentication/#anonymous-requests>requêtes anonymes</a> ou <a href=/docs/reference/access-authn-authz/authentication/#service-account-tokens>jeton de compte de service</a> sont autorisés.</p><p>Le certificat racine public du cluster doit être configuré pour que les nœuds puissent se connecter en toute sécurité à l'apiserver avec des informations d'identification client valides.
Par exemple, dans un déploiement GKE par défaut, les informations d'identification client fournies au kubelet sont sous la forme d'un certificat client.
Consultez <a href=/docs/reference/command-line-tools-reference/kubelet-tls-bootstrapping/>amorçage TLS de kubelet</a> pour le provisioning automatisé des certificats de client Kubelet.</p><p>Les pods qui souhaitent se connecter à l'apiserver peuvent le faire de manière sécurisée en utilisant un compte de service afin que Kubernetes injecte automatiquement le certificat racine public et un jeton de support valide dans le pod lorsqu'il est instancié.
Le service <code>kubernetes</code> (dans tous les namespaces) est configuré avec une adresse IP virtuelle redirigée (via kube-proxy) vers le point de terminaison HTTPS sur l'apiserver.</p><p>Les composants du master communiquent également avec l'apiserver du cluster via le port sécurisé.</p><p>Par conséquent, le mode de fonctionnement par défaut pour les connexions du cluster (nœuds et pods s'exécutant sur les nœuds) au master est sécurisé par défaut et peut s'exécuter sur des réseaux non sécurisés et/ou publics.</p><h2 id=communication-du-master-vers-le-cluster>Communication du Master vers le Cluster</h2><p>Il existe deux voies de communication principales du master (apiserver) au cluster.
La première est du processus apiserver au processus kubelet qui s'exécute sur chaque nœud du cluster.
La seconde part de l'apiserver vers n'importe quel nœud, pod ou service via la fonctionnalité proxy de l'apiserver.</p><h3 id=communication-de-l-apiserver-vers-le-kubelet>Communication de l'apiserver vers le kubelet</h3><p>Les connexions de l'apiserver au kubelet sont utilisées pour:</p><ul><li>Récupérer les logs des pods.</li><li>S'attacher (via kubectl) à des pods en cours d'exécution.</li><li>Fournir la fonctionnalité de transfert de port du kubelet.</li></ul><p>Ces connexions se terminent au point de terminaison HTTPS du kubelet.
Par défaut, l'apiserver ne vérifie pas le certificat du kubelet, ce qui rend la connexion sujette aux attaques de type "man-in-the-middle", et <strong>non sûre</strong> sur des réseaux non approuvés et/ou publics.</p><p>Pour vérifier cette connexion, utilisez l'argument <code>--kubelet-certificate-authority</code> pour fournir à l'apiserver un ensemble de certificats racine à utiliser pour vérifier le certificat du kubelet.</p><p>Si ce n'est pas possible, utilisez <a href=/docs/tasks/access-application-cluster/port-forward-access-application-cluster/>SSH tunneling</a> entre l'apiserver et le kubelet si nécessaire pour éviter la connexion sur un réseau non sécurisé ou public.</p><p>Finalement, l'<a href=/docs/admin/kubelet-authentication-authorization/>authentification et/ou autorisation du Kubelet</a> devrait être activée pour sécuriser l'API kubelet.</p><h3 id=apiserver-vers-nodes-pods-et-services>apiserver vers nodes, pods et services</h3><p>Les connexions de l'apiserver à un nœud, à un pod ou à un service sont définies par défaut en connexions HTTP.
Elles ne sont donc ni authentifiées ni chiffrées.
Elles peuvent être exécutées sur une connexion HTTPS sécurisée en préfixant <code>https:</code> au nom du nœud, du pod ou du service dans l'URL de l'API.
Cependant ils ne valideront pas le certificat fourni par le point de terminaison HTTPS ni ne fourniront les informations d'identification du client.
De plus, aucune garantie d'intégrité n'est fournie.
Ces connexions <strong>ne sont actuellement pas sûres</strong> pour fonctionner sur des réseaux non sécurisés et/ou publics.</p><h3 id=ssh-tunnels>SSH Tunnels</h3><p>Kubernetes prend en charge les tunnels SSH pour protéger les communications master -> cluster.
Dans cette configuration, l'apiserver initie un tunnel SSH vers chaque nœud du cluster (en se connectant au serveur ssh sur le port 22) et transmet tout le trafic destiné à un kubelet, un nœud, un pod ou un service via un tunnel.
Ce tunnel garantit que le trafic n'est pas exposé en dehors du réseau dans lequel les nœuds sont en cours d'exécution.</p><p>Les tunnels SSH étant actuellement obsolètes, vous ne devriez pas choisir de les utiliser à moins de savoir ce que vous faites.
Un remplacement pour ce canal de communication est en cours de conception.</p></div><div class=td-content style=page-break-before:always><h1 id=pg-bc804b02614d67025b4c788f1ca87fbc>3.2.3 - Concepts sous-jacents au Cloud Controller Manager</h1><p>Le concept de cloud controller manager (CCM) (ne pas confondre avec le binaire) a été créé à l'origine pour permettre au code de fournisseur spécifique de cloud et au noyau Kubernetes d'évoluer indépendamment les uns des autres.
Le gestionnaire de contrôleur de cloud fonctionne aux côtés d'autres composants principaux, tels que le gestionnaire de contrôleur Kubernetes, le serveur d'API et le planificateur.
Il peut également être démarré en tant qu’addon Kubernetes, auquel cas il s’exécute sur Kubernetes.</p><p>La conception du gestionnaire de contrôleur de cloud repose sur un mécanisme de plugin qui permet aux nouveaux fournisseurs de cloud de s'intégrer facilement à Kubernetes à l'aide de plugins.
Des plans sont en place pour intégrer de nouveaux fournisseurs de cloud sur Kubernetes et pour migrer les fournisseurs de cloud de l'ancien modèle vers le nouveau modèle CCM.</p><p>Ce document discute des concepts derrière le cloud controller manager et donne des détails sur ses fonctions associées.</p><p>Voici l'architecture d'un cluster Kubernetes sans le cloud controller manager:</p><p><img src=/images/docs/pre-ccm-arch.png alt="Pre CCM Kube Arch"></p><h2 id=conception>Conception</h2><p>Dans le diagramme précédent, Kubernetes et le fournisseur de cloud sont intégrés via plusieurs composants différents:</p><ul><li>Kubelet</li><li>Kubernetes controller manager</li><li>Kubernetes API server</li></ul><p>Le CCM consolide toute la logique dépendante du cloud des trois composants précédents pour créer un point d’intégration unique avec le cloud.
La nouvelle architecture avec le CCM se présente comme suit:</p><p><img src=/images/docs/post-ccm-arch.png alt="CCM Kube Arch"></p><h2 id=composants-du-ccm>Composants du CCM</h2><p>Le CCM rompt certaines fonctionnalités du Kubernetes Controller Manager (KCM) et les exécute en tant que processus séparé.
Plus précisément, il sépare les contrôleurs du KCM qui dépendent du cloud.
Le KCM comporte les boucles de contrôle dépendant du cloud suivantes:</p><ul><li>Contrôleur de nœud</li><li>Contrôleur de volume</li><li>Contrôleur de route</li><li>Contrôleur de service</li></ul><p>Dans la version 1.9, le CCM exécute les contrôleurs suivants de la liste précédente:</p><ul><li>Contrôleur de nœud</li><li>Contrôleur de route</li><li>Contrôleur de service</li></ul><div class="alert alert-info note callout" role=alert><strong>Note:</strong> Le contrôleur de volume a été délibérément choisi pour ne pas faire partie de CCM.
En raison de la complexité du processus et des efforts déployés pour supprimer la logique de volume spécifique au fournisseur, il a été décidé que le contrôleur de volume ne serait pas déplacé vers CCM.</div><p>Le plan initial de prise en charge des volumes à l'aide de CCM consistait à utiliser des volumes Flex pour prendre en charge des volumes pouvant être connectés.
Cependant, un effort concurrentiel appelé CSI est prévu pour remplacer Flex.</p><p>Compte tenu de cette dynamique, nous avons décidé d'avoir une mesure de transition intermédiaire jusqu'à ce que le CSI soit prêt.</p><h2 id=fonctions-du-ccm>Fonctions du CCM</h2><p>Le CCM hérite ses fonctions des composants de Kubernetes qui dépendent d'un fournisseur de cloud.
Cette section est structurée en fonction de ces composants.</p><h3 id=1-kubernetes-controller-manager>1. Kubernetes controller manager</h3><p>La majorité des fonctions du CCM sont dérivées du KCM.
Comme indiqué dans la section précédente, le CCM exécute les boucles de contrôle suivantes:</p><ul><li>Contrôleur de nœud</li><li>Contrôleur de route</li><li>Contrôleur de service</li></ul><h4 id=contrôleur-de-nœud>Contrôleur de nœud</h4><p>Le contrôleur de noeud est responsable de l'initialisation d'un noeud en obtenant des informations sur les noeuds s'exécutant dans le cluster auprès du fournisseur de cloud.
Le contrôleur de noeud exécute les fonctions suivantes:</p><ol><li>Il initialise le nœud avec des labels de zone/région spécifiques au cloud.</li><li>Il initialise le nœud avec des détails d'instance spécifiques au cloud, tels que le type et la taille de l'instance.</li><li>Il obtient les adresses réseau et le nom d'hôte du nœud.</li><li>Si un nœud ne répond plus, le controlleur vérifie avec le cloud pour voir s'il a été supprimé du cloud.
Si le nœud a été supprimé du cloud, le controlleur supprime l'objet Kubernetes Node.</li></ol><h4 id=contrôleur-de-route>Contrôleur de route</h4><p>Le contrôleur de route est responsable de la configuration appropriée des itinéraires dans le cloud afin que les conteneurs situés sur différents nœuds du cluster Kubernetes puissent communiquer entre eux.
Le contrôleur de route ne s'applique qu'aux clusters Google Compute Engine.</p><h4 id=contrôleur-de-service>Contrôleur de service</h4><p>Le contrôleur de service est chargé d'écouter les événements de création, de mise à jour et de suppression de service.
En fonction de l'état actuel des services dans Kubernetes, il configure les équilibreurs de charge dans le cloud (tels que ELB, Google LB ou Oracle Cloud Infrastructure LB) pour refléter l'état des services dans Kubernetes.
De plus, cela garantit que les services de base des services pour les load balancers dans le cloud sont à jour.</p><h3 id=2-kubelet>2. Kubelet</h3><p>Le contrôleur de noeud contient les fonctionnalités du kubelet dépendant du cloud.
Avant l'introduction du CCM, la sous-unité était responsable de l'initialisation d'un nœud avec des détails spécifiques au cloud, tels que les adresses IP, les étiquettes de région / zone et les informations de type d'instance.
L’introduction du CCM a déplacé cette opération d’initialisation du kubelet vers le CCM.</p><p>Dans ce nouveau modèle, le kubelet initialise un nœud sans informations spécifiques au cloud.
Cependant, il ajoute un marquage au nœud nouvellement créé, qui rend le nœud non planifiable jusqu'à ce que le CCM initialise le nœud avec des informations spécifiques au cloud.
Il supprime ensuite ce marquage.</p><h2 id=mécanisme-de-plugin>Mécanisme de plugin</h2><p>Le cloud controller manager utilise des interfaces Go pour autoriser la mise en œuvre d'implémentations depuis n'importe quel cloud.
Plus précisément, il utilise l'interface CloudProvider définie <a href=https://github.com/kubernetes/cloud-provider/blob/9b77dc1c384685cb732b3025ed5689dd597a5971/cloud.go#L42-L62>ici</a>.</p><p>La mise en œuvre des quatre contrôleurs partagés soulignés ci-dessus, ainsi que certaines configurations ainsi que l'interface partagée du fournisseur de cloud, resteront dans le noyau Kubernetes.
Les implémentations spécifiques aux fournisseurs de cloud seront construites en dehors du noyau et implémenteront les interfaces définies dans le noyau.</p><p>Pour plus d’informations sur le développement de plugins, consultez <a href=/docs/tasks/administer-cluster/developing-cloud-controller-manager/>Developing Cloud Controller Manager</a>.</p><h2 id=autorisation>Autorisation</h2><p>Cette section détaille les accès requis par le CCM sur divers objets API pour effectuer ses opérations.</p><h3 id=contrôleur-de-nœud-1>Contrôleur de nœud</h3><p>Le contrôleur de noeud ne fonctionne qu'avec les objets de noeud.
Il nécessite un accès complet aux objets Node via get, list, create, update, patch, watch et delete.</p><p>v1/Node:</p><ul><li>Get</li><li>List</li><li>Create</li><li>Update</li><li>Patch</li><li>Watch</li><li>Delete</li></ul><h3 id=contrôleur-de-route-1>Contrôleur de route</h3><p>Le contrôleur de route écoute les évenements de création d'objet Node et configure les routes de manière appropriée.
Cela nécessite un accès get aux objets Node.</p><p>v1/Node:</p><ul><li>Get</li></ul><h3 id=contrôleur-de-service-1>Contrôleur de Service</h3><p>Le contrôleur de service écoute les évenements de création, suppression et mises à jour des objets Service et configure les endpoints pour ces Services de manière appropriée.</p><p>Pour accéder aux Services, il faut les accès list et watch.
Pour mettre à jour les Services, il faut les accès patch et update.</p><p>Pour configurer des points de terminaison pour les services, vous devez avoir accès au create, list, get, watch, et update.</p><p>v1/Service:</p><ul><li>List</li><li>Get</li><li>Watch</li><li>Patch</li><li>Update</li></ul><h3 id=autres>Autres</h3><p>La mise en œuvre du CCM nécessite un accès pour créer des événements, et pour garantir un fonctionnement sécurisé, un accès est nécessaire pour créer ServiceAccounts.</p><p>v1/Event:</p><ul><li>Create</li><li>Patch</li><li>Update</li></ul><p>v1/ServiceAccount:</p><ul><li>Create</li></ul><p>Le ClusterRole RBAC pour le CCM ressemble à ceci:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>rbac.authorization.k8s.io/v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>ClusterRole<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>cloud-controller-manager<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>rules</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span>- <span style=color:green;font-weight:700>apiGroups</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:#b44>&#34;&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>resources</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- events<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>verbs</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- create<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- patch<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- update<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span>- <span style=color:green;font-weight:700>apiGroups</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:#b44>&#34;&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>resources</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- nodes<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>verbs</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:#b44>&#39;*&#39;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span>- <span style=color:green;font-weight:700>apiGroups</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:#b44>&#34;&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>resources</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- nodes/status<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>verbs</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- patch<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span>- <span style=color:green;font-weight:700>apiGroups</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:#b44>&#34;&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>resources</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- services<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>verbs</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- list<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- patch<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- update<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- watch<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span>- <span style=color:green;font-weight:700>apiGroups</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:#b44>&#34;&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>resources</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- serviceaccounts<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>verbs</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- create<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span>- <span style=color:green;font-weight:700>apiGroups</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:#b44>&#34;&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>resources</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- persistentvolumes<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>verbs</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- get<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- list<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- update<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- watch<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span>- <span style=color:green;font-weight:700>apiGroups</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:#b44>&#34;&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>resources</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- endpoints<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>verbs</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- create<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- get<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- list<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- watch<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- update<span style=color:#bbb>
</span></span></span></code></pre></div><h2 id=implémentations-des-fournisseurs-de-cloud>Implémentations des fournisseurs de cloud</h2><p>Les fournisseurs de cloud suivants ont implémenté leur CCM:</p><ul><li><a href=https://github.com/digitalocean/digitalocean-cloud-controller-manager>Digital Ocean</a></li><li><a href=https://github.com/oracle/oci-cloud-controller-manager>Oracle</a></li><li><a href=https://github.com/kubernetes/cloud-provider-azure>Azure</a></li><li><a href=https://github.com/kubernetes/cloud-provider-gcp>GCP</a></li><li><a href=https://github.com/kubernetes/cloud-provider-aws>AWS</a></li><li><a href=https://github.com/baidu/cloud-provider-baiducloud>BaiduCloud</a></li><li><a href=https://github.com/linode/linode-cloud-controller-manager>Linode</a></li><li><a href=https://github.com/scaleway/scaleway-cloud-controller-manager>Scaleway</a></li></ul><h2 id=administration-de-cluster>Administration de cluster</h2><p>Des instructions complètes pour la configuration et l'exécution du CCM sont fournies <a href=/docs/tasks/administer-cluster/running-cloud-controller/#cloud-controller-manager>ici</a>.</p></div><div class=td-content style=page-break-before:always><h1 id=pg-a5f7383c83ab9eb9cd0e3c4c020b3ae6>3.3 - Les conteneurs</h1><div class=lead>Conteneurs Kubernetes</div></div><div class=td-content><h1 id=pg-16042b4652ad19e565c7263824029a43>3.3.1 - Images</h1><div class=lead>Images conteneur Kubernetes</div><p>Vous créez une image Docker et la poussez dans un registre avant de la référencer depuis un pod Kubernetes.</p><p>La propriété <code>image</code> d'un conteneur utilise la même syntaxe que la commande <code>docker</code>, y compris pour les registres privés et les tags.</p><h2 id=mettre-à-jour-des-images>Mettre à jour des images</h2><p>La politique de récupération par défaut est <code>IfNotPresent</code>, Kubelet ne récupère alors pas une image si elle est déjà présente sur le nœud.
Si vous voulez forcer une récupération à chaque fois, vous pouvez faire une des actions suivantes :</p><ul><li>définissez <code>imagePullPolicy</code> du conteneur à <code>Always</code>.</li><li>omettez <code>imagePullPolicy</code> et utilisez <code>:latest</code> comme tag pour l'image à utiliser.</li><li>omettez <code>imagePullPolicy</code> et le tag de l'image à utiliser.</li><li>activez l'admission controller <a href=/docs/reference/access-authn-authz/admission-controllers/#alwayspullimages>AlwaysPullImages</a>.</li></ul><p>Notez que vous devez éviter d'utiliser le tag <code>:latest</code>, voir <a href=/docs/concepts/configuration/overview/#container-images>Bonnes pratiques pour la configuration</a> pour plus d'informations.</p><h2 id=créer-des-images-multi-architecture-à-partir-de-manifestes>Créer des images multi-architecture à partir de manifestes</h2><p>La CLI Docker prend maintenant en charge la commande <code>docker manifest</code> avec des sous-commandes comme <code>create</code>, <code>annotate</code> et <code>push</code>. Ces commandes peuvent être utilisées pour construire et pousser les manifestes. Vous pouvez utiliser <code>docker manifest inspect</code> pour voir le manifeste.</p><p>Vous pouvez voir la documentation Docker ici :
<a href=https://docs.docker.com/edge/engine/reference/commandline/manifest/>https://docs.docker.com/edge/engine/reference/commandline/manifest/</a></p><p>Voici comment nous l'utilisons dans notre outil de build:
<a href="https://cs.k8s.io/?q=docker%20manifest%20(create%7Cpush%7Cannotate)&i=nope&files=&repos=">https://cs.k8s.io/?q=docker%20manifest%20(create%7Cpush%7Cannotate)&i=nope&files=&repos=</a></p><p>Ces commandes se basent et sont implémentées purement sur la CLI Docker. Vous devrez soit éditer <code>$HOME/.docker/config.json</code> et définir la clé <code>experimental</code> à <code>enabled</code> ou vous pouvez simplement définir la variable d'environnement <code>DOCKER_CLI_EXPERIMENTAL</code> à <code>enabled</code> lorsque vous appelez les commandes de la CLI.</p><div class="alert alert-info note callout" role=alert><strong>Note:</strong> Veuillez utiliser les versions <em>18.06 ou ultérieure</em>, les versions antérieures ayant des bugs ou ne prenant pas en charge l'option <code>experimental</code> pour la ligne de commande. Par exemple <a href=https://github.com/docker/cli/issues/1135>https://github.com/docker/cli/issues/1135</a> cause des problèmes sous <code>containerd</code>.</div><p>Si vous avez des problèmes en téléchargeant des manifestes viciés, nettoyez les anciens manifestes dans <code>$HOME/.docker/manifests</code> pour recommencer de zéro.</p><p>Pour Kubernetes, nous avons historiquement utilisé des images avec des suffixes <code>-$(ARCH)</code>. Pour une rétrocompatibilité, veuillez générer les anciennes images avec des suffixes. Par exemple, l'image <code>pause</code> qui a le manifeste pour toutes les architetures et l'image <code>pause-amd64</code> qui est rétrocompatible
pour d'anciennes configurations ou des fichiers YAML qui auraient codé en dur les images avec des suffixes.</p><h2 id=utiliser-un-registre-privé>Utiliser un registre privé</h2><p>Les registres privés peuvent demander des clés pour pouvoir lire leurs images.</p><p>Ces certificats peuvent être fournis de différentes manières :</p><ul><li>En utilisant la Google Container Registry<ul><li>par cluster</li><li>automatiqueent configuré dans Google Compute Engine ou Google Kubernetes Engine</li><li>tous les pods peuvent lire le registre privé du projet</li></ul></li><li>En utilisant Amazon Elastic Container Registry (ECR)<ul><li>utilise les rôles et politiques IAM pour contrôler l'accès aux dépôts ECR</li><li>rafraîchit automatiquement les certificats de login ECR</li></ul></li><li>En utilisant Oracle Cloud Infrastructure Registry (OCIR)<ul><li>utilise les rôles et politiques IAM pour contrôler l'accès aux dépôts OCIR</li></ul></li><li>En utilisant Azure Container Registry (ACR)</li><li>En utilisant IBM Cloud Container Registry<ul><li>utilise les rôles et politiques IAM pour contrôler l'accès à l'IBM Cloud Container Registry</li></ul></li><li>En configurant les nœuds pour s'authentifier auprès d'un registre privé<ul><li>tous les pods peuvent lire les registres privés configurés</li><li>nécessite la configuration des nœuds par un administrateur du cluster</li></ul></li><li>En utilisant des images pré-chargées<ul><li>tous les pods peuvent utiliser toutes les images mises en cache sur un nœud</li><li>nécessite l'accès root à tous les nœuds pour la mise en place</li></ul></li><li>En spécifiant ImagePullSecrets dans un Pod<ul><li>seuls les pods fournissant ses propres clés peuvent accéder au registre privé</li></ul></li></ul><p>Chaque option est décrite plus en détails ci-dessous.</p><h3 id=utiliser-la-google-container-registry>Utiliser la Google Container Registry</h3><p>Kubernetes prend en charge nativement la <a href=https://cloud.google.com/tools/container-registry/>Google Container
Registry (GCR)</a>, lorsqu'il s'exécute dans Google Compute
Engine (GCE). Si vous exécutez votre cluster dans GCE ou Google Kubernetes Engine, utilisez simplement le nom complet de l'image (par ex. gcr.io/my_project/image:tag).</p><p>Tous les pods dans un cluster auront un accès en lecture aux images dans le registre.</p><p>Kubelet va s'authentifier auprès de GCR en utilisant le compte de service Google de l'instance.
Le compte de service dans l'instance aura un <code>https://www.googleapis.com/auth/devstorage.read_only</code>,
afin qu'il puisse récupérer depuis le GCR du projet mais qu'il ne puisse pas pousser une image.</p><h3 id=utiliser-amazon-elastic-container-registry>Utiliser Amazon Elastic Container Registry</h3><p>Kubernetes prend en charge nativement <a href=https://aws.amazon.com/ecr/>Amazon Elastic Container Registry</a>, lorsque les nœuds sont des instances de AWS EC2.</p><p>Utilisez simplement le nom complet de l'image (par ex. <code>ACCOUNT.dkr.ecr.REGION.amazonaws.com/imagename:tag</code>)
dans la définition du Pod.</p><p>Tous les utilisateurs du cluster qui peuvent créer des pods auront la possibilité
d'exécuter des pods qui utilisent n'importe quelle image du registre ECR.</p><p>Kubelet va aller chercher et rafraîchir périodiquement les certificats ECR. Les permissions suivantes sont requises par kubelet :</p><ul><li><code>ecr:GetAuthorizationToken</code></li><li><code>ecr:BatchCheckLayerAvailability</code></li><li><code>ecr:GetDownloadUrlForLayer</code></li><li><code>ecr:GetRepositoryPolicy</code></li><li><code>ecr:DescribeRepositories</code></li><li><code>ecr:ListImages</code></li><li><code>ecr:BatchGetImage</code></li></ul><p>Exigences :</p><ul><li>Vous devez utiliser kubelet version <code>v1.2.0</code> ou ultérieure. (exécutez par ex. <code>/usr/bin/kubelet --version=true</code>).</li><li>Si vos nœuds sont dans une région différente de votre registre, vous devez utiliser la version <code>v1.3.0</code> ou ultérieure.</li><li>ECR doit être disponible dans votre région.</li></ul><p>Dépannage :</p><ul><li>Vérifiez toutes les exigences ci-dessus.</li><li>Copiez les certificats de $REGION (par ex. <code>us-west-2</code>) sur votre poste de travail. Connectez-vous en SSH sur l'hôte et exécutez Docker manuellement avec ces certificats. Est-ce que ça marche ?</li><li>Vérifiez que kubelet s'exécute avec <code>--cloud-provider=aws</code>.</li><li>Augmentez la verbosité des logs de kubelet à au moins 3 et recherchez dans les logs de kubelet (par exemple avec <code>journalctl -u kubelet</code>) des lignes similaires à :</li></ul><ul><li><ul><li><code>aws_credentials.go:109] unable to get ECR credentials from cache, checking ECR API</code></li></ul></li><li><ul><li><code>aws_credentials.go:116] Got ECR credentials from ECR API for &lt;AWS account ID for ECR>.dkr.ecr.&lt;AWS region>.amazonaws.com</code></li></ul></li></ul><h3 id=utiliser-azure-container-registry-acr>Utiliser Azure Container Registry (ACR)</h3><p>En utilisant <a href=https://azure.microsoft.com/en-us/services/container-registry/>Azure Container Registry</a>
vous pouvez vous authentifier en utilisant soit un utilisateur admin soit un service principal.
Dans les deux cas, l'authentification est faite via l'authentification standard de Docker. Ces instructions assument l'outil en ligne de commande <a href=https://github.com/azure/azure-cli>azure-cli</a>.</p><p>Vous devez d'abord créer un registre et générer des certificats, la documentation complète pour cela peut être touvée dans la <a href=https://docs.microsoft.com/en-us/azure/container-registry/container-registry-get-started-azure-cli>documentation de Azure container registry</a>.</p><p>Une fois votre registre de conteneurs créé, vous utiliserez les certificats suivants pour vous connecter :</p><ul><li><code>DOCKER_USER</code> : service principal ou utilisateur admin</li><li><code>DOCKER_PASSWORD</code>: mot de passe du service principal ou utilisateur admin</li><li><code>DOCKER_REGISTRY_SERVER</code>: <code>${un-nom-de-registre}.azurecr.io</code></li><li><code>DOCKER_EMAIL</code>: <code>${une-adresse-email}</code></li></ul><p>Une fois que vous avez défini ces variables, vous pouvez
<a href=/docs/concepts/containers/images/#specifying-imagepullsecrets-on-a-pod>configurer un Secret Kubernetes et l'utiliser pour déployer un Pod</a>.</p><h3 id=utiliser-ibm-cloud-container-registry>Utiliser IBM Cloud Container Registry</h3><p>IBM Cloud Container Registry fournit un registre d'images multi-tenant privé que vous pouvez utiliser pour stocker et partager de manière sécurisée vos images. Par défaut, les images de votre registre privé sont scannées par le Vulnerability Advisor intégré pour détecter des failles de sécurité et des vulnérabilités potentielles. Les utilisateurs de votre compte IBM Cloud peuvent accéder à vos images, ou vous pouvez des rôles et politiques IAM pour fournir l'accès aux namespaces de l'IBM Cloud Container Registry.</p><p>Pour installer le plugin du CLI de IBM Cloud Container Registry et créer un namespace pour vos images, voir <a href="https://cloud.ibm.com/docs/Registry?topic=registry-getting-started">Débuter avec IBM Cloud Container Registry</a>.</p><p>Si vous utilisez le même compte et la même région, vous pouvez déployer des images stockées dans IBM Cloud Container Registry vers la namespace <code>default</code> de votre cluster IBM Cloud Kubernetes Service sans configuration supplémentaire, voir <a href="https://cloud.ibm.com/docs/containers?topic=containers-images">Construire des conteneurs à partir d'images</a>. Pour les autres options de configuration, voir <a href="https://cloud.ibm.com/docs/containers?topic=containers-registry#cluster_registry_auth">Comprendre comment autoriser votre cluster à télécharger des images depuis un registre</a>.</p><h3 id=configurer-les-nœuds-pour-s-authentifier-auprès-d-un-registre-privé>Configurer les nœuds pour s'authentifier auprès d'un registre privé</h3><div class="alert alert-info note callout" role=alert><strong>Note:</strong> Si vous travaillez dans Google Kubernetes Engine, vous trouverez un <code>.dockercfg</code> sur chaque nœud avec les certificats pour Google Container Registry. Vous ne pourrez pas utiliser cette méthode.</div><div class="alert alert-info note callout" role=alert><strong>Note:</strong> Si vous travaillez dans AWS EC2 et utilisez EC2 Container Registry (ECR), kubelet sur chaque nœud va gérer et mettre à jour les certificats du login ECR. Vous ne pourrez pas utiliser cette méthode.</div><div class="alert alert-info note callout" role=alert><strong>Note:</strong> Cette méthode est utilisable si vous avez le contrôle sur la configuration des nœuds. Elle ne marchera pas
correctement sur GCE, et sur tout autre fournisseur cloud qui fait du remplacement de nœud automatique.</div><div class="alert alert-info note callout" role=alert><strong>Note:</strong> Kubernetes prend pour l'instant en charge uniquement les sections <code>auths</code> et <code>HttpHeaders</code> de la config docker. Cela veut dire que les aides aux certificats (<code>credHelpers</code> ou <code>credsStore</code>) ne sont pas pris en charge.</div><p>Docker stocke les clés pour les regisres privés dans le fichier <code>$HOME/.dockercfg</code> ou <code>$HOME/.docker/config.json</code>. Si vous placez le même fichier dans un des chemins de recherche ci-dessous, kubelet l'utilise comme fournisseur de clés lorsque les images sont récupérées.</p><ul><li><code>{--root-dir:-/var/lib/kubelet}/config.json</code></li><li><code>{cwd of kubelet}/config.json</code></li><li><code>${HOME}/.docker/config.json</code></li><li><code>/.docker/config.json</code></li><li><code>{--root-dir:-/var/lib/kubelet}/.dockercfg</code></li><li><code>{cwd of kubelet}/.dockercfg</code></li><li><code>${HOME}/.dockercfg</code></li><li><code>/.dockercfg</code></li></ul><div class="alert alert-info note callout" role=alert><strong>Note:</strong> Vous pouvez avoir à définir <code>HOME=/root</code> explicitement dans votre fichier d'environnement pour kubelet.</div><p>Voici les étapes recommandées pour configurer vos nœuds pour qu'ils utilisent un registre privé. Dans cet exemple, exécutez-les sur votre poste de travail :</p><ol><li>Exécutez <code>docker login [server]</code> pour chaque jeu de certificats que vous désirez utiliser. Ceci met à jour <code>$HOME/.docker/config.json</code>.</li><li>Examinez <code>$HOME/.docker/config.json</code> dans un éditeur pour vous assurer qu'il contient uniquement les certificats que vous désirez utiliser.</li><li>Récupérez la liste de vos nœuds, par exemple :<ul><li>si vous voulez connaître les noms : <code>nodes=$(kubectl get nodes -o jsonpath='{range.items[*].metadata}{.name} {end}')</code></li><li>si vous voulez connaître les IPs : <code>nodes=$(kubectl get nodes -o jsonpath='{range .items[*].status.addresses[?(@.type=="ExternalIP")]}{.address} {end}')</code></li></ul></li><li>Copiez votre fichier <code>.docker/config.json</code> local dans un des chemins de recherche ci-dessus.<ul><li>par exemple : <code>for n in $nodes; do scp ~/.docker/config.json root@$n:/var/lib/kubelet/config.json; done</code></li></ul></li></ol><p>Vérifiez en créant un pod utilisant une image privée, par ex. :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl apply -f - <span style=color:#b44>&lt;&lt;EOF
</span></span></span><span style=display:flex><span><span style=color:#b44>apiVersion: v1
</span></span></span><span style=display:flex><span><span style=color:#b44>kind: Pod
</span></span></span><span style=display:flex><span><span style=color:#b44>metadata:
</span></span></span><span style=display:flex><span><span style=color:#b44>  name: test-image-privee-1
</span></span></span><span style=display:flex><span><span style=color:#b44>spec:
</span></span></span><span style=display:flex><span><span style=color:#b44>  containers:
</span></span></span><span style=display:flex><span><span style=color:#b44>    - name: utilise-image-privee
</span></span></span><span style=display:flex><span><span style=color:#b44>      image: $NOM_IMAGE_PRIVEE
</span></span></span><span style=display:flex><span><span style=color:#b44>      imagePullPolicy: Always
</span></span></span><span style=display:flex><span><span style=color:#b44>      command: [ &#34;echo&#34;, &#34;SUCCESS&#34; ]
</span></span></span><span style=display:flex><span><span style=color:#b44>EOF</span>
</span></span></code></pre></div><pre tabindex=0><code>pod/test-image-privee-1 created
</code></pre><p>Si tout fonctionne, alors, après quelques instants, vous pouvez exécuter :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl logs test-image-privee-1
</span></span></code></pre></div><p>et voir que la commande affiche :</p><pre tabindex=0><code>SUCCESS
</code></pre><p>Si vous suspectez que la commande a échouée, vous pouvez exécuter :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl describe pods/test-image-privee-1 | grep <span style=color:#b44>&#39;Failed&#39;</span>
</span></span></code></pre></div><p>En cas d'échec, l'affichage sera similaire à :</p><pre tabindex=0><code>  Fri, 26 Jun 2015 15:36:13 -0700    Fri, 26 Jun 2015 15:39:13 -0700    19    {kubelet node-i2hq}    spec.containers{uses-private-image}    failed        Failed to pull image &#34;user/privaterepo:v1&#34;: Error: image user/privaterepo:v1 not found
</code></pre><p>Vous devez vous assurer que tous les nœuds du cluster ont le même fichier <code>.docker/config.json</code>. Dans le cas contraire, les pods vont s'exécuter sur certains nœuds et échouer sur d'autres. Par exemple, si vous utilisez l'autoscaling des nœuds, alors chaque modèle d'instance doit inclure le fichier <code>.docker/config.json</code> ou monter un disque le contenant.</p><p>Tous les pods auront un accès en lecture aux images d'un registre privé dès que les clés du registre privé sont ajoutées au fichier <code>.docker/config.json</code>.</p><h3 id=images-pré-chargées>Images pré-chargées</h3><div class="alert alert-info note callout" role=alert><strong>Note:</strong> Si vous travaillez dans Google Kubernetes Engine, vous trouverez un <code>.dockercfg</code> sur chaque nœud avec les certificats pour Google Container Registry. Vous ne pourrez pas utiliser cette méthode.</div><div class="alert alert-info note callout" role=alert><strong>Note:</strong> Cette méthode est utilisable si vous avez le contrôle sur la configuration des nœuds. Elle ne marchera pas
correctement sur GCE, et sur tout autre fournisseur cloud qui fait du remplacement de nœud automatique.</div><p>Par défaut, kubelet essaiera de récupérer chaque image depuis le registre spécifié.
Cependant, si la propriété <code>imagePullPolicy</code> du conteneur est <code>IfNotPresent</code> ou <code>Never</code>,
alors une image locale est utilisée (respectivement de préférence ou exclusivement).</p><p>Si vous désirez vous reposer sur des images pré-chargées pour éviter l'authentification à un registre,
vous devez vous assurer que tous les nœuds du cluster ont les mêmes images pré-chargées.</p><p>Ceci peut être utilisé pour pré-charger certaines images pour gagner du temps, ou comme une alternative à l'authentification à un registre privé.</p><p>Tous les pods auront un accès en lecture aux images pré-chargées.</p><h3 id=spécifier-imagepullsecrets-dans-un-pod>Spécifier ImagePullSecrets dans un Pod</h3><div class="alert alert-info note callout" role=alert><strong>Note:</strong> Cette méthode est actuellement la méthode recommandée pour Google Kubernetes Engine, GCE, et tout autre fournisseur de cloud où la création de nœuds est automatisée.</div><p>Kubernetes permet de spécifier des clés de registre dans un pod.</p><h4 id=créer-un-secret-avec-une-config-docker>Créer un Secret avec une config Docker</h4><p>Exécutez la commande suivante, en substituant les valeurs en majuscule :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl create secret docker-registry &lt;name&gt; --docker-server<span style=color:#666>=</span>SERVEUR_REGISTRE_DOCKER --docker-username<span style=color:#666>=</span>UTILISATEUR_DOCKER --docker-password<span style=color:#666>=</span>MOT_DE_PASSE_DOCKER --docker-email<span style=color:#666>=</span>EMAIL_DOCKER
</span></span><span style=display:flex><span>secret/myregistrykey created.
</span></span></code></pre></div><p>Si vous avez déjà un fichier de clés Docker, alors, plutôt que d'utiliser la commande ci-dessus,
vous pouvez importer le fichier de clés comme un Secret Kubernetes.
<a href=/docs/tasks/configure-pod-container/pull-image-private-registry/#registry-secret-existing-credentials>Créer un Secret basé sur des clés Docker existantes</a> explique comment s'y prendre.
Ceci est particulièrement utile si vous utilisez plusieurs registres privés, <code>kubectl create secret docker-registry</code> créant un Secret ne fonctionnant qu'avec un seul registre privé.</p><div class="alert alert-info note callout" role=alert><strong>Note:</strong> Les pods peuvent référencer des pull secrets dans leur propre namespace uniquement,
ces étapes doivent donc être faites pour chaque namespace.</div><h4 id=se-référer-à-un-imagepullsecrets-dans-un-pod>Se référer à un imagePullSecrets dans un Pod</h4><p>Vous pouvez maintenant créer des pods qui référencent ce secret en ajoutant une section <code>imagePullSecrets</code>
dans la définition du pod.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>cat <span style=color:#b44>&lt;&lt;EOF &gt; pod.yaml
</span></span></span><span style=display:flex><span><span style=color:#b44>apiVersion: v1
</span></span></span><span style=display:flex><span><span style=color:#b44>kind: Pod
</span></span></span><span style=display:flex><span><span style=color:#b44>metadata:
</span></span></span><span style=display:flex><span><span style=color:#b44>  name: foo
</span></span></span><span style=display:flex><span><span style=color:#b44>  namespace: awesomeapps
</span></span></span><span style=display:flex><span><span style=color:#b44>spec:
</span></span></span><span style=display:flex><span><span style=color:#b44>  containers:
</span></span></span><span style=display:flex><span><span style=color:#b44>    - name: foo
</span></span></span><span style=display:flex><span><span style=color:#b44>      image: janedoe/awesomeapp:v1
</span></span></span><span style=display:flex><span><span style=color:#b44>  imagePullSecrets:
</span></span></span><span style=display:flex><span><span style=color:#b44>    - name: myregistrykey
</span></span></span><span style=display:flex><span><span style=color:#b44>EOF</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>cat <span style=color:#b44>&lt;&lt;EOF &gt;&gt; ./kustomization.yaml
</span></span></span><span style=display:flex><span><span style=color:#b44>resources:
</span></span></span><span style=display:flex><span><span style=color:#b44>- pod.yaml
</span></span></span><span style=display:flex><span><span style=color:#b44>EOF</span>
</span></span></code></pre></div><p>Ceci doit être fait pour chaque pod utilisant un registre privé.</p><p>Cependant, la définition de ce champ peut être automatisé en définissant <code>imagePullSecrets</code>
dans une ressource <a href=/docs/user-guide/service-accounts>serviceAccount</a>.
Voyez <a href=/docs/tasks/configure-pod-container/configure-service-account/#add-imagepullsecrets-to-a-service-account>Ajouter un ImagePullSecrets à un Service Account</a> pour des instructions détaillées.</p><p>Vous pouvez utiliser cette méthode en conjonction avec un <code>.docker/config.json</code> par nœud. Les certificats seront alors regroupés. Cette approche fonctionnera dans Google Kubernetes Engine.</p><h3 id=cas-d-utilisation>Cas d'utilisation</h3><p>Il y a plusieurs solutions pour configurer des registres privés. Voici quelques cas d'utilisation classiques et des propositions de solutions.</p><ol><li>Cluster exécutant uniquement des images non propriétaires (par ex. open-source). Inutile de protéger les images.<ul><li>Utilisez des images publiques dans le Hub Docker.<ul><li>Pas de configuration requise.</li><li>Dans GCE/Google Kubernetes Engine, un miroir local est automatiquement utilisé pour améliorer la vitesse et la disponibilité.</li></ul></li></ul></li><li>Cluster exécutant quelques images propriétaires qui doivent être protégées de l'extérieur de l'entreprise, mais visibles pour tous les utilisteurs du cluster.<ul><li>Utilisez un <a href=https://docs.docker.com/registry/>registre Docker</a> hébergé privé.<ul><li>Il peut être hébergé sur le <a href=https://hub.docker.com/signup>Hub Docker</a>, ou ailleurs.</li><li>Configurez manuellement .docker/config.json sur caque nœud comme décrit ci-dessus.</li></ul></li><li>Ou, utilisez un registre privé interne derrière votre pare-feu avec un accès ouvert en lecture.<ul><li>Aucune configuration Kubernetes n'est nécessaire.</li></ul></li><li>Ou, dans GCE/Google Kubernetes Engine, utilisez le Google Container Registry du projet.<ul><li>Cela fonctionnera mieux pour l'autoscaling du cluster que la configuration manuelle des nœuds.</li></ul></li><li>Ou, dans un cluster où le changement de la configuration des nœuds est difficile, utilisez <code>imagePullSecrets</code>.</li></ul></li><li>Cluster avec des images propriétaires, dont quelques-unes nécessitent un contrôle d'accès plus strict.<ul><li>Assurez-vous que <a href=/docs/reference/access-authn-authz/admission-controllers/#alwayspullimages>l'admission controller AlwaysPullImages</a> est actif. Autrement, tous les Pods ont potentiellement accès à toutes les images.</li><li>Déplacez les données sensibles dans une ressource "Secret", plutôt que de les intégrer dans une image.</li></ul></li><li>Un cluster multi-tenant où chaque <em>tenant</em> doit avoir son propre registre privé.<ul><li>Assurez-vous que <a href=/docs/reference/access-authn-authz/admission-controllers/#alwayspullimages>l'admission controller AlwaysPullImages</a> est actif. Autrement, tous les Pods ont potentiellement accès à toutes les images.</li><li>Utilisez un registre privé nécessitant l'autorisation.</li><li>Générez des certificats de registre pour chaque <em>tenant</em>, placez-les dans des secrets, et placez ces secrets dans les namespaces de chaque <em>tenant</em>.
pod - Le <em>tenant</em> ajoute ce secret dans les imagePullSecrets de chaque pod.</li></ul></li></ol><p>Si vous devez accéder à plusieurs registres, vous pouvez créer un secret pour chaque registre.
Kubelet va fusionner tous les <code>imagePullSecrets</code> dans un unique <code>.docker/config.json</code> virtuel.</p></div><div class=td-content style=page-break-before:always><h1 id=pg-a858027489648786a3b16264e451272b>3.3.2 - Classe d'exécution (Runtime Class)</h1><div class=lead>Classe d'execution conteneur pour Kubernetes</div><div style=margin-top:10px;margin-bottom:10px><b>FEATURE STATE:</b> <code>Kubernetes v1.12 [alpha]</code></div><p>Cette page décrit la ressource RuntimeClass et le mécanisme de sélection d'exécution (runtime).</p><h2 id=runtime-class>Runtime Class</h2><p>La RuntimeClass est une fonctionnalité alpha permettant de sélectionner la configuration d'exécution du conteneur
à utiliser pour exécuter les conteneurs d'un pod.</p><h3 id=installation>Installation</h3><p>En tant que nouvelle fonctionnalité alpha, certaines étapes de configuration supplémentaires doivent
être suivies pour utiliser la RuntimeClass:</p><ol><li>Activer la fonctionnalité RuntimeClass (sur les apiservers et les kubelets, nécessite la version 1.12+)</li><li>Installer la RuntimeClass CRD</li><li>Configurer l'implémentation CRI sur les nœuds (dépend du runtime)</li><li>Créer les ressources RuntimeClass correspondantes</li></ol><h4 id=1-activer-runtimeclass-feature-gate-portail-de-fonctionnalité>1. Activer RuntimeClass feature gate (portail de fonctionnalité)</h4><p>Voir <a href=/docs/reference/command-line-tools-reference/feature-gates/>Feature Gates</a> pour une explication
sur l'activation des feature gates. La <code>RuntimeClass</code> feature gate doit être activée sur les API servers <em>et</em>
les kubelets.</p><h4 id=2-installer-la-crd-runtimeclass>2. Installer la CRD RuntimeClass</h4><p>La RuntimeClass <a href=/docs/tasks/access-kubernetes-api/custom-resources/custom-resource-definitions/>CustomResourceDefinition</a> (CRD) se trouve dans le répertoire addons du dépôt
Git Kubernetes: <a href=https://github.com/kubernetes/kubernetes/tree/master/cluster/addons/runtimeclass/runtimeclass_crd.yaml>kubernetes/cluster/addons/runtimeclass/runtimeclass_crd.yaml</a></p><p>Installer la CRD avec <code>kubectl apply -f runtimeclass_crd.yaml</code>.</p><h4 id=3-configurer-l-implémentation-cri-sur-les-nœuds>3. Configurer l'implémentation CRI sur les nœuds</h4><p>Les configurations à sélectionner avec RuntimeClass dépendent de l'implémentation CRI. Consultez
la documentation correspondante pour votre implémentation CRI pour savoir comment le configurer.
Comme c'est une fonctionnalité alpha, tous les CRI ne prennent pas encore en charge plusieurs RuntimeClasses.</p><div class="alert alert-info note callout" role=alert><strong>Note:</strong> La RuntimeClass suppose actuellement une configuration de nœud homogène sur l'ensemble du cluster
(ce qui signifie que tous les nœuds sont configurés de la même manière en ce qui concerne les environnements d'exécution de conteneur). Toute hétérogénéité (configuration variable) doit être
gérée indépendamment de RuntimeClass via des fonctions de planification (scheduling features) (voir <a href=/docs/concepts/configuration/assign-pod-node/>Affectation de pods sur les nœuds</a>).</div><p>Les configurations ont un nom <code>RuntimeHandler</code> correspondant , référencé par la RuntimeClass.
Le RuntimeHandler doit être un sous-domaine DNS valide selon la norme RFC 1123 (alphanumériques + <code>-</code> et <code>.</code> caractères).</p><h4 id=4-créer-les-ressources-runtimeclass-correspondantes>4. Créer les ressources RuntimeClass correspondantes</h4><p>Les configurations effectuées à l'étape 3 doivent chacune avoir un nom <code>RuntimeHandler</code> associé, qui
identifie la configuration. Pour chaque RuntimeHandler (et optionellement les handlers vides <code>""</code>),
créez un objet RuntimeClass correspondant.</p><p>La ressource RuntimeClass ne contient actuellement que 2 champs significatifs: le nom RuntimeClass
(<code>metadata.name</code>) et le RuntimeHandler (<code>spec.runtimeHandler</code>). la définition de l'objet ressemble à ceci:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>node.k8s.io/v1alpha1 <span style=color:#bbb> </span><span style=color:#080;font-style:italic># La RuntimeClass est définie dans le groupe d&#39;API node.k8s.io</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>RuntimeClass<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>myclass <span style=color:#bbb> </span><span style=color:#080;font-style:italic># Le nom avec lequel la RuntimeClass sera référencée</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:#080;font-style:italic># La RuntimeClass est une ressource non cantonnées à un namespace</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>runtimeHandler</span>:<span style=color:#bbb> </span>myconfiguration <span style=color:#bbb> </span><span style=color:#080;font-style:italic># Le nom de la configuration CRI correspondante</span><span style=color:#bbb>
</span></span></span></code></pre></div><div class="alert alert-info note callout" role=alert><strong>Note:</strong> Il est recommandé de limiter les opérations d'écriture sur la RuntimeClass (create/update/patch/delete) à
l'administrateur du cluster. C'est la configuration par défault. Voir <a href=/docs/reference/access-authn-authz/authorization/>Vue d'ensemble d'autorisation</a> pour plus de détails.</div><h3 id=usage>Usage</h3><p>Une fois que les RuntimeClasses sont configurées pour le cluster, leur utilisation est très simple.
Spécifiez <code>runtimeClassName</code> dans la spécficiation du pod. Par exemple:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>mypod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>runtimeClassName</span>:<span style=color:#bbb> </span>myclass<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:#080;font-style:italic># ...</span><span style=color:#bbb>
</span></span></span></code></pre></div><p>Cela indiquera à la kubelet d'utiliser la RuntimeClass spécifiée pour exécuter ce pod. Si la
RuntimeClass n'existe pas, ou si la CRI ne peut pas exécuter le handler correspondant, le pod passera finalement à
<a href=/docs/concepts/workloads/pods/pod-lifecycle/#pod-phase>l'état</a> <code>failed</code>. Recherchez
<a href=/docs/tasks/debug-application-cluster/debug-application-introspection/>l'événement</a> correspondant pour un
message d'erreur.</p><p>Si aucun <code>runtimeClassName</code> n'est spécifié, le RuntimeHandler par défault sera utilisé, qui équivaut
au comportement lorsque la fonctionnalité RuntimeClass est désactivée.</p></div><div class=td-content style=page-break-before:always><h1 id=pg-643212488f778acf04bebed65ba34441>3.3.3 - L'environnement du conteneur</h1><div class=lead>L'environnement du conteneur Kubernetes</div><p>Cette page décrit les ressources disponibles pour les conteneurs dans l'environnement de conteneur.</p><h2 id=l-environnement-du-conteneur>L'environnement du conteneur</h2><p>L’environnement Kubernetes conteneur fournit plusieurs ressources importantes aux conteneurs:</p><ul><li>Un système de fichier, qui est une combinaison d'une <a href=/docs/concepts/containers/images/>image</a> et un ou plusieurs <a href=/docs/concepts/storage/volumes/>volumes</a>.</li><li>Informations sur le conteneur lui-même.</li><li>Informations sur les autres objets du cluster.</li></ul><h3 id=informations-sur-le-conteneur>Informations sur le conteneur</h3><p>Le nom d'<em>hôte</em> d'un conteneur est le nom du pod dans lequel le conteneur est en cours d'exécution.
Il est disponible via la commande <code>hostname</code> ou
<a href=http://man7.org/linux/man-pages/man2/gethostname.2.html><code>gethostname</code></a>
dans libc.</p><p>Le nom du pod et le namespace sont disponibles en tant que variables d'environnement via
<a href=/docs/tasks/inject-data-application/downward-api-volume-expose-pod-information/>l'API downward</a>.</p><p>Les variables d'environnement définies par l'utilisateur à partir de la définition de pod sont également disponibles pour le conteneur,
de même que toutes les variables d'environnement spécifiées de manière statique dans l'image Docker.</p><h3 id=informations-sur-le-cluster>Informations sur le cluster</h3><p>Une liste de tous les services en cours d'exécution lors de la création d'un conteneur est disponible pour ce conteneur en tant que variables d'environnement.
Ces variables d'environnement correspondent à la syntaxe des liens Docker.</p><p>Pour un service nommé <em>foo</em> qui correspond à un conteneur <em>bar</em>,
les variables suivantes sont définies:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span><span style=color:#b8860b>FOO_SERVICE_HOST</span><span style=color:#666>=</span>&lt;l<span>&#39;</span>hôte sur lequel le service est exécuté&gt;
</span></span><span style=display:flex><span><span style=color:#b8860b>FOO_SERVICE_PORT</span><span style=color:#666>=</span>&lt;le port sur lequel le service fonctionne&gt;
</span></span></code></pre></div><p>Les services ont des adresses IP dédiées et sont disponibles pour le conteneur avec le DNS,
si le <a href=http://releases.k8s.io/master/cluster/addons/dns/>module DNS</a> est activé. </p><h2 id=a-suivre>A suivre</h2><ul><li>En savoir plus sur <a href=/docs/concepts/containers/container-lifecycle-hooks/>les hooks du cycle de vie d'un conteneur</a>.</li><li>Acquérir une expérience pratique
<a href=/docs/tasks/configure-pod-container/attach-handler-lifecycle-event/>en attachant les handlers aux événements du cycle de vie du conteneur</a>.</li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-e6941d969d81540208a3e78bc56f43bc>3.3.4 - Hooks de cycle de vie de conteneurs</h1><p>Cette page décrit comment un conteneur pris en charge par kubelet peut utiliser
le framework de Hooks de cycle de vie de conteneurs pour exécuter du code déclenché par des
événements durant son cycle de vie.</p><h2 id=aperçu>Aperçu</h2><p>De manière similaire à quantité de frameworks de langages de programmation qui ont des hooks
de cycle de vie de composants, comme Angular, Kubernetes fournit aux conteneurs
des hooks de cycle de vie.
Les hooks permettent à un conteneur d'être au courant d'événements durant son cycle de vie
et d'exécuter du code implémenté dans un handler lorsque le hook de cycle de vie correspondant
est exécuté.</p><h2 id=hooks-de-conteneurs>Hooks de conteneurs</h2><p>Il existe deux hooks exposés aux conteneurs :</p><p><code>PostStart</code></p><p>Ce hook s'exécute immédiatement après qu'un conteneur soit créé.
Cependant, il n'y a aucune garantie que le hook s'exécute avant l'ENTRYPOINT du conteneur.
Aucun paramètre n'est passé au handler.</p><p><code>PreStop</code></p><p>Ce hook est appelé immédiatement avant qu'un conteneur se termine, en raison d'un appel à l'API
ou d'un événement comme un échec de la liveness probe, un droit de préemption, un conflit de ressources ou autres.
Un appel au hook preStop échoue si le conteneur est déjà dans l'état terminé ou complété.
Il est bloquant, ce qui veut dire qu'il est synchrone, et doit donc se terminer avant que l'appel pour supprimer le conteneur soit envoyé.
Aucun paramètre n'est passé au handler.</p><p>Une description plus précise du comportement de l'arrêt peut être trouvé dans
<a href=/fr/docs/concepts/workloads/pods/pod/#arr%C3%AAt-de-pods>Arrêt de Pods</a>.</p><h3 id=implémentation-d-un-handler-de-hook>Implémentation d'un handler de hook</h3><p>Les conteneurs peuvent accéder à un hook en implémentant et enregistrant un handler pour ce hook.
Il existe deux types de handlers de hook pouvant être implémentés pour des conteneurs :</p><ul><li>Exec - Exécute une commande donnée, comme <code>pre-stop.sh</code>, dans les cgroups et namespaces du conteneur.
Les ressources consommées par la commande sont comptabilisées pour le conteneur.</li><li>HTTP - Exécute une requête HTTP sur un endpoint spécifique du conteneur.</li></ul><h3 id=exécution-d-un-handler-de-hook>Exécution d'un handler de hook</h3><p>Lorsqu'un hook de cycle de vie de conteneur est appelé,
le système de gestion de Kubernetes exécute le handler dans le conteneur enregistré
pour ce hook.</p><p>Les appels aux handlers de hook sont synchrones dans le contexte du pod contenant le conteneur.
Ceci veut dire que pour un hook <code>PostStart</code>,
bien que l'ENTRYPOINT du conteneur et le hook soient lancés de manière asynchrone, si le hook prend trop de temps à s'exécuter ou se bloque,
le conteneur ne peut pas atteindre l'état <code>running</code>.</p><p>Le comportement est similaire pour un hook <code>PreStop</code>.
Si le hook se bloque durant l'exécution,
la phase du Pod reste en état <code>Terminating</code> et le hook est tué après <code>terminationGracePeriodSeconds</code> que le pod se termine.
Si un hook <code>PostStart</code> ou <code>PreStop</code> échoue,
le conteneur est tué.</p><p>Les utilisateurs doivent rendre leurs handlers de hook aussi légers que possible.
Il existe des cas, cependant, où de longues commandes ont un intérêt,
comme pour enregistrer un état avant de stopper un conteneur.</p><h3 id=garanties-de-déclenchement-d-un-hook>Garanties de déclenchement d'un hook</h3><p>La politique de déclenchement d'un hook est <em>au moins une fois</em>,
ce qui veut dire qu'un hook peut être déclenché plus d'une fois pour un événement donné,
comme <code>PostStart</code> ou <code>PreStop</code>.
Il appartient à l'implémentation du hook de prendre en compte correctement ce comportement.</p><p>En général, un seul déclenchement est fait.
Si, par exemple, un récepteur de hook HTTP est hors service et ne peut pas
prendre en charge du trafic, il n'y a aucune tentative de renvoi.
Dans quelques rares cas, cependant, un double envoi peut se produire.
Par exemple, si kubelet redémarre au milieu d'un déclenchement de hook,
le hook pourrait être re-déclenché après que kubelet redémarre.</p><h3 id=débugger-des-handlers-de-hook>Débugger des handlers de hook</h3><p>Les logs pour un handler de hook ne sont pas exposés dans les événements du Pod.
Si un handler échoue pour une raison particulière, il envoie un événement.
Pour <code>PostStart</code>, c'est l'événement <code>FailedPostStartHook</code>
et pour <code>PreStop</code>, c'est l'événement <code>FailedPreStopHook</code>.
Vous pouvez voir ces événements en exécutant <code>kubectl describe pod &lt;pod_name></code>.
Voici un exemple d'affichage d'événements lors de l'exécution de cette commande :</p><pre tabindex=0><code>Events:
  FirstSeen  LastSeen  Count  From                                                   SubObjectPath          Type      Reason               Message
  ---------  --------  -----  ----                                                   -------------          --------  ------               -------
  1m         1m        1      {default-scheduler }                                                          Normal    Scheduled            Successfully assigned test-1730497541-cq1d2 to gke-test-cluster-default-pool-a07e5d30-siqd
  1m         1m        1      {kubelet gke-test-cluster-default-pool-a07e5d30-siqd}  spec.containers{main}  Normal    Pulling              pulling image &#34;test:1.0&#34;
  1m         1m        1      {kubelet gke-test-cluster-default-pool-a07e5d30-siqd}  spec.containers{main}  Normal    Created              Created container with docker id 5c6a256a2567; Security:[seccomp=unconfined]
  1m         1m        1      {kubelet gke-test-cluster-default-pool-a07e5d30-siqd}  spec.containers{main}  Normal    Pulled               Successfully pulled image &#34;test:1.0&#34;
  1m         1m        1      {kubelet gke-test-cluster-default-pool-a07e5d30-siqd}  spec.containers{main}  Normal    Started              Started container with docker id 5c6a256a2567
  38s        38s       1      {kubelet gke-test-cluster-default-pool-a07e5d30-siqd}  spec.containers{main}  Normal    Killing              Killing container with docker id 5c6a256a2567: PostStart handler: Error executing in Docker Container: 1
  37s        37s       1      {kubelet gke-test-cluster-default-pool-a07e5d30-siqd}  spec.containers{main}  Normal    Killing              Killing container with docker id 8df9fdfd7054: PostStart handler: Error executing in Docker Container: 1
  38s        37s       2      {kubelet gke-test-cluster-default-pool-a07e5d30-siqd}                         Warning   FailedSync           Error syncing pod, skipping: failed to &#34;StartContainer&#34; for &#34;main&#34; with RunContainerError: &#34;PostStart handler: Error executing in Docker Container: 1&#34;
  1m         22s       2      {kubelet gke-test-cluster-default-pool-a07e5d30-siqd}  spec.containers{main}  Warning   FailedPostStartHook
</code></pre><h2 id=a-suivre>A suivre</h2><ul><li>En savoir plus sur l'<a href=/fr/docs/concepts/containers/container-environment/>Environnement d'un conteneur</a>.</li><li>Entraînez-vous à
<a href=/docs/tasks/configure-pod-container/attach-handler-lifecycle-event/>attacher des handlers de conteneurs à des événements de cycle de vie</a>.</li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-d52aadda80edd9f8c514cfe2321363c2>3.4 - Workloads</h1><div class=lead>Comprendre les Pods, le plus petit objet déployable sur Kubernetes, et les abstractions de haut niveaux vous permettant de les lancer.</div><p>Un workload (charge de travail) est une application fonctionnant sur Kubernetes. Que votre workload soit un composant unique ou un agrégat de composants, sur Kubernetes celui-ci fonctionnera dans une série de pods. Dans Kubernetes, un Pod represente un ensemble de conteneur (containers) en fonctionnement sur votre cluster.</p><p>Les pods Kubernetes ont un cycle de vie définit (defined lifecycle). Par exemple, quand un pod est en fonction sur votre cluster et qu’une panne critique survient sur le noeud (node) où se situe ce pod, tous les pods du noeud seront en échec. Kubernetes traite ce niveau d’échec comme un état final :
Vous devez créer un nouveau Pod pour retrouver l’état initial même si le noeud redevient sain.</p><p>Cependant, pour vous simplifier la vie, vous n’avez pas a gérer chaque Pod directement. Vous pouvez utiliser une ressource workload qui gère votre groupe de pods à votre place. Ces ressources configurent des controleurs (controllers) qui s’assurent que le bon nombre et le bon type de pod soit en fonction pour égaler l’état que vous avez spécifié.</p><p>Kubernetes fournit plusieurs ressources workload pré-faites :</p><ul><li><a href=/docs/concepts/workloads/controllers/deployment/><code>Deployment</code></a> et <a href=/docs/concepts/workloads/controllers/replicaset/><code>ReplicaSet</code></a>
(qui remplacent l’ancienne ressource <a class=glossary-tooltip title='A (deprecated) API object that manages a replicated application.' data-toggle=tooltip data-placement=top href='/fr/docs/reference/glossary/?all=true#term-replication-controller' target=_blank aria-label=ReplicationController>ReplicationController</a>)).
Le <code>Deployment</code> (déploiement) est une bonne approche pour manager une application stateless sur votre cluster, tous les <code>Pods</code> d’un <code>Deployment</code> sont interchangeables et peuvent être remplacés si besoin.</li><li>Le <a href=/docs/concepts/workloads/controllers/statefulset/><code>StatefulSet</code></a> vous permet de lancer un ou plusieurs Pods en relation qui garde plus ou moins la trace de leurs état.
Par exemple si votre workload enregistre des données de façon persistente, vous pouvez lancer un <code>StatefulSet</code> qui fera le lien entre les <code>Pods</code> et un volume persistent (<a href=/docs/concepts/storage/persistent-volumes/><code>PersistentVolume</code></a>).
Votre code, présent dans les <code>Pods</code> du <code>StatefulSet</code>, peut répliquer des données dans les autres <code>Pods</code> qui sont dans le même <code>StatefulSet</code>,
pour améliorer la résilience global.</li><li>Le <a href=/docs/concepts/workloads/controllers/daemonset/><code>DaemonSet</code></a> permet de définir les <code>Pods</code> qui effectuent des actions sur le noeud local.
Ceux-ci peuvent être fondamental aux opérations de votre cluster, comme un outil d’aide réseau, ou peuvent faire part d’un module complémentaire (add-on).
Pour chaque nouveau noeud ajouté au cluster, le controle plane organise l'ajout d'un <code>Pod</code> pour ce <code>DaemonSet</code> sur le nouveau noeud.</li><li>Les <a href=/docs/concepts/workloads/controllers/job/><code>Job</code></a> et <a href=/docs/concepts/workloads/controllers/cron-jobs/><code>CronJob</code></a> sont des taches lancées jusqu’à accomplissement puis s’arrêtent. Les <code>Jobs</code> réprésentent une tâche ponctuelle, les <code>CronJob</code> sont des tâches récurrentes planifiés.</li></ul><p>Dans l’écosystème étendu de Kubernetes, vous pouvez trouver des ressources workload de fournisseurs tiers qui offrent des fonctionnalités supplémentaires.
L’utilisation d’un <a href=/docs/concepts/extend-kubernetes/api-extension/custom-resources/><code>CustomResourceDefinition</code></a> permet d’ajouter une ressource workload d’un fournisseur tiers si vous souhaitez rajouter une fonctionnalité ou un comportement spécifique qui ne fait pas partie du noyau de Kubernetes.
Par exemple, si vous voulez lancer un groupe de <code>Pods</code> pour votre application mais que vous devez arrêter leurs fonctionnement tant qu’ils ne sont pas tous disponibles, alors vous pouvez implémenter ou installer une extension qui permet cette fonctionnalité.</p><h2 id=a-suivre>A suivre</h2><p>Vous pouvez continuer la lecture des ressources, vous pouvez aussi apprendre à connaitre les taches qui leurs sont liées :</p><ul><li>Lancer une <a href=/docs/tasks/run-application/run-stateless-application-deployment/>application stateless en utilisant un <code>Deployment</code></a>.</li><li>Lancer une application statefull, soit comme <a href=/docs/tasks/run-application/run-single-instance-stateful-application/>instance unique</a>
ou alors comme un <a href=/docs/tasks/run-application/run-replicated-stateful-application/>ensemble répliqué</a>.</li><li>Lancer une <a href=/docs/tasks/job/automated-tasks-with-cron-jobs/>tâche automatisée avec un <code>CronJob</code></a>.</li></ul><p>Pour en apprendre plus sur les méchanismes de Kubernetes, de séparation du code et de la configuration,
allez voir <a href=/docs/concepts/configuration/>Configuration</a>.</p><p>Il y a deux concepts supportés qui fournissent un contexte sur le sujet : comment Kubernetes gère les pods pour les applications :</p><ul><li>Le <a href=/docs/concepts/workloads/controllers/garbage-collection/>ramasse-miettes</a>, fait le ménage dans votre cluster après qu’une de <em>vos ressource</em> soit supprimé.</li><li>Le <a href=/docs/concepts/workloads/controllers/ttlafterfinished/>temps de vie d’un controlleur éteint</a> supprime les Jobs une fois qu’un temps définit soit passé après son accomplissement.</li></ul><p>Une fois que votre application est lancée, vous souhaitez peut etre la rendre disponible sur internet comme un <a href=/docs/concepts/services-networking/service/>Service</a> ou comme une application web uniquement en utilsant un <a href=/docs/concepts/services-networking/ingress>Ingress</a>.</p></div><div class=td-content style=page-break-before:always><h1 id=pg-4d68b0ccf9c683e6368ffdcc40c838d4>3.4.1 - Pods</h1></div><div class=td-content><h1 id=pg-37afa6c66c74400d1579f10faf55e5b6>3.4.1.1 - Aperçu du Pod</h1><div class=lead>Pod Concept Kubernetes</div><p>Cette page fournit un aperçu du <code>Pod</code>, l'objet déployable le plus petit dans le modèle d'objets Kubernetes.</p><h2 id=comprendre-les-pods>Comprendre les Pods</h2><p>Un <em>Pod</em> est l'unité d'exécution de base d'une application Kubernetes--l'unité la plus petite et la plus simple dans le modèle d'objets de Kubernetes--que vous créez ou déployez. Un Pod représente des process en cours d'exécution dans votre <a class=glossary-tooltip title='Un ensemble de machines, appelées des "nœuds", qui exécutent des applications conteneurisées gérées par Kubernetes.' data-toggle=tooltip data-placement=top href='/fr/docs/reference/glossary/?all=true#term-cluster' target=_blank aria-label=cluster>cluster</a>.</p><p>Un Pod encapsule un conteneur applicatif (ou, dans certains cas, plusieurs conteneurs), des ressources de stockage, une identité réseau (adresse IP) unique, ainsi que des options qui contrôlent comment le ou les conteneurs doivent s'exécuter. Un Pod représente une unité de déploiement : <em>une instance unique d'une application dans Kubernetes</em>, qui peut consister soit en un unique <a class=glossary-tooltip title='Une image exécutable légère et portable qui contient le logiciel et toutes ses dépendances.' data-toggle=tooltip data-placement=top href=/docs/concepts/overview/what-is-kubernetes/#why-containers target=_blank aria-label=container>container</a> soit en un petit nombre de conteneurs qui sont étroitement liés et qui partagent des ressources.</p><blockquote><p><a href=https://www.docker.com>Docker</a> est le runtime de conteneurs le plus courant utilisé dans un Pod Kubernetes, mais les Pods prennent également en charge d'autres <a href=/docs/setup/production-environment/container-runtimes/>runtimes de conteneurs</a>.</p></blockquote><p>Les Pods dans un cluster Kubernetes peuvent être utilisés de deux manières différentes :</p><ul><li><strong>les Pods exécutant un conteneur unique</strong>. Le modèle "un-conteneur-par-Pod" est le cas d'utilisation Kubernetes le plus courant ; dans ce cas, vous pouvez voir un Pod comme un wrapper autour d'un conteneur unique, et Kubernetes gère les Pods plutôt que directement les conteneurs.</li><li><strong>les Pods exécutant plusieurs conteneurs devant travailler ensemble</strong>. Un Pod peut encapsuler une application composée de plusieurs conteneurs co-localisés qui sont étroitement liés et qui doivent partager des ressources. Ces conteneurs co-localisés pourraient former une unique unité de service cohésive--un conteneur servant des fichiers d'un volume partagé au public, alors qu'un conteneur "sidecar" séparé rafraîchit ou met à jour ces fichiers. Le Pod enveloppe ensemble ces conteneurs et ressources de stockage en une entité maniable de base.</li></ul><p>Chaque Pod est destiné à exécuter une instance unique d'une application donnée. Si vous désirez mettre à l'échelle votre application horizontalement, (pour fournir plus de ressources au global en exécutant plus d'instances), vous devez utiliser plusieurs Pods, un pour chaque instance. Dans Kubernetes, on parle typiquement de <em>réplication</em>. Des Pods répliqués sont en général créés et gérés en tant que groupe par une ressource de charge de travail et son <a class=glossary-tooltip title="Boucle de contrôle surveillant l'état partagé du cluster à travers l'apiserver et effectuant des changements en essayant de déplacer l'état actuel vers l'état désiré." data-toggle=tooltip data-placement=top href=/docs/admin/kube-controller-manager/ target=_blank aria-label=_contrôleur_>_contrôleur_</a>. Voir <a href=#pods-et-controleurs>Pods et contrôleurs</a> pour plus d'informations.</p><h3 id=comment-les-pods-gèrent-plusieurs-conteneurs>Comment les Pods gèrent plusieurs conteneurs</h3><p>Les Pods sont conçus pour supporter plusieurs process coopérants (sous forme de conteneurs) qui forment une unité de service cohésive. Les conteneurs d'un même Pod sont automatiquement co-localisés et co-programmés sur la même machine physique ou virtuelle dans le cluster. Ces conteneurs peuvent partager des ressources et dépendances, communiquer entre eux, et coordonner quand et comment ils sont arrêtés.</p><p>Notez que grouper plusieurs conteneurs co-localisés et co-gérés dans un unique Pod est un cas d'utilisation relativement avancé. Vous devez utiliser ce pattern seulement dans des instances spécifiques dans lesquelles vos conteneurs sont étroitement liés. Par exemple, vous pourriez avoir un conteneur qui agit comme un serveur web pour des fichiers contenus dans un volume partagé, et un conteneur "sidecar" séparé qui met à jour ces fichiers depuis une source externe, comme dans le diagramme suivant :</p><figure><img src=/images/docs/pod.svg alt="example pod diagram" width=50%></figure><p>Certains Pods ont des <a class=glossary-tooltip title="Un ou plusieurs conteneurs d'initialisation qui doivent être exécutés jusqu'à la fin, avant l'exécution de tout conteneur d'application." data-toggle=tooltip data-placement=top href='/fr/docs/reference/glossary/?all=true#term-init-container' target=_blank aria-label='init containers'>init containers</a> en plus d'<a class=glossary-tooltip title="Un conteneur utilisé pour exécuter une partie d'une charge de travail, comparable à un init conteneur." data-toggle=tooltip data-placement=top href='/fr/docs/reference/glossary/?all=true#term-app-container' target=_blank aria-label='app containers'>app containers</a>. Les Init containers s'exécutent et terminent avant que les conteneurs d'application soient démarrés.</p><p>Les Pods fournissent deux types de ressources partagées pour leurs conteneurs : <em>réseau</em> et <em>stockage</em>.</p><h4 id=réseau>Réseau</h4><p>Chaque Pod se voit assigner une adresse IP unique pour chaque famille d'adresses. Tous les conteneurs d'un Pod partagent le même namespace réseau, y compris l'adresse IP et les ports réseau. Les conteneurs <em>à l'intérieur d'un Pod</em> peuvent communiquer entre eux en utilisant <code>localhost</code>. Lorsque les conteneurs dans un Pod communiquent avec des entités <em>en dehors du Pod</em>, ils doivent coordonner comment ils utilisent les ressources réseau partagées (comme les ports).</p><h4 id=stockage>Stockage</h4><p>Un Pod peut spécifier un jeu de <a class=glossary-tooltip title="Un répertoire contenant des données, accessible aux conteneurs d'un pod." data-toggle=tooltip data-placement=top href=/fr/docs/concepts/storage/volumes/ target=_blank aria-label=volumes>volumes</a> de stockage partagés. Tous les conteneurs dans le Pod peuvent accéder aux volumes partagés, permettant à ces conteneurs de partager des données. Les volumes permettent aussi les données persistantes d'un Pod de survivre au cas où un des conteneurs doit être redémarré. Voir <a href=/docs/concepts/storage/volumes/>Volumes</a> pour plus d'informations sur la façon dont Kubernetes implémente le stockage partagé dans un Pod.</p><h2 id=travailler-avec-des-pods>Travailler avec des Pods</h2><p>Vous aurez rarement à créer directement des Pods individuels dans Kubernetes--même des Pods à un seul conteneur. Ceci est dû au fait que les Pods sont conçus comme des entités relativement éphémères et jetables. Lorsqu'un Pod est créé (directement par vous ou indirectement par un <a class=glossary-tooltip title="Boucle de contrôle surveillant l'état partagé du cluster à travers l'apiserver et effectuant des changements en essayant de déplacer l'état actuel vers l'état désiré." data-toggle=tooltip data-placement=top href=/docs/admin/kube-controller-manager/ target=_blank aria-label=_contrôleur_>_contrôleur_</a>), il est programmé pour s'exécuter sur un <a class=glossary-tooltip title='A node is a worker machine in Kubernetes.' data-toggle=tooltip data-placement=top href=/docs/concepts/architecture/nodes/ target=_blank aria-label=Node>Node</a> dans votre cluster. Le Pod reste sur ce nœud jusqu'à ce que le process se termine, l'objet pod soit supprimé, le pod soit <em>expulsé</em> par manque de ressources, ou le nœud soit en échec.</p><div class="alert alert-info note callout" role=alert><strong>Note:</strong> Redémarrer un conteneur dans un Pod ne doit pas être confondu avec redémarrer un Pod. Un Pod n'est pas un process, mais un environnement pour exécuter un conteneur. Un Pod persiste jusqu'à ce qu'il soit supprimé.</div><p>Les Pods ne se guérissent pas par eux-mêmes. Si un Pod est programmé sur un Nœud qui échoue, ou si l'opération de programmation elle-même échoue, le Pod est supprimé ; de plus, un Pod ne survivra pas à une expulsion due à un manque de ressources ou une mise en maintenance du Nœud. Kubernetes utilise une abstraction de plus haut niveau, appelée un <em>contrôleur</em>, qui s'occupe de gérer les instances de Pods relativement jetables. Ainsi, même s'il est possible d'utiliser des Pods directement, il est beaucoup plus courant dans Kubernetes de gérer vos Pods en utilisant un contrôleur.</p><h3 id=pods-et-contrôleurs>Pods et contrôleurs</h3><p>Vous pouvez utiliser des ressources de charges de travail pour créer et gérer plusieurs Pods pour vous. Un contrôleur pour la ressource gère la réplication,
le plan de déploiement et la guérison automatique en cas de problèmes du Pod. Par exemple, si un noeud est en échec, un contrôleur note que les Pods de ce noeud
ont arrêté de fonctionner et créent des Pods pour les remplacer. L'ordonnanceur place le Pod de remplacement sur un noeud en fonctionnement.</p><p>Voici quelques exemples de ressources de charges de travail qui gèrent un ou plusieurs Pods :</p><ul><li><a class=glossary-tooltip title='Objet API gérant une application répliquée.' data-toggle=tooltip data-placement=top href=/docs/concepts/workloads/controllers/deployment/ target=_blank aria-label=Deployment>Deployment</a></li><li><a class=glossary-tooltip title="Gère le déploiement et la mise à l'échelle d'un ensemble de Pods, avec un stockage durable et des identifiants persistants pour chaque Pod." data-toggle=tooltip data-placement=top href=/fr/docs/concepts/workloads/controllers/statefulset/ target=_blank aria-label=StatefulSet>StatefulSet</a></li><li><a class=glossary-tooltip title="S'assure qu'une copie d'un Pod s'exécute sur un ensemble de nœuds d'un cluster." data-toggle=tooltip data-placement=top href=/docs/concepts/workloads/controllers/daemonset target=_blank aria-label=DaemonSet>DaemonSet</a></li></ul><h2 id=templates-de-pod>Templates de Pod</h2><p>Les Templates de Pod sont des spécifications pour créer des Pods, et sont inclus dans les ressources de charges de travail comme
les <a href=/fr/docs/concepts/workloads/controllers/deployment/>Deployments</a>, les <a href=/docs/concepts/jobs/run-to-completion-finite-workloads/>Jobs</a> et
les <a href=/docs/concepts/workloads/controllers/daemonset/>DaemonSets</a>.</p><p>Chaque contrôleur pour une ressource de charges de travail utilise le template de pod à l'intérieur de l'objet pour créer les Pods. Le template de pod fait partie de l'état désiré de la ressource de charges de travail que vous avez utilisé pour exécuter votre application.</p><p>L'exemple ci-dessous est un manifest pour un Job simple avec un <code>template</code> qui démarre un conteneur. Le conteneur dans ce Pod affiche un message puis se met en pause.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>batch/v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Job<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>hello<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>template</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:#080;font-style:italic># Ceci est un template de pod</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>hello<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>busybox<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>command</span>:<span style=color:#bbb> </span>[<span style=color:#b44>&#39;sh&#39;</span>,<span style=color:#bbb> </span><span style=color:#b44>&#39;-c&#39;</span>,<span style=color:#bbb> </span><span style=color:#b44>&#39;echo &#34;Hello, Kubernetes!&#34; &amp;&amp; sleep 3600&#39;</span>]<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>restartPolicy</span>:<span style=color:#bbb> </span>OnFailure<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:#080;font-style:italic># Le template de pod se termine ici</span><span style=color:#bbb>
</span></span></span></code></pre></div><p>Modifier le template de pod ou changer pour un nouvau template de pod n'a pas d'effet sur les pods déjà existants. Les Pods ne reçoivent pas une mise à jour
du template directement ; au lieu de cela, un nouveau Pod est créé pour correspondre au nouveau template de pod.</p><p>Par exemple, un contrôleur de Deployment s'assure que les Pods en cours d'exécution correspondent au template de pod en cours. Si le template est mis à jour,
le contrôleur doit supprimer les pods existants et créer de nouveaux Pods avec le nouveau template. Chaque contrôleur de charges de travail implémente ses propres
règles pour gérer les changements du template de Pod.</p><p>Sur les noeuds, le <a class=glossary-tooltip title="Un agent qui s'exécute sur chaque nœud du cluster. Il s'assure que les conteneurs fonctionnent dans un pod." data-toggle=tooltip data-placement=top href=/docs/reference/generated/kubelet target=_blank aria-label=kubelet>kubelet</a> n'observe ou ne gère pas directement les détails concernant les templates de pods et leurs mises à jours ; ces détails sont abstraits. Cette abstraction et cette séparation des préoccupations simplifie la sémantique du système, et rend possible l'extension du comportement du cluster sans changer le code existant.</p><h2 id=a-suivre>A suivre</h2><ul><li>En savoir plus sur les <a href=/docs/concepts/workloads/pods/pod/>Pods</a></li><li><a href=https://kubernetes.io/blog/2015/06/the-distributed-system-toolkit-patterns>The Distributed System Toolkit: Patterns for Composite Containers</a> explique les dispositions courantes pour des Pods avec plusieurs conteneurs</li><li>En savoir plus sur le comportement des Pods :<ul><li><a href=/docs/concepts/workloads/pods/pod/#termination-of-pods>Terminaison d'un Pod</a></li><li><a href=/docs/concepts/workloads/pods/pod-lifecycle/>Cycle de vie d'un Pod</a></li></ul></li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-99cce294fe789317ee684a6e1f07f20f>3.4.1.2 - Pods</h1><p>Les <em>Pods</em> sont les plus petites unités informatiques déployables
qui peuvent être créées et gérées dans Kubernetes.</p><h2 id=qu-est-ce-qu-un-pod>Qu'est-ce qu'un pod ?</h2><p>Un <em>pod</em> (terme anglo-saxon décrivant un groupe de baleines ou une gousse de pois) est un groupe d'un ou plusieurs conteneurs
(comme des conteneurs Docker), ayant du stockage/réseau partagé, et une spécification
sur la manière d'exécuter ces conteneurs. Les éléments d'un pod sont toujours co-localisés
et co-ordonnancés, et s'exécutent dans un contexte partagé. Un pod modélise un
"hôte logique" spécifique à une application - il contient un ou plusieurs conteneurs applicatifs
qui sont étroitement liés — dans un monde pré-conteneurs, être exécuté sur la même machine
physique ou virtuelle signifierait être exécuté sur le même hôte logique.</p><p>Bien que Kubernetes prenne en charge d'autres runtimes de conteneurs que Docker, Docker est le runtime
le plus connu, et cela aide à décrire des pods en termes Docker.</p><p>Le contexte partagé d'un pod est un ensemble de namespaces Linux, cgroups, et
potentiellement d'autres facettes d'isolation - les mêmes choses qui isolent un conteneur Docker.
Dans le contexte d'un pod, les applications individuelles peuvent se voir appliquer d'autres sous-isolations.</p><p>Les conteneurs d'un pod partagent une adresse IP et un espace de ports, et peuvent communiquer via <code>localhost</code>.
Ils peuvent aussi communiquer entre eux en utilisant des communications inter-process standard comme
les sémaphores SystemV ou la mémoire partagée POSIX. Les conteneurs appartenant à des pods distincts ont des adresses IP
distinctes et ne peuvent pas communiquer par IPC sans <a href=/docs/concepts/policy/pod-security-policy/>configuration spécifique</a>. Ces conteneurs communiquent en général entre eux via les adresses IP de leurs pods.</p><p>Les applications à l'intérieur d'un pod ont aussi accès à des volumes partagés,
qui sont définis dans le cadre d'un pod et sont mis à disposition pour être montés
dans le système de fichiers de chaque application.</p><p>En terme de concepts <a href=https://www.docker.com/>Docker</a>, un pod est modélisé par un groupe de conteneurs Docker
ayant des namespaces et des <a href=/docs/concepts/storage/volumes/>volumes</a> partagés.</p><p>Tout comme des conteneurs applicatifs individuels, les pods sont considérés comme des entités relativement éphémères (plutôt que durables).
Comme discuté dans <a href=/docs/concepts/workloads/pods/pod-lifecycle/>Cycle de vie d'un pod</a>, les pods sont créés, des ID uniques (UID) leurs sont assignés,
et ils sont ordonnancés sur des nœuds où il restent jusqu'à leur arrêt (selon la politique de redémarrage) ou suppression.
Si un nœud meurt, les pods ordonnancés sur ce nœud sont programmés pour être terminés, après un délai d'attente. Un pod donné (défini par un UID)
n'est pas "re-ordonnancé" sur un nouveau nœud ; par contre, il peut être remplacé par un pod identique,
ayant le même nom si désiré, mais avec un nouvel UID (voir <a href=/docs/concepts/workloads/controllers/replicationcontroller/>replication
controller</a> pour plus de détails).</p><p>Lorsque quelque chose, comme un volume, a le même cycle de vie qu'un pod, il existe aussi longtemps
que le pod (avec l'UID donné) existe. Si ce pod est supprimé pour une quelconque raison, même si un remplaçant
identique est recréé, la chose liée (par ex. le volume) est aussi détruite et créée à nouveau.</p><figure><img src=/images/docs/pod.svg width=50%><figcaption><h4>pod diagram</h4></figcaption></figure><p><em>Un pod multi-conteneurs contenant un extracteur de fichiers et un serveur web
utilisant un volume persistant comme espace de stockage partagé entre les conteneurs.</em></p><h2 id=intérêts-des-pods>Intérêts des pods</h2><h3 id=gestion>Gestion</h3><p>Les pods fournissent une unité de service cohérente afin d'avoir un modèle coopératif entre plusieurs processus.
Ils simplifient le déploiement et la gestion d'applications
en fournissant une abstraction de plus haut niveau que l'ensemble des applications les constituant.
Les pods servent d'unité de déploiement, de mise à l'échelle horizontale, et de réplication.
La co-localisation (co-ordonnancement), la fin partagée (par ex. l'arrêt),
la réplication coordonnée, le partage de ressources et la gestion des dépendances sont
traités automatiquement pour les conteneurs dans un pod.</p><h3 id=partage-de-ressources-et-communication>Partage de ressources et communication</h3><p>Les pods permettent le partage de ressources et la communication entre ses constituants.</p><p>Les applications dans un pod utilisent toutes le même réseau (même adresse IP et espace de ports)
et peuvent donc "se trouver" entre elles et communiquer en utilisant <code>localhost</code>.
À cause de cela, les applications dans un pod doivent coordonner leurs usages de ports.
Chaque pod a une adresse IP dans un réseau plat partagé ayant un accès complet
aux autres hôtes et pods à travers le réseau.</p><p>Le nom d'hôte est défini avec le nom du pod pour les conteneurs applicatifs à l'intérieur du pod.
<a href=/docs/concepts/cluster-administration/networking/>Plus de détails sur le réseau</a>.</p><p>En plus de définir les conteneurs applicatifs s'exécutant dans le pod, le pod spécifie
un ensemble de volumes de stockage partagés. Les volumes permettent aux données de survivre
aux redémarrages de conteneurs et d'être partagés entre les applications d'un même pod.</p><h2 id=cas-d-utilisation-de-pods>Cas d'utilisation de pods</h2><p>Des pods peuvent être utilisés pour héberger verticalement des piles applicatives intégrées (par ex. LAMP),
mais leur principal intérêt est la mise en place de programmes auxiliaires co-localisés et co-gérés, comme :</p><ul><li>systèmes de gestion de contenu, chargeurs de fichiers et de données, gestionnaires de cache local, etc.</li><li>sauvegarde de log et checkpoint, compression, rotation, prise d'instantanés, etc.</li><li>data change watchers, log tailers, adaptateurs de logs et monitoring, éditeurs d'événements, etc.</li><li>proxies, bridges et adaptateurs</li><li>contrôleurs, gestionnaires, configurateurs et gestionnaires de mise à jour</li></ul><p>Des pods individuels ne sont pas destinés à exécuter plusieurs instances de la même application, en général.</p><p>Pour une explication plus détaillée, voir <a href=https://kubernetes.io/blog/2015/06/the-distributed-system-toolkit-patterns>The Distributed System ToolKit: Patterns for
Composite
Containers</a>.</p><h2 id=alternatives-envisagées>Alternatives envisagées</h2><p><em>Pourquoi ne pas simplement exécuter plusieurs programmes dans un unique conteneur (Docker) ?</em></p><ol><li>Transparence. Rendre les conteneurs à l'intérieur du pod visibles par l'infrastucture
permet à l'infrastucture de fournir des services à ces conteneurs,
comme la gestion des processus et le monitoring des ressources. Ceci
apporte un certain nombre de facilités aux utilisateurs.</li><li>Découpler les dépendances logicielles. Les conteneurs individuels peuvent être
versionnés, reconstruits et redéployés de manière indépendante. Kubernetes pourrait
même un jour prendre en charge la mise à jour à chaud de conteneurs individuels.</li><li>Facilité d'utilisation. Les utilisateurs n'ont pas besoin d'exécuter leur propre gestionnaire
de processus, de se soucier de la propagation de signaux et de codes de sortie, etc.</li><li>Efficacité. L'infrastructure prenant plus de responsabilités, les conteneurs peuvent être plus légers.</li></ol><p><em>Pourquoi ne pas prendre en charge le co-ordonnancement de conteneurs basé sur les affinités ?</em></p><p>Cette approche pourrait fournir la co-localisation, mais ne fournirait pas la plupart
des bénéfices des pods, comme le partage de ressources, IPC, la garantie d'une fin partagée et une gestion simplifiée.</p><h2 id=durabilité-des-pods-ou-manque-de>Durabilité des pods (ou manque de)</h2><p>Les pods ne doivent pas être considérés comme des entités durables. Ils ne survivent pas à des erreurs d'ordonnancement, à un nœud en échec
ou à d'autres expulsions, suite à un manque de ressources ou une mise en maintenance d'un nœud.</p><p>En général, les utilisateurs n'ont pas à créer directement des pods. Ils doivent presque toujours
utiliser des contrôleurs, même pour des singletons, comme par exemple des <a href=/docs/concepts/workloads/controllers/deployment/>Deployments</a>.
Les contrôleurs fournissent l'auto-guérison à l'échelle du cluster, ainsi que la réplication et la gestion des déploiements (rollout).
Les contrôleurs comme <a href=/docs/concepts/workloads/controllers/statefulset.md>StatefulSet</a>
peuvent aussi prendre en charge des pods avec état (stateful).</p><p>L'utilisation d'APIs collectives comme principale primitive exposée à l'utilisateur est courante dans les systèmes d'ordonnancement de clusters, comme <a href=https://research.google.com/pubs/pub43438.html>Borg</a>, <a href=https://mesosphere.github.io/marathon/docs/rest-api.html>Marathon</a>, <a href=http://aurora.apache.org/documentation/latest/reference/configuration/#job-schema>Aurora</a>, et <a href=http://www.slideshare.net/Docker/aravindnarayanan-facebook140613153626phpapp02-37588997>Tupperware</a>.</p><p>Un Pod est exposé en tant que primitive afin de faciliter :</p><ul><li>la connexion du scheduler et du contrôleur</li><li>la possibilité d'opérations au niveau du pod sans besoin de passer par des APIs au niveau du contrôleur</li><li>le découplage du cycle de fin d'un pod de celui d'un contrôleur, comme pour l'amorçage (bootstrapping)</li><li>le découplage des contrôleurs et des services — le contrôleur d'endpoints examine uniquement des pods</li><li>la composition claire des fonctionnalités niveau Kubelet et des fonctionnalités niveau cluster — concrètement, Kubelet est le "contrôleur de pods"</li><li>les applications hautement disponibles, qui attendront que les pods soient remplacés avant leur arrêt et au moins avant leur suppression, comme dans les cas d'éviction programmée ou de pré-chargement d'image.</li></ul><h2 id=arrêt-de-pods>Arrêt de pods</h2><p>Les pods représentant des processus s'exécutant sur des nœuds d'un cluster, il est important de permettre à ces processus de se terminer proprement
lorsqu'ils ne sont plus nécessaires (plutôt que d'être violemment tués avec un signal KILL et n'avoir aucune chance de libérer ses ressources). Les
utilisateurs doivent pouvoir demander une suppression et savoir quand les processus se terminent, mais aussi être capable de s'assurer que la suppression
est réellement effective. Lorsqu'un utilisateur demande la suppression d'un pod, le système enregistre le délai de grâce prévu avant que le pod puisse
être tué de force, et qu'un signal TERM soit envoyé au processus principal de chaque conteneur. Une fois la période de grâce expirée, le signal KILL
est envoyé à ces processus, et le pod est alors supprimé de l'API server. Si Kubelet ou le gestionnaire de conteneurs est redémarré lors de l'attente de l'arrêt des processus, l'arrêt sera réessayé avec la période de grâce complète.</p><p>Un exemple de déroulement :</p><ol><li>Un utilisateur envoie une commande pour supprimer un Pod, avec une période de grâce par défaut (30s)</li><li>Le Pod dans l'API server est mis à jour avec le temps au delà duquel le Pod est considéré "mort" ainsi que la période de grâce.</li><li>Le Pod est affiché comme "Terminating" dans les listes des commandes client</li><li>(en même temps que 3) Lorsque Kubelet voit qu'un Pod a été marqué "Terminating", le temps ayant été mis en 2, il commence le processus de suppression du pod.<ol><li>Si un des conteneurs du Pod a défini un <a href=/fr/docs/concepts/containers/container-lifecycle-hooks/#hook-details>preStop hook</a>, il est exécuté à l'intérieur du conteneur. Si le <code>preStop</code> hook est toujours en cours d'exécution à la fin de la période de grâce, l'étape 2 est invoquée avec une courte (2 secondes) période de grâce supplémentaire une seule fois. Vous devez modifier <code>terminationGracePeriodSeconds</code> si le hook <code>preStop</code> a besoin de plus de temps pour se terminer.</li><li>Le signal TERM est envoyé aux conteneurs. Notez que tous les conteneurs du Pod ne recevront pas le signal TERM en même temps et il peut être nécessaire de définir des <code>preStop</code> hook si l'ordre d'arrêt est important.</li></ol></li><li>(en même temps que 3) Le Pod est supprimé des listes d'endpoints des services, et n'est plus considéré comme faisant partie des pods en cours d'exécution pour les contrôleurs de réplication. Les Pods s'arrêtant lentement ne peuvent pas continuer à servir du trafic, les load balancers (comme le service proxy) les supprimant de leurs rotations.</li><li>Lorsque la période de grâce expire, les processus s'exécutant toujours dans le Pod sont tués avec SIGKILL.</li><li>Kubelet va supprimer le Pod dans l'API server en indiquant une période de grâce de 0 (suppression immédiate). Le Pod disparaît de l'API et n'est plus visible par le client.</li></ol><p>Par défaut, toutes les suppressions ont une période de grâce de 30 secondes. La commande <code>kubectl delete</code> prend en charge l'option <code>--grace-period=&lt;secondes></code> permettant à l'utilisateur de spécifier sa propre valeur. La valeur <code>0</code> <a href=/docs/concepts/workloads/pods/pod/#force-deletion-of-pods>force la suppression</a> du pod. Avec kubectl version >= 1.5, vous devez spécifier un flag supplémentaire <code>--force</code> avec <code>--grace-period=0</code> pour pouvoir forcer la suppression.</p><h3 id=suppression-forcée-de-pods>Suppression forcée de pods</h3><p>La suppression forcée d'un pod est définie comme la suppression immédiate d'un pod de l'état du cluster et d'etcd. Lorqu'une suppression forcée est effectuée, l'apiserver n'attend pas la confirmation de kubelet que le pod a été terminé sur le nœud sur lequel il s'exécutait. Il supprime le pod de l'API immédiatement pour qu'un nouveau pod puisse être créé avec le même nom. Sur le nœud, les pods devant se terminer immédiatement se verront donner une courte période de grâce avant d'être tués de force.</p><p>Les suppressions forcées peuvent être potentiellement dangereuses pour certains pods et doivent être effectuées avec précaution. Dans le cas de pods d'un StatefulSet, veuillez vous référer à la documentation pour <a href=/docs/tasks/run-application/force-delete-stateful-set-pod/>supprimer des Pods d'un StatefulSet</a>.</p><h2 id=mode-privilégié-pour-les-conteneurs-d-un-pod>Mode privilégié pour les conteneurs d'un pod</h2><p>Depuis Kubernetes v1.1, tout conteneur d'un pod peut activer le mode privilégié, en utilisant le flag <code>privileged</code> du <code>SecurityContext</code> de la spec du conteneur. Ceci est utile pour les conteneurs voulant utiliser les capacités de Linux comme manipuler la pile réseau ou accéder aux périphériques. Les processus dans un tel conteneur ont pratiquement les mêmes privilèges que les processus en dehors d'un conteneur. En mode privilégié, il doit être plus facile d'écrire des plugins réseau et volume en tant que pods séparés ne devant pas être compilés dans kubelet.</p><p>Si le master exécute Kubernetes v1.1 ou supérieur, et les nœuds exécutent une version antérieure à v1.1, les nouveaux pods privilégiés seront acceptés par l'api-server, mais ne seront pas lancés. Il resteront en état "pending".
Si l'utilisateur appelle <code>kubectl describe pod FooPodName</code>, l'utilisateur peut voir la raison pour laquelle le pod est en état "pending". La table d'événements dans la sortie de la commande "describe" indiquera :
<code>Error validating pod "FooPodName"."FooPodNamespace" from api, ignoring: spec.containers[0].securityContext.privileged: forbidden '&lt;*>(0xc2089d3248)true'</code></p><p>Si le master exécute une version antérieure à v1.1, les pods privilégiés ne peuvent alors pas être créés. Si l'utilisateur tente de créer un pod ayant un conteneur privilégié, l'utilisateur obtiendra l'erreur suivante :
<code>The Pod "FooPodName" is invalid. spec.containers[0].securityContext.privileged: forbidden '&lt;*>(0xc20b222db0)true'</code></p><h2 id=objet-de-l-api>Objet de l'API</h2><p>Le Pod est une ressource au plus haut niveau dans l'API REST Kubernetes. Plus de détails sur l'objet de l'API peuvent être trouvés à :
<a href=/docs/reference/generated/kubernetes-api/v1.25/#pod-v1-core>Objet de l'API Pod</a>.</p><p>Lorsque vous créez un manifest pour un objet Pod, soyez certain que le nom spécifié est un <a href=/docs/concepts/overview/working-with-objects/names#dns-subdomain-names>nom de sous-domaine DNS</a> valide.</p></div><div class=td-content style=page-break-before:always><h1 id=pg-c3c2b9cf30915ec9d46c147201da3332>3.4.1.3 - Cycle de vie d'un Pod</h1><p>Cette page décrit le cycle de vie d'un Pod.</p><h2 id=phase-du-pod>Phase du Pod</h2><p>Le champ <code>status</code> d'un Pod est un objet
<a href=/docs/reference/generated/kubernetes-api/v1.25/#podstatus-v1-core>PodStatus</a>,
contenant un champ <code>phase</code>.</p><p>La phase d'un Pod est un résumé simple et de haut niveau de l'étape à laquelle le Pod se trouve
dans son cycle de vie.
La phase n'est pas faite pour être un cumul complet d'observations de l'état
du conteneur ou du Pod, ni pour être une machine à état compréhensible.</p><p>Le nombre et la signification des valeurs de phase d'un pod sont soigneusement gardés.
Hormis ce qui est documenté ici, rien ne doit être supposé sur des Pods
ayant une valeur de <code>phase</code> donnée.</p><p>Voici les valeurs possibles pour <code>phase</code> :</p><table><thead><tr><th style=text-align:left>Valeur</th><th style=text-align:left>Description</th></tr></thead><tbody><tr><td style=text-align:left><code>Pending</code></td><td style=text-align:left>Le Pod a été accepté par Kubernetes, mais une ou plusieurs images de conteneurs n'ont pas encore été créées. Ceci inclut le temps avant d'être affecté ainsi que le temps à télécharger les images à travers le réseau, ce qui peut prendre un certain temps.</td></tr><tr><td style=text-align:left><code>Running</code></td><td style=text-align:left>Le pod a été affecté à un nœud et tous les conteneurs ont été créés. Au moins un conteneur est toujours en cours d'exécution, ou est en train de démarrer ou redémarrer.</td></tr><tr><td style=text-align:left><code>Succeeded</code></td><td style=text-align:left>Tous les conteneurs du pod ont terminé avec succès et ne seront pas redémarrés.</td></tr><tr><td style=text-align:left><code>Failed</code></td><td style=text-align:left>Tous les conteneurs d'un pod ont terminé, et au moins un conteneur a terminé en échec : soit le conteneur a terminé avec un status non zéro, soit il a été arrêté par le système.</td></tr><tr><td style=text-align:left><code>Unknown</code></td><td style=text-align:left>Pour quelque raison l'état du pod ne peut pas être obtenu, en général en cas d'erreur de communication avec l'hôte du Pod.</td></tr></tbody></table><h2 id=conditions-du-pod>Conditions du Pod</h2><p>Un Pod a un PodStatus, qui contient un tableau de
<a href=/docs/reference/generated/kubernetes-api/v1.25/#podcondition-v1-core>PodConditions</a>
à travers lesquelles le Pod est ou non passé. Chaque élément
du tableau de PodCondition a six champs possibles :</p><ul><li><p>Le champ <code>lastProbeTime</code> fournit un timestamp auquel la condition du Pod
a été sondée pour la dernière fois.</p></li><li><p>Le champ <code>lastTransitionTime</code> fournit un timestamp auquel le Pod a changé de statut
pour la dernière fois.</p></li><li><p>Le champ <code>message</code> est un message lisible indiquant les détails de la transition.</p></li><li><p>Le champ <code>reason</code> est une raison unique, en un seul mot et en CamelCase de la transition
vers la dernière condition.</p></li><li><p>Le champ <code>status</code> est une chaîne de caractères avec les valeurs possibles "<code>True</code>", "<code>False</code>", et "<code>Unknown</code>".</p></li><li><p>Le champ <code>type</code> est une chaîne de caractères ayant une des valeurs suivantes :</p><ul><li><code>PodScheduled</code> : le Pod a été affecté à un nœud ;</li><li><code>Ready</code> : le Pod est prêt à servir des requêtes et doit être rajouté aux équilibreurs
de charge de tous les Services correspondants ;</li><li><code>Initialized</code> : tous les <a href=/fr/docs/concepts/workloads/pods/init-containers>init containers</a>
ont démarré correctement ;</li><li><code>ContainersReady</code> : tous les conteneurs du Pod sont prêts.</li></ul></li></ul><h2 id=sondes-du-conteneur>Sondes du Conteneur</h2><p>Une <a href=/docs/reference/generated/kubernetes-api/v1.25/#probe-v1-core>Sonde</a> (Probe) est un diagnostic
exécuté périodiquement par <a href=/docs/admin/kubelet/>kubelet</a>
sur un Conteneur. Pour exécuter un diagnostic, kubelet appelle un
<a href=https://godoc.org/k8s.io/kubernetes/pkg/api/v1#Handler>Handler</a> implémenté par
le Conteneur. Il existe trois types de handlers :</p><ul><li><p><a href=/docs/reference/generated/kubernetes-api/v1.25/#execaction-v1-core>ExecAction</a>:
Exécute la commande spécifiée à l'intérieur du Conteneur. Le diagnostic
est considéré réussi si la commande se termine avec un code de retour de 0.</p></li><li><p><a href=/docs/reference/generated/kubernetes-api/v1.25/#tcpsocketaction-v1-core>TCPSocketAction</a>:
Exécute un contrôle TCP sur l'adresse IP du Conteneur et sur un port spécifié.
Le diagnostic est considéré réussi si le port est ouvert.</p></li><li><p><a href=/docs/reference/generated/kubernetes-api/v1.25/#httpgetaction-v1-core>HTTPGetAction</a>:
Exécute une requête HTTP Get sur l'adresse IP du Conteneur et sur un port et
un chemin spécifiés. Le diagnostic est considéré réussi si la réponse a un code
de retour supérieur ou égal à 200 et inférieur à 400.</p></li></ul><p>Chaque sonde a un résultat parmi ces trois :</p><ul><li>Success: Le Conteneur a réussi le diagnostic.</li><li>Failure: Le Conteneur a échoué au diagnostic.</li><li>Unknown: L'exécution du diagnostic a échoué, et donc aucune action ne peut être prise.</li></ul><p>kubelet peut optionnellement exécuter et réagir à trois types de sondes sur des conteneurs
en cours d'exécution :</p><ul><li><p><code>livenessProbe</code> : Indique si le Conteneur est en cours d'exécution. Si
la liveness probe échoue, kubelet tue le Conteneur et le Conteneur
est soumis à sa <a href=#politique-de-redemarrage>politique de redémarrage</a> (restart policy).
Si un Conteneur ne fournit pas de liveness probe, l'état par défaut est <code>Success</code>.</p></li><li><p><code>readinessProbe</code> : Indique si le Conteneur est prêt à servir des requêtes.
Si la readiness probe échoue, le contrôleur de points de terminaison (Endpoints)
retire l'adresse IP du Pod des points de terminaison de tous les Services
correspodant au Pod. L'état par défaut avant le délai initial est
<code>Failure</code>. Si le Conteneur ne fournit pas de readiness probe, l'état par
défaut est <code>Success</code>.</p></li><li><p><code>startupProbe</code>: Indique si l'application à l'intérieur du conteneur a démarré.
Toutes les autres probes sont désactivées si une starup probe est fournie,
jusqu'à ce qu'elle réponde avec succès. Si la startup probe échoue, le kubelet
tue le conteneur, et le conteneur est assujetti à sa <a href=#politique-de-redemarrage>politique de redémarrage</a>.
Si un conteneur ne fournit pas de startup probe, l'état par défaut est <code>Success</code>.</p></li></ul><h3 id=quand-devez-vous-utiliser-une-liveness-probe>Quand devez-vous utiliser une liveness probe ?</h3><p>Si le process de votre Conteneur est capable de crasher de lui-même lorsqu'il
rencontre un problème ou devient inopérant, vous n'avez pas forcément besoin
d'une liveness probe ; kubelet va automatiquement exécuter l'action correcte
en accord avec la politique de redémarrage (<code>restartPolicy</code>) du Pod.</p><p>Si vous désirez que votre Conteneur soit tué et redémarré si une sonde échoue, alors
spécifiez une liveness probe et indiquez une valeur pour <code>restartPolicy</code> à Always
ou OnFailure.</p><h3 id=quand-devez-vous-utiliser-une-readiness-probe>Quand devez-vous utiliser une readiness probe ?</h3><div style=margin-top:10px;margin-bottom:10px><b>FEATURE STATE:</b> <code>Kubernetes v1.0 [stable]</code></div><p>Si vous voulez commencer à envoyer du trafic à un Pod seulement lorsqu'une sonde
réussit, spécifiez une readiness probe. Dans ce cas, la readiness probe peut être
la même que la liveness probe, mais l'existence de la readiness probe dans la spec
veut dire que le Pod va démarrer sans recevoir aucun trafic et va commencer
à recevoir du trafic après que la sonde réussisse.
Si votre Conteneur doit charger une grande quantité de données, des fichiers de
configuration ou exécuter des migrations au démarrage, spécifiez une readiness probe.</p><p>Si vous désirez que le Conteneur soit capable de se mettre en maintenance tout seul, vous
pouvez spécifier une readiness probe qui vérifie un point de terminaison spécifique au
readiness et différent de la liveness probe.</p><p>Notez que si vous voulez uniquement être capable de dérouter les requêtes lorsque
le Pod est supprimé, vous n'avez pas forcément besoin d'une readiness probe; lors
de sa suppression, le Pod se met automatiquement dans un état non prêt, que la
readiness probe existe ou non.
Le Pod reste dans le statut non prêt le temps que les Conteneurs du Pod s'arrêtent.</p><h3 id=quand-devez-vous-utiliser-une-startup-probe>Quand devez-vous utiliser une startup probe ?</h3><div style=margin-top:10px;margin-bottom:10px><b>FEATURE STATE:</b> <code>Kubernetes v1.16 [alpha]</code></div><p>Si votre conteneur démarre habituellement en plus de <code>initialDelaySeconds + failureThreshold × periodSeconds</code>,
vous devriez spécifier une startup probe qui vérifie le même point de terminaison que la liveness probe. La valeur par défaut pour <code>periodSeconds</code> est 30s.
Vous devriez alors mettre sa valeur <code>failureThreshold</code> suffisamment haute pour permettre au conteneur de démarrer, sans changer les valeurs par défaut de la liveness probe. Ceci aide à se protéger de deadlocks.</p><p>Pour plus d'informations sur la manière de mettre en place une liveness, readiness ou startup probe,
voir <a href=/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/>Configurer des Liveness, Readiness et Startup Probes</a>.</p><h2 id=statut-d-un-pod-et-d-un-conteneur>Statut d'un Pod et d'un Conteneur</h2><p>Pour des informations détaillées sur le statut d'un Pod et d'un Conteneur, voir
<a href=/docs/reference/generated/kubernetes-api/v1.25/#podstatus-v1-core>PodStatus</a>
et
<a href=/docs/reference/generated/kubernetes-api/v1.25/#containerstatus-v1-core>ContainerStatus</a>.
Notez que l'information rapportée comme statut d'un Pod dépend du
<a href=/docs/reference/generated/kubernetes-api/v1.25/#containerstatus-v1-core>ContainerState</a> actuel.</p><h2 id=états-d-un-conteneur>États d'un Conteneur</h2><p>Une fois que le Pod est assigné à un nœud par le scheduler, kubelet commence
à créer les conteneurs en utilisant le runtime de conteneurs. Il existe trois états possibles
pour les conteneurs : en attente (Waiting), en cours d'exécution (Running) et terminé (Terminated). Pour vérifier l'état d'un conteneur, vous pouvez utiliser <code>kubectl describe pod [POD_NAME]</code>. L'état est affiché pour chaque conteneur du Pod.</p><ul><li><p><code>Waiting</code> : état du conteneur par défaut. Si le conteneur n'est pas dans un état Running ou Terminated, il est dans l'état Waiting. Un conteneur dans l'état Waiting exécute
les opérations nécessaires, comme télécharger les images, appliquer des Secrets, etc. À côté
de cet état, un message et une raison sur l'état sont affichés pour vous fournir plus
d'informations.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#00f;font-weight:700>...</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>State</span>:<span style=color:#bbb>          </span>Waiting<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>   </span><span style=color:green;font-weight:700>Reason</span>:<span style=color:#bbb>       </span>ErrImagePull<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:#00f;font-weight:700>...</span><span style=color:#bbb>
</span></span></span></code></pre></div></li><li><p><code>Running</code> : Indique que le conteneur s'exécute sans problème. Le hook <code>postStart</code> (s'il existe) est exécuté avant que le conteneur entre dans l'état Running. Cet état affiche aussi le moment auquel le conteneur est entré dans l'état Running.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#00f;font-weight:700>...</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>   </span><span style=color:green;font-weight:700>State</span>:<span style=color:#bbb>          </span>Running<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>Started</span>:<span style=color:#bbb>      </span>Wed, 30 Jan 2019 16:46:38 +0530<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:#00f;font-weight:700>...</span><span style=color:#bbb>
</span></span></span></code></pre></div></li><li><p><code>Terminated</code>: Indique que le conteneur a terminé son exécution et s'est arrêté.
Un conteneur entre dans cet état lorsqu'il s'est exécuté avec succès ou lorsqu'il a
échoué pour une raison quelconque. De plus, une raison et un code de retour sont affichés,
ainsi que les moments de démarrage et d'arrêt du conteneur. Avant qu'un conteneur entre
dans l'état Terminated, le hook <code>preStop</code> est exécuté (s'il existe).</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#00f;font-weight:700>...</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>   </span><span style=color:green;font-weight:700>State</span>:<span style=color:#bbb>          </span>Terminated<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>     </span><span style=color:green;font-weight:700>Reason</span>:<span style=color:#bbb>       </span>Completed<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>     </span><span style=color:green;font-weight:700>Exit Code</span>:<span style=color:#bbb>    </span><span style=color:#666>0</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>     </span><span style=color:green;font-weight:700>Started</span>:<span style=color:#bbb>      </span>Wed, 30 Jan 2019 11:45:26 +0530<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>     </span><span style=color:green;font-weight:700>Finished</span>:<span style=color:#bbb>     </span>Wed, 30 Jan 2019 11:45:26 +0530<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb> </span>...<span style=color:#bbb>
</span></span></span></code></pre></div></li></ul><h2 id=pod-readiness-gate>Pod readiness</h2><div style=margin-top:10px;margin-bottom:10px><b>FEATURE STATE:</b> <code>Kubernetes v1.14 [stable]</code></div><p>Votre application peut injecter des données dans <code>PodStatus</code>.</p><p><em>Pod readiness</em>. Pour utiliser cette fonctionnalité, remplissez <code>readinessGates</code> dans le PodSpec avec
une liste de conditions supplémentaires que le kubelet évalue pour la disponibilité du Pod.</p><p>Les Readiness gates sont déterminées par l'état courant des champs <code>status.condition</code> du Pod.
Si Kubernetes ne peut pas trouver une telle condition dans le champs <code>status.conditions</code> d'un Pod, the statut de la condition
est mise par défaut à "<code>False</code>".</p><p>Voici un exemple :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:#00f;font-weight:700>...</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>readinessGates</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:green;font-weight:700>conditionType</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;www.example.com/feature-1&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>status</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>conditions</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:green;font-weight:700>type</span>:<span style=color:#bbb> </span>Ready <span style=color:#bbb> </span><span style=color:#080;font-style:italic># une PodCondition intégrée</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>status</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;False&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>lastProbeTime</span>:<span style=color:#bbb> </span><span style=color:#a2f;font-weight:700>null</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>lastTransitionTime</span>:<span style=color:#bbb> </span>2018-01-01T00:00:00Z<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:green;font-weight:700>type</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;www.example.com/feature-1&#34;</span><span style=color:#bbb>   </span><span style=color:#080;font-style:italic># une PodCondition supplémentaire</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>status</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;False&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>lastProbeTime</span>:<span style=color:#bbb> </span><span style=color:#a2f;font-weight:700>null</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>lastTransitionTime</span>:<span style=color:#bbb> </span>2018-01-01T00:00:00Z<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>containerStatuses</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:green;font-weight:700>containerID</span>:<span style=color:#bbb> </span>docker://abcd...<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>ready</span>:<span style=color:#bbb> </span><span style=color:#a2f;font-weight:700>true</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:#00f;font-weight:700>...</span><span style=color:#bbb>
</span></span></span></code></pre></div><p>Les conditions du Pod que vous ajoutez doivent avoir des noms qui sont conformes au <a href=/docs/concepts/overview/working-with-objects/labels/#syntax-and-character-set>format des étiquettes</a> de Kubernetes.</p><h3 id=statut-pod-disponibilité>Statut de la disponibilité d'un Pod</h3><p>La commande <code>kubectl patch</code> ne peut pas patcher le statut d'un objet.
Pour renseigner ces <code>status.conditions</code> pour le pod, les applications et
<a class=glossary-tooltip title='A specialized controller used to manage a custom resource' data-toggle=tooltip data-placement=top href=/docs/concepts/extend-kubernetes/operator/ target=_blank aria-label=operators>operators</a> doivent utiliser l'action <code>PATCH</code>.
Vous pouvez utiliser une <a href=/docs/reference/using-api/client-libraries/>bibliothèque client Kubernetes</a> pour
écrire du code qui renseigne les conditions particulières pour la disponibilité dun Pod.</p><p>Pour un Pod utilisant des conditions particulières, ce Pod est considéré prêt <strong>seulement</strong>
lorsque les deux déclarations ci-dessous sont vraies :</p><ul><li>Tous les conteneurs du Pod sont prêts.</li><li>Toutes les conditions spécifiées dans <code>ReadinessGates</code> sont <code>True</code>.</li></ul><p>Lorsque les conteneurs d'un Pod sont prêts mais qu'au moins une condition particulière
est manquante ou <code>False</code>, le kubelet renseigne la condition du Pod à <code>ContainersReady</code>.</p><h2 id=politique-de-redémarrage>Politique de redémarrage</h2><p>La structure PodSpec a un champ <code>restartPolicy</code> avec comme valeur possible
Always, OnFailure et Never. La valeur par défaut est Always.
<code>restartPolicy</code> s'applique à tous les Conteneurs du Pod. <code>restartPolicy</code> s'applique
seulement aux redémarrages des Conteneurs par kubelet sur le même nœud. Des conteneurs
terminés qui sont redémarrés par kubelet sont redémarrés avec un délai exponentiel
(10s, 20s, 40s ...) plafonné à cinq minutes, qui est réinitialisé après dix minutes
d'exécution normale. Comme discuté dans le
<a href=/docs/user-guide/pods/#durability-of-pods-or-lack-thereof>document sur les Pods</a>,
une fois attaché à un nœud, un Pod ne sera jamais rattaché à un autre nœud.</p><h2 id=durée-de-vie-d-un-pod>Durée de vie d'un Pod</h2><p>En général, les Pods restent jusqu'à ce qu'un humain ou un process de
<a class=glossary-tooltip title="Boucle de contrôle surveillant l'état partagé du cluster à travers l'apiserver et effectuant des changements en essayant de déplacer l'état actuel vers l'état désiré." data-toggle=tooltip data-placement=top href=/docs/admin/kube-controller-manager/ target=_blank aria-label=contrôleur>contrôleur</a> les supprime explicitement.</p><p>Le plan de contrôle nettoie les Pods terminés (avec une phase à <code>Succeeded</code> ou
<code>Failed</code>), lorsque le nombre de Pods excède le seuil configuré
(determiné par <code>terminated-pod-gc-threshold</code> dans le kube-controller-manager).
Ceci empêche une fuite de ressources lorsque les Pods sont créés et supprimés au fil du temps.</p><p>Il y a différents types de ressources pour créer des Pods :</p><ul><li><p>Utilisez un <a class=glossary-tooltip title='Objet API gérant une application répliquée.' data-toggle=tooltip data-placement=top href=/docs/concepts/workloads/controllers/deployment/ target=_blank aria-label=Déploiement>Déploiement</a>,
<a class=glossary-tooltip title='ReplicaSet ensures that a specified number of Pod replicas are running at one time' data-toggle=tooltip data-placement=top href=/docs/concepts/workloads/controllers/replicaset/ target=_blank aria-label=ReplicaSet>ReplicaSet</a> ou <a class=glossary-tooltip title="Gère le déploiement et la mise à l'échelle d'un ensemble de Pods, avec un stockage durable et des identifiants persistants pour chaque Pod." data-toggle=tooltip data-placement=top href=/fr/docs/concepts/workloads/controllers/statefulset/ target=_blank aria-label=StatefulSet>StatefulSet</a>
pour les Pods qui ne sont pas censés terminer, par exemple des serveurs web.</p></li><li><p>Utilisez un <a class=glossary-tooltip title='A finite or batch task that runs to completion.' data-toggle=tooltip data-placement=top href=/docs/concepts/workloads/controllers/job/ target=_blank aria-label=Job>Job</a>
pour les Pods qui sont censés se terminer une fois leur tâche accomplie. Les Jobs sont appropriés
seulement pour des Pods ayant <code>restartPolicy</code> égal à OnFailure ou Never.</p></li><li><p>Utilisez un <a class=glossary-tooltip title="S'assure qu'une copie d'un Pod s'exécute sur un ensemble de nœuds d'un cluster." data-toggle=tooltip data-placement=top href=/docs/concepts/workloads/controllers/daemonset target=_blank aria-label=DaemonSet>DaemonSet</a>
pour les Pods qui doivent s'exécuter sur chaque noeud éligible.</p></li></ul><p>Toutes les ressources de charges de travail contiennent une PodSpec. Il est recommandé de créer
la ressource de charges de travail appropriée et laisser le contrôleur de la ressource créer les Pods
pour vous, plutôt que de créer directement les Pods vous-même.</p><p>Si un nœud meurt ou est déconnecté du reste du cluster, Kubernetes applique
une politique pour mettre la <code>phase</code> de tous les Pods du nœud perdu à Failed.</p><h2 id=exemples>Exemples</h2><h3 id=exemple-avancé-de-liveness-probe>Exemple avancé de liveness probe</h3><p>Les Liveness probes sont exécutées par kubelet, toutes les requêtes sont donc faites
dans l'espace réseau de kubelet.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>labels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>test</span>:<span style=color:#bbb> </span>liveness<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>liveness-http<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>args</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- /server<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>k8s.gcr.io/liveness<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>livenessProbe</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>httpGet</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:#080;font-style:italic># lorsque &#34;host&#34; n&#39;est pas défini, &#34;PodIP&#34; sera utilisé</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:#080;font-style:italic># host: my-host</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:#080;font-style:italic># lorsque &#34;scheme&#34; n&#39;est pas défini, &#34;HTTP&#34; sera utilisé. &#34;HTTP&#34; et &#34;HTTPS&#34; sont les seules valeurs possibles</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:#080;font-style:italic># scheme: HTTPS</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>path</span>:<span style=color:#bbb> </span>/healthz<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>port</span>:<span style=color:#bbb> </span><span style=color:#666>8080</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>httpHeaders</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>X-Custom-Header<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>value</span>:<span style=color:#bbb> </span>Awesome<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>initialDelaySeconds</span>:<span style=color:#bbb> </span><span style=color:#666>15</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>timeoutSeconds</span>:<span style=color:#bbb> </span><span style=color:#666>1</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>liveness<span style=color:#bbb>
</span></span></span></code></pre></div><h3 id=exemples-d-états>Exemples d'états</h3><ul><li><p>Un Pod est en cours d'exécution et a un Conteneur. Le conteneur se termine avec succès.</p><ul><li>Écriture d'un événement de complétion.</li><li>Si <code>restartPolicy</code> est :<ul><li>Always : Redémarrage du Conteneur ; la <code>phase</code> du Pod reste à Running.</li><li>OnFailure : la <code>phase</code> du Pod passe à Succeeded.</li><li>Never : la <code>phase</code> du Pod passe à Succeeded.</li></ul></li></ul></li><li><p>Un Pod est en cours d'exécution et a un Conteneur. Le conteneur se termine en erreur.</p><ul><li>Écriture d'un événement d'échec.</li><li>Si <code>restartPolicy</code> est :<ul><li>Always : Redémarrage du Conteneur ; la <code>phase</code> du Pod reste à Running.</li><li>OnFailure : Redémarrage du Conteneur ; la <code>phase</code> du Pod reste à Running.</li><li>Never : la <code>phase</code> du Pod passe à Failed.</li></ul></li></ul></li><li><p>Un Pod est en cours d'exécution et a deux Conteneurs. Le conteneur 1 termine en erreur.</p><ul><li>Écriture d'un événement d'échec.</li><li>Si <code>restartPolicy</code> est :<ul><li>Always : Redémarrage du Conteneur ; la <code>phase</code> du Pod reste à Running.</li><li>OnFailure : Redémarrage du Conteneur ; la <code>phase</code> du Pod reste à Running.</li><li>Never : Le Conteneur n'est pas redémarré ; la <code>phase</code> du Pod reste à Running.</li></ul></li><li>Si Container 1 est arrêté, et Conteneur 2 se termine :<ul><li>Écriture d'un événement d'échec.</li><li>Si <code>restartPolicy</code> est :<ul><li>Always : Redémarrage du Conteneur ; la <code>phase</code> du Pod reste à Running.</li><li>OnFailure : Redémarrage du Conteneur ; la <code>phase</code> du Pod reste à Running.</li><li>Never : la <code>phase</code> du Pod passe à Failed.</li></ul></li></ul></li></ul></li><li><p>Un Pod est en cours d'exécution et a un Conteneur. Le Conteneur n'a plus assez de mémoire.</p><ul><li>Le Conteneur se termine en erreur.</li><li>Écriture d'un événement OOM.</li><li>Si <code>restartPolicy</code> est :<ul><li>Always : Redémarrage du Conteneur ; la <code>phase</code> du Pod reste à Running.</li><li>OnFailure : Redémarrage du Conteneur ; la <code>phase</code> du Pod reste à Running.</li><li>Never : Écriture d'un événement d'erreur ; la <code>phase</code> du Pod passe à Failed.</li></ul></li></ul></li><li><p>Le Pod est en cours d'exécution, et un disque meurt.</p><ul><li>Tous les conteneurs sont tués.</li><li>Écriture d'un événement approprié.</li><li>La <code>phase</code> du Pod devient Failed.</li><li>Si le Pod s'exécute sous un contrôleur, le Pod est recréé ailleurs.</li></ul></li><li><p>Le Pod est en cours d'exécution et son nœud est segmenté.</p><ul><li>Le contrôleur de Nœud attend un certain temps.</li><li>Le contrôleur de Nœud passe la <code>phase</code> du Pod à Failed.</li><li>Si le Pod s'exécute sous un contrôleur, le Pod est recréé ailleurs.</li></ul></li></ul><h2 id=a-suivre>A suivre</h2><ul><li><p>Apprenez par la pratique
<a href=/docs/tasks/configure-pod-container/attach-handler-lifecycle-event/>attacher des handlers à des événements de cycle de vie d'un conteneur</a>.</p></li><li><p>Apprenez par la pratique
<a href=/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/>configurer des liveness, readiness et startup probes</a>.</p></li><li><p>En apprendre plus sur les <a href=/docs/concepts/containers/container-lifecycle-hooks/>hooks de cycle de vie d'un Conteneur</a>.</p></li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-c8d62295ca703fdcef1aaf89fb4c916a>3.4.1.4 - Contraintes de propagation de topologie pour les Pods</h1><div style=margin-top:10px;margin-bottom:10px><b>FEATURE STATE:</b> <code>Kubernetes v1.18 [beta]</code></div><p>Vous pouvez utiliser des <em>contraintes de propagation de topologie</em> pour contrôler comment les <a class=glossary-tooltip title='Le plus petit et le plus simple des objets Kubernetes. Un Pod est un ensemble de conteneurs fonctionnant sur votre cluster.' data-toggle=tooltip data-placement=top href=/fr/docs/concepts/workloads/pods/pod-overview/ target=_blank aria-label=Pods>Pods</a> sont propagés à travers votre cluster parmi les domaines de défaillance comme les régions, zones, noeuds et autres domaines de topologie définis par l'utilisateur. Ceci peut aider à mettre en place de la haute disponibilité et à utiliser efficacement les ressources.</p><h2 id=conditions-préalables>Conditions préalables</h2><h3 id=autoriser-la-feature-gate>Autoriser la Feature Gate</h3><p>La <a href=/docs/reference/command-line-tools-reference/feature-gates/>feature gate</a> <code>EvenPodsSpread</code> doit être autorisée pour
<a class=glossary-tooltip title="Composant sur le master qui expose l'API Kubernetes. Il s'agit du front-end pour le plan de contrôle Kubernetes." data-toggle=tooltip data-placement=top href=/docs/reference/generated/kube-apiserver/ target=_blank aria-label="l'API Server">l'API Server</a> <strong>et</strong> le
<a class=glossary-tooltip title="Composant sur le master qui surveille les pods nouvellement créés qui ne sont pas assignés à un nœud et sélectionne un nœud sur lequel ils vont s'exécuter." data-toggle=tooltip data-placement=top href=/docs/reference/generated/kube-scheduler/ target=_blank aria-label=scheduler>scheduler</a>.</p><h3 id=labels-de-noeuds>Labels de noeuds</h3><p>Les contraintes de propagation de topologie reposent sur les labels de noeuds pour identifier le ou les domaines de topologie dans lesquels se trouve chacun des noeuds. Par exemple, un noeud pourrait avoir les labels: <code>node=node1,zone=us-east-1a,region=us-east-1</code></p><p>Supposons que vous ayez un cluster de 4 noeuds ayant les labels suivants:</p><pre tabindex=0><code>NAME    STATUS   ROLES    AGE     VERSION   LABELS
node1   Ready    &lt;none&gt;   4m26s   v1.16.0   node=node1,zone=zoneA
node2   Ready    &lt;none&gt;   3m58s   v1.16.0   node=node2,zone=zoneA
node3   Ready    &lt;none&gt;   3m17s   v1.16.0   node=node3,zone=zoneB
node4   Ready    &lt;none&gt;   2m43s   v1.16.0   node=node4,zone=zoneB
</code></pre><p>Une vue logique du cluster est celle-ci :</p><pre tabindex=0><code>+---------------+---------------+
|     zoneA     |     zoneB     |
+-------+-------+-------+-------+
| node1 | node2 | node3 | node4 |
+-------+-------+-------+-------+
</code></pre><p>Plutôt que d'appliquer des labels manuellement, vous pouvez aussi réutiliser les <a href=/docs/reference/kubernetes-api/labels-annotations-taints/>labels réputés</a> qui sont créés et renseignés automatiquement dans la plupart des clusters.</p><h2 id=contraintes-de-propagation-pour-les-pods>Contraintes de propagation pour les Pods</h2><h3 id=api>API</h3><p>Le champ <code>pod.spec.topologySpreadConstraints</code> est introduit dans 1.16 comme suit :</p><pre tabindex=0><code>apiVersion: v1
kind: Pod
metadata:
  name: mypod
spec:
  topologySpreadConstraints:
    - maxSkew: &lt;integer&gt;
      minDomains: &lt;integer&gt;
      topologyKey: &lt;string&gt;
      whenUnsatisfiable: &lt;string&gt;
      labelSelector: &lt;object&gt;
</code></pre><p>Vous pouvez définir une ou plusieurs <code>topologySpreadConstraint</code> pour indiquer au kube-scheduler comment placer chaque nouveau Pod par rapport aux Pods déjà existants dans votre cluster. Les champs sont :</p><ul><li><strong>maxSkew</strong> décrit le degré avec lequel les Pods peuvent être inégalement distribués. C'est la différence maximale permise entre le nombre de Pods correspondants entre deux quelconques domaines de topologie d'un type donné. Il doit être supérieur à zéro.</li><li><strong>topologyKey</strong> est la clé des labels de noeuds. Si deux noeuds sont étiquettés avec cette clé et ont des valeurs égales pour ce label, le scheduler considère les deux noeuds dans la même topologie. Le scheduler essaie de placer un nombre équilibré de Pods dans chaque domaine de topologie.</li><li><strong>whenUnsatisfiable</strong> indique comment traiter un Pod qui ne satisfait pas les contraintes de propagation :<ul><li><code>DoNotSchedule</code> (défaut) indique au scheduler de ne pas le programmer.</li><li><code>ScheduleAnyway</code> indique au scheduler de le programmer, tout en priorisant les noeuds minimisant le biais (<em>skew</em>).</li></ul></li><li><strong>labelSelector</strong> est utilisé pour touver les Pods correspondants. Les Pods correspondants à ce sélecteur de labels sont comptés pour déterminer le nombre de Pods dans leurs domaines de topologie correspodants. Voir <a href=/docs/concepts/overview/working-with-objects/labels/#label-selectors>Sélecteurs de labels</a> pour plus de détails.</li></ul><p>Vous pouvez en savoir plus sur ces champ en exécutant <code>kubectl explain Pod.spec.topologySpreadConstraints</code>.</p><h3 id=exemple-une-topologyspreadconstraint>Exemple : Une TopologySpreadConstraint</h3><p>Supposons que vous ayez un cluster de 4 noeuds où 3 Pods étiquettés <code>foo:bar</code> sont placés sur node1, node2 et node3 respectivement (<code>P</code> représente un Pod) :</p><pre tabindex=0><code>+---------------+---------------+
|     zoneA     |     zoneB     |
+-------+-------+-------+-------+
| node1 | node2 | node3 | node4 |
+-------+-------+-------+-------+
|   P   |   P   |   P   |       |
+-------+-------+-------+-------+
</code></pre><p>Si nous voulons qu'un nouveau Pod soit uniformément réparti avec les Pods existants à travers les zones, la spec peut être :</p><div class=highlight><div class=copy-code-icon style=text-align:right><a href=https://raw.githubusercontent.com/kubernetes/website/main/content/fr/examples/pods/topology-spread-constraints/one-constraint.yaml download=pods/topology-spread-constraints/one-constraint.yaml><code>pods/topology-spread-constraints/one-constraint.yaml</code></a>
<img src=/images/copycode.svg style=max-height:24px;cursor:pointer onclick='copyCode("pods-topology-spread-constraints-one-constraint-yaml")' title="Copy pods/topology-spread-constraints/one-constraint.yaml to clipboard"></img></div><div class=includecode id=pods-topology-spread-constraints-one-constraint-yaml><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>mypod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>labels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>foo</span>:<span style=color:#bbb> </span>bar<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>topologySpreadConstraints</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>maxSkew</span>:<span style=color:#bbb> </span><span style=color:#666>1</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>topologyKey</span>:<span style=color:#bbb> </span>zone<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>whenUnsatisfiable</span>:<span style=color:#bbb> </span>DoNotSchedule<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>labelSelector</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>matchLabels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>foo</span>:<span style=color:#bbb> </span>bar<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>pause<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>k8s.gcr.io/pause:3.1<span style=color:#bbb>
</span></span></span></code></pre></div></div></div><p><code>topologyKey: zone</code> implique que la distribution uniforme sera uniquement appliquée pour les noeuds ayant le label "zone:&lt;any value>" présent. <code>whenUnsatisfiable: DoNotSchedule</code> indique au scheduler de laisser le Pod dans l'état Pending si le Pod entrant ne peut pas satisfaire la contrainte.</p><p>Si le scheduler plaçait ce Pod entrant dans "zoneA", la distribution des Pods deviendrait [3, 1], et le biais serait de 2 (3 - 1) - ce qui va à l'encontre de <code>maxSkew: 1</code>. Dans cet exemple, le Pod entrant peut uniquement être placé dans "zoneB":</p><pre tabindex=0><code>+---------------+---------------+      +---------------+---------------+
|     zoneA     |     zoneB     |      |     zoneA     |     zoneB     |
+-------+-------+-------+-------+      +-------+-------+-------+-------+
| node1 | node2 | node3 | node4 |  OR  | node1 | node2 | node3 | node4 |
+-------+-------+-------+-------+      +-------+-------+-------+-------+
|   P   |   P   |   P   |   P   |      |   P   |   P   |  P P  |       |
+-------+-------+-------+-------+      +-------+-------+-------+-------+
</code></pre><p>Vous pouvez ajuster la spec du Pod pour pour répondre à divers types d'exigences :</p><ul><li>Changez <code>maxSkew</code> pour une valeur plus grande comme "2" pour que le Pod entrant puisse aussi être placé dans la "zoneA".</li><li>Changez <code>topologyKey</code> pour "node" pour distribuer les Pods uniformément à travers les noeuds et non plus les zones. Dans l'exemple ci-dessus, si <code>maxSkew</code> reste à "1", le Pod entrant peut être uniquement placé dans "node4".</li><li>Changez <code>whenUnsatisfiable: DoNotSchedule</code> en <code>whenUnsatisfiable: ScheduleAnyway</code> pour s'assurer que le Pod est toujours programmable (en supposant que les autres APIs de scheduling soient satisfaites). Cependant, il sera de préférence placé dans la topologie de domaine ayant le moins de Pods correspondants. (Prenez note que cette préférence est normalisée conjointement avec d'autres priorités de scheduling interne comme le ratio d'usage de ressources, etc.)</li></ul><h3 id=example-plusieurs-topologyspreadconstraints>Example: Plusieurs TopologySpreadConstraints</h3><p>Cela s'appuie sur l'exemple précédent. Supposons que vous ayez un cluster de 4 noeuds où 3 Pods étiquetés <code>foo:bar</code> sont placés sur node1, node2 et node3 respectivement (<code>P</code> représente un Pod):</p><pre tabindex=0><code>+---------------+---------------+
|     zoneA     |     zoneB     |
+-------+-------+-------+-------+
| node1 | node2 | node3 | node4 |
+-------+-------+-------+-------+
|   P   |   P   |   P   |       |
+-------+-------+-------+-------+
</code></pre><p>Vous pouvez utiliser 2 TopologySpreadConstraints pour contrôler la répartition des Pods aussi bien dans les zones que dans les noeuds :</p><div class=highlight><div class=copy-code-icon style=text-align:right><a href=https://raw.githubusercontent.com/kubernetes/website/main/content/fr/examples/pods/topology-spread-constraints/two-constraints.yaml download=pods/topology-spread-constraints/two-constraints.yaml><code>pods/topology-spread-constraints/two-constraints.yaml</code></a>
<img src=/images/copycode.svg style=max-height:24px;cursor:pointer onclick='copyCode("pods-topology-spread-constraints-two-constraints-yaml")' title="Copy pods/topology-spread-constraints/two-constraints.yaml to clipboard"></img></div><div class=includecode id=pods-topology-spread-constraints-two-constraints-yaml><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>mypod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>labels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>foo</span>:<span style=color:#bbb> </span>bar<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>topologySpreadConstraints</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>maxSkew</span>:<span style=color:#bbb> </span><span style=color:#666>1</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>topologyKey</span>:<span style=color:#bbb> </span>zone<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>whenUnsatisfiable</span>:<span style=color:#bbb> </span>DoNotSchedule<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>labelSelector</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>matchLabels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>foo</span>:<span style=color:#bbb> </span>bar<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>maxSkew</span>:<span style=color:#bbb> </span><span style=color:#666>1</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>topologyKey</span>:<span style=color:#bbb> </span>node<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>whenUnsatisfiable</span>:<span style=color:#bbb> </span>DoNotSchedule<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>labelSelector</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>matchLabels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>foo</span>:<span style=color:#bbb> </span>bar<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>pause<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>k8s.gcr.io/pause:3.1<span style=color:#bbb>
</span></span></span></code></pre></div></div></div><p>Dans ce cas, pour satisfaire la première contrainte, le Pod entrant peut uniquement être placé dans "zoneB" ; alors que pour satisfaire la seconde contrainte, le Pod entrant peut uniquement être placé dans "node4". Le résultat étant l'intersection des résultats des 2 contraintes, l'unique option possible est de placer le Pod entrant dans "node4".</p><p>Plusieurs contraintes peuvent entraîner des conflits. Supposons que vous ayez un cluster de 3 noeuds couvrant 2 zones :</p><pre tabindex=0><code>+---------------+-------+
|     zoneA     | zoneB |
+-------+-------+-------+
| node1 | node2 | node3 |
+-------+-------+-------+
|  P P  |   P   |  P P  |
+-------+-------+-------+
</code></pre><p>Si vous appliquez "two-constraints.yaml" à ce cluster, vous noterez que "mypod" reste dans l'état <code>Pending</code>. Cela parce que : pour satisfaire la première contrainte, "mypod" peut uniquement être placé dans "zoneB"; alors que pour satisfaire la seconde contrainte, "mypod" peut uniquement être placé sur "node2". Ainsi, le résultat de l'intersection entre "zoneB" et "node2" ne retourne rien.</p><p>Pour surmonter cette situation, vous pouvez soit augmenter <code>maxSkew</code>, soit modifier une des contraintes pour qu'elle utilise <code>whenUnsatisfiable: ScheduleAnyway</code>.</p><h3 id=conventions>Conventions</h3><p>Il existe quelques conventions implicites qu'il est intéressant de noter ici :</p><ul><li><p>Seuls le Pods du même espace de noms que le Pod entrant peuvent être des candidats pour la correspondance.</p></li><li><p>Les noeuds sans label <code>topologySpreadConstraints[*].topologyKey</code> seront ignorés. Cela induit que :</p><ol><li>les Pods localisés sur ces noeuds n'impactent pas le calcul de <code>maxSkew</code> - dans l'exemple ci-dessus, supposons que "node1" n'a pas de label "zone", alors les 2 Pods ne seront pas comptés, et le Pod entrant sera placé dans "zoneA".</li><li>le Pod entrant n'a aucune chance d'être programmé sur ce type de noeuds - dans l'exemple ci-dessus, supposons qu'un "node5" portant un label <code>{zone-typo: zoneC}</code> joigne le cluster ; il sera ignoré, en raison de l'absence de label "zone".</li></ol></li><li><p>Faites attention à ce qui arrive lorsque le <code>topologySpreadConstraints[*].labelSelector</code> du Pod entrant ne correspond pas à ses propres labels. Dans l'exemple ci-dessus, si nous supprimons les labels du Pod entrant, il sera toujours placé dans "zoneB" car les contraintes sont toujours satisfaites. Cependant, après le placement, le degré de déséquilibre du cluster reste inchangé - zoneA contient toujours 2 Pods ayant le label {foo:bar}, et zoneB contient 1 Pod cayant le label {foo:bar}. Si ce n'est pas ce que vous attendez, nous recommandons que <code>topologySpreadConstraints[*].labelSelector</code> du workload corresponde à ses propres labels.</p></li><li><p>Si le Pod entrant a défini <code>spec.nodeSelector</code> ou <code>spec.affinity.nodeAffinity</code>, les noeuds non correspondants seront ignorés.</p><p>Supposons que vous ayez un cluster de 5 noeuds allant de zoneA à zoneC :</p><pre tabindex=0><code>+---------------+---------------+-------+
|     zoneA     |     zoneB     | zoneC |
+-------+-------+-------+-------+-------+
| node1 | node2 | node3 | node4 | node5 |
+-------+-------+-------+-------+-------+
|   P   |   P   |   P   |       |       |
+-------+-------+-------+-------+-------+
</code></pre><p>et vous savez que "zoneC" doit être exclue. Dans ce cas, vous pouvez écrire le yaml ci-dessous, pour que "mypod" soit placé dans "zoneB" plutôt que dans "zoneC". <code>spec.nodeSelector</code> est pris en compte de la même manière.</p><div class=highlight><div class=copy-code-icon style=text-align:right><a href=https://raw.githubusercontent.com/kubernetes/website/main/content/fr/examples/pods/topology-spread-constraints/one-constraint-with-nodeaffinity.yaml download=pods/topology-spread-constraints/one-constraint-with-nodeaffinity.yaml><code>pods/topology-spread-constraints/one-constraint-with-nodeaffinity.yaml</code></a>
<img src=/images/copycode.svg style=max-height:24px;cursor:pointer onclick='copyCode("pods-topology-spread-constraints-one-constraint-with-nodeaffinity-yaml")' title="Copy pods/topology-spread-constraints/one-constraint-with-nodeaffinity.yaml to clipboard"></img></div><div class=includecode id=pods-topology-spread-constraints-one-constraint-with-nodeaffinity-yaml><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Pod<span style=color:#bbb>
    </span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
    </span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
    </span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>mypod<span style=color:#bbb>
    </span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>labels</span>:<span style=color:#bbb>
    </span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>foo</span>:<span style=color:#bbb> </span>bar<span style=color:#bbb>
    </span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
    </span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>topologySpreadConstraints</span>:<span style=color:#bbb>
    </span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>maxSkew</span>:<span style=color:#bbb> </span><span style=color:#666>1</span><span style=color:#bbb>
    </span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>topologyKey</span>:<span style=color:#bbb> </span>zone<span style=color:#bbb>
    </span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>whenUnsatisfiable</span>:<span style=color:#bbb> </span>DoNotSchedule<span style=color:#bbb>
    </span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>labelSelector</span>:<span style=color:#bbb>
    </span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>matchLabels</span>:<span style=color:#bbb>
    </span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>foo</span>:<span style=color:#bbb> </span>bar<span style=color:#bbb>
    </span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>affinity</span>:<span style=color:#bbb>
    </span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>nodeAffinity</span>:<span style=color:#bbb>
    </span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>requiredDuringSchedulingIgnoredDuringExecution</span>:<span style=color:#bbb>
    </span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>nodeSelectorTerms</span>:<span style=color:#bbb>
    </span></span></span><span style=display:flex><span><span style=color:#bbb>        </span>- <span style=color:green;font-weight:700>matchExpressions</span>:<span style=color:#bbb>
    </span></span></span><span style=display:flex><span><span style=color:#bbb>          </span>- <span style=color:green;font-weight:700>key</span>:<span style=color:#bbb> </span>zone<span style=color:#bbb>
    </span></span></span><span style=display:flex><span><span style=color:#bbb>            </span><span style=color:green;font-weight:700>operator</span>:<span style=color:#bbb> </span>NotIn<span style=color:#bbb>
    </span></span></span><span style=display:flex><span><span style=color:#bbb>            </span><span style=color:green;font-weight:700>values</span>:<span style=color:#bbb>
    </span></span></span><span style=display:flex><span><span style=color:#bbb>            </span>- zoneC<span style=color:#bbb>
    </span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
    </span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>pause<span style=color:#bbb>
    </span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>k8s.gcr.io/pause:3.1<span style=color:#bbb>
    </span></span></span></code></pre></div></div></div></li></ul><h3 id=contraintes-par-défaut-au-niveau-du-cluster>Contraintes par défaut au niveau du cluster</h3><div style=margin-top:10px;margin-bottom:10px><b>FEATURE STATE:</b> <code>Kubernetes v1.18 [alpha]</code></div><p>Il est possible de définir des contraintes de propagation de topologie par défaut pour un cluster. Les contraintes de propagation de topologie sont appliquées à un Pod si et seulement si :</p><ul><li>Il ne définit aucune contrainte dans son <code>.spec.topologySpreadConstraints</code>.</li><li>Il appartient à un service, replication controller, replica set ou stateful set.</li></ul><p>Les contraintes par défaut peuvent être définies comme arguments du plugin <code>PodTopologySpread</code>
dans un <a href=/docs/reference/scheduling/profiles>profil de scheduling</a>.
Les contraintes sont spécifiées avec la même <a href=#api>API ci-dessus</a>, à l'exception que
<code>labelSelector</code> doit être vide. Les sélecteurs sont calculés à partir des services,
replication controllers, replica sets ou stateful sets auxquels le Pod appartient.</p><p>Un exemple de configuration pourrait ressembler à :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>kubescheduler.config.k8s.io/v1alpha2<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>KubeSchedulerConfiguration<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>profiles</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>schedulerName</span>:<span style=color:#bbb> </span>default-scheduler<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>pluginConfig</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>PodTopologySpread<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>args</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>defaultConstraints</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>            </span>- <span style=color:green;font-weight:700>maxSkew</span>:<span style=color:#bbb> </span><span style=color:#666>1</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>              </span><span style=color:green;font-weight:700>topologyKey</span>:<span style=color:#bbb> </span>topology.kubernetes.io/zone<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>              </span><span style=color:green;font-weight:700>whenUnsatisfiable</span>:<span style=color:#bbb> </span>ScheduleAnyway<span style=color:#bbb>
</span></span></span></code></pre></div><div class="alert alert-info note callout" role=alert><strong>Note:</strong> Le score produit par les contraintes de scheduling par défaut peuvent rentrer en conflit avec le score
produit par le <a href=/docs/reference/scheduling/profiles/#scheduling-plugins>plugin <code>DefaultPodTopologySpread</code></a>.
Il est recommandé de désactiver ce plugin dans le profil de scheduling lorsque vous utilisez des contraintes
par défaut pour <code>PodTopologySpread</code>.</div><h2 id=comparaison-avec-podaffinity-podantiaffinity>Comparaison avec PodAffinity/PodAntiAffinity</h2><p>Dans Kubernetes, les directives relatives aux "Affinités" contrôlent comment les Pods sont
programmés - plus regroupés ou plus dispersés.</p><ul><li>Pour <code>PodAffinity</code>, vous pouvez essayer de regrouper un certain nombre de Pods dans des domaines de topologie qualifiés,</li><li>Pour <code>PodAntiAffinity</code>, seulement un Pod peut être programmé dans un domaine de topologie unique.</li></ul><p>La fonctionnalité "EvenPodsSpread" fournit des options flexibles pour distribuer des Pods uniformément sur différents domaines de topologie - pour mettre en place de la haute disponibilité ou réduire les coûts. Cela peut aussi aider
au rolling update des charges de travail et à la mise à l'échelle de réplicas. Voir <a href=https://github.com/kubernetes/enhancements/tree/master/keps/sig-scheduling/895-pod-topology-spread#motivation>Motivations</a> pour plus de détails.</p><h2 id=limitations-connues>Limitations connues</h2><p>En version 1.18, pour laquelle cette fonctionnalité est en Beta, il y a quelques limitations connues :</p><ul><li>Réduire un Déploiement peut résulter en une distrubution désiquilibrée des Pods.</li><li>Les Pods correspondants sur des noeuds taintés sont respectés. Voir <a href=https://github.com/kubernetes/kubernetes/issues/80921>Issue 80921</a></li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-1ccbd4eeded6ab138d98b59175bd557e>3.4.1.5 - Init Containers</h1><p>Cette page fournit une vue d'ensemble des <em>conteneurs d'initialisation</em> (init containers) : des conteneurs spécialisés qui s'exécutent avant les conteneurs d'application dans un <a class=glossary-tooltip title='Le plus petit et le plus simple des objets Kubernetes. Un Pod est un ensemble de conteneurs fonctionnant sur votre cluster.' data-toggle=tooltip data-placement=top href=/fr/docs/concepts/workloads/pods/pod-overview/ target=_blank aria-label=Pod>Pod</a>.
Les init containers peuvent contenir des utilitaires ou des scripts d'installation qui ne sont pas présents dans une image d'application.</p><p>Vous pouvez spécifier des init containers dans la spécification du Pod à côté du tableau <code>containers</code> (qui décrit les conteneurs d'application)</p><h2 id=comprendre-les-init-containers>Comprendre les init containers</h2><p>Un <a class=glossary-tooltip title='Le plus petit et le plus simple des objets Kubernetes. Un Pod est un ensemble de conteneurs fonctionnant sur votre cluster.' data-toggle=tooltip data-placement=top href=/fr/docs/concepts/workloads/pods/pod-overview/ target=_blank aria-label=Pod>Pod</a> peut avoir plusieurs conteneurs exécutant des applications mais peut aussi avoir un ou plusieurs init containers, qui sont exécutés avant que les conteneurs d'application ne démarrent.</p><p>Les init containers se comportent comme les conteneurs réguliers, avec quelques différences :</p><ul><li>Les init containers s'exécutent toujours jusqu'à la complétion.</li><li>Chaque init container doit se terminer avec succès avant que le prochain ne démarre.</li></ul><p>Si le init container d'un Pod échoue, Kubernetes redémarre le Pod à répétition jusqu'à ce que le init container se termine avec succès.
Cependant, si le Pod a une <code>restartPolicy</code> à "Never", Kubernetes ne redémarre pas le Pod.</p><p>Afin de spécifier un init container pour un Pod, il faut ajouter le champ <code>initContainers</code> dans la spécification du Pod, comme un
tableau d'objets de type <a href=/docs/reference/generated/kubernetes-api/v1.25/#container-v1-core>Container</a>, au même niveau que le tableau d'applications <code>containers</code>.
Le statut des init containers est retourné dans le champ <code>.status.initContainerStatuses</code>
comme un tableau des statuts du conteneur (comparable au champ <code>.status.containerStatuses</code>).</p><h3 id=différences-avec-les-conteneurs-réguliers>Différences avec les conteneurs réguliers</h3><p>Les init containers supportent tous les champs et fonctionnalités des conteneurs d'application
incluant les limites de ressources, les volumes et les paramètres de sécurité.
Cependant, les demandes de ressources pour un init container sont gérées différemment des
limites de ressources, tel que documenté dans <a href=#ressources>Ressources</a>.</p><p>De plus, les init containers ne supportent pas les readiness probes parce que ces conteneurs
s'exécutent jusqu'au bout avant que le Pod soit prêt.</p><p>Si l'on spécifie plusieurs init containers pour un Pod, Kubelet exécute chaque
init container de manière séquentielle.
Chaque init container doit se terminer avec succès avant que le prochain ne puisse s'exécuter.
Lorsque tous les init containers se sont exécutés jusqu'au bout, Kubelet initialise
les conteneurs d'application pour le Pod et les exécute comme d'habitude.</p><h2 id=utiliser-les-init-containers>Utiliser les init containers</h2><p>Puisque les init containers ont des images séparées des conteneurs d'application,
ils apportent certains avantages pour du code de mise en route :</p><ul><li>Les init containers peuvent contenir des utilitaires ou du code de configuration personnalisé
qui ne sont pas présents dans une image d'application.
Par exemple, il n'y a pas besoin de faire hériter une image d'une autre (<code>FROM</code>) seulement pour utiliser
un outil comme <code>sed</code>, <code>awk</code>, <code>python</code>, ou <code>dig</code> pendant l'installation.</li><li>Les init containers peuvent exécuter en toute sécurité des utilitaires qui rendraient moins sécurisée une image de conteneur d'application.</li><li>Les rôles "builder" et "deployer" d'une image d'application peuvent travailler indépendamment sans qu'il n'y ait besoin
de créer conjointement une seule image d'application.</li><li>Les init containers peuvent s'exécuter avec une vue du système de fichiers différente de celle des conteneurs d'application dans le même Pod. Par conséquent, on peut leur donner accès aux <a class=glossary-tooltip title='Stores sensitive information, such as passwords, OAuth tokens, and ssh keys.' data-toggle=tooltip data-placement=top href=/docs/concepts/configuration/secret/ target=_blank aria-label=Secrets>Secrets</a>, auxquels les conteneurs d'application n'ont pas accès.</li><li>Puisque les init containers s'exécutent jusqu'à la complétion avant qu'un conteneur d'application ne démarre, les init containers
offrent un mécanisme pour bloquer ou retarder le démarrage d'un conteneur d'application tant qu'un ensemble de préconditions n'est pas respecté. Une fois que les préconditions sont respectées, tous les conteneurs d'application dans un Pod peuvent démarrer en parallèle.</li></ul><h3 id=exemples>Exemples</h3><p>Voici plusieurs idées pour utiliser les init containers :</p><ul><li><p>Attendre qu'un <a class=glossary-tooltip title="Un moyen d'exposer une application s'exécutant sur un ensemble de pods en tant que service réseau." data-toggle=tooltip data-placement=top href=/fr/docs/concepts/services-networking/service/ target=_blank aria-label=Service>Service</a> soit créé,
en utilisant une commande shell d'une ligne telle que :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span><span style=color:#a2f;font-weight:700>for</span> i in <span style=color:#666>{</span>1..100<span style=color:#666>}</span>; <span style=color:#a2f;font-weight:700>do</span> sleep 1; <span style=color:#a2f;font-weight:700>if</span> dig myservice; <span style=color:#a2f;font-weight:700>then</span> <span style=color:#a2f>exit</span> 0; <span style=color:#a2f;font-weight:700>fi</span>; <span style=color:#a2f;font-weight:700>done</span>; <span style=color:#a2f>exit</span> <span style=color:#666>1</span>
</span></span></code></pre></div></li><li><p>Enregistrer ce Pod à un serveur distant depuis l'API downward avec une commande telle que :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>curl -X POST http://<span style=color:#b8860b>$MANAGEMENT_SERVICE_HOST</span>:<span style=color:#b8860b>$MANAGEMENT_SERVICE_PORT</span>/register -d <span style=color:#b44>&#39;instance=$(&lt;POD_NAME&gt;)&amp;ip=$(&lt;POD_IP&gt;)&#39;</span>
</span></span></code></pre></div></li><li><p>Attendre un certain temps avant de démarrer le conteneur d'application avec une commande telle que :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>sleep <span style=color:#666>60</span>
</span></span></code></pre></div></li><li><p>Cloner un dépôt Git dans un <a class=glossary-tooltip title="Un répertoire contenant des données, accessible aux conteneurs d'un pod." data-toggle=tooltip data-placement=top href=/fr/docs/concepts/storage/volumes/ target=_blank aria-label=Volume>Volume</a></p></li><li><p>Placer des valeurs dans un fichier de configuration et exécuter un outil de templating pour générer
dynamiquement un fichier de configuration pour le conteneur d'application principal.
Par exemple, placer la valeur <code>POD_IP</code> dans une configuration et générer le fichier de configuration de l'application principale
en utilisant Jinja.</p></li></ul><h4 id=les-init-containers-en-utilisation>Les init containers en utilisation</h4><p>Cet exemple définit un simple Pod possédant deux init containers.
Le premier attend <code>myservice</code> et le second attend <code>mydb</code>. Une fois que les deux
init containers terminent leur exécution, le Pod exécute le conteneur d'application décrit dans sa section <code>spec</code>.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>myapp-pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>labels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>app.kubernetes.io/name</span>:<span style=color:#bbb> </span>MyApp<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>myapp-container<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>busybox:1.28<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>command</span>:<span style=color:#bbb> </span>[<span style=color:#b44>&#39;sh&#39;</span>,<span style=color:#bbb> </span><span style=color:#b44>&#39;-c&#39;</span>,<span style=color:#bbb> </span><span style=color:#b44>&#39;echo &#34;L&#39;&#39;app s&#39;&#39;exécute!&#34; &amp;&amp; sleep 3600&#39;</span>]<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>initContainers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>init-myservice<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>busybox:1.28<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>command</span>:<span style=color:#bbb> </span>[<span style=color:#b44>&#39;sh&#39;</span>,<span style=color:#bbb> </span><span style=color:#b44>&#39;-c&#39;</span>,<span style=color:#bbb> </span><span style=color:#b44>&#34;until nslookup myservice.$(cat /var/run/secrets/kubernetes.io/serviceaccount/namespace).svc.cluster.local; do echo en attente de myservice; sleep 2; done&#34;</span>]<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>init-mydb<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>busybox:1.28<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>command</span>:<span style=color:#bbb> </span>[<span style=color:#b44>&#39;sh&#39;</span>,<span style=color:#bbb> </span><span style=color:#b44>&#39;-c&#39;</span>,<span style=color:#bbb> </span><span style=color:#b44>&#34;until nslookup mydb.$(cat /var/run/secrets/kubernetes.io/serviceaccount/namespace).svc.cluster.local; do echo en attente de mydb; sleep 2; done&#34;</span>]<span style=color:#bbb>
</span></span></span></code></pre></div><p>Les fichiers YAML suivants résument les services <code>mydb</code> et <code>myservice</code> :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Service<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>myservice<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>ports</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>protocol</span>:<span style=color:#bbb> </span>TCP<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>port</span>:<span style=color:#bbb> </span><span style=color:#666>80</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>targetPort</span>:<span style=color:#bbb> </span><span style=color:#666>9376</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:#00f;font-weight:700>---</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Service<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>mydb<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>ports</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>protocol</span>:<span style=color:#bbb> </span>TCP<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>port</span>:<span style=color:#bbb> </span><span style=color:#666>80</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>targetPort</span>:<span style=color:#bbb> </span><span style=color:#666>9377</span><span style=color:#bbb>
</span></span></span></code></pre></div><p>Vous pouvez démarrer ce Pod en exécutant :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl apply -f myapp.yaml
</span></span></code></pre></div><pre tabindex=0><code>pod/myapp-pod created
</code></pre><p>Et vérifier son statut avec :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get -f myapp.yaml
</span></span></code></pre></div><pre tabindex=0><code>NAME        READY     STATUS     RESTARTS   AGE
myapp-pod   0/1       Init:0/2   0          6m
</code></pre><p>ou pour plus de détails :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl describe -f myapp.yaml
</span></span></code></pre></div><pre tabindex=0><code>Name:          myapp-pod
Namespace:     default
[...]
Labels:        app.kubernetes.io/name=MyApp
Status:        Pending
[...]
Init Containers:
  init-myservice:
[...]
    State:         Running
[...]
  init-mydb:
[...]
    State:         Waiting
      Reason:      PodInitializing
    Ready:         False
[...]
Containers:
  myapp-container:
[...]
    State:         Waiting
      Reason:      PodInitializing
    Ready:         False
[...]
Events:
  FirstSeen    LastSeen    Count    From                      SubObjectPath                           Type          Reason        Message
  ---------    --------    -----    ----                      -------------                           --------      ------        -------
  16s          16s         1        {default-scheduler }                                              Normal        Scheduled     Successfully assigned myapp-pod to 172.17.4.201
  16s          16s         1        {kubelet 172.17.4.201}    spec.initContainers{init-myservice}     Normal        Pulling       pulling image &#34;busybox&#34;
  13s          13s         1        {kubelet 172.17.4.201}    spec.initContainers{init-myservice}     Normal        Pulled        Successfully pulled image &#34;busybox&#34;
  13s          13s         1        {kubelet 172.17.4.201}    spec.initContainers{init-myservice}     Normal        Created       Created container with docker id 5ced34a04634; Security:[seccomp=unconfined]
  13s          13s         1        {kubelet 172.17.4.201}    spec.initContainers{init-myservice}     Normal        Started       Started container with docker id 5ced34a04634
</code></pre><p>Pour voir les logs des init containers dans ce Pod, exécuter :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl logs myapp-pod -c init-myservice <span style=color:#080;font-style:italic># Inspecter le premier init container</span>
</span></span><span style=display:flex><span>kubectl logs myapp-pod -c init-mydb      <span style=color:#080;font-style:italic># Inspecter le second init container</span>
</span></span></code></pre></div><p>À ce stade, ces init containers attendent de découvrir les services nommés
<code>mydb</code> et <code>myservice</code>.</p><p>Voici une configuration que vous pouvez utiliser pour faire apparaître ces Services :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#00f;font-weight:700>---</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Service<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>myservice<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>ports</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>protocol</span>:<span style=color:#bbb> </span>TCP<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>port</span>:<span style=color:#bbb> </span><span style=color:#666>80</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>targetPort</span>:<span style=color:#bbb> </span><span style=color:#666>9376</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:#00f;font-weight:700>---</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Service<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>mydb<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>ports</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>protocol</span>:<span style=color:#bbb> </span>TCP<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>port</span>:<span style=color:#bbb> </span><span style=color:#666>80</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>targetPort</span>:<span style=color:#bbb> </span><span style=color:#666>9377</span><span style=color:#bbb>
</span></span></span></code></pre></div><p>Pour créer les services <code>mydb</code> et <code>myservice</code> :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl apply -f services.yaml
</span></span></code></pre></div><pre tabindex=0><code>service/myservice created
service/mydb created
</code></pre><p>Vous verrez ensuite que ces init containers se terminent et que le Pod <code>myapp-pod</code> évolue vers l'état "Running" (en exécution) :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get -f myapp.yaml
</span></span></code></pre></div><pre tabindex=0><code>NAME        READY     STATUS    RESTARTS   AGE
myapp-pod   1/1       Running   0          9m
</code></pre><p>Cet exemple simple devrait suffire à vous inspirer pour créer vos propres init containers.
<a href=#a-suivre>A suivre</a> contient un lien vers un exemple plus détaillé.</p><h2 id=comportement-détaillé>Comportement détaillé</h2><p>Pendant le démarrage d'un Pod, chaque init container démarre en ordre, après que le réseau
et les volumes ont été initialisés. Chaque conteneur doit se terminer avec succès avant que le prochain
ne démarre. Si un conteneur n'arrive pas à démarrer à cause d'un problème d'exécution ou
se termine avec un échec, il est redémarré selon la <code>restartPolicy</code> du Pod.
Toutefois, si la <code>restartPolicy</code> du Pod est configurée à "Always", les init containers utilisent la <code>restartPolicy</code> "OnFailure".</p><p>Un Pod ne peut pas être <code>Ready</code> tant que tous les init containers ne se sont pas exécutés avec succès.
Les ports d'un init container ne sont pas agrégés sous un Service. Un Pod qui s'initialise
est dans l'état <code>Pending</code> mais devrait avoir une condition <code>Initialized</code> configurée à "true".</p><p>Si le Pod <a href=#raisons-du-red%C3%A9marrage-d-un-pod>redémarre</a> ou est redémarré, tous les init containers
doivent s'exécuter à nouveau.</p><p>Les changements aux spec d'un init containers sont limités au champ image du conteneur.
Changer le champ image d'un init container équivaut à redémarrer le Pod.</p><p>Puisque les init containers peuvent être redémarrés, réessayés ou ré-exécutés,
leur code doit être idempotent. En particulier, le code qui écrit dans des fichiers sur <code>EmptyDirs</code>
devrait être préparé à la possibilité qu'un fichier de sortie existe déjà.</p><p>Les init containers ont tous les champs d'un conteneur d'application.
Cependant, Kubernetes interdit l'utilisation de <code>readinessProbe</code> parce que les init containers
ne peuvent pas définir une "readiness" distincte de la complétion. Ceci est appliqué lors de la validation.</p><p>L'utilisation de <code>activeDeadlineSeconds</code> sur le Pod et <code>livenessProbe</code> sur le conteneur
permet d'empêcher les init containers d'échouer tout le temps.
La deadline active inclut les init containers.</p><p>Le nom de chaque application et init container dans un Pod doit être unique; une erreur de validation
est générée pour tout conteneur partageant un nom avec un autre.</p><h3 id=ressources>Ressources</h3><p>Étant donné l'ordonnancement et l'exécution des init containers, les règles suivantes s'appliquent pour l'utilisation des ressources :</p><ul><li>La plus haute requête ou limite particulière de ressource définie pour tous les init containers
est la <em>limite/requête d'initialisation effective</em></li><li>La <em>limite/requête effective</em> d'un Pod pour une ressource est la plus haute parmis :<ul><li>la somme de toutes les requêtes/limites des conteneurs d'application pour une ressource</li><li>la limite/requête d'initialisation effective pour une ressource</li></ul></li><li>Le Scheduling est effectué sur la base des requêtes/limites effectives, ce qui signifie
que les init containers peuvent réserver des ressources pour l'initialisation qui ne sont pas utilisées durant le
cycle de vie du Pod.</li><li>La QoS (qualité de service) tierce de la <em>QoS tierce effective</em> d'un Pod est la QoS tierce aussi bien pour les init containers
que pour les conteneurs d'application.</li></ul><p>Les quotas et limites sont appliqués sur la base de la requête/limite effective d'un Pod.</p><p>Les groupes de contrôle au niveau du Pod (<a class=glossary-tooltip title="Un groupe de processus Linux avec des options d'isolation, de suivi, et de limites des ressources." data-toggle=tooltip data-placement=top href='/fr/docs/reference/glossary/?all=true#term-cgroup' target=_blank aria-label=cgroups>cgroups</a>) sont basés sur la requête/limite effective de Pod, la même que
celle du scheduler.</p><h3 id=raisons-du-redémarrage-d-un-pod>Raisons du redémarrage d'un Pod</h3><p>Un Pod peut redémarrer, ce qui cause la ré-exécution des init containers, pour les raisons suivantes :</p><ul><li>Un utilisateur met à jour les spécifications du Pod, ce qui cause le changement de l'image de l'init container.
Tout changement à l'image du init container redémarre le Pod. Les changements au conteneur d'application entraînent seulement le
redémarrage du conteneur d'application.</li><li>Le conteneur d'infrastructure Pod est redémarré. Ceci est peu commun et serait effectué par une personne ayant un accès root aux nœuds.</li><li>Tous les conteneurs dans un Pod sont terminés tandis que <code>restartPolicy</code> est configurée à "Always", ce qui force le redémarrage, et l'enregistrement de complétion du init container a été perdu à cause d'une opération de garbage collection (récupération de mémoire).</li></ul><h2 id=a-suivre>A suivre</h2><ul><li>Lire à propos de la <a href=/docs/tasks/configure-pod-container/configure-pod-initialization/#creating-a-pod-that-has-an-init-container>création d'un Pod ayant un init container</a></li><li>Apprendre à <a href=/docs/tasks/debug/debug-application/debug-init-containers/>debugger les init containers</a></li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-89637410cacae45a36ab1cc278c482eb>3.4.2 - Contrôleurs</h1></div><div class=td-content><h1 id=pg-d459b930218774655fa7fd1620625539>3.4.2.1 - ReplicaSet</h1><p>Un ReplicaSet (ensemble de réplicas en français) a pour but de maintenir un ensemble stable de Pods à un moment donné.
Cet objet est souvent utilisé pour garantir la disponibilité d'un certain nombre identique de Pods.</p><h2 id=comment-un-replicaset-fonctionne>Comment un ReplicaSet fonctionne</h2><p>Un ReplicaSet est défini avec des champs, incluant un selecteur qui spécifie comment identifier les Pods qu'il peut posséder,
un nombre de replicas indiquant le nombre de Pods qu'il doit maintenir et un modèle de Pod spécifiant les données que les
nouveaux Pods que le replicatSet va créer jusqu'au nombre de replicas demandé.</p><p>Un ReplicaSet va atteindre son objectif en créant et supprimant des Pods pour atteindre le nombre de réplicas désirés.
Quand un ReplicaSet a besoin de créer de nouveaux Pods, il utilise alors son Pod template.</p><p>Le lien d'un ReplicaSet à ses Pods est fait par le champ <a href=/docs/concepts/workloads/controllers/garbage-collection/#owners-and-dependents>metadata.ownerReferences</a>,
qui spécifie la ressource de l'objet par lequel il est détenu. Tous les Pods acquis par un ReplicaSet ont leurs propres informations d'identification de leur Replicaset, avec leur propre champ ownerReferences. C'est par ce lien que le ReplicaSet connait l'état des Pods qu'il maintient et agit en fonction de ces derniers.</p><p>Un ReplicaSet identifie des nouveaux Pods à acquérir en utilisant son selecteur.
Si il y a un Pod qui n'a pas de OwnerReference ou que OwnerReference n'est pas un controller et qu'il correspond à un sélecteur de ReplicaSet, il va immédiatement être acquis par ce ReplicaSet.</p><h2 id=quand-utiliser-un-replicaset>Quand utiliser un ReplicaSet ?</h2><p>Un ReplicaSet garantit qu’un nombre spécifié de réplicas de Pod soient exécutés à un moment donné.
Cependant, un Deployment est un concept de plus haut niveau qui gère les ReplicaSets et
fournit des mises à jour déclaratives aux Pods ainsi que de nombreuses autres fonctionnalités utiles.
Par conséquent, nous vous recommandons d’utiliser des Deployments au lieu d’utiliser directement des ReplicaSets, sauf si
vous avez besoin d'une orchestration personnalisée des mises à jour ou si vous n'avez pas besoin de mises à jour.</p><p>Cela signifie qu'il est possible que vous n'ayez jamais besoin de manipuler des objets ReplicaSet :
utilisez plutôt un déploiement et définissez votre application dans la section spec.</p><h2 id=exemple>Exemple</h2><div class=highlight><div class=copy-code-icon style=text-align:right><a href=https://raw.githubusercontent.com/kubernetes/website/main/content/fr/examples/controllers/frontend.yaml download=controllers/frontend.yaml><code>controllers/frontend.yaml</code></a>
<img src=/images/copycode.svg style=max-height:24px;cursor:pointer onclick='copyCode("controllers-frontend-yaml")' title="Copy controllers/frontend.yaml to clipboard"></img></div><div class=includecode id=controllers-frontend-yaml><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>apps/v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>ReplicaSet<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>frontend<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>labels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>app</span>:<span style=color:#bbb> </span>guestbook<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>tier</span>:<span style=color:#bbb> </span>frontend<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:#080;font-style:italic># modify replicas according to your case</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>replicas</span>:<span style=color:#bbb> </span><span style=color:#666>3</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>selector</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>matchLabels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>tier</span>:<span style=color:#bbb> </span>frontend<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>template</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>labels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>tier</span>:<span style=color:#bbb> </span>frontend<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>php-redis<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>gcr.io/google_samples/gb-frontend:v3<span style=color:#bbb>
</span></span></span></code></pre></div></div></div><p>Enregistrer ce manifeste dans <code>frontend.yaml</code> et le soumettre à un cluster Kubernetes va créer le ReplicaSet défini et les pods qu’il gère.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl apply -f https://kubernetes.io/examples/controllers/frontend.yaml
</span></span></code></pre></div><p>Vous pouvez ensuite récupérer les ReplicaSets actuellement déployés :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get rs
</span></span></code></pre></div><p>Et voir le frontend que vous avez créé :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>NAME       DESIRED   CURRENT   READY   AGE
</span></span><span style=display:flex><span>frontend   <span style=color:#666>3</span>         <span style=color:#666>3</span>         <span style=color:#666>3</span>       6s
</span></span></code></pre></div><p>Vous pouvez également vérifier l'état du ReplicaSet :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl describe rs/frontend
</span></span></code></pre></div><p>Et vous verrez une sortie similaire à :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>Name:		frontend
</span></span><span style=display:flex><span>Namespace:	default
</span></span><span style=display:flex><span>Selector:	<span style=color:#b8860b>tier</span><span style=color:#666>=</span>frontend,tier in <span style=color:#666>(</span>frontend<span style=color:#666>)</span>
</span></span><span style=display:flex><span>Labels:		<span style=color:#b8860b>app</span><span style=color:#666>=</span>guestbook
</span></span><span style=display:flex><span>		<span style=color:#b8860b>tier</span><span style=color:#666>=</span>frontend
</span></span><span style=display:flex><span>Annotations:	&lt;none&gt;
</span></span><span style=display:flex><span>Replicas:	<span style=color:#666>3</span> current / <span style=color:#666>3</span> desired
</span></span><span style=display:flex><span>Pods Status:	<span style=color:#666>3</span> Running / <span style=color:#666>0</span> Waiting / <span style=color:#666>0</span> Succeeded / <span style=color:#666>0</span> Failed
</span></span><span style=display:flex><span>Pod Template:
</span></span><span style=display:flex><span>  Labels:       <span style=color:#b8860b>app</span><span style=color:#666>=</span>guestbook
</span></span><span style=display:flex><span>                <span style=color:#b8860b>tier</span><span style=color:#666>=</span>frontend
</span></span><span style=display:flex><span>  Containers:
</span></span><span style=display:flex><span>   php-redis:
</span></span><span style=display:flex><span>    Image:      gcr.io/google_samples/gb-frontend:v3
</span></span><span style=display:flex><span>    Port:       80/TCP
</span></span><span style=display:flex><span>    Requests:
</span></span><span style=display:flex><span>      cpu:      100m
</span></span><span style=display:flex><span>      memory:   100Mi
</span></span><span style=display:flex><span>    Environment:
</span></span><span style=display:flex><span>      GET_HOSTS_FROM:   dns
</span></span><span style=display:flex><span>    Mounts:             &lt;none&gt;
</span></span><span style=display:flex><span>  Volumes:              &lt;none&gt;
</span></span><span style=display:flex><span>Events:
</span></span><span style=display:flex><span>  FirstSeen    LastSeen    Count    From                SubobjectPath    Type        Reason            Message
</span></span><span style=display:flex><span>  ---------    --------    -----    ----                -------------    --------    ------            -------
</span></span><span style=display:flex><span>  1m           1m          <span style=color:#666>1</span>        <span style=color:#666>{</span>replicaset-controller <span style=color:#666>}</span>             Normal      SuccessfulCreate  Created pod: frontend-qhloh
</span></span><span style=display:flex><span>  1m           1m          <span style=color:#666>1</span>        <span style=color:#666>{</span>replicaset-controller <span style=color:#666>}</span>             Normal      SuccessfulCreate  Created pod: frontend-dnjpy
</span></span><span style=display:flex><span>  1m           1m          <span style=color:#666>1</span>        <span style=color:#666>{</span>replicaset-controller <span style=color:#666>}</span>             Normal      SuccessfulCreate  Created pod: frontend-9si5l
</span></span></code></pre></div><p>Et enfin, vous pourrez afficher les Pods déployés :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get Pods
</span></span></code></pre></div><p>Vous devriez voir des informations sur les Pods avec une sortie similaire à :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>NAME             READY     STATUS    RESTARTS   AGE
</span></span><span style=display:flex><span>frontend-9si5l   1/1       Running   <span style=color:#666>0</span>          1m
</span></span><span style=display:flex><span>frontend-dnjpy   1/1       Running   <span style=color:#666>0</span>          1m
</span></span><span style=display:flex><span>frontend-qhloh   1/1       Running   <span style=color:#666>0</span>          1m
</span></span></code></pre></div><p>Vous pouvez également vérifier que la OwnerReference de ces pods est définie sur le frontend ReplicaSet.
Pour ce faire, récupérez le yaml de l’un des pods :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get pods frontend-9si5l -o yaml
</span></span></code></pre></div><p>La sortie sera similaire à celle-ci, avec les informations de l'interface ReplicaSet frontend définies dans le champ ownerReferences des métadonnées:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>apiVersion: v1
</span></span><span style=display:flex><span>kind: Pod
</span></span><span style=display:flex><span>metadata:
</span></span><span style=display:flex><span>  creationTimestamp: 2019-01-31T17:20:41Z
</span></span><span style=display:flex><span>  generateName: frontend-
</span></span><span style=display:flex><span>  labels:
</span></span><span style=display:flex><span>    tier: frontend
</span></span><span style=display:flex><span>  name: frontend-9si5l
</span></span><span style=display:flex><span>  namespace: default
</span></span><span style=display:flex><span>  ownerReferences:
</span></span><span style=display:flex><span>  - apiVersion: extensions/v1beta1
</span></span><span style=display:flex><span>    blockOwnerDeletion: <span style=color:#a2f>true</span>
</span></span><span style=display:flex><span>    controller: <span style=color:#a2f>true</span>
</span></span><span style=display:flex><span>    kind: ReplicaSet
</span></span><span style=display:flex><span>    name: frontend
</span></span><span style=display:flex><span>    uid: 892a2330-257c-11e9-aecd-025000000001
</span></span><span style=display:flex><span>...
</span></span></code></pre></div><h2 id=acquisitions-de-pod-en-dehors-du-template>Acquisitions de Pod en dehors du template</h2><p>Bien que vous puissiez créer des pods manuellement sans problème, il est fortement recommandé de s’assurer que ces pods n'ont pas de
labels correspondant au sélecteur de l’un de vos ReplicaSets. Car un ReplicaSet n’est pas limité
à posséder les pods spécifiés par son modèle - il peut acquérir d’autres pods de la manière spécifiée dans les sections précédentes.</p><p>Prenez l'exemple précédent de ReplicaSet, ainsi que les pods spécifiés dans le manifeste suivant :</p><div class=highlight><div class=copy-code-icon style=text-align:right><a href=https://raw.githubusercontent.com/kubernetes/website/main/content/fr/examples/pods/pod-rs.yaml download=pods/pod-rs.yaml><code>pods/pod-rs.yaml</code></a>
<img src=/images/copycode.svg style=max-height:24px;cursor:pointer onclick='copyCode("pods-pod-rs-yaml")' title="Copy pods/pod-rs.yaml to clipboard"></img></div><div class=includecode id=pods-pod-rs-yaml><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>pod1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>labels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>tier</span>:<span style=color:#bbb> </span>frontend<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>hello1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>gcr.io/google-samples/hello-app:2.0<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:#00f;font-weight:700>---</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>pod2<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>labels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>tier</span>:<span style=color:#bbb> </span>frontend<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>hello2<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>gcr.io/google-samples/hello-app:1.0<span style=color:#bbb>
</span></span></span></code></pre></div></div></div><p>Ces pods n’ayant pas de contrôleur (ni d’objet) en tant que référence propriétaire, ils correspondent au sélecteur de du ReplicaSet frontend, ils seront donc immédiatement acquis par ce ReplicaSet.</p><p>Supposons que vous créiez les pods une fois le ReplicaSet frontend déployé et qui a déjà déployé ses replicas de Pods initiaux afin de
remplir son exigence de nombre de replicas :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl apply -f https://kubernetes.io/examples/pods/pod-rs.yaml
</span></span></code></pre></div><p>Les nouveaux pods seront acquis par le ReplicaSet, puis immédiatement terminés car le ReplicaSet dépasserait alors le compte désiré.</p><p>En récupérant les pods :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get Pods
</span></span></code></pre></div><p>La sortie montre que les nouveaux pods sont soit déjà terminés, soit en voie de l'être :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>NAME             READY   STATUS        RESTARTS   AGE
</span></span><span style=display:flex><span>frontend-9si5l   1/1     Running       <span style=color:#666>0</span>          1m
</span></span><span style=display:flex><span>frontend-dnjpy   1/1     Running       <span style=color:#666>0</span>          1m
</span></span><span style=display:flex><span>frontend-qhloh   1/1     Running       <span style=color:#666>0</span>          1m
</span></span><span style=display:flex><span>pod2             0/1     Terminating   <span style=color:#666>0</span>          4s
</span></span></code></pre></div><p>Cependant, si vous créez d'abord les pods :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl apply -f https://kubernetes.io/examples/pods/pod-rs.yaml
</span></span></code></pre></div><p>Et puis créez le ReplicaSet :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl apply -f https://kubernetes.io/examples/controllers/frontend.yaml
</span></span></code></pre></div><p>Vous verrez que le ReplicaSet a acquis les pods et n'a créé que les nouveaux Pods manquants, conformément à ses spécifications,
jusqu'au nombre souhaité de Pods. En récupérant les Pods :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get Pods
</span></span></code></pre></div><p>La sortie va donner :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>NAME             READY   STATUS    RESTARTS   AGE
</span></span><span style=display:flex><span>frontend-pxj4r   1/1     Running   <span style=color:#666>0</span>          5s
</span></span><span style=display:flex><span>pod1             1/1     Running   <span style=color:#666>0</span>          13s
</span></span><span style=display:flex><span>pod2             1/1     Running   <span style=color:#666>0</span>          13s
</span></span></code></pre></div><p>De cette manière, un ReplicaSet peut avoir un ensemble de Pods hétérogène.</p><h2 id=écrire-un-manifest-de-replicaset>Écrire un manifest de ReplicaSet</h2><p>Comme avec tous les autres objets API Kubernetes, un ReplicaSet a besoin des champs <code>apiVersion</code>, <code>kind</code> et <code>metadata</code>.
Pour ReplicaSets, l'attribut <code>kind</code> est toujours ReplicaSet.</p><p>Dans Kubernetes 1.9, la version de l'API <code>apps/v1</code> pour le type ReplicaSet est la version actuelle et activée par défaut. La version de l'API <code>apps/v1beta2</code> est obsolète.</p><p>Reportez-vous aux premières lignes de l'exemple <code>frontend.yaml</code> pour obtenir des conseils.</p><p>Un ReplicaSet a également besoin de <a href=https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#spec-and-status><code>.spec</code> section</a>.</p><h3 id=pod-template>Pod Template</h3><p>L'attribut <code>.spec.template</code> est un <a href=/docs/concepts/workloads/Pods/pod-overview/#pod-templates>modèle de pod</a> qui requiert d'avoir des labels. Dans notre exemple <code>frontend.yaml</code>, nous avons un label : <code>tier: frontend</code>.
Il faut faire attention à ne pas avoir des selecteurs que d'autres controllers utilisent, afin d'éviter que le ReplicaSet n'adopte ce pod.</p><p>Pour le champ <a href=/docs/concepts/workloads/pods/pod-lifecycle/#restart-policy>restart policy</a>,
<code>.spec.template.spec.restartPolicy</code>, la seule valeur autorisée est <code>Always</code>, qui est la valeur par défaut.</p><h3 id=sélecteur-de-pod>Sélecteur de Pod</h3><p>Le champ <code>.spec.selector</code> est un <a href=/docs/concepts/overview/working-with-objects/labels/>label selector</a>. Tel que discuté
<a href=#how-a-replicaset-works>précédemment</a>, ce sont les labels utilisés pour identifier les Pods potentiels à acquérir. Dans notre
exemple avec <code>frontend.yaml</code>, le sélecteur était :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>matchLabels:
</span></span><span style=display:flex><span>	tier: frontend
</span></span></code></pre></div><p>Dans le ReplicaSet, <code>.spec.template.metadata.labels</code> doit correspondre à <code>spec.selector</code>, ou sinon il sera rejeté par l'API.</p><div class="alert alert-info note callout" role=alert><strong>Note:</strong> Pour 2 ReplicaSets spécifiant le même <code>.spec.selector</code> mais différents <code>.spec.template.metadata.labels</code> et <code>.spec.template.spec</code>, chaque ReplicaSet ignore les pods créés par l'autre ReplicaSet.</div><h3 id=replicas>Replicas</h3><p>Vous pouvez spécifier le nombre de pods à exécuter simultanément en définissant <code>.spec.replicas</code>. Le ReplicaSet va créer/supprimer
ses pods pour correspondre à ce nombre.</p><p>Si vous ne spécifiez pas <code>.spec.replicas</code>, la valeur par défaut est 1.</p><h2 id=travailler-avec-des-replicasets>Travailler avec des ReplicaSets</h2><h3 id=suppression-d-un-replicaset-et-de-ses-pods>Suppression d'un ReplicaSet et de ses pods</h3><p>Pour supprimer un ReplicaSet et tous ses pods, utilisez <a href=/docs/reference/generated/kubectl/kubectl-commands#delete><code>kubectl delete</code></a>. The <a href=/docs/concepts/workloads/controllers/garbage-collection/>Garbage collector</a> supprime automatiquement tous les pods associés par défaut.</p><p>Lors de l’utilisation de l’API REST ou de la bibliothèque <code>client-go</code>, vous devez définir <code>propagationPolicy</code> sur <code>Background</code> ou <code>Foreground</code> dans
l'option -d.
Par exemple :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl proxy --port<span style=color:#666>=</span><span style=color:#666>8080</span>
</span></span><span style=display:flex><span>curl -X DELETE  <span style=color:#b44>&#39;localhost:8080/apis/extensions/v1beta1/namespaces/default/replicasets/frontend&#39;</span> <span style=color:#b62;font-weight:700>\
</span></span></span><span style=display:flex><span><span style=color:#b62;font-weight:700></span>&gt; -d <span style=color:#b44>&#39;{&#34;kind&#34;:&#34;DeleteOptions&#34;,&#34;apiVersion&#34;:&#34;v1&#34;,&#34;propagationPolicy&#34;:&#34;Foreground&#34;}&#39;</span> <span style=color:#b62;font-weight:700>\
</span></span></span><span style=display:flex><span><span style=color:#b62;font-weight:700></span>&gt; -H <span style=color:#b44>&#34;Content-Type: application/json&#34;</span>
</span></span></code></pre></div><h3 id=supprimer-juste-un-replicaset>Supprimer juste un ReplicaSet</h3><p>Vous pouvez supprimer un ReplicaSet sans affecter ses pods à l’aide de <a href=/docs/reference/generated/kubectl/kubectl-commands#delete><code>kubectl delete</code></a> avec l'option <code>--cascade=false</code>.
Lorsque vous utilisez l'API REST ou la bibliothèque <code>client-go</code>, vous devez définir <code>propagationPolicy</code> sur <code>Orphan</code>.
Par exemple :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl proxy --port<span style=color:#666>=</span><span style=color:#666>8080</span>
</span></span><span style=display:flex><span>curl -X DELETE  <span style=color:#b44>&#39;localhost:8080/apis/extensions/v1beta1/namespaces/default/replicasets/frontend&#39;</span> <span style=color:#b62;font-weight:700>\
</span></span></span><span style=display:flex><span><span style=color:#b62;font-weight:700></span>&gt; -d <span style=color:#b44>&#39;{&#34;kind&#34;:&#34;DeleteOptions&#34;,&#34;apiVersion&#34;:&#34;v1&#34;,&#34;propagationPolicy&#34;:&#34;Orphan&#34;}&#39;</span> <span style=color:#b62;font-weight:700>\
</span></span></span><span style=display:flex><span><span style=color:#b62;font-weight:700></span>&gt; -H <span style=color:#b44>&#34;Content-Type: application/json&#34;</span>
</span></span></code></pre></div><p>Une fois l’original supprimé, vous pouvez créer un nouveau ReplicaSet pour le remplacer. Tant que l'ancien et le nouveau <code>.spec.selector</code> sont identiques, le nouveau adoptera les anciens Pods.
Cependant, le ReplicaSet ne fera aucun effort pour que les pods existants correspondent à un nouveau Pod template.
Pour mettre à jour les Pods à une nouvelle spec de manière contrôlée, utilisez un
<a href=/docs/concepts/workloads/controllers/deployment/#creating-a-deployment>Deployment</a>, car les ReplicaSets ne supportent pas de rolling update directement.</p><h3 id=isoler-les-pods-d-un-replicaset>Isoler les pods d'un ReplicaSet</h3><p>Vous pouvez supprimer les pods d'un ReplicaSet en modifiant leurs labels. Cette technique peut être utilisée pour enlever les pods
pour le débogage, récupération de données, etc. Les pods ainsi supprimés seront automatiquement remplacés
(en supposant que le nombre de réplicas n’est pas également modifié).</p><h3 id=scaling-d-un-replicaset>Scaling d'un ReplicaSet</h3><p>Un ReplicaSet peut facilement être scalé en mettant simplement à jour le champ <code>.spec.replicas</code>. Le contrôleur ReplicaSet
garantit que le nombre souhaité de pods avec un sélecteur de label correspondant soient disponibles et opérationnels.</p><h3 id=replicaset-en-tant-que-horizontal-pod-autoscaler-target>ReplicaSet en tant que Horizontal Pod Autoscaler Target</h3><p>Un ReplicaSet peut également être une cible pour
<a href=/docs/tasks/run-application/horizontal-pod-autoscale/>Horizontal Pod Autoscalers (HPA)</a>.
Un ReplicaSet peut être mis à l'échelle automatiquement par un HPA. Voici un exemple HPA qui cible
le ReplicaSet que nous avons créé dans l'exemple précédent.</p><div class=highlight><div class=copy-code-icon style=text-align:right><a href=https://raw.githubusercontent.com/kubernetes/website/main/content/fr/examples/controllers/hpa-rs.yaml download=controllers/hpa-rs.yaml><code>controllers/hpa-rs.yaml</code></a>
<img src=/images/copycode.svg style=max-height:24px;cursor:pointer onclick='copyCode("controllers-hpa-rs-yaml")' title="Copy controllers/hpa-rs.yaml to clipboard"></img></div><div class=includecode id=controllers-hpa-rs-yaml><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>autoscaling/v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>HorizontalPodAutoscaler<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>frontend-scaler<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>scaleTargetRef</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>ReplicaSet<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>frontend<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>minReplicas</span>:<span style=color:#bbb> </span><span style=color:#666>3</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>maxReplicas</span>:<span style=color:#bbb> </span><span style=color:#666>10</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>targetCPUUtilizationPercentage</span>:<span style=color:#bbb> </span><span style=color:#666>50</span><span style=color:#bbb>
</span></span></span></code></pre></div></div></div><p>Enregistrer ce manifeste dans <code>hpa-rs.yaml</code> et le soumettre à un cluster Kubernetes devrait
créer le HPA défini qui scale automatiquement le ReplicaSet cible en fonction de l'utilisation du processeur
des pods répliqués.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl apply -f https://k8s.io/examples/controllers/hpa-rs.yaml
</span></span></code></pre></div><p>Vous pouvez aussi utiliser la commande <code>kubectl autoscale</code> pour accomplir la même chose.
(et c'est plus facile !)</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl autoscale rs frontend --max<span style=color:#666>=</span><span style=color:#666>10</span>
</span></span></code></pre></div><h2 id=alternatives-au-replicaset>Alternatives au ReplicaSet</h2><h3 id=deployment-recommandé>Deployment (recommandé)</h3><p>Le <a href=/docs/concepts/workloads/controllers/deployment/><code>Deployment</code></a> est un object qui peut posséder les ReplicaSets et les mettres à jour ainsi que leurs Pods de façon déclarative, côté serveur et avec des rolling updates.</p><p>Alors que les ReplicaSets peuvent être utilisés indépendamment, ils sont principalement utilisés aujourd'hui par Deployments comme mécanisme pour orchestrer la création, suppresion et mises à jour des Pods.
Lorsque vous utilisez des Deployments, vous n’aurez plus à vous soucier de la gestion des ReplicaSets ainsi créés.
Les déploiements possèdent et gèrent leurs ReplicaSets.
C'est pourquoi il est recommandé d’utiliser les déploiements lorsque vous voulez des ReplicaSets.</p><h3 id=pods-nus>Pods nus</h3><p>Contrairement au cas où un utilisateur a créé directement des pods, un ReplicaSet remplace les pods supprimés ou terminés pour quelque raison que ce soit, par exemple en cas de défaillance d'un nœud ou de maintenance de nœud perturbateur, telle qu'une mise à jour kernel. Pour cette raison, nous vous recommandons d'utiliser un ReplicaSet même si votre application ne nécessite qu'un seul pod. Pensez-y de la même manière qu’un superviseur de processus, mais il supervise plusieurs pods sur plusieurs nœuds au lieu de processus individuels sur un seul nœud. Un ReplicaSet délègue les redémarrages de conteneurs locaux à un agent du nœud (par exemple, Kubelet ou Docker).</p><h3 id=job>Job</h3><p>Utilisez un <a href=/docs/concepts/jobs/run-to-completion-finite-workloads/><code>Job</code></a> au lieu d'un ReplicaSet pour les pods qui doivent se terminer seuls
(c'est à dire des batch jobs).</p><h3 id=daemonset>DaemonSet</h3><p>Utilisez un <a href=/docs/concepts/workloads/controllers/daemonset/><code>DaemonSet</code></a> au lieu d’un ReplicaSet pour les pods qui fournissent une
fonction au niveau du noeud, comme le monitoring ou la gestion des logs de ce noeud. Ces pods ont une durée de vie qui est liée
durée de vie d’une machine : le pod doit être en cours d’exécution sur la machine avant le démarrage des autres Pods et sont
sûrs de se terminer lorsque la machine est prête à être redémarrée/arrêtée.</p><h3 id=replicationcontroller>ReplicationController</h3><p>Les ReplicaSets sont les successeurs de <a href=/docs/concepts/workloads/controllers/replicationcontroller/><em>ReplicationControllers</em></a>.
Les deux servent le même objectif et se comportent de la même manière, à la différence près que ReplicationController ne prend pas en charge les
les exigences de sélecteur décrites dans le <a href=/docs/concepts/overview/working-with-objects/labels/#label-selectors>labels user guide</a>.
En tant que tels, les ReplicaSets sont préférés aux ReplicationControllers.</p></div><div class=td-content style=page-break-before:always><h1 id=pg-a2dc0393e0c4079e1c504b6429844e86>3.4.2.2 - Déploiements</h1><p>Un <em>Deployment</em> (déploiement en français) fournit des mises à jour déclaratives pour <a href=/fr/docs/concepts/workloads/pods/pod/>Pods</a> et <a href=/fr/docs/concepts/workloads/controllers/replicaset/>ReplicaSets</a>.</p><p>Vous décrivez un <em>état désiré</em> dans un déploiement et le <a class=glossary-tooltip title="Boucle de contrôle surveillant l'état partagé du cluster à travers l'apiserver et effectuant des changements en essayant de déplacer l'état actuel vers l'état désiré." data-toggle=tooltip data-placement=top href=/docs/admin/kube-controller-manager/ target=_blank aria-label=controlleur>controlleur</a> déploiement change l'état réel à l'état souhaité à un rythme contrôlé.
Vous pouvez définir des Deployments pour créer de nouveaux ReplicaSets, ou pour supprimer des déploiements existants et adopter toutes leurs ressources avec de nouveaux déploiements.</p><div class="alert alert-info note callout" role=alert><strong>Note:</strong> Ne gérez pas les ReplicaSets appartenant à un Deployment.
Pensez à ouvrir un ticket dans le dépot Kubernetes principal si votre cas d'utilisation n'est pas traité ci-dessous.</div><h2 id=cas-d-utilisation>Cas d'utilisation</h2><p>Voici des cas d'utilisation typiques pour les déploiements:</p><ul><li><a href=#cr%C3%A9ation-dun-d%C3%A9ploiement>Créer un déploiement pour déployer un ReplicaSet</a>.
Le ReplicaSet crée des pods en arrière-plan.
Vérifiez l'état du déploiement pour voir s'il réussit ou non.</li><li><a href=#mise-%C3%A0-jour-dun-d%C3%A9ploiement>Déclarez le nouvel état des Pods</a> en mettant à jour le PodTemplateSpec du déploiement.
Un nouveau ReplicaSet est créé et le déploiement gère le déplacement des pods de l'ancien ReplicaSet vers le nouveau à un rythme contrôlé.
Chaque nouveau ReplicaSet met à jour la révision du déploiement.</li><li><a href=#annulation-dun-d%C3%A9ploiement>Revenir à une révision de déploiement antérieure</a> si l'état actuel du déploiement n'est pas stable.
Chaque restauration met à jour la révision du déploiement.</li><li><a href=#mise-%C3%A0-l%C3%A9chelle-dun-d%C3%A9ploiement>Augmentez le déploiement pour traiter plus de charge</a>.</li><li><a href=#pause-et-reprise-dun-d%C3%A9ploiement>Suspendre le déploiement</a> d'appliquer plusieurs correctifs à son PodTemplateSpec, puis de le reprendre pour démarrer un nouveau déploiement.</li><li><a href=#statut-de-d%C3%A9ploiement>Utiliser l'état du déploiement</a> comme indicateur qu'un déploiement est bloqué.</li><li><a href=#politique-de-nettoyage>Nettoyer les anciens ReplicaSets</a> dont vous n'avez plus besoin.</li></ul><h2 id=création-d-un-déploiement>Création d'un déploiement</h2><p>Voici un exemple de déploiement.
Il crée un ReplicaSet pour faire apparaître trois pods <code>nginx</code>:</p><div class=highlight><div class=copy-code-icon style=text-align:right><a href=https://raw.githubusercontent.com/kubernetes/website/main/content/fr/examples/controllers/nginx-deployment.yaml download=controllers/nginx-deployment.yaml><code>controllers/nginx-deployment.yaml</code></a>
<img src=/images/copycode.svg style=max-height:24px;cursor:pointer onclick='copyCode("controllers-nginx-deployment-yaml")' title="Copy controllers/nginx-deployment.yaml to clipboard"></img></div><div class=includecode id=controllers-nginx-deployment-yaml><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>apps/v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Deployment<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>nginx-deployment<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>labels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>app</span>:<span style=color:#bbb> </span>nginx<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>replicas</span>:<span style=color:#bbb> </span><span style=color:#666>3</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>selector</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>matchLabels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>app</span>:<span style=color:#bbb> </span>nginx<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>template</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>labels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>app</span>:<span style=color:#bbb> </span>nginx<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>nginx<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>nginx:1.7.9<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>ports</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span>- <span style=color:green;font-weight:700>containerPort</span>:<span style=color:#bbb> </span><span style=color:#666>80</span><span style=color:#bbb>
</span></span></span></code></pre></div></div></div><p>Dans cet exemple:</p><ul><li><p>Un déploiement nommé <code>nginx-deployment</code> est créé, indiqué par le champ <code>.metadata.name</code>.</p></li><li><p>Le déploiement crée trois pods répliqués, indiqués par le champ <code>replicas</code>.</p></li><li><p>Le champ <code>selector</code> définit comment le déploiement trouve les pods à gérer.
Dans ce cas, vous sélectionnez simplement un label définie dans le template de pod (<code>app:nginx</code>).
Cependant, des règles de sélection plus sophistiquées sont possibles, tant que le modèle de pod satisfait lui-même la règle.</p><div class="alert alert-info note callout" role=alert><strong>Note:</strong> Le champ <code>matchLabels</code> est une table de hash {clé, valeur}.
Une seule {clé, valeur} dans la table <code>matchLabels</code> est équivalente à un élément de <code>matchExpressions</code>, dont le champ clé est "clé", l'opérateur est "In" et le tableau de valeurs contient uniquement "valeur".
Toutes les exigences, à la fois de <code>matchLabels</code> et de <code>matchExpressions</code>, doivent être satisfaites pour correspondre.</div></li><li><p>Le champ <code>template</code> contient les sous-champs suivants:</p><ul><li>Les Pods reçoivent le label <code>app:nginx</code> dans le champ <code>labels</code>.</li><li>La spécification du template de pod dans le champ <code>.template.spec</code>, indique que les pods exécutent un conteneur, <code>nginx</code>, qui utilise l'image <code>nginx</code> <a href=https://hub.docker.com/>Docker Hub</a> à la version 1.7.9.</li><li>Créez un conteneur et nommez-le <code>nginx</code> en utilisant le champ <code>name</code>.</li></ul></li></ul><p>Suivez les étapes ci-dessous pour créer le déploiement ci-dessus:</p><p>Avant de commencer, assurez-vous que votre cluster Kubernetes est opérationnel.</p><ol><li><p>Créez le déploiement en exécutant la commande suivante:</p><div class="alert alert-info note callout" role=alert><strong>Note:</strong> Vous pouvez spécifier l'indicateur <code>--record</code> pour écrire la commande exécutée dans l'annotation de ressource <code>kubernetes.io/change-cause</code>.
C'est utile pour une future introspection.
Par exemple, pour voir les commandes exécutées dans chaque révision de déploiement.</div><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl apply -f https://k8s.io/examples/controllers/nginx-deployment.yaml
</span></span></code></pre></div></li><li><p>Exécutez <code>kubectl get deployments</code> pour vérifier si le déploiement a été créé.
Si le déploiement est toujours en cours de création, la sortie est similaire à:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>NAME               READY   UP-TO-DATE   AVAILABLE   AGE
</span></span><span style=display:flex><span>nginx-deployment   0/3     <span style=color:#666>0</span>            <span style=color:#666>0</span>           1s
</span></span></code></pre></div><p>Lorsque vous inspectez les déploiements de votre cluster, les champs suivants s'affichent:</p><ul><li><code>NAME</code> répertorie les noms des déploiements dans le cluster.</li><li><code>DESIRED</code> affiche le nombre souhaité de <em>répliques</em> de l'application, que vous définissez lorsque vous créez le déploiement.
C'est l'<em>état désiré</em>.</li><li><code>CURRENT</code> affiche le nombre de réplicas en cours d'exécution.</li><li><code>UP-TO-DATE</code> affiche le nombre de réplicas qui ont été mises à jour pour atteindre l'état souhaité.</li><li><code>AVAILABLE</code> affiche le nombre de réplicas de l'application disponibles pour vos utilisateurs.</li><li><code>AGE</code> affiche la durée d'exécution de l'application.</li></ul><p>Notez que le nombre de réplicas souhaitées est de 3 selon le champ <code>.spec.replicas</code>.</p></li><li><p>Pour voir l'état du déploiement, exécutez:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl rollout status deployment.v1.apps/nginx-deployment
</span></span></code></pre></div><p>La sortie est similaire à ceci:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>Waiting <span style=color:#a2f;font-weight:700>for</span> rollout to finish: <span style=color:#666>2</span> out of <span style=color:#666>3</span> new replicas have been updated...
</span></span><span style=display:flex><span>deployment <span style=color:#b44>&#34;nginx-deployment&#34;</span> successfully rolled out
</span></span></code></pre></div></li><li><p>Exécutez à nouveau <code>kubectl get deployments</code> quelques secondes plus tard.
La sortie est similaire à ceci:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-text data-lang=text><span style=display:flex><span>NAME               READY   UP-TO-DATE   AVAILABLE   AGE
</span></span><span style=display:flex><span>nginx-deployment   3/3     3            3           18s
</span></span></code></pre></div><p>Notez que le déploiement a créé les trois répliques et que toutes les répliques sont à jour (elles contiennent le dernier modèle de pod) et disponibles.</p></li><li><p>Pour voir le ReplicaSet (<code>rs</code>) créé par le déploiement, exécutez <code>kubectl get rs</code>.
La sortie est similaire à ceci:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-text data-lang=text><span style=display:flex><span>NAME                          DESIRED   CURRENT   READY   AGE
</span></span><span style=display:flex><span>nginx-deployment-75675f5897   3         3         3       18s
</span></span></code></pre></div><p>Notez que le nom du ReplicaSet est toujours formaté comme: <code>[DEPLOYMENT-NAME]-[RANDOM-STRING]</code>.
La chaîne aléatoire est générée aléatoirement et utilise le pod-template-hash comme graine.</p></li><li><p>Pour voir les labels générées automatiquement pour chaque Pod, exécutez <code>kubectl get pods --show-labels</code>.
La sortie est similaire à ceci:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-text data-lang=text><span style=display:flex><span>NAME                                READY     STATUS    RESTARTS   AGE       LABELS
</span></span><span style=display:flex><span>nginx-deployment-75675f5897-7ci7o   1/1       Running   0          18s       app=nginx,pod-template-hash=3123191453
</span></span><span style=display:flex><span>nginx-deployment-75675f5897-kzszj   1/1       Running   0          18s       app=nginx,pod-template-hash=3123191453
</span></span><span style=display:flex><span>nginx-deployment-75675f5897-qqcnn   1/1       Running   0          18s       app=nginx,pod-template-hash=3123191453
</span></span></code></pre></div></li></ol><p>Le ReplicaSet créé garantit qu'il y a trois pods <code>nginx</code>.</p><div class="alert alert-info note callout" role=alert><strong>Note:</strong> Vous devez spécifier un sélecteur approprié et des labels de template de pod dans un déploiement (dans ce cas, <code>app: nginx</code>).
Ne superposez pas les étiquettes ou les sélecteurs avec d'autres contrôleurs (y compris d'autres déploiements et StatefulSets).
Kubernetes n'empêche pas les chevauchements de noms, et si plusieurs contrôleurs ont des sélecteurs qui se chevauchent, ces contrôleurs peuvent entrer en conflit et se comporter de façon inattendue.</div><h3 id=étiquette-pod-template-hash>Étiquette pod-template-hash</h3><div class="alert alert-info note callout" role=alert><strong>Note:</strong> Ne modifiez pas ce label.</div><p>Le label <code>pod-template-hash</code> est ajoutée par le contrôleur de déploiement à chaque ReplicaSet créé ou adopté par un déploiement.</p><p>Ce label garantit que les ReplicaSets enfants d'un déploiement ne se chevauchent pas.
Il est généré en hachant le <code>PodTemplate</code> du ReplicaSet et en utilisant le hachage résultant comme valeur de label qui est ajoutée au sélecteur ReplicaSet, aux labels de template de pod et dans tous les pods existants que le ReplicaSet peut avoir.</p><h2 id=mise-à-jour-d-un-déploiement>Mise à jour d'un déploiement</h2><div class="alert alert-info note callout" role=alert><strong>Note:</strong> Le re-déploiement d'un déploiement est déclenché si et seulement si le modèle de pod du déploiement (c'est-à-dire <code>.spec.template</code>) est modifié, par exemple si les labels ou les images de conteneur du template sont mis à jour.
D'autres mises à jour, telles que la mise à l'échelle du déploiement, ne déclenchent pas de rollout.</div><p>Suivez les étapes ci-dessous pour mettre à jour votre déploiement:</p><ol><li><p>Mettons à jour les pods nginx pour utiliser l'image <code>nginx: 1.9.1</code> au lieu de l'image <code>nginx: 1.7.9</code>.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl --record deployment.apps/nginx-deployment <span style=color:#a2f>set</span> image deployment.v1.apps/nginx-deployment <span style=color:#b8860b>nginx</span><span style=color:#666>=</span>nginx:1.9.1
</span></span></code></pre></div><p>ou utilisez la commande suivante:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl <span style=color:#a2f>set</span> image deployment/nginx-deployment <span style=color:#b8860b>nginx</span><span style=color:#666>=</span>nginx:1.9.1 --record
</span></span></code></pre></div><p>La sortie est similaire à ceci:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-text data-lang=text><span style=display:flex><span>deployment.apps/nginx-deployment image updated
</span></span></code></pre></div><p>Alternativement, vous pouvez <code>éditer</code> le déploiement et changer <code>.spec.template.spec.containers[0].image</code> de <code>nginx: 1.7.9</code> à <code>nginx: 1.9.1</code>:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl edit deployment.v1.apps/nginx-deployment
</span></span></code></pre></div><p>La sortie est similaire à ceci:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-text data-lang=text><span style=display:flex><span>deployment.apps/nginx-deployment edited
</span></span></code></pre></div></li><li><p>Pour voir l'état du déploiement, exécutez:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl rollout status deployment.v1.apps/nginx-deployment
</span></span></code></pre></div><p>La sortie est similaire à ceci:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-text data-lang=text><span style=display:flex><span>Waiting for rollout to finish: 2 out of 3 new replicas have been updated...
</span></span></code></pre></div><p>ou</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-text data-lang=text><span style=display:flex><span>deployment &#34;nginx-deployment&#34; successfully rolled out
</span></span></code></pre></div></li></ol><p>Obtenez plus de détails sur votre déploiement mis à jour:</p><ul><li><p>Une fois le déploiement réussi, vous pouvez afficher le déploiement en exécutant <code>kubectl get deployments</code>.
La sortie est similaire à ceci:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-text data-lang=text><span style=display:flex><span>NAME               READY   UP-TO-DATE   AVAILABLE   AGE
</span></span><span style=display:flex><span>nginx-deployment   3/3     3            3           36s
</span></span></code></pre></div></li><li><p>Exécutez <code>kubectl get rs</code> pour voir que le déploiement a mis à jour les pods en créant un nouveau ReplicaSet et en le redimensionnant jusqu'à 3 replicas, ainsi qu'en réduisant l'ancien ReplicaSet à 0 réplicas.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get rs
</span></span></code></pre></div><p>La sortie est similaire à ceci:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-text data-lang=text><span style=display:flex><span>NAME                          DESIRED   CURRENT   READY   AGE
</span></span><span style=display:flex><span>nginx-deployment-1564180365   3         3         3       6s
</span></span><span style=display:flex><span>nginx-deployment-2035384211   0         0         0       36s
</span></span></code></pre></div></li><li><p>L'exécution de <code>kubectl get pods</code> ne devrait désormais afficher que les nouveaux pods:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get pods
</span></span></code></pre></div><p>La sortie est similaire à ceci:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-text data-lang=text><span style=display:flex><span>NAME                                READY     STATUS    RESTARTS   AGE
</span></span><span style=display:flex><span>nginx-deployment-1564180365-khku8   1/1       Running   0          14s
</span></span><span style=display:flex><span>nginx-deployment-1564180365-nacti   1/1       Running   0          14s
</span></span><span style=display:flex><span>nginx-deployment-1564180365-z9gth   1/1       Running   0          14s
</span></span></code></pre></div><p>La prochaine fois que vous souhaitez mettre à jour ces pods, il vous suffit de mettre à jour le modèle de pod de déploiement à nouveau.</p><p>Le déploiement garantit que seul un certain nombre de pods sont en panne pendant leur mise à jour.
Par défaut, il garantit qu'au moins 75% du nombre souhaité de pods sont en place (25% max indisponible).</p><p>Le déploiement garantit également que seul un certain nombre de pods sont créés au-dessus du nombre souhaité de pods.
Par défaut, il garantit qu'au plus 125% du nombre de pods souhaité sont en hausse (surtension maximale de 25%).</p><p>Par exemple, si vous regardez attentivement le déploiement ci-dessus, vous verrez qu'il a d'abord créé un nouveau pod, puis supprimé certains anciens pods et en a créé de nouveaux.
Il ne tue pas les anciens Pods tant qu'un nombre suffisant de nouveaux Pods n'est pas apparu, et ne crée pas de nouveaux Pods tant qu'un nombre suffisant de Pods anciens n'a pas été tué.
Il s'assure qu'au moins 2 pods sont disponibles et qu'au maximum 4 pods au total sont disponibles.</p></li><li><p>Obtenez les détails de votre déploiement:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl describe deployments
</span></span></code></pre></div><p>La sortie est similaire à ceci:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-text data-lang=text><span style=display:flex><span>Name:                   nginx-deployment
</span></span><span style=display:flex><span>Namespace:              default
</span></span><span style=display:flex><span>CreationTimestamp:      Thu, 30 Nov 2017 10:56:25 +0000
</span></span><span style=display:flex><span>Labels:                 app=nginx
</span></span><span style=display:flex><span>Annotations:            deployment.kubernetes.io/revision=2
</span></span><span style=display:flex><span>Selector:               app=nginx
</span></span><span style=display:flex><span>Replicas:               3 desired | 3 updated | 3 total | 3 available | 0 unavailable
</span></span><span style=display:flex><span>StrategyType:           RollingUpdate
</span></span><span style=display:flex><span>MinReadySeconds:        0
</span></span><span style=display:flex><span>RollingUpdateStrategy:  25% max unavailable, 25% max surge
</span></span><span style=display:flex><span>Pod Template:
</span></span><span style=display:flex><span>    Labels:  app=nginx
</span></span><span style=display:flex><span>    Containers:
</span></span><span style=display:flex><span>    nginx:
</span></span><span style=display:flex><span>        Image:        nginx:1.9.1
</span></span><span style=display:flex><span>        Port:         80/TCP
</span></span><span style=display:flex><span>        Environment:  &lt;none&gt;
</span></span><span style=display:flex><span>        Mounts:       &lt;none&gt;
</span></span><span style=display:flex><span>    Volumes:        &lt;none&gt;
</span></span><span style=display:flex><span>    Conditions:
</span></span><span style=display:flex><span>    Type           Status  Reason
</span></span><span style=display:flex><span>    ----           ------  ------
</span></span><span style=display:flex><span>    Available      True    MinimumReplicasAvailable
</span></span><span style=display:flex><span>    Progressing    True    NewReplicaSetAvailable
</span></span><span style=display:flex><span>    OldReplicaSets:  &lt;none&gt;
</span></span><span style=display:flex><span>    NewReplicaSet:   nginx-deployment-1564180365 (3/3 replicas created)
</span></span><span style=display:flex><span>    Events:
</span></span><span style=display:flex><span>    Type    Reason             Age   From                   Message
</span></span><span style=display:flex><span>    ----    ------             ----  ----                   -------
</span></span><span style=display:flex><span>    Normal  ScalingReplicaSet  2m    deployment-controller  Scaled up replica set nginx-deployment-2035384211 to 3
</span></span><span style=display:flex><span>    Normal  ScalingReplicaSet  24s   deployment-controller  Scaled up replica set nginx-deployment-1564180365 to 1
</span></span><span style=display:flex><span>    Normal  ScalingReplicaSet  22s   deployment-controller  Scaled down replica set nginx-deployment-2035384211 to 2
</span></span><span style=display:flex><span>    Normal  ScalingReplicaSet  22s   deployment-controller  Scaled up replica set nginx-deployment-1564180365 to 2
</span></span><span style=display:flex><span>    Normal  ScalingReplicaSet  19s   deployment-controller  Scaled down replica set nginx-deployment-2035384211 to 1
</span></span><span style=display:flex><span>    Normal  ScalingReplicaSet  19s   deployment-controller  Scaled up replica set nginx-deployment-1564180365 to 3
</span></span><span style=display:flex><span>    Normal  ScalingReplicaSet  14s   deployment-controller  Scaled down replica set nginx-deployment-2035384211 to 0
</span></span></code></pre></div><p>Ici, vous voyez que lorsque vous avez créé le déploiement pour la première fois, il a créé un ReplicaSet (nginx-deployment-2035384211) et l'a mis à l'échelle directement jusqu'à 3 réplicas.
Lorsque vous avez mis à jour le déploiement, il a créé un nouveau ReplicaSet (nginx-deployment-1564180365) et l'a mis à l'échelle jusqu'à 1, puis a réduit l'ancien ReplicaSet à 2, de sorte qu'au moins 2 pods étaient disponibles et au plus 4 pods ont été créés à chaque fois.
Il a ensuite poursuivi la montée en puissance du nouveau et de l'ancien ReplicaSet, avec la même stratégie de mise à jour continue.
Enfin, vous aurez 3 réplicas disponibles dans le nouveau ReplicaSet, et l'ancien ReplicaSet est réduit à 0.</p></li></ul><h3 id=rollover>Rollover (alias plusieurs mises à jour en vol)</h3><p>Chaque fois qu'un nouveau déploiement est observé par le contrôleur de déploiement, un ReplicaSet est créé pour afficher les pods souhaités.
Si le déploiement est mis à jour, le ReplicaSet existant qui contrôle les pods dont les étiquettes correspondent à <code>.spec.selector</code> mais dont le modèle ne correspond pas à <code>.spec.template</code> est réduit.
Finalement, le nouveau ReplicaSet est mis à l'échelle à <code>.spec.replicas</code> et tous les anciens ReplicaSets sont mis à l'échelle à 0.</p><p>Si vous mettez à jour un déploiement alors qu'un déploiement existant est en cours, le déploiement crée un nouveau ReplicaSet conformément à la mise à jour et commence à le mettre à l'échelle, et arrête de mettre à jour le ReplicaSet qu'il augmentait précédemment - il l'ajoutera à sa liste de anciens ReplicaSets et commencera à le réduire.</p><p>Par exemple, supposons que vous créez un déploiement pour créer 5 répliques de <code>nginx: 1.7.9</code>, puis mettez à jour le déploiement pour créer 5 répliques de <code>nginx: 1.9.1</code>, alors que seulement 3 répliques de <code>nginx:1.7.9</code> avait été créés.
Dans ce cas, le déploiement commence immédiatement à tuer les 3 pods <code>nginx: 1.7.9</code> qu'il avait créés et commence à créer des pods <code>nginx: 1.9.1</code>.
Il n'attend pas que les 5 répliques de <code>nginx: 1.7.9</code> soient créées avant de changer de cap.</p><h3 id=mises-à-jour-du-sélecteur-de-labels>Mises à jour du sélecteur de labels</h3><p>Il est généralement déconseillé de mettre à jour le sélecteur de labels et il est suggéré de planifier vos sélecteurs à l'avance.
Dans tous les cas, si vous devez effectuer une mise à jour du sélecteur de labels, soyez très prudent et assurez-vous d'avoir saisi toutes les implications.</p><div class="alert alert-info note callout" role=alert><strong>Note:</strong> Dans la version d'API <code>apps/v1</code>, le sélecteur de label d'un déploiement est immuable après sa création.</div><ul><li>Les ajouts de sélecteur nécessitent que les labels de template de pod dans la spécification de déploiement soient également mises à jour avec les nouveaux labels, sinon une erreur de validation est renvoyée.
Cette modification ne se chevauche pas, ce qui signifie que le nouveau sélecteur ne sélectionne pas les ReplicaSets et les pods créés avec l'ancien sélecteur, ce qui entraîne la perte de tous les anciens ReplicaSets et la création d'un nouveau ReplicaSet.</li><li>Les mises à jour du sélecteur modifient la valeur existante dans une clé de sélection - entraînent le même comportement que les ajouts.</li><li>La suppression de sélecteur supprime une clé existante du sélecteur de déploiement - ne nécessite aucune modification dans les labels du template de pod.
Les ReplicaSets existants ne sont pas orphelins et aucun nouveau ReplicaSet n'est créé, mais notez que le label supprimé existe toujours dans tous les Pods et ReplicaSets existants.</li></ul><h2 id=annulation-d-un-déploiement>Annulation d'un déploiement</h2><p>Parfois, vous souhaiterez peut-être annuler un déploiement; par exemple, lorsque le déploiement n'est pas stable, comme en cas d'échecs à répétition (CrashLoopBackOff).
Par défaut, tout l'historique des déploiements d'un déploiement est conservé dans le système afin que vous puissiez le restaurer à tout moment (vous pouvez le modifier en modifiant la limite de l'historique des révisions).</p><div class="alert alert-info note callout" role=alert><strong>Note:</strong> La révision d'un déploiement est créée lorsque le déploiement d'un déploiement est déclenché.
Cela signifie qu'une nouvelle révision est créée si et seulement si le template de pod de déploiement (<code>.spec.template</code>) est modifié, par exemple si vous mettez à jour les labels ou les images de conteneur du template.
D'autres mises à jour, telles que la mise à l'échelle du déploiement, ne créent pas de révision de déploiement, de sorte que vous puissiez faciliter la mise à l'échelle manuelle ou automatique simultanée.
Cela signifie que lorsque vous revenez à une révision antérieure, seule la partie du template de pod de déploiement est annulée.</div><ul><li><p>Supposons que vous ayez fait une faute de frappe lors de la mise à jour du déploiement, en mettant le nom de l'image sous la forme <code>nginx:1.91</code> au lieu de <code>nginx: 1.9.1</code>:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl <span style=color:#a2f>set</span> image deployment.v1.apps/nginx-deployment <span style=color:#b8860b>nginx</span><span style=color:#666>=</span>nginx:1.91 --record<span style=color:#666>=</span><span style=color:#a2f>true</span>
</span></span></code></pre></div><p>La sortie est similaire à ceci:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-text data-lang=text><span style=display:flex><span>deployment.apps/nginx-deployment image updated
</span></span></code></pre></div></li><li><p>Le déploiement est bloqué.
Vous pouvez le vérifier en vérifiant l'état du déploiement:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl rollout status deployment.v1.apps/nginx-deployment
</span></span></code></pre></div><p>La sortie est similaire à ceci:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-text data-lang=text><span style=display:flex><span>Waiting for rollout to finish: 1 out of 3 new replicas have been updated...
</span></span></code></pre></div></li><li><p>Appuyez sur Ctrl-C pour arrêter la surveillance d'état de déploiement ci-dessus.
Pour plus d'informations sur les déploiements bloqués, <a href=#deployment-status>en savoir plus ici</a>.</p></li><li><p>Vous voyez que le nombre d'anciens réplicas (<code>nginx-deployment-1564180365</code> et <code>nginx-deployment-2035384211</code>) est 2, et les nouveaux réplicas (<code>nginx-deployment-3066724191</code>) est 1.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get rs
</span></span></code></pre></div><p>La sortie est similaire à ceci:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-text data-lang=text><span style=display:flex><span>NAME                          DESIRED   CURRENT   READY   AGE
</span></span><span style=display:flex><span>nginx-deployment-1564180365   3         3         3       25s
</span></span><span style=display:flex><span>nginx-deployment-2035384211   0         0         0       36s
</span></span><span style=display:flex><span>nginx-deployment-3066724191   1         1         0       6s
</span></span></code></pre></div></li><li><p>En regardant les pods créés, vous voyez que 1 pod créé par le nouveau ReplicaSet est coincé dans une boucle pour récupérer son image:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get pods
</span></span></code></pre></div><p>La sortie est similaire à ceci:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-text data-lang=text><span style=display:flex><span>NAME                                READY     STATUS             RESTARTS   AGE
</span></span><span style=display:flex><span>nginx-deployment-1564180365-70iae   1/1       Running            0          25s
</span></span><span style=display:flex><span>nginx-deployment-1564180365-jbqqo   1/1       Running            0          25s
</span></span><span style=display:flex><span>nginx-deployment-1564180365-hysrc   1/1       Running            0          25s
</span></span><span style=display:flex><span>nginx-deployment-3066724191-08mng   0/1       ImagePullBackOff   0          6s
</span></span></code></pre></div><div class="alert alert-info note callout" role=alert><strong>Note:</strong> Le contrôleur de déploiement arrête automatiquement le mauvais déploiement et arrête la mise à l'échelle du nouveau ReplicaSet.
Cela dépend des paramètres rollingUpdate (<code>maxUnavailable</code> spécifiquement) que vous avez spécifiés.
Kubernetes définit par défaut la valeur à 25%.</div></li><li><p>Obtenez la description du déploiement:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl describe deployment
</span></span></code></pre></div><p>La sortie est similaire à ceci:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-text data-lang=text><span style=display:flex><span>Name:           nginx-deployment
</span></span><span style=display:flex><span>Namespace:      default
</span></span><span style=display:flex><span>CreationTimestamp:  Tue, 15 Mar 2016 14:48:04 -0700
</span></span><span style=display:flex><span>Labels:         app=nginx
</span></span><span style=display:flex><span>Selector:       app=nginx
</span></span><span style=display:flex><span>Replicas:       3 desired | 1 updated | 4 total | 3 available | 1 unavailable
</span></span><span style=display:flex><span>StrategyType:       RollingUpdate
</span></span><span style=display:flex><span>MinReadySeconds:    0
</span></span><span style=display:flex><span>RollingUpdateStrategy:  25% max unavailable, 25% max surge
</span></span><span style=display:flex><span>Pod Template:
</span></span><span style=display:flex><span>  Labels:  app=nginx
</span></span><span style=display:flex><span>  Containers:
</span></span><span style=display:flex><span>   nginx:
</span></span><span style=display:flex><span>    Image:        nginx:1.91
</span></span><span style=display:flex><span>    Port:         80/TCP
</span></span><span style=display:flex><span>    Host Port:    0/TCP
</span></span><span style=display:flex><span>    Environment:  &lt;none&gt;
</span></span><span style=display:flex><span>    Mounts:       &lt;none&gt;
</span></span><span style=display:flex><span>  Volumes:        &lt;none&gt;
</span></span><span style=display:flex><span>Conditions:
</span></span><span style=display:flex><span>  Type           Status  Reason
</span></span><span style=display:flex><span>  ----           ------  ------
</span></span><span style=display:flex><span>  Available      True    MinimumReplicasAvailable
</span></span><span style=display:flex><span>  Progressing    True    ReplicaSetUpdated
</span></span><span style=display:flex><span>OldReplicaSets:     nginx-deployment-1564180365 (3/3 replicas created)
</span></span><span style=display:flex><span>NewReplicaSet:      nginx-deployment-3066724191 (1/1 replicas created)
</span></span><span style=display:flex><span>Events:
</span></span><span style=display:flex><span>  FirstSeen LastSeen    Count   From                    SubObjectPath   Type        Reason              Message
</span></span><span style=display:flex><span>  --------- --------    -----   ----                    -------------   --------    ------              -------
</span></span><span style=display:flex><span>  1m        1m          1       {deployment-controller }                Normal      ScalingReplicaSet   Scaled up replica set nginx-deployment-2035384211 to 3
</span></span><span style=display:flex><span>  22s       22s         1       {deployment-controller }                Normal      ScalingReplicaSet   Scaled up replica set nginx-deployment-1564180365 to 1
</span></span><span style=display:flex><span>  22s       22s         1       {deployment-controller }                Normal      ScalingReplicaSet   Scaled down replica set nginx-deployment-2035384211 to 2
</span></span><span style=display:flex><span>  22s       22s         1       {deployment-controller }                Normal      ScalingReplicaSet   Scaled up replica set nginx-deployment-1564180365 to 2
</span></span><span style=display:flex><span>  21s       21s         1       {deployment-controller }                Normal      ScalingReplicaSet   Scaled down replica set nginx-deployment-2035384211 to 1
</span></span><span style=display:flex><span>  21s       21s         1       {deployment-controller }                Normal      ScalingReplicaSet   Scaled up replica set nginx-deployment-1564180365 to 3
</span></span><span style=display:flex><span>  13s       13s         1       {deployment-controller }                Normal      ScalingReplicaSet   Scaled down replica set nginx-deployment-2035384211 to 0
</span></span><span style=display:flex><span>  13s       13s         1       {deployment-controller }                Normal      ScalingReplicaSet   Scaled up replica set nginx-deployment-3066724191 to 1
</span></span></code></pre></div><p>Pour résoudre ce problème, vous devez revenir à une version précédente de Deployment qui est stable.</p></li></ul><h3 id=vérification-de-l-historique-de-déploiement-d-un-déploiement>Vérification de l'historique de déploiement d'un déploiement</h3><p>Suivez les étapes ci-dessous pour vérifier l'historique de déploiement:</p><ol><li><p>Tout d'abord, vérifiez les révisions de ce déploiement:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl rollout <span style=color:#a2f>history</span> deployment.v1.apps/nginx-deployment
</span></span></code></pre></div><p>La sortie est similaire à ceci:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-text data-lang=text><span style=display:flex><span>deployments &#34;nginx-deployment&#34;
</span></span><span style=display:flex><span>REVISION    CHANGE-CAUSE
</span></span><span style=display:flex><span>1           kubectl apply --filename=https://k8s.io/examples/controllers/nginx-deployment.yaml --record=true
</span></span><span style=display:flex><span>2           kubectl set image deployment.v1.apps/nginx-deployment nginx=nginx:1.9.1 --record=true
</span></span><span style=display:flex><span>3           kubectl set image deployment.v1.apps/nginx-deployment nginx=nginx:1.91 --record=true
</span></span></code></pre></div><p><code>CHANGE-CAUSE</code> est copié de l'annotation de déploiement <code>kubernetes.io/change-cause</code> dans ses révisions lors de la création.
Vous pouvez spécifier le message<code>CHANGE-CAUSE</code> en:</p><ul><li>Annoter le déploiement avec <code>kubectl annotate deployment.v1.apps/nginx-deployment kubernetes.io/change-cause="image mis à jour en 1.9.1"</code></li><li>Ajoutez le drapeau <code>--record</code> pour enregistrer la commande <code>kubectl</code> qui apporte des modifications à la ressource.</li><li>Modification manuelle du manifeste de la ressource.</li></ul></li><li><p>Pour voir les détails de chaque révision, exécutez:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl rollout <span style=color:#a2f>history</span> deployment.v1.apps/nginx-deployment --revision<span style=color:#666>=</span><span style=color:#666>2</span>
</span></span></code></pre></div><p>La sortie est similaire à ceci:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-text data-lang=text><span style=display:flex><span>deployments &#34;nginx-deployment&#34; revision 2
</span></span><span style=display:flex><span>  Labels:       app=nginx
</span></span><span style=display:flex><span>          pod-template-hash=1159050644
</span></span><span style=display:flex><span>  Annotations:  kubernetes.io/change-cause=kubectl set image deployment.v1.apps/nginx-deployment nginx=nginx:1.9.1 --record=true
</span></span><span style=display:flex><span>  Containers:
</span></span><span style=display:flex><span>   nginx:
</span></span><span style=display:flex><span>    Image:      nginx:1.9.1
</span></span><span style=display:flex><span>    Port:       80/TCP
</span></span><span style=display:flex><span>     QoS Tier:
</span></span><span style=display:flex><span>        cpu:      BestEffort
</span></span><span style=display:flex><span>        memory:   BestEffort
</span></span><span style=display:flex><span>    Environment Variables:      &lt;none&gt;
</span></span><span style=display:flex><span>  No volumes.
</span></span></code></pre></div></li></ol><h3 id=revenir-à-une-révision-précédente>Revenir à une révision précédente</h3><p>Suivez les étapes ci-dessous pour restaurer le déploiement de la version actuelle à la version précédente, qui est la version 2.</p><ol><li><p>Vous avez maintenant décidé d'annuler le déploiement actuel et le retour à la révision précédente:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl rollout undo deployment.v1.apps/nginx-deployment
</span></span></code></pre></div><p>La sortie est similaire à ceci:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-text data-lang=text><span style=display:flex><span>deployment.apps/nginx-deployment
</span></span></code></pre></div><p>Alternativement, vous pouvez revenir à une révision spécifique en la spécifiant avec <code>--to-revision</code>:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl rollout undo deployment.v1.apps/nginx-deployment --to-revision<span style=color:#666>=</span><span style=color:#666>2</span>
</span></span></code></pre></div><p>La sortie est similaire à ceci:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-text data-lang=text><span style=display:flex><span>deployment.apps/nginx-deployment
</span></span></code></pre></div><p>Pour plus de détails sur les commandes liées au déploiement, lisez <a href=/docs/reference/generated/kubectl/kubectl-commands#rollout><code>kubectl rollout</code></a>.</p><p>Le déploiement est maintenant rétabli à une précédente révision stable.
Comme vous pouvez le voir, un événement <code>DeploymentRollback</code> pour revenir à la révision 2 est généré à partir du contrôleur de déploiement.</p></li><li><p>Vérifiez si la restauration a réussi et que le déploiement s'exécute comme prévu, exécutez:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get deployment nginx-deployment
</span></span></code></pre></div><p>La sortie est similaire à ceci:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-text data-lang=text><span style=display:flex><span>NAME               READY   UP-TO-DATE   AVAILABLE   AGE
</span></span><span style=display:flex><span>nginx-deployment   3/3     3            3           30m
</span></span></code></pre></div></li><li><p>Obtenez la description du déploiement:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl describe deployment nginx-deployment
</span></span></code></pre></div><p>La sortie est similaire à ceci:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-text data-lang=text><span style=display:flex><span>Name:                   nginx-deployment
</span></span><span style=display:flex><span>Namespace:              default
</span></span><span style=display:flex><span>CreationTimestamp:      Sun, 02 Sep 2018 18:17:55 -0500
</span></span><span style=display:flex><span>Labels:                 app=nginx
</span></span><span style=display:flex><span>Annotations:            deployment.kubernetes.io/revision=4
</span></span><span style=display:flex><span>                        kubernetes.io/change-cause=kubectl set image deployment.v1.apps/nginx-deployment nginx=nginx:1.9.1 --record=true
</span></span><span style=display:flex><span>Selector:               app=nginx
</span></span><span style=display:flex><span>Replicas:               3 desired | 3 updated | 3 total | 3 available | 0 unavailable
</span></span><span style=display:flex><span>StrategyType:           RollingUpdate
</span></span><span style=display:flex><span>MinReadySeconds:        0
</span></span><span style=display:flex><span>RollingUpdateStrategy:  25% max unavailable, 25% max surge
</span></span><span style=display:flex><span>Pod Template:
</span></span><span style=display:flex><span>  Labels:  app=nginx
</span></span><span style=display:flex><span>  Containers:
</span></span><span style=display:flex><span>   nginx:
</span></span><span style=display:flex><span>    Image:        nginx:1.9.1
</span></span><span style=display:flex><span>    Port:         80/TCP
</span></span><span style=display:flex><span>    Host Port:    0/TCP
</span></span><span style=display:flex><span>    Environment:  &lt;none&gt;
</span></span><span style=display:flex><span>    Mounts:       &lt;none&gt;
</span></span><span style=display:flex><span>  Volumes:        &lt;none&gt;
</span></span><span style=display:flex><span>Conditions:
</span></span><span style=display:flex><span>  Type           Status  Reason
</span></span><span style=display:flex><span>  ----           ------  ------
</span></span><span style=display:flex><span>  Available      True    MinimumReplicasAvailable
</span></span><span style=display:flex><span>  Progressing    True    NewReplicaSetAvailable
</span></span><span style=display:flex><span>OldReplicaSets:  &lt;none&gt;
</span></span><span style=display:flex><span>NewReplicaSet:   nginx-deployment-c4747d96c (3/3 replicas created)
</span></span><span style=display:flex><span>Events:
</span></span><span style=display:flex><span>  Type    Reason              Age   From                   Message
</span></span><span style=display:flex><span>  ----    ------              ----  ----                   -------
</span></span><span style=display:flex><span>  Normal  ScalingReplicaSet   12m   deployment-controller  Scaled up replica set nginx-deployment-75675f5897 to 3
</span></span><span style=display:flex><span>  Normal  ScalingReplicaSet   11m   deployment-controller  Scaled up replica set nginx-deployment-c4747d96c to 1
</span></span><span style=display:flex><span>  Normal  ScalingReplicaSet   11m   deployment-controller  Scaled down replica set nginx-deployment-75675f5897 to 2
</span></span><span style=display:flex><span>  Normal  ScalingReplicaSet   11m   deployment-controller  Scaled up replica set nginx-deployment-c4747d96c to 2
</span></span><span style=display:flex><span>  Normal  ScalingReplicaSet   11m   deployment-controller  Scaled down replica set nginx-deployment-75675f5897 to 1
</span></span><span style=display:flex><span>  Normal  ScalingReplicaSet   11m   deployment-controller  Scaled up replica set nginx-deployment-c4747d96c to 3
</span></span><span style=display:flex><span>  Normal  ScalingReplicaSet   11m   deployment-controller  Scaled down replica set nginx-deployment-75675f5897 to 0
</span></span><span style=display:flex><span>  Normal  ScalingReplicaSet   11m   deployment-controller  Scaled up replica set nginx-deployment-595696685f to 1
</span></span><span style=display:flex><span>  Normal  DeploymentRollback  15s   deployment-controller  Rolled back deployment &#34;nginx-deployment&#34; to revision 2
</span></span><span style=display:flex><span>  Normal  ScalingReplicaSet   15s   deployment-controller  Scaled down replica set nginx-deployment-595696685f to 0
</span></span></code></pre></div></li></ol><h2 id=mise-à-l-échelle-d-un-déploiement>Mise à l'échelle d'un déploiement</h2><p>Vous pouvez mettre à l'échelle un déploiement à l'aide de la commande suivante:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl scale deployment.v1.apps/nginx-deployment --replicas<span style=color:#666>=</span><span style=color:#666>10</span>
</span></span></code></pre></div><p>La sortie est similaire à ceci:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-text data-lang=text><span style=display:flex><span>deployment.apps/nginx-deployment scaled
</span></span></code></pre></div><p>En supposant que l'<a href=/docs/tasks/run-application/horizontal-pod-autoscale-walkthrough/>horizontal Pod autoscaling</a> est activé dans votre cluster, vous pouvez configurer une mise à l'échelle automatique pour votre déploiement et choisir le nombre minimum et maximum de pods que vous souhaitez exécuter en fonction de l'utilisation du processeur de vos pods existants.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl autoscale deployment.v1.apps/nginx-deployment --min<span style=color:#666>=</span><span style=color:#666>10</span> --max<span style=color:#666>=</span><span style=color:#666>15</span> --cpu-percent<span style=color:#666>=</span><span style=color:#666>80</span>
</span></span></code></pre></div><p>La sortie est similaire à ceci:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-text data-lang=text><span style=display:flex><span>deployment.apps/nginx-deployment scaled
</span></span></code></pre></div><h3 id=mise-à-l-échelle-proportionnelle>Mise à l'échelle proportionnelle</h3><p>Les déploiements RollingUpdate prennent en charge l'exécution simultanée de plusieurs versions d'une application.
Lorsque vous ou un autoscaler mettez à l'échelle un déploiement RollingUpdate qui se trouve au milieu d'un déploiement (en cours ou en pause), le contrôleur de déploiement équilibre les réplicas supplémentaires dans les ReplicaSets actifs existants (ReplicaSets avec pods) afin d'atténuer le risque.
Ceci est appelé <em>mise à l'échelle proportionnelle</em>.</p><p>Par exemple, vous exécutez un déploiement avec 10 réplicas, <a href=#max-surge>maxSurge</a>=3, et <a href=#max-unavailable>maxUnavailable</a>=2.</p><ul><li><p>Assurez-vous que les 10 réplicas de votre déploiement sont en cours d'exécution.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get deploy
</span></span></code></pre></div><p>La sortie est similaire à ceci:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-text data-lang=text><span style=display:flex><span>NAME                 DESIRED   CURRENT   UP-TO-DATE   AVAILABLE   AGE
</span></span><span style=display:flex><span>nginx-deployment     10        10        10           10          50s
</span></span></code></pre></div></li><li><p>Vous effectuez une mise à jour vers une nouvelle image qui s'avère impossible à résoudre depuis l'intérieur du cluster.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl <span style=color:#a2f>set</span> image deployment.v1.apps/nginx-deployment <span style=color:#b8860b>nginx</span><span style=color:#666>=</span>nginx:sometag
</span></span></code></pre></div><p>La sortie est similaire à ceci:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-text data-lang=text><span style=display:flex><span>deployment.apps/nginx-deployment image updated
</span></span></code></pre></div></li><li><p>La mise à jour de l'image démarre un nouveau déploiement avec ReplicaSet <code>nginx-deployment-1989198191</code>, mais elle est bloquée en raison de l'exigence <code>maxUnavailable</code> que vous avez mentionnée ci-dessus.
Découvrez l'état du déploiement:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get rs
</span></span></code></pre></div><p>La sortie est similaire à ceci:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-text data-lang=text><span style=display:flex><span>NAME                          DESIRED   CURRENT   READY     AGE
</span></span><span style=display:flex><span>nginx-deployment-1989198191   5         5         0         9s
</span></span><span style=display:flex><span>nginx-deployment-618515232    8         8         8         1m
</span></span></code></pre></div></li><li><p>Ensuite, une nouvelle demande de mise à l'échelle pour le déploiement arrive.
La mise à l'échelle automatique incrémente les réplicas de déploiement à 15.
Le contrôleur de déploiement doit décider où ajouter ces 5 nouvelles répliques.
Si vous n'utilisiez pas la mise à l'échelle proportionnelle, les 5 seraient ajoutés dans le nouveau ReplicaSet.
Avec une mise à l'échelle proportionnelle, vous répartissez les répliques supplémentaires sur tous les ReplicaSets.
Des proportions plus importantes vont aux ReplicaSets avec le plus de répliques et des proportions plus faibles vont aux ReplicaSets avec moins de replicas.
Tous les restes sont ajoutés au ReplicaSet avec le plus de répliques.
Les ReplicaSets avec zéro réplicas ne sont pas mis à l'échelle.</p></li></ul><p>Dans notre exemple ci-dessus, 3 répliques sont ajoutées à l'ancien ReplicaSet et 2 répliques sont ajoutées au nouveau ReplicaSet.
Le processus de déploiement devrait éventuellement déplacer toutes les répliques vers le nouveau ReplicaSet, en supposant que les nouvelles répliques deviennent saines.
Pour confirmer cela, exécutez:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get deploy
</span></span></code></pre></div><p>La sortie est similaire à ceci:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-text data-lang=text><span style=display:flex><span>NAME                 DESIRED   CURRENT   UP-TO-DATE   AVAILABLE   AGE
</span></span><span style=display:flex><span>nginx-deployment     15        18        7            8           7m
</span></span></code></pre></div><p>Le statut de déploiement confirme la façon dont les réplicas ont été ajoutés à chaque ReplicaSet.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get rs
</span></span></code></pre></div><p>La sortie est similaire à ceci:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-text data-lang=text><span style=display:flex><span>NAME                          DESIRED   CURRENT   READY     AGE
</span></span><span style=display:flex><span>nginx-deployment-1989198191   7         7         0         7m
</span></span><span style=display:flex><span>nginx-deployment-618515232    11        11        11        7m
</span></span></code></pre></div><h2 id=pause-et-reprise-d-un-déploiement>Pause et reprise d'un déploiement</h2><p>Vous pouvez suspendre un déploiement avant de déclencher une ou plusieurs mises à jour, puis le reprendre.
Cela vous permet d'appliquer plusieurs correctifs entre la pause et la reprise sans déclencher de déploiements inutiles.</p><ul><li><p>Par exemple, avec un déploiement qui vient d'être créé:
Obtenez les détails du déploiement:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get deploy
</span></span></code></pre></div><p>La sortie est similaire à ceci:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-text data-lang=text><span style=display:flex><span>NAME      DESIRED   CURRENT   UP-TO-DATE   AVAILABLE   AGE
</span></span><span style=display:flex><span>nginx     3         3         3            3           1m
</span></span></code></pre></div><p>Obtenez le statut de déploiement:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get rs
</span></span></code></pre></div><p>La sortie est similaire à ceci:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-text data-lang=text><span style=display:flex><span>NAME               DESIRED   CURRENT   READY     AGE
</span></span><span style=display:flex><span>nginx-2142116321   3         3         3         1m
</span></span></code></pre></div></li><li><p>Mettez le déploiement en pause en exécutant la commande suivante:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl rollout pause deployment.v1.apps/nginx-deployment
</span></span></code></pre></div><p>La sortie est similaire à ceci:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-text data-lang=text><span style=display:flex><span>deployment.apps/nginx-deployment paused
</span></span></code></pre></div></li><li><p>Mettez ensuite à jour l'image du déploiement:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl <span style=color:#a2f>set</span> image deployment.v1.apps/nginx-deployment <span style=color:#b8860b>nginx</span><span style=color:#666>=</span>nginx:1.9.1
</span></span></code></pre></div><p>La sortie est similaire à ceci:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-text data-lang=text><span style=display:flex><span>deployment.apps/nginx-deployment image updated
</span></span></code></pre></div></li><li><p>Notez qu'aucun nouveau déploiement n'a commencé:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl rollout <span style=color:#a2f>history</span> deployment.v1.apps/nginx-deployment
</span></span></code></pre></div><p>La sortie est similaire à ceci:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-text data-lang=text><span style=display:flex><span>deployments &#34;nginx&#34;
</span></span><span style=display:flex><span>REVISION  CHANGE-CAUSE
</span></span><span style=display:flex><span>1   &lt;none&gt;
</span></span></code></pre></div></li><li><p>Obtenez l'état de déploiement pour vous assurer que le déploiement est correctement mis à jour:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get rs
</span></span></code></pre></div><p>La sortie est similaire à ceci:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-text data-lang=text><span style=display:flex><span>NAME               DESIRED   CURRENT   READY     AGE
</span></span><span style=display:flex><span>nginx-2142116321   3         3         3         2m
</span></span></code></pre></div></li><li><p>Vous pouvez effectuer autant de mises à jour que vous le souhaitez, par exemple, mettre à jour les ressources qui seront utilisées:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl <span style=color:#a2f>set</span> resources deployment.v1.apps/nginx-deployment -c<span style=color:#666>=</span>nginx --limits<span style=color:#666>=</span><span style=color:#b8860b>cpu</span><span style=color:#666>=</span>200m,memory<span style=color:#666>=</span>512Mi
</span></span></code></pre></div><p>La sortie est similaire à ceci:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-text data-lang=text><span style=display:flex><span>deployment.apps/nginx-deployment resource requirements updated
</span></span></code></pre></div><p>L'état initial du déploiement avant de le suspendre continuera de fonctionner, mais les nouvelles mises à jour du déploiement n'auront aucun effet tant que le déploiement sera suspendu.</p></li><li><p>Finalement, reprenez le déploiement et observez un nouveau ReplicaSet à venir avec toutes les nouvelles mises à jour:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl rollout resume deployment.v1.apps/nginx-deployment
</span></span></code></pre></div><p>La sortie est similaire à ceci:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-text data-lang=text><span style=display:flex><span>deployment.apps/nginx-deployment resumed
</span></span></code></pre></div></li><li><p>Regardez l'état du déploiement jusqu'à ce qu'il soit terminé.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get rs -w
</span></span></code></pre></div><p>La sortie est similaire à ceci:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-text data-lang=text><span style=display:flex><span>NAME               DESIRED   CURRENT   READY     AGE
</span></span><span style=display:flex><span>nginx-2142116321   2         2         2         2m
</span></span><span style=display:flex><span>nginx-3926361531   2         2         0         6s
</span></span><span style=display:flex><span>nginx-3926361531   2         2         1         18s
</span></span><span style=display:flex><span>nginx-2142116321   1         2         2         2m
</span></span><span style=display:flex><span>nginx-2142116321   1         2         2         2m
</span></span><span style=display:flex><span>nginx-3926361531   3         2         1         18s
</span></span><span style=display:flex><span>nginx-3926361531   3         2         1         18s
</span></span><span style=display:flex><span>nginx-2142116321   1         1         1         2m
</span></span><span style=display:flex><span>nginx-3926361531   3         3         1         18s
</span></span><span style=display:flex><span>nginx-3926361531   3         3         2         19s
</span></span><span style=display:flex><span>nginx-2142116321   0         1         1         2m
</span></span><span style=display:flex><span>nginx-2142116321   0         1         1         2m
</span></span><span style=display:flex><span>nginx-2142116321   0         0         0         2m
</span></span><span style=display:flex><span>nginx-3926361531   3         3         3         20s
</span></span></code></pre></div></li><li><p>Obtenez le statut du dernier déploiement:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get rs
</span></span></code></pre></div><p>La sortie est similaire à ceci:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-text data-lang=text><span style=display:flex><span>NAME               DESIRED   CURRENT   READY     AGE
</span></span><span style=display:flex><span>nginx-2142116321   0         0         0         2m
</span></span><span style=display:flex><span>nginx-3926361531   3         3         3         28s
</span></span></code></pre></div></li></ul><div class="alert alert-info note callout" role=alert><strong>Note:</strong> Vous ne pouvez pas annuler un déploiement suspendu avant de le reprendre.</div><h2 id=statut-de-déploiement>Statut de déploiement</h2><p>Un déploiement entre dans différents états au cours de son cycle de vie.
Il peut être <a href=#progressing-deployment>progressant</a> lors du déploiement d'un nouveau ReplicaSet, il peut être <a href=#complete-deployment>effectué</a>, ou il peut <a href=#failed-deployment>ne pas progresser</a>.</p><h3 id=progression-du-déploiement>Progression du déploiement</h3><p>Kubernetes marque un déploiement comme <em>progressing</em> lorsqu'une des tâches suivantes est effectuée:</p><ul><li>Le déploiement crée un nouveau ReplicaSet.</li><li>Le déploiement augmente son nouveau ReplicaSet.</li><li>Le déploiement réduit ses anciens ReplicaSet.</li><li>De nouveaux pods deviennent prêts ou disponibles (prêt pour au moins <a href=#min-ready-seconds>MinReadySeconds</a>).</li></ul><p>Vous pouvez surveiller la progression d'un déploiement à l'aide de <code>kubectl rollout status</code>.</p><h3 id=déploiement-effectué>Déploiement effectué</h3><p>Kubernetes marque un déploiement comme <em>effectué</em> lorsqu'il présente les caractéristiques suivantes:</p><ul><li>Toutes les répliques associées au déploiement ont été mises à jour vers la dernière version que vous avez spécifiée, ce qui signifie que toutes les mises à jour que vous avez demandées ont été effectuées.</li><li>Toutes les répliques associées au déploiement sont disponibles.</li><li>Aucune ancienne réplique pour le déploiement n'est en cours d'exécution.</li></ul><p>Vous pouvez vérifier si un déploiement est terminé en utilisant <code>kubectl rollout status</code>.
Si le déploiement s'est terminé avec succès, <code>kubectl rollout status</code> renvoie un code de sortie de 0.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl rollout status deployment.v1.apps/nginx-deployment
</span></span></code></pre></div><p>La sortie est similaire à ceci:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-text data-lang=text><span style=display:flex><span>Waiting for rollout to finish: 2 of 3 updated replicas are available...
</span></span><span style=display:flex><span>deployment &#34;nginx-deployment&#34; successfully rolled out
</span></span><span style=display:flex><span>$ echo $?
</span></span><span style=display:flex><span>0
</span></span></code></pre></div><h3 id=déploiement-échoué>Déploiement échoué</h3><p>Votre déploiement peut rester bloqué en essayant de déployer son nouveau ReplicaSet sans jamais terminer.
Cela peut se produire en raison de certains des facteurs suivants:</p><ul><li>Quota insuffisant</li><li>Échecs de la sonde de préparation</li><li>Erreurs d'extraction d'image</li><li>Permissions insuffisantes</li><li>Plages limites</li><li>Mauvaise configuration de l'exécution de l'application</li></ul><p>Vous pouvez détecter cette condition en spécifiant un paramètre d'échéance dans votre spécification de déploiement:
(<a href=#progress-deadline-seconds><code>.spec.progressDeadlineSeconds</code></a>).
<code>.spec.progressDeadlineSeconds</code> indique le nombre de secondes pendant lesquelles le contrôleur de déploiement attend avant d'indiquer (dans l'état de déploiement) que la progression du déploiement est au point mort.</p><p>La commande <code>kubectl</code> suivante définit la spécification avec <code>progressDeadlineSeconds</code> pour que le contrôleur signale l'absence de progression pour un déploiement après 10 minutes:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl patch deployment.v1.apps/nginx-deployment -p <span style=color:#b44>&#39;{&#34;spec&#34;:{&#34;progressDeadlineSeconds&#34;:600}}&#39;</span>
</span></span></code></pre></div><p>La sortie est similaire à ceci:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-text data-lang=text><span style=display:flex><span>deployment.apps/nginx-deployment patched
</span></span></code></pre></div><p>Une fois le délai dépassé, le contrôleur de déploiement ajoute un <code>DeploymentCondition</code> avec les attributs suivants aux <code>.status.conditions</code> du déploiement:</p><ul><li>Type=Progressing</li><li>Status=False</li><li>Reason=ProgressDeadlineExceeded</li></ul><p>Voir les <a href=https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#typical-status-properties>conventions Kubernetes API</a> pour plus d'informations sur les conditions d'état.</p><div class="alert alert-info note callout" role=alert><strong>Note:</strong> Kubernetes ne prend aucune mesure sur un déploiement bloqué, sauf pour signaler une condition d'état avec <code>Reason=ProgressDeadlineExceeded</code>.
Les orchestrateurs de niveau supérieur peuvent en tirer parti et agir en conséquence, par exemple, restaurer le déploiement vers sa version précédente.</div><div class="alert alert-info note callout" role=alert><strong>Note:</strong> Si vous suspendez un déploiement, Kubernetes ne vérifie pas la progression par rapport à votre échéance spécifiée.
Vous pouvez suspendre un déploiement en toute sécurité au milieu d'un déploiement et reprendre sans déclencher la condition de dépassement du délai.</div><p>Vous pouvez rencontrer des erreurs transitoires avec vos déploiements, soit en raison d'un délai d'attente bas que vous avez défini, soit en raison de tout autre type d'erreur pouvant être traité comme transitoire.
Par exemple, supposons que votre quota soit insuffisant.
Si vous décrivez le déploiement, vous remarquerez la section suivante:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl describe deployment nginx-deployment
</span></span></code></pre></div><p>La sortie est similaire à ceci:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-text data-lang=text><span style=display:flex><span>&lt;...&gt;
</span></span><span style=display:flex><span>Conditions:
</span></span><span style=display:flex><span>  Type            Status  Reason
</span></span><span style=display:flex><span>  ----            ------  ------
</span></span><span style=display:flex><span>  Available       True    MinimumReplicasAvailable
</span></span><span style=display:flex><span>  Progressing     True    ReplicaSetUpdated
</span></span><span style=display:flex><span>  ReplicaFailure  True    FailedCreate
</span></span><span style=display:flex><span>&lt;...&gt;
</span></span></code></pre></div><p>Si vous exécutez <code>kubectl get deployment nginx-deployment -o yaml</code>, l'état de déploiement est similaire à ceci:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>status</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>availableReplicas</span>:<span style=color:#bbb> </span><span style=color:#666>2</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>conditions</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>lastTransitionTime</span>:<span style=color:#bbb> </span>2016-10-04T12:25:39Z<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>lastUpdateTime</span>:<span style=color:#bbb> </span>2016-10-04T12:25:39Z<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>message</span>:<span style=color:#bbb> </span>Replica set &#34;nginx-deployment-4262182780&#34; is progressing.<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>reason</span>:<span style=color:#bbb> </span>ReplicaSetUpdated<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>status</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;True&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>type</span>:<span style=color:#bbb> </span>Progressing<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>lastTransitionTime</span>:<span style=color:#bbb> </span>2016-10-04T12:25:42Z<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>lastUpdateTime</span>:<span style=color:#bbb> </span>2016-10-04T12:25:42Z<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>message</span>:<span style=color:#bbb> </span>Deployment has minimum availability.<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>reason</span>:<span style=color:#bbb> </span>MinimumReplicasAvailable<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>status</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;True&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>type</span>:<span style=color:#bbb> </span>Available<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>lastTransitionTime</span>:<span style=color:#bbb> </span>2016-10-04T12:25:39Z<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>lastUpdateTime</span>:<span style=color:#bbb> </span>2016-10-04T12:25:39Z<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>message: &#39;Error creating</span>:<span style=color:#bbb> </span>pods &#34;nginx-deployment-4262182780-&#34; is forbidden: exceeded quota:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>object-counts, requested: pods=1, used: pods=3, limited</span>:<span style=color:#bbb> </span>pods=2&#39;<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>reason</span>:<span style=color:#bbb> </span>FailedCreate<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>status</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;True&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>type</span>:<span style=color:#bbb> </span>ReplicaFailure<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>observedGeneration</span>:<span style=color:#bbb> </span><span style=color:#666>3</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>replicas</span>:<span style=color:#bbb> </span><span style=color:#666>2</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>unavailableReplicas</span>:<span style=color:#bbb> </span><span style=color:#666>2</span><span style=color:#bbb>
</span></span></span></code></pre></div><p>Finalement, une fois la date limite de progression du déploiement dépassée, Kubernetes met à jour le statut et la raison de la condition de progression:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-text data-lang=text><span style=display:flex><span>Conditions:
</span></span><span style=display:flex><span>  Type            Status  Reason
</span></span><span style=display:flex><span>  ----            ------  ------
</span></span><span style=display:flex><span>  Available       True    MinimumReplicasAvailable
</span></span><span style=display:flex><span>  Progressing     False   ProgressDeadlineExceeded
</span></span><span style=display:flex><span>  ReplicaFailure  True    FailedCreate
</span></span></code></pre></div><p>Vous pouvez résoudre un problème de quota insuffisant en réduisant votre déploiement, en réduisant d'autres contrôleurs que vous exécutez ou en augmentant le quota de votre namespace.
Si vous remplissez les conditions de quota et que le contrôleur de déploiement termine ensuite le déploiement de déploiement, vous verrez la mise à jour de l'état du déploiement avec une condition réussie (<code>Status=True</code> et <code>Reason=NewReplicaSetAvailable</code>).</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-text data-lang=text><span style=display:flex><span>Conditions:
</span></span><span style=display:flex><span>  Type          Status  Reason
</span></span><span style=display:flex><span>  ----          ------  ------
</span></span><span style=display:flex><span>  Available     True    MinimumReplicasAvailable
</span></span><span style=display:flex><span>  Progressing   True    NewReplicaSetAvailable
</span></span></code></pre></div><p><code>Type=Available</code> avec <code>Status=True</code> signifie que votre déploiement a une disponibilité minimale.
La disponibilité minimale est dictée par les paramètres spécifiés dans la stratégie de déploiement.
<code>Type=Progressing</code> avec <code>Status=True</code> signifie que votre déploiement est soit au milieu d'un déploiement et qu'il progresse ou qu'il a terminé avec succès sa progression et que les nouvelles répliques minimales requises sont disponibles (voir la raison de la condition pour les détails - dans notre cas, <code>Reason=NewReplicaSetAvailable</code> signifie que le déploiement est terminé).</p><p>Vous pouvez vérifier si un déploiement n'a pas pu progresser en utilisant <code>kubectl rollout status</code>.
<code>kubectl rollout status</code> renvoie un code de sortie différent de zéro si le déploiement a dépassé le délai de progression.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl rollout status deployment.v1.apps/nginx-deployment
</span></span></code></pre></div><p>La sortie est similaire à ceci:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-text data-lang=text><span style=display:flex><span>Waiting for rollout to finish: 2 out of 3 new replicas have been updated...
</span></span><span style=display:flex><span>error: deployment &#34;nginx&#34; exceeded its progress deadline
</span></span><span style=display:flex><span>$ echo $?
</span></span><span style=display:flex><span>1
</span></span></code></pre></div><h3 id=agir-sur-un-déploiement-échoué>Agir sur un déploiement échoué</h3><p>Toutes les actions qui s'appliquent à un déploiement complet s'appliquent également à un déploiement ayant échoué.
Vous pouvez le mettre à l'échelle à la hausse/baisse, revenir à une révision précédente ou même la suspendre si vous devez appliquer plusieurs réglages dans le modèle de pod de déploiement.</p><h2 id=politique-de-nettoyage>Politique de nettoyage</h2><p>Vous pouvez définir le champ <code>.spec.revisionHistoryLimit</code> dans un déploiement pour spécifier le nombre d'anciens ReplicaSets pour ce déploiement que vous souhaitez conserver.
Le reste sera effacé en arrière-plan.
Par défaut, c'est 10.</p><div class="alert alert-info note callout" role=alert><strong>Note:</strong> La définition explicite de ce champ sur 0 entraînera le nettoyage de tout l'historique de votre déploiement, de sorte que le déploiement ne pourra pas revenir en arrière.</div><h2 id=déploiement-des-canaries>Déploiement des Canaries</h2><p>Si vous souhaitez déployer des versions sur un sous-ensemble d'utilisateurs ou de serveurs à l'aide du déploiement, vous pouvez créer plusieurs déploiements, un pour chaque version, en suivant le modèle canari décrit dans <a href=/docs/concepts/cluster-administration/manage-deployment/#canary-deployments>gestion des ressources</a>.</p><h2 id=écriture-d-une-spécification-de-déploiement>Écriture d'une spécification de déploiement</h2><p>Comme pour toutes les autres configurations Kubernetes, un déploiement a besoin des champs <code>apiVersion</code>, <code>kind</code> et <code>metadata</code>.
Pour des informations générales sur l'utilisation des fichiers de configuration, voir <a href=/docs/tutorials/stateless-application/run-stateless-application-deployment/>déploiement d'applications</a>, configuration des conteneurs, et <a href=/docs/concepts/overview/working-with-objects/object-management/>Utilisation de kubectl pour gérer les ressources</a>.</p><p>Un déploiement nécessite également un <a href=https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#spec-and-status><code>.spec</code> section</a>.</p><h3 id=pod-template>Pod Template</h3><p>Les <code>.spec.template</code> et <code>.spec.selector</code> sont les seuls champs obligatoires du <code>.spec</code>.</p><p>Le <code>.spec.template</code> est un <a href=/fr/docs/concepts/workloads/pods/pod-overview/#pod-templates>Pod template</a>.
Il a exactement le même schéma qu'un <a href=/fr/docs/concepts/workloads/pods/pod/>Pod</a>, sauf qu'il est imbriqué et n'a pas de <code>apiVersion</code> ou de <code>kind</code>.</p><p>En plus des champs obligatoires pour un pod, un Pod Template dans un déploiement doit spécifier des labels appropriées et une stratégie de redémarrage appropriée.
Pour les labels, assurez-vous de ne pas chevaucher l'action d'autres contrôleurs.
Voir <a href=#selector>sélecteur</a>).</p><p>Seulement un <a href=/fr/docs/concepts/workloads/pods/pod-lifecycle/#restart-policy><code>.spec.template.spec.restartPolicy</code></a> égal à <code>Always</code> est autorisé, ce qui est la valeur par défaut s'il n'est pas spécifié.</p><h3 id=répliques>Répliques</h3><p><code>.spec.replicas</code> est un champ facultatif qui spécifie le nombre de pods souhaités.
Il vaut par défaut 1.</p><h3 id=sélecteur>Sélecteur</h3><p><code>.spec.selector</code> est un champ obligatoire qui spécifie un <a href=/docs/concepts/overview/working-with-objects/labels/>sélecteur de labels</a> pour les pods ciblés par ce déploiement.</p><p><code>.spec.selector</code> doit correspondre <code>.spec.template.metadata.labels</code>, ou il sera rejeté par l'API.</p><p>Dans la version d'API <code>apps/v1</code>, <code>.spec.selector</code> et <code>.metadata.labels</code> ne sont pas définis par défaut sur <code>.spec.template.metadata.labels</code> s'ils ne sont pas définis.
Ils doivent donc être définis explicitement.
Notez également que <code>.spec.selector</code> est immuable après la création du déploiement dans <code>apps/v1</code>.</p><p>Un déploiement peut mettre fin aux pods dont les étiquettes correspondent au sélecteur si leur modèle est différent de <code>.spec.template</code> ou si le nombre total de ces pods dépasse <code>.spec.replicas</code>.
Il fait apparaître de nouveaux pods avec <code>.spec.template</code> si le nombre de pods est inférieur au nombre souhaité.</p><div class="alert alert-info note callout" role=alert><strong>Note:</strong> Vous ne devez pas créer d'autres pods dont les labels correspondent à ce sélecteur, soit directement, en créant un autre déploiement, soit en créant un autre contrôleur tel qu'un ReplicaSet ou un ReplicationController.
Si vous le faites, le premier déploiement pense qu'il a créé ces autres pods.
Kubernetes ne vous empêche pas de le faire.</div><p>Si vous avez plusieurs contrôleurs qui ont des sélecteurs qui se chevauchent, les contrôleurs se battront entre eux et ne se comporteront pas correctement.</p><h3 id=stratégie>Stratégie</h3><p><code>.spec.strategy</code> spécifie la stratégie utilisée pour remplacer les anciens pods par de nouveaux.
<code>.spec.strategy.type</code> peut être "Recreate" ou "RollingUpdate".
"RollingUpdate" est la valeur par défaut.</p><h4 id=déploiment-recreate>Déploiment Recreate</h4><p>Tous les pods existants sont tués avant que de nouveaux ne soient créés lorsque <code>.spec.strategy.type==Recreate</code>.</p><h4 id=déploiement-de-mise-à-jour-continue>Déploiement de mise à jour continue</h4><p>Le déploiement met à jour les pods dans une <a href=/docs/tasks/run-application/rolling-update-replication-controller/>mise à jour continue</a> quand <code>.spec.strategy.type==RollingUpdate</code>.
Vous pouvez spécifier <code>maxUnavailable</code> et <code>maxSurge</code> pour contrôler le processus de mise à jour continue.</p><h5 id=max-non-disponible>Max non disponible</h5><p><code>.spec.strategy.rollingUpdate.maxUnavailable</code> est un champ facultatif qui spécifie le nombre maximal de pods qui peuvent être indisponibles pendant le processus de mise à jour.
La valeur peut être un nombre absolu (par exemple, 5) ou un pourcentage des pods souhaités (par exemple, 10%).
Le nombre absolu est calculé à partir du pourcentage en arrondissant vers le bas.
La valeur ne peut pas être 0 si <code>.spec.strategy.rollingUpdate.maxSurge</code> est 0.
La valeur par défaut est 25%.</p><p>Par exemple, lorsque cette valeur est définie sur 30%, l'ancien ReplicaSet peut être réduit à 70% des pods souhaités immédiatement au démarrage de la mise à jour continue.
Une fois que les nouveaux pods sont prêts, l'ancien ReplicaSet peut être réduit davantage, suivi d'une augmentation du nouveau ReplicaSet, garantissant que le nombre total de pods disponibles à tout moment pendant la mise à jour est d'au moins 70% des pods souhaités.</p><h5 id=max-surge>Max Surge</h5><p><code>.spec.strategy.rollingUpdate.maxSurge</code> est un champ facultatif qui spécifie le nombre maximal de pods pouvant être créés sur le nombre de pods souhaité.
La valeur peut être un nombre absolu (par exemple, 5) ou un pourcentage des pods souhaités (par exemple, 10%).
La valeur ne peut pas être 0 si <code>MaxUnavailable</code> est 0.
Le nombre absolu est calculé à partir du pourcentage en arrondissant.
La valeur par défaut est 25%.</p><p>Par exemple, lorsque cette valeur est définie sur 30%, le nouveau ReplicaSet peut être mis à l'échelle immédiatement au démarrage de la mise à jour continue, de sorte que le nombre total d'anciens et de nouveaux pods ne dépasse pas 130% des pods souhaités.
Une fois que les anciens pods ont été détruits, le nouveau ReplicaSet peut être augmenté davantage, garantissant que le nombre total de pods en cours d'exécution à tout moment pendant la mise à jour est au maximum de 130% des pods souhaités.</p><h3 id=progress-deadline-seconds>Progress Deadline Seconds</h3><p><code>.spec.progressDeadlineSeconds</code> est un champ facultatif qui spécifie le nombre de secondes pendant lesquelles vous souhaitez attendre que votre déploiement progresse avant que le système ne signale que le déploiement a <a href=#failed-deployment>échoué</a> - refait surface comme une condition avec <code>Type=Progressing</code>, <code>Status=False</code> et <code>Reason=ProgressDeadlineExceeded</code> dans l'état de la ressource.
Le contrôleur de déploiement continuera de réessayer le déploiement.
À l'avenir, une fois la restauration automatique implémentée, le contrôleur de déploiement annulera un déploiement dès qu'il observera une telle condition.</p><p>S'il est spécifié, ce champ doit être supérieur à <code>.spec.minReadySeconds</code>.</p><h3 id=min-ready-seconds>Min Ready Seconds</h3><p><code>.spec.minReadySeconds</code> est un champ facultatif qui spécifie le nombre minimum de secondes pendant lequel un pod nouvellement créé doit être prêt sans qu'aucun de ses conteneurs ne plante, pour qu'il soit considéré comme disponible.
Cette valeur par défaut est 0 (le pod sera considéré comme disponible dès qu'il sera prêt).
Pour en savoir plus sur le moment où un pod est considéré comme prêt, consultez <a href=/fr/docs/concepts/workloads/pods/pod-lifecycle/#container-probes>Sondes de conteneur</a>.</p><h3 id=rollback-to>Rollback To</h3><p>Le champ <code>.spec.rollbackTo</code> est obsolète dans les versions d'API <code>extensions/v1beta1</code> et <code>apps/v1beta1</code> et n'est plus pris en charge dans les versions d'API commençant par <code>apps/v1beta2</code>.
Utilisez, <code>kubectl rollout undo</code> pour <a href=#revenir-%C3%A0-une-r%C3%A9vision-pr%C3%A9c%C3%A9dente>Revenir à une révision précédente</a>.</p><h3 id=limite-de-l-historique-des-révisions>Limite de l'historique des révisions</h3><p>L'historique de révision d'un déploiement est stocké dans les ReplicaSets qu'il contrôle.</p><p><code>.spec.revisionHistoryLimit</code> est un champ facultatif qui spécifie le nombre d'anciens ReplicaSets à conserver pour permettre la restauration.
Ces anciens ReplicaSets consomment des ressources dans <code>etcd</code> et encombrent la sortie de <code>kubectl get rs</code>.
La configuration de chaque révision de déploiement est stockée dans ses ReplicaSets; par conséquent, une fois un ancien ReplicaSet supprimé, vous perdez la possibilité de revenir à cette révision du déploiement.
Par défaut, 10 anciens ReplicaSets seront conservés, mais sa valeur idéale dépend de la fréquence et de la stabilité des nouveaux déploiements.</p><p>Plus précisément, la définition de ce champ à zéro signifie que tous les anciens ReplicaSets avec 0 réplicas seront nettoyés.
Dans ce cas, un nouveau panneau déroulant Déploiement ne peut pas être annulé, car son historique de révision est nettoyé.</p><h3 id=paused>Paused</h3><p><code>.spec.paused</code> est un champ booléen facultatif pour suspendre et reprendre un déploiement.
La seule différence entre un déploiement suspendu et un autre qui n'est pas suspendu, c'est que toute modification apportée au <code>PodTemplateSpec</code> du déploiement suspendu ne déclenchera pas de nouveaux déploiements tant qu'il sera suspendu.
Un déploiement n'est pas suspendu par défaut lors de sa création.</p><h2 id=alternative-aux-déploiements>Alternative aux déploiements</h2><h3 id=kubectl-rolling-update>kubectl rolling-update</h3><p><a href=/docs/reference/generated/kubectl/kubectl-commands#rolling-update><code>kubectl rolling-update</code></a> met à jour les pods et les ReplicationControllers de la même manière.
Mais les déploiements sont recommandés, car ils sont déclaratifs, côté serveur et ont des fonctionnalités supplémentaires, telles que la restauration de toute révision précédente même après la mise à jour progressive..</p></div><div class=td-content style=page-break-before:always><h1 id=pg-6d72299952c37ca8cc61b416e5bdbcd4>3.4.2.3 - StatefulSets</h1><p>StatefulSet est l'objet de l'API de charge de travail utilisé pour gérer des applications avec état (<em>stateful</em>).</p><p>Gère le déploiement et la mise à l'échelle d'un ensemble de <a class=glossary-tooltip title='Le plus petit et le plus simple des objets Kubernetes. Un Pod est un ensemble de conteneurs fonctionnant sur votre cluster.' data-toggle=tooltip data-placement=top href=/fr/docs/concepts/workloads/pods/pod-overview/ target=_blank aria-label=Pods>Pods</a>, <em>et fournit des garanties sur l'ordre et l'unicité</em> de ces Pods.</p><p>Comme un <a class=glossary-tooltip title='Objet API gérant une application répliquée.' data-toggle=tooltip data-placement=top href=/docs/concepts/workloads/controllers/deployment/ target=_blank aria-label=Déploiement>Déploiement</a>, un StatefulSet gère des Pods qui sont basés sur une même spécification de conteneur. Contrairement à un Deployment, un StatefulSet maintient une identité pour chacun de ces Pods. Ces Pods sont créés à partir de la même spec, mais ne sont pas interchangeables : chacun a un identifiant persistant qu'il garde à travers tous ses re-scheduling.</p><p>Si vous voulez utiliser des volumes de stockage pour fournir de la persistance à votre charge de travail, vous pouvez utiliser un StatefulSet comme partie de la solution. Même si des Pods individuels d'un StatefulSet sont susceptibles d'échouer, les identifiants persistants des Pods rendent plus facile de faire correspondre les volumes existants aux nouveaux Pods remplaçant ceux ayant échoué.</p><h2 id=utiliser-des-statefulsets>Utiliser des StatefulSets</h2><p>Les StatefulSets sont utiles pour des applications qui nécessitent une ou plusieurs des choses suivantes :</p><ul><li>Des identifiants réseau stables et uniques.</li><li>Un stockage persistant stable.</li><li>Un déploiement et une mise à l'échelle ordonnés et contrôlés.</li><li>Des mises à jour continues (<em>rolling update</em>) ordonnées et automatisées.</li></ul><p>Ci-dessus, stable est synonyme de persistance suite au (re)scheduling de Pods.
Si une application ne nécessite aucun identifiant stable ou de déploiement, suppression ou
mise à l'échelle stables, vous devriez déployer votre application en utilisant un objet de charge de travail
fournissant un ensemble de réplicas sans état (<em>stateless</em>).</p><p>Un <a href=/fr/docs/concepts/workloads/controllers/deployment/>Deployment</a> ou
<a href=/fr/docs/concepts/workloads/controllers/replicaset/>ReplicaSet</a> peut être mieux adapté pour vos applications sans état.</p><h2 id=limitations>Limitations</h2><ul><li>Le stockage pour un Pod donné doit être provisionné soit par un <a href=https://github.com/kubernetes/examples/tree/master/staging/persistent-volume-provisioning/README.md>approvisionneur de PersistentVolume</a> basé sur un <code>storage class</code> donné, soit pré-provisionné par un admin.</li><li>Supprimer et/ou réduire l'échelle d'un StatefulSet à zéro ne supprimera <em>pas</em> les volumes associés avec le StatefulSet. Ceci est fait pour garantir la sécurité des données, ce qui a généralement plus de valeur qu'une purge automatique de toutes les ressources relatives à un StatefulSet.</li><li>Les StatefulSets nécessitent actuellement un <a href=/fr/docs/concepts/services-networking/service/#headless-services>Service Headless</a> qui est responsable de l'identité réseau des Pods. Vous êtes responsable de la création de ce Service.</li><li>Les StatefulSets ne fournissent aucune garantie de la terminaison des pods lorsqu'un StatefulSet est supprimé. Pour avoir une terminaison ordonnée et maîtrisée des pods du StatefulSet, il est possible de réduire l'échelle du StatefulSet à 0 avant de le supprimer.</li><li>Lors de l'utilisation de <a href=#rolling-updates>Rolling Updates</a> avec la
<a href=#politiques-de-gestion-dun-pod>Politique de gestion des Pods</a> par défaut (<code>OrderedReady</code>),
il est possible de tomber dans un état indéfini nécessitant une
<a href=#rollback-forc%C3%A9>intervention manuelle pour réparer</a>.</li></ul><h2 id=composants>Composants</h2><p>L'exemple ci-dessous décrit les composants d'un StatefulSet.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Service<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>nginx<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>labels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>app</span>:<span style=color:#bbb> </span>nginx<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>ports</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>port</span>:<span style=color:#bbb> </span><span style=color:#666>80</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>web<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>clusterIP</span>:<span style=color:#bbb> </span>None<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>selector</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>app</span>:<span style=color:#bbb> </span>nginx<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:#00f;font-weight:700>---</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>apps/v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>StatefulSet<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>web<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>selector</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>matchLabels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>app</span>:<span style=color:#bbb> </span>nginx<span style=color:#bbb> </span><span style=color:#080;font-style:italic># doit correspondre à .spec.template.metadata.labels</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>serviceName</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;nginx&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>replicas</span>:<span style=color:#bbb> </span><span style=color:#666>3</span><span style=color:#bbb> </span><span style=color:#080;font-style:italic># est 1 par défaut</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>template</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>labels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>app</span>:<span style=color:#bbb> </span>nginx<span style=color:#bbb> </span><span style=color:#080;font-style:italic># doit correspondre à .spec.selector.matchLabels</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>terminationGracePeriodSeconds</span>:<span style=color:#bbb> </span><span style=color:#666>10</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>nginx<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>k8s.gcr.io/nginx-slim:0.8<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>ports</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span>- <span style=color:green;font-weight:700>containerPort</span>:<span style=color:#bbb> </span><span style=color:#666>80</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>web<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>volumeMounts</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>www<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>mountPath</span>:<span style=color:#bbb> </span>/usr/share/nginx/html<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>volumeClaimTemplates</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>www<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>accessModes</span>:<span style=color:#bbb> </span>[<span style=color:#bbb> </span><span style=color:#b44>&#34;ReadWriteOnce&#34;</span><span style=color:#bbb> </span>]<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>storageClassName</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;my-storage-class&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>resources</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>requests</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>storage</span>:<span style=color:#bbb> </span>1Gi<span style=color:#bbb>
</span></span></span></code></pre></div><p>Dans l'exemple ci-dessus :</p><ul><li>Un Service Headless, appelé <code>nginx</code>, est utilisé pour contrôler le domaine réseau.</li><li>Le StatefulSet, appelé <code>web</code>, a une Spec indiquant que 3 réplicas du container nginx seront démarrés dans des Pods.</li><li>Le <code>volumeClaimTemplates</code> fournira un stockage stable utilisant des <a href=/docs/concepts/storage/persistent-volumes/>PersistentVolumes</a> provisionnés par un approvisionneur de PersistentVolume.</li></ul><p>Le nom d'un objet StatefulSet doit être un
<a href=/docs/concepts/overview/working-with-objects/names#dns-subdomain-names>nom de sous-domaine DNS</a> valide.</p><h2 id=sélecteur-de-pod>Sélecteur de Pod</h2><p>Vous devez renseigner le champ <code>.spec.selector</code> d'un StatefulSet pour qu'il corresponde aux labels de son <code>.spec.template.metadata.labels</code>. Avant Kubernetes 1.8, le champ <code>.spec.selector</code> était mis par défaut s'il était omis. Pour les versions 1.8 et ultérieures, ne pas spécifier de sélecteur de Pod résulte en une erreur de validation lors de la création du StatefulSet.</p><h2 id=identité-du-pod>Identité du Pod</h2><p>Les Pods d'un StatefulSet ont une identité unique comprenant un ordinal, une identité réseau stable et un stockage stable.
L'identité est accrochée au Pod, indépendamment du noeud sur lequel il est (re)programmé.</p><h3 id=index-ordinal>Index Ordinal</h3><p>Pour un StatefulSet avec N réplicas, chaque Pod du StatefulSet se verra assigné un ordinal entier, de 0 à N-1,
unique sur l'ensemble des pods.</p><h3 id=id-réseau-stable>ID réseau stable</h3><p>Chaque Pod dans un StatefulSet dérive son nom d'hôte du nom du StatefulSet
et de l'ordinal du Pod. Le modèle pour le nom d'hôte généré est
<code>$(nom statefulset)-$(ordinal)</code>. L'exemple ci-dessus créera trois Pods
nommés <code>web-0,web-1,web-2</code>.
Un StatefulSet peut utiliser un <a href=/docs/concepts/services-networking/service/#headless-services>Service Headless</a>
pour contrôler le domaine de ses Pods. Le domaine pris en charge par ce Service prend la forme :
<code>$(nom service).$(namespace).svc.cluster.local</code>, où "cluster.local" est le domaine du cluster.
Chaque fois qu'un Pod est créé, il obtient un sous-domaine DNS correspondant, prenant la forme :
<code>$(nom pod).$(domaine du service gouvernant)</code>, où le service gouvernant est défini par le
champ <code>serviceName</code> du StatefulSet.</p><p>En fonction de la façon dont est configuré le DNS dans votre cluster, vous ne pourrez peut-être pas rechercher immédiatement
le nom DNS d'un pod nouvellement exécuté. Ce problème peut se produire lorsque d'autres clients dans le
cluster ont déjà envoyé des requêtes pour le nom d'hôte du Pod avant sa création.
La mise en cache négative (normale pour le DNS) signifie que les résultats des recherches précédentes ayant échoué sont
mémorisés et réutilisés, même après que le Pod ait démarré, pendant au moins quelques secondes.</p><p>Si vous avez besoin de découvrir les Pods rapidement après leur création, vous avez plusieurs options :</p><ul><li>Interrogez directement l'API Kubernetes (par exemple, à l'aide d'un watch) plutôt que de vous fier aux recherches DNS.</li><li>Réduisez le temps de mise en cache dans votre fournisseur de DNS Kubernetes (cela signifie généralement modifier le ConfigMap de CoreDNS, qui met actuellement en cache pendant 30 secondes).</li></ul><p>Comme mentionné dans la section <a href=#limitations>limitations</a>, vous êtes responsable de
créer le <a href=/docs/concepts/services-networking/service/#headless-services>Service Headless</a>
responsable de l'identité réseau des Pods.</p><p>Voici quelques exemples de choix pour le domaine du cluster, le nom du service,
le nom du StatefulSet et comment cela affecte les noms DNS des pods du StatefulSet.</p><table><thead><tr><th>Domaine Cluster</th><th>Service (ns/nom)</th><th>StatefulSet (ns/nom)</th><th>Domaine StatefulSet</th><th>DNS Pod</th><th>Nom d'hôte</th></tr></thead><tbody><tr><td>cluster.local</td><td>default/nginx</td><td>default/web</td><td>nginx.default.svc.cluster.local</td><td>web-{0..N-1}.nginx.default.svc.cluster.local</td><td>web-{0..N-1}</td></tr><tr><td>cluster.local</td><td>foo/nginx</td><td>foo/web</td><td>nginx.foo.svc.cluster.local</td><td>web-{0..N-1}.nginx.foo.svc.cluster.local</td><td>web-{0..N-1}</td></tr><tr><td>kube.local</td><td>foo/nginx</td><td>foo/web</td><td>nginx.foo.svc.kube.local</td><td>web-{0..N-1}.nginx.foo.svc.kube.local</td><td>web-{0..N-1}</td></tr></tbody></table><div class="alert alert-info note callout" role=alert><strong>Note:</strong> Le domaine cluster sera <code>cluster.local</code> à moins qu'il soit
<a href=/docs/concepts/services-networking/dns-pod-service/>configuré autrement</a>.</div><h3 id=stockage-stable>Stockage stable</h3><p>Kubernetes crée un <a href=/docs/concepts/storage/persistent-volumes/>PersistentVolume</a> pour chaque
VolumeClaimTemplate. Dans l'exemple nginx ci-dessus, chaque Pod se verra affecter un unique PersistentVolume
avec un StorageClass de <code>my-storage-class</code> et 1 Gib de stockage provisionné. Si aucun StorageClass
n'est spécifié, alors le StorageClass par défaut sera utilisé. Lorsqu'un Pod est (re)schedulé
sur un noeud, ses <code>volumeMounts</code> montent les PersistentVolumes associés aux<br>PersistentVolumeClaims. Notez que les PersistentVolumes associés avec les PersistentVolumeClaims des Pods
ne sont pas supprimés lorsque les Pods, ou le StatefulSet, sont supprimés.
Ceci doit être fait manuellement.</p><h3 id=étiquette-du-nom-de-pod>Étiquette du nom de Pod</h3><p>Lorsque le StatefulSet <a class=glossary-tooltip title="Boucle de contrôle surveillant l'état partagé du cluster à travers l'apiserver et effectuant des changements en essayant de déplacer l'état actuel vers l'état désiré." data-toggle=tooltip data-placement=top href=/docs/admin/kube-controller-manager/ target=_blank aria-label=Contrôleur>Contrôleur</a> crée un Pod,
il ajoute une étiquette, <code>statefulset.kubernetes.io/pod-name</code>, renseignée avec le nom du Pod.
Cette étiquette vous permet d'attacher un Service à un Pod spécifique du StatefulSet.</p><h2 id=garanties-de-déploiement-et-de-mise-à-l-échelle>Garanties de déploiement et de mise à l'échelle</h2><ul><li>Pour un StatefulSet avec N réplicas, lorsque les Pods sont déployés, ils sont créés de manière séquentielle, dans l'ordre {0..N-1}.</li><li>Lorsque les Pods sont supprimés, ils sont terminés dans l'ordre inverse, {N-1..0}.</li><li>Avant qu'une opération de mise à l'échelle soit appliquée à un Pod, tous ses prédécesseurs doivent être Running et Ready.</li><li>Avant qu'un Pod soit terminé, tous ses successeurs doivent être complètement arrêtés.</li></ul><p>Le StatefulSet ne devrait pas spécifier un <code>pod.Spec.TerminationGracePeriodSeconds</code> à 0. Cette pratique
est dangereuse et fortement déconseillée. Pour plus d'explications, veuillez vous référer à <a href=/docs/tasks/run-application/force-delete-stateful-set-pod/>forcer la suppression de Pods de StatefulSet</a>.</p><p>Lorsque l'exemple nginx ci-dessus est créé, trois Pods seront déployés dans l'ordre
web-0, web-1, web-2. web-1 ne sera pas déployé avant que web-0 soit
<a href=/fr/docs/concepts/workloads/pods/pod-lifecycle/>Running et Ready</a>, et web-2 ne sera pas déployé avant que
web-1 soit Running et Ready. Si web-0 venait à échouer, après que web-1 soit Running et Ready, mais avant que
web-2 soit lancé, web-2 ne serait pas lancé avant que web-0 soit correctement relancé et redevienne Running et Ready.</p><p>Si un utilisateur venait à mettre à l'échelle l'exemple déployé en patchant le StatefulSet pour que
<code>replicas=1</code>, web-2 serait terminé en premier. web-1 ne serait pas terminé avant que web-2
ne soit complètement arrêté et supprimé. Si web-0 venait à échouer après que web-2 soit terminé et complètement arrêté,
mais avant que web-1 soit terminé, web-1 ne serait pas terminé avant que web-0 soit Running et Ready.</p><h3 id=politiques-de-gestion-d-un-pod>Politiques de gestion d'un Pod</h3><p>Dans Kubernetes 1.7 et ultérieurs, le StatefulSet vous permet d'assouplir ses garanties d'ordre,
tout en préservant ses garanties d'unicité et d'identité via son champ <code>.spec.podManagementPolicy</code>.</p><h4 id=gestion-de-pod-orderedready>Gestion de Pod OrderedReady</h4><p>La gestion de Pod <code>OrderedReady</code> est la valeur par défaut pour les StatefulSets. Il implémente le comportement décrit <a href=#garanties-de-d%C3%A9ploiment-et-de-mise-%C3%A0-l-%C3%A9chelle>ci-dessus</a>.</p><h4 id=gestion-de-pod-parallel>Gestion de Pod Parallel</h4><p>La gestion de Pod <code>Parallel</code> indique au contrôleur de StatefulSet de lancer ou
terminer tous les Pods en parallèle, et de ne pas attendre que les Pods deviennent Running
et Ready ou complètement terminés avant de lancer ou terminer un autre
Pod. Cette option affecte seulement le comportement pour les opérations de mise à l'échelle.
Les mises à jour ne sont pas affectées.</p><h2 id=stratégies-de-mise-à-jour>Stratégies de mise à jour</h2><p>Dans Kubernetes 1.7 et ultérieurs, le champ <code>.spec.updateStrategy</code> d'un StatefulSet vous permet
de configurer et désactiver les rolling updates automatisés pour les conteneurs, étiquettes,
requête/limites de ressources, et annotations pour les Pods d'un StatefulSet.</p><h3 id=on-delete>On Delete</h3><p>La stratégie de mise à jour <code>OnDelete</code> implémente l'ancien comportement (1.6 et précédents). Lorsque
<code>.spec.updateStrategy.type</code> d'un StatefulSet est mis à <code>OnDelete</code>, le contrôleur de StatefulSet
ne mettra pas à jour automatiquement les Pods dans un StatefulSet.
Les utilisateurs doivent supprimer manuellement les Pods pour forcer le contrôleur à créer de nouveaux
Pods qui réflètent les modifications faites à un <code>.spec.template</code> d'un StatefulSet.</p><h3 id=rolling-updates>Rolling Updates</h3><p>La stratégie de mise à jour <code>RollingUpdate</code> implémente le rolling update automatisé pour les Pods d'un
StatefulSet. C'est la stratégie par défaut lorsque <code>.spec.updateStrategy</code> n'est pas spécifié.
Lorsqu'un <code>.spec.updateStrategy.type</code> d'un StatefulSet est mis à <code>RollingUpdate</code>, le contrôleur de
StatefulSet va supprimer et recréer chaque Pod d'un StatefulSet. Il va procéder dans le même ordre
que pour la terminaison d'un Pod (de l'ordinal le plus grand au plus petit), mettant à jour chaque Pod,
un seul à la fois. Il va attendre qu'un Pod mis à jour soit Running et Ready avant de mettre à jour
son prédécesseur.</p><h4 id=partitions>Partitions</h4><p>La stratégie de mise à jour <code>RollingUpdate</code> peut être partitionnée, en spécifiant une
<code>.spec.updateStrategy.rollingUpdate.partition</code>. Si une partition est spécifiée, tous les Pods ayant un
ordinal plus grand ou égal à la partition seront mis à jour lorsque le
<code>.spec.template</code> du StatefulSet sera mis à jour. Tous les Pods ayant un ordinal inférieur à la partition
ne sera pas mis à jour, et, même s'ils sont supprimés, ils seront recréés avec l'ancienne version. Si une
<code>.spec.updateStrategy.rollingUpdate.partition</code> d'un StatefulSet est plus grand que son <code>.spec.replicas</code>,
les mises à jour de son <code>.spec.template</code> ne seront pas propagés à ses Pods.
Dans la plupart des cas vous n'aurez pas à utiliser de partition, mais elles sont utiles si vous désirez
organiser une mise à jour, déployer une version canari, ou effectuer un déploiement par étapes.</p><h4 id=rollback-forcé>Rollback forcé</h4><p>En utilisant des <a href=#rolling-updates>Rolling Updates</a> avec la
<a href=#politiques-de-gestion-dun-pod>politique de gestion d'un Pod</a> par défaut (<code>OrderedReady</code>),
il est possible de se retrouver dans un état inconsistant nécessitant une intervention manuelle pour réparation.</p><p>Si vous mettez à jour le template de Pod dans une configuration qui ne devient jamais Running et
Ready (par exemple, du fait d'un mauvais binaire ou d'une erreur de configuration au niveau de l'application),
le StatefulSet va arrêter le rollout et attendre.</p><p>Dans cet état, il n'est pas suffisant de revenir à une bonne configuration du template de Pod.
En raison d'une <a href=https://github.com/kubernetes/kubernetes/issues/67250>erreur connue</a>,
le StatefulSet va continuer à attendre que le Pod en échec Pod devienne Ready
(ce qui n'arrive jamais) avant qu'il tente de revenir à la bonne configuration.</p><p>Après être revenu au bon template, vous devez aussi supprimer tous les Pods que le StatefulSet
avait déjà essayé de démarrer avec la mauvaise configuration.
Le StatefulSet va alors commencer à recréer les Pods en utilisant le bon template.</p><h2 id=a-suivre>A suivre</h2><ul><li>Suivre un exemple de <a href=/docs/tutorials/stateful-application/basic-stateful-set/>déploiement d'une application stateful</a>.</li><li>Suivre un exemple de <a href=/docs/tutorials/stateful-application/cassandra/>déploiement de Cassandra avec des Stateful Sets</a>.</li><li>Suivre un exemple d'<a href=/docs/tasks/run-application/run-replicated-stateful-application/>exécution d'une application stateful redondante</a>.</li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-0a0a7eca3e302a3c08f8c85e15d337fd>3.5 - Services, Equilibreur de charge, et Réseau</h1><div class=lead>Service Reseau Kubernetes</div></div><div class=td-content><h1 id=pg-f51db1097575de8072afe1f5b156a70c>3.5.1 - EndpointSlices</h1><div style=margin-top:10px;margin-bottom:10px><b>FEATURE STATE:</b> <code>Kubernetes v1.17 [beta]</code></div><p><em>EndpointSlices</em> offrent une méthode simple pour suivre les Endpoints d'un réseau au sein d'un cluster de Kubernetes. Ils offrent une alternative plus évolutive et extensible aux Endpoints.</p><h2 id=endpointslice-resource>Ressource pour EndpointSlice</h2><p>Dans Kubernetes, un EndpointSlice contient des références à un ensemble de Endpoints.
Le controleur d'EndpointSlice crée automatiquement des EndpointSlices pour un Service quand un <a class=glossary-tooltip title='Allows users to filter a list of resources based on labels.' data-toggle=tooltip data-placement=top href=/docs/concepts/overview/working-with-objects/labels/ target=_blank aria-label=sélecteur>sélecteur</a> est spécifié.
Ces EndpointSlices vont inclure des références à n'importe quels Pods qui correspondent aux selecteurs de Service.
EndpointSlices groupent ensemble les Endpoints d'un réseau par combinaisons uniques de Services et de Ports.</p><p>Par exemple, voici un échantillon d'une ressource EndpointSlice pour le Kubernetes Service <code>exemple</code>.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>discovery.k8s.io/v1beta1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>EndpointSlice<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>exemple-abc<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>labels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>kubernetes.io/service-name</span>:<span style=color:#bbb> </span>exemple<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>addressType</span>:<span style=color:#bbb> </span>IPv4<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>ports</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>http<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>protocol</span>:<span style=color:#bbb> </span>TCP<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>port</span>:<span style=color:#bbb> </span><span style=color:#666>80</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>endpoints</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>addresses</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- <span style=color:#b44>&#34;10.1.2.3&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>conditions</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>ready</span>:<span style=color:#bbb> </span><span style=color:#a2f;font-weight:700>true</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>hostname</span>:<span style=color:#bbb> </span>pod-1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>topology</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>kubernetes.io/hostname</span>:<span style=color:#bbb> </span>node-1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>topology.kubernetes.io/zone</span>:<span style=color:#bbb> </span>us-west2-a<span style=color:#bbb>
</span></span></span></code></pre></div><p>Les EndpointSlices gérés par le contrôleur d'EndpointSlice n'auront, par défaut, pas plus de 100 Endpoints chacun.
En dessous de cette échelle, EndpointSlices devraient mapper 1:1 les Endpoints et les Services et devraient avoir une performance similaire.</p><p>EndpointSlices peuvent agir en tant que source de vérité pour kube-proxy quand il s'agit du routage d'un trafic interne.
Lorsqu'ils sont activés, ils devraient offrir une amélioration de performance pour les services qui ont une grand quantité d'Endpoints.</p><h3 id=types-d-addresses>Types d'addresses</h3><p>Les EndpointSlices supportent 3 types d'addresses :</p><ul><li>IPv4</li><li>IPv6</li><li>FQDN (Fully Qualified Domain Name) - [nom de domaine entièrement qualifié]</li></ul><h3 id=topologie>Topologie</h3><p>Chaque Endpoint dans un EndpointSlice peut contenir des informations de topologie pertinentes.
Ceci est utilisé pour indiquer où se trouve un Endpoint, qui contient les informations sur le Node, zone et région correspondantes. Lorsque les valeurs sont disponibles, les labels de Topologies suivants seront définis par le contrôleur EndpointSlice:</p><ul><li><code>kubernetes.io/hostname</code> - Nom du Node sur lequel l'Endpoint se situe.</li><li><code>topology.kubernetes.io/zone</code> - Zone dans laquelle l'Endpoint se situe.</li><li><code>topology.kubernetes.io/region</code> - Région dans laquelle l'Endpoint se situe.</li></ul><p>Le contrôleur EndpointSlice surveille les Services et les Pods pour assurer que leurs correspondances avec les EndpointSlices sont à jour.
Le contrôleur gère les EndpointSlices pour tous les Services qui ont un sélecteur - [référence: <a class=glossary-tooltip title='Allows users to filter a list of resources based on labels.' data-toggle=tooltip data-placement=top href=/docs/concepts/overview/working-with-objects/labels/ target=_blank aria-label=sélecteur>sélecteur</a>] - specifié. Celles-ci représenteront les IPs des Pods qui correspondent au sélecteur.</p><h3 id=capacité-d-endpointslices>Capacité d'EndpointSlices</h3><p>Les EndpointSlices sont limités à une capacité de 100 Endpoints chacun, par défaut. Vous pouvez configurer ceci avec l'indicateur <code>--max-endpoints-per-slice</code> <a class=glossary-tooltip title='Composant du master qui exécute les contrôleurs.' data-toggle=tooltip data-placement=top href=/docs/reference/generated/kube-controller-manager/ target=_blank aria-label=kube-controller-manager>kube-controller-manager</a> jusqu'à un maximum de 1000.</p><h3 id=distribution-d-endpointslices>Distribution d'EndpointSlices</h3><p>Chaque EndpointSlice a un ensemble de ports qui s'applique à tous les Endpoints dans la ressource.
Lorsque les ports nommés sont utilisés pour un Service, les Pods peuvent se retrouver avec différents ports cibles pour le même port nommé, nécessitant différents EndpointSlices.</p><p>Le contrôleur essaie de remplir les EndpointSlices aussi complètement que possible, mais ne les rééquilibre pas activement. La logique du contrôleur est assez simple:</p><ol><li>Itérer à travers les EndpointSlices existants, retirer les Endpoints qui ne sont plus voulus et mettre à jour les Endpoints qui ont changé.</li><li>Itérer à travers les EndpointSlices qui ont été modifiés dans la première étape et les remplir avec n'importe quel Endpoint nécéssaire.</li><li>S'il reste encore des Endpoints nouveaux à ajouter, essayez de les mettre dans une slice qui n'a pas été changée et/ou en créer une nouvelle.</li></ol><p>Par-dessus tout, la troisième étape priorise la limitation de mises à jour d'EndpointSlice sur une distribution complètement pleine d'EndpointSlices. Par exemple, s'il y avait 10 nouveaux Endpoints à ajouter et 2 EndpointSlices qui peuvent contenir 5 Endpoints en plus chacun; cette approche créera un nouveau EndpointSlice au lieu de remplir les EndpointSlice existants. C'est à dire, une seule création EndpointSlice est préférable à plusieurs mises à jour d'EndpointSlices.</p><p>Avec kube-proxy exécuté sur chaque Node et surveillant EndpointSlices, chaque changement d'un EndpointSlice devient relativement coûteux puisqu'ils seront transmis à chaque Node du cluster.
Cette approche vise à limiter le nombre de modifications qui doivent être envoyées à chaque Node, même si ça peut causer plusieurs EndpointSlices non remplis.</p><p>En pratique, cette distribution bien peu idéale devrait être rare. La plupart des changements traités par le contrôleur EndpointSlice seront suffisamment petits pour tenir dans un EndpointSlice existant, et sinon, un nouveau EndpointSlice aurait probablement été bientôt nécessaire de toute façon. Les mises à jour continues des déploiements fournissent également une compaction naturelle des EndpointSlices avec tous leurs pods et les Endpoints correspondants qui se feront remplacer.</p><h2 id=motivation>Motivation</h2><p>L'API des Endpoints fournit une méthode simple et facile à suivre pour les Endpoints dans Kubernetes. Malheureusement, comme les clusters Kubernetes et Services sont devenus plus grands, les limitations de cette API sont devenues plus visibles. Plus particulièrement, celles-ci comprennent des limitations liées au dimensionnement vers un plus grand nombre d'Endpoints d'un réseau.</p><p>Puisque tous les Endpoints d'un réseau pour un Service ont été stockés dans une seule ressource Endpoints, ces ressources pourraient devenir assez lourdes. Cela affecte les performances des composants Kubernetes (notamment le plan de contrôle) et cause une grande quantité de trafic réseau et de traitements lorsque les Endpoints changent. Les EndpointSlices aident à atténuer ces problèmes ainsi qu'à fournir une plate-forme extensible pour des fonctionnalités supplémentaires telles que le routage topologique.</p><h2 id=a-suivre>A suivre</h2><ul><li><a href=/docs/tasks/administer-cluster/enabling-endpointslices>Activer EndpointSlices</a></li><li>Lire <a href=/docs/concepts/services-networking/connect-applications-service/>Connecter des applications aux Services</a></li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-5701136fd2ce258047b6ddc389112352>3.5.2 - Service</h1>Une manière abstraite d'exposer une application s'exécutant sur un ensemble de <a class=glossary-tooltip title='Le plus petit et le plus simple des objets Kubernetes. Un Pod est un ensemble de conteneurs fonctionnant sur votre cluster.' data-toggle=tooltip data-placement=top href=/fr/docs/concepts/workloads/pods/pod-overview/ target=_blank aria-label=Pods>Pods</a> en tant que service réseau.<p>Avec Kubernetes, vous n'avez pas besoin de modifier votre application pour utiliser un mécanisme de découverte de services inconnu.
Kubernetes donne aux pods leurs propres adresses IP et un nom DNS unique pour un ensemble de pods, et peut équilibrer la charge entre eux.</p><h2 id=motivation>Motivation</h2><p>Les <a class=glossary-tooltip title='Le plus petit et le plus simple des objets Kubernetes. Un Pod est un ensemble de conteneurs fonctionnant sur votre cluster.' data-toggle=tooltip data-placement=top href=/fr/docs/concepts/workloads/pods/pod-overview/ target=_blank aria-label=Pods>Pods</a> Kubernetes sont mortels.
Ils naissent et lorsqu'ils meurent, ils ne ressuscitent pas.
Si vous utilisez un <a class=glossary-tooltip title='Objet API gérant une application répliquée.' data-toggle=tooltip data-placement=top href=/docs/concepts/workloads/controllers/deployment/ target=_blank aria-label=Déploiement>Déploiement</a> pour exécuter votre application, il peut créer et détruire dynamiquement des pods.</p><p>Chaque pod obtient sa propre adresse IP, mais dans un déploiement, l'ensemble de pods s'exécutant en un instant peut être différent de l'ensemble de pods exécutant cette application un instant plus tard.</p><p>Cela conduit à un problème: si un ensemble de pods (appelez-les «backends») fournit des fonctionnalités à d'autres pods (appelez-les «frontends») à l'intérieur de votre cluster, comment les frontends peuvent-ils trouver et suivre l'adresse IP à laquelle se connecter, afin que le frontend puisse utiliser la partie backend de la charge de travail?</p><p>C'est là où les <em>Services</em> rentrent en jeu.</p><h2 id=service-resource>La ressource Service</h2><p>Dans Kubernetes, un service est une abstraction qui définit un ensemble logique de pods et une politique permettant d'y accéder (parfois ce modèle est appelé un micro-service).
L'ensemble des pods ciblés par un service est généralement déterminé par un <a class=glossary-tooltip title='Allows users to filter a list of resources based on labels.' data-toggle=tooltip data-placement=top href=/docs/concepts/overview/working-with-objects/labels/ target=_blank aria-label=selector>selector</a> (voir <a href=#services-without-selectors>ci-dessous</a> pourquoi vous voudrez peut-être un service <em>sans</em> un sélecteur).</p><p>Par exemple, considérons un backend de traitement d'image sans état qui s'exécute avec 3 replicas.
Ces réplicas sont fongibles et les frontends ne se soucient pas du backend qu'ils utilisent.
Bien que les pods réels qui composent l'ensemble backend puissent changer, les clients frontends ne devraient pas avoir besoin de le savoir, pas plus qu'ils ne doivent suivre eux-mêmes l'ensemble des backends.</p><p>L'abstraction du service permet ce découplage.</p><h3 id=découverte-de-services-native-du-cloud>Découverte de services native du cloud</h3><p>Si vous pouvez utiliser les API Kubernetes pour la découverte de services dans votre application, vous pouvez interroger l'<a class=glossary-tooltip title="Composant sur le master qui expose l'API Kubernetes. Il s'agit du front-end pour le plan de contrôle Kubernetes." data-toggle=tooltip data-placement=top href=/docs/reference/generated/kube-apiserver/ target=_blank aria-label='API server'>API server</a> pour les Endpoints, qui sont mis à jour chaque fois que l'ensemble des pods d'un service change.</p><p>Pour les applications non natives, Kubernetes propose des moyens de placer un port réseau ou un load balancer entre votre application et les modules backend.</p><h2 id=définition-d-un-service>Définition d'un service</h2><p>Un service dans Kubernetes est un objet REST, semblable à un pod.
Comme tous les objets REST, vous pouvez effectuer un <code>POST</code> d'une définition de service sur le serveur API pour créer une nouvelle instance.</p><p>Par exemple, supposons que vous ayez un ensemble de pods qui écoutent chacun sur le port TCP 9376 et portent une étiquette <code>app.kubernetes.io/name=MyApp</code>:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Service<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>my-service<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>selector</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>app.kubernetes.io/name</span>:<span style=color:#bbb> </span>MyApp<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>ports</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:green;font-weight:700>protocol</span>:<span style=color:#bbb> </span>TCP<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>port</span>:<span style=color:#bbb> </span><span style=color:#666>80</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>targetPort</span>:<span style=color:#bbb> </span><span style=color:#666>9376</span><span style=color:#bbb>
</span></span></span></code></pre></div><p>Cette spécification crée un nouvel objet Service nommé «my-service», qui cible le port TCP 9376 sur n'importe quel pod avec l'étiquette «app.kubernetes.io/name=MyApp».</p><p>Kubernetes attribue à ce service une adresse IP (parfois appelé l'"IP cluster"), qui est utilisé par les proxies Service (voir <a href=#virtual-ips-and-service-proxies>IP virtuelles et proxy de service</a>).</p><p>Le contrôleur de service recherche en continu les pods qui correspondent à son sélecteur, puis POST toutes les mises à jour d'un objet Endpoint également appelé "my-service".</p><div class="alert alert-info note callout" role=alert><strong>Note:</strong> Un service peut mapper <em>n'importe quel</em> <code>port</code> entrant vers un <code>targetPort</code>.
Par défaut et pour plus de commodité, le <code>targetPort</code> a la même valeur que le champ <code>port</code>.</div><p>Les définitions de port dans les pods ont des noms, et vous pouvez référencer ces noms dans l'attribut <code>targetPort</code> d'un service.
Cela fonctionne même s'il existe un mélange de pods dans le service utilisant un seul nom configuré, avec le même protocole réseau disponible via différents numéros de port.
Cela offre beaucoup de flexibilité pour déployer et faire évoluer vos services.
Par exemple, vous pouvez modifier les numéros de port que les pods exposent dans la prochaine version de votre logiciel principal, sans casser les clients.</p><p>Le protocole par défaut pour les services est TCP; vous pouvez également utiliser tout autre <a href=#protocol-support>protocole pris en charge</a>.</p><p>Comme de nombreux services doivent exposer plus d'un port, Kubernetes prend en charge plusieurs définitions de port sur un objet Service.
Chaque définition de port peut avoir le même protocole, ou un autre.</p><h3 id=services-sans-sélecteurs>Services sans sélecteurs</h3><p>Les services abritent le plus souvent l'accès aux pods Kubernetes, mais ils peuvent également abstraire d'autres types de backends.
Par exemple:</p><ul><li>Vous voulez avoir un cluster de base de données externe en production, mais dans votre environnement de test, vous utilisez vos propres bases de données.</li><li>Vous souhaitez pointer votre service vers un service dans un autre <a class=glossary-tooltip title='An abstraction used by Kubernetes to support isolation of groups of resources within a single cluster.' data-toggle=tooltip data-placement=top href=/docs/concepts/overview/working-with-objects/namespaces target=_blank aria-label=Namespace>Namespace</a> ou sur un autre cluster.</li><li>Vous migrez une charge de travail vers Kubernetes.
Lors de l'évaluation de l'approche, vous exécutez uniquement une partie de vos backends dans Kubernetes.</li></ul><p>Dans n'importe lequel de ces scénarios, vous pouvez définir un service <em>sans</em> un sélecteur de pod.
Par exemple:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Service<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>my-service<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>ports</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:green;font-weight:700>protocol</span>:<span style=color:#bbb> </span>TCP<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>port</span>:<span style=color:#bbb> </span><span style=color:#666>80</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>targetPort</span>:<span style=color:#bbb> </span><span style=color:#666>9376</span><span style=color:#bbb>
</span></span></span></code></pre></div><p>Étant donné que ce service n'a pas de sélecteur, l'objet Endpoint correspondant n'est <em>pas</em> créé automatiquement.
Vous pouvez mapper manuellement le service à l'adresse réseau et au port où il s'exécute, en ajoutant manuellement un objet Endpoint:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Endpoints<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>my-service<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>subsets</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>addresses</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- <span style=color:green;font-weight:700>ip</span>:<span style=color:#bbb> </span><span style=color:#666>192.0.2.42</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>ports</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- <span style=color:green;font-weight:700>port</span>:<span style=color:#bbb> </span><span style=color:#666>9376</span><span style=color:#bbb>
</span></span></span></code></pre></div><div class="alert alert-info note callout" role=alert><strong>Note:</strong><p>Les IP de noeud final ne doivent pas être: loopback (127.0.0.0/8 pour IPv4, ::1/128 pour IPv6), ou link-local (169.254.0.0/16 et 224.0.0.0/24 pour IPv4, fe80::/64 pour IPv6).</p><p>Les adresses IP de noeud final ne peuvent pas être les adresses IP de cluster d'autres services Kubernetes, car <a class=glossary-tooltip title="kube-proxy est un proxy réseau qui s'exécute sur chaque nœud du cluster." data-toggle=tooltip data-placement=top href=/docs/reference/command-line-tools-reference/kube-proxy/ target=_blank aria-label=kube-proxy>kube-proxy</a> ne prend pas en charge les adresses IP virtuelles en tant que destination.</p></div><p>L'accès à un service sans sélecteur fonctionne de la même manière que s'il avait un sélecteur.
Dans l'exemple ci-dessus, le trafic est routé vers le Endpoint unique défini dans le YAML: <code>192.0.2.42:9376</code> (TCP).</p><p>Un service ExternalName est un cas spécial de service qui n'a pas de sélecteurs et utilise des noms DNS à la place.
Pour plus d'informations, consultez la section <a href=#externalname>ExternalName</a> plus loin dans ce document.</p><h3 id=endpoint-slices>Endpoint Slices</h3><div style=margin-top:10px;margin-bottom:10px><b>FEATURE STATE:</b> <code>Kubernetes v1.17 [beta]</code></div><p>Un Endpoint Slices est une ressource API qui peut fournir une alternative plus évolutive au Endpoints.
Bien que conceptuellement assez similaire aux Endpoints, les Endpoint Slices permettent la distribution des endpoints réseau sur plusieurs ressources.
Par défaut, un Endpoint Slice est considéré comme "plein" une fois qu'il atteint 100 endpoints, au delà, des Endpoint Slices addtionnels seront crées pour stocker tout autre endpoints.</p><p>Les Endpoint Slices fournissent des attributs et des fonctionnalités supplémentaires qui sont décrits en détail dans <a href=/docs/concepts/services-networking/endpoint-slices/>Endpoint Slices</a>.</p><h2 id=ip-virtuelles-et-proxy-de-service>IP virtuelles et proxy de service</h2><p>Chaque nœud d'un cluster Kubernetes exécute un <code>kube-proxy</code>.
<code>kube-proxy</code> est responsable de l'implémentation d'une forme d'IP virtuelle pour les <code>Services</code> qui ne sont pas de type <a href=#externalname><code>ExternalName</code></a>.</p><h3 id=pourquoi-ne-pas-utiliser-le-dns-round-robin>Pourquoi ne pas utiliser le DNS round-robin ?</h3><p>Une question qui apparaît de temps en temps est pourquoi Kubernetes s'appuie sur le proxy pour transférer le trafic entrant vers les backends.
Et les autres approches?
Par exemple, serait-il possible de configurer des enregistrements DNS qui ont plusieurs valeurs A (ou AAAA pour IPv6), et de s'appuyer sur la résolution de nom à tour de rôle (round-robin)?</p><p>Il existe plusieurs raisons d'utiliser le proxy pour les services:</p><ul><li>Il existe une longue histoire d'implémentations DNS ne respectant pas les TTL d'enregistrement et mettant en cache les résultats des recherches de noms après leur expiration.</li><li>Certaines applications n'effectuent des recherches DNS qu'une seule fois et mettent en cache les résultats indéfiniment.</li><li>Même si les applications et les bibliothèques ont fait une bonne résolution, les TTL faibles ou nuls sur les enregistrements DNS pourraient imposer une charge élevée sur DNS qui devient alors difficile à gérer.</li></ul><h3 id=proxy-mode-userspace>User space proxy mode</h3><p>Dans ce mode, kube-proxy surveille le maître Kubernetes pour l'ajout et la suppression d'objets Service et Endpoint.
Pour chaque service, il ouvre un port (choisi au hasard) sur le nœud local.
Toutes les connexions à ce "port proxy" sont transmises par proxy à l'un des modules backend du service (comme indiqué via les Endpoints).
kube-proxy prend en compte le paramètre <code>SessionAffinity</code> du service pour décider quel pod backend utiliser.</p><p>Enfin, le proxy de l'espace utilisateur installe des règles iptables qui capturent le trafic vers le service <code>clusterIP</code> (qui est virtuel) et <code>port</code>.
Les règles redirigent ce trafic vers le port proxy qui fait office de proxy pour le Pod de backend.</p><p>Par défaut, kube-proxy en mode espace utilisateur choisit un backend via un algorithme round-robin.</p><p><img src=/images/docs/services-userspace-overview.svg alt="Diagramme de vue d'ensemble des services pour le proxy de l'espace utilisateur"></p><h3 id=proxy-mode-iptables><code>iptables</code> proxy mode</h3><p>Dans ce mode, kube-proxy surveille le plan de contrôle Kubernetes pour l'ajout et la suppression d'objets Service et Endpoint.
Pour chaque service, il installe des règles iptables, qui capturent le trafic vers le «clusterIP» et le «port» du service, et redirigent ce trafic vers l'un des ensembles principaux du service.
Pour chaque objet Endpoint, il installe des règles iptables qui sélectionnent un Pod de backend.</p><p>Par défaut, kube-proxy en mode iptables choisit un backend au hasard.</p><p>L'utilisation d'iptables pour gérer le trafic a un coût système inférieur, car le trafic est géré par Linux netfilter sans avoir besoin de basculer entre l'espace utilisateur et l'espace noyau.
Cette approche est également susceptible d'être plus fiable.</p><p>Si kube-proxy s'exécute en mode iptables et que le premier pod sélectionné ne répond pas, la connexion échoue.
C'est différent du mode espace utilisateur: dans ce scénario, kube-proxy détecterait que la connexion au premier pod avait échoué et réessayerait automatiquement avec un pod backend différent.</p><p>Vous pouvez utiliser les <a href=/docs/concepts/workloads/pods/pod-lifecycle/#container-probes>readiness probes</a> d'un Pod pour vérifier que les pods backend fonctionnent correctement, de sorte que kube-proxy en mode iptables ne voit que les backends testés comme sains.
Cela signifie que vous évitez d'envoyer du trafic via kube-proxy vers un pod connu pour avoir échoué.</p><p><img src=/images/docs/services-iptables-overview.svg alt="Diagramme de présentation des services pour le proxy iptables"></p><h3 id=proxy-mode-ipvs>IPVS proxy mode</h3><div style=margin-top:10px;margin-bottom:10px><b>FEATURE STATE:</b> <code>Kubernetes v1.11 [stable]</code></div><p>En mode <code>ipvs</code>, kube-proxy surveille les Services et Endpoints Kubernetes. kube-proxy appelle l'interface <code>netlink</code> pour créer les règles IPVS en conséquence et synchronise périodiquement les règles IPVS avec les Services et Endpoints Kubernetes.
Cette boucle de contrôle garantit que l'état IPVS correspond à l'état souhaité.
Lors de l'accès à un service, IPVS dirige le trafic vers l'un des pods backend.</p><p>Le mode proxy IPVS est basé sur des fonctions hooks de netfilter qui est similaire au mode iptables, mais utilise la table de hachage comme structure de données sous-jacente et fonctionne dans l'espace du noyau.
Cela signifie que kube-proxy en mode IPVS redirige le trafic avec une latence plus faible que kube-proxy en mode iptables, avec de bien meilleures performances lors de la synchronisation des règles de proxy.
Par rapport aux autres modes proxy, le mode IPVS prend également en charge un débit plus élevé de trafic réseau.</p><p>IPVS offre plus d'options pour équilibrer le trafic vers les pods d'arrière-plan; ceux-ci sont:</p><ul><li><code>rr</code>: round-robin</li><li><code>lc</code>: least connection (plus petit nombre de connexions ouvertes)</li><li><code>dh</code>: destination hashing</li><li><code>sh</code>: source hashing</li><li><code>sed</code>: shortest expected delay</li><li><code>nq</code>: never queue</li></ul><div class="alert alert-info note callout" role=alert><strong>Note:</strong><p>Pour exécuter kube-proxy en mode IPVS, vous devez rendre IPVS Linux disponible sur le nœud avant de démarrer kube-proxy.</p><p>Lorsque kube-proxy démarre en mode proxy IPVS, il vérifie si les modules du noyau IPVS sont disponibles.
Si les modules du noyau IPVS ne sont pas détectés, alors kube-proxy revient à fonctionner en mode proxy iptables.</p></div><p><img src=/images/docs/services-ipvs-overview.svg alt="Diagramme de vue d'ensemble des services pour le proxy IPVS"></p><p>Dans ces modèles de proxy, le trafic lié à l'IP: Port du service est dirigé vers un backend approprié sans que les clients ne sachent quoi que ce soit sur Kubernetes, les services ou les pods.</p><p>Si vous souhaitez vous assurer que les connexions d'un client particulier sont transmises à chaque fois au même pod, vous pouvez sélectionner l'affinité de session en fonction des adresses IP du client en définissant <code>service.spec.sessionAffinity</code> sur" ClientIP "(la valeur par défaut est" None").
Vous pouvez également définir la durée maximale de session persistante en définissant <code>service.spec.sessionAffinityConfig.clientIP.timeoutSeconds</code> de manière appropriée (la valeur par défaut est 10800, ce qui correspond à 3 heures).</p><h2 id=services-multi-ports>Services multi-ports</h2><p>Pour certains services, vous devez exposer plusieurs ports.
Kubernetes vous permet de configurer plusieurs définitions de port sur un objet Service.
Lorsque vous utilisez plusieurs ports pour un service, vous devez donner tous vos noms de ports afin qu'ils ne soient pas ambigus.
Par exemple:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Service<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>my-service<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>selector</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>app.kubernetes.io/name</span>:<span style=color:#bbb> </span>MyApp<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>ports</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>http<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>protocol</span>:<span style=color:#bbb> </span>TCP<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>port</span>:<span style=color:#bbb> </span><span style=color:#666>80</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>targetPort</span>:<span style=color:#bbb> </span><span style=color:#666>9376</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>https<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>protocol</span>:<span style=color:#bbb> </span>TCP<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>port</span>:<span style=color:#bbb> </span><span style=color:#666>443</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>targetPort</span>:<span style=color:#bbb> </span><span style=color:#666>9377</span><span style=color:#bbb>
</span></span></span></code></pre></div><div class="alert alert-info note callout" role=alert><strong>Note:</strong><p>Comme pour tous les <a class=glossary-tooltip title='A client-provided string that refers to an object in a resource URL, such as /api/v1/pods/some-name.' data-toggle=tooltip data-placement=top href=/docs/concepts/overview/working-with-objects/names target=_blank aria-label=names>names</a> Kubernetes en général, les noms de ports ne doivent contenir que des caractères alphanumériques en minuscules et <code>-</code>.
Les noms de port doivent également commencer et se terminer par un caractère alphanumérique.</p><p>Par exemple, les noms <code>123-abc</code> et <code>web</code> sont valides, mais <code>123_abc</code> et <code>-web</code> ne le sont pas.</p></div><h2 id=choisir-sa-propre-adresse-ip>Choisir sa propre adresse IP</h2><p>Vous pouvez spécifier votre propre adresse IP de cluster dans le cadre d'une demande de création de Service.
Pour ce faire, définissez le champ <code>.spec.clusterIP</code>.
Par exemple, si vous avez déjà une entrée DNS existante que vous souhaitez réutiliser, ou des systèmes existants qui sont configurés pour une adresse IP spécifique et difficiles à reconfigurer.</p><p>L'adresse IP que vous choisissez doit être une adresse IPv4 ou IPv6 valide dans la plage CIDR <code>service-cluster-ip-range</code> configurée pour le serveur API.
Si vous essayez de créer un service avec une valeur d'adresse de clusterIP non valide, le serveur API retournera un code d'état HTTP 422 pour indiquer qu'il y a un problème.</p><h2 id=découvrir-les-services>Découvrir les services</h2><p>Kubernetes prend en charge 2 modes principaux de recherche d'un service: les variables d'environnement et DNS.</p><h3 id=variables-d-environnement>Variables d'environnement</h3><p>Lorsqu'un pod est exécuté sur un nœud, le kubelet ajoute un ensemble de variables d'environnement pour chaque service actif.
Il prend en charge à la fois les variables <a href=https://docs.docker.com/userguide/dockerlinks/>Docker links</a> (voir <a href=http://releases.k8s.io/master/pkg/kubelet/envvars/envvars.go#L49>makeLinkVariables</a>) et plus simplement les variables <code>{SVCNAME}_SERVICE_HOST</code> et <code>{SVCNAME}_SERVICE_PORT</code>, où le nom du service est en majuscules et les tirets sont convertis en underscore.</p><p>Par exemple, le service <code>redis-master</code> qui expose le port TCP 6379 et a reçu l'adresse IP de cluster 10.0.0.11, produit les variables d'environnement suivantes:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span><span style=color:#b8860b>REDIS_MASTER_SERVICE_HOST</span><span style=color:#666>=</span>10.0.0.11
</span></span><span style=display:flex><span><span style=color:#b8860b>REDIS_MASTER_SERVICE_PORT</span><span style=color:#666>=</span><span style=color:#666>6379</span>
</span></span><span style=display:flex><span><span style=color:#b8860b>REDIS_MASTER_PORT</span><span style=color:#666>=</span>tcp://10.0.0.11:6379
</span></span><span style=display:flex><span><span style=color:#b8860b>REDIS_MASTER_PORT_6379_TCP</span><span style=color:#666>=</span>tcp://10.0.0.11:6379
</span></span><span style=display:flex><span><span style=color:#b8860b>REDIS_MASTER_PORT_6379_TCP_PROTO</span><span style=color:#666>=</span>tcp
</span></span><span style=display:flex><span><span style=color:#b8860b>REDIS_MASTER_PORT_6379_TCP_PORT</span><span style=color:#666>=</span><span style=color:#666>6379</span>
</span></span><span style=display:flex><span><span style=color:#b8860b>REDIS_MASTER_PORT_6379_TCP_ADDR</span><span style=color:#666>=</span>10.0.0.11
</span></span></code></pre></div><div class="alert alert-info note callout" role=alert><strong>Note:</strong><p>Lorsque vous avez un pod qui doit accéder à un service et que vous utilisez la méthode des variables d'environnement pour publier le port et l'IP du cluster sur les pods clients, vous devez créer le service <em>avant</em> que les pods clients n'existent.
Sinon, ces pods clients n'auront pas leurs variables d'environnement remplies.</p><p>Si vous utilisez uniquement DNS pour découvrir l'IP du cluster pour un service, vous n'avez pas à vous soucier de ce problème de commande.</p></div><h3 id=dns>DNS</h3><p>Vous pouvez (et devriez presque toujours) configurer un service DNS pour votre cluster Kubernetes à l'aide d'un <a href=/docs/concepts/cluster-administration/addons/>add-on</a>.</p><p>Un serveur DNS prenant en charge les clusters, tel que CoreDNS, surveille l'API Kubernetes pour les nouveaux services et crée un ensemble d'enregistrements DNS pour chacun.
Si le DNS a été activé dans votre cluster, tous les pods devraient automatiquement être en mesure de résoudre les services par leur nom DNS.</p><p>Par exemple, si vous avez un service appelé <code>"my-service"</code> dans un namespace Kubernetes <code>"my-ns"</code>, le plan de contrôle et le service DNS agissant ensemble et créent un enregistrement DNS pour <code>"my-service.my-ns"</code>.
Les Pods dans le Namespace <code>"my-ns"</code> devrait être en mesure de le trouver en faisant simplement une recherche de nom pour <code>my-service</code> (<code>"my-service.my-ns"</code> fonctionnerait également).</p><p>Les pods dans d'autres namespaces doivent utiliser le nom de <code>my-service.my-ns</code>.
Ces noms seront résolus en IP de cluster attribuée pour le service.</p><p>Kubernetes prend également en charge les enregistrements DNS SRV (Service) pour les ports nommés.
Si le service <code>"my-service.my-ns"</code> a un port nommé <code>http</code> avec un protocole défini sur <code>TCP</code>, vous pouvez effectuer une requête DNS SRV pour <code>_http._tcp.my-service.my-ns</code> pour découvrir le numéro de port de <code>http</code>, ainsi que l'adresse IP.</p><p>Le serveur DNS Kubernetes est le seul moyen d'accéder aux services <code>ExternalName</code>.
Vous pouvez trouver plus d'informations sur la résolution de <code>ExternalName</code> dans <a href=/docs/concepts/services-networking/dns-pod-service/>DNS Pods et Services</a>.</p><h2 id=headless-services>Headless Services</h2><p>Parfois, vous n'avez pas besoin de load-balancing et d'une seule IP de Service.
Dans ce cas, vous pouvez créer ce que l'on appelle des services "headless", en spécifiant explicitement "None" pour l'IP du cluster (<code>.spec.clusterIP</code>).</p><p>Vous pouvez utiliser un service headless pour interfacer avec d'autres mécanismes de découverte de service, sans être lié à l'implémentation de Kubernetes.</p><p>Pour les services headless, une IP de cluster n'est pas allouée, kube-proxy ne gère pas ces services et aucun load-balancing ou proxy n'est effectué par la plateforme pour eux.
La configuration automatique de DNS dépend de la définition ou non de sélecteurs par le service:</p><h3 id=avec-sélecteurs>Avec sélecteurs</h3><p>Pour les services headless qui définissent des sélecteurs, le controlleur des Endpoints crée des enregistrements <code>Endpoints</code> dans l'API, et modifie la configuration DNS pour renvoyer des enregistrements (adresses) qui pointent directement vers les <code>Pods</code> visés par le <code>Service</code>.</p><h3 id=sans-sélecteurs>Sans sélecteurs</h3><p>Pour les services headless qui ne définissent pas de sélecteurs, le contrôleur des Endpoints ne crée pas d'enregistrements <code>Endpoints</code>.
Cependant, le système DNS recherche et configure soit:</p><ul><li>Enregistrements CNAME pour les services de type <a href=#externalname><code>ExternalName</code></a>.</li><li>Un enregistrement pour tous les «Endpoints» qui partagent un nom avec le Service, pour tous les autres types.</li></ul><h2 id=publishing-services-service-types>Services de publication (ServiceTypes)</h2><p>Pour certaines parties de votre application (par exemple, les frontaux), vous souhaiterez peut-être exposer un service sur une adresse IP externe, qui est en dehors de votre cluster.</p><p>Les «ServiceTypes» de Kubernetes vous permettent de spécifier le type de service que vous souhaitez.
La valeur par défaut est «ClusterIP».</p><p>Les valeurs de <code>Type</code> et leurs comportements sont:</p><ul><li><code>ClusterIP</code>: Expose le service sur une IP interne au cluster.
Le choix de cette valeur rend le service uniquement accessible à partir du cluster.
Il s'agit du <code>ServiceType</code> par défaut.</li><li><a href=#type-nodeport><code>NodePort</code></a>: Expose le service sur l'IP de chaque nœud sur un port statique (le <code>NodePort</code>).
Un service <code>ClusterIP</code>, vers lequel le service <code>NodePort</code> est automatiquement créé.
Vous pourrez contacter le service <code>NodePort</code>, depuis l'extérieur du cluster, en demandant <code>&lt;NodeIP>: &lt;NodePort></code>.</li><li><a href=#loadbalancer><code>LoadBalancer</code></a>: Expose le service en externe à l'aide de l'équilibreur de charge d'un fournisseur de cloud.
Les services <code>NodePort</code> et <code>ClusterIP</code>, vers lesquels les itinéraires de l'équilibreur de charge externe, sont automatiquement créés.</li><li><a href=#externalname><code>ExternalName</code></a>: Mappe le service au contenu du champ <code>externalName</code> (par exemple <code>foo.bar.example.com</code>), en renvoyant un enregistrement <code>CNAME</code> avec sa valeur.
Aucun proxy d'aucune sorte n'est mis en place.<div class="alert alert-info note callout" role=alert><strong>Note:</strong> Vous avez besoin de CoreDNS version 1.7 ou supérieure pour utiliser le type <code>ExternalName</code>.</div></li></ul><p>Vous pouvez également utiliser <a href=/fr/docs/concepts/services-networking/ingress>Ingress</a> pour exposer votre service.
Ingress n'est pas un type de service, mais il sert de point d'entrée pour votre cluster.
Il vous permet de consolider vos règles de routage en une seule ressource car il peut exposer plusieurs services sous la même adresse IP.</p><h3 id=type-nodeport>Type NodePort</h3><p>Si vous définissez le champ <code>type</code> sur<code> NodePort</code>, le plan de contrôle Kubernetes alloue un port à partir d'une plage spécifiée par l'indicateur <code>--service-node-port-range</code> (par défaut: 30000-32767).
Chaque nœud assure le proxy de ce port (le même numéro de port sur chaque nœud) vers votre service.
Votre service signale le port alloué dans son champ <code>.spec.ports[*].nodePort</code>.</p><p>Si vous souhaitez spécifier une ou des adresses IP particulières pour proxyfier le port, vous pouvez définir l'indicateur <code>--nodeport-addresses</code> dans kube-proxy sur des blocs IP particuliers; cela est pris en charge depuis Kubernetes v1.10.
Cet indicateur prend une liste délimitée par des virgules de blocs IP (par exemple 10.0.0.0/8, 192.0.2.0/25) pour spécifier les plages d'adresses IP que kube-proxy doit considérer comme locales pour ce nœud.</p><p>Par exemple, si vous démarrez kube-proxy avec l'indicateur <code>--nodeport-addresses=127.0.0.0/8</code>, kube-proxy sélectionne uniquement l'interface de boucle locale pour les services NodePort.
La valeur par défaut pour <code>--nodeport-addresses</code> est une liste vide.
Cela signifie que kube-proxy doit prendre en compte toutes les interfaces réseau disponibles pour NodePort (qui est également compatible avec les versions antérieures de Kubernetes).</p><p>Si vous voulez un numéro de port spécifique, vous pouvez spécifier une valeur dans le champ <code>nodePort</code>.
Le plan de contrôle vous attribuera ce port ou signalera l'échec de la transaction API.
Cela signifie que vous devez vous occuper vous-même des éventuelles collisions de ports.
Vous devez également utiliser un numéro de port valide, celui qui se trouve dans la plage configurée pour l'utilisation de NodePort.</p><p>L'utilisation d'un NodePort vous donne la liberté de configurer votre propre solution d'équilibrage de charge, de configurer des environnements qui ne sont pas entièrement pris en charge par Kubernetes, ou même d'exposer directement les adresses IP d'un ou plusieurs nœuds.</p><p>Notez que ce service est visible en tant que <code>&lt;NodeIP>: spec.ports[*].nodePort</code> et <code>.spec.clusterIP: spec.ports[*].Port</code>.
(Si l'indicateur <code>--nodeport-addresses</code> dans kube-proxy est défini, <nodeip>serait filtré NodeIP(s).)</p><h3 id=loadbalancer>Type LoadBalancer</h3><p>Sur les fournisseurs de cloud qui prennent en charge les load balancers externes, la définition du champ <code>type</code> sur<code> LoadBalancer</code> provisionne un load balancer pour votre service.
La création réelle du load balancer se produit de manière asynchrone et les informations sur le load balancer provisionné sont publiées dans le champ <code>.status.loadBalancer</code>.
Par exemple:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Service<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>my-service<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>selector</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>app.kubernetes.io/name</span>:<span style=color:#bbb> </span>MyApp<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>ports</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:green;font-weight:700>protocol</span>:<span style=color:#bbb> </span>TCP<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>port</span>:<span style=color:#bbb> </span><span style=color:#666>80</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>targetPort</span>:<span style=color:#bbb> </span><span style=color:#666>9376</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>clusterIP</span>:<span style=color:#bbb> </span><span style=color:#666>10.0.171.239</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>type</span>:<span style=color:#bbb> </span>LoadBalancer<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>status</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>loadBalancer</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>ingress</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:green;font-weight:700>ip</span>:<span style=color:#bbb> </span><span style=color:#666>192.0.2.127</span><span style=color:#bbb>
</span></span></span></code></pre></div><p>Le trafic provenant du load balancer externe est dirigé vers les Pods backend.
Le fournisseur de cloud décide de la répartition de la charge.</p><p>Certains fournisseurs de cloud vous permettent de spécifier le <code>loadBalancerIP</code>.
Dans ces cas, le load balancer est créé avec le <code>loadBalancerIP</code> spécifié par l'utilisateur.
Si le champ <code>loadBalancerIP</code> n'est pas spécifié, le loadBalancer est configuré avec une adresse IP éphémère.
Si vous spécifiez un <code>loadBalancerIP</code> mais que votre fournisseur de cloud ne prend pas en charge la fonctionnalité, le champ <code>loadBalancerIP</code> que vous définissez est ignoré.</p><div class="alert alert-info note callout" role=alert><strong>Note:</strong> Si vous utilisez SCTP, voir le <a href=#caveat-sctp-loadbalancer-service-type>caveat</a> ci-dessous sur le type de service <code>LoadBalancer</code>.</div><div class="alert alert-info note callout" role=alert><strong>Note:</strong><p>Sur <strong>Azure</strong>, si vous souhaitez utiliser un type public spécifié par l'utilisateur <code>loadBalancerIP</code>, vous devez d'abord créer une ressource d'adresse IP publique de type statique.
Cette ressource d'adresse IP publique doit se trouver dans le même groupe de ressources que les autres ressources créées automatiquement du cluster.
Par exemple, <code>MC_myResourceGroup_myAKSCluster_eastus</code>.</p><p>Spécifiez l'adresse IP attribuée en tant que loadBalancerIP.
Assurez-vous d'avoir mis à jour le securityGroupName dans le fichier de configuration du fournisseur de cloud.
Pour plus d'informations sur le dépannage <code>CreatingLoadBalancerFailed</code> relatif aux permissions consultez: <a href=https://docs.microsoft.com/en-us/azure/aks/static-ip>Use a static IP address with the Azure Kubernetes Service (AKS) load balancer</a> ou <a href=https://github.com/Azure/AKS/issues/357>CreatingLoadBalancerFailed on AKS cluster with advanced networking</a>.</p></div><h4 id=load-balancer-interne>Load Balancer interne</h4><p>Dans un environnement mixte, il est parfois nécessaire d'acheminer le trafic des services à l'intérieur du même bloc d'adresse réseau (virtuel).</p><p>Dans un environnement DNS à horizon divisé, vous auriez besoin de deux services pour pouvoir acheminer le trafic externe et interne vers vos endpoints.</p><p>Vous pouvez y parvenir en ajoutant une des annotations suivantes à un service.
L'annotation à ajouter dépend du fournisseur de services cloud que vous utilisez.</p><ul class="nav nav-tabs" id=service-tabs role=tablist><li class=nav-item><a data-toggle=tab class="nav-link active" href=#service-tabs-0 role=tab aria-controls=service-tabs-0 aria-selected=true>Default</a></li><li class=nav-item><a data-toggle=tab class=nav-link href=#service-tabs-1 role=tab aria-controls=service-tabs-1>GCP</a></li><li class=nav-item><a data-toggle=tab class=nav-link href=#service-tabs-2 role=tab aria-controls=service-tabs-2>AWS</a></li><li class=nav-item><a data-toggle=tab class=nav-link href=#service-tabs-3 role=tab aria-controls=service-tabs-3>Azure</a></li><li class=nav-item><a data-toggle=tab class=nav-link href=#service-tabs-4 role=tab aria-controls=service-tabs-4>OpenStack</a></li><li class=nav-item><a data-toggle=tab class=nav-link href=#service-tabs-5 role=tab aria-controls=service-tabs-5>Baidu Cloud</a></li><li class=nav-item><a data-toggle=tab class=nav-link href=#service-tabs-6 role=tab aria-controls=service-tabs-6>Tencent Cloud</a></li></ul><div class=tab-content id=service-tabs><div id=service-tabs-0 class="tab-pane show active" role=tabpanel aria-labelledby=service-tabs-0><p><p>Sélectionnez l'un des onglets.</p></div><div id=service-tabs-1 class=tab-pane role=tabpanel aria-labelledby=service-tabs-1><p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span>[...]<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>my-service<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>annotations</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>cloud.google.com/load-balancer-type</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;Internal&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span>[...]<span style=color:#bbb>
</span></span></span></code></pre></div></div><div id=service-tabs-2 class=tab-pane role=tabpanel aria-labelledby=service-tabs-2><p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span>[...]<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>my-service<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>annotations</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>service.beta.kubernetes.io/aws-load-balancer-internal</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;true&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span>[...]<span style=color:#bbb>
</span></span></span></code></pre></div></div><div id=service-tabs-3 class=tab-pane role=tabpanel aria-labelledby=service-tabs-3><p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span>[...]<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>my-service<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>annotations</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>service.beta.kubernetes.io/azure-load-balancer-internal</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;true&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span>[...]<span style=color:#bbb>
</span></span></span></code></pre></div></div><div id=service-tabs-4 class=tab-pane role=tabpanel aria-labelledby=service-tabs-4><p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span>[...]<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>my-service<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>annotations</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>service.beta.kubernetes.io/openstack-internal-load-balancer</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;true&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span>[...]<span style=color:#bbb>
</span></span></span></code></pre></div></div><div id=service-tabs-5 class=tab-pane role=tabpanel aria-labelledby=service-tabs-5><p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span>[...]<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>my-service<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>annotations</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>service.beta.kubernetes.io/cce-load-balancer-internal-vpc</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;true&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span>[...]<span style=color:#bbb>
</span></span></span></code></pre></div></div><div id=service-tabs-6 class=tab-pane role=tabpanel aria-labelledby=service-tabs-6><p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span>[...]<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>annotations</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>service.kubernetes.io/qcloud-loadbalancer-internal-subnetid</span>:<span style=color:#bbb> </span>subnet-xxxxx<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span>[...]<span style=color:#bbb>
</span></span></span></code></pre></div></div></div><h4 id=ssl-support-on-aws>Prise en charge TLS sur AWS</h4><p>Pour une prise en charge partielle de TLS / SSL sur des clusters exécutés sur AWS, vous pouvez ajouter trois annotations à un service <code>LoadBalancer</code>:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>my-service<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>annotations</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>service.beta.kubernetes.io/aws-load-balancer-ssl-cert</span>:<span style=color:#bbb> </span>arn:aws:acm:us-east-1:123456789012:certificate/12345678-1234-1234-1234-123456789012<span style=color:#bbb>
</span></span></span></code></pre></div><p>Le premier spécifie l'ARN du certificat à utiliser.
Il peut s'agir soit d'un certificat d'un émetteur tiers qui a été téléchargé sur IAM, soit d'un certificat créé dans AWS Certificate Manager.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>my-service<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>annotations</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>service.beta.kubernetes.io/aws-load-balancer-backend-protocol</span>:<span style=color:#bbb> </span>(https|http|ssl|tcp)<span style=color:#bbb>
</span></span></span></code></pre></div><p>La deuxième annotation spécifie le protocole utilisé par un pod.
Pour HTTPS et SSL, l'ELB s'attend à ce que le pod s'authentifie sur la connexion chiffrée, à l'aide d'un certificat.</p><p>HTTP et HTTPS sélectionnent le proxy de couche 7: l'ELB met fin à la connexion avec l'utilisateur, analyse les en-têtes et injecte l'en-tête <code>X-Forwarded-For</code> avec l'adresse IP de l'utilisateur (les pods ne voient que l'adresse IP de l'ELB à l'autre extrémité de sa connexion) lors du transfert des demandes.</p><p>TCP et SSL sélectionnent le proxy de couche 4: l'ELB transfère le trafic sans modifier les en-têtes.</p><p>Dans un environnement à usage mixte où certains ports sont sécurisés et d'autres non chiffrés, vous pouvez utiliser les annotations suivantes:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>my-service<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>annotations</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>service.beta.kubernetes.io/aws-load-balancer-backend-protocol</span>:<span style=color:#bbb> </span>http<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>service.beta.kubernetes.io/aws-load-balancer-ssl-ports</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;443,8443&#34;</span><span style=color:#bbb>
</span></span></span></code></pre></div><p>Dans l'exemple ci-dessus, si le service contenait trois ports, «80», «443» et «8443», alors «443» et «8443» utiliseraient le certificat SSL, mais «80» serait simplement un proxy HTTP.</p><p>A partir de Kubernetes v1.9, vous pouvez utiliser des <a href=https://docs.aws.amazon.com/elasticloadbalancing/latest/classic/elb-security-policy-table.html>stratégies SSL AWS prédéfinies</a> avec des écouteurs HTTPS ou SSL pour vos services.
Pour voir quelles politiques sont disponibles, vous pouvez utiliser l'outil de ligne de commande <code>aws</code>:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>aws elb describe-load-balancer-policies --query <span style=color:#b44>&#39;PolicyDescriptions[].PolicyName&#39;</span>
</span></span></code></pre></div><p>Vous pouvez ensuite spécifier l'une de ces stratégies à l'aide de l'annotation "<code>service.beta.kubernetes.io/aws-load-balancer-ssl-negotiation-policy</code>"; par exemple:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>my-service<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>annotations</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>service.beta.kubernetes.io/aws-load-balancer-ssl-negotiation-policy</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;ELBSecurityPolicy-TLS-1-2-2017-01&#34;</span><span style=color:#bbb>
</span></span></span></code></pre></div><h4 id=prise-en-charge-du-protocole-proxy-sur-aws>Prise en charge du protocole PROXY sur AWS</h4><p>Pour activer <a href=https://www.haproxy.org/download/1.8/doc/proxy-protocol.txt>protocole PROXY</a> prise en charge des clusters exécutés sur AWS, vous pouvez utiliser l'annotation de service suivante:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>my-service<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>annotations</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>service.beta.kubernetes.io/aws-load-balancer-proxy-protocol</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;*&#34;</span><span style=color:#bbb>
</span></span></span></code></pre></div><p>Depuis la version 1.3.0, l'utilisation de cette annotation s'applique à tous les ports mandatés par l'ELB et ne peut pas être configurée autrement.</p><h4 id=journaux-d-accès-elb-sur-aws>Journaux d'accès ELB sur AWS</h4><p>Il existe plusieurs annotations pour gérer les journaux d'accès aux services ELB sur AWS.</p><p>L'annotation <code>service.beta.kubernetes.io/aws-load-balancer-access-log-enabled</code> contrôle si les journaux d'accès sont activés.</p><p>L'annotation <code>service.beta.kubernetes.io/aws-load-balancer-access-log-emit-interval</code> contrôle l'intervalle en minutes pour la publication des journaux d'accès.
Vous pouvez spécifier un intervalle de 5 ou 60 minutes.</p><p>L'annotation <code>service.beta.kubernetes.io/aws-load-balancer-access-log-s3-bucket-name</code> contrôle le nom du bucket Amazon S3 où les journaux d'accès au load balancer sont stockés.</p><p>L'annotation <code>service.beta.kubernetes.io/aws-load-balancer-access-log-s3-bucket-prefix</code> spécifie la hiérarchie logique que vous avez créée pour votre bucket Amazon S3.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>my-service<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>annotations</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>service.beta.kubernetes.io/aws-load-balancer-access-log-enabled</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;true&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:#080;font-style:italic># Spécifie si les journaux d&#39;accès sont activés pour le load balancer</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>service.beta.kubernetes.io/aws-load-balancer-access-log-emit-interval</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;60&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:#080;font-style:italic># L&#39;intervalle de publication des journaux d&#39;accès.</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:#080;font-style:italic># Vous pouvez spécifier un intervalle de 5 ou 60 (minutes).</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>service.beta.kubernetes.io/aws-load-balancer-access-log-s3-bucket-name</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;my-bucket&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:#080;font-style:italic># Le nom du bucket Amazon S3 où les journaux d&#39;accès sont stockés</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>service.beta.kubernetes.io/aws-load-balancer-access-log-s3-bucket-prefix</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;my-bucket-prefix/prod&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:#080;font-style:italic># La hiérarchie logique que vous avez créée pour votre bucket Amazon S3, par exemple `my-bucket-prefix/prod`</span><span style=color:#bbb>
</span></span></span></code></pre></div><h4 id=drainage-de-connexion-sur-aws>Drainage de connexion sur AWS</h4><p>Le drainage des connexions pour les ELB classiques peut être géré avec l'annotation <code>service.beta.kubernetes.io / aws-load-balancer-connection-draining-enabled</code> définie sur la valeur <code>true</code>.
L'annotation <code>service.beta.kubernetes.io / aws-load-balancer-connection-draining-timeout</code> peut également être utilisée pour définir la durée maximale, en secondes, pour garder les connexions existantes ouvertes avant de désenregistrer les instances.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>my-service<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>annotations</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>service.beta.kubernetes.io/aws-load-balancer-connection-draining-enabled</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;true&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>service.beta.kubernetes.io/aws-load-balancer-connection-draining-timeout</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;60&#34;</span><span style=color:#bbb>
</span></span></span></code></pre></div><h4 id=autres-annotations-elb>Autres annotations ELB</h4><p>Il existe d'autres annotations pour gérer les Elastic Load Balancers décrits ci-dessous.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>my-service<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>annotations</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>service.beta.kubernetes.io/aws-load-balancer-connection-idle-timeout</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;60&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:#080;font-style:italic># Délai, en secondes, pendant lequel la connexion peut être inactive (aucune donnée n&#39;a été envoyée via la connexion) avant d&#39;être fermée par le load balancer</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>service.beta.kubernetes.io/aws-load-balancer-cross-zone-load-balancing-enabled</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;true&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:#080;font-style:italic># Spécifie si le load balancing inter-zones est activé pour le load balancer</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>service.beta.kubernetes.io/aws-load-balancer-additional-resource-tags</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;environment=prod,owner=devops&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:#080;font-style:italic># Une liste de paires clé-valeur séparées par des virgules qui seront enregistrées en tant que balises supplémentaires dans l&#39;ELB.</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>service.beta.kubernetes.io/aws-load-balancer-healthcheck-healthy-threshold</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:#080;font-style:italic># Nombre de contrôles de santé successifs réussis requis pour qu&#39;un backend soit considéré comme sain pour le trafic.</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:#080;font-style:italic># La valeur par défaut est 2, doit être comprise entre 2 et 10</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>service.beta.kubernetes.io/aws-load-balancer-healthcheck-unhealthy-threshold</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;3&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:#080;font-style:italic># Nombre de contrôles de santé infructueux requis pour qu&#39;un backend soit considéré comme inapte pour le trafic.</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:#080;font-style:italic># La valeur par défaut est 6, doit être comprise entre 2 et 10</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>service.beta.kubernetes.io/aws-load-balancer-healthcheck-interval</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;20&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:#080;font-style:italic># Intervalle approximatif, en secondes, entre les contrôles d&#39;intégrité d&#39;une instance individuelle.</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:#080;font-style:italic># La valeur par défaut est 10, doit être comprise entre 5 et 300</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>service.beta.kubernetes.io/aws-load-balancer-healthcheck-timeout</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;5&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:#080;font-style:italic># Durée, en secondes, pendant laquelle aucune réponse ne signifie l&#39;échec d&#39;un contrôle de santé.</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:#080;font-style:italic># Cette valeur doit être inférieure à la valeur service.beta.kubernetes.io/aws-load-balancer-healthcheck-interval.</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:#080;font-style:italic># La valeur par défaut est 5, doit être comprise entre 2 et 60</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>service.beta.kubernetes.io/aws-load-balancer-extra-security-groups</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;sg-53fae93f,sg-42efd82e&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:#080;font-style:italic># Une liste de groupes de sécurité supplémentaires à ajouter à l&#39;ELB</span><span style=color:#bbb>
</span></span></span></code></pre></div><h4 id=aws-nlb-support>Prise en charge du load balancer réseau sur AWS</h4><div style=margin-top:10px;margin-bottom:10px><b>FEATURE STATE:</b> <code>Kubernetes v1.15 [beta]</code></div><p>Pour utiliser un load balancer réseau sur AWS, utilisez l'annotation <code>service.beta.kubernetes.io/aws-load-balancer-type</code> avec la valeur définie sur <code>nlb</code>.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>my-service<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>annotations</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>service.beta.kubernetes.io/aws-load-balancer-type</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;nlb&#34;</span><span style=color:#bbb>
</span></span></span></code></pre></div><div class="alert alert-info note callout" role=alert><strong>Note:</strong> NLB ne fonctionne qu'avec certaines classes d'instance; voir la <a href=http://docs.aws.amazon.com/elasticloadbalancing/latest/network/target-group-register-targets.html#register-deregister-targets>documentation AWS</a> sur Elastic Load Balancing pour une liste des types d'instances pris en charge.</div><p>Contrairement aux équilibreurs de charge élastiques classiques, les équilibreurs de charge réseau (NLB) transfèrent l'adresse IP du client jusqu'au nœud.
Si un service est <code>.spec.externalTrafficPolicy</code> est réglé sur <code>Cluster</code>, l'adresse IP du client n'est pas propagée aux pods finaux.</p><p>En définissant <code>.spec.externalTrafficPolicy</code> à <code>Local</code>, les adresses IP des clients sont propagées aux pods finaux, mais cela peut entraîner une répartition inégale du trafic.
Les nœuds sans pods pour un service LoadBalancer particulier échoueront au contrôle de santé du groupe cible NLB sur le <code>.spec.healthCheckNodePort</code> attribué automatiquement et ne recevront aucun trafic.</p><p>Pour obtenir un trafic uniforme, utilisez un DaemonSet ou spécifiez un <a href=/docs/concepts/configuration/assign-pod-node/#affinity-and-anti-affinity>pod anti-affinity</a> pour ne pas localiser sur le même noeud.</p><p>Vous pouvez également utiliser les services NLB avec l'annotation <a href=/docs/concepts/services-networking/service/#internal-load-balancer>load balancer internal</a>.</p><p>Pour que le trafic client atteigne des instances derrière un NLB, les groupes de sécurité du nœud sont modifiés avec les règles IP suivantes:</p><table><thead><tr><th>Rule</th><th>Protocol</th><th>Port(s)</th><th>IpRange(s)</th><th>IpRange Description</th></tr></thead><tbody><tr><td>Health Check</td><td>TCP</td><td>NodePort(s) (<code>.spec.healthCheckNodePort</code> for <code>.spec.externalTrafficPolicy = Local</code>)</td><td>VPC CIDR</td><td>kubernetes.io/rule/nlb/health=&lt;loadBalancerName></td></tr><tr><td>Client Traffic</td><td>TCP</td><td>NodePort(s)</td><td><code>.spec.loadBalancerSourceRanges</code> (defaults to <code>0.0.0.0/0</code>)</td><td>kubernetes.io/rule/nlb/client=&lt;loadBalancerName></td></tr><tr><td>MTU Discovery</td><td>ICMP</td><td>3,4</td><td><code>.spec.loadBalancerSourceRanges</code> (defaults to <code>0.0.0.0/0</code>)</td><td>kubernetes.io/rule/nlb/mtu=&lt;loadBalancerName></td></tr></tbody></table><p>Afin de limiter les IP clientes pouvant accéder à l'équilibreur de charge réseau, spécifiez <code>loadBalancerSourceRanges</code>.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>loadBalancerSourceRanges</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:#b44>&#34;143.231.0.0/16&#34;</span><span style=color:#bbb>
</span></span></span></code></pre></div><div class="alert alert-info note callout" role=alert><strong>Note:</strong> Si <code>.spec.loadBalancerSourceRanges</code> n'est pas défini, Kubernetes autorise le trafic de <code>0.0.0.0/0</code> vers les groupes de sécurité des nœuds.
Si les nœuds ont des adresses IP publiques, sachez que le trafic non NLB peut également atteindre toutes les instances de ces groupes de sécurité modifiés.</div><h4 id=autres-annotations-clb-sur-tencent-kubernetes-engine-tke>Autres annotations CLB sur Tencent Kubernetes Engine (TKE)</h4><p>Il existe d'autres annotations pour la gestion des équilibreurs de charge cloud sur TKE, comme indiqué ci-dessous.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>my-service<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>annotations</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:#080;font-style:italic># Lier des load balancers avec des nœuds spécifiques</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>service.kubernetes.io/qcloud-loadbalancer-backends-label</span>:<span style=color:#bbb> </span>key in (value1, value2)<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:#080;font-style:italic># ID d&#39;un load balancer existant</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span>service.kubernetes.io/tke-existed-lbid：lb-6swtxxxx<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:#080;font-style:italic># Paramètres personnalisés pour le load balancer (LB), ne prend pas encore en charge la modification du type LB</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>service.kubernetes.io/service.extensiveParameters</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:#080;font-style:italic># Paramètres personnalisés pour le listener LB</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>service.kubernetes.io/service.listenerParameters</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:#080;font-style:italic># Spécifie le type de Load balancer;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:#080;font-style:italic># valeurs valides: classic (Classic Cloud Load Balancer) ou application (Application Cloud Load Balancer)</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>service.kubernetes.io/loadbalance-type</span>:<span style=color:#bbb> </span>xxxxx<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:#080;font-style:italic># Spécifie la méthode de facturation de la bande passante du réseau public;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:#080;font-style:italic># valid values: TRAFFIC_POSTPAID_BY_HOUR(bill-by-traffic) and BANDWIDTH_POSTPAID_BY_HOUR (bill-by-bandwidth).</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>service.kubernetes.io/qcloud-loadbalancer-internet-charge-type</span>:<span style=color:#bbb> </span>xxxxxx<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:#080;font-style:italic># Spécifie la valeur de bande passante (plage de valeurs: [1,2000] Mbps).</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>service.kubernetes.io/qcloud-loadbalancer-internet-max-bandwidth-out</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;10&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:#080;font-style:italic># Lorsque cette annotation est définie, les équilibreurs de charge n&#39;enregistrent que les nœuds sur lesquels le pod s&#39;exécute, sinon tous les nœuds seront enregistrés.</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>service.kubernetes.io/local-svc-only-bind-node-with-pod</span>:<span style=color:#bbb> </span><span style=color:#a2f;font-weight:700>true</span><span style=color:#bbb>
</span></span></span></code></pre></div><h3 id=externalname>Type ExternalName</h3><p>Les services de type ExternalName mappent un service à un nom DNS, et non à un sélecteur standard tel que <code>my-service</code> ou <code>cassandra</code>.
Vous spécifiez ces services avec le paramètre <code>spec.externalName</code>.</p><p>Cette définition de service, par exemple, mappe le service <code>my-service</code> dans l'espace de noms<code> prod</code> à <code>my.database.example.com</code>:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Service<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>my-service<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>namespace</span>:<span style=color:#bbb> </span>prod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>type</span>:<span style=color:#bbb> </span>ExternalName<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>externalName</span>:<span style=color:#bbb> </span>my.database.example.com<span style=color:#bbb>
</span></span></span></code></pre></div><div class="alert alert-info note callout" role=alert><strong>Note:</strong> ExternalName accepte une chaîne d'adresse IPv4, mais en tant que noms DNS composés de chiffres, et non en tant qu'adresse IP.
Les noms externes qui ressemblent aux adresses IPv4 ne sont pas résolus par CoreDNS ou ingress-nginx car ExternalName est destiné à spécifier un nom DNS canonique.
Pour coder en dur une adresse IP, pensez à utiliser des <a href=#headless-services>Services headless</a>.</div><p>Lors de la recherche de l'hôte <code>my-service.prod.svc.cluster.local</code>, le service DNS du cluster renvoie un enregistrement<code> CNAME</code> avec la valeur <code>my.database.example.com</code>.
L'accès à «mon-service» fonctionne de la même manière que les autres services, mais avec la différence cruciale que la redirection se produit au niveau DNS plutôt que via un proxy ou un transfert.
Si vous décidez ultérieurement de déplacer votre base de données dans votre cluster, vous pouvez démarrer ses pods, ajouter des sélecteurs ou des Endpoints appropriés et modifier le <code>type</code> du service.</p><div class="alert alert-danger warning callout" role=alert><strong>Attention:</strong><p>Vous pouvez rencontrer des difficultés à utiliser ExternalName pour certains protocoles courants, notamment HTTP et HTTPS.
Si vous utilisez ExternalName, le nom d'hôte utilisé par les clients à l'intérieur de votre cluster est différent du nom référencé par ExternalName.</p><p>Pour les protocoles qui utilisent des noms d'hôtes, cette différence peut entraîner des erreurs ou des réponses inattendues.
Les requêtes HTTP auront un en-tête <code>Host:</code> que le serveur d'origine ne reconnaît pas; Les serveurs TLS ne pourront pas fournir de certificat correspondant au nom d'hôte auquel le client s'est connecté.</p></div><div class="alert alert-info note callout" role=alert><strong>Note:</strong> Cette section est redevable à l'article <a href=https://akomljen.com/kubernetes-tips-part-1/>Kubernetes Tips - Part 1</a> d'<a href=https://akomljen.com/>Alen Komljen</a>.</div><h3 id=ip-externes>IP externes</h3><p>S'il existe des adresses IP externes qui acheminent vers un ou plusieurs nœuds de cluster, les services Kubernetes peuvent être exposés sur ces "IP externes".
Le trafic qui pénètre dans le cluster avec l'IP externe (en tant qu'IP de destination), sur le port de service, sera routé vers l'un des Endpoints de service.
Les <code>externalIPs</code> ne sont pas gérées par Kubernetes et relèvent de la responsabilité de l'administrateur du cluster.</p><p>Dans la spécification de service, «externalIPs» peut être spécifié avec n'importe lequel des «ServiceTypes».
Dans l'exemple ci-dessous, "<code>my-service</code>" peut être consulté par les clients sur "<code>80.11.12.10:80</code>" (<code>externalIP:port</code>)</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Service<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>my-service<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>selector</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>app.kubernetes.io/name</span>:<span style=color:#bbb> </span>MyApp<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>ports</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>http<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>protocol</span>:<span style=color:#bbb> </span>TCP<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>port</span>:<span style=color:#bbb> </span><span style=color:#666>80</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>targetPort</span>:<span style=color:#bbb> </span><span style=color:#666>9376</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>externalIPs</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:#666>80.11.12.10</span><span style=color:#bbb>
</span></span></span></code></pre></div><h2 id=lacunes>Lacunes</h2><p>Le proxy fonctionnant dans l'espace utilisateur pour les VIP peut fonctionner à petite ou moyenne échelle, mais montrera ses limites dans de très grands clusters avec des milliers de services.
La <a href=http://issue.k8s.io/1107>proposition de conception originale pour les portails</a> a plus de détails à ce sujet.</p><p>L'utilisation du proxy de l'espace utilisateur masque l'adresse IP source d'un paquet accédant à un service.
Cela rend certains types de filtrage réseau (pare-feu) impossibles.
Le mode proxy iptables n'obscurcit pas les adresses IP source dans le cluster, mais il affecte toujours les clients passant par un <code>LoadBalancer</code> ou un <code>NodePort</code>.</p><p>Le champ <code>Type</code> est conçu comme une fonctionnalité imbriquée - chaque niveau s'ajoute au précédent.
Cela n'est pas strictement requis sur tous les fournisseurs de cloud (par exemple, Google Compute Engine n'a pas besoin d'allouer un <code>NodePort</code> pour faire fonctionner <code>LoadBalancer</code>, mais AWS le fait) mais l'API actuelle le requiert.</p><h2 id=the-gory-details-of-virtual-ips>Implémentation IP virtuelle</h2><p>Les informations précédentes devraient être suffisantes pour de nombreuses personnes qui souhaitent simplement utiliser les Services.
Cependant, il se passe beaucoup de choses dans les coulisses qui méritent d'être comprises.</p><h3 id=éviter-les-collisions>Éviter les collisions</h3><p>L'une des principales philosophies de Kubernetes est que vous ne devez pas être exposé à des situations qui pourraient entraîner l'échec de vos actions sans aucune faute de votre part.
Pour la conception de la ressource Service, cela signifie de ne pas vous faire choisir votre propre numéro de port si ce choix pourrait entrer en collision avec le choix de quelqu'un d'autre.
C'est un échec d'isolement.</p><p>Afin de vous permettre de choisir un numéro de port pour vos Services, nous devons nous assurer qu'aucun deux Services ne peuvent entrer en collision.
Kubernetes le fait en attribuant à chaque service sa propre adresse IP.</p><p>Pour garantir que chaque service reçoit une adresse IP unique, un allocateur interne met à jour atomiquement une carte d'allocation globale dans <a class=glossary-tooltip title='Base de données clé-valeur consistante et hautement disponible utilisée comme mémoire de sauvegarde pour toutes les données du cluster.' data-toggle=tooltip data-placement=top href=/docs/tasks/administer-cluster/configure-upgrade-etcd/ target=_blank aria-label=etcd>etcd</a> avant de créer chaque service.
L'objet de mappage doit exister dans le registre pour que les services obtiennent des affectations d'adresse IP, sinon les créations échoueront avec un message indiquant qu'une adresse IP n'a pas pu être allouée.</p><p>Dans le plan de contrôle, un contrôleur d'arrière-plan est responsable de la création de cette carte (nécessaire pour prendre en charge la migration à partir d'anciennes versions de Kubernetes qui utilisaient le verrouillage en mémoire).
Kubernetes utilise également des contrôleurs pour vérifier les affectations non valides (par exemple en raison d'une intervention de l'administrateur) et pour nettoyer les adresses IP allouées qui ne sont plus utilisées par aucun service.</p><h3 id=ips-and-vips>Service IP addresses</h3><p>Contrairement aux adresses IP des pods, qui acheminent réellement vers une destination fixe, les adresses IP des services ne sont pas réellement répondues par un seul hôte.
Au lieu de cela, kube-proxy utilise iptables (logique de traitement des paquets sous Linux) pour définir les adresses IP <em>virtual</em> qui sont redirigées de manière transparente selon les besoins.
Lorsque les clients se connectent au VIP, leur trafic est automatiquement transporté vers un Endpoint approprié.
Les variables d'environnement et DNS pour les services sont en fait remplis en termes d'adresse IP virtuelle (et de port) du service.</p><p>kube-proxy prend en charge trois modes proxy — espace utilisateur, iptables et IPVS — qui fonctionnent chacun légèrement différemment.</p><h4 id=userspace>Userspace</h4><p>À titre d'exemple, considérons l'application de traitement d'image décrite ci-dessus.
Lorsque le service backend est créé, le maître Kubernetes attribue une adresse IP virtuelle, par exemple 10.0.0.1.
En supposant que le port de service est 1234, le service est observé par toutes les instances kube-proxy dans le cluster.
Lorsqu'un proxy voit un nouveau service, il ouvre un nouveau port aléatoire, établit une redirection iptables de l'adresse IP virtuelle vers ce nouveau port et commence à accepter les connexions sur celui-ci.</p><p>Lorsqu'un client se connecte à l'adresse IP virtuelle du service, la règle iptables entre en jeu et redirige les paquets vers le propre port du proxy.
Le “Service proxy” choisit un backend, et commence le proxy du trafic du client vers le backend.</p><p>Cela signifie que les propriétaires de services peuvent choisir le port de leur choix sans risque de collision.
Les clients peuvent simplement se connecter à une adresse IP et à un port, sans savoir à quels pods ils accèdent réellement.</p><h4 id=iptables>iptables</h4><p>Considérons à nouveau l'application de traitement d'image décrite ci-dessus.
Lorsque le service backend est créé, le plan de contrôle Kubernetes attribue une adresse IP virtuelle, par exemple 10.0.0.1.
En supposant que le port de service est 1234, le service est observé par toutes les instances de kube-proxy dans le cluster.
Lorsqu'un proxy voit un nouveau service, il installe une série de règles iptables qui redirigent de l'adresse IP virtuelle vers des règles par service.
Les règles par service sont liées aux règles des Endpoints qui redirigent le trafic (à l'aide du NAT de destination) vers les backends.</p><p>Lorsqu'un client se connecte à l'adresse IP virtuelle du service, la règle iptables entre en jeu.
Un backend est choisi (soit en fonction de l'affinité de la session, soit au hasard) et les paquets sont redirigés vers le backend.
Contrairement au proxy de l'espace utilisateur, les paquets ne sont jamais copiés dans l'espace utilisateur, le proxy de kube n'a pas besoin d'être exécuté pour que l'adresse IP virtuelle fonctionne et les nœuds voient le trafic provenant de l'adresse IP du client non modifiée.</p><p>Ce même flux de base s'exécute lorsque le trafic arrive via un port de nœud ou via un load balancer, bien que dans ces cas, l'adresse IP du client soit modifiée.</p><h4 id=ipvs>IPVS</h4><p>Les opérations iptables ralentissent considérablement dans un cluster à grande échelle, par exemple 10000 services.
IPVS est conçu pour l'équilibrage de charge et basé sur des tables de hachage dans le noyau.
Ainsi, vous pouvez obtenir une cohérence des performances dans un grand nombre de services à partir d'un kube-proxy basé sur IPVS.
De plus, kube-proxy basé sur IPVS a des algorithmes d'équilibrage de charge plus sophistiqués (le moins de connexions, localité, pondéré, persistance).</p><h2 id=objet-api>Objet API</h2><p>Le service est une ressource de niveau supérieur dans l'API REST Kubernetes.
Vous pouvez trouver plus de détails sur l'objet API sur: <a href=/docs/reference/generated/kubernetes-api/v1.25/#service-v1-core>Service API object</a>.</p><h2 id=protocol-support>Protocoles pris en charge</h2><h3 id=tcp>TCP</h3><div style=margin-top:10px;margin-bottom:10px><b>FEATURE STATE:</b> <code>Kubernetes v1.0 [stable]</code></div><p>Vous pouvez utiliser TCP pour tout type de service, et c'est le protocole réseau par défaut.</p><h3 id=udp>UDP</h3><div style=margin-top:10px;margin-bottom:10px><b>FEATURE STATE:</b> <code>Kubernetes v1.0 [stable]</code></div><p>Vous pouvez utiliser UDP pour la plupart des services.
Pour Services de type LoadBalancer, la prise en charge UDP dépend du fournisseur de cloud offrant cette fonctionnalité.</p><h3 id=http>HTTP</h3><div style=margin-top:10px;margin-bottom:10px><b>FEATURE STATE:</b> <code>Kubernetes v1.1 [stable]</code></div><p>Si votre fournisseur de cloud le prend en charge, vous pouvez utiliser un service dans le mode LoadBalancer pour configurer le proxy inverse HTTP / HTTPS externe, transmis au Endpoints du Service.</p><div class="alert alert-info note callout" role=alert><strong>Note:</strong> Vous pouvez aussi utiliser <a class=glossary-tooltip title="Un objet API qui gère l'accès externe aux services d'un cluster, typiquement HTTP." data-toggle=tooltip data-placement=top href=/docs/concepts/services-networking/ingress/ target=_blank aria-label=Ingress>Ingress</a> à la place du service pour exposer les services HTTP/HTTPS.</div><h3 id=protocole-proxy>Protocole PROXY</h3><div style=margin-top:10px;margin-bottom:10px><b>FEATURE STATE:</b> <code>Kubernetes v1.1 [stable]</code></div><p>Si votre fournisseur de cloud le prend en charge(eg, <a href=/docs/concepts/cluster-administration/cloud-providers/#aws>AWS</a>), vous pouvez utiliser un service en mode LoadBalancer pour configurer un load balancer en dehors de Kubernetes lui-même, qui transmettra les connexions préfixées par <a href=https://www.haproxy.org/download/1.8/doc/proxy-protocol.txt>PROXY protocol</a>.</p><p>Le load balancer enverra une première série d'octets décrivant la connexion entrante, similaire à cet exemple</p><pre tabindex=0><code>PROXY TCP4 192.0.2.202 10.0.42.7 12345 7\r\n
</code></pre><p>suivi des données du client.</p><h3 id=sctp>SCTP</h3><div style=margin-top:10px;margin-bottom:10px><b>FEATURE STATE:</b> <code>Kubernetes v1.12 [alpha]</code></div><p>Kubernetes prend en charge SCTP en tant que valeur de «protocole» dans les définitions de Service, Endpoint, NetworkPolicy et Pod en tant que fonctionnalité alpha.
Pour activer cette fonction, l'administrateur du cluster doit activer le flag <code>SCTPSupport</code> sur l'apiserver, par exemple, <code>--feature-gates=SCTPSupport=true,…</code>.</p><p>When the feature gate is enabled, you can set the <code>protocol</code> field of a Service, Endpoint, NetworkPolicy or Pod to <code>SCTP</code>.
Kubernetes sets up the network accordingly for the SCTP associations, just like it does for TCP connections.</p><h4 id=caveat-sctp-overview>Avertissements</h4><h5 id=caveat-sctp-multihomed>Prise en charge des associations SCTP multi-hôtes</h5><div class="alert alert-danger warning callout" role=alert><strong>Attention:</strong><p>La prise en charge des associations SCTP multi-hôtes nécessite que le plug-in CNI puisse prendre en charge l'attribution de plusieurs interfaces et adresses IP à un pod.</p><p>Le NAT pour les associations SCTP multi-hôtes nécessite une logique spéciale dans les modules de noyau correspondants.</p></div><h5 id=caveat-sctp-loadbalancer-service-type>Service avec type=LoadBalancer</h5><div class="alert alert-danger warning callout" role=alert><strong>Attention:</strong> Vous ne pouvez créer un service de type LoadBalancer avec SCTP que si le fournisseur de load balancer supporte SCTP comme protocole.
Sinon, la demande de création de service est rejetée.
L'ensemble actuel de fournisseurs de load balancer cloud (Azure, AWS, CloudStack, GCE, OpenStack) ne prennent pas en charge SCTP.</div><h5 id=caveat-sctp-windows-os>Windows</h5><div class="alert alert-danger warning callout" role=alert><strong>Attention:</strong> SCTP n'est pas pris en charge sur les nœuds Windows.</div><h5 id=caveat-sctp-kube-proxy-userspace>Userspace kube-proxy</h5><div class="alert alert-danger warning callout" role=alert><strong>Attention:</strong> Le kube-proxy ne prend pas en charge la gestion des associations SCTP lorsqu'il est en mode userspace.</div><h2 id=futurs-développements>Futurs développements</h2><p>À l'avenir, la stratégie de proxy pour les services peut devenir plus nuancée que le simple équilibrage alterné, par exemple master-elected ou sharded.
Nous prévoyons également que certains services auront des load balancer «réels», auquel cas l'adresse IP virtuelle y transportera simplement les paquets.</p><p>Le projet Kubernetes vise à améliorer la prise en charge des services L7 (HTTP).</p><p>Le projet Kubernetes prévoit d'avoir des modes d'entrée plus flexibles pour les services, qui englobent les modes ClusterIP, NodePort et LoadBalancer actuels et plus encore.</p><h2 id=a-suivre>A suivre</h2><ul><li>Voir <a href=/docs/concepts/services-networking/connect-applications-service/>Connecting Applications with Services</a></li><li>Voir <a href=/docs/concepts/services-networking/ingress/>Ingress</a></li><li>Voir <a href=/docs/concepts/services-networking/endpoint-slices/>Endpoint Slices</a></li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-91cb8a4438b003df11bc1c426a81b756>3.5.3 - DNS pour les services et les pods</h1><div class=lead>DNS services pods Kubernetes</div><p>Cette page fournit une vue d'ensemble du support DNS par Kubernetes.</p><h2 id=introduction>Introduction</h2><p>Kubernetes planifie un pod et un service DNS sur le cluster et configure
les kubelets pour indiquer à chaque conteneur d'utiliser l'adresse IP du service DNS pour résoudre les noms DNS.</p><h3 id=quels-composants-obtiennent-des-noms-dns>Quels composants obtiennent des noms DNS?</h3><p>Chaque service défini dans le cluster (y compris le serveur DNS lui-même) a un nom DNS. Par défaut, la liste de recherche DNS du client d'un pod inclura le namespace (espace de nommage) du pod et le domaine par défaut du cluster. C'est mieux
illustré par un exemple :</p><p>Supposons un service nommé <code>foo</code> dans le namespace Kubernetes <code>bar</code>. Un pod en cours d'exécution dans le namespace <code>bar</code> peut rechercher ce service en faisant simplement une requête DNS "foo". Un pod qui tourne dans le namespace <code>quux</code> peut rechercher ce service en effectuant une requête DNS <code>foo.bar</code>.</p><p>Les sections suivantes détaillent les types d’enregistrement et la structure supportée par Kubernetes. Toute autre structure ou noms ou requêtes qui fonctionnent sont
considérés comme des détails d'implémentation et peuvent changer sans préavis.
Pour une spécification plus à jour, voir
<a href=https://github.com/kubernetes/dns/blob/master/docs/specification.md>Découverte des services basée sur le DNS Kubernetes</a>.</p><h2 id=services>Services</h2><h3 id=enregistrement-a>Enregistrement A</h3><p>Les services "normaux" (pas sans en-tête) se voient attribuer un enregistrement DNS A, et ont un nom sous la forme : <code>mon-service.mon-namespace.svc.cluster.local</code>. La résolution de ce nom donne l'adresse <code>ClusterIP</code> du service.</p><p>Les Services "Headless" (ou sans en-tête, c'est à dire sans ClusterIP) auront également un enregistrement type A, donc un nom sous la forme : <code>mon-service.mon-namespace.svc.cluster.local</code>. Contrairement aux Services Normaux, cela résout l'ensemble des adresses IP des pods sélectionnés par le Service.
On s'attend à ce que les clients consomment l'ensemble ou utilisent le standard de sélection round-robin de l'ensemble.</p><h3 id=enregistrement-srv>Enregistrement SRV</h3><p>Les enregistrements SRV sont créés pour les ports nommés faisant partie des services normaux ou <a href=/docs/concepts/services-networking/service/#headless-services>Headless (sans en-tête)</a>.
Pour chaque port nommé, l'enregistrement SRV aurait la forme
<code>_mon-nom-de-port._mon-protocole-de-port.mon-service.mon-namespace.svc.cluster.local</code>.
Pour un service régulier, cela se traduit par le numéro de port et le nom de domaine :
<code>mon-service.mon-namespace.svc.cluster.local</code>.
Pour un service sans en-tête, cela pourrait être résolu en plusieurs réponses, une réponse pour chaque pod lié à ce service et qui contient le numéro de port, ainsi le nom de domaine du pod est sous la forme <code>nom-auto-genere.mon-service.mon-namespace.svc.cluster.local</code>.</p><h2 id=pods>Pods</h2><h3 id=enregistrement-a-1>Enregistrement A</h3><p>Lorsque cette option est activée, un enregistrement DNS A est attribué aux pods sous la forme <code>adresse-ip-du-pod.mon-namespace.pod.cluster.local</code>.</p><p>Par exemple, un pod avec l’IP <code>1.2.3.4</code> dans le namespace (espace de nommage) <code>default</code> avec un nom DNS de <code>cluster.local</code> aurait une entrée : <code>1-2-3-4.default.pod.cluster.local</code>.</p><h3 id=nom-d-hôte-et-sous-domaine-d-un-pod>Nom d'hôte et sous-domaine d'un pod</h3><p>Actuellement, lorsqu'un pod est créé, son nom d'hôte a la valeur <code>metadata.name</code> du pod.</p><p>La spécification du pod a un champ optionnel <code>hostname</code>, qui peut être utilisé pour spécifier la valeur du nom d'hôte du pod. Quand c'est spécifié, ce dernier a la priorité sur le nom du pod. Par exemple, si un pod a un <code>hostname</code> ayant la valeur "<code>mon-hote</code>", son nom d'hôte sera "<code>mon-hote</code>".</p><p>La spécification du pod a également un champ optionnel <code>subdomain</code> qui peut être utilisé pour spécifier son sous-domaine. Par exemple, un pod avec une valeur "<code>foo</code>" du champ <code>hostname</code> et une valeur "<code>bar</code>" du champ <code>subdomain</code>, dans le namespace "<code>mon-namespace</code>", aura un nom de domaine (FQDN) "<code>foo.bar.mon-namespace.svc.cluster.local</code>".</p><p>Exemple :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Service<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>sous-domaine-par-default<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>selector</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>busybox<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>clusterIP</span>:<span style=color:#bbb> </span>None<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>ports</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>foo<span style=color:#bbb> </span><span style=color:#080;font-style:italic># En vrai, cette définition de port est à titre d&#39;exemple, nous n&#39;avons pas vraiment besoin de ports pour cette application.</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>port</span>:<span style=color:#bbb> </span><span style=color:#666>1234</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>targetPort</span>:<span style=color:#bbb> </span><span style=color:#666>1234</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:#00f;font-weight:700>---</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>busybox1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>labels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>busybox<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>hostname</span>:<span style=color:#bbb> </span>busybox-1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>subdomain</span>:<span style=color:#bbb> </span>sous-domaine-par-default<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>busybox:1.28<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>command</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- sleep<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- <span style=color:#b44>&#34;3600&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>busybox<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:#00f;font-weight:700>---</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>busybox2<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>labels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>busybox<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>hostname</span>:<span style=color:#bbb> </span>busybox-2<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>subdomain</span>:<span style=color:#bbb> </span>sous-domaine-par-default<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>busybox:1.28<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>command</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- sleep<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- <span style=color:#b44>&#34;3600&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>busybox<span style=color:#bbb>
</span></span></span></code></pre></div><p>Si un service sans en-tête (headless) est dans le même namespace que son pod et avec le même nom que le sous-domaine, le serveur KubeDNS du cluster renvoie également un enregistrement A pour le nom d’hôte (hostname) du pod.
Par exemple, si un pod dont le nom d’hôte est "<code> busybox-1</code>" et le sous-domaine est "<code>sous-domaine-par-default</code>", et un service sans en-tête nommé "<code>sous-domaine-par-default</code>" dans le même namespace, le pod verra son propre nom de domaine complet "<code>busybox-1.sous-domaine-par-default.mon-namespace.svc.cluster.local</code>". Le DNS sert un enregistrement A portant ce nom, et pointant vers l'adresse IP du pod. Les deux Pods "<code>busybox1</code>" et "<code> busybox2</code>" peuvent avoir leurs enregistrements A distincts.</p><p>L’objet Endpoints peut spécifier le <code>hostname</code> pour n’importe quelle adresse d'endpoint (noeud final), avec son adresse IP.</p><div class="alert alert-info note callout" role=alert><strong>Note:</strong> Etant donné que les enregistrements A ne sont pas créés pour les noms de pods, le <code>hostname</code> est requis pour la création de l'enregistrement A du pod. Un pod sans <code>hostname</code> mais avec <code>subdomain</code> (sous domaine) ne créera que l'enregistrement A pour le service sans en-tête (<code>sous-domaine-par-default.mon-namespace.svc.cluster.local</code>), pointant vers l'adresse IP du pod.</div><h3 id=politique-dns-du-pod>Politique DNS du Pod</h3><p>Les stratégies DNS peuvent être définies par pod. Actuellement, Kubernetes supporte des stratégies DNS qui sont spécifiques au pod. Ces politiques sont spécifiées dans le
Champ <code>dnsPolicy</code> de la spécification du pod.</p><ul><li>"<code>Default</code>" : le pod hérite de la configuration de résolution des noms du node (noeud) sur lequel ce même pod est en train de tourner.
Voir <a href=/docs/tasks/administer-cluster/dns-custom-nameservers/#inheriting-dns-from-the-node>discussion liée</a> pour plus de détails.</li><li>"<code>ClusterFirst</code>" : toute requête DNS ne correspondant pas au suffixe du domaine configuré dans le cluster, tel que "<code>www.kubernetes.io</code>", sera transmise au serveur en amont hérité du node (noeud). Les administrateurs du cluster peuvent configurer des serveurs DNS supplémentaires que ce soit des serveurs secondaires (locaux) ou des vrais serveurs récursifs en amont pour faire la résolution.
  Voir <a href=/docs/tasks/administer-cluster/dns-custom-nameservers/#impacts-on-pods>discussion liée</a> pour plus de détails sur la manière dont les requêtes DNS sont traitées dans ces cas.</li><li>"<code>ClusterFirstWithHostNet</code>" : pour les pods exécutés avec <code>hostNetwork</code>, vous devez explicitement définir sa politique DNS "<code>ClusterFirstWithHostNet</code>".</li><li>"<code>None</code>" : une nouvelle valeur optionnelle introduite dans Kubernetes v1.9 (Beta dans v1.10). Elle permet à un pod d’ignorer les configurations DNS de l’environnement Kubernetes. Ainsi, toutes les configurations DNS sont supposées être fournies dans le champ <code>dnsConfig</code> de la spécification du pod.
  Voir la sous-section <a href=#dns-config>Config DNS</a> ci-dessous.</li></ul><div class="alert alert-info note callout" role=alert><strong>Note:</strong> "Default" n'est pas la stratégie DNS par défaut. Si <code>dnsPolicy</code> n'est pas explicitement spécifié, <code>ClusterFirst</code> sera utilisé.</div><p>L’exemple ci-dessous montre un pod avec une stratégie DNS "<code>ClusterFirstWithHostNet</code>" car il a le champ <code>hostNetwork</code> défini à <code>true</code>.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>busybox<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>namespace</span>:<span style=color:#bbb> </span>default<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>busybox:1.28<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>command</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- sleep<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- <span style=color:#b44>&#34;3600&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>imagePullPolicy</span>:<span style=color:#bbb> </span>IfNotPresent<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>busybox<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>restartPolicy</span>:<span style=color:#bbb> </span>Always<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>hostNetwork</span>:<span style=color:#bbb> </span><span style=color:#a2f;font-weight:700>true</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>dnsPolicy</span>:<span style=color:#bbb> </span>ClusterFirstWithHostNet<span style=color:#bbb>
</span></span></span></code></pre></div><h3 id=configuration-dns-du-pod>Configuration DNS du pod</h3><p>Kubernetes v1.9 introduit une fonctionnalité Alpha (version beta de v1.10) qui permet aux utilisateurs d'avoir plus de contrôle sur les paramètres DNS d'un pod. Cette fonctionnalité est activée par défaut dans la version 1.10.
Pour activer cette fonctionnalité dans la version 1.9, l'administrateur du cluster doit activer la feature gate (porte de fonctionnalité) <code>CustomPodDNS</code> sur les serveurs apiserver et kubelet, par exemple, "<code>--feature-gates=CustomPodDNS=true,...</code>".
Lorsque la fonction est activée, les utilisateurs peuvent mettre le champ <code>dnsPolicy</code> d’un pod à "<code>None</code>" et ils peuvent rajouter un nouveau champ <code>dnsConfig</code> à la spécification du pod.</p><p>Le champ <code>dnsConfig</code> est facultatif et peut fonctionner avec toute configuration <code>dnsPolicy</code>.
Cependant, quand <code>dnsPolicy</code> du pod est réglé sur "<code>None</code>", le champ <code>dnsConfig</code> doit être explicitement spécifié.</p><p>Vous trouverez ci-dessous les propriétés qu'un utilisateur peut spécifier dans le champ <code>dnsConfig</code>:</p><ul><li><code>nameservers</code> : liste d'adresses IP qui seront utilisées comme serveurs DNS pour le Pod. Il peut y avoir au plus 3 adresses IP spécifiées. Quand le champ <code>dnsPolicy</code> du Pod est mis à "<code>None</code>", la liste doit contenir au moins une adresse IP, sinon cette propriété est facultative.
  Les serveurs listés seront combinés avec les nameservers (serveurs de noms) de base générés à partir de la stratégie DNS spécifiée, tout en supprimant les adresses en double.</li><li><code>searches</code> : liste des domaines de recherche DNS pour la recherche du nom d'hôte dans le pod.
  Cette propriété est facultative. Si elle est spécifiée, la liste fournie sera fusionnée avec les noms de domaine de recherche de base générés à partir de la stratégie DNS choisie.
  Les noms de domaine en double sont supprimés.
  Kubernetes permet au plus 6 domaines de recherche.</li><li><code>options</code>: une liste optionnelle d'objets où chaque objet peut avoir une propriété <code>name</code> (obligatoire) et une propriété <code>value</code> (facultatif). Le contenu de cette propriété sera fusionné avec les options générées à partir de la stratégie DNS spécifiée.
  Les entrées en double sont supprimées.</li></ul><p>Voici un exemple de Pod avec des configurations DNS personnalisées :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>namespace</span>:<span style=color:#bbb> </span>default<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>exemple-dns<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>test<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>nginx<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>dnsPolicy</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;None&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>dnsConfig</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>nameservers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- <span style=color:#666>1.2.3.4</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>searches</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- ns1.svc.cluster.local<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- mon.dns.search.suffix<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>options</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>ndots<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>value</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;2&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>edns0<span style=color:#bbb>
</span></span></span></code></pre></div><p>Lorsque le Pod ci-dessus est créé, le conteneur <code>test</code> obtient le contenu suivant dans son fichier <code>/etc/resolv.conf</code> :</p><pre tabindex=0><code>nameserver 1.2.3.4
search ns1.svc.cluster.local mon.dns.search.suffix
options ndots:2 edns0
</code></pre><p>Pour la configuration IPv6, le chemin de recherche et le serveur de noms doivent être configurés comme suit :</p><pre tabindex=0><code>$ kubectl exec -it exemple-dns -- cat /etc/resolv.conf
nameserver fd00:79:30::a
search default.svc.cluster.local svc.cluster.local cluster.local
options ndots:5
</code></pre><h2 id=a-suivre>A suivre</h2><p>Pour obtenir des recommendations sur l’administration des configurations DNS, consultez
<a href=/docs/tasks/administer-cluster/dns-custom-nameservers/>Configurer le service DNS</a></p></div><div class=td-content style=page-break-before:always><h1 id=pg-199bcc92443dbc9bed44819467d7eb75>3.5.4 - Ingress</h1><p>Un Ingress est un objet Kubernetes qui gère l'accès externe aux services dans un cluster, généralement du trafic HTTP.</p><p>Un Ingress peut fournir un équilibrage de charge, une terminaison TLS et un hébergement virtuel basé sur un nom.</p><h2 id=terminologie>Terminologie</h2><p>Par souci de clarté, ce guide définit les termes suivants :</p><ul><li>Nœud (Node) : une seule machine virtuelle ou physique dans un cluster Kubernetes.</li><li>Cluster : groupe de nœuds protégés par un pare-feu du trafic provenant d'Internet et constituant les principales ressources de calcul gérées par Kubernetes.</li><li>Routeur Edge : routeur appliquant la stratégie de pare-feu pour votre cluster. Il peut s’agir d’une passerelle gérée par un fournisseur de cloud ou d’un matériel physique.</li><li>Réseau de cluster : ensemble de liens, logiques ou physiques, facilitant la communication au sein d'un cluster selon le <a href=/docs/concepts/cluster-administration/networking/>modèle de réseau Kubernetes</a>.</li><li>Service : un Kubernetes <a href=/docs/concepts/services-networking/service/>Service</a> identifiant un ensemble de pods à l'aide de sélecteurs d'étiquettes. Sauf indication contraire, les services sont supposés avoir des adresses IP virtuelles routables uniquement dans le réseau du cluster.</li></ul><h2 id=qu-est-ce-qu-un-ingress>Qu'est-ce qu'un Ingress ?</h2><p>Ingress (ou une entrée réseau), ajouté à Kubernetes v1.1, expose les routes HTTP et HTTPS de l'extérieur du cluster à des
<a href=/docs/concepts/services-networking/service/ target=_blank>services</a> au sein du cluster.
Le routage du trafic est contrôlé par des règles définies sur la ressource Ingress.</p><pre tabindex=0><code class=language-none data-lang=none>    internet
        |
   [ Ingress ]
   --|-----|--
   [ Services ]
</code></pre><p>Un Ingress peut être configuré pour donner aux services des URLs accessibles de l'extérieur, un équilibrage du trafic de charge externe, la terminaison SSL/TLS et un hébergement virtuel basé sur le nom. Un <a href=/docs/concepts/services-networking/ingress-controllers>contrôleur d'Ingress</a> est responsable de l'exécution de l'Ingress, généralement avec un load-balancer (équilibreur de charge), bien qu'il puisse également configurer votre routeur périphérique ou des interfaces supplémentaires pour aider à gérer le trafic.</p><p>Un Ingress n'expose pas de ports ni de protocoles arbitraires. Exposer des services autres que HTTP et HTTPS à Internet généralement utilise un service de type <a href=/docs/concepts/services-networking/service/#nodeport>Service.Type=NodePort</a> ou <a href=/docs/concepts/services-networking/service/#loadbalancer>Service.Type=LoadBalancer</a>.</p><h2 id=conditions-préalables>Conditions préalables</h2><div style=margin-top:10px;margin-bottom:10px><b>FEATURE STATE:</b> <code>Kubernetes v1.1 [beta]</code></div><p>Avant de commencer à utiliser un Ingress, vous devez comprendre certaines choses. Un Ingress est une ressource en "version Beta".</p><div class="alert alert-info note callout" role=alert><strong>Note:</strong> Vous devez avoir un <a href=/docs/concepts/services-networking/ingress-controllers>contrôleur d'Ingress</a> pour lancer un Ingress. Seule, la création d'une ressource Ingress n'a aucun effet.</div><p>GCE/GKE (Google Cloud Engine / Google Kubernetes Engine) déploie un contrôleur d’Ingress sur le master (le maître de kubernetes). Revoir les <a href=https://github.com/kubernetes/ingress-gce/blob/master/BETA_LIMITATIONS.md#glbc-beta-limitations>limitations beta</a> de ce contrôleur si vous utilisez GCE/GKE.</p><p>Dans les environnements autres que GCE/GKE, vous devrez peut-être <a href=https://kubernetes.github.io/ingress-nginx/deploy/>déployer un contrôleur d'Ingress</a>. Il y a un certain nombre de <a href=/docs/concepts/services-networking/ingress-controllers>contrôleurs d'Ingress</a> parmi lesquels vous pouvez choisir.</p><h3 id=avant-de-commencer>Avant de commencer</h3><p>Dans l’idéal, tous les contrôleurs d’Ingress devraient correspondre à cette spécification. Cependant le fonctionnement est légèrement différent d'un contrôleur à un autre (en fonction de son implémentation).</p><div class="alert alert-info note callout" role=alert><strong>Note:</strong> Assurez-vous de consulter la documentation de votre contrôleur d’Ingress pour bien comprendre les mises en garde à prendre en compte au moment de le choisir.</div><h2 id=la-ressource-ingress>La ressource Ingress</h2><p>Exemple de ressource Ingress minimale :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>networking.k8s.io/v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Ingress<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>test-ingress<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>annotations</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>nginx.ingress.kubernetes.io/rewrite-target</span>:<span style=color:#bbb> </span>/<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>rules</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>http</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>paths</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- <span style=color:green;font-weight:700>path</span>:<span style=color:#bbb> </span>/testpath<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>pathType</span>:<span style=color:#bbb> </span>Prefix<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>backend</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>service</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>            </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>test<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>            </span><span style=color:green;font-weight:700>port</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>              </span><span style=color:green;font-weight:700>number</span>:<span style=color:#bbb> </span><span style=color:#666>80</span><span style=color:#bbb>
</span></span></span></code></pre></div><p>Comme pour toutes les autres ressources Kubernetes, un Ingress (une entrée) a besoin des champs <code>apiVersion</code>, <code>kind</code> et <code>metadata</code>.
 Pour des informations générales sur l'utilisation des fichiers de configuration, voir <a href=/docs/tasks/run-application/run-stateless-application-deployment/>déployer des applications</a>, <a href=/docs/tasks/configure-pod-container/configure-pod-configmap/>configurer des conteneurs</a>, <a href=/docs/concepts/cluster-administration/manage-deployment/>gestion des ressources</a>.
 Ingress utilise fréquemment des annotations pour configurer certaines options en fonction du contrôleur Ingress, dont un exemple
 est l'annotation <a href=https://github.com/kubernetes/ingress-nginx/blob/master/docs/examples/rewrite/README.md>rewrite-target</a>.
 Différents <a href=/docs/concepts/services-networking/ingress-controllers>Ingress controller</a> prennent en charge différentes annotations. Consultez la documentation du contrôleur Ingress de votre choix pour savoir quelles annotations sont prises en charge.</p><p>La <a href=https://github.com/kubernetes/community/blob/master/contributors/devel/sig-architecture/api-conventions.md#spec-and-status>spécification de la ressource Ingress</a> dispose de toutes les informations nécessaires pour configurer un loadbalancer ou un serveur proxy. Plus important encore, il
contient une liste de règles d'appariement de toutes les demandes entrantes. La ressource Ingress ne supporte que les règles pour diriger le trafic HTTP.</p><h3 id=ingress-rules>Ingress rules</h3><p>Chaque règle http contient les informations suivantes :</p><ul><li>Un hôte optionnel. Dans cet exemple, aucun hôte n'est spécifié. La règle s'applique donc à tous les appels entrants.
  Le trafic HTTP via l'adresse IP est spécifié. Si un hôte est fourni (par exemple,
  foo.bar.com), les règles s’appliquent à cet hôte.</li><li>une liste de chemins (par exemple, /testpath), chacun étant associé à un backend associé défini par un <code>serviceName</code> et <code>servicePort</code>. L’hôte et le chemin doivent correspondre au contenu d’une demande entrante avant que le load-balancer ne dirige le trafic vers le service référencé.</li><li>Un backend est une combinaison de noms de services et de ports, comme décrit dans
<a href=/docs/concepts/services-networking/service/>services doc</a>. Les requêtes HTTP (et HTTPS) envoyées à l'Ingress correspondant à l'hôte et au chemin de la règle seront envoyées au backend indiqué.</li></ul><p>Un backend par défaut est souvent configuré dans un contrôleur d’Ingress qui traite toutes les demandes qui ne correspondent à aucun chemin dans la spécification.</p><h3 id=backend-par-défaut>Backend par défaut</h3><p>Un Ingress sans règles envoie tout le trafic à un seul backend par défaut. Le backend par défaut est généralement une option de configuration du <a href=/docs/concepts/services-networking/ingress-controllers>Contrôleur d'ingress</a> et n'est pas spécifié dans vos ressources Ingress.</p><p>Si aucun des hôtes ou chemins ne correspond à la demande HTTP dans les objets Ingress, le trafic est routé vers votre backend par défaut.</p><h2 id=types-d-ingress>Types d'Ingress</h2><h3 id=ingress-pour-service-unique>Ingress pour service unique</h3><p>Il existe des concepts Kubernetes qui vous permettent d’exposer un seul service.
(voir <a href=#alternatives>alternatives</a>). Vous pouvez également le faire avec un Ingress en spécifiant un <em>backend par défaut</em> sans règles.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>networking.k8s.io/v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Ingress<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>test-ingress<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>defaultBackend</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>service</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>testsvc<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>port</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>number</span>:<span style=color:#bbb> </span><span style=color:#666>80</span><span style=color:#bbb>
</span></span></span></code></pre></div><p>Si vous le créez en utilisant <code>kubectl create -f</code>, vous devriez voir :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get ingress test-ingress
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>NAME           HOSTS     ADDRESS           PORTS     AGE
</span></span><span style=display:flex><span>test-ingress   *         107.178.254.228   <span style=color:#666>80</span>        59s
</span></span></code></pre></div><p>Où <code>107.178.254.228</code> est l’adresse IP allouée par le contrôleur d’Ingress pour satisfaire cette entrée.</p><div class="alert alert-info note callout" role=alert><strong>Note:</strong> Les contrôleurs d'Ingress et les load-balancers peuvent prendre une minute ou deux pour allouer une adresse IP.
Jusque-là, vous verrez souvent l’adresse listée sous la forme <code>&lt;pending></code> (en attente).</div><h3 id=fanout-simple>Fanout simple</h3><p>Une configuration de type fanout achemine le trafic d'une adresse IP unique vers plusieurs services, en se basant sur l'URI HTTP demandée. Une entrée vous permet de garder le nombre de loadbalancers au minimum. Par exemple, une configuration comme :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>foo.bar.com -&gt; 178.91.123.132 -&gt; / foo    service1:4200
</span></span><span style=display:flex><span>                                 / bar    service2:8080
</span></span></code></pre></div><p>ceci nécessitera un Ingress défini comme suit :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>networking.k8s.io/v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Ingress<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>simple-fanout-example<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>annotations</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>nginx.ingress.kubernetes.io/rewrite-target</span>:<span style=color:#bbb> </span>/<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>rules</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>host</span>:<span style=color:#bbb> </span>foo.bar.com<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>http</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>paths</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- <span style=color:green;font-weight:700>path</span>:<span style=color:#bbb> </span>/foo<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>pathType</span>:<span style=color:#bbb> </span>Prefix<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>backend</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>service</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>            </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>service1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>            </span><span style=color:green;font-weight:700>port</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>              </span><span style=color:green;font-weight:700>number</span>:<span style=color:#bbb> </span><span style=color:#666>4200</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- <span style=color:green;font-weight:700>path</span>:<span style=color:#bbb> </span>/bar<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>pathType</span>:<span style=color:#bbb> </span>Prefix<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>backend</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>service</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>            </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>service2<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>            </span><span style=color:green;font-weight:700>port</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>              </span><span style=color:green;font-weight:700>number</span>:<span style=color:#bbb> </span><span style=color:#666>8080</span><span style=color:#bbb>
</span></span></span></code></pre></div><p>Lorsque vous créez l'ingress avec <code>kubectl create -f</code>:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl describe ingress simple-fanout-example
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>Name:             simple-fanout-example
</span></span><span style=display:flex><span>Namespace:        default
</span></span><span style=display:flex><span>Address:          178.91.123.132
</span></span><span style=display:flex><span>Default backend:  default-http-backend:80 <span style=color:#666>(</span>10.8.2.3:8080<span style=color:#666>)</span>
</span></span><span style=display:flex><span>Rules:
</span></span><span style=display:flex><span>  Host         Path  Backends
</span></span><span style=display:flex><span>  ----         ----  --------
</span></span><span style=display:flex><span>  foo.bar.com
</span></span><span style=display:flex><span>               /foo   service1:4200 <span style=color:#666>(</span>10.8.0.90:4200<span style=color:#666>)</span>
</span></span><span style=display:flex><span>               /bar   service2:8080 <span style=color:#666>(</span>10.8.0.91:8080<span style=color:#666>)</span>
</span></span><span style=display:flex><span>Annotations:
</span></span><span style=display:flex><span>  nginx.ingress.kubernetes.io/rewrite-target:  /
</span></span><span style=display:flex><span>Events:
</span></span><span style=display:flex><span>  Type     Reason  Age                From                     Message
</span></span><span style=display:flex><span>  ----     ------  ----               ----                     -------
</span></span><span style=display:flex><span>  Normal   ADD     22s                loadbalancer-controller  default/test
</span></span></code></pre></div><p>Le contrôleur d’Ingress fournit une implémentation spécifique aux load-balancers qui satisfait l'Ingress, tant que les services (<code>s1</code>, <code>s2</code>) existent.
Lorsque cela est fait, vous pouvez voir l’adresse du load-balancer sur le champ d'adresse.</p><div class="alert alert-info note callout" role=alert><strong>Note:</strong> En fonction du <a href=/docs/concepts/services-networking/ingress-controllers>Contrôleur d'ingress</a> que vous utilisez, vous devrez peut-être
créer un backend http par défaut <a href=/docs/concepts/services-networking/service/>Service</a>.</div><h3 id=hébergement-virtuel-basé-sur-le-nom>Hébergement virtuel basé sur le nom</h3><p>Les hôtes virtuels basés sur des noms prennent en charge le routage du trafic HTTP vers plusieurs noms d'hôte basés sur la même adresse IP.</p><pre tabindex=0><code class=language-none data-lang=none>foo.bar.com --|                 |-&gt; foo.bar.com s1:80
              | 178.91.123.132  |
bar.foo.com --|                 |-&gt; bar.foo.com s2:80
</code></pre><p>L’Ingress suivant indique au load-balancer de router les requêtes en fonction de <a href=https://tools.ietf.org/html/rfc7230#section-5.4>En-tête du hôte</a>.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>networking.k8s.io/v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Ingress<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>name-virtual-host-ingress<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>rules</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>host</span>:<span style=color:#bbb> </span>foo.bar.com<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>http</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>paths</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- <span style=color:green;font-weight:700>path</span>:<span style=color:#bbb> </span>/<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>pathType</span>:<span style=color:#bbb> </span>Prefix<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>backend</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>service</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>            </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>service1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>            </span><span style=color:green;font-weight:700>port</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>              </span><span style=color:green;font-weight:700>number</span>:<span style=color:#bbb> </span><span style=color:#666>80</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>host</span>:<span style=color:#bbb> </span>bar.foo.com<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>http</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>paths</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- <span style=color:green;font-weight:700>path</span>:<span style=color:#bbb> </span>/<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>pathType</span>:<span style=color:#bbb> </span>Prefix<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>backend</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>service</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>            </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>service2<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>            </span><span style=color:green;font-weight:700>port</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>              </span><span style=color:green;font-weight:700>number</span>:<span style=color:#bbb> </span><span style=color:#666>80</span><span style=color:#bbb>
</span></span></span></code></pre></div><p>Si vous créez une ressource Ingress sans aucun hôte défini dans les règles, tout trafic Web à destination de l'adresse IP de votre contrôleur d'Ingress peut être mis en correspondance sans qu'un hôte virtuel basé sur le nom ne soit requis. Par exemple, la ressource Ingress suivante acheminera le trafic demandé pour <code>first.bar.com</code> au <code>service1</code>, <code>second.foo.com</code> au <code>service2</code>, et à tout trafic à l'adresse IP sans nom d'hôte défini dans la demande (c'est-à-dire sans en-tête de requête présenté) au <code>service3</code>.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>networking.k8s.io/v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Ingress<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>name-virtual-host-ingress<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>rules</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>host</span>:<span style=color:#bbb> </span>first.bar.com<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>http</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>paths</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- <span style=color:green;font-weight:700>path</span>:<span style=color:#bbb> </span>/<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>pathType</span>:<span style=color:#bbb> </span>Prefix<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>backend</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>service</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>            </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>service1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>            </span><span style=color:green;font-weight:700>port</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>              </span><span style=color:green;font-weight:700>number</span>:<span style=color:#bbb> </span><span style=color:#666>80</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>host</span>:<span style=color:#bbb> </span>second.foo.com<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>http</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>paths</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- <span style=color:green;font-weight:700>path</span>:<span style=color:#bbb> </span>/<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>pathType</span>:<span style=color:#bbb> </span>Prefix<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>backend</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>service</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>            </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>service2<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>            </span><span style=color:green;font-weight:700>port</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>              </span><span style=color:green;font-weight:700>number</span>:<span style=color:#bbb> </span><span style=color:#666>80</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>http</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>paths</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- <span style=color:green;font-weight:700>path</span>:<span style=color:#bbb> </span>/<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>pathType</span>:<span style=color:#bbb> </span>Prefix<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>backend</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>service</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>            </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>service3<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>            </span><span style=color:green;font-weight:700>port</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>              </span><span style=color:green;font-weight:700>number</span>:<span style=color:#bbb> </span><span style=color:#666>80</span><span style=color:#bbb>
</span></span></span></code></pre></div><h3 id=tls>TLS</h3><p>Vous pouvez sécuriser un Ingress en définissant un <a href=/docs/concepts/configuration/secret>secret</a> qui contient une clé privée et un certificat TLS. Actuellement, l'Ingress prend seulement en charge l'unique port TLS, 443, et suppose une terminaison TLS. Si la section de configuration TLS dans un Ingress spécifie différents hôtes, ils seront multiplexés sur le même port en fonction du nom d’hôte spécifié via l'extension SNI TLS (à condition que le contrôleur d’Ingress prenne en charge SNI). Le secret de TLS doit contenir les clés <code>tls.crt</code> et <code>tls.key</code> contenant le certificat et clé privée à utiliser pour TLS, par exemple :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>data</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>tls.crt</span>:<span style=color:#bbb> </span>base64 encoded cert<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>tls.key</span>:<span style=color:#bbb> </span>base64 encoded key<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Secret<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>testsecret-tls<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>namespace</span>:<span style=color:#bbb> </span>default<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>type</span>:<span style=color:#bbb> </span>kubernetes.io/tls<span style=color:#bbb>
</span></span></span></code></pre></div><p>Référencer ce secret dans un Ingress indiquera au contrôleur d'Ingress de sécuriser le canal du client au load-balancer à l'aide de TLS. Vous devez vous assurer que le secret TLS que vous avez créé provenait d'un certificat contenant un Common Name (CN), aussi appelé nom de domaine pleinement qualifié (FQDN), pour <code>https-example.foo.com</code>.</p><div class=highlight><div class=copy-code-icon style=text-align:right><a href=https://raw.githubusercontent.com/kubernetes/website/main/content/fr/examples/service/networking/tls-example-ingress.yaml download=service/networking/tls-example-ingress.yaml><code>service/networking/tls-example-ingress.yaml</code></a>
<img src=/images/copycode.svg style=max-height:24px;cursor:pointer onclick='copyCode("service-networking-tls-example-ingress-yaml")' title="Copy service/networking/tls-example-ingress.yaml to clipboard"></img></div><div class=includecode id=service-networking-tls-example-ingress-yaml><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>networking.k8s.io/v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Ingress<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>tls-example-ingress<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>tls</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>hosts</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- https-example.foo.com<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>secretName</span>:<span style=color:#bbb> </span>testsecret-tls<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>rules</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>host</span>:<span style=color:#bbb> </span>https-example.foo.com<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>http</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>paths</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- <span style=color:green;font-weight:700>path</span>:<span style=color:#bbb> </span>/<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>pathType</span>:<span style=color:#bbb> </span>Prefix<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>backend</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>service</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>            </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>service1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>            </span><span style=color:green;font-weight:700>port</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>              </span><span style=color:green;font-weight:700>number</span>:<span style=color:#bbb> </span><span style=color:#666>80</span><span style=color:#bbb>
</span></span></span></code></pre></div></div></div><div class="alert alert-info note callout" role=alert><strong>Note:</strong> Les fonctionnalités TLS prisent en charge par les différents contrôleurs peuvent être différentes. Veuillez vous référer à la documentation sur
<a href=https://git.k8s.io/ingress-nginx/README.md#https>nginx</a>,
<a href=https://git.k8s.io/ingress-gce/README.md#frontend-https>GCE</a>,
ou tout autre contrôleur d’Ingress spécifique à la plate-forme pour comprendre le fonctionnement de TLS dans votre environnement.</div><h3 id=l-équilibrage-de-charge>L'équilibrage de charge</h3><p>Un contrôleur d’Ingress est démarré avec certains paramètres de politique d’équilibrage de charge
qui s'appliquent à toutes les entrées, tels que l'algorithme d'équilibrage de la charge, le régime de pondérations des backends, et d'autres.
Les concepts un peu plus avancés d'équilibrage de charge (p. ex. sessions persistantes, pondérations dynamiques) ne sont pas encore exposés pour l'Ingress. Vous pouvez toujours obtenir ces fonctionnalités via le <a href=https://github.com/kubernetes/ingress-nginx>service loadbalancer</a>.</p><p>Il est également intéressant de noter que même si les health checks (contrôles de santé) ne sont pas exposés directement via l'Ingress, il existe des concepts parallèles dans Kubernetes, tels que <a href=/docs/tasks/configure-pod-container/configure-liveness-readiness-probes/>readiness probes</a> qui vous permettent d'obtenir le même résultat final. Veuillez consulter les documents spécifiques au contrôleur pour voir comment il gère les health checks. (<a href=https://git.k8s.io/ingress-nginx/README.md>nginx</a>,<a href=https://git.k8s.io/ingress-gce/README.md#health-checks>GCE</a>).</p><h2 id=mise-à-jour-d-un-ingress>Mise à jour d'un Ingress</h2><p>Pour mettre à jour un Ingress existant afin d'ajouter un nouvel hôte, vous pouvez le mettre à jour en modifiant la ressource :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl describe ingress <span style=color:#a2f>test</span>
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>Name:             <span style=color:#a2f>test</span>
</span></span><span style=display:flex><span>Namespace:        default
</span></span><span style=display:flex><span>Address:          178.91.123.132
</span></span><span style=display:flex><span>Default backend:  default-http-backend:80 <span style=color:#666>(</span>10.8.2.3:8080<span style=color:#666>)</span>
</span></span><span style=display:flex><span>Rules:
</span></span><span style=display:flex><span>  Host         Path  Backends
</span></span><span style=display:flex><span>  ----         ----  --------
</span></span><span style=display:flex><span>  foo.bar.com
</span></span><span style=display:flex><span>               /foo   s1:80 <span style=color:#666>(</span>10.8.0.90:80<span style=color:#666>)</span>
</span></span><span style=display:flex><span>Annotations:
</span></span><span style=display:flex><span>  nginx.ingress.kubernetes.io/rewrite-target:  /
</span></span><span style=display:flex><span>Events:
</span></span><span style=display:flex><span>  Type     Reason  Age                From                     Message
</span></span><span style=display:flex><span>  ----     ------  ----               ----                     -------
</span></span><span style=display:flex><span>  Normal   ADD     35s                loadbalancer-controller  default/test
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl edit ingress <span style=color:#a2f>test</span>
</span></span></code></pre></div><p>Cela devrait faire apparaître un éditeur avec le yaml existant, modifiez-le pour inclure le nouvel hôte :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>rules</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>host</span>:<span style=color:#bbb> </span>foo.bar.com<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>http</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>paths</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- <span style=color:green;font-weight:700>backend</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>service</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>            </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>s1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>            </span><span style=color:green;font-weight:700>port</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>              </span><span style=color:green;font-weight:700>number</span>:<span style=color:#bbb> </span><span style=color:#666>80</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>path</span>:<span style=color:#bbb> </span>/foo<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>pathType</span>:<span style=color:#bbb> </span>Prefix<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>host</span>:<span style=color:#bbb> </span>bar.baz.com<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>http</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>paths</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- <span style=color:green;font-weight:700>backend</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>service</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>            </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>s2<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>            </span><span style=color:green;font-weight:700>port</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>              </span><span style=color:green;font-weight:700>number</span>:<span style=color:#bbb> </span><span style=color:#666>80</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>path</span>:<span style=color:#bbb> </span>/foo<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>pathType</span>:<span style=color:#bbb> </span>Prefix<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span>..<span style=color:#bbb>
</span></span></span></code></pre></div><p>L'enregistrement du yaml mettra à jour la ressource dans le serveur d'API, ce qui devrait indiquer au contrôleur d'Ingress de reconfigurer le load-balancer.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl describe ingress <span style=color:#a2f>test</span>
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>Name:             <span style=color:#a2f>test</span>
</span></span><span style=display:flex><span>Namespace:        default
</span></span><span style=display:flex><span>Address:          178.91.123.132
</span></span><span style=display:flex><span>Default backend:  default-http-backend:80 <span style=color:#666>(</span>10.8.2.3:8080<span style=color:#666>)</span>
</span></span><span style=display:flex><span>Rules:
</span></span><span style=display:flex><span>  Host         Path  Backends
</span></span><span style=display:flex><span>  ----         ----  --------
</span></span><span style=display:flex><span>  foo.bar.com
</span></span><span style=display:flex><span>               /foo   s1:80 <span style=color:#666>(</span>10.8.0.90:80<span style=color:#666>)</span>
</span></span><span style=display:flex><span>  bar.baz.com
</span></span><span style=display:flex><span>               /foo   s2:80 <span style=color:#666>(</span>10.8.0.91:80<span style=color:#666>)</span>
</span></span><span style=display:flex><span>Annotations:
</span></span><span style=display:flex><span>  nginx.ingress.kubernetes.io/rewrite-target:  /
</span></span><span style=display:flex><span>Events:
</span></span><span style=display:flex><span>  Type     Reason  Age                From                     Message
</span></span><span style=display:flex><span>  ----     ------  ----               ----                     -------
</span></span><span style=display:flex><span>  Normal   ADD     45s                loadbalancer-controller  default/test
</span></span></code></pre></div><p>Vous pouvez obtenir le même résultat en appelant <code>kubectl replace -f</code> sur un fichier Ingress yaml modifié.</p><h2 id=échec-dans-les-zones-de-disponibilité>Échec dans les zones de disponibilité</h2><p>Les techniques permettant de répartir le trafic sur plusieurs domaines de défaillance diffèrent d'un fournisseur de cloud à l'autre.
Veuillez consulter la documentation du <a href=/docs/concepts/services-networking/ingress-controllers>Contrôleur d'ingress</a> pour plus de détails. Vous pouvez également vous référer à la <a href=/docs/concepts/cluster-administration/federation/>documentation de la fédération</a> pour plus d'informations sur le déploiement d'Ingress dans un cluster fédéré.</p><h2 id=travail-futur>Travail futur</h2><p>Suivez <a href=https://github.com/kubernetes/community/tree/master/sig-network>SIG network</a> (groupe d'intérêt spécial Réseau) pour plus de détails sur l'évolution de l'Ingress et des ressources associées. Vous pouvez également suivre le <a href=https://github.com/kubernetes/ingress/tree/master>Dépôt Ingress</a> pour plus de détails sur l'évolution des différents contrôleurs d’Ingress.</p><h2 id=alternatives>Alternatives</h2><p>Vous pouvez exposer un service de plusieurs manières sans impliquer directement la ressource Ingress :</p><ul><li>Utilisez <a href=/docs/concepts/services-networking/service/#loadbalancer>Service.Type=LoadBalancer</a></li><li>Utilisez <a href=/docs/concepts/services-networking/service/#nodeport>Service.Type=NodePort</a></li><li>Utilisez un <a href=https://git.k8s.io/contrib/for-demos/proxy-to-service>Proxy du port</a></li></ul><h2 id=a-suivre>A suivre</h2><ul><li><a href=/docs/tasks/access-application-cluster/ingress-minikube>Configurer Ingress sur Minikube avec le contrôleur NGINX</a></li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-f018f568c6723865753f150c3c59bdda>3.6 - Stockage</h1></div><div class=td-content><h1 id=pg-27795584640a03bd2024f1fe3b3ab754>3.6.1 - Volumes</h1><p>Les fichiers sur disque dans un conteneur sont éphémères, ce qui présente des problèmes pour
des applications non-triviales lorsqu'elles s'exécutent dans des conteneurs. Premièrement, lorsqu'un
conteneur plante, kubelet va le redémarrer mais les fichiers seront perdus - le conteneur démarre
avec un état propre. Deuxièmement, lorsque plusieurs conteneurs s'exécutent ensemble dans un <code>Pod</code>,
il est souvent nécessaire de partager des fichiers entre ces conteneurs. L'abstraction Kubernetes
<code>Volume</code> résout ces deux problèmes.</p><p>Une connaissance des <a href=/fr/docs/concepts/workloads/pods/pod>Pods</a> est suggérée.</p><h2 id=contexte>Contexte</h2><p>Docker a également un concept de <a href=https://docs.docker.com/storage/>volumes</a>, bien qu'il
soit, dans une certaine mesure, plus relâché et moins géré.
Avec Docker, un volume est simplement un dossier sur le disque ou dans un autre conteneur.
Les durées de vie ne sont pas gérées et, jusqu'à très récemment, seuls les volumes supportés par un disque local l'étaient.
Docker fournit maintenant des pilotes de volume, mais la fonctionnalité est très limitée pour le moment (par exemple, à partir de Docker 1.7, seulement un pilote de volume est autorisé par conteneur et il n'est pas possible de passer des paramètres aux volumes).</p><p>Un volume Kubernetes, en revanche, a une durée de vie explicite - la même que le Pod qui l'inclut.
Par conséquent, un volume survit aux conteneurs qui s'exécutent à l'intérieur du Pod et les données sont préservées lorsque le conteneur redémarre.
Bien sûr, lorsqu'un Pod cesse d'exister, le volume va également cesser d'exister.
Peut-être plus important encore, Kubernetes supporte de nombreux types de volumes et un Pod peut en utiliser plusieurs simultanément.</p><p>À la base, un volume est juste un dossier, contenant possiblement des données, qui est accessible aux conteneurs dans un Pod. La manière dont ce dossier est créé, le support qui le sauvegarde et son contenu sont déterminés par le type de volume utilisé.</p><p>Pour utiliser un volume, un Pod spécifie les volumes à fournir au Pod (le champ <code>.spec.volumes</code>)
et où les monter dans les conteneurs (le champ <code>.spec.containers.volumeMounts</code>).</p><p>Un processus dans un conteneur a une vue système de fichiers composée de son image et de ses volumes Docker.
L'<a href=https://docs.docker.com/userguide/dockerimages/>image Docker</a> est à la racine de la hiérarchie du système de fichiers et tous les volumes sont montés sur les chemins spécifiés dans l'image.
Les volumes ne peuvent pas être montés sur d'autres volumes ou avoir des liens physiques vers d'autres volumes.
Chaque conteneur dans le Pod doit spécifier indépendamment où monter chaque volume.</p><h2 id=types-de-volumes>Types de Volumes</h2><p>Kubernetes supporte plusieurs types de Volumes:</p><ul><li><a href=#awselasticblockstore>awsElasticBlockStore</a></li><li><a href=#azuredisk>azureDisk</a></li><li><a href=#azurefile>azureFile</a></li><li><a href=#cephfs>cephfs</a></li><li><a href=#cinder>cinder</a></li><li><a href=#configmap>configMap</a></li><li><a href=#csi>csi</a></li><li><a href=#downwardapi>downwardAPI</a></li><li><a href=#emptydir>emptyDir</a></li><li><a href=#fc>fc (fibre channel)</a></li><li><a href=#flexVolume>flexVolume</a></li><li><a href=#flocker>flocker</a></li><li><a href=#gcepersistentdisk>gcePersistentDisk</a></li><li><a href=#gitrepo>gitRepo (deprecated)</a></li><li><a href=#glusterfs>glusterfs</a></li><li><a href=#hostpath>hostPath</a></li><li><a href=#iscsi>iscsi</a></li><li><a href=#local>local</a></li><li><a href=#nfs>nfs</a></li><li><a href=#persistentvolumeclaim>persistentVolumeClaim</a></li><li><a href=#projected>projected</a></li><li><a href=#portworxvolume>portworxVolume</a></li><li><a href=#quobyte>quobyte</a></li><li><a href=#rbd>rbd</a></li><li><a href=#scaleio>scaleIO</a></li><li><a href=#secret>secret</a></li><li><a href=#storageos>storageos</a></li><li><a href=#vspherevolume>vsphereVolume</a></li></ul><p>Toute contribution supplémentaire est la bienvenue.</p><h3 id=awselasticblockstore>awsElasticBlockStore</h3><p>Un type de volume <code>awsElasticBlockStore</code> monte un <a href=http://aws.amazon.com/ebs/>Volume EBS</a> d'Amazon Web Services (AWS) dans un Pod.
À la différence de <code>emptyDir</code>, qui est écrasé lorsqu'un Pod est supprimé, le contenu d'un volume EBS
est préservé et le volume est seulement démonté. Cela signifie qu'un volume EBS peut être prérempli avec des données et que les données peuvent être transmises entre les Pods.</p><div class="alert alert-warning caution callout" role=alert><strong>Avertissement:</strong> Vous devez créer un volume EBS avec la commande <code>aws ec2 create-volume</code> ou l'API AWS avant de pouvoir l'utiliser.</div><p>Des restrictions existent lorsque l'on utilise un volume <code>awsElasticBlockStore</code> :</p><ul><li>les nœuds dans lesquels les Pods s'exécutent doivent être des instances AWS EC2</li><li>ces instances doivent être dans la même région et la même zone de disponibilité que le volume EBS</li><li>EBS supporte uniquement le montage d'un volume par une seule instance EC2</li></ul><h4 id=création-d-un-volume-ebs>Création d'un volume EBS</h4><p>Avant que vous puissiez utiliser un volume EBS dans un Pod, vous devez le créer.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>aws ec2 create-volume --availability-zone<span style=color:#666>=</span>eu-west-1a --size<span style=color:#666>=</span><span style=color:#666>10</span> --volume-type<span style=color:#666>=</span>gp2
</span></span></code></pre></div><p>Assurez-vous que la zone correspond à la zone de votre grappe de serveurs (cluster).
(Et vérifiez aussi que la taille et le type du volume EBS conviennent à votre utilisation!)</p><h4 id=exemple-de-configuration-aws-ebs>Exemple de configuration AWS EBS</h4><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>test-ebs<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>k8s.gcr.io/test-webserver<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>test-container<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>volumeMounts</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:green;font-weight:700>mountPath</span>:<span style=color:#bbb> </span>/test-ebs<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>test-volume<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>volumes</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>test-volume<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:#080;font-style:italic># Ce volume AWS EBS doit déjà exister.</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>awsElasticBlockStore</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>volumeID</span>:<span style=color:#bbb> </span>&lt;volume-id&gt;<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>fsType</span>:<span style=color:#bbb> </span>ext4<span style=color:#bbb>
</span></span></span></code></pre></div><h4 id=migration-csi>Migration CSI</h4><div style=margin-top:10px;margin-bottom:10px><b>FEATURE STATE:</b> <code>Kubernetes v1.14 [alpha]</code></div><p>La fonctionnalité de migration CSI pour awsElasticBlockStore, lorsque activée, fixe toutes les opérations de plugin depuis le plugin "in-tree" vers le pilote de l'interface CSI (Container Storage Interface) <code>ebs.csi.aws.com</code>.
Afin d'utiliser cette fonctionnalité, le <a href=https://github.com/kubernetes-sigs/aws-ebs-csi-driver>Pilote AWS EBS CSI</a> doit être installé dans le cluster et les fonctionnalités Alpha <code>CSIMigration</code> et <code>CSIMigrationAWS</code> doivent être activées.</p><h3 id=azuredisk>azureDisk</h3><p>Un type de volume <code>azureDisk</code> est utilisé pour monter un disque de données (<a href=https://azure.microsoft.com/en-us/documentation/articles/virtual-machines-linux-about-disks-vhds/>Data Disk</a>) dans un Pod.</p><p>Plus de détails sont disponibles <a href=https://github.com/kubernetes/examples/tree/master/staging/volumes/azure_disk/README.md>ici</a>.</p><h4 id=migration-csi-1>Migration CSI</h4><div style=margin-top:10px;margin-bottom:10px><b>FEATURE STATE:</b> <code>Kubernetes v1.15 [alpha]</code></div><p>La fonctionnalité de migration CSI pour azureDisk, lorsque activée, fixe toutes les opérations de plugin depuis le plugin "in-tree" vers le pilote de l'interface CSI (Container Storage Interface) <code>disk.csi.azure.com</code>.
Afin d'utiliser cette fonctionnalité, le <a href=https://github.com/kubernetes-sigs/azuredisk-csi-driver>Pilote Azure Disk CSI</a> doit être installé dans le cluster et les fonctionnalités Alpha <code>CSIMigration</code> et <code>CSIMigrationAzureDisk</code> doivent être activées.</p><h3 id=azurefile>azureFile</h3><p>Un type de volume <code>azureFile</code> est utilisé pour monter un volume de fichier Microsoft Azure (SMB 2.1 et 3.0) dans un Pod.</p><p>Plus de détails sont disponibles <a href=https://github.com/kubernetes/examples/tree/master/staging/volumes/azure_file/README.md>ici</a>.</p><h4 id=migration-csi-2>Migration CSI</h4><div style=margin-top:10px;margin-bottom:10px><b>FEATURE STATE:</b> <code>Kubernetes v1.15 [alpha]</code></div><p>La fonctionnalité de migration CSI pour azureFile, lorsque activée, fixe toutes les opérations de plugin depuis le plugin "in-tree" vers le pilote de l'interface CSI (Container Storage Interface) <code>file.csi.azure.com</code>.
Afin d'utiliser cette fonctionnalité, le <a href=https://github.com/kubernetes-sigs/azurefile-csi-driver>Pilote Azure File CSI</a> doit être installé dans le cluster et les fonctionnalités Alpha <code>CSIMigration</code> et <code>CSIMigrationAzureFile</code> doivent être activées.</p><h3 id=cephfs>cephfs</h3><p>Un volume <code>cephfs</code> permet de monter un volume CephFS existant dans un Pod.
Contrairement à <code>emptyDir</code>, qui est écrasé quand un Pod est supprimé, le contenu d'un volume <code>cephfs</code> est préservé et le volume est simplement démonté.
Cela signifie qu'un volume CephFS peut être prérempli avec des données et ces données peuvent être transmises entre les Pods.
CephFS peut être monté plusieurs fois en écriture simultanément.</p><div class="alert alert-warning caution callout" role=alert><strong>Avertissement:</strong> Vous devez exécuter votre propre serveur Ceph avec le partage exporté avant de pouvoir l'utiliser.</div><p>Voir <a href=https://github.com/kubernetes/examples/tree/master/volumes/cephfs/>l'exemple CephFS</a> pour plus de détails.</p><h3 id=cinder>cinder</h3><div class="alert alert-info note callout" role=alert><strong>Note:</strong> prérequis : Kubernetes avec le fournisseur infonuagique OpenStack (OpenStack Cloud Provider) configuré.
Pour la configuration cloudprovider, se référer à <a href=https://kubernetes.io/docs/concepts/cluster-administration/cloud-providers/#openstack>cloud provider openstack</a>.</div><p><code>cinder</code> est utilisé pour monter un volume Cinder OpenStack dans un Pod.</p><h4 id=exemple-de-configuration-d-un-volume-cinder>Exemple de configuration d'un volume Cinder</h4><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>test-cinder<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>k8s.gcr.io/test-webserver<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>test-cinder-container<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>volumeMounts</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:green;font-weight:700>mountPath</span>:<span style=color:#bbb> </span>/test-cinder<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>test-volume<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>volumes</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>test-volume<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:#080;font-style:italic># Ce volume OpenStack doit déjà exister.</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>cinder</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>volumeID</span>:<span style=color:#bbb> </span>&lt;volume-id&gt;<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>fsType</span>:<span style=color:#bbb> </span>ext4<span style=color:#bbb>
</span></span></span></code></pre></div><h4 id=migration-csi-3>Migration CSI</h4><div style=margin-top:10px;margin-bottom:10px><b>FEATURE STATE:</b> <code>Kubernetes v1.14 [alpha]</code></div><p>La fonctionnalité de migration CSI pour Cinder, lorsque activée, fixe toutes les opérations de plugin depuis le plugin "in-tree" vers le pilote de l'interface CSI (Container Storage Interface) <code>cinder.csi.openstack.org</code>.
Afin d'utiliser cette fonctionnalité, le <a href=https://github.com/kubernetes/cloud-provider-openstack/blob/master/docs/using-cinder-csi-plugin.md>Pilote Cinder CSI</a> doit être installé dans le cluster et les fonctionnalités Alpha <code>CSIMigration</code> et <code>CSIMigrationOpenStack</code> doivent être activées.</p><h3 id=configmap>configMap</h3><p>La ressource <a href=/docs/tasks/configure-pod-container/configure-pod-configmap/><code>configMap</code></a> fournit un moyen d'injecter des données de configuration dans les Pods.
Les données stockées dans un objet <code>ConfigMap</code> peuvent être référencées dans un volume de type <code>configMap</code>
et être ensuite consommées par des applications conteneurisées s'exécutant dans un Pod.</p><p>Lorsque l'on référence un objet <code>configMap</code>, on peut simplement fournir son nom dans le volume
pour le référencer. On peut également personnaliser le chemin pour utiliser une entrée spécifique dans
la ConfigMap. Par exemple, pour monter la ConfigMap <code>log-config</code> sur un Pod appelé <code>configmap-pod</code>,
vous pourriez utiliser le YAML suivant :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>configmap-pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>test<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>busybox<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>volumeMounts</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>config-vol<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>mountPath</span>:<span style=color:#bbb> </span>/etc/config<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>volumes</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>config-vol<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>configMap</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>log-config<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>items</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span>- <span style=color:green;font-weight:700>key</span>:<span style=color:#bbb> </span>log_level<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>            </span><span style=color:green;font-weight:700>path</span>:<span style=color:#bbb> </span>log_level<span style=color:#bbb>
</span></span></span></code></pre></div><p>La ConfigMap <code>log-config</code> est montée comme un volume et tout le contenu stocké dans son entrée <code>log_level</code>
est monté dans le Pod au chemin "<code>/etc/config/log_level</code>".
À noter que ce chemin est dérivé du <code>mountPath</code> du volume et le <code>path</code> est étiqueté avec la clef <code>log_level</code>.</p><div class="alert alert-warning caution callout" role=alert><strong>Avertissement:</strong> Vous devez créer une <a href=/docs/tasks/configure-pod-container/configure-pod-configmap/>ConfigMap</a> avant de pouvoir l'utiliser.</div><div class="alert alert-info note callout" role=alert><strong>Note:</strong> Un conteneur utilisant une ConfigMap en tant que montage de volume <a href=#using-subpath>subPath</a> ne recevra pas les mises à jour de la ConfigMap.</div><h3 id=downwardapi>downwardAPI</h3><p>Un volume <code>downwardAPI</code> est utilisé pour rendre disponibles aux applications les données de l'API Downward.
Il monte un dossier et écrit les données demandées dans des fichiers de texte brut.</p><div class="alert alert-info note callout" role=alert><strong>Note:</strong> Un conteneur utilisant l'API Downward en tant que montage de volume <a href=#using-subpath>subPath</a> ne recevra pas les mises à jour de l'API Downward.</div><p>Voir <a href=/docs/tasks/inject-data-application/downward-api-volume-expose-pod-information/>l'exemple de volume <code>downwardAPI</code></a> pour plus de détails.</p><h3 id=emptydir>emptyDir</h3><p>Un volume <code>emptyDir</code> est d'abord créé lorsqu'un Pod est assigné à un nœud et existe aussi longtemps que le Pod s'exécute sur ce nœud.
Comme le nom l'indique, le volume est initialement vide. Les conteneurs dans le Pod peuvent tous lire et écrire les mêmes fichiers dans le volume <code>emptyDir</code>, bien que ce volume puisse être monté sur le même ou différents chemins dans chaque conteneur.
Lorsqu'un Pod est supprimé d'un nœud pour une raison quelconque, les données dans le <code>emptyDir</code> sont supprimées à jamais.</p><div class="alert alert-info note callout" role=alert><strong>Note:</strong> Un conteneur qui plante ne retire <em>PAS</em> un Pod d'un nœud, ainsi, les données présentes dans un <code>emptyDir</code> sont protégées en cas de plantage du conteneur.</div><p>Des cas d'utilisation pour un <code>emptyDir</code> peuvent être :</p><ul><li>un espace de travail, par exemple pour un tri fusion sur disque.</li><li>l'établissement d'un point de reprise d'un long calcul à des fins de récupération des données après un crash.</li><li>le stockage de fichiers qu'un conteneur de gestion de contenu va chercher pendant qu'un conteneur serveur web expose les données.</li></ul><p>Par défaut, les volumes <code>emptyDir</code> sont stockés sur tout médium supporté par le nœud - que ce soit un disque dur, un disque SSD ou un stockage réseau, dépendamment de l'environnement.
Cependant, vous pouvez définir le champ <code>emptyDir.medium</code> à <code>"Memory"</code> pour indiquer à Kubernetes de monter un tmpfs (système de fichiers supporté par la RAM) pour vous à la place.
Tandis que tmpfs est très rapide, soyez conscient qu'au contraire des disques, un tmpfs est effacé au redémarrage du nœud et tous les fichiers que vous écrivez seront comptabilisés dans la limite de mémoire de votre conteneur.</p><h4 id=exemple-de-pod>Exemple de Pod</h4><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>test-pd<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>k8s.gcr.io/test-webserver<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>test-container<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>volumeMounts</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:green;font-weight:700>mountPath</span>:<span style=color:#bbb> </span>/cache<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>cache-volume<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>volumes</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>cache-volume<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>emptyDir</span>:<span style=color:#bbb> </span>{}<span style=color:#bbb>
</span></span></span></code></pre></div><h3 id=fc>fc (fibre channel)</h3><p>Un volume <code>fc</code> permet à un volume Fibre Channel existant d'être monté dans un Pod.
Vous pouvez spécifier une ou plusieurs cibles World Wide Names en utilisant le paramètre
<code>targetWWNs</code> dans votre configuration de volume.
Si plusieurs WWNs sont spécifiés, targetWWNs s'attend à ce que ces WWNs proviennent de connexions multi-path.</p><div class="alert alert-warning caution callout" role=alert><strong>Avertissement:</strong> Vous devez configurer un zonage FC SAN pour allouer et masquer au préalable ces LUNs (volumes) aux cibles WWNs afin que les hôtes Kubernetes puissent y accéder.</div><p>Voir <a href=https://github.com/kubernetes/examples/tree/master/staging/volumes/fibre_channel>l'exemple FC</a> pour plus de détails.</p><h3 id=flocker>flocker</h3><p><a href=https://github.com/ClusterHQ/flocker>Flocker</a> est un gestionnaire de volumes de données en cluster open-source. Il assure la gestion et l'orchestration de volumes de données supportés par divers serveurs de stockage.</p><p>Un volume <code>flocker</code> permet de monter un ensemble de données Flocker dans un Pod.
Si l'ensemble de données n'existe pas déjà dans Flocker, il doit d'abord être créé avec la CLI Flocker ou en utilisant l'API Flocker.
Si l'ensemble de données existe déjà, il sera réattaché par Flocker au nœud sur lequel le Pod est planifié.
Cela signifie que les données peuvent être transmises entre les Pods selon les besoins.</p><div class="alert alert-warning caution callout" role=alert><strong>Avertissement:</strong> Vous devez exécuter votre propre installation de Flocker avant de pouvoir l'utiliser.</div><p>Voir <a href=https://github.com/kubernetes/examples/tree/master/staging/volumes/flocker>l'exemple Flocker</a> pour plus de détails.</p><h3 id=gcepersistentdisk>gcePersistentDisk</h3><p>Un volume <code>gcePersistentDisk</code> monte un <a href=http://cloud.google.com/compute/docs/disks>Disque Persistant</a> Google Compute Engine (GCE) dans un Pod.
À la différence d'un <code>emptyDir</code>, qui est écrasé lorsqu'un Pod est supprimé, le contenu d'un disque persistant est préservé et le volume est simplement démonté. Cela signifie qu'un disque persistant peut être prérempli avec des données et que ces données peuvent être transmises entre les Pods.</p><div class="alert alert-warning caution callout" role=alert><strong>Avertissement:</strong> Vous devez créer un disque persistant en utilisant <code>gcloud</code>, l'API GCE ou l'interface utilisateur avant de pouvoir utiliser ce disque.</div><p>Des restrictions existent lors de l'utilisation d'un <code>gcePersistentDisk</code>:</p><ul><li>les nœuds sur lesquels les Pods s'exécutent doivent être des machines virtuelles (VMs) GCE.</li><li>ces VMs doivent se trouver dans le même projet et la même zone GCE que le disque persistant</li></ul><p>Une fonctionnalité des disques persistants est qu'ils peuvent être montés en lecture seule par plusieurs consommateurs simultanément.
Cela signifie que vous pouvez préremplir un disque persistant avec votre jeu de données et l'exposer en parallèle à partir d'autant de Pods que nécessaire.
Malheureusement, les disques persistants peuvent seulement être montés par un seul consommateur en mode lecture-écriture - les écritures simultanées ne sont pas autorisées.</p><p>Utiliser un disque persistant dans un Pod contrôlé par un ReplicationController échouera à moins que le disque persistant soit en lecture seule ou que le nombre de répliques soit de 0 ou 1.</p><h4 id=création-d-un-disque-persistant>Création d'un disque persistant</h4><p>Avant de pouvoir utiliser un disque persistant GCE avec un Pod, vous devez le créer.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>gcloud compute disks create --size<span style=color:#666>=</span>500GB --zone<span style=color:#666>=</span>us-central1-a my-data-disk
</span></span></code></pre></div><h4 id=exemple-de-pod-1>Exemple de Pod</h4><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>test-pd<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>k8s.gcr.io/test-webserver<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>test-container<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>volumeMounts</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:green;font-weight:700>mountPath</span>:<span style=color:#bbb> </span>/test-pd<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>test-volume<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>volumes</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>test-volume<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:#080;font-style:italic># Ce disque persistant GCE doit déjà exister.</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>gcePersistentDisk</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>pdName</span>:<span style=color:#bbb> </span>my-data-disk<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>fsType</span>:<span style=color:#bbb> </span>ext4<span style=color:#bbb>
</span></span></span></code></pre></div><h4 id=disques-persistants-régionaux>Disques persistants régionaux</h4><div style=margin-top:10px;margin-bottom:10px><b>FEATURE STATE:</b> <code>Kubernetes v1.10 [beta]</code></div><p>La fonctionnalité de disques persistants régionaux (<a href=https://cloud.google.com/compute/docs/disks/#repds>Regional Persistent Disks</a>) permet la création de disques persistants disponibles dans deux zones à l'intérieur d'une même région.
Afin d'utiliser cette fonctionnalité, le volume doit être provisionné en tant que PersistentVolume; le référencement du volume directement depuis un Pod n'est pas supporté.</p><h4 id=provisionnement-manuel-d-un-disque-persistant-régional-en-tant-que-persistentvolume>Provisionnement manuel d'un disque persistant régional en tant que PersistentVolume</h4><p>Le provisionnement dynamique est possible en utilisant une <a href=/docs/concepts/storage/storage-classes/#gce-pd>StorageClass pour un disque persistant GCE</a>.
Avant de créer un PersistentVolume, vous devez créer le disque persistant :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>gcloud beta compute disks create --size<span style=color:#666>=</span>500GB my-data-disk
</span></span><span style=display:flex><span>    --region us-central1
</span></span><span style=display:flex><span>    --replica-zones us-central1-a,us-central1-b
</span></span></code></pre></div><p>Exemple de spec PersistentVolume :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>PersistentVolume<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>test-volume<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>labels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>failure-domain.beta.kubernetes.io/zone</span>:<span style=color:#bbb> </span>us-central1-a__us-central1-b<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>capacity</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>storage</span>:<span style=color:#bbb> </span>400Gi<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>accessModes</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- ReadWriteOnce<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>gcePersistentDisk</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>pdName</span>:<span style=color:#bbb> </span>my-data-disk<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>fsType</span>:<span style=color:#bbb> </span>ext4<span style=color:#bbb>
</span></span></span></code></pre></div><h4 id=migration-csi-4>Migration CSI</h4><div style=margin-top:10px;margin-bottom:10px><b>FEATURE STATE:</b> <code>Kubernetes v1.14 [alpha]</code></div><p>La fonctionnalité de migration CSI pour un disque persistant GCE, lorsque activée, fixe toutes les opérations de plugin depuis le plugin "in-tree" vers le pilote de l'interface CSI (Container Storage Interface) <code>pd.csi.storage.gke.io</code>.
Afin d'utiliser cette fonctionnalité, le <a href=https://github.com/kubernetes/cloud-provider-openstack/blob/master/docs/using-cinder-csi-plugin.md>Pilote CSI de disque persistant GCE</a> doit être installé dans le cluster et les fonctionnalités Alpha <code>CSIMigration</code> et <code>CSIMigrationGCE</code> doivent être activées.</p><h3 id=gitrepo>gitRepo (obsolète)</h3><div class="alert alert-danger warning callout" role=alert><strong>Attention:</strong> Le type de volume gitRepo est obsolète. Pour provisionner un conteneur avec un dépôt git, il faut monter un <a href=#emptydir>EmptyDir</a> dans un InitContainer qui clone le dépôt en utilisant git, ensuite, monter le <a href=#emptydir>EmptyDir</a> dans le conteneur du Pod.</div><p>Un volume <code>gitRepo</code> est un exemple de ce qui peut être réalisé en tant que plugin de volume.
Cela monte un dossier vide et clone un dépôt git à l'intérieur, à la disposition d'un Pod.
Dans le futur, de tels volumes pourraient être déplacé vers un modèle encore plus découplé plutôt qu'étendre l'API Kubernetes pour chaque cas d'utilisation.</p><p>Voici un exemple d'un volume gitRepo :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>server<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>nginx<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>nginx<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>volumeMounts</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:green;font-weight:700>mountPath</span>:<span style=color:#bbb> </span>/mypath<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>git-volume<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>volumes</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>git-volume<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>gitRepo</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>repository</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;git@somewhere:me/my-git-repository.git&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>revision</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;22f1d8406d464b0c0874075539c1f2e96c253775&#34;</span><span style=color:#bbb>
</span></span></span></code></pre></div><h3 id=glusterfs>glusterfs</h3><p>Un volume <code>glusterfs</code> permet à un volume <a href=http://www.gluster.org>Glusterfs</a> (un système de fichiers en réseau open
source) d'être monté dans un Pod. À la différence d'un <code>emptyDir</code>, qui est écrasé lorsqu'un Pod est supprimé. le contenu d'un volume <code>glusterfs</code> est préservé et le volume est simplement démonté.
Cela signifie qu'un volume glusterfs peut être prérempli avec des données et que ces données peuvent être transmises entre les Pods.
GlusterFS peut être monté plusieurs fois en écriture simultanément.</p><div class="alert alert-warning caution callout" role=alert><strong>Avertissement:</strong> Vous devez exécuter votre propre installation de GlusterFS avant de pouvoir l'utiliser.</div><p>Voir <a href=https://github.com/kubernetes/examples/tree/master/volumes/glusterfs>l'exemple GlusterFS</a> pour plus de détails.</p><h3 id=hostpath>hostPath</h3><p>Un volume <code>hostPath</code> monte un fichier ou un dossier depuis le système de fichiers du nœud hôte à l'intérieur d'un Pod.
Ce ne sera pas requis pour la plupart des Pods, mais cela offre une puissante solution de secours pour certaines applications.</p><p>Par exemple, des utilisations du <code>hostPath</code> peuvent être :</p><ul><li>exécuter un conteneur qui nécessite l'accès aux éléments internes de Docker; utiliser un <code>hostPath</code> de <code>/var/lib/docker</code></li><li>exécuter cAdvisor dans un conteneur; utiliser un <code>hostPath</code> de <code>/sys</code></li><li>autoriser un Pod à spécifier si un <code>hostPath</code> donné devrait exister avant la mise en exécution du Pod, s'il devrait être créé et en tant que quoi il devrait exister.</li></ul><p>En plus de la propriété requise <code>path</code>, un utilisateur peut optionnellement spécifier un <code>type</code> pour un volume <code>hostPath</code>.</p><p>Les valeurs supportées pour le champ <code>type</code> sont les suivantes :</p><table><thead><tr><th style=text-align:left>Valeur</th><th style=text-align:left>Comportement</th></tr></thead><tbody><tr><td style=text-align:left></td><td style=text-align:left>Une chaîne de caractères vide (par défaut) sert à la rétrocompatibilité, ce qui signifie qu'aucune vérification ne sera effectuée avant de monter le volume hostPath.</td></tr><tr><td style=text-align:left><code>DirectoryOrCreate</code></td><td style=text-align:left>Si rien n'existe au chemin fourni, un dossier vide y sera créé au besoin avec les permissions définies à 0755, avec le même groupe et la même possession que Kubelet.</td></tr><tr><td style=text-align:left><code>Directory</code></td><td style=text-align:left>Un dossier doit exister au chemin fourni</td></tr><tr><td style=text-align:left><code>FileOrCreate</code></td><td style=text-align:left>Si rien n'existe au chemin fourni, un fichier vide y sera créé au besoin avec les permissions définies à 0644, avec le même groupe et la même possession que Kubelet.</td></tr><tr><td style=text-align:left><code>File</code></td><td style=text-align:left>Un fichier doit exister au chemin fourni</td></tr><tr><td style=text-align:left><code>Socket</code></td><td style=text-align:left>Un socket UNIX doit exister au chemin fourni</td></tr><tr><td style=text-align:left><code>CharDevice</code></td><td style=text-align:left>Un périphérique en mode caractère doit exister au chemin fourni</td></tr><tr><td style=text-align:left><code>BlockDevice</code></td><td style=text-align:left>Un périphérique en mode bloc doit exister au chemin fourni</td></tr></tbody></table><p>Une attention particulière doit être portée lors de l'utilisation de ce type de volume car :</p><ul><li>les Pods avec une configuration identique (tels que ceux créés depuis un podTemplate) peuvent se comporter différemment sur des nœuds différents à cause de fichiers différents sur les nœuds.</li><li>lorsque Kubernetes ajoute une planification tenant compte des ressources, comme prévu, il ne pourra pas prendre en compte les ressources utilisées par un <code>hostPath</code>.</li><li>les fichiers ou dossiers créés sur les hôtes sous-jacents ne sont accessibles en écriture que par root. Vous devez soit exécuter votre programme en tant que root dans un <a href=/docs/user-guide/security-context>conteneur privilégié</a> ou modifier les permissions du fichier sur l'hôte pour pouvoir écrire dans un volume <code>hostPath</code>.</li></ul><h4 id=exemple-de-pod-2>Exemple de Pod</h4><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>test-pd<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>k8s.gcr.io/test-webserver<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>test-container<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>volumeMounts</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:green;font-weight:700>mountPath</span>:<span style=color:#bbb> </span>/test-pd<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>test-volume<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>volumes</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>test-volume<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>hostPath</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:#080;font-style:italic># chemin du dossier sur l&#39;hôte</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>path</span>:<span style=color:#bbb> </span>/data<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:#080;font-style:italic># ce champ est optionnel</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>type</span>:<span style=color:#bbb> </span>Directory<span style=color:#bbb>
</span></span></span></code></pre></div><h3 id=iscsi>iscsi</h3><p>Un volume <code>iscsi</code> permet à un volume existant iSCSI (SCSI over IP) d'être monté dans un Pod.
À la différence d'un <code>emptyDir</code>, qui est écrasé lorsqu'un Pod est supprimé, le contenu d'un volume <code>iscsi</code> est préservé et le volume est simplement démonté.
Cela signifie qu'un volume iscsi peut être prérempli avec des données que ces données peuvent être transmises entre les Pods.</p><div class="alert alert-warning caution callout" role=alert><strong>Avertissement:</strong> Vous devez exécuter votre propre serveur iSCSI avec le volume créé avant de pouvoir l'utiliser.</div><p>Une fonctionnalité de iSCSI est qu'il peut être monté en lecture seule par plusieurs consommateurs simultanément.
Cela signifie que vous pouvez préremplir un volume avec votre jeu de données et l'exposer en parallèle à partir d'autant de Pods que nécessaire.
Malheureusement, les volumes iSCSI peuvent seulement être montés par un seul consommateur en mode lecture-écriture - les écritures simultanées ne sont pas autorisées.</p><p>Voir <a href=https://github.com/kubernetes/examples/tree/master/volumes/iscsi>l'exemple iSCSI</a> pour plus de détails.</p><h3 id=local>local</h3><div style=margin-top:10px;margin-bottom:10px><b>FEATURE STATE:</b> <code>Kubernetes v1.14 [stable]</code></div><p>Un volume <code>local</code> représente un périphérique de stockage local monté tels qu'un disque, une partition ou un dossier.</p><p>Les volumes locaux peuvent seulement être utilisés comme un PersistentVolume créé statiquement.
Le provisionnement dynamique n'est pas encore supporté.</p><p>Comparés aux volumes <code>hostPath</code>, les volumes locaux peuvent être utilisés de manière durable et portable sans planifier manuellement des Pods sur les nœuds, puisque le système est conscient des contraintes de nœud du volume en examinant l'affinité de nœud sur le PersistentVolume.</p><p>Toutefois, les volumes locaux sont encore sujets à la disponibilité du nœud sous-jacent et ne conviennent pas à toutes les applications. Si un nœud devient "en mauvaise santé" (unhealthy), alors le volume local deviendra également inaccessible et un Pod qui l'utilise ne sera pas en mesure de s'exécuter. Les applications qui utilisent des volumes locaux doivent être en mesure de tolérer cette disponibilité réduite, ainsi que de potentielles pertes de données, dépendamment des caractéristiques de durabilité du disque sous-jacent.</p><p>L'exemple suivant traite d'une spec d'un PersistentVolume utilisant un volume <code>local</code> et une <code>nodeAffinity</code>:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>PersistentVolume<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>example-pv<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>capacity</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>storage</span>:<span style=color:#bbb> </span>100Gi<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:#080;font-style:italic># le champ volumeMode requiert l&#39;activation de la &#34;feature gate&#34; Alpha BlockVolume</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>volumeMode</span>:<span style=color:#bbb> </span>Filesystem<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>accessModes</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- ReadWriteOnce<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>persistentVolumeReclaimPolicy</span>:<span style=color:#bbb> </span>Delete<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>storageClassName</span>:<span style=color:#bbb> </span>local-storage<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>local</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>path</span>:<span style=color:#bbb> </span>/mnt/disks/ssd1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>nodeAffinity</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>required</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>nodeSelectorTerms</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- <span style=color:green;font-weight:700>matchExpressions</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span>- <span style=color:green;font-weight:700>key</span>:<span style=color:#bbb> </span>kubernetes.io/hostname<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>operator</span>:<span style=color:#bbb> </span>In<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>values</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span>- example-node<span style=color:#bbb>
</span></span></span></code></pre></div><p>La <code>nodeAffinity</code> d'un PersistentVolume est requise lors de l'utilisation de volumes locaux.
Cela permet au planificateur (scheduler) Kubernetes de planifier correctement des Pods utilisant des volumes locaux aux bons nœuds.</p><p>Le <code>volumeMode</code> d'un PersistentVolume peut maintenant être configuré à "Block" (au lieu de la valeur par défaut "Filesystem") pour exposer le volume local en tant que périphérique bloc brut (raw block device).
Le champ <code>volumeMode</code> requiert l'activation de la "feature gate" Alpha <code>BlockVolume</code>.</p><p>Lors de l'utilisation des volumes locaux, il est recommandé de créer une StorageClass avec <code>volumeBindingMode</code> configuré à <code>WaitForFirstConsumer</code>. Voir <a href=/docs/concepts/storage/storage-classes/#local>l'exemple</a>. Retarder la liaison (binding) du volume garantit que la décision de liaison du PersistentVolumeClaim sera également évaluée avec toutes les autres contraintes de nœud que le Pod peut avoir, tels que les exigences en ressources du nœud, les sélecteurs de nœud, leur affinité et leur anti-affinité.</p><p>Un provisionneur statique externe peut être exécuté séparément pour une gestion améliorée du cycle de vie du volume local.
Noter que ce provisionneur ne supporte pas encore le provisionnement dynamique. Pour un exemple sur la façon d'exécuter un provisionneur externe local, voir le <a href=https://github.com/kubernetes-sigs/sig-storage-local-static-provisioner>guide utilisateur de provisionneur de volume local</a>.</p><div class="alert alert-info note callout" role=alert><strong>Note:</strong> Le PersistentVolume local requiert un nettoyage manuel et une suppression par l'utilisateur si le provisionneur statique n'est pas utilisé pour gérer le cycle de vie du volume.</div><h3 id=nfs>nfs</h3><p>Un volume <code>nfs</code> permet à un partage NFS (Network File System) existant d'être monté dans un Pod.
À la différence d'un <code>emptyDir</code>, qui est écrasé lorsqu'un Pod est supprimé, le contenu d'un volume <code>nfs</code> est préservé et le volume est simplement démonté.
Cela signifie qu'un volume NFS peut être prérempli avec des données et que les données peuvent être transmises entre les Pods. NFS peut être monté plusieurs fois en écriture simultanément.</p><div class="alert alert-warning caution callout" role=alert><strong>Avertissement:</strong> Vous devez exécuter votre propre serveur NFS avec le partage exporté avant de pouvoir l'utiliser.</div><p>Voir <a href=https://github.com/kubernetes/examples/tree/master/staging/volumes/nfs>l'exemple NFS</a> pour plus de détails.</p><h3 id=persistentvolumeclaim>persistentVolumeClaim</h3><p>Un volume <code>persistentVolumeClaim</code> est utilisé pour monter un <a href=/docs/concepts/storage/persistent-volumes/>PersistentVolume</a> dans un Pod. Les PersistentVolumes sont une manière pour les utilisateurs de "revendiquer" un stockage durable (comme un PersistentDisk GCE ou un volume iSCSI) sans savoir les détails d'un environnement cloud particulier.</p><p>Voir <a href=/docs/concepts/storage/persistent-volumes/>l'exemple PersistentVolumes</a> pour plus de détails.</p><h3 id=projected>projected</h3><p>Un volume <code>projected</code> mappe plusieurs sources de volume existantes dans le même dossier.</p><p>Actuellement, les types de sources de volume suivantes peuvent être projetés :</p><ul><li><a href=#secret><code>secret</code></a></li><li><a href=#downwardapi><code>downwardAPI</code></a></li><li><a href=#configmap><code>configMap</code></a></li><li><code>serviceAccountToken</code></li></ul><p>Toutes les sources doivent se trouver dans le même namespace que celui du Pod. Pour plus de détails, voir le <a href=https://github.com/kubernetes/community/blob/master/contributors/design-proposals/node/all-in-one-volume.md>document de conception tout-en-un </a>.</p><p>La projection des jetons de compte de service (service account) est une fonctionnalité introduite dans Kubernetes 1.11 et promue en Beta dans la version 1.12.
Pour activer cette fonctionnalité dans la version 1.11, il faut configurer explicitement la <a href=/docs/reference/command-line-tools-reference/feature-gates/>"feature gate" <code>TokenRequestProjection</code></a> à "True".</p><h4 id=exemple-d-un-pod-avec-un-secret-une-api-downward-et-une-configmap>Exemple d'un Pod avec un secret, une API downward et une configmap.</h4><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>volume-test<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>container-test<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>busybox<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>volumeMounts</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>all-in-one<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>mountPath</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;/projected-volume&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>readOnly</span>:<span style=color:#bbb> </span><span style=color:#a2f;font-weight:700>true</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>volumes</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>all-in-one<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>projected</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>sources</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- <span style=color:green;font-weight:700>secret</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>mysecret<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>items</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>            </span>- <span style=color:green;font-weight:700>key</span>:<span style=color:#bbb> </span>username<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>              </span><span style=color:green;font-weight:700>path</span>:<span style=color:#bbb> </span>my-group/my-username<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- <span style=color:green;font-weight:700>downwardAPI</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>items</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>            </span>- <span style=color:green;font-weight:700>path</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;labels&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>              </span><span style=color:green;font-weight:700>fieldRef</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>                </span><span style=color:green;font-weight:700>fieldPath</span>:<span style=color:#bbb> </span>metadata.labels<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>            </span>- <span style=color:green;font-weight:700>path</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;cpu_limit&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>              </span><span style=color:green;font-weight:700>resourceFieldRef</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>                </span><span style=color:green;font-weight:700>containerName</span>:<span style=color:#bbb> </span>container-test<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>                </span><span style=color:green;font-weight:700>resource</span>:<span style=color:#bbb> </span>limits.cpu<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- <span style=color:green;font-weight:700>configMap</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>myconfigmap<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>items</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>            </span>- <span style=color:green;font-weight:700>key</span>:<span style=color:#bbb> </span>config<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>              </span><span style=color:green;font-weight:700>path</span>:<span style=color:#bbb> </span>my-group/my-config<span style=color:#bbb>
</span></span></span></code></pre></div><h4 id=exemple-d-un-pod-avec-plusieurs-secrets-avec-une-configuration-de-mode-de-permission-autre-que-celle-par-défaut>Exemple d'un Pod avec plusieurs secrets avec une configuration de mode de permission autre que celle par défaut.</h4><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>volume-test<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>container-test<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>busybox<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>volumeMounts</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>all-in-one<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>mountPath</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;/projected-volume&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>readOnly</span>:<span style=color:#bbb> </span><span style=color:#a2f;font-weight:700>true</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>volumes</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>all-in-one<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>projected</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>sources</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- <span style=color:green;font-weight:700>secret</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>mysecret<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>items</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>            </span>- <span style=color:green;font-weight:700>key</span>:<span style=color:#bbb> </span>username<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>              </span><span style=color:green;font-weight:700>path</span>:<span style=color:#bbb> </span>my-group/my-username<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- <span style=color:green;font-weight:700>secret</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>mysecret2<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>items</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>            </span>- <span style=color:green;font-weight:700>key</span>:<span style=color:#bbb> </span>password<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>              </span><span style=color:green;font-weight:700>path</span>:<span style=color:#bbb> </span>my-group/my-password<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>              </span><span style=color:green;font-weight:700>mode</span>:<span style=color:#bbb> </span><span style=color:#666>511</span><span style=color:#bbb>
</span></span></span></code></pre></div><p>Chaque source de volume projeté est listée dans la spec, sous <code>sources</code>. Les paramètres sont à peu près les mêmes avec deux exceptions :</p><ul><li>Pour les secrets, le champ <code>secretName</code> a été changé par <code>name</code> pour être consistant avec le nommage des ConfigMap.</li><li>Le <code>defaultMode</code> peut seulement être spécifié au niveau projeté et non pour chaque source de volume. Cependant, tel qu'illustré au-dessus, il est possible de configurer explicitement le <code>mode</code> pour chaque projection individuelle.</li></ul><p>Lorsque la fonctionnalité <code>TokenRequestProjection</code> est activée, vous pouvez injecter le jeton pour le <a href=/docs/reference/access-authn-authz/authentication/#service-account-tokens>service account</a> courant dans un Pod au chemin spécifié. Ci-dessous, un exemple :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>sa-token-test<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>container-test<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>busybox<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>volumeMounts</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>token-vol<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>mountPath</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;/service-account&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>readOnly</span>:<span style=color:#bbb> </span><span style=color:#a2f;font-weight:700>true</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>volumes</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>token-vol<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>projected</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>sources</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- <span style=color:green;font-weight:700>serviceAccountToken</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>audience</span>:<span style=color:#bbb> </span>api<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>expirationSeconds</span>:<span style=color:#bbb> </span><span style=color:#666>3600</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>path</span>:<span style=color:#bbb> </span>token<span style=color:#bbb>
</span></span></span></code></pre></div><p>Le pod d'exemple possède un volume projeté contenant le jeton injecté du service account.
Ce jeton peut être utilisé par des conteneurs de Pod pour accéder au service d'API Kubernetes API, par exemple.
Le champ <code>audience</code> contient l'audience-cible du jeton.
Un destinataire du jeton doit s'identifier avec un identificateur spécifié dans l'audience du jeton, sinon il doit rejeter le jeton. Ce champ est facultatif et sa valeur par défaut est l'identifiant du serveur API.</p><p>Le champ <code>expirationSeconds</code> est la durée de validité attendue du jeton de service account.
Sa valeur par défaut est de 1 heure et doit être au moins de 10 minutes (600 secondes). Un administrateur peut aussi limiter sa valeur maximum en spécifiant l'option <code>--service-account-max-token-expiration</code> pour le serveur API.
Le champ <code>path</code> spécifie un chemin relatif au point de montage du volume projeté.</p><div class="alert alert-info note callout" role=alert><strong>Note:</strong> Un conteneur utilisant une source de volume projeté en tant que point de montage de volume <a href=#using-subpath>subPath</a> ne recevra pas de mises à jour pour ces sources de volume.</div><h3 id=portworxvolume>portworxVolume</h3><p>Un <code>portworxVolume</code> est une couche de stockage bloc élastique qui s'exécute de manière hyperconvergée avec Kubernetes.
<a href=https://portworx.com/use-case/kubernetes-storage/>Portworx</a> donne l'empreinte digitale d'un stockage dans un serveur, tiers basés sur les capacités et agrège la capacité sur plusieurs serveurs. Portworx s'exécute en invité sur des machines virtuelles ou sur des nœuds Linux bare metal.</p><p>Un <code>portworxVolume</code> peut être créé dynamiquement à travers Kubernetes ou il peut également être pré-provisionné et référencé à l'intérieur d'un Pod Kubernetes.
Voici un exemple de Pod référençant un PortworxVolume pré-provisionné :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>test-portworx-volume-pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>k8s.gcr.io/test-webserver<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>test-container<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>volumeMounts</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:green;font-weight:700>mountPath</span>:<span style=color:#bbb> </span>/mnt<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>pxvol<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>volumes</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>pxvol<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:#080;font-style:italic># Ce volume Portworx doit déjà exister.</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>portworxVolume</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>volumeID</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;pxvol&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>fsType</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;&lt;fs-type&gt;&#34;</span><span style=color:#bbb>
</span></span></span></code></pre></div><div class="alert alert-warning caution callout" role=alert><strong>Avertissement:</strong> Il faut s'assurer d'avoir un PortworxVolume existant avec le nom <code>pxvol</code> avant de l'utiliser dans le Pod.</div><p>Plus de détails et d'exemples peuvent être trouvé <a href=https://github.com/kubernetes/examples/tree/master/staging/volumes/portworx/README.md>ici</a>.</p><h3 id=quobyte>quobyte</h3><p>Un volume <code>quobyte</code> permet à un volume existant <a href=http://www.quobyte.com>Quobyte</a> d'être monté dans un Pod.</p><div class="alert alert-warning caution callout" role=alert><strong>Avertissement:</strong> Vous devez exécuter votre propre configuration Quobyte avec les volumes créés avant de pouvoir l'utiliser.</div><p>Quobyte supporte le <a class=glossary-tooltip title="L'Interface de Stockage de Conteneurs (CSI, de l'anglais Container Storage Interface) définit une interface normalisée pour exposer les systèmes de stockage aux conteneurs." data-toggle=tooltip data-placement=top href=/docs/concepts/storage/volumes/#csi target=_blank aria-label='Container Storage Interface'>Container Storage Interface</a>.
CSI est le plugin recommandé pour utiliser les volumes Quobyte volumes dans Kubernetes. Le projet GitHub Quobyte dispose <a href=https://github.com/quobyte/quobyte-csi#quobyte-csi>d'instructions</a> pour déployer Quobyte en utilisant CSI, avec des exemples.</p><h3 id=rbd>rbd</h3><p>Un volume <code>rbd</code> permet à un volume périphérique bloc Rados (<a href=http://ceph.com/docs/master/rbd/rbd/>Rados Block
Device</a>) d'être monté dans un Pod.
À la différence d'un <code>emptyDir</code>, qui est écrasé lorsqu'un Pod est supprimé, le contenu d'un volume <code>rbd</code> est préservé et le volume est simplement démonté.
Cela signifie qu'un volume RBD peut être prérempli avec des données et que ces données peuvent être transmises entre les Pods.</p><div class="alert alert-warning caution callout" role=alert><strong>Avertissement:</strong> Vous devez exécuter votre propre installation Ceph avant de pouvoir utiliser RBD.</div><p>Une fonctionnalité de RBD est qu'il peut être monté en lecture seule par plusieurs consommateurs simultanément.
Cela signifie que vous pouvez préremplir un volume avec votre jeu de données et l'exposer en parallèle à partir d'autant de Pods que nécessaire.
Malheureusement, les volumes RBD peuvent seulement être montés par un seul consommateur en mode lecture-écriture - les écritures simultanées ne sont pas autorisées.</p><p>Voir <a href=https://github.com/kubernetes/examples/tree/master/volumes/rbd>l'exemple RBD</a> pour plus de détails.</p><h3 id=scaleio>scaleIO</h3><p>ScaleIO est une plateforme de stockage logicielle qui peut utiliser du matériel physique existant pour créer des clusters de stockage bloc partagé en réseau évolutif.
Le plugin de volume <code>scaleIO</code> permet aux Pods déployés d'accéder à des volumes ScaleIO existants (ou il peut provisionner dynamiquement de nouveaux volumes pour des revendications de volumes persistants, voir <a href=/docs/concepts/storage/persistent-volumes/#scaleio>ScaleIO Persistent Volumes</a>).</p><div class="alert alert-warning caution callout" role=alert><strong>Avertissement:</strong> Vous devez exécuter un cluster ScaleIO déjà configuré avec les volumes créés avant de pouvoir les utiliser.</div><p>L'exemple suivant montre une configuration de Pod avec ScaleIO :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>pod-0<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>k8s.gcr.io/test-webserver<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>pod-0<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>volumeMounts</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:green;font-weight:700>mountPath</span>:<span style=color:#bbb> </span>/test-pd<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>vol-0<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>volumes</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>vol-0<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>scaleIO</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>gateway</span>:<span style=color:#bbb> </span>https://localhost:443/api<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>system</span>:<span style=color:#bbb> </span>scaleio<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>protectionDomain</span>:<span style=color:#bbb> </span>sd0<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>storagePool</span>:<span style=color:#bbb> </span>sp1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>volumeName</span>:<span style=color:#bbb> </span>vol-0<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>secretRef</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>sio-secret<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>fsType</span>:<span style=color:#bbb> </span>xfs<span style=color:#bbb>
</span></span></span></code></pre></div><p>Pour plus de détails, consulter <a href=https://github.com/kubernetes/examples/tree/master/staging/volumes/scaleio>les exemples ScaleIO</a>.</p><h3 id=secret>secret</h3><p>Un volume <code>secret</code> est utilisé pour fournir des informations sensibles, comme des mots de passe, aux Pods.
Vous pouvez stocker des secrets dans l'API Kubernetes et les monter en tant que fichiers pour être utilisés par les Pods sans les coupler directement avec Kubernetes. Les volumes <code>secret</code> sont supportés par tmpfs (un système de fichiers en RAM) pour qu'ils ne soient jamais écrits sur du stockage non volatil.</p><div class="alert alert-warning caution callout" role=alert><strong>Avertissement:</strong> Vous devez créer un secret dans l'API Kubernetes avant de pouvoir l'utiliser.</div><div class="alert alert-info note callout" role=alert><strong>Note:</strong> Un conteneur utilisant un secret en tant que point de montage de volume <a href=#using-subpath>subPath</a> ne recevra pas les mises à jour des secrets.</div><p>Les secrets sont décrits plus en détails <a href=/docs/user-guide/secrets>ici</a>.</p><h3 id=storageos>storageOS</h3><p>Un volume <code>storageos</code> permet à un volume <a href=https://www.storageos.com>StorageOS</a> existant d'être monté dans un Pod.</p><p>StorageOS s'exécute en tant que conteneur dans l'environnement Kubernetes en rendant le stockage local ou attaché accessible depuis n'importe quel nœud dans le cluster Kubernetes.
Les données peuvent être répliquées pour se protéger des défaillances de nœuds.
Les techniques d'allocation fine et dynamique et de compression peuvent améliorer l'utilisation et réduire les coûts.</p><p>À la base, StorageOS fournit un stockage bloc aux conteneurs accessible via un système de fichiers.</p><p>Le conteneur StorageOS requiert Linux 64-bit et n'a pas besoin de dépendances supplémentaires.
Une licence développeur libre est disponible.</p><div class="alert alert-warning caution callout" role=alert><strong>Avertissement:</strong> Vous devez exécuter le conteneur StorageOS sur chaque nœud qui souhaite accéder aux volumes StorageOS ou qui veut contribuer à la
capacité de stockage du pool.
Pour les instructions d'installation, consulter la <a href=https://docs.storageos.com>documentation StorageOS</a>.</div><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>labels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>redis<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>role</span>:<span style=color:#bbb> </span>master<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>test-storageos-redis<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>master<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>kubernetes/redis:v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>env</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>MASTER<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>value</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;true&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>ports</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span>- <span style=color:green;font-weight:700>containerPort</span>:<span style=color:#bbb> </span><span style=color:#666>6379</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>volumeMounts</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span>- <span style=color:green;font-weight:700>mountPath</span>:<span style=color:#bbb> </span>/redis-master-data<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>redis-data<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>volumes</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>redis-data<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>storageos</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:#080;font-style:italic># Le volume `redis-vol01` doit déjà exister dans StorageOS, dans le namespace `default`.</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>volumeName</span>:<span style=color:#bbb> </span>redis-vol01<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>fsType</span>:<span style=color:#bbb> </span>ext4<span style=color:#bbb>
</span></span></span></code></pre></div><p>Pour plus d'informations incluant le provisionnement dynamique (Dynamic Provisioning) et les réclamations de volume persistant (Persistent Volume Claims), consulter les <a href=https://github.com/kubernetes/examples/blob/master/volumes/storageos>exemples StorageOS</a>.</p><h3 id=vspherevolume>vsphereVolume</h3><div class="alert alert-info note callout" role=alert><strong>Note:</strong> Prérequis : Kubernetes avec vSphere Cloud Provider configuré. Pour la configuration cloudprovider,
se référer au <a href=https://vmware.github.io/vsphere-storage-for-kubernetes/documentation/>guide de mise en marche vSphere</a>.</div><p>Un volume <code>vsphereVolume</code> est utilisé pour monter un volume vSphere VMDK dans un Pod. Le contenu d'un volume est préservé lorsqu'il est démonté. Il supporte les banques de données (datastore) VMFS and VSAN.</p><div class="alert alert-warning caution callout" role=alert><strong>Avertissement:</strong> Vous devez créer VMDK en utilisant une des méthodes suivantes avant de l'utiliser avec un Pod.</div><h4 id=création-d-un-volume-vmdk>Création d'un volume VMDK</h4><p>Choisir une des méthodes suivantes pour créer un VMDK.</p><ul class="nav nav-tabs" id=tabs-volumes role=tablist><li class=nav-item><a data-toggle=tab class="nav-link active" href=#tabs-volumes-0 role=tab aria-controls=tabs-volumes-0 aria-selected=true>Création en utilisant vmkfstools</a></li><li class=nav-item><a data-toggle=tab class=nav-link href=#tabs-volumes-1 role=tab aria-controls=tabs-volumes-1>Création en utilisant vmware-vdiskmanager</a></li></ul><div class=tab-content id=tabs-volumes><div id=tabs-volumes-0 class="tab-pane show active" role=tabpanel aria-labelledby=tabs-volumes-0><p><p>Premièrement, se connecter en ssh dans l'ESX, ensuite, utiliser la commande suivante pour créer un VMDK :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>vmkfstools -c 2G /vmfs/volumes/DatastoreName/volumes/myDisk.vmdk
</span></span></code></pre></div></div><div id=tabs-volumes-1 class=tab-pane role=tabpanel aria-labelledby=tabs-volumes-1><p><p>Utiliser la commande suivante pour créer un VMDK:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>vmware-vdiskmanager -c -t <span style=color:#666>0</span> -s 40GB -a lsilogic myDisk.vmdk
</span></span></code></pre></div></div></div><h4 id=exemple-de-configuration-vsphere-vmdk>Exemple de configuration vSphere VMDK</h4><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>test-vmdk<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>k8s.gcr.io/test-webserver<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>test-container<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>volumeMounts</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:green;font-weight:700>mountPath</span>:<span style=color:#bbb> </span>/test-vmdk<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>test-volume<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>volumes</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>test-volume<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:#080;font-style:italic># Ce volume VMDK doit déjà exister.</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>vsphereVolume</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>volumePath</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;[DatastoreName] volumes/myDisk&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>fsType</span>:<span style=color:#bbb> </span>ext4<span style=color:#bbb>
</span></span></span></code></pre></div><p>Plus d'exemples sont disponibles <a href=https://github.com/kubernetes/examples/tree/master/staging/volumes/vsphere>ici</a>.</p><h2 id=utilisation-de-subpath>Utilisation de subPath</h2><p>Parfois, il est utile de partager un volume pour plusieurs utilisations dans un même Pod.
La propriété <code>volumeMounts.subPath</code> peut être utilisée pour spécifier un sous-chemin à l'intérieur du volume référencé au lieu de sa racine.</p><p>Voici un exemple d'un Pod avec une stack LAMP (Linux Apache Mysql PHP) utilisant un unique volume partagé.
Le contenu HTML est mappé à son dossier <code>html</code> et les bases de données seront stockées dans son dossier <code>mysql</code> :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>my-lamp-site<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>mysql<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>mysql<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>env</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>MYSQL_ROOT_PASSWORD<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>value</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;rootpasswd&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>volumeMounts</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- <span style=color:green;font-weight:700>mountPath</span>:<span style=color:#bbb> </span>/var/lib/mysql<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>site-data<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>subPath</span>:<span style=color:#bbb> </span>mysql<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>php<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>php:7.0-apache<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>volumeMounts</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- <span style=color:green;font-weight:700>mountPath</span>:<span style=color:#bbb> </span>/var/www/html<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>site-data<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>subPath</span>:<span style=color:#bbb> </span>html<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>volumes</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>site-data<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>persistentVolumeClaim</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>claimName</span>:<span style=color:#bbb> </span>my-lamp-site-data<span style=color:#bbb>
</span></span></span></code></pre></div><h3 id=utilisation-d-un-subpath-avec-des-variables-d-environnement-étendues>Utilisation d'un subPath avec des variables d'environnement étendues</h3><div style=margin-top:10px;margin-bottom:10px><b>FEATURE STATE:</b> <code>Kubernetes v1.15 [beta]</code></div><p>Utiliser le champ <code>subPathExpr</code> pour construire des noms de dossier <code>subPath</code> depuis les variables d'environnement de l'API Downward.
Avant d'utiliser cette fonctionnalité, vous devez activer la "feature gate" <code>VolumeSubpathEnvExpansion</code>.
Les propriétés <code>subPath</code> et <code>subPathExpr</code> sont mutuellement exclusives.</p><p>Dans cet exemple, un Pod utilise <code>subPathExpr</code> pour créer un dossier <code>pod1</code> à l'intérieur du volume hostPath <code>/var/log/pods</code>, en utilisant le nom du pod depuis l'API Downward.
Le dossier hôte <code>/var/log/pods/pod1</code> est monté sur <code>/logs</code> dans le conteneur.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>pod1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>container1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>env</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>POD_NAME<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>valueFrom</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>fieldRef</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>fieldPath</span>:<span style=color:#bbb> </span>metadata.name<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>busybox<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>command</span>:<span style=color:#bbb> </span>[<span style=color:#bbb> </span><span style=color:#b44>&#34;sh&#34;</span>,<span style=color:#bbb> </span><span style=color:#b44>&#34;-c&#34;</span>,<span style=color:#bbb> </span><span style=color:#b44>&#34;while [ true ]; do echo &#39;Hello&#39;; sleep 10; done | tee -a /logs/hello.txt&#34;</span><span style=color:#bbb> </span>]<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>volumeMounts</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>workdir1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>mountPath</span>:<span style=color:#bbb> </span>/logs<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>subPathExpr</span>:<span style=color:#bbb> </span>$(POD_NAME)<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>restartPolicy</span>:<span style=color:#bbb> </span>Never<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>volumes</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>workdir1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>hostPath</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>path</span>:<span style=color:#bbb> </span>/var/log/pods<span style=color:#bbb>
</span></span></span></code></pre></div><h2 id=ressources>Ressources</h2><p>Le support de stockage (Disk, SSD, etc.) d'un volume <code>emptyDir</code> est déterminé par le support du système de fichiers
contenant le dossier racine de kubelet (typiquement <code>/var/lib/kubelet</code>).
Il n'y a pas de limite sur l'espace qu'un volume <code>emptyDir</code> ou <code>hostPath</code> peut consommer
et pas d'isolation entre les conteneurs ou entre les Pods.</p><p>Dans le futur, il est prévu que les volumes <code>emptyDir</code> et <code>hostPath</code> soient en mesure de demander une certaine quantité d'espace en utilisant une spécification de <a href=/docs/user-guide/compute-resources>ressource</a> et de sélectionner un type de support à utiliser, pour les clusters qui ont plusieurs types de support.</p><h2 id=plugins-de-volume-out-of-tree>Plugins de volume Out-of-Tree</h2><p>Les plugins de volume Out-of-tree incluent l'interface CSI (Container Storage Interface) et FlexVolume.
Ils permettent aux fournisseurs de stockage de créer des plugins de stockage personnalisés sans les ajouter au dépôt Kubernetes.</p><p>Avant l'introduction de l'interface CSI et FlexVolume, tous les plugins de volume (tels que les types de volume listés plus haut) étaient "in-tree", ce qui signifie qu'ils étaient construits, liés, compilés et livrés avec les binaires de base Kubernetes et étendent l'API Kubernetes de base.
Cela signifiait que l'ajout d'un nouveau système de stockage à Kubernetes (un plugin de volume) requérait de vérifier le code dans le dépôt de base de Kubernetes.</p><p>CSI et FlexVolume permettent à des plugins de volume d'être développés indépendamment de la base de code Kubernetes et déployés (installés) sur des clusters Kubernetes en tant qu'extensions.</p><p>Pour les fournisseurs de stockage qui cherchent à créer un plugin de volume "out-of-tree", se référer à <a href=https://github.com/kubernetes/community/blob/master/sig-storage/volume-plugin-faq.md>cette FAQ</a>.</p><h3 id=csi>CSI</h3><p>L'interface <a href=https://github.com/container-storage-interface/spec/blob/master/spec.md>Container Storage Interface</a> (CSI) définit une interface standard pour les systèmes d'orchestration de conteneurs (comme Kubernetes) pour exposer des systèmes de stockage arbitraires aux charges de travail de leurs conteneurs.</p><p>Pour plus d'informations, lire la <a href=https://github.com/kubernetes/community/blob/master/contributors/design-proposals/storage/container-storage-interface.md>proposition de conception CSI</a>.</p><p>Le support CSI a été introduit en alpha à partir de Kubernetes v1.9, a évolué en beta dans Kubernetes v1.10 et est en disponibilité générale (GA) depuis Kubernetes v1.13.</p><div class="alert alert-info note callout" role=alert><strong>Note:</strong> Le support des versions spec CSI 0.2 et 0.3 sont obsolètes dans Kubernetes v1.13 et seront retirés dans une version future.</div><div class="alert alert-info note callout" role=alert><strong>Note:</strong> Les pilotes CSI peuvent ne pas être compatibles avec toutes les versions de Kubernetes.
Vérifier la documentation des pilotes CSI spécifiques pour les étapes de déploiement supportées pour chaque version de Kubernetes et la matrice de compatibilité.</div><p>Une fois qu'un pilote de volume CSI compatible est déployé dans un cluster Kubernetes, les utilisateurs peuvent
utiliser le type de volume <code>csi</code> pour attacher, monter, etc.., les volumes exposés par le pilote CSI.</p><p>Le type de volume <code>csi</code> ne supporte pas de référence directe depuis un Pod et ne peut être référencé seulement dans un Pod que par un objet <code>PersistentVolumeClaim</code>.</p><p>Les champs suivants sont disponibles aux administrateurs de stockage pour configurer un volume persistant CSI :</p><ul><li><code>driver</code>: Une valeur texte qui spécifie le nom du pilote de volume à utiliser.
Cette valeur doit correspondre à la valeur retournée dans le <code>GetPluginInfoResponse</code> par le pilote CSI tel que défini dans la
<a href=https://github.com/container-storage-interface/spec/blob/master/spec.md#getplugininfo>spec CSI</a>.
Elle est utilisée par Kubernetes pour identifier le pilote CSI à appeler et par les composants du pilote CSI
pour identifier quels objets PV appartiennent au pilote CSI.</li><li><code>volumeHandle</code>: Une valeur texte qui identifie le volume de manière unique. Cette valeur doit correspondre à la valeur retournée dans le champ <code>volume.id</code> de <code>CreateVolumeResponse</code> par le pilote CSI tel que défini dans la <a href=https://github.com/container-storage-interface/spec/blob/master/spec.md#createvolume>spec CSI</a>.
La valeur est passée en tant que <code>volume_id</code> sur tous les appels au pilote de volume CSI lorsque le volume est référencé.</li><li><code>readOnly</code>: Une valeur booléenne optionnelle indiquant si le volume doit être
"ControllerPublished" (attaché) en lecture seule. La valeur par défaut est "false". Cette valeur est passées au pilote CSI
via le champ <code>readonly</code> dans le <code>ControllerPublishVolumeRequest</code>.</li><li><code>fsType</code>: Si le <code>VolumeMode</code> du PV est <code>Filesystem</code>, alors ce champ peut être utilisé pour spécifier le système de fichiers
qui devrait être utilisé pour monter le volume. Si le volume n'a pas été formaté et que le formatage est supporté, cette valeur sera
utilisée pour formater le volume.
Cette valeur est passée au pilote CSI driver via le champ <code>VolumeCapability</code> de
<code>ControllerPublishVolumeRequest</code>, <code>NodeStageVolumeRequest</code>, et
<code>NodePublishVolumeRequest</code>.</li><li><code>volumeAttributes</code>: Un tableau associatif (map) string vers string qui spécifie les propriétés statiques d'un volume. Ce tableau associatif doit correspondre à celui retourné dans le champ
<code>volume.attributes</code> du <code>CreateVolumeResponse</code> par le pilote CSI tel que défini dans
la <a href=https://github.com/container-storage-interface/spec/blob/master/spec.md#createvolume>spec CSI</a>.
Le tableau associatif est passé au pilote CSI via le champ <code>volume_attributes</code> dans la <code>ControllerPublishVolumeRequest</code>, <code>NodeStageV olumeRequest</code>, et <code>NodePublishVolumeRequest</code>.</li><li><code>controllerPublishSecretRef</code>: Une référence de l'objet de type secret contenant des informations sensibles à passer
au driver CSI pour compléter les appels CSI <code>ControllerPublishVolume</code> et <code>ControllerUnpublishVolume</code>.
Ce champ est optionnel et peut être vide si aucun secret n'est requis.
Si l'objet secret contient plus qu'un secret, tous les secrets sont passés.</li><li><code>nodeStageSecretRef</code>: Une référence à l'objet de type secret contenant des informations sensibles à passer au pilote CSI
pour compléter l'appel CSI <code>NodeStageVolume</code>. Ce champ est optionnel et peut être vide si aucun secret n'est requis.
Si l'objet secret contient plus qu'un secret, tous les secrets sont passés.</li><li><code>nodePublishSecretRef</code>: Une référence vers l'objet de type secret contenant des informations sensibles à passer au pilote CSI
pour compléter l'appel CSI <code>NodePublishVolume</code>. Ce champ est optionnel et peut être vide si aucun secret n'est requis.
Si l'objet secret contient plus qu'un secret, tous les secrets sont passés.</li></ul><h4 id=support-de-volume-bloc-brut-csi>Support de volume bloc brut CSI</h4><div style=margin-top:10px;margin-bottom:10px><b>FEATURE STATE:</b> <code>Kubernetes v1.14 [beta]</code></div><p>À partir de la version 1.11, CSI a introduit le support des volumes bloc bruts, qui s'appuient
sur la fonctionnalité de volume bloc brut introduite dans une version précédente de Kubernetes.
Cette fonctionnalité va permettre aux fournisseurs avec des pilotes CSI externes d'implémenter le support pour les volumes bloc bruts
dans les charges de travail Kubernetes.</p><p>Le support volume bloc CSI est une "feature-gate", mais est activée par défaut. Les deux
"feature gates" qui doivent être activées pour cette fonctionnalité sont <code>BlockVolume</code> et <code>CSIBlockVolume</code>.</p><p>Apprenez comment <a href=/docs/concepts/storage/persistent-volumes/#raw-block-volume-support>configurer votre PV/PVC avec le support de volume bloc brut</a>.</p><h4 id=volumes-csi-éphémères>Volumes CSI éphémères</h4><div style=margin-top:10px;margin-bottom:10px><b>FEATURE STATE:</b> <code>Kubernetes v1.15 [alpha]</code></div><p>Cette fonctionnalité permet aux volumes CSI d'être embarqués directement dans la spécification du Pod au lieu de celle d'un PersistentVolume. Les Volumes spécifiés de cette manière sont éphémères et ne persistent pas lorsque le Pod redémarre.</p><p>Exemple :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>my-csi-app<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>my-frontend<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>busybox<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>volumeMounts</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- <span style=color:green;font-weight:700>mountPath</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;/data&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>my-csi-inline-vol<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>command</span>:<span style=color:#bbb> </span>[<span style=color:#bbb> </span><span style=color:#b44>&#34;sleep&#34;</span>,<span style=color:#bbb> </span><span style=color:#b44>&#34;1000000&#34;</span><span style=color:#bbb> </span>]<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>volumes</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>my-csi-inline-vol<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>csi</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>driver</span>:<span style=color:#bbb> </span>inline.storage.kubernetes.io<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>volumeAttributes</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>              </span><span style=color:green;font-weight:700>foo</span>:<span style=color:#bbb> </span>bar<span style=color:#bbb>
</span></span></span></code></pre></div><p>Cette fonctionnalité requiert l'activation de la "feature gate" CSIInlineVolume :</p><pre tabindex=0><code>--feature-gates=CSIInlineVolume=true
</code></pre><p>Les volumes éphémères CSI sont seulement supportés par un sous-ensemble des pilotes CSI. La liste des pilotes CSI est disponible <a href=https://kubernetes-csi.github.io/docs/drivers.html>ici</a>.</p><h1 id=ressources-pour-développeur>Ressources pour développeur</h1><p>Pour plus d'informations sur la manière de développer un pilote CSI, se référer à la <a href=https://kubernetes-csi.github.io/docs/>documentation kubernetes-csi</a></p><h4 id=migration-de-pilotes-csi-depuis-des-plugins-in-tree>Migration de pilotes CSI depuis des plugins "in-tree"</h4><div style=margin-top:10px;margin-bottom:10px><b>FEATURE STATE:</b> <code>Kubernetes v1.14 [alpha]</code></div><p>La fonctionnalité de migration CSI, lorsque activée, dirige les opérations sur les plugins "in-tree" existants vers les plugins CSI correspondants (qui sont sensés être installés et configurés).
Cette fonctionnalité implémente la logique de translation nécessaire et les fixations nécessaires pour rerouter les opérations
de manière transparente. En conséquence, les opérateurs n'ont pas à effectuer de changements de configuration aux classes de stockage (Storage Classes) existantes, PV ou PVC (référençant aux plugins "in-tree") lors de la transition vers un pilote CSI qui remplace un plugin "in-tree".</p><p>Dans l'état alpha, les opérations et fonctionnalités qui sont supportées incluent provisionnement/suppression, attachement/détachement, montage/démontage et le redimensionnement des volumes.</p><p>Les plugins "in-tree" qui supportent la migration CSI et qui ont un pilote CSI correspondant implémenté sont listés dans la section "Types de volumes" au-dessus.</p><h3 id=flexVolume>FlexVolume</h3><p>FlexVolume est une interface de plugin "out-of-tree" qui existe dans Kubernetes depuis la version 1.2 (avant CSI).
Elle utilise un modèle basé sur exec pour s'interfacer avec les pilotes. Les binaires de pilote FlexVolume doivent être installés dans un chemin de volume de plugin prédéfini sur chaque nœud (et dans certains cas le nœud maître).</p><p>Les Pods interagissent avec les pilotes FlexVolume à travers le plugin "in-tree" <code>flexvolume</code>
Plus de détails sont disponibles <a href=https://github.com/kubernetes/community/blob/master/contributors/devel/sig-storage/flexvolume.md>ici</a>.</p><h2 id=propagation-de-montage>Propagation de montage</h2><p>La propagation de montage permet à des volumes partagés montés par un conteneur à d'autres conteneurs dans un même Pod, ou même à d'autres Pods dans le même nœud.</p><p>La propagation de montage d'un volume est contrôlée par le champ <code>mountPropagation</code> dans Container.volumeMounts.
Ses valeurs sont :</p><ul><li><p><code>None</code> - Ce montage de volume ne recevra aucun montage subséquent qui est monté à ce volume ou n'importe lequel de ses sous-dossiers par l'hôte. De la même manière, aucun montage créé par le conteneur ne sera visible sur l'hôte. C'est le mode par défaut.</p><p>Ce mode équivaut à une propagation de montage <code>private</code> tel que décrit dans la <a href=https://www.kernel.org/doc/Documentation/filesystems/sharedsubtree.txt>documentation du noyau Linux</a></p></li><li><p><code>HostToContainer</code> - Ce montage de volume recevra les montages subséquents qui sont montés sur ce volume ou n'importe lequel de ses sous-dossiers.</p><p>En d'autres termes, si l'hôte monte quoi que ce soit dans le montage de volume, le conteneur va le voir monté à cet endroit.</p><p>De manière similaire, si un Pod avec la propagation de montage <code>Bidirectional</code> vers le même volume y monte quoi que ce soit,
le conteneur avec la propagation de montage <code>HostToContainer</code> le verra.</p><p>Ce mode est équivalent à la propagation de montage <code>rslave</code> tel que décrit dans la
<a href=https://www.kernel.org/doc/Documentation/filesystems/sharedsubtree.txt>documentation du noyau Linux</a></p></li><li><p><code>Bidirectional</code> - Ce montage de volume se comporte de la même manière que le montage <code>HostToContainer</code>.
De plus, tous les montages de volume créés par le conteneur seront propagés à l'hôte et à tous les conteneurs des autres Pods qui utilisent le même volume.</p><p>Un cas d'utilisation typique pour ce mode est un Pod avec un FlexVolume ou un pilote CSI, ou un Pod qui nécessite de monter quelque chose sur l'hôte en utilisant un volume <code>hostPath</code>.</p><p>Ce mode est équivalent à une propagation de montage <code>rshared</code> tel que décrit dans la
<a href=https://www.kernel.org/doc/Documentation/filesystems/sharedsubtree.txt>documentation du noyau Linux</a></p></li></ul><div class="alert alert-warning caution callout" role=alert><strong>Avertissement:</strong> La propagation de montage <code>Bidirectional</code> peut être dangereuse. Elle peut endommager le système d'exploitation hôte
et est donc autorisée seulement dans des conteneurs privilégiés.
Il est fortement recommandé d'être familier avec le comportement du noyau Linux.
De plus, tous les montages de volume créés par des conteneurs dans des Pods doivent être détruits (démontés) par les conteneurs lors de la terminaison.</div><h3 id=configuration>Configuration</h3><p>Avant que la propagation de montage puisse fonctionner correctement sur certains déploiements (CoreOS,
RedHat/Centos, Ubuntu) le partage de montage doit être correctement configuré dans Docker tel qu'illustré ci-dessous :</p><p>Modifiez le fichier de service <code>systemd</code> de votre Docker. Configurez votre <code>MountFlags</code> comme suit :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span><span style=color:#b8860b>MountFlags</span><span style=color:#666>=</span>shared
</span></span></code></pre></div><p>Ou bien retirez <code>MountFlags=slave</code> si présent. Redémarrez ensuite le démon Docker :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>sudo systemctl daemon-reload
</span></span><span style=display:flex><span>sudo systemctl restart docker
</span></span></code></pre></div><h2 id=a-suivre>A suivre</h2><ul><li>Suivez un exemple de <a href=/docs/tutorials/stateful-application/mysql-wordpress-persistent-volume/>déploiement de WordPress et MySQL avec des volumes persistants</a>.</li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-ffd12528a12882b282e1bd19e29f9e75>3.6.2 - Volumes persistants</h1><p>Ce document décrit l'état actuel de <code>PersistentVolumes</code> dans Kubernetes.
Une connaissance des <a href=/fr/docs/concepts/storage/volumes/>volumes</a> est suggérée.</p><h2 id=introduction>Introduction</h2><p>La gestion du stockage est un problème distinct de la gestion des instances de calcul.
Le sous-système <code>PersistentVolume</code> fournit une API pour les utilisateurs et les administrateurs qui abstrait les détails de la façon dont le stockage est fourni et de la façon dont il est utilisé.
Pour ce faire, nous introduisons deux nouvelles ressources API: <code>PersistentVolume</code> et <code>PersistentVolumeClaim</code>.</p><p>Un <code>PersistentVolume</code> (PV) est un élément de stockage dans le cluster qui a été provisionné par un administrateur ou provisionné dynamiquement à l'aide de <a href=/docs/concepts/storage/storage-classes/>Storage Classes</a>.
Il s'agit d'une ressource dans le cluster, tout comme un nœud est une ressource de cluster.
Les PV sont des plugins de volume comme Volumes, mais ont un cycle de vie indépendant de tout pod individuel qui utilise le PV.
Cet objet API capture les détails de l'implémentation du stockage, que ce soit NFS, iSCSI ou un système de stockage spécifique au fournisseur de cloud.</p><p>Un <code>PersistentVolumeClaim</code> (PVC) est une demande de stockage par un utilisateur.
Il est similaire à un Pod.
Les pods consomment des ressources de noeud et les PVC consomment des ressources PV.
Les pods peuvent demander des niveaux spécifiques de ressources (CPU et mémoire).
Les PVC peuvent demander une taille et des modes d'accès spécifiques (par exemple, ils peuvent être montés une fois en lecture/écriture ou plusieurs fois en lecture seule).</p><p>Alors que les <code>PersistentVolumeClaims</code> permettent à un utilisateur de consommer des ressources de stockage abstraites, il est courant que les utilisateurs aient besoin de <code>PersistentVolumes</code> avec des propriétés et des performances variables pour différents problèmes.
Les administrateurs de cluster doivent être en mesure d'offrir une variété de <code>PersistentVolumes</code> qui diffèrent de bien des façons plus que la taille et les modes d'accès, sans exposer les utilisateurs aux détails de la façon dont ces volumes sont mis en œuvre.
Pour ces besoins, il existe la ressource <code>StorageClass</code>.</p><p>Voir la <a href=/docs/tasks/configure-pod-container/configure-persistent-volume-storage/>procédure détaillée avec des exemples</a>.</p><h2 id=cycle-de-vie-d-un-pv-et-d-un-pvc>Cycle de vie d'un PV et d'un PVC</h2><p>Les PV sont des ressources du cluster.
Les PVC sont des demandes pour ces ressources et agissent également comme des contrôles de réclamation pour la ressource.
L'interaction entre les PV et les PVC suit ce cycle de vie:</p><h3 id=provisionnement>Provisionnement</h3><p>Les PV peuvent être provisionnés de deux manières: statiquement ou dynamiquement.</p><h4 id=provisionnement-statique>Provisionnement statique</h4><p>Un administrateur de cluster crée un certain nombre de PV.
Ils contiennent les détails du stockage réel, qui est disponible pour une utilisation par les utilisateurs du cluster.
Ils existent dans l'API Kubernetes et sont disponibles pour la consommation.</p><h4 id=provisionnement-dynamique>Provisionnement dynamique</h4><p>Lorsqu'aucun des PV statiques créés par l'administrateur ne correspond au <code>PersistentVolumeClaim</code> d'un utilisateur, le cluster peut essayer de provisionner dynamiquement un volume spécialement pour le PVC.
Ce provisionnement est basé sur les <code>StorageClasses</code>: le PVC doit demander une <a href=/docs/concepts/storage/storage-classes/>storage class</a> et l'administrateur doit avoir créé et configuré cette classe pour que l'approvisionnement dynamique se produise.
Les PVC qui demandent la classe <code>""</code> désactive le provisionnement dynamique pour eux-mêmes.</p><p>Pour activer le provisionnement de stockage dynamique basé sur la classe de stockage, l'administrateur de cluster doit activer le <code>DefaultStorageClass</code> dans l'<a href=/docs/reference/access-authn-authz/admission-controllers/#defaultstorageclass>contrôleur d'admission</a> sur le serveur API.
Cela peut être fait, par exemple, en veillant à ce que <code>DefaultStorageClass</code> figure parmi la liste de valeurs séparées par des virgules pour l'option <code>--enable-admission-plugins</code> du composant serveur API.
Pour plus d'informations sur les options de ligne de commande du serveur API, consultez la documentation <a href=/docs/admin/kube-apiserver/>kube-apiserver</a>.</p><h3 id=liaison>Liaison</h3><p>Un utilisateur crée, ou dans le cas d'un provisionnement dynamique, a déjà créé, un <code>PersistentVolumeClaim</code> avec une quantité spécifique de stockage demandée et avec certains modes d'accès.
Une boucle de contrôle dans le maître surveille les nouveaux PVC, trouve un PV correspondant (si possible) et les lie ensemble.
Si un PV a été dynamiquement provisionné pour un nouveau PVC, la boucle liera toujours ce PV au PVC.
Sinon, l'utilisateur obtiendra toujours au moins ce qu'il a demandé, mais le volume peut être supérieur à ce qui a été demandé.
Une fois liées, les liaisons <code>PersistentVolumeClaim</code> sont exclusives, quelle que soit la façon dont elles ont été liées.
Une liaison PVC-PV est une relation 1-à-1.</p><p>Les PVC resteront non liés indéfiniment s'il n'existe pas de volume correspondant.
Le PVC sera lié à mesure que les volumes correspondants deviendront disponibles.
Par exemple, un cluster provisionné avec de nombreux PV 50Gi ne correspondrait pas à un PVC demandant 100Gi.
Le PVC peut être lié lorsqu'un PV 100Gi est ajouté au cluster.</p><h3 id=utilisation>Utilisation</h3><p>Les Pods utilisent les PVC comme des volumes.
Le cluster inspecte le PVC pour trouver le volume lié et monte ce volume pour un Pod.
Pour les volumes qui prennent en charge plusieurs modes d'accès, l'utilisateur spécifie le mode souhaité lors de l'utilisation de leur PVC comme volume dans un Pod.</p><p>Une fois qu'un utilisateur a un PVC et que ce PVC est lié, le PV lié appartient à l'utilisateur aussi longtemps qu'il en a besoin.
Les utilisateurs planifient des pods et accèdent à leurs PV revendiqués en incluant un <code>persistentVolumeClaim</code> dans le bloc de volumes de leur Pod <a href=#claims-as-volumes>Voir ci-dessous pour les détails de la syntaxe</a>.</p><h3 id=protection-de-l-objet-de-stockage-en-cours-d-utilisation>Protection de l'objet de stockage en cours d'utilisation</h3><p>Le but de la fonction de protection des objets de stockage utilisés est de garantir que les revendications de volume persistantes (PVC) en cours d'utilisation par un Pod et les volumes persistants (PV) liés aux PVC ne sont pas supprimées du système, car cela peut entraîner des pertes de données.</p><div class="alert alert-info note callout" role=alert><strong>Note:</strong> Le PVC est utilisé activement par un pod lorsqu'il existe un objet Pod qui utilise le PVC.</div><p>Si un utilisateur supprime un PVC en cours d'utilisation par un pod, le PVC n'est pas supprimé immédiatement.
L'élimination du PVC est différée jusqu'à ce que le PVC ne soit plus activement utilisé par les pods.
De plus, si un administrateur supprime un PV lié à un PVC, le PV n'est pas supprimé immédiatement.
L'élimination du PV est différée jusqu'à ce que le PV ne soit plus lié à un PVC.</p><p>Vous pouvez voir qu'un PVC est protégé lorsque son état est <code>Terminating</code> et la liste <code>Finalizers</code> inclus <code>kubernetes.io/pvc-protection</code>:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-text data-lang=text><span style=display:flex><span>kubectl describe pvc hostpath
</span></span><span style=display:flex><span>Name:          hostpath
</span></span><span style=display:flex><span>Namespace:     default
</span></span><span style=display:flex><span>StorageClass:  example-hostpath
</span></span><span style=display:flex><span>Status:        Terminating
</span></span><span style=display:flex><span>Volume:
</span></span><span style=display:flex><span>Labels:        &lt;none&gt;
</span></span><span style=display:flex><span>Annotations:   volume.beta.kubernetes.io/storage-class=example-hostpath
</span></span><span style=display:flex><span>               volume.beta.kubernetes.io/storage-provisioner=example.com/hostpath
</span></span><span style=display:flex><span>Finalizers:    [kubernetes.io/pvc-protection]
</span></span><span style=display:flex><span>...
</span></span></code></pre></div><p>Vous pouvez voir qu'un PV est protégé lorsque son état est <code>Terminating</code> et la liste <code>Finalizers</code> inclus <code>kubernetes.io/pv-protection</code> aussi:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-text data-lang=text><span style=display:flex><span>kubectl describe pv task-pv-volume
</span></span><span style=display:flex><span>Name:            task-pv-volume
</span></span><span style=display:flex><span>Labels:          type=local
</span></span><span style=display:flex><span>Annotations:     &lt;none&gt;
</span></span><span style=display:flex><span>Finalizers:      [kubernetes.io/pv-protection]
</span></span><span style=display:flex><span>StorageClass:    standard
</span></span><span style=display:flex><span>Status:          Available
</span></span><span style=display:flex><span>Claim:
</span></span><span style=display:flex><span>Reclaim Policy:  Delete
</span></span><span style=display:flex><span>Access Modes:    RWO
</span></span><span style=display:flex><span>Capacity:        1Gi
</span></span><span style=display:flex><span>Message:
</span></span><span style=display:flex><span>Source:
</span></span><span style=display:flex><span>    Type:          HostPath (bare host directory volume)
</span></span><span style=display:flex><span>    Path:          /tmp/data
</span></span><span style=display:flex><span>    HostPathType:
</span></span><span style=display:flex><span>Events:            &lt;none&gt;
</span></span></code></pre></div><h3 id=récupération-des-volumes>Récupération des volumes</h3><p>Lorsqu'un utilisateur a terminé avec son volume, il peut supprimer les objets PVC de l'API qui permet la récupération de la ressource.
La politique de récupération pour un <code>PersistentVolume</code> indique au cluster ce qu'il doit faire du volume une fois qu'il a été libéré de son PVC.
Actuellement, les volumes peuvent être conservés, recyclés ou supprimés.</p><h4 id=volumes-conservés>Volumes conservés</h4><p>La politique de récupération <code>Retain</code> permet la récupération manuelle de la ressource.
Lorsque le <code>PersistentVolumeClaim</code> est supprimé, le <code>PersistentVolume</code> existe toujours et le volume est considéré comme «libéré».
Mais il n'est pas encore disponible pour une autre demande car les données du demandeur précédent restent sur le volume.
Un administrateur peut récupérer manuellement le volume en procédant comme suit.</p><ol><li>Supprimer le <code>PersistentVolume</code>.
L'actif de stockage associé dans une infrastructure externe (comme un volume AWS EBS, GCE PD, Azure Disk ou Cinder) existe toujours après la suppression du PV.</li><li>Nettoyez manuellement les données sur l'actif de stockage associé en conséquence.</li><li>Supprimez manuellement l'actif de stockage associé ou, si vous souhaitez réutiliser le même actif de stockage, créez un nouveau <code>PersistentVolume</code> avec la définition de l'actif de stockage.</li></ol><h4 id=volumes-supprimés>Volumes supprimés</h4><p>Pour les plug-ins de volume qui prennent en charge la stratégie de récupération <code>Delete</code>, la suppression supprime à la fois l'objet <code>PersistentVolume</code> de Kubernetes, ainsi que l'actif de stockage associé dans l'infrastructure externe, tel qu'un volume AWS EBS, GCE PD, Azure Disk ou Cinder.
Les volumes qui ont été dynamiquement provisionnés héritent de la <a href=#politique-de-r%C3%A9cup%C3%A9ration>politique de récupération de leur <code>StorageClass</code></a>, qui par défaut est <code>Delete</code>.
L'administrateur doit configurer la <code>StorageClass</code> selon les attentes des utilisateurs; sinon, le PV doit être édité ou corrigé après sa création.
Voir <a href=/docs/tasks/administer-cluster/change-pv-reclaim-policy/>Modifier la politique de récupération d'un PersistentVolume</a>.</p><h4 id=volumes-recyclés>Volumes recyclés</h4><div class="alert alert-danger warning callout" role=alert><strong>Attention:</strong> La politique de récupération <code>Recycle</code> est obsolète.
Au lieu de cela, l'approche recommandée consiste à utiliser l'approvisionnement dynamique.</div><p>Si elle est prise en charge par le plug-in de volume sous-jacent, la stratégie de récupération <code>Recycle</code> effectue un nettoyage de base (<code>rm -rf /thevolume/*</code>) sur le volume et le rend à nouveau disponible pour une nouvelle demande.</p><p>Cependant, un administrateur peut configurer un modèle de module de recyclage personnalisé à l'aide des arguments de ligne de commande du gestionnaire de contrôleur Kubernetes, comme décrit <a href=/docs/admin/kube-controller-manager/>ici</a>.
Le modèle de pod de recycleur personnalisé doit contenir une définition de <code>volumes</code>, comme le montre l'exemple ci-dessous:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>pv-recycler<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>namespace</span>:<span style=color:#bbb> </span>default<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>restartPolicy</span>:<span style=color:#bbb> </span>Never<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>volumes</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>vol<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>hostPath</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>path</span>:<span style=color:#bbb> </span>/any/path/it/will/be/replaced<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>pv-recycler<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;k8s.gcr.io/busybox&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>command</span>:<span style=color:#bbb> </span>[<span style=color:#b44>&#34;/bin/sh&#34;</span>,<span style=color:#bbb> </span><span style=color:#b44>&#34;-c&#34;</span>,<span style=color:#bbb> </span><span style=color:#b44>&#34;test -e /scrub &amp;&amp; rm -rf /scrub/..?* /scrub/.[!.]* /scrub/*  &amp;&amp; test -z \&#34;$(ls -A /scrub)\&#34; || exit 1&#34;</span>]<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>volumeMounts</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>vol<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>mountPath</span>:<span style=color:#bbb> </span>/scrub<span style=color:#bbb>
</span></span></span></code></pre></div><p>Cependant, le chemin particulier spécifié dans la partie <code>volumes</code> du template personnalisé de Pod est remplacée par le chemin particulier du volume qui est recyclé.</p><h3 id=redimensionnement-des-pvc>Redimensionnement des PVC</h3><div style=margin-top:10px;margin-bottom:10px><b>FEATURE STATE:</b> <code>Kubernetes v1.11 [beta]</code></div><p>La prise en charge du redimensionnement des PersistentVolumeClaims (PVCs) est désormais activée par défaut.
Vous pouvez redimensionner les types de volumes suivants:</p><ul><li>gcePersistentDisk</li><li>awsElasticBlockStore</li><li>Cinder</li><li>glusterfs</li><li>rbd</li><li>Azure File</li><li>Azure Disk</li><li>Portworx</li><li>FlexVolumes</li><li>CSI</li></ul><p>Vous ne pouvez redimensionner un PVC que si le champ <code>allowVolumeExpansion</code> de sa classe de stockage est défini sur true.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>storage.k8s.io/v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>StorageClass<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>gluster-vol-default<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>provisioner</span>:<span style=color:#bbb> </span>kubernetes.io/glusterfs<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>parameters</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>resturl</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;http://192.168.10.100:8080&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>restuser</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>secretNamespace</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>secretName</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>allowVolumeExpansion</span>:<span style=color:#bbb> </span><span style=color:#a2f;font-weight:700>true</span><span style=color:#bbb>
</span></span></span></code></pre></div><p>Pour demander un volume plus important pour un PVC, modifiez l'objet PVC et spécifiez une taille plus grande.
Cela déclenche l'expansion du volume qui soutient le <code>PersistentVolume</code> sous-jacent.
Un nouveau <code>PersistentVolume</code> n'est jamais créé pour satisfaire la demande.
Au lieu de cela, un volume existant est redimensionné.</p><h4 id=redimensionnement-de-volume-csi>Redimensionnement de volume CSI</h4><div style=margin-top:10px;margin-bottom:10px><b>FEATURE STATE:</b> <code>Kubernetes v1.24 [stable]</code></div><p>La prise en charge du redimensionnement des volumes CSI est activée par défaut, mais elle nécessite également un pilote CSI spécifique pour prendre en charge le redimensionnement des volumes.
Reportez-vous à la documentation du pilote CSI spécifique pour plus d'informations.</p><h4 id=redimensionner-un-volume-contenant-un-système-de-fichiers>Redimensionner un volume contenant un système de fichiers</h4><p>Vous ne pouvez redimensionner des volumes contenant un système de fichiers que si le système de fichiers est XFS, Ext3 ou Ext4.</p><p>Lorsqu'un volume contient un système de fichiers, le système de fichiers n'est redimensionné que lorsqu'un nouveau pod utilise le <code>PersistentVolumeClaim</code> en mode ReadWrite.
L'extension du système de fichiers est effectuée au démarrage d'un pod ou lorsqu'un pod est en cours d'exécution et que le système de fichiers sous-jacent prend en charge le redimensionnement en ligne.</p><p>FlexVolumes autorise le redimensionnement si le pilote est défini avec la capacité <code>requiresFSResize</code> sur <code>true</code>.
Le FlexVolume peut être redimensionné au redémarrage du pod.</p><h4 id=redimensionnement-d-un-persistentvolumeclaim-en-cours-d-utilisation>Redimensionnement d'un PersistentVolumeClaim en cours d'utilisation</h4><div style=margin-top:10px;margin-bottom:10px><b>FEATURE STATE:</b> <code>Kubernetes v1.15 [beta]</code></div><div class="alert alert-info note callout" role=alert><strong>Note:</strong> Redimensionner un PVCs à chaud est disponible en version bêta depuis Kubernetes 1.15 et en version alpha depuis 1.11.
La fonctionnalité <code>ExpandInUsePersistentVolumes</code> doit être activée, ce qui est le cas automatiquement pour de nombreux clusters de fonctionnalités bêta.
Se référer à la documentation de la <a href=/docs/reference/command-line-tools-reference/feature-gates/>feature gate</a> pour plus d'informations.</div><p>Dans ce cas, vous n'avez pas besoin de supprimer et de recréer un pod ou un déploiement qui utilise un PVC existant.
Tout PVC en cours d'utilisation devient automatiquement disponible pour son pod dès que son système de fichiers a été étendu.
Cette fonctionnalité n'a aucun effet sur les PVC qui ne sont pas utilisés par un pod ou un déploiement.
Vous devez créer un pod qui utilise le PVC avant que l'extension puisse se terminer.</p><p>Semblable à d'autres types de volume - les volumes FlexVolume peuvent également être étendus lorsqu'ils sont utilisés par un pod.</p><div class="alert alert-info note callout" role=alert><strong>Note:</strong> Le redimensionnement de FlexVolume n'est possible que lorsque le pilote sous-jacent prend en charge le redimensionnement.</div><div class="alert alert-info note callout" role=alert><strong>Note:</strong> L'augmentation des volumes EBS est une opération longue.
En outre, il existe un quota par volume d'une modification toutes les 6 heures.</div><h2 id=types-de-volumes-persistants>Types de volumes persistants</h2><p>Les types <code>PersistentVolume</code> sont implémentés en tant que plugins.
Kubernetes prend actuellement en charge les plugins suivants:</p><ul><li>GCEPersistentDisk</li><li>AWSElasticBlockStore</li><li>AzureFile</li><li>AzureDisk</li><li>CSI</li><li>FC (Fibre Channel)</li><li>FlexVolume</li><li>Flocker</li><li>NFS</li><li>iSCSI</li><li>RBD (Ceph Block Device)</li><li>CephFS</li><li>Cinder (OpenStack block storage)</li><li>Glusterfs</li><li>VsphereVolume</li><li>Quobyte Volumes</li><li>HostPath (Test de nœud unique uniquement -- le stockage local n'est en aucun cas pris en charge et NE FONCTIONNERA PAS dans un cluster à plusieurs nœuds)</li><li>Portworx Volumes</li><li>ScaleIO Volumes</li><li>StorageOS</li></ul><h2 id=volumes-persistants>Volumes persistants</h2><p>Chaque PV contient une spécification et un état, qui sont les spécifications et l'état du volume.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>PersistentVolume<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>pv0003<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>capacity</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>storage</span>:<span style=color:#bbb> </span>5Gi<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>volumeMode</span>:<span style=color:#bbb> </span>Filesystem<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>accessModes</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- ReadWriteOnce<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>persistentVolumeReclaimPolicy</span>:<span style=color:#bbb> </span>Recycle<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>storageClassName</span>:<span style=color:#bbb> </span>slow<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>mountOptions</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- hard<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- nfsvers=4.1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>nfs</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>path</span>:<span style=color:#bbb> </span>/tmp<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>server</span>:<span style=color:#bbb> </span><span style=color:#666>172.17.0.2</span><span style=color:#bbb>
</span></span></span></code></pre></div><div class="alert alert-info note callout" role=alert><strong>Note:</strong> Des logiciels additionnels supportant un type de montage de volume pourraient être nécessaires afin d'utiliser un PersistentVolume depuis un cluster.
Dans l'exemple d'un PersistentVolume de type NFS, le logiciel additionnel <code>/sbin/mount.nfs</code> est requis pour permettre de monter des systèmes de fichiers de type NFS.</div><h3 id=capacité>Capacité</h3><p>Généralement, un PV aura une capacité de stockage spécifique.
Ceci est réglé en utilisant l'attribut <code>capacity</code> des PV.
Voir le Kubernetes <a href=https://git.k8s.io/community/contributors/design-proposals/scheduling/resources.md>modèle de ressource</a> pour comprendre les unités attendues par <code>capacity</code>.</p><p>Actuellement, la taille du stockage est la seule ressource qui peut être définie ou demandée.
Les futurs attributs peuvent inclure les IOPS, le débit, etc.</p><h3 id=mode-volume>Mode volume</h3><div style=margin-top:10px;margin-bottom:10px><b>FEATURE STATE:</b> <code>Kubernetes v1.13 [beta]</code></div><p>Avant Kubernetes 1.9, tous les plug-ins de volume créaient un système de fichiers sur le volume persistant.
Maintenant, vous pouvez définir la valeur de <code>volumeMode</code> sur <code>block</code> pour utiliser un périphérique de bloc brut, ou <code>filesystem</code> pour utiliser un système de fichiers.
<code>filesystem</code> est la valeur par défaut si la valeur est omise.
Il s'agit d'un paramètre API facultatif.</p><h3 id=modes-d-accès>Modes d'accès</h3><p>Un <code>PersistentVolume</code> peut être monté sur un hôte de n'importe quelle manière prise en charge par le fournisseur de ressources.
Comme indiqué dans le tableau ci-dessous, les fournisseurs auront des capacités différentes et les modes d'accès de chaque PV sont définis sur les modes spécifiques pris en charge par ce volume particulier.
Par exemple, NFS peut prendre en charge plusieurs clients en lecture/écriture, mais un PV NFS spécifique peut être exporté sur le serveur en lecture seule.
Chaque PV dispose de son propre ensemble de modes d'accès décrivant les capacités spécifiques de ce PV.</p><p>Les modes d'accès sont:</p><ul><li>ReadWriteOnce -- le volume peut être monté en lecture-écriture par un seul nœud</li><li>ReadOnlyMany -- le volume peut être monté en lecture seule par plusieurs nœuds</li><li>ReadWriteMany -- le volume peut être monté en lecture-écriture par de nombreux nœuds</li></ul><p>Dans la CLI, les modes d'accès sont abrégés comme suit:</p><ul><li>RWO - ReadWriteOnce</li><li>ROX - ReadOnlyMany</li><li>RWX - ReadWriteMany</li></ul><blockquote><p><strong>Important!</strong> Un volume ne peut être monté qu'en utilisant un seul mode d'accès à la fois, même s'il prend en charge plusieurs.
Par exemple, un GCEPersistentDisk peut être monté en tant que ReadWriteOnce par un seul nœud ou ReadOnlyMany par plusieurs nœuds, mais pas en même temps.</p></blockquote><table><thead><tr><th style=text-align:center>Volume Plugin</th><th style=text-align:center>ReadWriteOnce</th><th style=text-align:center>ReadOnlyMany</th><th style=text-align:center>ReadWriteMany</th></tr></thead><tbody><tr><td style=text-align:center>AWSElasticBlockStore</td><td style=text-align:center>✓</td><td style=text-align:center>-</td><td style=text-align:center>-</td></tr><tr><td style=text-align:center>AzureFile</td><td style=text-align:center>✓</td><td style=text-align:center>✓</td><td style=text-align:center>✓</td></tr><tr><td style=text-align:center>AzureDisk</td><td style=text-align:center>✓</td><td style=text-align:center>-</td><td style=text-align:center>-</td></tr><tr><td style=text-align:center>CephFS</td><td style=text-align:center>✓</td><td style=text-align:center>✓</td><td style=text-align:center>✓</td></tr><tr><td style=text-align:center>Cinder</td><td style=text-align:center>✓</td><td style=text-align:center>-</td><td style=text-align:center>-</td></tr><tr><td style=text-align:center>CSI</td><td style=text-align:center>dépend du pilote</td><td style=text-align:center>dépend du pilote</td><td style=text-align:center>dépend du pilote</td></tr><tr><td style=text-align:center>FC</td><td style=text-align:center>✓</td><td style=text-align:center>✓</td><td style=text-align:center>-</td></tr><tr><td style=text-align:center>FlexVolume</td><td style=text-align:center>✓</td><td style=text-align:center>✓</td><td style=text-align:center>dépend du pilote</td></tr><tr><td style=text-align:center>Flocker</td><td style=text-align:center>✓</td><td style=text-align:center>-</td><td style=text-align:center>-</td></tr><tr><td style=text-align:center>GCEPersistentDisk</td><td style=text-align:center>✓</td><td style=text-align:center>✓</td><td style=text-align:center>-</td></tr><tr><td style=text-align:center>Glusterfs</td><td style=text-align:center>✓</td><td style=text-align:center>✓</td><td style=text-align:center>✓</td></tr><tr><td style=text-align:center>HostPath</td><td style=text-align:center>✓</td><td style=text-align:center>-</td><td style=text-align:center>-</td></tr><tr><td style=text-align:center>iSCSI</td><td style=text-align:center>✓</td><td style=text-align:center>✓</td><td style=text-align:center>-</td></tr><tr><td style=text-align:center>Quobyte</td><td style=text-align:center>✓</td><td style=text-align:center>✓</td><td style=text-align:center>✓</td></tr><tr><td style=text-align:center>NFS</td><td style=text-align:center>✓</td><td style=text-align:center>✓</td><td style=text-align:center>✓</td></tr><tr><td style=text-align:center>RBD</td><td style=text-align:center>✓</td><td style=text-align:center>✓</td><td style=text-align:center>-</td></tr><tr><td style=text-align:center>VsphereVolume</td><td style=text-align:center>✓</td><td style=text-align:center>-</td><td style=text-align:center>- (fonctionne lorsque les pods sont colocalisés)</td></tr><tr><td style=text-align:center>PortworxVolume</td><td style=text-align:center>✓</td><td style=text-align:center>-</td><td style=text-align:center>✓</td></tr><tr><td style=text-align:center>ScaleIO</td><td style=text-align:center>✓</td><td style=text-align:center>✓</td><td style=text-align:center>-</td></tr><tr><td style=text-align:center>StorageOS</td><td style=text-align:center>✓</td><td style=text-align:center>-</td><td style=text-align:center>-</td></tr></tbody></table><h3 id=classe>Classe</h3><p>Un PV peut avoir une classe, qui est spécifiée en définissant l'attribut <code>storageClassName</code> sur le nom d'une <a href=/docs/concepts/storage/storage-classes/>StorageClass</a>.
Un PV d'une classe particulière ne peut être lié qu'à des PVC demandant cette classe.
Un PV sans <code>storageClassName</code> n'a pas de classe et ne peut être lié qu'à des PVC qui ne demandent aucune classe particulière.</p><p>Dans le passé, l'annotation <code>volume.beta.kubernetes.io/storage-class</code> a été utilisé à la place de l'attribut <code>storageClassName</code>.
Cette annotation fonctionne toujours; cependant, il deviendra complètement obsolète dans une future version de Kubernetes.</p><h3 id=politique-de-récupération>Politique de récupération</h3><p>Les politiques de récupération actuelles sont:</p><ul><li>Retain -- remise en état manuelle</li><li>Recycle -- effacement de base (<code>rm -rf /thevolume/*</code>)</li><li>Delete -- l'élément de stockage associé tel qu'AWS EBS, GCE PD, Azure Disk ou le volume OpenStack Cinder est supprimé</li></ul><p>Actuellement, seuls NFS et HostPath prennent en charge le recyclage.
Les volumes AWS EBS, GCE PD, Azure Disk et Cinder prennent en charge la suppression.</p><h3 id=options-de-montage>Options de montage</h3><p>Un administrateur Kubernetes peut spécifier des options de montage supplémentaires pour quand un <code>PersistentVolume</code> est monté sur un nœud.</p><div class="alert alert-info note callout" role=alert><strong>Note:</strong> Tous les types de volumes persistants ne prennent pas en charge les options de montage.</div><p>Les types de volume suivants prennent en charge les options de montage:</p><ul><li>AWSElasticBlockStore</li><li>AzureDisk</li><li>AzureFile</li><li>CephFS</li><li>Cinder (OpenStack block storage)</li><li>GCEPersistentDisk</li><li>Glusterfs</li><li>NFS</li><li>Quobyte Volumes</li><li>RBD (Ceph Block Device)</li><li>StorageOS</li><li>VsphereVolume</li><li>iSCSI</li></ul><p>Les options de montage ne sont pas validées, donc le montage échouera simplement si l'une n'est pas valide.</p><p>Dans le passé, l'annotation <code>volume.beta.kubernetes.io/mount-options</code> était utilisée à la place de l'attribut <code>mountOptions</code>.
Cette annotation fonctionne toujours; cependant, elle deviendra complètement obsolète dans une future version de Kubernetes.</p><h3 id=affinité-des-nœuds>Affinité des nœuds</h3><div class="alert alert-info note callout" role=alert><strong>Note:</strong> Pour la plupart des types de volume, vous n'avez pas besoin de définir ce champ.
Il est automatiquement rempli pour les volumes bloc de type <a href=/docs/concepts/storage/volumes/#awselasticblockstore>AWS EBS</a>, <a href=/docs/concepts/storage/volumes/#gcepersistentdisk>GCE PD</a> et <a href=/docs/concepts/storage/volumes/#azuredisk>Azure Disk</a>.
Vous devez définir explicitement ceci pour les volumes <a href=/docs/concepts/storage/volumes/#local>locaux</a>.</div><p>Un PV peut spécifier une <a href=/docs/reference/generated/kubernetes-api/v1.25/#volumenodeaffinity-v1-core>affinité de nœud</a> pour définir les contraintes qui limitent les nœuds à partir desquels ce volume est accessible.
Les pods qui utilisent un PV seront uniquement planifiés sur les nœuds sélectionnés par l'affinité de nœud.</p><h3 id=phase>Phase</h3><p>Un volume sera dans l'une des phases suivantes:</p><ul><li>Available -- une ressource libre qui n'est pas encore liée à une demande</li><li>Bound -- le volume est lié à une demande</li><li>Released -- la demande a été supprimée, mais la ressource n'est pas encore récupérée par le cluster</li><li>Failed -- le volume n'a pas réussi sa récupération automatique</li></ul><p>Le CLI affichera le nom du PVC lié au PV.</p><h2 id=persistentvolumeclaims>PersistentVolumeClaims</h2><p>Chaque PVC contient une spécification et un état, qui sont les spécifications et l'état de la réclamation.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>PersistentVolumeClaim<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>myclaim<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>accessModes</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- ReadWriteOnce<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>volumeMode</span>:<span style=color:#bbb> </span>Filesystem<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>resources</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>requests</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>storage</span>:<span style=color:#bbb> </span>8Gi<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>storageClassName</span>:<span style=color:#bbb> </span>slow<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>selector</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>matchLabels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>release</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;stable&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>matchExpressions</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- {<span style=color:green;font-weight:700>key: environment, operator: In, values</span>:<span style=color:#bbb> </span>[dev]}<span style=color:#bbb>
</span></span></span></code></pre></div><h3 id=modes-d-accès-1>Modes d'accès</h3><p>Les PVC utilisent les mêmes conventions que les volumes lorsque vous demandez un stockage avec des modes d'accès spécifiques.</p><h3 id=modes-de-volume>Modes de volume</h3><p>Les PVC utilisent la même convention que les volumes pour indiquer la consommation du volume en tant que système de fichiers ou périphérique de bloc.</p><h3 id=ressources>Ressources</h3><p>Les PVC, comme les pods, peuvent demander des quantités spécifiques d'une ressource.
Dans ce cas, la demande concerne le stockage.
Le même <a href=https://git.k8s.io/community/contributors/design-proposals/scheduling/resources.md>modèle de ressource</a> s'applique aux volumes et aux PVC.</p><h3 id=sélecteur>Sélecteur</h3><p>Les PVC peuvent spécifier un <a href=/docs/concepts/overview/working-with-objects/labels/#label-selectors>sélecteur de labels</a> pour filtrer davantage l'ensemble des volumes.
Seuls les volumes dont les étiquettes correspondent au sélecteur peuvent être liés au PVC.
Le sélecteur peut comprendre deux champs:</p><ul><li><code>matchLabels</code> - le volume doit avoir un label avec cette valeur</li><li><code>matchExpressions</code> - une liste des exigences définies en spécifiant la clé, la liste des valeurs et l'opérateur qui relie la clé et les valeurs.
Les opérateurs valides incluent In, NotIn, Exists et DoesNotExist.</li></ul><p>Toutes les exigences, à la fois de <code>matchLabels</code> et de <code>matchExpressions</code> doivent toutes être satisfaites pour correspondre (application d'un opérateur booléen ET).</p><h3 id=classe-1>Classe</h3><p>Un PVC peut demander une classe particulière en spécifiant le nom d'une <a href=/docs/concepts/storage/storage-classes/>StorageClass</a> en utilisant l'attribut <code>storageClassName</code>.
Seuls les PV de la classe demandée, ceux ayant le même <code>storageClassName</code> que le PVC, peuvent être liés au PVC.</p><p>Les PVC n'ont pas nécessairement à demander une classe.
Un PVC avec son attribut <code>storageClassName</code> égal à <code>""</code> est toujours interprété comme demandant un PV sans classe, il ne peut donc être lié qu'à des PV sans classe (pas d'annotation ou une annotation égal à <code>""</code>).
Un PVC sans <code>storageClassName</code> n'est pas tout à fait la même et est traité différemment par le cluster, selon que le <a href=/docs/reference/access-authn-authz/admission-controllers/#defaultstorageclass><code>DefaultStorageClass</code> admission plugin</a> est activé.</p><ul><li>Si le plug-in d'admission est activé, l'administrateur peut spécifier une valeur par défaut <code>StorageClass</code>.
Tous les PVC qui n'ont pas de <code>storageClassName</code> ne peuvent être liés qu'aux PV de cette valeur par défaut.
La spécification d'une <code>StorageClass</code> par défaut se fait en définissant l'annotation <code>storageclass.kubernetes.io/is-default-class</code> égal à <code>true</code> dans un objet <code>StorageClass</code>.
Si l'administrateur ne spécifie pas de valeur par défaut, le cluster répond à la création de PVC comme si le plug-in d'admission était désactivé.
Si plusieurs valeurs par défaut sont spécifiées, le plugin d'admission interdit la création de tous les PVC.</li><li>Si le plugin d'admission est désactivé, il n'y a aucune notion de défaut <code>StorageClass</code>.
Tous les PVC qui n'ont pas <code>storageClassName</code> peut être lié uniquement aux PV qui n'ont pas de classe.
Dans ce cas, les PVC qui n'ont pas <code>storageClassName</code> sont traités de la même manière que les PVC qui ont leur <code>storageClassName</code> égal à <code>""</code>.</li></ul><p>Selon la méthode d'installation, une <code>StorageClass</code> par défaut peut être déployée sur un cluster Kubernetes par le gestionnaire d'extensions pendant l'installation.</p><p>Lorsqu'un PVC spécifie un <code>selector</code> en plus de demander une <code>StorageClass</code>, les exigences sont ET ensemble: seul un PV de la classe demandée et avec les labels demandées peut être lié au PVC.</p><div class="alert alert-info note callout" role=alert><strong>Note:</strong> Actuellement, un PVC avec un <code>selector</code> non vide ne peut pas avoir un PV provisionné dynamiquement pour cela.</div><p>Dans le passé, l'annotation <code>volume.beta.kubernetes.io/storage-class</code> a été utilisé au lieu de l'attribut <code>storageClassName</code>.
Cette annotation fonctionne toujours; cependant, elle ne sera pas pris en charge dans une future version de Kubernetes.</p><h2 id=pvc-sous-forme-de-volumes>PVC sous forme de volumes</h2><p>Les pods accèdent au stockage en utilisant le PVC comme volume.
Les PVC et les pods qui les utilisent doivent exister dans le même namespace.
Le cluster trouve le PVC dans le namespace où se trouve le pod et l'utilise pour obtenir le <code>PersistentVolume</code> visé par le PVC.
Le volume est ensuite monté sur l'hôte et dans le pod.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>mypod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>myfrontend<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>nginx<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>volumeMounts</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- <span style=color:green;font-weight:700>mountPath</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;/var/www/html&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>mypd<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>volumes</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>mypd<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>persistentVolumeClaim</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>claimName</span>:<span style=color:#bbb> </span>myclaim<span style=color:#bbb>
</span></span></span></code></pre></div><h3 id=remarque-au-sujet-des-namespaces>Remarque au sujet des namespaces</h3><p>Les liaisons <code>PersistentVolumes</code> sont exclusives, et comme les objets <code>PersistentVolumeClaims</code> sont des objets vivant dans un namespace donné, le montage de PVC avec les modes "Many" (<code>ROX</code>, <code>RWX</code>) n'est possible qu'au sein d'un même namespace.</p><h2 id=prise-en-charge-du-volume-de-bloc-brut>Prise en charge du volume de bloc brut</h2><div style=margin-top:10px;margin-bottom:10px><b>FEATURE STATE:</b> <code>Kubernetes v1.13 [beta]</code></div><p>Les plug-ins de volume suivants prennent en charge les volumes de blocs bruts, y compris l'approvisionnement dynamique, le cas échéant:</p><ul><li>AWSElasticBlockStore</li><li>AzureDisk</li><li>FC (Fibre Channel)</li><li>GCEPersistentDisk</li><li>iSCSI</li><li>Local volume</li><li>RBD (Ceph Block Device)</li><li>VsphereVolume (alpha)</li></ul><div class="alert alert-info note callout" role=alert><strong>Note:</strong> Seuls les volumes FC et iSCSI prennent en charge les volumes de blocs bruts dans Kubernetes 1.9.
La prise en charge des plugins supplémentaires a été ajoutée dans 1.10.</div><h3 id=volumes-persistants-utilisant-un-volume-de-bloc-brut>Volumes persistants utilisant un volume de bloc brut</h3><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>PersistentVolume<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>block-pv<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>capacity</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>storage</span>:<span style=color:#bbb> </span>10Gi<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>accessModes</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- ReadWriteOnce<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>volumeMode</span>:<span style=color:#bbb> </span>Block<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>persistentVolumeReclaimPolicy</span>:<span style=color:#bbb> </span>Retain<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>fc</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>targetWWNs</span>:<span style=color:#bbb> </span>[<span style=color:#b44>&#34;50060e801049cfd1&#34;</span>]<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>lun</span>:<span style=color:#bbb> </span><span style=color:#666>0</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>readOnly</span>:<span style=color:#bbb> </span><span style=color:#a2f;font-weight:700>false</span><span style=color:#bbb>
</span></span></span></code></pre></div><h3 id=revendication-de-volume-persistant-demandant-un-volume-de-bloc-brut>Revendication de volume persistant demandant un volume de bloc brut</h3><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>PersistentVolumeClaim<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>block-pvc<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>accessModes</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- ReadWriteOnce<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>volumeMode</span>:<span style=color:#bbb> </span>Block<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>resources</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>requests</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>storage</span>:<span style=color:#bbb> </span>10Gi<span style=color:#bbb>
</span></span></span></code></pre></div><h3 id=spécification-de-pod-ajoutant-le-chemin-du-périphérique-de-bloc-brut-dans-le-conteneur>Spécification de pod ajoutant le chemin du périphérique de bloc brut dans le conteneur</h3><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>pod-with-block-volume<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>fc-container<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>fedora:26<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>command</span>:<span style=color:#bbb> </span>[<span style=color:#b44>&#34;/bin/sh&#34;</span>,<span style=color:#bbb> </span><span style=color:#b44>&#34;-c&#34;</span>]<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>args</span>:<span style=color:#bbb> </span>[<span style=color:#bbb> </span><span style=color:#b44>&#34;tail -f /dev/null&#34;</span><span style=color:#bbb> </span>]<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>volumeDevices</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>data<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>devicePath</span>:<span style=color:#bbb> </span>/dev/xvda<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>volumes</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>data<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>persistentVolumeClaim</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>claimName</span>:<span style=color:#bbb> </span>block-pvc<span style=color:#bbb>
</span></span></span></code></pre></div><div class="alert alert-info note callout" role=alert><strong>Note:</strong> Lorsque vous ajoutez un périphérique de bloc brut pour un pod, vous spécifiez le chemin de périphérique dans le conteneur au lieu d'un chemin de montage.</div><h3 id=lier-des-volumes-bloc-bruts>Lier des volumes bloc bruts</h3><p>Si un utilisateur demande un volume de bloc brut en l'indiquant à l'aide du champ <code>volumeMode</code> dans la spécification <code>PersistentVolumeClaim</code>, les règles de liaison diffèrent légèrement des versions précédentes qui ne considéraient pas ce mode comme faisant partie de la spécification.
Voici un tableau des combinaisons possibles que l'utilisateur et l'administrateur peuvent spécifier pour demander un périphérique de bloc brut.
Le tableau indique si le volume sera lié ou non compte tenu des combinaisons:
Matrice de liaison de volume pour les volumes provisionnés statiquement:</p><p>| PV volumeMode | PVC volumeMode | Result |
|---------------|-:-:------------|--:------|
| unspecified | unspecified | BIND |
| unspecified | Block | NO BIND |
| unspecified | Filesystem | BIND |
| Block | unspecified | NO BIND |
| Block | Block | BIND |
| Block | Filesystem | NO BIND |
| Filesystem | Filesystem | BIND |
| Filesystem | Block | NO BIND |
| Filesystem | unspecified | BIND |</p><div class="alert alert-info note callout" role=alert><strong>Note:</strong> Seuls les volumes provisionnés statiquement sont pris en charge pour la version alpha.
Les administrateurs doivent prendre en compte ces valeurs lorsqu'ils travaillent avec des périphériques de bloc brut.</div><h2 id=snapshot-et-restauration-de-volumes>Snapshot et restauration de volumes</h2><div style=margin-top:10px;margin-bottom:10px><b>FEATURE STATE:</b> <code>Kubernetes v1.12 [alpha]</code></div><p>La fonction de snapshot de volume a été ajoutée pour prendre en charge uniquement les plug-ins de volume CSI.
Pour plus de détails, voir <a href=/docs/concepts/storage/volume-snapshots/>volume snapshots</a>.</p><p>Pour activer la prise en charge de la restauration d'un volume à partir d'un snapshot de volume, activez la fonctionnalité <code>VolumeSnapshotDataSource</code> sur l'apiserver et le controller-manager.</p><h3 id=créer-du-pvc-à-partir-d-un-snapshot-de-volume>Créer du PVC à partir d'un snapshot de volume</h3><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>PersistentVolumeClaim<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>restore-pvc<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>storageClassName</span>:<span style=color:#bbb> </span>csi-hostpath-sc<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>dataSource</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>new-snapshot-test<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>VolumeSnapshot<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>apiGroup</span>:<span style=color:#bbb> </span>snapshot.storage.k8s.io<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>accessModes</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- ReadWriteOnce<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>resources</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>requests</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>storage</span>:<span style=color:#bbb> </span>10Gi<span style=color:#bbb>
</span></span></span></code></pre></div><h2 id=clonage-de-volume>Clonage de volume</h2><div style=margin-top:10px;margin-bottom:10px><b>FEATURE STATE:</b> <code>Kubernetes v1.16 [beta]</code></div><p>La fonctionnalité de clonage de volume a été ajoutée pour prendre en charge uniquement les plug-ins de volume CSI.
Pour plus de détails, voir <a href=/docs/concepts/storage/volume-pvc-datasource/>clonage de volume</a>.</p><p>Pour activer la prise en charge du clonage d'un volume à partir d'une source de données PVC, activez la propriété <code>VolumePVCDataSource</code> sur l'apiserver et le controller-manager.</p><h3 id=créer-un-pvc-à-partir-d-un-pvc-existant>Créer un PVC à partir d'un PVC existant</h3><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>PersistentVolumeClaim<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>cloned-pvc<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>storageClassName</span>:<span style=color:#bbb> </span>my-csi-plugin<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>dataSource</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>existing-src-pvc-name<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>PersistentVolumeClaim<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>accessModes</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- ReadWriteOnce<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>resources</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>requests</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>storage</span>:<span style=color:#bbb> </span>10Gi<span style=color:#bbb>
</span></span></span></code></pre></div><h2 id=écriture-d-une-configuration-portable>Écriture d'une configuration portable</h2><p>Si vous écrivez des templates de configuration ou des exemples qui s'exécutent sur une large gamme de clusters et nécessitent un stockage persistant, il est recommandé d'utiliser le modèle suivant:</p><ul><li>Incluez des objets <code>PersistentVolumeClaim</code> dans votre ensemble de config (aux côtés de <code>Deployments</code>, <code>ConfigMaps</code>, etc.).</li><li>N'incluez pas d'objets <code>PersistentVolume</code> dans la configuration, car l'utilisateur qui instancie la configuration peut ne pas être autorisé à créer des <code>PersistentVolumes</code>.</li><li>Donnez à l'utilisateur la possibilité de fournir un nom de classe de stockage lors de l'instanciation du template.<ul><li>Si l'utilisateur fournit un nom de classe de stockage, mettez cette valeur dans le champ <code>persistentVolumeClaim.storageClassName</code>.
Cela entraînera le PVC pour utiliser la bonne classe de stockage si le cluster a cette <code>StorageClasses</code> activé par l'administrateur.</li><li>Si l'utilisateur ne fournit pas de nom de classe de stockage, laissez le champ <code>persistentVolumeClaim.storageClassName</code> à zéro.
Cela entraînera un PV à être automatiquement provisionné pour l'utilisateur avec la <code>StorageClass</code> par défaut dans le cluster.
De nombreux environnements de cluster ont une <code>StorageClass</code> par défaut installée, où les administrateurs peuvent créer leur propre <code>StorageClass</code> par défaut.</li></ul></li><li>Dans votre outillage, surveillez les PVCs qui ne sont pas liés après un certain temps et signalez-le à l'utilisateur, car cela peut indiquer que le cluster n'a pas de support de stockage dynamique (auquel cas l'utilisateur doit créer un PV correspondant) ou que le cluster n'a aucun système de stockage (auquel cas l'utilisateur ne peut pas déployer de configuration nécessitant des PVCs).</li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-275bea454e1cf4c5adeca4058b5af988>3.7 - Configuration</h1></div><div class=td-content><h1 id=pg-e511ed821ada65d0053341dbd8ad2bb5>3.7.1 - Secrets</h1><p>Les objets <code>secret</code> de Kubernetes vous permettent de stocker et de gérer des informations sensibles, telles que les mots de passe, les jetons OAuth et les clés ssh.
Mettre ces informations dans un <code>secret</code> est plus sûr et plus flexible que de le mettre en dur dans la définition d'un <a class=glossary-tooltip title='Le plus petit et le plus simple des objets Kubernetes. Un Pod est un ensemble de conteneurs fonctionnant sur votre cluster.' data-toggle=tooltip data-placement=top href=/fr/docs/concepts/workloads/pods/pod-overview/ target=_blank aria-label=Pod>Pod</a> ou dans une <a class=glossary-tooltip title="Instance stockée d'un conteneur qui contient un ensemble de logiciels nécessaires à l'exécution d'une application." data-toggle=tooltip data-placement=top href='/fr/docs/reference/glossary/?all=true#term-image' target=_blank aria-label='container image'>container image</a>.
Voir <a href=https://github.com/kubernetes/design-proposals-archive/blob/main/auth/secrets.md>Document de conception des secrets</a> pour plus d'informations.</p><h2 id=présentation-des-secrets>Présentation des secrets</h2><p>Un secret est un objet qui contient une petite quantité de données sensibles telles qu'un mot de passe, un jeton ou une clé.
De telles informations pourraient autrement être placées dans une spécification de pod ou dans une image; le placer dans un objet secret permet de mieux contrôler la façon dont il est utilisé et réduit le risque d'exposition accidentelle.</p><p>Les utilisateurs peuvent créer des secrets et le système crée également des secrets.</p><p>Pour utiliser un secret, un pod doit référencer le secret.
Un secret peut être utilisé avec un pod de deux manières: sous forme de fichiers dans un <a class=glossary-tooltip title="Un répertoire contenant des données, accessible aux conteneurs d'un pod." data-toggle=tooltip data-placement=top href=/fr/docs/concepts/storage/volumes/ target=_blank aria-label=volume>volume</a> monté sur un ou plusieurs de ses conteneurs, ou utilisé par kubelet lorsque vous récupérez des images pour le pod.</p><h3 id=secrets-intégrés>Secrets intégrés</h3><h4 id=les-comptes-de-service-créent-et-attachent-automatiquement-des-secrets-avec-les-informations-d-identification-de-l-api>Les comptes de service créent et attachent automatiquement des secrets avec les informations d'identification de l'API</h4><p>Kubernetes crée automatiquement des secrets qui contiennent des informations d'identification pour accéder à l'API et il modifie automatiquement vos pods pour utiliser ce type de secret.</p><p>La création et l'utilisation automatiques des informations d'identification de l'API peuvent être désactivées ou remplacées si vous le souhaitez.
Cependant, si tout ce que vous avez à faire est d'accéder en toute sécurité à l'apiserver, il s'agit de la méthode recommandée.</p><p>Voir la documentation des <a href=/docs/tasks/configure-pod-container/configure-service-account/>Compte de service</a> pour plus d'informations sur le fonctionnement des comptes de service.</p><h3 id=créer-vos-propres-secrets>Créer vos propres secrets</h3><h4 id=créer-un-secret-avec-kubectl-create-secret>Créer un secret avec kubectl create secret</h4><p>Supposons que certains pods doivent accéder à une base de données.
Le nom d'utilisateur et le mot de passe que les pods doivent utiliser se trouvent dans les fichiers <code>./username.txt</code> et <code>./password.txt</code> sur votre machine locale.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span><span style=color:#080;font-style:italic># Create files needed for rest of example.</span>
</span></span><span style=display:flex><span><span style=color:#a2f>echo</span> -n <span style=color:#b44>&#39;admin&#39;</span> &gt; ./username.txt
</span></span><span style=display:flex><span><span style=color:#a2f>echo</span> -n <span style=color:#b44>&#39;1f2d1e2e67df&#39;</span> &gt; ./password.txt
</span></span></code></pre></div><p>La commande <code>kubectl create secret</code> regroupe ces fichiers dans un secret et crée l'objet sur l'Apiserver.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl create secret generic db-user-pass --from-file<span style=color:#666>=</span>./username.txt --from-file<span style=color:#666>=</span>./password.txt
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-text data-lang=text><span style=display:flex><span>secret &#34;db-user-pass&#34; created
</span></span></code></pre></div><div class="alert alert-info note callout" role=alert><strong>Note:</strong><p>Les caractères spéciaux tels que <code>$</code>, <code>\</code>, <code>*</code>, et <code>!</code> seront interprétés par votre <a href=https://en.wikipedia.org/wiki/Shell_(computing)>shell</a> et nécessitent d'être échappés.
Dans les shells les plus courants, le moyen le plus simple d'échapper au mot de passe est de l'entourer de guillemets simples (<code>'</code>).
Par exemple, si votre mot de passe réel est <code>S!B\*d$zDsb</code>, vous devez exécuter la commande de cette façon:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-text data-lang=text><span style=display:flex><span>kubectl create secret generic dev-db-secret --from-literal=username=devuser --from-literal=password=&#39;S!B\*d$zDsb&#39;
</span></span></code></pre></div><p>Vous n'avez pas besoin d'échapper les caractères spéciaux dans les mots de passe des fichiers (<code>--from-file</code>).</p></div><p>Vous pouvez vérifier que le secret a été créé comme ceci:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get secrets
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-text data-lang=text><span style=display:flex><span>NAME                  TYPE                                  DATA      AGE
</span></span><span style=display:flex><span>db-user-pass          Opaque                                2         51s
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-text data-lang=text><span style=display:flex><span>kubectl describe secrets/db-user-pass
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-text data-lang=text><span style=display:flex><span>Name:            db-user-pass
</span></span><span style=display:flex><span>Namespace:       default
</span></span><span style=display:flex><span>Labels:          &lt;none&gt;
</span></span><span style=display:flex><span>Annotations:     &lt;none&gt;
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>Type:            Opaque
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>Data
</span></span><span style=display:flex><span>====
</span></span><span style=display:flex><span>password.txt:    12 bytes
</span></span><span style=display:flex><span>username.txt:    5 bytes
</span></span></code></pre></div><div class="alert alert-info note callout" role=alert><strong>Note:</strong> <code>kubectl get</code> et <code>kubectl describe</code> évitent d'afficher le contenu d'un secret par défaut.
Il s'agit de protéger le secret contre une exposition accidentelle à un spectateur de l'écran ou contre son stockage dans un journal de terminal.</div><p>Voir <a href=#decoding-a-secret>décoder un secret</a> pour voir le contenu d'un secret.</p><h4 id=création-manuelle-d-un-secret>Création manuelle d'un secret</h4><p>Vous pouvez également créer un secret dans un fichier d'abord, au format json ou yaml, puis créer cet objet.
Le <a href=/docs/reference/generated/kubernetes-api/v1.25/#secret-v1-core>secret</a> contient deux table de hachage: <code>data</code> et <code>stringData</code>.
Le champ <code>data</code> est utilisé pour stocker des données arbitraires, encodées en base64.
Le champ <code>stringData</code> est fourni pour plus de commodité et vous permet de fournir des données secrètes sous forme de chaînes non codées.</p><p>Par exemple, pour stocker deux chaînes dans un secret à l'aide du champ <code>data</code>, convertissez-les en base64 comme suit:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span><span style=color:#a2f>echo</span> -n <span style=color:#b44>&#39;admin&#39;</span> | base64
</span></span><span style=display:flex><span><span style=color:#b8860b>YWRtaW4</span><span style=color:#666>=</span>
</span></span><span style=display:flex><span><span style=color:#a2f>echo</span> -n <span style=color:#b44>&#39;1f2d1e2e67df&#39;</span> | base64
</span></span><span style=display:flex><span>MWYyZDFlMmU2N2Rm
</span></span></code></pre></div><p>Écrivez un secret qui ressemble à ceci:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Secret<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>mysecret<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>type</span>:<span style=color:#bbb> </span>Opaque<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>data</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>username</span>:<span style=color:#bbb> </span>YWRtaW4=<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>password</span>:<span style=color:#bbb> </span>MWYyZDFlMmU2N2Rm<span style=color:#bbb>
</span></span></span></code></pre></div><p>Maintenant, créez le secret en utilisant <a href=/docs/reference/generated/kubectl/kubectl-commands#apply><code>kubectl apply</code></a>:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-text data-lang=text><span style=display:flex><span>kubectl apply -f ./secret.yaml
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-text data-lang=text><span style=display:flex><span>secret &#34;mysecret&#34; created
</span></span></code></pre></div><p>Pour certains scénarios, vous pouvez utiliser le champ <code>stringData</code> à la place.
Ce champ vous permet de mettre une chaîne non codée en base64 directement dans le secret, et la chaîne sera codée pour vous lorsque le secret sera créé ou mis à jour.</p><p>Un exemple pratique de cela pourrait être le suivant: vous déployez une application qui utilise un secret pour stocker un fichier de configuration.
Vous souhaitez remplir des parties de ce fichier de configuration pendant votre processus de déploiement.</p><p>Si votre application utilise le fichier de configuration suivant:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiUrl</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;https://my.api.com/api/v1&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>username</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;user&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>password</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;password&#34;</span><span style=color:#bbb>
</span></span></span></code></pre></div><p>Vous pouvez stocker cela dans un secret en utilisant ce qui suit:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Secret<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>mysecret<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>type</span>:<span style=color:#bbb> </span>Opaque<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>stringData</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>config.yaml</span>:<span style=color:#bbb> </span>|-<span style=color:#b44;font-style:italic>
</span></span></span><span style=display:flex><span><span style=color:#b44;font-style:italic>    apiUrl: &#34;https://my.api.com/api/v1&#34;
</span></span></span><span style=display:flex><span><span style=color:#b44;font-style:italic>    username: {{username}}
</span></span></span><span style=display:flex><span><span style=color:#b44;font-style:italic>    password: {{password}}</span><span style=color:#bbb>    
</span></span></span></code></pre></div><p>Votre outil de déploiement pourrait alors remplacer les variables de modèle <code>{{username}}</code> et <code>{{password}}</code> avant d'exécuter <code>kubectl apply</code>.</p><p><code>stringData</code> est un champ de commodité en écriture seule.
Il n'est jamais affiché lors de la récupération des secrets.
Par exemple, si vous exécutez la commande suivante:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-text data-lang=text><span style=display:flex><span>kubectl get secret mysecret -o yaml
</span></span></code></pre></div><p>La sortie sera similaire à:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Secret<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>creationTimestamp</span>:<span style=color:#bbb> </span>2018-11-15T20:40:59Z<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>mysecret<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>namespace</span>:<span style=color:#bbb> </span>default<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>resourceVersion</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;7225&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>uid</span>:<span style=color:#bbb> </span>c280ad2e-e916-11e8-98f2-025000000001<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>type</span>:<span style=color:#bbb> </span>Opaque<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>data</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>config.yaml</span>:<span style=color:#bbb> </span>YXBpVXJsOiAiaHR0cHM6Ly9teS5hcGkuY29tL2FwaS92MSIKdXNlcm5hbWU6IHt7dXNlcm5hbWV9fQpwYXNzd29yZDoge3twYXNzd29yZH19<span style=color:#bbb>
</span></span></span></code></pre></div><p>Si un champ est spécifié à la fois dans <code>data</code> et <code>stringData</code>, la valeur de <code>stringData</code> est utilisée.
Par exemple, la définition de secret suivante:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Secret<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>mysecret<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>type</span>:<span style=color:#bbb> </span>Opaque<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>data</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>username</span>:<span style=color:#bbb> </span>YWRtaW4=<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>stringData</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>username</span>:<span style=color:#bbb> </span>administrateur<span style=color:#bbb>
</span></span></span></code></pre></div><p>Donnera le secret suivant:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Secret<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>creationTimestamp</span>:<span style=color:#bbb> </span>2018-11-15T20:46:46Z<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>mysecret<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>namespace</span>:<span style=color:#bbb> </span>default<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>resourceVersion</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;7579&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>uid</span>:<span style=color:#bbb> </span>91460ecb-e917-11e8-98f2-025000000001<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>type</span>:<span style=color:#bbb> </span>Opaque<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>data</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>username</span>:<span style=color:#bbb> </span>YWRtaW5pc3RyYXRldXI=<span style=color:#bbb>
</span></span></span></code></pre></div><p>Où <code>YWRtaW5pc3RyYXRldXI=</code> décode en <code>administrateur</code>.</p><p>Les clés de <code>data</code> et <code>stringData</code> doivent être composées de caractères alphanumériques, '-', '_' ou '.'.</p><p><strong>Encoding Note:</strong> Les valeurs JSON et YAML sérialisées des données secrètes sont codées sous forme de chaînes base64.
Les sauts de ligne ne sont pas valides dans ces chaînes et doivent être omis.
Lors de l'utilisation de l'utilitaire <code>base64</code> sur Darwin / macOS, les utilisateurs doivent éviter d'utiliser l'option <code>-b</code> pour diviser les longues lignes.
Inversement, les utilisateurs Linux <em>devraient</em> ajouter l'option <code>-w 0</code> aux commandes <code>base64</code> ou le pipeline <code>base64 | tr -d '\ n'</code> si l'option <code>-w</code> n'est pas disponible.</p><h4 id=création-d-un-secret-à-partir-du-générateur>Création d'un secret à partir du générateur</h4><p>Kubectl prend en charge <a href=/docs/tasks/manage-kubernetes-objects/kustomization/>la gestion des objets à l'aide de Kustomize</a> depuis 1.14.
Avec cette nouvelle fonctionnalité, vous pouvez également créer un secret à partir de générateurs, puis l'appliquer pour créer l'objet sur l'Apiserver.
Les générateurs doivent être spécifiés dans un <code>kustomization.yaml</code> à l'intérieur d'un répertoire.</p><p>Par exemple, pour générer un secret à partir des fichiers <code>./username.txt</code> et <code>./password.txt</code></p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span><span style=color:#080;font-style:italic># Create a kustomization.yaml file with SecretGenerator</span>
</span></span><span style=display:flex><span>cat <span style=color:#b44>&lt;&lt;EOF &gt;./kustomization.yaml
</span></span></span><span style=display:flex><span><span style=color:#b44>secretGenerator:
</span></span></span><span style=display:flex><span><span style=color:#b44>- name: db-user-pass
</span></span></span><span style=display:flex><span><span style=color:#b44>  files:
</span></span></span><span style=display:flex><span><span style=color:#b44>  - username.txt
</span></span></span><span style=display:flex><span><span style=color:#b44>  - password.txt
</span></span></span><span style=display:flex><span><span style=color:#b44>EOF</span>
</span></span></code></pre></div><p>Appliquez le répertoire de personnalisation pour créer l'objet secret.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-text data-lang=text><span style=display:flex><span>$ kubectl apply -k .
</span></span><span style=display:flex><span>secret/db-user-pass-96mffmfh4k created
</span></span></code></pre></div><p>Vous pouvez vérifier que le secret a été créé comme ceci:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-text data-lang=text><span style=display:flex><span>$ kubectl get secrets
</span></span><span style=display:flex><span>NAME                             TYPE                                  DATA      AGE
</span></span><span style=display:flex><span>db-user-pass-96mffmfh4k          Opaque                                2         51s
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>$ kubectl describe secrets/db-user-pass-96mffmfh4k
</span></span><span style=display:flex><span>Name:            db-user-pass
</span></span><span style=display:flex><span>Namespace:       default
</span></span><span style=display:flex><span>Labels:          &lt;none&gt;
</span></span><span style=display:flex><span>Annotations:     &lt;none&gt;
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>Type:            Opaque
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>Data
</span></span><span style=display:flex><span>====
</span></span><span style=display:flex><span>password.txt:    12 bytes
</span></span><span style=display:flex><span>username.txt:    5 bytes
</span></span></code></pre></div><p>Par exemple, pour générer un secret à partir des littéraux <code>username=admin</code> et <code>password=secret</code>, vous pouvez spécifier le générateur de secret dans <code>kustomization.yaml</code> comme:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span><span style=color:#080;font-style:italic># Create a kustomization.yaml file with SecretGenerator</span>
</span></span><span style=display:flex><span>$ cat <span style=color:#b44>&lt;&lt;EOF &gt;./kustomization.yaml
</span></span></span><span style=display:flex><span><span style=color:#b44>secretGenerator:
</span></span></span><span style=display:flex><span><span style=color:#b44>- name: db-user-pass
</span></span></span><span style=display:flex><span><span style=color:#b44>  literals:
</span></span></span><span style=display:flex><span><span style=color:#b44>  - username=admin
</span></span></span><span style=display:flex><span><span style=color:#b44>  - password=secret
</span></span></span><span style=display:flex><span><span style=color:#b44>EOF</span>
</span></span></code></pre></div><p>Appliquer le repertoire kustomization pour créer l'objet secret.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>$ kubectl apply -k .
</span></span><span style=display:flex><span>secret/db-user-pass-dddghtt9b5 created
</span></span></code></pre></div><div class="alert alert-info note callout" role=alert><strong>Note:</strong> Le nom des secrets généré a un suffixe ajouté en hachant le contenu.
Cela garantit qu'un nouveau secret est généré chaque fois que le contenu est modifié.</div><h4 id=décoder-un-secret>Décoder un secret</h4><p>Les secrets peuvent être récupérés via la command <code>kubectl get secret</code>.
Par exemple, pour récupérer le secret créé dans la section précédente:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get secret mysecret -o yaml
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Secret<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>creationTimestamp</span>:<span style=color:#bbb> </span>2016-01-22T18:41:56Z<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>mysecret<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>namespace</span>:<span style=color:#bbb> </span>default<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>resourceVersion</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;164619&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>uid</span>:<span style=color:#bbb> </span>cfee02d6-c137-11e5-8d73-42010af00002<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>type</span>:<span style=color:#bbb> </span>Opaque<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>data</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>username</span>:<span style=color:#bbb> </span>YWRtaW4=<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>password</span>:<span style=color:#bbb> </span>MWYyZDFlMmU2N2Rm<span style=color:#bbb>
</span></span></span></code></pre></div><p>Décodez le champ du mot de passe:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span><span style=color:#a2f>echo</span> <span style=color:#b44>&#39;MWYyZDFlMmU2N2Rm&#39;</span> | base64 --decode
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-text data-lang=text><span style=display:flex><span>1f2d1e2e67df
</span></span></code></pre></div><h4 id=modification-d-un-secret>Modification d'un secret</h4><p>Un secret existant peut être modifié avec la commande suivante:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-text data-lang=text><span style=display:flex><span>kubectl edit secrets mysecret
</span></span></code></pre></div><p>Cela ouvrira l'éditeur configuré par défaut et permettra de mettre à jour les valeurs secrètes codées en base64 dans le champ <code>data</code>:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#080;font-style:italic># Please edit the object below. Lines beginning with a &#39;#&#39; will be ignored,</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:#080;font-style:italic># and an empty file will abort the edit. If an error occurs while saving this file will be</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:#080;font-style:italic># reopened with the relevant failures.</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:#080;font-style:italic>#</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>data</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>username</span>:<span style=color:#bbb> </span>YWRtaW4=<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>password</span>:<span style=color:#bbb> </span>MWYyZDFlMmU2N2Rm<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Secret<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>annotations</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>kubectl.kubernetes.io/last-applied-configuration</span>:<span style=color:#bbb> </span>{<span style=color:#bbb> </span>... }<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>creationTimestamp</span>:<span style=color:#bbb> </span>2016-01-22T18:41:56Z<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>mysecret<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>namespace</span>:<span style=color:#bbb> </span>default<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>resourceVersion</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;164619&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>uid</span>:<span style=color:#bbb> </span>cfee02d6-c137-11e5-8d73-42010af00002<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>type</span>:<span style=color:#bbb> </span>Opaque<span style=color:#bbb>
</span></span></span></code></pre></div><h2 id=utiliser-les-secrets>Utiliser les secrets</h2><p>Les secrets peuvent être montés en tant que volumes de données ou être exposés en tant que <a class=glossary-tooltip title="Les variables d'environnement de conteneur sont des paires nom=valeur qui fournissent des informations utiles aux conteneurs fonctionnant au sein d'un Pod." data-toggle=tooltip data-placement=top href=/docs/concepts/containers/container-environment-variables/ target=_blank aria-label="variables d'environnement">variables d'environnement</a> à utiliser par un conteneur dans un Pod.
Ils peuvent également être utilisés par d'autres parties du système, sans être directement exposés aux Pods.
Par exemple, ils peuvent détenir des informations d'identification que d'autres parties du système doivent utiliser pour interagir avec des systèmes externes en votre nom.</p><h3 id=utilisation-de-secrets-comme-fichiers-d-un-pod>Utilisation de secrets comme fichiers d'un pod</h3><p>Pour consommer un secret dans un volume dans un pod:</p><ol><li>Créez un secret ou utilisez-en un déjà existant.
Plusieurs Pods peuvent référencer le même secret.</li><li>Modifiez la définition de votre Pod pour ajouter un volume sous <code>.spec.volumes[]</code>.
Nommez le volume et ayez un champ <code>.spec.volumes[].secret.secretName</code> égal au nom de l'objet secret.</li><li>Ajouter un <code>.spec.containers[].volumeMounts[]</code> à chaque conteneur qui a besoin du secret.
Spécifier <code>.spec.containers[].volumeMounts[].readOnly = true</code> et <code>.spec.containers[].volumeMounts[].mountPath</code> à un nom de répertoire inutilisé où vous souhaitez que les secrets apparaissent.</li><li>Modifiez votre image et/ou votre ligne de commande pour que le programme recherche les fichiers dans ce répertoire.
Chaque clé de la carte secrète <code>data</code> devient le nom de fichier sous <code>mountPath</code>.</li></ol><p>Voici un exemple de pod qui monte un secret dans un volume:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>mypod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>mypod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>redis<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>volumeMounts</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>foo<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>mountPath</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;/etc/foo&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>readOnly</span>:<span style=color:#bbb> </span><span style=color:#a2f;font-weight:700>true</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>volumes</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>foo<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>secret</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>secretName</span>:<span style=color:#bbb> </span>mysecret<span style=color:#bbb>
</span></span></span></code></pre></div><p>Chaque secret que vous souhaitez utiliser doit être mentionné dans <code>.spec.volumes</code>.</p><p>S'il y a plusieurs conteneurs dans le pod, alors chaque conteneur a besoin de son propre bloc <code>volumeMounts</code>, mais un seul <code>.spec.volumes</code> est nécessaire par secret.</p><p>Vous pouvez regrouper de nombreux fichiers en un seul secret ou utiliser de nombreux secrets, selon le cas.</p><h3 id=projection-de-clés-secrètes-vers-des-chemins-spécifiques>Projection de clés secrètes vers des chemins spécifiques</h3><p>Nous pouvons également contrôler les chemins dans le volume où les clés secrètes sont projetées.
Vous pouvez utiliser le champ <code>.spec.volumes []. Secret.items</code> pour changer le chemin cible de chaque clé:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>mypod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>mypod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>redis<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>volumeMounts</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>foo<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>mountPath</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;/etc/foo&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>readOnly</span>:<span style=color:#bbb> </span><span style=color:#a2f;font-weight:700>true</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>volumes</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>foo<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>secret</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>secretName</span>:<span style=color:#bbb> </span>mysecret<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>items</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- <span style=color:green;font-weight:700>key</span>:<span style=color:#bbb> </span>username<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>path</span>:<span style=color:#bbb> </span>my-group/my-username<span style=color:#bbb>
</span></span></span></code></pre></div><p>Que se passera-t-il:</p><ul><li><code>username</code> est stocké dans le fichier <code>/etc/foo/my-group/my-username</code> au lieu de <code>/etc/foo/username</code>.</li><li><code>password</code> n'est pas projeté</li></ul><p>Si <code>.spec.volumes[].secret.items</code> est utilisé, seules les clés spécifiées dans <code>items</code> sont projetées.
Pour consommer toutes les clés du secret, toutes doivent être répertoriées dans le champ <code>items</code>.
Toutes les clés répertoriées doivent exister dans le secret correspondant.
Sinon, le volume n'est pas créé.</p><h3 id=autorisations-de-fichiers-secrets>Autorisations de fichiers secrets</h3><p>Vous pouvez également spécifier les bits de mode d'autorisation des fichiers contenant les parties d'un secret.
Si vous n'en spécifiez pas, <code>0644</code> est utilisé par défaut.
Vous pouvez spécifier un mode par défaut pour tout le volume secret et remplacer par clé si nécessaire.</p><p>Par exemple, vous pouvez spécifier un mode par défaut comme celui-ci:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>mypod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>mypod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>redis<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>volumeMounts</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>foo<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>mountPath</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;/etc/foo&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>volumes</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>foo<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>secret</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>secretName</span>:<span style=color:#bbb> </span>mysecret<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>defaultMode</span>:<span style=color:#bbb> </span><span style=color:#666>256</span><span style=color:#bbb>
</span></span></span></code></pre></div><p>Ensuite, le secret sera monté sur <code>/etc/foo</code> et tous les fichiers créés par le montage de volume secret auront la permission <code>0400</code>.</p><p>Notez que la spécification JSON ne prend pas en charge la notation octale, utilisez donc la valeur 256 pour les autorisations 0400.
Si vous utilisez yaml au lieu de json pour le pod, vous pouvez utiliser la notation octale pour spécifier les autorisations de manière plus naturelle.</p><p>Vous pouvez aussi utiliser un mapping, comme dans l'exemple précédent, et spécifier des autorisations différentes pour différents fichiers comme celui-ci:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>mypod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>mypod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>redis<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>volumeMounts</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>foo<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>mountPath</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;/etc/foo&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>volumes</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>foo<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>secret</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>secretName</span>:<span style=color:#bbb> </span>mysecret<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>items</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- <span style=color:green;font-weight:700>key</span>:<span style=color:#bbb> </span>username<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>path</span>:<span style=color:#bbb> </span>my-group/my-username<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>mode</span>:<span style=color:#bbb> </span><span style=color:#666>511</span><span style=color:#bbb>
</span></span></span></code></pre></div><p>Dans ce cas, le fichier résultant <code>/etc/foo/my-group/my-username</code> aura la valeur d'autorisation de <code>0777</code>.
En raison des limitations JSON, vous devez spécifier le mode en notation décimale.</p><p>Notez que cette valeur d'autorisation peut être affichée en notation décimale si vous la lisez plus tard.</p><h3 id=consommer-des-valeurs-secrètes-à-partir-de-volumes>Consommer des valeurs secrètes à partir de volumes</h3><p>À l'intérieur du conteneur qui monte un volume secret, les clés secrètes apparaissent sous forme de fichiers et les valeurs secrètes sont décodées en base 64 et stockées à l'intérieur de ces fichiers.
C'est le résultat des commandes exécutées à l'intérieur du conteneur de l'exemple ci-dessus:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>ls /etc/foo/
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-text data-lang=text><span style=display:flex><span>username
</span></span><span style=display:flex><span>password
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>cat /etc/foo/username
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-text data-lang=text><span style=display:flex><span>admin
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>cat /etc/foo/password
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-text data-lang=text><span style=display:flex><span>1f2d1e2e67df
</span></span></code></pre></div><p>Le programme dans un conteneur est responsable de la lecture des secrets des fichiers.</p><h3 id=les-secrets-montés-sont-mis-à-jour-automatiquement>Les secrets montés sont mis à jour automatiquement</h3><p>Lorsqu'un secret déjà consommé dans un volume est mis à jour, les clés projetées sont finalement mises à jour également.
Kubelet vérifie si le secret monté est récent à chaque synchronisation périodique.
Cependant, il utilise son cache local pour obtenir la valeur actuelle du Secret.
Le type de cache est configurable à l'aide de le champ <code>ConfigMapAndSecretChangeDetectionStrategy</code> dans la structure <a href=https://github.com/kubernetes/kubernetes/blob/main/staging/src/k8s.io/kubelet/config/v1beta1/types.go>KubeletConfiguration</a>.
Il peut être soit propagé via watch (par défaut), basé sur ttl, ou simplement redirigé toutes les requêtes vers directement kube-apiserver.
Par conséquent, le délai total entre le moment où le secret est mis à jour et le moment où de nouvelles clés sont projetées sur le pod peut être aussi long que la période de synchronisation du kubelet + le délai de propagation du cache, où le délai de propagation du cache dépend du type de cache choisi (cela équivaut au delai de propagation du watch, ttl du cache, ou bien zéro).</p><div class="alert alert-info note callout" role=alert><strong>Note:</strong> Un conteneur utilisant un secret comme un volume <a href=/docs/concepts/storage/volumes#using-subpath>subPath</a> monté ne recevra pas de mises à jour secrètes.</div><h3 id=utilisation-de-secrets-comme-variables-d-environnement>Utilisation de secrets comme variables d'environnement</h3><p>Pour utiliser un secret dans une <a class=glossary-tooltip title="Les variables d'environnement de conteneur sont des paires nom=valeur qui fournissent des informations utiles aux conteneurs fonctionnant au sein d'un Pod." data-toggle=tooltip data-placement=top href=/docs/concepts/containers/container-environment-variables/ target=_blank aria-label="variable d'environnement">variable d'environnement</a> dans un pod:</p><ol><li>Créez un secret ou utilisez-en un déjà existant.
Plusieurs pods peuvent référencer le même secret.</li><li>Modifiez la définition de votre pod dans chaque conteneur où vous souhaitez utiliser la valeur d'une clé secrète pour ajouter une variable d'environnement pour chaque clé secrète que vous souhaitez consommer.
La variable d'environnement qui consomme la clé secrète doit remplir le nom et la clé du secret dans <code>env[].valueFrom.secretKeyRef</code>.</li><li>Modifiez votre image et/ou votre ligne de commande pour que le programme recherche des valeurs dans les variables d'environnement spécifiées</li></ol><p>Voici un exemple de pod qui utilise des secrets de variables d'environnement:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>secret-env-pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>mycontainer<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>redis<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>env</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>SECRET_USERNAME<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>valueFrom</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>secretKeyRef</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>            </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>mysecret<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>            </span><span style=color:green;font-weight:700>key</span>:<span style=color:#bbb> </span>username<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>SECRET_PASSWORD<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>valueFrom</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>secretKeyRef</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>            </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>mysecret<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>            </span><span style=color:green;font-weight:700>key</span>:<span style=color:#bbb> </span>password<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>restartPolicy</span>:<span style=color:#bbb> </span>Never<span style=color:#bbb>
</span></span></span></code></pre></div><h3 id=consommation-de-valeurs-secrètes-à-partir-de-variables-d-environnement>Consommation de valeurs secrètes à partir de variables d'environnement</h3><p>À l'intérieur d'un conteneur qui consomme un secret dans des variables d'environnement, les clés secrètes apparaissent comme des variables d'environnement normales contenant les valeurs décodées en base64 des données secrètes.
C'est le résultat des commandes exécutées à l'intérieur du conteneur de l'exemple ci-dessus:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span><span style=color:#a2f>echo</span> <span style=color:#b8860b>$SECRET_USERNAME</span>
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-text data-lang=text><span style=display:flex><span>admin
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span><span style=color:#a2f>echo</span> <span style=color:#b8860b>$SECRET_PASSWORD</span>
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-text data-lang=text><span style=display:flex><span>1f2d1e2e67df
</span></span></code></pre></div><h3 id=utilisation-des-imagepullsecrets>Utilisation des imagePullSecrets</h3><p>Un <code>imagePullSecret</code> est un moyen de transmettre un secret qui contient un mot de passe de registre d'images Docker (ou autre) au Kubelet afin qu'il puisse extraire une image privée au nom de votre Pod.</p><h4 id=spécification-manuelle-d-une-imagepullsecret>Spécification manuelle d'une imagePullSecret</h4><p>L'utilisation de <code>imagePullSecrets</code> est décrite dans la <a href=/docs/concepts/containers/images/#specifying-imagepullsecrets-on-a-pod>documentation des images</a></p><h3 id=arranging-for-imagepullsecrets-to-be-automatically-attached>Arranging for imagePullSecrets to be Automatically Attached</h3><p>Vous pouvez créer manuellement un <code>imagePullSecret</code> et le référencer à partir d'un <code>serviceAccount</code>.
Tous les pods créés avec ce <code>serviceAccount</code> ou cette valeur par défaut pour utiliser ce <code>serviceAccount</code>, verront leur champ <code>imagePullSecret</code> défini sur celui du compte de service.
Voir <a href=/docs/tasks/configure-pod-container/configure-service-account/#add-imagepullsecrets-to-a-service-account>Ajouter ImagePullSecrets à un compte de service</a> pour une explication détaillée de ce processus.</p><h3 id=montage-automatique-de-secrets-créés-manuellement>Montage automatique de secrets créés manuellement</h3><p>Les secrets créés manuellement (par exemple, un contenant un jeton pour accéder à un compte github) peuvent être automatiquement associés aux pods en fonction de leur compte de service.
Voir <a href=/docs/tasks/inject-data-application/podpreset/>Injection d'informations dans des pods à l'aide d'un PodPreset</a> pour une explication détaillée de ce processus.</p><h2 id=details>Details</h2><h3 id=restrictions>Restrictions</h3><p>Les sources de volume secrètes sont validées pour garantir que la référence d'objet spécifiée pointe réellement vers un objet de type Secret.
Par conséquent, un secret doit être créé avant tous les pods qui en dépendent.</p><p>Les objets API secrets résident dans un <a class=glossary-tooltip title='An abstraction used by Kubernetes to support isolation of groups of resources within a single cluster.' data-toggle=tooltip data-placement=top href=/docs/concepts/overview/working-with-objects/namespaces target=_blank aria-label=namespace>namespace</a>.
Ils ne peuvent être référencés que par des pods dans le même espace de noms.</p><p>Les secrets individuels sont limités à 1 Mo de taille.
C'est pour décourager la création de très grands secrets qui épuiseraient la mémoire de l'apiserver et du kubelet.
Cependant, la création de nombreux petits secrets pourrait également épuiser la mémoire.
Des limites plus complètes sur l'utilisation de la mémoire en raison de secrets sont une fonctionnalité prévue.</p><p>Kubelet prend uniquement en charge l'utilisation des secrets pour les pods qu'il obtient du serveur API.
Cela inclut tous les pods créés à l'aide de kubectl, ou indirectement via un contrôleur de réplication.
Il n'inclut pas les pods créés via les drapeaux kubelet <code>--manifest-url</code>, ou <code>--config</code>, ou son API REST (ce ne sont pas des moyens courants de créer des Pods).</p><p>Les secrets doivent être créés avant d'être consommés dans les pods en tant que variables d'environnement, sauf s'ils sont marqués comme facultatifs.
Les références à des secrets qui n'existent pas empêcheront le pod de démarrer.</p><p>Les références via <code>secretKeyRef</code> à des clés qui n'existent pas dans un Secret nommé empêcheront le pod de démarrer.</p><p>Les secrets utilisés pour remplir les variables d'environnement via <code>envFrom</code> qui ont des clés considérées comme des noms de variables d'environnement non valides verront ces clés ignorées.
Le pod sera autorisé à démarrer.
Il y aura un événement dont la raison est <code>InvalidVariableNames</code> et le message contiendra la liste des clés invalides qui ont été ignorées.
L'exemple montre un pod qui fait référence au / mysecret par défaut qui contient 2 clés invalides, 1badkey et 2alsobad.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get events
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-text data-lang=text><span style=display:flex><span>LASTSEEN   FIRSTSEEN   COUNT     NAME            KIND      SUBOBJECT                         TYPE      REASON
</span></span><span style=display:flex><span>0s         0s          1         dapi-test-pod   Pod                                         Warning   InvalidEnvironmentVariableNames   kubelet, 127.0.0.1      Keys [1badkey, 2alsobad] from the EnvFrom secret default/mysecret were skipped since they are considered invalid environment variable names.
</span></span></code></pre></div><h3 id=cycle-de-vie-de-l-intéraction-secret-et-pod>Cycle de vie de l'intéraction Secret et Pod</h3><p>Lorsqu'un pod est créé via l'API, il n'est pas vérifié s'il existe un secret référencé.
Une fois qu'un pod est programmé, le kubelet tentera de récupérer la valeur secrète.
Si le secret ne peut pas être récupéré parce qu'il n'existe pas ou en raison d'un manque temporaire de connexion au serveur API, kubelet réessayera périodiquement.
Il rapportera un événement sur le pod expliquant la raison pour laquelle il n'a pas encore démarré.
Une fois le secret récupéré, le kubelet créera et montera un volume le contenant.
Aucun des conteneurs du pod ne démarre tant que tous les volumes du pod ne sont pas montés.</p><h2 id=cas-d-utilisation>Cas d'utilisation</h2><h3 id=cas-d-utilisation-pod-avec-clés-ssh>Cas d'utilisation: pod avec clés SSH</h3><p>Créez un kustomization.yaml avec un <code>SecretGenerator</code> contenant quelques clés SSH:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl create secret generic ssh-key-secret --from-file<span style=color:#666>=</span>ssh-privatekey<span style=color:#666>=</span>/path/to/.ssh/id_rsa --from-file<span style=color:#666>=</span>ssh-publickey<span style=color:#666>=</span>/path/to/.ssh/id_rsa.pub
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-text data-lang=text><span style=display:flex><span>secret &#34;ssh-key-secret&#34; created
</span></span></code></pre></div><div class="alert alert-warning caution callout" role=alert><strong>Avertissement:</strong> Réfléchissez bien avant d'envoyer vos propres clés SSH: d'autres utilisateurs du cluster peuvent avoir accès au secret.
Utilisez un compte de service que vous souhaitez rendre accessible à tous les utilisateurs avec lesquels vous partagez le cluster Kubernetes et que vous pouvez révoquer s'ils sont compromis.</div><p>Nous pouvons maintenant créer un pod qui référence le secret avec la clé SSH et le consomme dans un volume:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>secret-test-pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>labels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>secret-test<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>volumes</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>secret-volume<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>secret</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>secretName</span>:<span style=color:#bbb> </span>ssh-key-secret<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>ssh-test-container<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>mySshImage<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>volumeMounts</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>secret-volume<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>readOnly</span>:<span style=color:#bbb> </span><span style=color:#a2f;font-weight:700>true</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>mountPath</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;/etc/secret-volume&#34;</span><span style=color:#bbb>
</span></span></span></code></pre></div><p>Lorsque la commande du conteneur s'exécute, les morceaux de la clé seront disponibles dans:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>/etc/secret-volume/ssh-publickey
</span></span><span style=display:flex><span>/etc/secret-volume/ssh-privatekey
</span></span></code></pre></div><p>Le conteneur est alors libre d'utiliser les données secrètes pour établir une connexion SSH.</p><h3 id=cas-d-utilisation-pods-avec-informations-d-identification-de-prod-test>Cas d'utilisation: pods avec informations d'identification de prod/test</h3><p>Faites un fichier kustomization.yaml avec un SecretGenerator.</p><p>Cet exemple illustre un Pod qui consomme un secret contenant des informations d'identification de prod et un autre Pod qui consomme un secret avec des informations d'identification d'environnement de test.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl create secret generic prod-db-secret --from-literal<span style=color:#666>=</span><span style=color:#b8860b>username</span><span style=color:#666>=</span>produser --from-literal<span style=color:#666>=</span><span style=color:#b8860b>password</span><span style=color:#666>=</span>Y4nys7f11
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-text data-lang=text><span style=display:flex><span>secret &#34;prod-db-secret&#34; created
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl create secret generic test-db-secret --from-literal<span style=color:#666>=</span><span style=color:#b8860b>username</span><span style=color:#666>=</span>testuser --from-literal<span style=color:#666>=</span><span style=color:#b8860b>password</span><span style=color:#666>=</span>iluvtests
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-text data-lang=text><span style=display:flex><span>secret &#34;test-db-secret&#34; created
</span></span></code></pre></div><div class="alert alert-info note callout" role=alert><strong>Note:</strong><p>Caractères spéciaux tels que <code>$</code>, <code>\</code>, <code>*</code>, et <code>!</code> seront interprétés par votre <a href=https://en.wikipedia.org/wiki/Shell_(computing)>shell</a> et nécessitent d'être échappés.
Dans les shells les plus courants, le moyen le plus simple d'échapper au mot de passe est de l'entourer de guillemets simples (<code>'</code>).
Par exemple, si votre mot de passe réel est <code>S!B\*d$zDsb</code>, vous devez exécuter la commande de cette façon:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-text data-lang=text><span style=display:flex><span>kubectl create secret generic dev-db-secret --from-literal=username=devuser --from-literal=password=&#39;S!B\*d$zDsb&#39;
</span></span></code></pre></div><p>Vous n'avez pas besoin d'échapper les caractères spéciaux dans les mots de passe des fichiers (<code>--from-file</code>).</p></div><p>Maintenant, faites les pods:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>$ cat <span style=color:#b44>&lt;&lt;EOF &gt; pod.yaml
</span></span></span><span style=display:flex><span><span style=color:#b44>apiVersion: v1
</span></span></span><span style=display:flex><span><span style=color:#b44>kind: List
</span></span></span><span style=display:flex><span><span style=color:#b44>items:
</span></span></span><span style=display:flex><span><span style=color:#b44>- kind: Pod
</span></span></span><span style=display:flex><span><span style=color:#b44>  apiVersion: v1
</span></span></span><span style=display:flex><span><span style=color:#b44>  metadata:
</span></span></span><span style=display:flex><span><span style=color:#b44>    name: prod-db-client-pod
</span></span></span><span style=display:flex><span><span style=color:#b44>    labels:
</span></span></span><span style=display:flex><span><span style=color:#b44>      name: prod-db-client
</span></span></span><span style=display:flex><span><span style=color:#b44>  spec:
</span></span></span><span style=display:flex><span><span style=color:#b44>    volumes:
</span></span></span><span style=display:flex><span><span style=color:#b44>    - name: secret-volume
</span></span></span><span style=display:flex><span><span style=color:#b44>      secret:
</span></span></span><span style=display:flex><span><span style=color:#b44>        secretName: prod-db-secret
</span></span></span><span style=display:flex><span><span style=color:#b44>    containers:
</span></span></span><span style=display:flex><span><span style=color:#b44>    - name: db-client-container
</span></span></span><span style=display:flex><span><span style=color:#b44>      image: myClientImage
</span></span></span><span style=display:flex><span><span style=color:#b44>      volumeMounts:
</span></span></span><span style=display:flex><span><span style=color:#b44>      - name: secret-volume
</span></span></span><span style=display:flex><span><span style=color:#b44>        readOnly: true
</span></span></span><span style=display:flex><span><span style=color:#b44>        mountPath: &#34;/etc/secret-volume&#34;
</span></span></span><span style=display:flex><span><span style=color:#b44>- kind: Pod
</span></span></span><span style=display:flex><span><span style=color:#b44>  apiVersion: v1
</span></span></span><span style=display:flex><span><span style=color:#b44>  metadata:
</span></span></span><span style=display:flex><span><span style=color:#b44>    name: test-db-client-pod
</span></span></span><span style=display:flex><span><span style=color:#b44>    labels:
</span></span></span><span style=display:flex><span><span style=color:#b44>      name: test-db-client
</span></span></span><span style=display:flex><span><span style=color:#b44>  spec:
</span></span></span><span style=display:flex><span><span style=color:#b44>    volumes:
</span></span></span><span style=display:flex><span><span style=color:#b44>    - name: secret-volume
</span></span></span><span style=display:flex><span><span style=color:#b44>      secret:
</span></span></span><span style=display:flex><span><span style=color:#b44>        secretName: test-db-secret
</span></span></span><span style=display:flex><span><span style=color:#b44>    containers:
</span></span></span><span style=display:flex><span><span style=color:#b44>    - name: db-client-container
</span></span></span><span style=display:flex><span><span style=color:#b44>      image: myClientImage
</span></span></span><span style=display:flex><span><span style=color:#b44>      volumeMounts:
</span></span></span><span style=display:flex><span><span style=color:#b44>      - name: secret-volume
</span></span></span><span style=display:flex><span><span style=color:#b44>        readOnly: true
</span></span></span><span style=display:flex><span><span style=color:#b44>        mountPath: &#34;/etc/secret-volume&#34;
</span></span></span><span style=display:flex><span><span style=color:#b44>EOF</span>
</span></span></code></pre></div><p>Ajoutez les pods à la même kustomization.yaml</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>$ cat <span style=color:#b44>&lt;&lt;EOF &gt;&gt; kustomization.yaml
</span></span></span><span style=display:flex><span><span style=color:#b44>resources:
</span></span></span><span style=display:flex><span><span style=color:#b44>- pod.yaml
</span></span></span><span style=display:flex><span><span style=color:#b44>EOF</span>
</span></span></code></pre></div><p>Appliquez tous ces objets sur l'Apiserver avec</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl apply -k .
</span></span></code></pre></div><p>Les deux conteneurs auront les fichiers suivants présents sur leurs systèmes de fichiers avec les valeurs pour l'environnement de chaque conteneur:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>/etc/secret-volume/username
</span></span><span style=display:flex><span>/etc/secret-volume/password
</span></span></code></pre></div><p>Notez comment les spécifications pour les deux pods ne diffèrent que dans un champ; cela facilite la création de pods avec différentes capacités à partir d'un template de pod commun.</p><p>Vous pouvez encore simplifier la spécification du pod de base en utilisant deux comptes de service: un appelé, disons, <code>prod-user</code> avec le secret <code>prod-db-secret</code>, et un appelé, <code>test-user</code> avec le secret <code>test-db-secret</code>.
Ensuite, la spécification du pod peut être raccourcie, par exemple:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>prod-db-client-pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>labels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>prod-db-client<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>serviceAccount</span>:<span style=color:#bbb> </span>prod-db-client<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>db-client-container<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>myClientImage<span style=color:#bbb>
</span></span></span></code></pre></div><h3 id=cas-d-utilisation-dotfiles-dans-un-volume-secret>Cas d'utilisation: Dotfiles dans un volume secret</h3><p>Afin de masquer des données (c'est-à-dire dans un fichier dont le nom commence par un point), il suffit de faire commencer cette clé par un point.
Par exemple, lorsque le secret suivant est monté dans un volume:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Secret<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>dotfile-secret<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>data</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>.secret-file</span>:<span style=color:#bbb> </span>dmFsdWUtMg0KDQo=<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:#00f;font-weight:700>---</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>secret-dotfiles-pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>volumes</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>secret-volume<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>secret</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>secretName</span>:<span style=color:#bbb> </span>dotfile-secret<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>dotfile-test-container<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>k8s.gcr.io/busybox<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>command</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- ls<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:#b44>&#34;-l&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:#b44>&#34;/etc/secret-volume&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>volumeMounts</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>secret-volume<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>readOnly</span>:<span style=color:#bbb> </span><span style=color:#a2f;font-weight:700>true</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>mountPath</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;/etc/secret-volume&#34;</span><span style=color:#bbb>
</span></span></span></code></pre></div><p>Le <code>secret-volume</code> contiendra un seul fichier, appelé <code>.secret-file</code>, et le <code>dotfile-test-container</code> aura ce fichier présent au chemin <code>/etc/secret-volume/.secret-file</code>.</p><div class="alert alert-info note callout" role=alert><strong>Note:</strong> Les fichiers commençant par des points sont masqués de la sortie de <code>ls -l</code>; vous devez utiliser <code>ls -la</code> pour les voir lors de la liste du contenu du répertoire.</div><h3 id=cas-d-utilisation-secret-visible-pour-un-conteneur-dans-un-pod>Cas d'utilisation: secret visible pour un conteneur dans un pod</h3><p>Envisagez un programme qui doit gérer les requêtes HTTP, effectuer une logique métier complexe, puis signer certains messages avec un HMAC.
Parce qu'il a une logique d'application complexe, il pourrait y avoir un exploit de lecture de fichier à distance inaperçu dans le serveur, qui pourrait exposer la clé privée à un attaquant.</p><p>Cela pourrait être divisé en deux processus dans deux conteneurs: un conteneur frontal qui gère l'interaction utilisateur et la logique métier, mais qui ne peut pas voir la clé privée; et un conteneur de signataire qui peut voir la clé privée, et répond aux demandes de signature simples du frontend (par exemple sur le réseau localhost).</p><p>Avec cette approche partitionnée, un attaquant doit maintenant inciter le serveur d'applications à faire quelque chose d'assez arbitraire, ce qui peut être plus difficile que de lui faire lire un fichier.</p><h2 id=les-meilleures-pratiques>Les meilleures pratiques</h2><h3 id=clients-qui-utilisent-l-api-secrets>Clients qui utilisent l'API secrets</h3><p>Lors du déploiement d'applications qui interagissent avec l'API secrets, l'accès doit être limité à l'aide de <a href=/docs/reference/access-authn-authz/authorization/>politiques d'autorisation</a> telles que <a href=/docs/reference/access-authn-authz/rbac/>RBAC</a>.</p><p>Les secrets contiennent souvent des valeurs qui couvrent un spectre d'importance, dont beaucoup peuvent provoquer des escalades au sein de Kubernetes (par exemple, les jetons de compte de service) et vers les systèmes externes.
Même si une application individuelle peut raisonner sur la puissance des secrets avec lesquels elle s'attend à interagir, d'autres applications dans le même namespace peuvent rendre ces hypothèses invalides.</p><p>Pour ces raisons, les requêtes <code>watch</code> et <code>list</code> pour les secrets dans un namespace sont des capacités extrêmement puissantes et doivent être évitées, puisque la liste des secrets permet aux clients d'inspecter les valeurs de tous les secrets qui se trouvent dans ce namespace.
La capacité à effectuer un <code>watch</code> ou <code>list</code> des secrets dans un cluster doit être réservé uniquement aux composants les plus privilégiés au niveau du système.</p><p>Les applications qui ont besoin d'accéder à l'API secrets doivent effectuer des requêtes <code>get</code> sur les secrets dont elles ont besoin.
Cela permet aux administrateurs de restreindre l'accès à tous les secrets tout en donnant <a href=/docs/reference/access-authn-authz/rbac/#referring-to-resources>accès en liste blanche aux instances individuelles</a> dont l'application a besoin.</p><p>Pour des performances améliorées sur une boucle <code>get</code>, les clients peuvent concevoir des ressources qui font référence à un secret puis <code>watch</code> la ressource, demandant à nouveau le secret lorsque la ressource change.
De plus, un <a href=https://github.com/kubernetes/community/blob/master/contributors/design-proposals/api-machinery/bulk_watch.md>"bulk watch" API</a> laisse les clients <code>watch</code> des ressources individuelles ont également été proposées et seront probablement disponibles dans les prochaines versions de Kubernetes.</p><h2 id=propriétés-de-sécurité>Propriétés de sécurité</h2><h3 id=protections>Protections</h3><p>Étant donné que les objets secrets peuvent être créés indépendamment des Pods qui les utilisent, il y a moins de risques que le secret soit exposé pendant la création, la visualisation et la modification des Pods.
Le système peut également prendre des précautions supplémentaires avec les objets secrets, comme éviter de les écrire sur le disque lorsque cela est possible.</p><p>Un secret n'est envoyé à un nœud que si un module sur ce nœud l'exige.
Kubelet stocke le secret dans un <code>tmpfs</code> afin que le secret ne soit pas écrit sur le stockage sur disque.
Une fois que le pod qui dépend du secret est supprimé, kubelet supprimera également sa copie locale des données secrètes.</p><p>Il peut y avoir des secrets pour plusieurs pods sur le même nœud.
Cependant, seuls les secrets qu'un pod demande sont potentiellement visibles dans ses conteneurs.
Par conséquent, un pod n'a pas accès aux secrets d'un autre pod.</p><p>Il peut y avoir plusieurs conteneurs dans un pod.
Cependant, chaque conteneur d'un pod doit demander le volume secret dans ses <code>volumesMounts</code> pour qu'il soit visible dans le conteneur.
Cela peut être utilisé pour construire des <a href=#use-case-secret-visible-to-one-container-in-a-pod>partitions de sécurité au niveau du pod</a>.</p><p>Sur la plupart des distributions gérées par le projet Kubernetes, la communication entre l'utilisateur vers l'apiserver et entre l'apiserver et les kubelets est protégée par SSL/TLS.
Les secrets sont protégés lorsqu'ils sont transmis sur ces canaux.</p><div style=margin-top:10px;margin-bottom:10px><b>FEATURE STATE:</b> <code>Kubernetes v1.13 [beta]</code></div><p>Vous pouvez activer le <a href=/docs/tasks/administer-cluster/encrypt-data/>chiffrement au repos</a> pour les données secrètes, afin que les secrets ne soient pas stockés en clair dans <a class=glossary-tooltip title='Base de données clé-valeur consistante et hautement disponible utilisée comme mémoire de sauvegarde pour toutes les données du cluster.' data-toggle=tooltip data-placement=top href=/docs/tasks/administer-cluster/configure-upgrade-etcd/ target=_blank aria-label=etcd>etcd</a>.</p><h3 id=risques>Risques</h3><ul><li>Dans le serveur API, les données secrètes sont stockées dans <a class=glossary-tooltip title='Base de données clé-valeur consistante et hautement disponible utilisée comme mémoire de sauvegarde pour toutes les données du cluster.' data-toggle=tooltip data-placement=top href=/docs/tasks/administer-cluster/configure-upgrade-etcd/ target=_blank aria-label=etcd>etcd</a>; par conséquent:<ul><li>Les administrateurs doivent activer le chiffrement au repos pour les données du cluster (nécessite la version 1.13 ou ultérieure)</li><li>Les administrateurs devraient limiter l'accès à etcd aux utilisateurs administrateurs</li><li>Les administrateurs peuvent vouloir effacer/détruire les disques utilisés par etcd lorsqu'ils ne sont plus utilisés</li><li>Si vous exécutez etcd dans un cluster, les administrateurs doivent s'assurer d'utiliser SSL/TLS pour la communication peer-to-peer etcd.</li></ul></li><li>Si vous configurez le secret via un fichier manifeste (JSON ou YAML) qui a les données secrètes codées en base64, partager ce fichier ou l'archiver dans un dépot de source signifie que le secret est compromis.
L'encodage Base64 <em>n'est pas</em> une méthode de chiffrement, il est considéré comme identique au texte brut.</li><li>Les applications doivent toujours protéger la valeur du secret après l'avoir lu dans le volume, comme ne pas le mettre accidentellement dans un journal ou le transmettre à une partie non fiable.</li><li>Un utilisateur qui peut créer un pod qui utilise un secret peut également voir la valeur de ce secret.
Même si la stratégie apiserver ne permet pas à cet utilisateur de lire l'objet secret, l'utilisateur peut créer un pod qui expose le secret.</li><li>Actuellement, toute personne disposant des droit root sur n'importe quel nœud peut lire <em>n'importe quel</em> secret depuis l'apiserver, en usurpant l'identité du kubelet.
Il est prévu de n'envoyer des secrets qu'aux nœuds qui en ont réellement besoin, pour limiter l'impact d'un exploit root sur un seul nœud.</li></ul><h2 id=a-suivre>A suivre</h2></div><div class=td-content style=page-break-before:always><h1 id=pg-712cb3c03ff14a39e5a83a6d9b71d203>3.8 - Sécurité</h1></div><div class=td-content style=page-break-before:always><h1 id=pg-ac9161c6d952925b083ad9602b4e8e7f>3.9 - Politiques</h1></div><div class=td-content style=page-break-before:always><h1 id=pg-285a3785fd3d20f437c28d87ca4dadca>3.10 - Administration d'un cluster</h1><div class=lead>Administration cluster Kubernetes</div></div><div class=td-content><h1 id=pg-fb494ea3b1874bd753dcd11c3f35c2dc>3.10.1 - Vue d'ensemble de l'administration d'un cluster</h1><div class=lead>Administration cluster Kubernetes</div><p>La vue d'ensemble de l'administration d'un cluster est destinée à toute personne créant ou administrant un cluster Kubernetes.
Il suppose une certaine familiarité avec les <a href=/docs/concepts/>concepts</a> de Kubernetes.</p><h2 id=planifier-le-déploiement-d-un-cluster>Planifier le déploiement d'un cluster</h2><p>Voir le guide: <a href=/fr/docs/setup/pick-right-solution/>choisir la bonne solution</a> pour des exemples de planification, de mise en place et de configuration de clusters Kubernetes. Les solutions répertoriées dans cet article s'appellent des <em>distributions</em>.</p><p>Avant de choisir un guide, voici quelques considérations:</p><ul><li>Voulez-vous simplement essayer Kubernetes sur votre machine ou voulez-vous créer un cluster haute disponibilité à plusieurs nœuds? Choisissez les distributions les mieux adaptées à vos besoins.</li><li><strong>Si vous recherchez la haute disponibilité</strong>, apprenez à configurer des <a href=/docs/concepts/cluster-administration/federation/>clusters multi zones</a>.</li><li>Utiliserez-vous <strong>un cluster Kubernetes hébergé</strong>, comme <a href=https://cloud.google.com/kubernetes-engine/>Google Kubernetes Engine</a>, ou <strong>hébergerez-vous votre propre cluster</strong>?</li><li>Votre cluster sera-t-il <strong>on-premises</strong>, ou <strong>sur un cloud (IaaS)</strong>? Kubernetes ne prend pas directement en charge les clusters hybrides. Cependant, vous pouvez configurer plusieurs clusters.</li><li><strong>Si vous configurez Kubernetes on-premises</strong>, choisissez le <a href=/docs/concepts/cluster-administration/networking/>modèle réseau</a> qui vous convient le mieux.</li><li>Voulez-vous faire tourner Kubernetes sur du <strong>bare metal</strong> ou sur des <strong>machines virtuelles (VMs)</strong>?</li><li>Voulez-vous <strong>simplement faire tourner un cluster</strong>, ou vous attendez-vous à faire du <strong>développement actif sur le code du projet Kubernetes</strong>? Dans ce dernier cas, choisissez une distribution activement développée. Certaines distributions n’utilisent que des versions binaires, mais offrent une plus grande variété de choix.</li><li>Familiarisez-vous avec les <a href=/docs/admin/cluster-components/>composants</a> nécessaires pour faire tourner un cluster.</li></ul><p>A noter: Toutes les distributions ne sont pas activement maintenues. Choisissez des distributions qui ont été testées avec une version récente de Kubernetes.</p><h2 id=gérer-un-cluster>Gérer un cluster</h2><ul><li><p><a href=/docs/tasks/administer-cluster/cluster-management/>Gérer un cluster</a> décrit plusieurs rubriques relatives au cycle de vie d’un cluster: création d’un nouveau cluster, mise à niveau des nœuds maître et des workers de votre cluster, maintenance des nœuds (mises à niveau du noyau, par exemple) et mise à niveau de la version de l’API Kubernetes d’un cluster en cours d’exécution.</p></li><li><p>Apprenez comment <a href=/docs/concepts/nodes/node/>gérer les nœuds</a>.</p></li><li><p>Apprenez à configurer et gérer les <a href=/docs/concepts/policy/resource-quotas/>quotas de ressources</a> pour les clusters partagés.</p></li></ul><h2 id=sécuriser-un-cluster>Sécuriser un cluster</h2><ul><li><p>La rubrique <a href=/docs/concepts/cluster-administration/certificates/>Certificats</a> décrit les étapes à suivre pour générer des certificats à l’aide de différentes suites d'outils.</p></li><li><p>L' <a href=/docs/concepts/containers/container-environment/>Environnement de conteneur dans Kubernetes</a> décrit l'environnement des conteneurs gérés par Kubelet sur un nœud Kubernetes.</p></li><li><p>Le <a href=/docs/reference/access-authn-authz/controlling-access/>Contrôle de l'accès à l'API Kubernetes</a> explique comment configurer les autorisations pour les utilisateurs et les comptes de service.</p></li><li><p>La rubrique <a href=/docs/reference/access-authn-authz/authentication/>Authentification</a> explique l'authentification dans Kubernetes, y compris les différentes options d'authentification.</p></li><li><p><a href=/docs/reference/access-authn-authz/authorization/>Autorisations</a> est distinct de l'authentification et contrôle le traitement des appels HTTP.</p></li><li><p><a href=/docs/reference/access-authn-authz/admission-controllers/>Utiliser les Admission Controllers</a> explique les plug-ins qui interceptent les requêtes adressées au serveur d'API Kubernetes après authentification et autorisation.</p></li><li><p><a href=/docs/concepts/cluster-administration/sysctl-cluster/>Utiliser Sysctls dans un cluster Kubernetes</a> explique aux administrateurs comment utiliser l'outil de ligne de commande <code>sysctl</code> pour définir les paramètres du noyau.</p></li><li><p><a href=/docs/tasks/debug-application-cluster/audit/>Auditer</a> explique comment interagir avec les journaux d'audit de Kubernetes.</p></li></ul><h3 id=sécuriser-la-kubelet>Sécuriser la Kubelet</h3><ul><li><a href=/docs/concepts/architecture/master-node-communication/>Communication Master-Node</a></li><li><a href=/docs/reference/command-line-tools-reference/kubelet-tls-bootstrapping/>TLS bootstrapping</a></li><li><a href=/docs/admin/kubelet-authentication-authorization/>Kubelet authentification/autorisations</a></li></ul><h2 id=services-de-cluster-optionnels>Services de cluster optionnels</h2><ul><li><p><a href=/docs/concepts/services-networking/dns-pod-service/>Integration DNS</a> décrit comment résoudre un nom DNS directement vers un service Kubernetes.</p></li><li><p><a href=/docs/concepts/cluster-administration/logging/>Journalisation des évènements et surveillance de l'activité du cluster</a> explique le fonctionnement de la journalisation des évènements dans Kubernetes et son implémentation.</p></li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-2bf9a93ab5ba014fb6ff70b22c29d432>3.10.2 - Certificats</h1><div class=lead>Certifications cluster Kubernetes</div><p>Lorsque vous utilisez l'authentification par certificats client, vous pouvez générer des certificats
manuellement grâce à <code>easyrsa</code>, <code>openssl</code> ou <code>cfssl</code>.</p><h3 id=easyrsa>easyrsa</h3><p><strong>easyrsa</strong> peut générer manuellement des certificats pour votre cluster.</p><ol><li><p>Téléchargez, décompressez et initialisez la version corrigée de easyrsa3.</p><pre><code>curl -LO https://storage.googleapis.com/kubernetes-release/easy-rsa/easy-rsa.tar.gz
tar xzf easy-rsa.tar.gz
cd easy-rsa-master/easyrsa3
./easyrsa init-pki
</code></pre></li><li><p>Générez une CA. (<code>--batch</code> pour le mode automatique. <code>--req-cn</code> CN par défaut à utiliser)</p><pre><code>./easyrsa --batch &quot;--req-cn=${MASTER_IP}@`date +%s`&quot; build-ca nopass
</code></pre></li><li><p>Générer un certificat de serveur et une clé.
L' argument <code>--subject-alt-name</code> définit les adresses IP et noms DNS possibles par lesquels l'API
serveur peut être atteind. La <code>MASTER_CLUSTER_IP</code> est généralement la première adresse IP du CIDR des services
qui est spécifié en tant qu'argument <code>--service-cluster-ip-range</code> pour l'API Server et
le composant controller manager. L'argument <code>--days</code> est utilisé pour définir le nombre de jours
après lesquels le certificat expire.
L’exemple ci-dessous suppose également que vous utilisez <code>cluster.local</code> par défaut comme
nom de domaine DNS.</p><pre><code>./easyrsa --subject-alt-name=&quot;IP:${MASTER_IP},&quot;\
&quot;IP:${MASTER_CLUSTER_IP},&quot;\
&quot;DNS:kubernetes,&quot;\
&quot;DNS:kubernetes.default,&quot;\
&quot;DNS:kubernetes.default.svc,&quot;\
&quot;DNS:kubernetes.default.svc.cluster,&quot;\
&quot;DNS:kubernetes.default.svc.cluster.local&quot; \
--days=10000 \
build-server-full server nopass
</code></pre></li><li><p>Copiez <code>pki/ca.crt</code>, <code>pki/issued/server.crt</code>, et <code>pki/private/server.key</code> dans votre répertoire.</p></li><li><p>Personnalisez et ajoutez les lignes suivantes aux paramètres de démarrage de l'API Server:</p><pre><code>--client-ca-file=/yourdirectory/ca.crt
--tls-cert-file=/yourdirectory/server.crt
--tls-private-key-file=/yourdirectory/server.key
</code></pre></li></ol><h3 id=openssl>openssl</h3><p><strong>openssl</strong> peut générer manuellement des certificats pour votre cluster.</p><ol><li><p>Générez ca.key en 2048bit:</p><pre><code>openssl genrsa -out ca.key 2048
</code></pre></li><li><p>A partir de la clé ca.key générez ca.crt (utilisez -days pour définir la durée du certificat):</p><pre><code>openssl req -x509 -new -nodes -key ca.key -subj &quot;/CN=${MASTER_IP}&quot; -days 10000 -out ca.crt
</code></pre></li><li><p>Générez server.key en 2048bit:</p><pre><code>openssl genrsa -out server.key 2048
</code></pre></li><li><p>Créez un fichier de configuration pour générer une demande de signature de certificat (CSR).
Assurez-vous de remplacer les valeurs marquées par des "&lt; >" (par exemple, <code>&lt;MASTER_IP></code>)
avec des valeurs réelles avant de l'enregistrer dans un fichier (par exemple, <code>csr.conf</code>).
Notez que la valeur de <code>MASTER_CLUSTER_IP</code> est celle du service Cluster IP pour l'
API Server comme décrit dans la sous-section précédente.
L’exemple ci-dessous suppose également que vous utilisez <code>cluster.local</code> par défaut comme
nom de domaine DNS.</p><pre><code>[ req ]
default_bits = 2048
prompt = no
default_md = sha256
req_extensions = req_ext
distinguished_name = dn

[ dn ]
C = &lt;country&gt;
ST = &lt;state&gt;
L = &lt;city&gt;
O = &lt;organization&gt;
OU = &lt;organization unit&gt;
CN = &lt;MASTER_IP&gt;

[ req_ext ]
subjectAltName = @alt_names

[ alt_names ]
DNS.1 = kubernetes
DNS.2 = kubernetes.default
DNS.3 = kubernetes.default.svc
DNS.4 = kubernetes.default.svc.cluster
DNS.5 = kubernetes.default.svc.cluster.local
IP.1 = &lt;MASTER_IP&gt;
IP.2 = &lt;MASTER_CLUSTER_IP&gt;

[ v3_ext ]
authorityKeyIdentifier=keyid,issuer:always
basicConstraints=CA:FALSE
keyUsage=keyEncipherment,dataEncipherment
extendedKeyUsage=serverAuth,clientAuth
subjectAltName=@alt_names
</code></pre></li><li><p>Générez la demande de signature de certificat basée sur le fichier de configuration:</p><pre><code>openssl req -new -key server.key -out server.csr -config csr.conf
</code></pre></li><li><p>Générez le certificat de serveur en utilisant ca.key, ca.crt et server.csr:</p><pre><code>openssl x509 -req -in server.csr -CA ca.crt -CAkey ca.key \
-CAcreateserial -out server.crt -days 10000 \
-extensions v3_ext -extfile csr.conf
</code></pre></li><li><p>Vérifiez le certificat:</p><pre><code>openssl x509  -noout -text -in ./server.crt
</code></pre></li></ol><p>Enfin, ajoutez les mêmes paramètres aux paramètres de démarrage de l'API Server.</p><h3 id=cfssl>cfssl</h3><p><strong>cfssl</strong> est un autre outil pour la génération de certificat.</p><ol><li><p>Téléchargez, décompressez et préparez les outils de ligne de commande comme indiqué ci-dessous.
Notez que vous devrez peut-être adapter les exemples de commandes en fonction du matériel,
de l'architecture et de la version de cfssl que vous utilisez.</p><pre><code>curl -L https://pkg.cfssl.org/R1.2/cfssl_linux-amd64 -o cfssl
chmod +x cfssl
curl -L https://pkg.cfssl.org/R1.2/cfssljson_linux-amd64 -o cfssljson
chmod +x cfssljson
curl -L https://pkg.cfssl.org/R1.2/cfssl-certinfo_linux-amd64 -o cfssl-certinfo
chmod +x cfssl-certinfo
</code></pre></li><li><p>Créez un répertoire pour contenir les artefacts et initialiser cfssl:</p><pre><code>mkdir cert
cd cert
../cfssl print-defaults config &gt; config.json
../cfssl print-defaults csr &gt; csr.json
</code></pre></li><li><p>Créez un fichier JSON pour générer le fichier d'autorité de certification, par exemple, <code>ca-config.json</code>:</p><pre><code>{
  &quot;signing&quot;: {
    &quot;default&quot;: {
      &quot;expiry&quot;: &quot;8760h&quot;
    },
    &quot;profiles&quot;: {
      &quot;kubernetes&quot;: {
        &quot;usages&quot;: [
          &quot;signing&quot;,
          &quot;key encipherment&quot;,
          &quot;server auth&quot;,
          &quot;client auth&quot;
        ],
        &quot;expiry&quot;: &quot;8760h&quot;
      }
    }
  }
}
</code></pre></li><li><p>Créez un fichier JSON pour la demande de signature de certificat de l'autorité de certification, par exemple,
<code>ca-csr.json</code>. Assurez-vous de remplacer les valeurs marquées par des "&lt; >" par
les vraies valeurs que vous voulez utiliser.</p><pre><code>{
  &quot;CN&quot;: &quot;kubernetes&quot;,
  &quot;key&quot;: {
    &quot;algo&quot;: &quot;rsa&quot;,
    &quot;size&quot;: 2048
  },
  &quot;names&quot;:[{
    &quot;C&quot;: &quot;&lt;country&gt;&quot;,
    &quot;ST&quot;: &quot;&lt;state&gt;&quot;,
    &quot;L&quot;: &quot;&lt;city&gt;&quot;,
    &quot;O&quot;: &quot;&lt;organization&gt;&quot;,
    &quot;OU&quot;: &quot;&lt;organization unit&gt;&quot;
  }]
}
</code></pre></li><li><p>Générez la clé de CA (<code>ca-key.pem</code>) et le certificat (<code>ca.pem</code>):</p><pre><code>../cfssl gencert -initca ca-csr.json | ../cfssljson -bare ca
</code></pre></li><li><p>Créer un fichier JSON pour générer des clés et des certificats pour l'API Server,
par exemple, <code>server-csr.json</code>. Assurez-vous de remplacer les valeurs entre "&lt; >" par
les vraies valeurs que vous voulez utiliser. <code>MASTER_CLUSTER_IP</code> est le service Cluster IP
de l'API Server, comme décrit dans la sous-section précédente.
L’exemple ci-dessous suppose également que vous utilisez <code>cluster.local</code> par défaut comme
nom de domaine DNS.</p><pre><code>{
  &quot;CN&quot;: &quot;kubernetes&quot;,
  &quot;hosts&quot;: [
    &quot;127.0.0.1&quot;,
    &quot;&lt;MASTER_IP&gt;&quot;,
    &quot;&lt;MASTER_CLUSTER_IP&gt;&quot;,
    &quot;kubernetes&quot;,
    &quot;kubernetes.default&quot;,
    &quot;kubernetes.default.svc&quot;,
    &quot;kubernetes.default.svc.cluster&quot;,
    &quot;kubernetes.default.svc.cluster.local&quot;
  ],
  &quot;key&quot;: {
    &quot;algo&quot;: &quot;rsa&quot;,
    &quot;size&quot;: 2048
  },
  &quot;names&quot;: [{
    &quot;C&quot;: &quot;&lt;country&gt;&quot;,
    &quot;ST&quot;: &quot;&lt;state&gt;&quot;,
    &quot;L&quot;: &quot;&lt;city&gt;&quot;,
    &quot;O&quot;: &quot;&lt;organization&gt;&quot;,
    &quot;OU&quot;: &quot;&lt;organization unit&gt;&quot;
  }]
}
</code></pre></li><li><p>Générez la clé et le certificat pour l'API Server, qui sont par défaut
sauvegardés respectivement dans les fichiers <code>server-key.pem</code> et<code> server.pem</code>:</p><pre><code>../cfssl gencert -ca=ca.pem -ca-key=ca-key.pem \
--config=ca-config.json -profile=kubernetes \
server-csr.json | ../cfssljson -bare server
</code></pre></li></ol><h2 id=distribuer-un-certificat-auto-signé>Distribuer un certificat auto-signé</h2><p>Un client peut refuser de reconnaître un certificat auto-signé comme valide.
Pour un déploiement hors production ou pour un déploiement exécuté derrière un
pare-feu d'entreprise, vous pouvez distribuer un certificat auto-signé à tous les clients et
actualiser la liste locale pour les certificats valides.</p><p>Sur chaque client, effectuez les opérations suivantes:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>$ sudo cp ca.crt /usr/local/share/ca-certificates/kubernetes.crt
</span></span><span style=display:flex><span>$ sudo update-ca-certificates
</span></span><span style=display:flex><span>Updating certificates in /etc/ssl/certs...
</span></span><span style=display:flex><span><span style=color:#666>1</span> added, <span style=color:#666>0</span> removed; <span style=color:#a2f;font-weight:700>done</span>.
</span></span><span style=display:flex><span>Running hooks in /etc/ca-certificates/update.d....
</span></span><span style=display:flex><span><span style=color:#a2f;font-weight:700>done</span>.
</span></span></code></pre></div><h2 id=api-pour-les-certificats>API pour les certificats</h2><p>Vous pouvez utiliser l’API <code>certificates.k8s.io</code> pour faire créer des
Certificats x509 à utiliser pour l'authentification, comme documenté
<a href=/docs/tasks/tls/managing-tls-in-a-cluster>ici</a>.</p></div><div class=td-content style=page-break-before:always><h1 id=pg-c4b1e87a84441f8a90699a345ce48d68>3.10.3 - Architecture de Journalisation d'évènements (logging)</h1><p>La journalisation des évènements systèmes et d'applications peut aider à
comprendre ce qui se passe dans un cluster. Les journaux sont particulièrement
utiles pour débogguer les problèmes et surveiller l'activité du cluster. La
plupart des applications modernes ont un mécanisme de journalisation
d'évènements, et la plupart des environnements d'exécution de conteneurs ont été
conçus pour supporter la journalisation des évènements. La méthode de
journalisation la plus facile et la plus répandue pour des applications
conteneurisées est d'écrire dans les flux de sortie standard et d'erreur
(<code>stdout</code> et <code>stderr</code>).</p><p>Malgré cela, la fonctionnalité de journalisation fournie nativement par
l'environnement d'exécution de conteneurs n'est pas suffisante comme solution
complète de journalisation. Quand un conteneur crashe, quand un Pod est expulsé
ou quand un nœud disparaît, il est utile de pouvoir accéder au journal
d'événements de l'application. C'est pourquoi les journaux doivent avoir leur
propre espace de stockage et un cycle de vie indépendamment des nœuds, Pods ou
conteneurs. Ce concept est appelé <em>journalisation des évènements au niveau du
cluster</em> (cluster-level-logging). Un backend dédié pour stocker, analyser et
faire des requêtes est alors nécessaire. Kubernetes n'offre pas nativement de
solution de stockage pour les journaux mais il est possible d'intégrer de
nombreuses solutions de journalisation d'évènements dans un cluster Kubernetes.</p><p>L'architecture de journalisation des évènements au niveau du cluster est décrite
en considérant qu'un backend de journalisation est présent à l'intérieur ou à
l'extérieur du cluster. Même sans avoir l'intention de journaliser les
évènements au niveau du cluster, il est intéressant de savoir comment les
journaux sont conservés et gérés au niveau d'un nœud.</p><h2 id=journalisation-simple-d-évènements-dans-kubernetes>Journalisation simple d'évènements dans Kubernetes</h2><p>Dans cette section, on va utiliser un exemple simple de journalisation
d'évènements avec le flux de sortie standard. Cette démonstration utilise un
manifeste pour un Pod avec un seul conteneur qui écrit du texte sur le flux
de sortie standard toutes les secondes.</p><div class=highlight><div class=copy-code-icon style=text-align:right><a href=https://raw.githubusercontent.com/kubernetes/website/main/content/fr/examples/debug/counter-pod.yaml download=debug/counter-pod.yaml><code>debug/counter-pod.yaml</code></a>
<img src=/images/copycode.svg style=max-height:24px;cursor:pointer onclick='copyCode("debug-counter-pod-yaml")' title="Copy debug/counter-pod.yaml to clipboard"></img></div><div class=includecode id=debug-counter-pod-yaml><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>counter<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>count<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>busybox<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>args</span>:<span style=color:#bbb> </span>[/bin/sh, -c,<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>            </span><span style=color:#b44>&#39;i=0; while true; do echo &#34;$i: $(date)&#34;; i=$((i+1)); sleep 1; done&#39;</span>]<span style=color:#bbb>
</span></span></span></code></pre></div></div></div><p>Pour lancer ce Pod, utilisez la commande suivante :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl apply -f https://k8s.io/examples/debug/counter-pod.yaml
</span></span></code></pre></div><p>Le résultat est :</p><pre tabindex=0><code>pod/counter created
</code></pre><p>Pour récupérer les événements du conteneur d'un pod, utilisez la commande
<code>kubectl logs</code> de la manière suivante :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl logs counter
</span></span></code></pre></div><p>Le résultat est :</p><pre tabindex=0><code>0: Mon Jan  1 00:00:00 UTC 2001
1: Mon Jan  1 00:00:01 UTC 2001
2: Mon Jan  1 00:00:02 UTC 2001
...
</code></pre><p>Utilisez <code>kubectl logs</code> pour récupérer les évènements de l'instanciation
précédente d'un Pod en utilisant l'option <code>--previous</code> quand par exemple le
conteneur a crashé.</p><p>Si le Pod a plusieurs conteneurs, il faut spécifier le nom du conteneur dont on
veut récupérer le journal d'évènement. Dans notre exemple le conteneur s'appelle
<code>count</code> donc vous pouvez utiliser <code>kubectl logs counter count</code>. Plus de détails
dans la [documentation de <code>kubectl logs</code>] (/docs/reference/generated/kubectl/kubectl-commands#logs)</p><h2 id=journalisation-d-évènements-au-niveau-du-nœud>Journalisation d'évènements au niveau du nœud</h2><p><img src=/images/docs/user-guide/logging/logging-node-level.png alt="Journalisation d'évènements au niveau dunœud"></p><p>Tout ce qu'une application conteneurisée écrit sur <code>stdout</code> ou <code>stderr</code> est pris
en compte et redirigé par l'environnement d'exécution des conteneurs. Par exemple,
Docker redirige ces deux flux vers un <a href=https://docs.docker.com/config/containers/logging/configure/>driver de journalisation
(EN)</a> qui est
configuré dans Kubernetes pour écrire dans un fichier au format json.</p><div class="alert alert-info note callout" role=alert><strong>Note:</strong> Le driver json de Docker traite chaque ligne comme un message
différent. Avec ce driver il n'y a pas de support direct pour des messages
multi-lignes. Il faut donc traiter les messages multi-lignes au niveau de
l'agent de journalisation ou plus en amont encore.</div><p>Par défaut quand un conteneur redémarre, le kubelet ne conserve le journal que
du dernier conteneur terminé. Quand un Pod est expulsé d'un nœud, tous ses
conteneurs sont aussi expulsés avec leurs journaux d'évènements.</p><p>Quand on utilise la journalisation d'évènements au niveau du nœud, il faut
prendre garde à mettre en place une politique de rotation des journaux adéquate
afin qu'ils n'utilisent pas tout l'espace de stockage du nœud. Kubernetes n'a
pas en charge la rotation des journaux, c'est à l'outil de déploiement de le
prendre en compte.</p><p>Par exemple, dans les clusters Kubernetes déployés avec le script <code>kube-up.sh</code>
<a href=https://linux.die.net/man/8/logrotate><code>logrotate</code></a> est configuré pour
s'exécuter toutes les heures. Il est aussi possible de configurer
l'environnement d'exécution des conteneurs pour que la rotation des journaux
s'exécute automatiquement, e.g. en utilisant le paramètre <code>log-opt</code> de Docker.
Dans le script <code>kube-up.sh</code>, c'est cette méthode qui est utilisée pour des
images COS sur GCP et sinon c'est la première méthode dans tous les autres cas.
Quelle que soit la méthode choisie par <code>kube-up.sh</code> la rotation est configurée par
défaut quand la taille d'un journal atteint 10 Mo.</p><p>Ce <a href=https://github.com/kubernetes/kubernetes/blob/main/cluster/gce/gci/configure-helper.sh>script</a> montre de manière détaillée comment <code>kube-up.sh</code>
met en place la journalisation d'évènements pour des images COS sur GCP.</p><p>Quand <a href=/docs/reference/generated/kubectl/kubectl-commands#logs><code>kubectl logs</code></a>
s'exécute comme dans le premier exemple de journalisation simple le kubelet du
nœud gère la requête et lit directement depuis le fichier de journal et retourne
son contenu dans la réponse.</p><div class="alert alert-info note callout" role=alert><strong>Note:</strong> Si un système externe a effectué la rotation des journaux, seul le
contenu du dernier fichier journal sera disponible avec <code>kubectl logs</code>. Par
exemple quand le journal atteint 10 Mo, <code>logrotate</code> effectue une rotation, il y a
alors 2 fichers, un de 10 Mo et un de vide, à ce moment là <code>kubectl logs</code>
retournera une réponse vide.</div><h3 id=journalisation-des-évènements-des-composants-système>Journalisation des évènements des composants système</h3><p>Il y a deux types de composants système selon qu'ils s'exécutent dans un
conteneur ou pas.</p><p>Par exemple :</p><ul><li>Le scheduler Kubernetes et kube-proxy s'exécutent dans un conteneur.</li><li>Kubelet et l'environnement d'exécution de conteneurs, comme par exemple
Docker, ne s'exécutent pas dans un conteneur.</li></ul><p>Sur les systèmes avec systemd, kubelet et l'environnement d'exécution de
conteneurs écrivent dans journald. Si systemd n'est pas présent, ils écrivent
dans un fichier <code>.log</code> dans le répertoire <code>/var/log</code>.</p><p>Les composants système qui s'exécutent dans un conteneur écrivent toujours dans
le répertoire <code>/var/log</code>, en contournant le mécanisme de journalisation par
défaut. Ils utilisent la bibliothèque de journalisation <a href=https://github.com/kubernetes/klog>klog</a>. Les
conventions pour la sévérité des évènements pour ces composants se trouvent dans
cette [documentation sur les conventions de journalisation des évènements dans
kubernetes]
(<a href=https://github.com/kubernetes/community/blob/master/contributors/devel/sig-instrumentation/logging.md)>https://github.com/kubernetes/community/blob/master/contributors/devel/sig-instrumentation/logging.md)</a>.</p><p>De la même manière que les journaux des conteneurs, les journaux des composants
systèmes doivent avoir une politique de rotation. Dans un cluster créé avec
le script <code>kube-up.sh</code>, les journaux ont une rotation journalière ou quand leur
taille atteint 100 Mo.</p><h2 id=architecture-de-journalisation-des-évènements-au-niveau-du-cluster>Architecture de journalisation des évènements au niveau du cluster</h2><p>Kubernetes ne fournit pas de solution native pour la journalisation des
évènements au niveau du cluster. Mais il y a différentes approches qui peuvent
être considérées :</p><ul><li>Utiliser un agent de journalisation au niveau du nœud sur chacun des nœuds.</li><li>Inclure un conteneur side-car pour journaliser les évènements du Pod
applicatif.</li><li>Envoyer les évènements directement a un backend depuis l'application.</li></ul><h3 id=utiliser-un-agent-de-journalisation-au-niveau-du-nœud>Utiliser un agent de journalisation au niveau du nœud</h3><p><img src=/images/docs/user-guide/logging/logging-with-node-agent.png alt="Utiliser un agent de journalisation au niveau dunœud"></p><p>Vous pouvez implémenter une journalisation au niveau du cluster en incluant un
<em>agent de journalisation au niveau du nœud</em> sur chacun des nœuds. L'agent de
journalisation est un outil dédié qui met à disposition ou envoie les journaux à
un backend. Communément l'agent de journalisation est un conteneur qui a accès
au répertoire qui contient les journaux des conteneurs applicatifs sur ce nœud.</p><p>Comme l'agent de journalisation doit s'exécuter sur chacun des nœuds, on utilise
soit un DaemonSet, soit un manifeste de Pod, soit un processus dédié natif sur
le nœud. Ces deux dernières options sont obsolètes et fortement découragées.</p><p>Utiliser un agent de journalisation au niveau du nœud est l'approche la plus
commune et recommandée pour un cluster Kubernetes parce qu'un seul agent par
nœud est créé et qu'aucune modification dans l'application n'est nécessaire.
Mais cette approche <em>ne fonctionne correctement que pour les flux standards de
sortie et d'erreurs des applications</em>.</p><p>Kubernetes ne définit pas d'agent de journalisation, mais deux agents de
journalisation optionnels sont fournis avec la version de Kubernetes :
<a href=/docs/user-guide/logging/stackdriver>Stackdriver (EN)</a> pour utiliser sur
Google Cloud Platform, et <a href=/docs/user-guide/logging/elasticsearch>Elasticsearch
(EN)</a>. Les deux utilisent
<a href=http://www.fluentd.org/>fluentd</a> avec une configuration spécifique comme agent
sur le nœud. Les liens précédents fournissent plus d'informations et les
instructions pour les utiliser et configurer.</p><h3 id=inclure-un-conteneur-side-car-pour-journaliser-les-évènements-du-pod-applicatif>Inclure un conteneur side-car pour journaliser les évènements du Pod applicatif</h3><p>Vous pouvez utiliser un conteneur side-car d'une des manières suivantes :</p><ul><li>Le conteneur side-car diffuse les journaux de l'application sur son propre
<code>stdout</code>.</li><li>Le conteneur side-car exécute un agent de journalisation qui est configuré
pour récupérer les journaux du conteneur applicatif.</li></ul><h4 id=conteneur-side-car-diffusant-streaming-sidecar-container>Conteneur side-car diffusant (Streaming sidecar container)</h4><p><img src=/images/docs/user-guide/logging/logging-with-streaming-sidecar.png alt="Conteneur side-cardiffusant"></p><p>Comme le conteneur side-car diffuse les journaux sur ses propres flux <code>stdout</code>
et <code>stderr</code>, on peut bénéficier du kubelet et de l'agent de journalisation qui
s'exécute déjà sur chaque nœud. Les conteneurs side-car lisent les journaux
depuis un fichier, un socket ou bien journald. Chaque conteneur side-car écrit
son journal sur son propre flux <code>stdout</code> ou <code>stderr</code>.</p><p>Cette méthode permet de séparer les flux de journaux de différentes
parties de votre application même si elles ne supportent pas d'écrire sur
<code>stdout</code> ou <code>stderr</code>. La logique de rediriger les journaux est minime et
le surcoût est non significatif. De plus comme les flux standards <code>stdout</code> et
<code>stderr</code> sont gérés par kubelet, les outils natifs comme <code>kubectl logs</code> peuvent
être utilisés.</p><p>Regardez l'exemple qui suit.</p><p>Un Pod exécute un unique conteneur et ce conteneur écrit dans deux fichiers de
journaux différents en utilisant deux format différents. Voici le manifeste du
Pod :</p><div class=highlight><div class=copy-code-icon style=text-align:right><a href=https://raw.githubusercontent.com/kubernetes/website/main/content/fr/examples/admin/logging/two-files-counter-pod.yaml download=admin/logging/two-files-counter-pod.yaml><code>admin/logging/two-files-counter-pod.yaml</code></a>
<img src=/images/copycode.svg style=max-height:24px;cursor:pointer onclick='copyCode("admin-logging-two-files-counter-pod-yaml")' title="Copy admin/logging/two-files-counter-pod.yaml to clipboard"></img></div><div class=includecode id=admin-logging-two-files-counter-pod-yaml><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>counter<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>count<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>busybox<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>args</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- /bin/sh<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- -c<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- &gt;<span style=color:#b44;font-style:italic>
</span></span></span><span style=display:flex><span><span style=color:#b44;font-style:italic>      i=0;
</span></span></span><span style=display:flex><span><span style=color:#b44;font-style:italic>      while true;
</span></span></span><span style=display:flex><span><span style=color:#b44;font-style:italic>      do
</span></span></span><span style=display:flex><span><span style=color:#b44;font-style:italic>        echo &#34;$i: $(date)&#34; &gt;&gt; /var/log/1.log;
</span></span></span><span style=display:flex><span><span style=color:#b44;font-style:italic>        echo &#34;$(date) INFO $i&#34; &gt;&gt; /var/log/2.log;
</span></span></span><span style=display:flex><span><span style=color:#b44;font-style:italic>        i=$((i+1));
</span></span></span><span style=display:flex><span><span style=color:#b44;font-style:italic>        sleep 1;
</span></span></span><span style=display:flex><span><span style=color:#b44;font-style:italic>      done</span><span style=color:#bbb>      
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>volumeMounts</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>varlog<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>mountPath</span>:<span style=color:#bbb> </span>/var/log<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>volumes</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>varlog<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>emptyDir</span>:<span style=color:#bbb> </span>{}<span style=color:#bbb>
</span></span></span></code></pre></div></div></div><p>Il serait très désordonné d'avoir des évènements avec des formats différents
dans le même journal en redirigeant les évènements dans le flux de sortie
<code>stdout</code> d'un seul conteneur. Il est plutôt souhaitable d'utiliser deux
conteneurs side-car, un pour chaque type de journaux. Chaque conteneur side-car
suit un des fichiers et renvoie les évènements sur son propre <code>stdout</code>.</p><p>Ci-dessous se trouve le manifeste pour un Pod avec deux conteneurs side-car.</p><div class=highlight><div class=copy-code-icon style=text-align:right><a href=https://raw.githubusercontent.com/kubernetes/website/main/content/fr/examples/admin/logging/two-files-counter-pod-streaming-sidecar.yaml download=admin/logging/two-files-counter-pod-streaming-sidecar.yaml><code>admin/logging/two-files-counter-pod-streaming-sidecar.yaml</code></a>
<img src=/images/copycode.svg style=max-height:24px;cursor:pointer onclick='copyCode("admin-logging-two-files-counter-pod-streaming-sidecar-yaml")' title="Copy admin/logging/two-files-counter-pod-streaming-sidecar.yaml to clipboard"></img></div><div class=includecode id=admin-logging-two-files-counter-pod-streaming-sidecar-yaml><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>counter<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>count<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>busybox<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>args</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- /bin/sh<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- -c<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- &gt;<span style=color:#b44;font-style:italic>
</span></span></span><span style=display:flex><span><span style=color:#b44;font-style:italic>      i=0;
</span></span></span><span style=display:flex><span><span style=color:#b44;font-style:italic>      while true;
</span></span></span><span style=display:flex><span><span style=color:#b44;font-style:italic>      do
</span></span></span><span style=display:flex><span><span style=color:#b44;font-style:italic>        echo &#34;$i: $(date)&#34; &gt;&gt; /var/log/1.log;
</span></span></span><span style=display:flex><span><span style=color:#b44;font-style:italic>        echo &#34;$(date) INFO $i&#34; &gt;&gt; /var/log/2.log;
</span></span></span><span style=display:flex><span><span style=color:#b44;font-style:italic>        i=$((i+1));
</span></span></span><span style=display:flex><span><span style=color:#b44;font-style:italic>        sleep 1;
</span></span></span><span style=display:flex><span><span style=color:#b44;font-style:italic>      done</span><span style=color:#bbb>      
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>volumeMounts</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>varlog<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>mountPath</span>:<span style=color:#bbb> </span>/var/log<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>count-log-1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>busybox<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>args</span>:<span style=color:#bbb> </span>[/bin/sh, -c, &#39;tail -n+1 -f /var/log/1.log&#39;]<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>volumeMounts</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>varlog<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>mountPath</span>:<span style=color:#bbb> </span>/var/log<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>count-log-2<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>busybox<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>args</span>:<span style=color:#bbb> </span>[/bin/sh, -c, &#39;tail -n+1 -f /var/log/2.log&#39;]<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>volumeMounts</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>varlog<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>mountPath</span>:<span style=color:#bbb> </span>/var/log<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>volumes</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>varlog<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>emptyDir</span>:<span style=color:#bbb> </span>{}<span style=color:#bbb>
</span></span></span></code></pre></div></div></div><p>Quand ce Pod s'exécute, chaque journal peut être diffusé séparément en
utilisant les commandes suivantes :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl logs counter count-log-1
</span></span></code></pre></div><pre tabindex=0><code>0: Mon Jan  1 00:00:00 UTC 2001
1: Mon Jan  1 00:00:01 UTC 2001
2: Mon Jan  1 00:00:02 UTC 2001
...
</code></pre><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl logs counter count-log-2
</span></span></code></pre></div><pre tabindex=0><code>Mon Jan  1 00:00:00 UTC 2001 INFO 0
Mon Jan  1 00:00:01 UTC 2001 INFO 1
Mon Jan  1 00:00:02 UTC 2001 INFO 2
...
</code></pre><p>L'agent au niveau du nœud installé dans le cluster récupère les deux flux de
journaux sans aucune configuration supplémentaire. Il est possible de configurer
l'agent pour qu'il analyse syntaxiquement les évènements en fonction du
conteneur source.</p><p>Notez que bien que la consommation en CPU et mémoire soit faible ( de l'ordre de
quelques milicores pour la CPU et quelques mégaoctets pour la mémoire), ecrire
les évènements dans un fichier et les envoyer ensuite dans <code>stdout</code> peut doubler
l'espace disque utilisé. Quand une application écrit dans un seul fichier de
journal, il est préférable de configurer <code>/dev/stdout</code> comme destination plutôt
que d'implémenter un conteneur side-car diffusant.</p><p>Les conteneurs side-car peuvent être utilisés pour faire la rotation des
journaux quand l'application n'en est pas capable elle-même. Un exemple serait
un petit conteneur side-car qui effectuerait cette rotation périodiquement.
Toutefois, il est recommandé d'utiliser <code>stdout</code> et <code>stderr</code> directement et de
laisser la rotation et les politiques de rétentions au kubelet.</p><h3 id=conteneur-side-car-avec-un-agent-de-journalisation>Conteneur side-car avec un agent de journalisation</h3><p><img src=/images/docs/user-guide/logging/logging-with-sidecar-agent.png alt="Conteneur side-car avec un agent dejournalisation"></p><p>Quand un agent de journalisation au niveau du nœud n'est pas assez flexible pour
votre utilisation, vous pouvez créer un conteneur side-car avec un agent de
journalisation séparé que vous avez configuré spécialement pour qu'il s'exécute
avec votre application.</p><div class="alert alert-info note callout" role=alert><strong>Note:</strong> Utiliser un agent de journalisation dans un conteneur side-car peut entraîner
une consommation de ressources significative. De plus vous n'avez plus accès aux
journaux avec la commande <code>kubectl</code> parce qu'ils ne sont plus gérés par
kubelet.</div><p>Comme exemple, vous pouvez utiliser
<a href=/docs/tasks/debug-application-cluster/logging-stackdriver/>Stackdriver</a> où
fluentd est l'agent de journalisation. Ci-dessous se trouvent deux
configurations qui implémentent cette méthode.</p><p>Le premier fichier contient un
<a href=/docs/tasks/configure-pod-container/configure-pod-configmap/>ConfigMap</a> pour
configurer fluentd.</p><div class=highlight><div class=copy-code-icon style=text-align:right><a href=https://raw.githubusercontent.com/kubernetes/website/main/content/fr/examples/admin/logging/fluentd-sidecar-config.yaml download=admin/logging/fluentd-sidecar-config.yaml><code>admin/logging/fluentd-sidecar-config.yaml</code></a>
<img src=/images/copycode.svg style=max-height:24px;cursor:pointer onclick='copyCode("admin-logging-fluentd-sidecar-config-yaml")' title="Copy admin/logging/fluentd-sidecar-config.yaml to clipboard"></img></div><div class=includecode id=admin-logging-fluentd-sidecar-config-yaml><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>ConfigMap<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>fluentd-config<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>data</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>fluentd.conf</span>:<span style=color:#bbb> </span>|<span style=color:#b44;font-style:italic>
</span></span></span><span style=display:flex><span><span style=color:#b44;font-style:italic>    &lt;source&gt;
</span></span></span><span style=display:flex><span><span style=color:#b44;font-style:italic>      type tail
</span></span></span><span style=display:flex><span><span style=color:#b44;font-style:italic>      format none
</span></span></span><span style=display:flex><span><span style=color:#b44;font-style:italic>      path /var/log/1.log
</span></span></span><span style=display:flex><span><span style=color:#b44;font-style:italic>      pos_file /var/log/1.log.pos
</span></span></span><span style=display:flex><span><span style=color:#b44;font-style:italic>      tag count.format1
</span></span></span><span style=display:flex><span><span style=color:#b44;font-style:italic>    &lt;/source&gt;
</span></span></span><span style=display:flex><span><span style=color:#b44;font-style:italic>
</span></span></span><span style=display:flex><span><span style=color:#b44;font-style:italic>    &lt;source&gt;
</span></span></span><span style=display:flex><span><span style=color:#b44;font-style:italic>      type tail
</span></span></span><span style=display:flex><span><span style=color:#b44;font-style:italic>      format none
</span></span></span><span style=display:flex><span><span style=color:#b44;font-style:italic>      path /var/log/2.log
</span></span></span><span style=display:flex><span><span style=color:#b44;font-style:italic>      pos_file /var/log/2.log.pos
</span></span></span><span style=display:flex><span><span style=color:#b44;font-style:italic>      tag count.format2
</span></span></span><span style=display:flex><span><span style=color:#b44;font-style:italic>    &lt;/source&gt;
</span></span></span><span style=display:flex><span><span style=color:#b44;font-style:italic>
</span></span></span><span style=display:flex><span><span style=color:#b44;font-style:italic>    &lt;match **&gt;
</span></span></span><span style=display:flex><span><span style=color:#b44;font-style:italic>      type google_cloud
</span></span></span><span style=display:flex><span><span style=color:#b44;font-style:italic>    &lt;/match&gt;</span><span style=color:#bbb>    
</span></span></span></code></pre></div></div></div><div class="alert alert-info note callout" role=alert><strong>Note:</strong> La configuration de fluentd est hors du cadre de cet article. Vous trouverez
des informations pour configurer fluentd dans la <a href=http://docs.fluentd.org/>documentation officielle de
fluentd</a>.</div><p>Le second fichier est un manifeste pour un Pod avec un conteneur side-car qui
exécute fluentd. Le Pod monte un volume où fluentd peut récupérer sa
configuration.</p><div class=highlight><div class=copy-code-icon style=text-align:right><a href=https://raw.githubusercontent.com/kubernetes/website/main/content/fr/examples/admin/logging/two-files-counter-pod-agent-sidecar.yaml download=admin/logging/two-files-counter-pod-agent-sidecar.yaml><code>admin/logging/two-files-counter-pod-agent-sidecar.yaml</code></a>
<img src=/images/copycode.svg style=max-height:24px;cursor:pointer onclick='copyCode("admin-logging-two-files-counter-pod-agent-sidecar-yaml")' title="Copy admin/logging/two-files-counter-pod-agent-sidecar.yaml to clipboard"></img></div><div class=includecode id=admin-logging-two-files-counter-pod-agent-sidecar-yaml><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>counter<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>count<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>busybox<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>args</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- /bin/sh<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- -c<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- &gt;<span style=color:#b44;font-style:italic>
</span></span></span><span style=display:flex><span><span style=color:#b44;font-style:italic>      i=0;
</span></span></span><span style=display:flex><span><span style=color:#b44;font-style:italic>      while true;
</span></span></span><span style=display:flex><span><span style=color:#b44;font-style:italic>      do
</span></span></span><span style=display:flex><span><span style=color:#b44;font-style:italic>        echo &#34;$i: $(date)&#34; &gt;&gt; /var/log/1.log;
</span></span></span><span style=display:flex><span><span style=color:#b44;font-style:italic>        echo &#34;$(date) INFO $i&#34; &gt;&gt; /var/log/2.log;
</span></span></span><span style=display:flex><span><span style=color:#b44;font-style:italic>        i=$((i+1));
</span></span></span><span style=display:flex><span><span style=color:#b44;font-style:italic>        sleep 1;
</span></span></span><span style=display:flex><span><span style=color:#b44;font-style:italic>      done</span><span style=color:#bbb>      
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>volumeMounts</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>varlog<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>mountPath</span>:<span style=color:#bbb> </span>/var/log<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>count-agent<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>k8s.gcr.io/fluentd-gcp:1.30<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>env</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>FLUENTD_ARGS<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>value</span>:<span style=color:#bbb> </span>-c /etc/fluentd-config/fluentd.conf<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>volumeMounts</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>varlog<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>mountPath</span>:<span style=color:#bbb> </span>/var/log<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>config-volume<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>mountPath</span>:<span style=color:#bbb> </span>/etc/fluentd-config<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>volumes</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>varlog<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>emptyDir</span>:<span style=color:#bbb> </span>{}<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>config-volume<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>configMap</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>fluentd-config<span style=color:#bbb>
</span></span></span></code></pre></div></div></div><p>Apres quelques minutes, les évènements apparaîtront dans l'interface de
Stackdriver.</p><p>Ce n'est qu'un exemple et vous pouvez remplacer fluentd par n'importe quel
agent de journalisation qui lit depuis n'importe quelle source de votre
application.</p><h3 id=envoyer-les-évènements-directement-depuis-l-application>Envoyer les évènements directement depuis l'application.</h3><p><img src=/images/docs/user-guide/logging/logging-from-application.png alt="Envoyer les évènements directement a un backend depuisl'application."></p><p>Vous pouvez implémenter la journalisation au niveau cluster en mettant à
disposition ou en envoyant les journaux directement depuis chaque application;
Toutefois l'implémentation de ce mécanisme de journalisation est hors du cadre
de Kubernetes.</p></div><div class=td-content style=page-break-before:always><h1 id=pg-7e0d97616b15e2c383c6a0a96ec442cb>3.11 - Extensions Kubernetes</h1></div><div class=td-content><h1 id=pg-0af41d3bd7c785621b58b7564793396a>3.11.1 - Extensions de l'API Kubernetes</h1></div><div class=td-content style=page-break-before:always><h1 id=pg-c8937cdc9df96f3328becf04f8211292>3.11.2 - Extensions compute, stockage et réseau</h1></div><div class=td-content style=page-break-before:always><h1 id=pg-43f3f6f898190163fe7314de24b1dd1c>4 - Solutions indépendantes</h1></div><div class=td-content><h1 id=pg-9d8860326aa0a9106035ce48c98feb47>4.1 - Serveurs physiques</h1></div><div class=td-content style=page-break-before:always><h1 id=pg-f8918f697450c2009b75913f9e9317a5>5 - Tâches</h1><nav id=TableOfContents><ul><li><a href=#dashboard>Interface web (Dashboard)</a></li><li><a href=#utilisation-de-la-ligne-de-commande-kubectl>Utilisation de la ligne de commande kubectl</a></li><li><a href=#configuration-des-pods-et-des-conteneurs>Configuration des Pods et des Conteneurs</a></li><li><a href=#exécution-d-applications>Exécution d'applications</a></li><li><a href=#executez-des-jobs>Executez des jobs</a></li><li><a href=#accéder-aux-applications-dans-un-cluster>Accéder aux applications dans un cluster</a></li><li><a href=#monitoring-logging-and-debugging>Monitoring, Logging, and Debugging</a></li><li><a href=#accéder-à-l-api-kubernetes>Accéder à l'API Kubernetes</a></li><li><a href=#utiliser-tls>Utiliser TLS</a></li><li><a href=#administration-d-un-cluster>Administration d'un cluster</a></li><li><a href=#administration-d-une-fédération>Administration d'une fédération</a></li><li><a href=#gestion-des-applications-avec-état>Gestion des applications avec état</a></li><li><a href=#gestion-des-démons-cluster>Gestion des démons cluster</a></li><li><a href=#gestion-des-gpu>Gestion des GPU</a></li><li><a href=#gestion-des-hugepages>Gestion des HugePages</a></li><li><a href=#a-suivre>A suivre</a></li></ul></nav><p>Cette section de la documentation de Kubernetes contient des pages qui montrent comment effectuer des tâches individuelles.
Une page montre comment effectuer une seule chose, généralement en donnant une courte séquence d'étapes.</p><h2 id=dashboard>Interface web (Dashboard)</h2><p>Déployer et accéder au dashboard web de votre cluster pour vous aider à le gérer et administrer un cluster Kubernetes.</p><h2 id=utilisation-de-la-ligne-de-commande-kubectl>Utilisation de la ligne de commande kubectl</h2><p>Installez et configurez l’outil en ligne de commande <code>kubectl</code> utilisé pour gérer directement les clusters Kubernetes.</p><h2 id=configuration-des-pods-et-des-conteneurs>Configuration des Pods et des Conteneurs</h2><p>Effectuer des tâches de configuration courantes pour les pods et les conteneurs.</p><h2 id=exécution-d-applications>Exécution d'applications</h2><p>Effectuez des tâches courantes de gestion des applications, telles que les mises à jour progressives, l'injection de données dans les pods et la mise à l'échelle automatique des pods.</p><h2 id=executez-des-jobs>Executez des jobs</h2><p>Exécuter des jobs en utilisant un traitement parallèle</p><h2 id=accéder-aux-applications-dans-un-cluster>Accéder aux applications dans un cluster</h2><p>Configuration du load balancing, du port forwarding, ou mise en place d'un firewall ou la configuration DNS pour accéder aux applications dans un cluster.</p><h2 id=monitoring-logging-and-debugging>Monitoring, Logging, and Debugging</h2><p>Mettre en place le monitoring et le logging pour diagnostiquer un cluster ou debugguer une application conteneurisée.</p><h2 id=accéder-à-l-api-kubernetes>Accéder à l'API Kubernetes</h2><p>Apprenez diverses méthodes pour accéder directement à l'API Kubernetes.</p><h2 id=utiliser-tls>Utiliser TLS</h2><p>Configurer votre application pour faire confiance à et utiliser le certificat racine de votre Certificate Authority (CA).</p><h2 id=administration-d-un-cluster>Administration d'un cluster</h2><p>Apprenez les tâches courantes pour administrer un cluster.</p><h2 id=administration-d-une-fédération>Administration d'une fédération</h2><p>Configurez les composants dans une fédération de cluster.</p><h2 id=gestion-des-applications-avec-état>Gestion des applications avec état</h2><p>Effectuez des taches communes pour gérer des applications avec état, notamment la mise à l'échelle, la suppression et le debugging des objets StatefulSets.</p><h2 id=gestion-des-démons-cluster>Gestion des démons cluster</h2><p>Effectuez des tâches courantes pour gérer un DaemonSet, telles que la mise à jour progressive.</p><h2 id=gestion-des-gpu>Gestion des GPU</h2><p>Configurer des GPUs NVIDIA pour les utiliser dans des noeuds dans un cluster.</p><h2 id=gestion-des-hugepages>Gestion des HugePages</h2><p>Configuration des huge pages comme une ressource planifiable dans un cluster.</p><h2 id=a-suivre>A suivre</h2><p>Si vous souhaitez écrire une page, consultez
<a href=/docs/home/contribute/create-pull-request/>Création d'une PullRequest de documentation</a>.</p></div><div class=td-content style=page-break-before:always><h1 id=pg-57bf66f59d9a642b82eebeabbc66470b>5.1 - Outils d'installation</h1></div><div class=td-content><h1 id=pg-bbdc530b292ab4074d1dfe69feafb3e7>5.1.1 - Installer et configurer kubectl</h1><div class=lead>Installation et configuration de kubectl</div><p>L'outil en ligne de commande de kubernetes, <a href=/docs/user-guide/kubectl/>kubectl</a>, vous permet d'exécuter des commandes dans les clusters Kubernetes. Vous pouvez utiliser kubectl pour déployer des applications, inspecter et gérer les ressources du cluster et consulter les logs. Pour une liste complète des opérations kubectl, voir <a href=/fr/docs/reference/kubectl/overview/>Aperçu de kubectl</a>.</p><h2 id=pré-requis>Pré-requis</h2><p>Vous devez utiliser une version de kubectl qui différe seulement d'une version mineure de la version de votre cluster. Par exemple, un client v1.2 doit fonctionner avec un master v1.1, v1.2 et v1.3. L'utilisation de la dernière version de kubectl permet d'éviter des problèmes imprévus.</p><h2 id=installer-kubectl-sur-linux>Installer kubectl sur Linux</h2><h3 id=installer-le-binaire-de-kubectl-avec-curl-sur-linux>Installer le binaire de kubectl avec curl sur Linux</h3><ol><li><p>Téléchargez la dernière release avec la commande :</p><pre tabindex=0><code>curl -LO https://storage.googleapis.com/kubernetes-release/release/$(curl -s https://storage.googleapis.com/kubernetes-release/release/stable.txt)/bin/linux/amd64/kubectl
</code></pre><p>Pour télécharger une version spécifique, remplacez <code>$(curl -s https://storage.googleapis.com/kubernetes-release/release/stable.txt)</code> avec la version spécifique.</p><p>Par exemple, pour télécharger la version v1.25.0 sur Linux, tapez :</p><pre tabindex=0><code>curl -LO https://storage.googleapis.com/kubernetes-release/release/v1.25.0/bin/linux/amd64/kubectl
</code></pre></li><li><p>Rendez le binaire kubectl exécutable.</p><pre tabindex=0><code>chmod +x ./kubectl
</code></pre></li><li><p>Déplacez le binaire dans votre PATH.</p><pre tabindex=0><code>sudo mv ./kubectl /usr/local/bin/kubectl
</code></pre></li><li><p>Testez pour vous assurer que la version que vous avez installée est à jour:</p><pre tabindex=0><code>kubectl version --client
</code></pre></li></ol><h3 id=installation-à-l-aide-des-gestionnaires-des-paquets-natifs>Installation à l'aide des gestionnaires des paquets natifs</h3><ul class="nav nav-tabs" id=kubectl-install role=tablist><li class=nav-item><a data-toggle=tab class="nav-link active" href=#kubectl-install-0 role=tab aria-controls=kubectl-install-0 aria-selected=true>Ubuntu, Debian or HypriotOS</a></li><li class=nav-item><a data-toggle=tab class=nav-link href=#kubectl-install-1 role=tab aria-controls=kubectl-install-1>CentOS, RHEL or Fedora</a></li></ul><div class=tab-content id=kubectl-install><div id=kubectl-install-0 class="tab-pane show active" role=tabpanel aria-labelledby=kubectl-install-0><p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>
</span></span><span style=display:flex><span>sudo apt-get update <span style=color:#666>&amp;&amp;</span> sudo apt-get install -y apt-transport-https
</span></span><span style=display:flex><span>curl -s https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key add -
</span></span><span style=display:flex><span><span style=color:#a2f>echo</span> <span style=color:#b44>&#34;deb https://apt.kubernetes.io/ kubernetes-xenial main&#34;</span> | sudo tee -a /etc/apt/sources.list.d/kubernetes.list
</span></span><span style=display:flex><span>sudo apt-get update
</span></span><span style=display:flex><span>sudo apt-get install -y kubectl
</span></span></code></pre></div></div><div id=kubectl-install-1 class=tab-pane role=tabpanel aria-labelledby=kubectl-install-1><p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>sudo cat <span style=color:#b44>&lt;&lt;EOF &gt; /etc/yum.repos.d/kubernetes.repo
</span></span></span><span style=display:flex><span><span style=color:#b44>[kubernetes]
</span></span></span><span style=display:flex><span><span style=color:#b44>name=Kubernetes
</span></span></span><span style=display:flex><span><span style=color:#b44>baseurl=https://packages.cloud.google.com/yum/repos/kubernetes-el7-x86_64
</span></span></span><span style=display:flex><span><span style=color:#b44>enabled=1
</span></span></span><span style=display:flex><span><span style=color:#b44>gpgcheck=1
</span></span></span><span style=display:flex><span><span style=color:#b44>repo_gpgcheck=1
</span></span></span><span style=display:flex><span><span style=color:#b44>gpgkey=https://packages.cloud.google.com/yum/doc/rpm-package-key.gpg
</span></span></span><span style=display:flex><span><span style=color:#b44>EOF</span>
</span></span><span style=display:flex><span>sudo yum install -y kubectl
</span></span></code></pre></div></div></div><h3 id=installation-avec-des-gestionnaires-de-paquets-alternatifs>Installation avec des gestionnaires de paquets alternatifs</h3><ul class="nav nav-tabs" id=other-kubectl-install role=tablist><li class=nav-item><a data-toggle=tab class="nav-link active" href=#other-kubectl-install-0 role=tab aria-controls=other-kubectl-install-0 aria-selected=true>Snap</a></li><li class=nav-item><a data-toggle=tab class=nav-link href=#other-kubectl-install-1 role=tab aria-controls=other-kubectl-install-1>Homebrew</a></li></ul><div class=tab-content id=other-kubectl-install><div id=other-kubectl-install-0 class="tab-pane show active" role=tabpanel aria-labelledby=other-kubectl-install-0><p><p>Si vous êtes sur Ubuntu ou une autre distribution Linux qui supporte le gestionnaire de paquets <a href=https://snapcraft.io/docs/core/install>snap</a>, kubectl est disponible comme application <a href=https://snapcraft.io/>snap</a>.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>snap install kubectl --classic
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>kubectl version --client
</span></span></code></pre></div></div><div id=other-kubectl-install-1 class=tab-pane role=tabpanel aria-labelledby=other-kubectl-install-1><p><p>Si vous êtes sur Linux et que vous utiliser <a href=https://docs.brew.sh/Homebrew-on-Linux>Homebrew</a> comme gestionnaire de paquets, kubectl est disponible. <a href=https://docs.brew.sh/Homebrew-on-Linux#install>installation</a></p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>brew install kubectl
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>kubectl version --client
</span></span></code></pre></div></div></div><h2 id=installer-kubectl-sur-macos>Installer kubectl sur macOS</h2><h3 id=installer-le-binaire-kubectl-avec-curl-sur-macos>Installer le binaire kubectl avec curl sur macOS</h3><ol><li><p>Téléchargez la dernière version:</p><pre tabindex=0><code>curl -LO https://storage.googleapis.com/kubernetes-release/release/$(curl -s https://storage.googleapis.com/kubernetes-release/release/stable.txt)/bin/darwin/amd64/kubectl
</code></pre><p>Pour télécharger une version spécifique, remplacez <code>$(curl -s https://storage.googleapis.com/kubernetes-release/release/stable.txt)</code> avec la version spécifique.</p><p>Par exemple, pour télécharger la version v1.25.0 sur macOS, tapez :</p><pre tabindex=0><code>curl -LO https://storage.googleapis.com/kubernetes-release/release/v1.25.0/bin/darwin/amd64/kubectl
</code></pre></li><li><p>Rendez le binaire kubectl exécutable.</p><pre tabindex=0><code>chmod +x ./kubectl
</code></pre></li><li><p>Déplacez le binaire dans votre PATH.</p><pre tabindex=0><code>sudo mv ./kubectl /usr/local/bin/kubectl
</code></pre></li><li><p>Testez pour vous assurer que la version que vous avez installée est à jour:</p><pre tabindex=0><code>kubectl version --client
</code></pre></li></ol><h3 id=installer-avec-homebrew-sur-macos>Installer avec Homebrew sur macOS</h3><p>Si vous êtes sur MacOS et que vous utilisez le gestionnaire de paquets <a href=https://brew.sh/>Homebrew</a>, vous pouvez installer kubectl avec Homebrew.</p><ol><li><p>Exécutez la commande d'installation:</p><pre tabindex=0><code>brew install kubectl 
</code></pre><p>ou</p><pre tabindex=0><code>brew install kubernetes-cli
</code></pre></li><li><p>Testez pour vous assurer que la version que vous avez installée est à jour:</p><pre tabindex=0><code>kubectl version --client
</code></pre></li></ol><h3 id=installer-avec-macports-sur-macos>Installer avec Macports sur macOS</h3><p>Si vous êtes sur MacOS et que vous utilisez le gestionnaire de paquets <a href=https://macports.org/>Macports</a>, vous pouvez installer kubectl avec Macports.</p><ol><li><p>Exécuter la commande d'installation:</p><pre tabindex=0><code>sudo port selfupdate
sudo port install kubectl
</code></pre></li><li><p>Testez pour vous assurer que la version que vous avez installée est à jour:</p><pre tabindex=0><code>kubectl version --client
</code></pre></li></ol><h2 id=installer-kubectl-sur-windows>Installer kubectl sur Windows</h2><h3 id=installer-le-binaire-kubectl-avec-curl-sur-windows>Installer le binaire kubectl avec curl sur Windows</h3><ol><li><p>Téléchargez la dernière version v1.25.0 depuis <a href=https://storage.googleapis.com/kubernetes-release/release/v1.25.0/bin/windows/amd64/kubectl.exe>ce lien</a>.</p><p>Ou si vous avez <code>curl</code> installé, utilisez cette commande:</p><pre tabindex=0><code>curl -LO https://storage.googleapis.com/kubernetes-release/release/v1.25.0/bin/windows/amd64/kubectl.exe
</code></pre><p>Pour connaître la dernière version stable (par exemple, en scripting), jetez un coup d'oeil à <a href=https://storage.googleapis.com/kubernetes-release/release/stable.txt>https://storage.googleapis.com/kubernetes-release/release/stable.txt</a>.</p></li><li><p>Ajoutez le binaire dans votre PATH.</p></li><li><p>Testez pour vous assurer que la version que vous avez installée est à jour:</p><pre tabindex=0><code>kubectl version --client
</code></pre></li></ol><div class="alert alert-info note callout" role=alert><strong>Note:</strong> <a href=https://docs.docker.com/docker-for-windows/#kubernetes>Docker Desktop pour Windows</a> ajoute sa propre version de <code>kubectl</code> au $PATH.
Si vous avez déjà installé Docker Desktop, vous devrez peut-être placer votre entrée PATH avant celle ajoutée par le programme d'installation de Docker Desktop ou supprimer le <code>kubectl</code> de Docker Desktop.</div><h3 id=installer-avec-powershell-de-psgallery>Installer avec Powershell de PSGallery</h3><p>Si vous êtes sous Windows et que vous utilisez le gestionnaire de paquets <a href=https://www.powershellgallery.com/>Powershell Gallery</a> , vous pouvez installer et mettre à jour kubectl avec Powershell.</p><ol><li><p>Exécutez les commandes d'installation (spécifier le <code>DownloadLocation</code>):</p><pre tabindex=0><code>Install-Script -Name install-kubectl -Scope CurrentUser -Force
install-kubectl.ps1 [-DownloadLocation &lt;path&gt;]
</code></pre><div class="alert alert-info note callout" role=alert><strong>Note:</strong> Si vous ne spécifiez pas un <code>DownloadLocation</code>, <code>kubectl</code> sera installé dans le répertoire temp de l'utilisateur.</div><p>Le programme d'installation creé <code>$HOME/.kube</code> qui est suivie par la création d'un fichier de configuration</p></li><li><p>Testez pour vous assurer que la version que vous avez installée est à jour:</p><pre tabindex=0><code>kubectl version --client
</code></pre><div class="alert alert-info note callout" role=alert><strong>Note:</strong> La mise à jour de l'installation s'effectue en réexécutant les deux commandes listées à l'étape 1.</div></li></ol><h3 id=installer-sur-windows-avec-chocolatey-ou-scoop>Installer sur Windows avec Chocolatey ou Scoop</h3><p>Pour installer kubectl sur Windows, vous pouvez utiliser le gestionnaire de paquets <a href=https://chocolatey.org>Chocolatey</a> ou l'installateur en ligne de commande <a href=https://scoop.sh>Scoop</a>.<ul class="nav nav-tabs" id=kubectl-win-install role=tablist><li class=nav-item><a data-toggle=tab class="nav-link active" href=#kubectl-win-install-0 role=tab aria-controls=kubectl-win-install-0 aria-selected=true>choco</a></li><li class=nav-item><a data-toggle=tab class=nav-link href=#kubectl-win-install-1 role=tab aria-controls=kubectl-win-install-1>scoop</a></li></ul><div class=tab-content id=kubectl-win-install><div id=kubectl-win-install-0 class="tab-pane show active" role=tabpanel aria-labelledby=kubectl-win-install-0><p><pre><code>choco install kubernetes-cli
</code></pre></div><div id=kubectl-win-install-1 class=tab-pane role=tabpanel aria-labelledby=kubectl-win-install-1><p><pre><code>scoop install kubectl
</code></pre></div></div>2. Testez pour vous assurer que la version que vous avez installée est à jour:</p><pre><code>```
kubectl version --client
```
</code></pre><ol start=3><li><p>Accédez à votre répertoire personnel:</p><pre tabindex=0><code>cd %USERPROFILE%
</code></pre></li><li><p>Créez le répertoire <code>.kube</code>:</p><pre tabindex=0><code>mkdir .kube
</code></pre></li><li><p>Allez dans le répertoire <code>.kube</code> que vous venez de créer:</p><pre tabindex=0><code>cd .kube
</code></pre></li><li><p>Configurez kubectl pour utiliser un remote cluster Kubernetes:</p><pre tabindex=0><code>New-Item config -type file
</code></pre><div class="alert alert-info note callout" role=alert><strong>Note:</strong> Editez le fichier de configuration avec un éditeur de texte de votre choix, tel que Notepad.</div></li></ol><h2 id=télécharger-en-tant-qu-élément-du-sdk-google-cloud>Télécharger en tant qu'élément du SDK Google Cloud</h2><p>Vous pouvez installer kubectl en tant qu'élément du SDK Google Cloud.</p><ol><li><p>Installer <a href=https://cloud.google.com/sdk/>Google Cloud SDK</a>.</p></li><li><p>Exécutez la commande d'installation <code>kubectl</code>:</p><pre tabindex=0><code>gcloud components install kubectl
</code></pre></li><li><p>Testez pour vous assurer que la version que vous avez installée est à jour:</p><pre tabindex=0><code>kubectl version --client
</code></pre></li></ol><h2 id=vérification-de-la-configuration-de-kubectl>Vérification de la configuration de kubectl</h2><p>Pour permettre à kubectl de trouver et d'accéder à un cluster Kubernetes, il lui faut un <a href=/docs/tasks/access-application-cluster/configure-access-multiple-clusters/>fichier kubeconfig</a>, qui est créé automatiquement lorsque vous créez un cluster avec <a href=https://github.com/kubernetes/kubernetes/blob/master/cluster/kube-up.sh>kube-up.sh</a> ou en déployant un cluster Minikube avec succès. Par défaut, la configuration de kubectl est située sous <code>~/.kube/config</code>.</p><p>Vérifiez que kubectl est correctement configuré en obtenant l'état du cluster:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl cluster-info
</span></span></code></pre></div><p>Si vous voyez une réponse avec une URL, kubectl est correctement configuré pour accéder à votre cluster.</p><p>Si vous voyez un message similaire à celui qui suit, kubectl n'est pas configuré correctement ou n'est pas capable de se connecter à un cluster Kubernetes.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>The connection to the server &lt;server-name:port&gt; was refused - did you specify the right host or port?
</span></span></code></pre></div><p>Si par exemple, vous avez l'intention d'exécuter un cluster Kubernetes sur votre machine (localement), vous aurez besoin d'un outil comme Minikube pour être installé en premier et exécuter à nouveau les commandes décrites ci-dessus.</p><p>Si kubectl cluster-info retourne la réponse en url mais que vous ne pouvez pas accéder à votre cluster, vous pouvez vérifier s'il est configuré correctement, en utilisant:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl cluster-info dump
</span></span></code></pre></div><h2 id=configurations-kubectl-optionnelles>Configurations kubectl optionnelles</h2><h3 id=activation-de-l-auto-complétion-de-shell>Activation de l'auto-complétion de shell</h3><p>kubectl fournit un support d'auto-complétion pour Bash et Zsh, ce qui peut vous éviter beaucoup de temps de saisie.</p><p>Vous trouverez ci-dessous les étapes à suivre pour configurer l'auto-complétion pour Bash (y compris la différence entre Linux et MacOS) et Zsh.</p><ul class="nav nav-tabs" id=kubectl-autocompletion role=tablist><li class=nav-item><a data-toggle=tab class="nav-link active" href=#kubectl-autocompletion-0 role=tab aria-controls=kubectl-autocompletion-0 aria-selected=true>Bash sur Linux</a></li><li class=nav-item><a data-toggle=tab class=nav-link href=#kubectl-autocompletion-1 role=tab aria-controls=kubectl-autocompletion-1>Bash sur macOS</a></li><li class=nav-item><a data-toggle=tab class=nav-link href=#kubectl-autocompletion-2 role=tab aria-controls=kubectl-autocompletion-2>Zsh</a></li></ul><div class=tab-content id=kubectl-autocompletion><div id=kubectl-autocompletion-0 class="tab-pane show active" role=tabpanel aria-labelledby=kubectl-autocompletion-0><p><h3 id=introduction>Introduction</h3><p>Le script de complétion kubectl pour Bash peut être généré avec la commande <code>kubectl completion bash</code>. Sourcer le script de completion dans votre shell permet l'auto-complétion de kubectl.</p><p>En revanche, le script de complétion dépend de <a href=https://github.com/scop/bash-completion><strong>bash-completion</strong></a>, ce qui implique que vous devez d'abord installer ce logiciel (vous pouvez tester si vous avez déjà installé bash-completion en utilisant <code>type _init_completion</code>).</p><h3 id=installer-bash-completion>Installer bash-completion</h3><p>bash-completion est fourni par plusieurs gestionnaires de paquets (voir <a href=https://github.com/scop/bash-completion#installation>ici</a>). Vous pouvez l'installer avec <code>apt-get install bash-completion</code> or <code>yum install bash-completion</code>, etc.</p><p>Les commandes ci-dessus créent <code>/usr/share/bash-completion/bash_completion</code>, qui est le script principal de bash-completion. En fonction de votre gestionnaire de paquets, vous devez manuellement sourcer ce fichier dans votre <code>~/.bashrc</code>.</p><p>Il vous suffit de recharger votre shell et de lancer <code>type _init_completion</code>. Si la commande réussit, vous êtes déjà configuré, sinon ajoutez le suivant à votre fichier `~/.bashrc' :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span><span style=color:#a2f>source</span> /usr/share/bash-completion/bash_completion
</span></span></code></pre></div><p>Rechargez votre shell et vérifiez que bash-completion est correctement installé en tapant <code>type _init_completion</code>.</p><h3 id=activer-l-auto-complétion-de-kubectl>Activer l'auto-complétion de kubectl</h3><p>Vous devez maintenant vérifier que le script de completion de kubectl est bien sourcé dans toutes vos sessions shell. Il y a deux façons de le faire:</p><ul><li><p>Sourcer le script de completion dans votre fichier <code>~/.bashrc</code>:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span><span style=color:#a2f>echo</span> <span style=color:#b44>&#39;source &lt;(kubectl completion bash)&#39;</span> &gt;&gt;~/.bashrc
</span></span></code></pre></div></li><li><p>Ajoutez le script de complétion dans le répertoire <code>/etc/bash_completion.d</code>:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl completion bash &gt;/etc/bash_completion.d/kubectl
</span></span></code></pre></div></li><li><p>Si vous avez un alias pour kubectl, vous pouvez étendre la completion de votre shell pour fonctionner avec cet alias:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span><span style=color:#a2f>echo</span> <span style=color:#b44>&#39;alias k=kubectl&#39;</span> &gt;&gt;~/.bashrc
</span></span><span style=display:flex><span><span style=color:#a2f>echo</span> <span style=color:#b44>&#39;complete -o default -F __start_kubectl k&#39;</span> &gt;&gt;~/.bashrc
</span></span></code></pre></div></li></ul><div class="alert alert-info note callout" role=alert><strong>Note:</strong> bash-completion source tous les scripts de completion dans <code>/etc/bash_completion.d</code>.</div><p>Les deux approches sont équivalentes. Après avoir rechargé votre shell, l'auto-complétion de kubectl devrait fonctionner.</p></div><div id=kubectl-autocompletion-1 class=tab-pane role=tabpanel aria-labelledby=kubectl-autocompletion-1><p><h3 id=introduction>Introduction</h3><p>Le script de complétion kubectl pour Bash peut être généré avec la commande <code>kubectl completion bash</code>. Sourcer le script de completion dans votre shell permet l'auto-complétion de kubectl.</p><p>En revanche, le script de complétion dépend de <a href=https://github.com/scop/bash-completion><strong>bash-completion</strong></a>, ce qui implique que vous devez d'abord installer ce logiciel.</p><div class="alert alert-danger warning callout" role=alert><strong>Attention:</strong> macOS inclut Bash 3.2 par défaut. Le script de complétion kubectl nécessite Bash 4.1+ et ne fonctionne pas avec Bash 3.2. Une des solutions possibles est d'installer une version plus récente de Bash sous macOS (voir instructions <a href=https://itnext.io/upgrading-bash-on-macos-7138bd1066ba>ici</a>). Les instructions ci-dessous ne fonctionnent que si vous utilisez Bash 4.1+.</div><h3 id=installer-bash-completion>Installer bash-completion</h3><div class="alert alert-info note callout" role=alert><strong>Note:</strong> Comme mentionné, ces instructions supposent que vous utilisez Bash 4.1+, ce qui signifie que vous installerez bash-completion v2 (contrairement à Bash 3.2 et bash-completion v1, auquel cas la complétion pour kubectl ne fonctionnera pas).</div><p>Vous pouvez tester si vous avez déjà installé bash-completion en utilisant <code>type _init_completion</code>. Si il n'est pas installé, vous pouvez installer bash-completion avec Homebrew:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>brew install bash-completion@2
</span></span></code></pre></div><p>Comme indiqué dans la sortie de <code>brew install</code> (section "Caveats"), ajoutez les lignes suivantes à votre fichier <code>~/.bashrc</code> ou <code>~/.bash_profile</code> :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span><span style=color:#a2f>export</span> <span style=color:#b8860b>BASH_COMPLETION_COMPAT_DIR</span><span style=color:#666>=</span><span style=color:#b44>&#34;/usr/local/etc/bash_completion.d&#34;</span>
</span></span><span style=display:flex><span><span style=color:#666>[[</span> -r <span style=color:#b44>&#34;/usr/local/etc/profile.d/bash_completion.sh&#34;</span> <span style=color:#666>]]</span> <span style=color:#666>&amp;&amp;</span> . <span style=color:#b44>&#34;/usr/local/etc/profile.d/bash_completion.sh&#34;</span>
</span></span></code></pre></div><p>Rechargez votre shell et vérifiez que bash-completion v2 est correctement installé avec <code>type _init_completion</code>.</p><h3 id=activer-l-auto-complétion-de-kubectl>Activer l'auto-complétion de kubectl</h3><p>Si vous n'avez pas installé via Homebrew, vous devez maintenant vous assurer que le script de complétion kubectl est bien sourcé dans toutes vos sessions shell comme suit:</p><ul><li><p>Sourcer le script de completion dans votre fichier <code>~/.bashrc</code>:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span><span style=color:#a2f>echo</span> <span style=color:#b44>&#39;source &lt;(kubectl completion bash)&#39;</span> &gt;&gt;~/.bashrc
</span></span></code></pre></div></li><li><p>Ajoutez le script de complétion dans le répertoire <code>/usr/local/etc/bash_completion.d</code>:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl completion bash &gt;/usr/local/etc/bash_completion.d/kubectl
</span></span></code></pre></div></li><li><p>Si vous avez un alias pour kubectl, vous pouvez étendre la completion de votre shell pour fonctionner avec cet alias:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span><span style=color:#a2f>echo</span> <span style=color:#b44>&#39;alias k=kubectl&#39;</span> &gt;&gt;~/.bashrc
</span></span><span style=display:flex><span><span style=color:#a2f>echo</span> <span style=color:#b44>&#39;complete -o default -F __start_kubectl k&#39;</span> &gt;&gt;~/.bashrc
</span></span></code></pre></div></li></ul><p>Si vous avez installé kubectl avec Homebrew (comme expliqué <a href=#installer-avec-homebrew-sur-macos>ici</a>), alors le script de complétion a été automatiquement installé dans <code>/usr/local/etc/bash_completion.d/kubectl</code>. Dans ce cas, vous n'avez rien à faire.</p><div class="alert alert-info note callout" role=alert><strong>Note:</strong> L'installation Homebrew de bash-complétion v2 source tous les fichiers du répertoire <code>BASH_COMPLETION_COMPAT_DIR</code>, c'est pourquoi les deux dernières méthodes fonctionnent.</div><p>Après avoir rechargé votre shell, l'auto-complétion de kubectl devrait fonctionner.</p></div><div id=kubectl-autocompletion-2 class=tab-pane role=tabpanel aria-labelledby=kubectl-autocompletion-2><p><p>Le script de complétion de kubectl pour Zsh peut être généré avec la commande <code>kubectl completion zsh</code>. Sourcer le script de completion dans votre shell permet l'auto-complétion de kubectl.</p><p>Pour faire ainsi dans toutes vos sessions shell, ajoutez ce qui suit à votre fichier <code>~/.zshrc</code>:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span><span style=color:#a2f>source</span> &lt;<span style=color:#666>(</span>kubectl completion zsh<span style=color:#666>)</span>
</span></span></code></pre></div><p>Si vous avez un alias pour kubectl, vous pouvez étendre la completion de votre shell pour fonctionner avec cet alias:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span><span style=color:#a2f>echo</span> <span style=color:#b44>&#39;alias k=kubectl&#39;</span> &gt;&gt;~/.zshrc
</span></span><span style=display:flex><span><span style=color:#a2f>echo</span> <span style=color:#b44>&#39;compdef __start_kubectl k&#39;</span> &gt;&gt;~/.zshrc
</span></span></code></pre></div><p>Après avoir rechargé votre shell, l'auto-complétion de kubectl devrait fonctionner.</p><p>Si vous rencontrez une erreur comme <code>complete:13: command not found: compdef</code>, alors ajoutez ce qui suit au début de votre fichier <code>~/.zshrc</code>:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>autoload -Uz compinit
</span></span><span style=display:flex><span>compinit
</span></span></code></pre></div></div></div><h2 id=a-suivre>A suivre</h2><ul><li><a href=/docs/tasks/tools/install-minikube/>Installer Minikube</a></li><li>Voir les <a href=/fr/docs/setup/>guides de démarrage</a> pour plus d'informations sur la création de clusters.</li><li><a href=/docs/tasks/access-application-cluster/service-access-application-cluster/>Apprenez comment lancer et exposer votre application</a></li><li>Si vous avez besoin d'accéder à un cluster que vous n'avez pas créé, consultez <a href=/docs/tasks/access-application-cluster/configure-access-multiple-clusters/>Partager l'accès du Cluster</a>.</li><li>Consulter les <a href=/fr/docs/reference/kubectl/kubectl/>documents de référence de kubectl</a></li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-2142bfe0834f1bf8f47887f85adba495>5.1.2 - Installer Minikube</h1><p>Cette page vous montre comment installer <a href=/fr/docs/tutorials/hello-minikube/>Minikube</a>, qui est un outil qui fait tourner un cluster Kubernetes à un noeud unique dans une machine virtuelle sur votre machine.</p><h2 id=pré-requis>Pré-requis</h2><ul class="nav nav-tabs" id=minikube-before-you-begin role=tablist><li class=nav-item><a data-toggle=tab class="nav-link active" href=#minikube-before-you-begin-0 role=tab aria-controls=minikube-before-you-begin-0 aria-selected=true>Linux</a></li><li class=nav-item><a data-toggle=tab class=nav-link href=#minikube-before-you-begin-1 role=tab aria-controls=minikube-before-you-begin-1>macOS</a></li><li class=nav-item><a data-toggle=tab class=nav-link href=#minikube-before-you-begin-2 role=tab aria-controls=minikube-before-you-begin-2>Windows</a></li></ul><div class=tab-content id=minikube-before-you-begin><div id=minikube-before-you-begin-0 class="tab-pane show active" role=tabpanel aria-labelledby=minikube-before-you-begin-0><p><p>Pour vérifier si la virtualisation est prise en charge sur Linux, exécutez la commande suivante et vérifiez que la sortie n'est pas vide :</p><pre tabindex=0><code>grep -E --color &#39;vmx|svm&#39; /proc/cpuinfo
</code></pre></div><div id=minikube-before-you-begin-1 class=tab-pane role=tabpanel aria-labelledby=minikube-before-you-begin-1><p><p>Pour vérifier si la virtualisation est prise en charge sur macOS, exécutez la commande suivante sur votre terminal.</p><pre tabindex=0><code>sysctl -a | grep -E --color &#39;machdep.cpu.features|VMX&#39;
</code></pre><p>Si vous trouvez <code>VMX</code> dans la sortie, la fonction VT-x est supportée sur votre OS.</p></div><div id=minikube-before-you-begin-2 class=tab-pane role=tabpanel aria-labelledby=minikube-before-you-begin-2><p><p>Pour vérifier si la virtualisation est prise en charge sur Windows 8 et au-delà, exécutez la commande suivante sur votre terminal Windows ou à l'invite de commande.</p><pre tabindex=0><code>systeminfo
</code></pre><p>Si vous obtenez la sortie suivant, la virtualisation est prise en charge sur Windows.</p><pre tabindex=0><code>Hyper-V Requirements:     VM Monitor Mode Extensions: Yes
                          Virtualization Enabled In Firmware: Yes
                          Second Level Address Translation: Yes
                          Data Execution Prevention Available: Yes
</code></pre><p>Si vous voyez la sortie suivante, votre système a déjà un hyperviseur installé et vous pouvez ignorer l'étape suivante.</p><pre tabindex=0><code>Configuration requise pour Hyper-V: un hyperviseur a été détecté. Les fonctionnalités requises pour Hyper-V ne seront pas affichées.
</code></pre></div></div><h2 id=installer-minikube>Installer Minikube</h2><ul class="nav nav-tabs" id=tab-with-md role=tablist><li class=nav-item><a data-toggle=tab class="nav-link active" href=#tab-with-md-0 role=tab aria-controls=tab-with-md-0 aria-selected=true>Linux</a></li><li class=nav-item><a data-toggle=tab class=nav-link href=#tab-with-md-1 role=tab aria-controls=tab-with-md-1>macOS</a></li><li class=nav-item><a data-toggle=tab class=nav-link href=#tab-with-md-2 role=tab aria-controls=tab-with-md-2>Windows</a></li></ul><div class=tab-content id=tab-with-md><div id=tab-with-md-0 class="tab-pane show active" role=tabpanel aria-labelledby=tab-with-md-0><p><h3 id=installer-kubectl>Installer kubectl</h3><p>Installez kubectl en suivant les instructions de la section <a href=/fr/docs/tasks/tools/install-kubectl/#install-kubectl-on-linux>Installer et configurer kubectl</a>.</p><h3 id=installer-un-hyperviseur>Installer un hyperviseur</h3><p>Si vous n'avez pas déjà un hyperviseur installé, installez-le maintenant pour votre système d'exploitation :</p><p>• <a href=http://www.linux-kvm.org/>KVM</a>, qui utilise également QEMU</p><p>• <a href=https://www.virtualbox.org/wiki/Downloads>VirtualBox</a></p><p>Minikube supporte également une option <code>--vm-driver=none</code> qui exécute les composants Kubernetes sur la machine hôte et pas dans une VM.
L'utilisation de ce pilote nécessite <a href=https://www.docker.com/products/docker-desktop>Docker</a> et un environnement Linux mais pas un hyperviseur.</p><p>Si vous utilisez le pilote <code>none</code> dans Debian ou un dérivé, utilisez les paquets<code> .deb</code> pour
Docker plutôt que le package snap, qui ne fonctionne pas avec Minikube.
Vous pouvez télécharger les packages <code>.deb</code> depuis <a href=https://www.docker.com/products/docker-desktop>Docker</a>.</p><div class="alert alert-warning caution callout" role=alert><strong>Avertissement:</strong> Le pilote VM <code>none</code> peut entraîner des problèmes de sécurité et de perte de données.
Avant d'utiliser <code>--driver=none</code>, consultez <a href=https://minikube.sigs.k8s.io/docs/reference/drivers/none/>cette documentation</a> pour plus d'informations.</div><p>Minikube prend également en charge un <code>vm-driver=podman</code> similaire au pilote Docker. Podman est exécuté en tant que superutilisateur (utilisateur root), c'est le meilleur moyen de garantir que vos conteneurs ont un accès complet à toutes les fonctionnalités disponibles sur votre système.</p><div class="alert alert-warning caution callout" role=alert><strong>Avertissement:</strong> Le pilote <code>podman</code> nécessite l’exécution des conteneurs en tant que root car les comptes d’utilisateurs normaux n’ont pas un accès complet à toutes les fonctionnalités du système d’exploitation que leurs conteneurs pourraient avoir besoin d’exécuter.</div><h3 id=installer-minikube-à-l-aide-d-un-package>Installer Minikube à l'aide d'un package</h3><p>Il existe des packages * expérimentaux * pour Minikube; vous pouvez trouver des packages Linux (AMD64)
depuis la page <a href=https://github.com/kubernetes/minikube/releases>releases</a> de Minikube sur GitHub.</p><p>Utilisez l'outil de package de votre distribution Linux pour installer un package approprié.</p><h3 id=installez-minikube-par-téléchargement-direct>Installez Minikube par téléchargement direct</h3><p>Si vous n'installez pas via un package, vous pouvez télécharger
un binaire autonome et l'utiliser.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>curl -Lo minikube https://storage.googleapis.com/minikube/releases/latest/minikube-linux-amd64 <span style=color:#b62;font-weight:700>\
</span></span></span><span style=display:flex><span><span style=color:#b62;font-weight:700></span>  <span style=color:#666>&amp;&amp;</span> chmod +x minikube
</span></span></code></pre></div><p>Voici un moyen simple d'ajouter l'exécutable Minikube à votre path :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>sudo mkdir -p /usr/local/bin/
</span></span><span style=display:flex><span>sudo install minikube /usr/local/bin/
</span></span></code></pre></div><h3 id=installer-minikube-en-utilisant-homebrew>Installer Minikube en utilisant Homebrew</h3><p>Une autre alternative, vous pouvez installer Minikube en utilisant Linux [Homebrew] (<a href=https://docs.brew.sh/Homebrew-on-Linux>https://docs.brew.sh/Homebrew-on-Linux</a>) :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>brew install minikube
</span></span></code></pre></div></div><div id=tab-with-md-1 class=tab-pane role=tabpanel aria-labelledby=tab-with-md-1><p><h3 id=installer-kubectl>Installer kubectl</h3><p>Installez kubectl en suivant les instructions de la section <a href=/fr/docs/tasks/tools/install-kubectl/#install-kubectl-on-macos>Installer et configurer kubectl</a>.</p><h3 id=installer-un-hyperviseur>Installer un hyperviseur</h3><p>Si vous n'avez pas encore installé d'hyperviseur, installez-en un maintenant :</p><p>• <a href=https://github.com/moby/hyperkit>HyperKit</a></p><p>• <a href=https://www.virtualbox.org/wiki/Downloads>VirtualBox</a></p><p>• <a href=https://www.vmware.com/products/fusion>VMware Fusion</a></p><h3 id=installer-minikube>Installer Minikube</h3><p>La façon la plus simple d'installer Minikube sur macOS est d'utiliser <a href=https://brew.sh>Homebrew</a>:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>brew install minikube
</span></span></code></pre></div><p>Vous pouvez aussi l'installer sur macOS en téléchargeant un binaire statique :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>curl -Lo minikube https://storage.googleapis.com/minikube/releases/latest/minikube-darwin-amd64 <span style=color:#b62;font-weight:700>\
</span></span></span><span style=display:flex><span><span style=color:#b62;font-weight:700></span>  <span style=color:#666>&amp;&amp;</span> chmod +x minikube
</span></span></code></pre></div><p>Voici une façon simple d'ajouter l'exécutable de Minikube à votre path :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>sudo mv minikube /usr/local/bin
</span></span></code></pre></div></div><div id=tab-with-md-2 class=tab-pane role=tabpanel aria-labelledby=tab-with-md-2><p><h3 id=installer-kubectl>Installer kubectl</h3><p>Installez kubectl en suivant les instructions de la section <a href=/fr/docs/tasks/tools/install-kubectl/#install-kubectl-on-windows>Installer et configurer kubectl</a>.</p><h3 id=installer-un-hyperviseur>Installer un hyperviseur</h3><p>Si vous n'avez pas encore installé d'hyperviseur, installez-en un maintenant :</p><p>• <a href=https://msdn.microsoft.com/en-us/virtualization/hyperv_on_windows/quick_start/walkthrough_install>Hyper-V</a></p><p>• <a href=https://www.virtualbox.org/wiki/Downloads>VirtualBox</a></p><div class="alert alert-info note callout" role=alert><strong>Note:</strong> Hyper-V peut fonctionner sur trois versions de Windows 10: Windows 10 Entreprise, Windows 10 Professionnel et Windows 10 Éducation.</div><h3 id=installer-minikube-en-utilisant-chocolatey>Installer Minikube en utilisant Chocolatey</h3><p>La façon la plus simple d'installer Minikube sur Windows est d'utiliser <a href=https://chocolatey.org/>Chocolatey</a> (exécuté avec les droits administrateur) :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>choco install minikube
</span></span></code></pre></div><p>Une fois l'installation de Minikube terminée, fermez la session CLI en cours et redémarrez. Minikube devrait avoir été ajouté à votre path automatiquement.</p><h3 id=installer-minikube-avec-windows-installer>Installer Minikube avec Windows Installer</h3><p>Pour installer manuellement Minikube sur Windows à l'aide de <a href=https://docs.microsoft.com/en-us/windows/desktop/msi/windows-installer-portal>Windows Installer</a>, téléchargez <a href=https://github.com/kubernetes/minikube/releases/latest><code>minikube-installer.exe</code></a> et exécutez l'Installer.</p><h4 id=installer-minikube-manuellement>Installer Minikube manuellement</h4><p>Pour installer Minikube manuellement sur Windows, téléchargez <a href=https://github.com/kubernetes/minikube/releases/latest><code>minikube-windows-amd64</code></a>, renommez-le en <code>minikube.exe</code>, et ajoutez-le à votre path.</p></div></div><h2 id=confirmer-l-installation>Confirmer l'installation</h2><p>Pour confirmer la réussite de l'installation d'un hyperviseur et d'un mini-cube, vous pouvez exécuter la commande suivante pour démarrer un cluster Kubernetes local :</p><div class="alert alert-info note callout" role=alert><strong>Note:</strong> Pour définir le <code>--driver</code> avec<code> minikube start</code>, entrez le nom de l'hyperviseur que vous avez installé en minuscules où <code>&lt;driver_name></code> est mentionné ci-dessous. Une liste complète des valeurs <code>--driver</code> est disponible dans <a href=https://kubernetes.io/docs/setup/learning-environment/minikube/#specifying-the-vm-driver>la documentation spécifiant le pilote VM</a>.</div><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>minikube start --driver<span style=color:#666>=</span>&lt;driver_name&gt;
</span></span></code></pre></div><p>Une fois <code>minikube start</code> terminé, exécutez la commande ci-dessous pour vérifier l'état du cluster :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>minikube status
</span></span></code></pre></div><p>Si votre cluster est en cours d'exécution, la sortie de <code>minikube status</code> devrait être similaire à :</p><pre tabindex=0><code>host: Running
kubelet: Running
apiserver: Running
kubeconfig: Configured
</code></pre><p>Après avoir vérifié si Minikube fonctionne avec l'hyperviseur choisi, vous pouvez continuer à utiliser Minikube ou arrêter votre cluster. Pour arrêter votre cluster, exécutez :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>minikube stop
</span></span></code></pre></div><h2 id=tout-nettoyer-pour-recommencer-à-zéro>Tout nettoyer pour recommencer à zéro</h2><p>Si vous avez déjà installé minikube, exécutez :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>minikube start
</span></span></code></pre></div><p>Si cette commande renvoie une erreur :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>machine does not exist
</span></span></code></pre></div><p>Vous devez supprimer les fichiers de configuration :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>rm -rf ~/.minikube
</span></span></code></pre></div><h2 id=a-suivre>A suivre</h2><ul><li><a href=/fr/docs/setup/learning-environment/minikube/>Exécutez Kubernetes localement via Minikube</a></li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-34a810f1516ad9d99b2697e36e9b0d0f>5.2 - Administration d'un cluster</h1></div><div class=td-content><h1 id=pg-8e16d69617b175d61e2e7a6e1642c9d6>5.2.1 - Administration avec kubeadm</h1></div><div class=td-content style=page-break-before:always><h1 id=pg-47be5dd51f686017f1766e6ec7aa6f41>5.2.2 - Gestion de la mémoire du CPU et des ressources d'API</h1></div><div class=td-content style=page-break-before:always><h1 id=pg-8c31aafd38fad5b0de0bd191758d6f93>5.2.3 - Installation d'un fournisseur de politiques de réseau</h1></div><div class=td-content style=page-break-before:always><h1 id=pg-9585dc0efb0450fd68728e7511754717>5.2.4 - Développer un Cloud Controller Manager</h1><p><div style=margin-top:10px;margin-bottom:10px><b>FEATURE STATE:</b> <code>Kubernetes v1.11 [beta]</code></div>Dans les prochaines versions, Cloud Controller Manager sera le moyen privilégié d’intégrer Kubernetes à n’importe quel cloud.
Cela garantira que les fournisseurs de cloud peuvent développer leurs fonctionnalités indépendamment des cycles de publication de Kubernetes.</p><div style=margin-top:10px;margin-bottom:10px><b>FEATURE STATE:</b> <code>Kubernetes 1.8 [alpha]</code></div><p>Avant d’expliquer comment créer votre propre gestionnaire de contrôleur de cloud, il est utile d’avoir quelques informations sur son fonctionnement interne.
Le cloud controller manager est un code de <code>kube-controller-manager</code> utilisant des interfaces Go pour permettre la mise en œuvre d'implémentations depuis n'importe quel cloud.
La plupart des implémentations de contrôleurs génériques seront au cœur du projet, mais elles seront toujours exécutées sur les interfaces de cloud fournies, à condition que l'<a href=https://github.com/kubernetes/cloud-provider/blob/master/cloud.go#L42-L62>interface du fournisseur de cloud</a> soit satisfaite.</p><p>Pour approfondir un peu les détails de la mise en œuvre, tous les gestionnaires de contrôleurs de nuage vont importer des packages à partir de Kubernetes core, la seule différence étant que chaque projet enregistre son propre fournisseur de nuage en appelant <a href=https://github.com/kubernetes/cloud-provider/blob/master/plugins.go#L56-L66>cloudprovider.RegisterCloudProvider</a> où une variable globale des fournisseurs de cloud disponibles est mise à jour.</p><h2 id=développement>Développement</h2><h3 id=out-of-tree>Out of Tree</h3><p>Pour construire un out-of-tree cloud-controller-manager pour votre cloud, suivez ces étapes:</p><ol><li>Créez un package Go avec une implémentation satisfaisant<a href=https://github.com/kubernetes/cloud-provider/blob/master/cloud.go>cloudprovider.Interface</a>.</li><li>Utilisez <a href=https://github.com/kubernetes/kubernetes/blob/master/cmd/cloud-controller-manager/controller-manager.go>main.go dans cloud-controller-manager</a> de Kubernetes core en tant que modèle pour votre main.go. Comme mentionné ci-dessus, la seule différence devrait être le package cloud qui sera importé.</li><li>Importez votre paquet cloud dans <code>main.go</code>, assurez-vous que votre paquet a un bloc <code>init</code> à exécuter <a href=https://github.com/kubernetes/cloud-provider/blob/master/plugins.go>cloudprovider.RegisterCloudProvider</a>.</li></ol><p>Utiliser des exemples de fournisseurs de cloud out-of-tree peut être utile.
Vous pouvez trouver la liste <a href=/docs/tasks/administer-cluster/running-cloud-controller.md#examples>ici</a>.</p><h3 id=in-tree>In Tree</h3><p>Pour les cloud in-tree, vous pouvez exécuter le in-tree cloud controller manager comme un <a href=/examples/admin/cloud/ccm-example.yaml>Daemonset</a> dans votre cluster.
Voir la <a href=/docs/tasks/administer-cluster/running-cloud-controller.md>documentation sur l'exécution d'un cloud controller manager</a> pour plus de détails.</p></div><div class=td-content style=page-break-before:always><h1 id=pg-ce4cd28c8feb9faa783e79b48af37961>5.2.5 - Kubernetes cloud-controller-manager</h1><div style=margin-top:10px;margin-bottom:10px><b>FEATURE STATE:</b> <code>Kubernetes v1.25 [beta]</code></div><p>Kubernetes v1.6 a introduit un nouveau binaire appelé <code>cloud-controller-manager</code>.
<code>cloud-controller-manager</code> est un démon qui intègre des boucles de contrôle spécifiques au cloud.
Ces boucles de contrôle spécifiques au cloud étaient à l’origine dans le binaire <code>kube-controller-manager</code>.
Étant donné que les fournisseurs de cloud développent et publient à un rythme différent de celui du projet Kubernetes, fournir une abstraction du code du <code>cloud-controller-manager</code> permet aux fournisseurs de cloud d’évoluer indépendamment du code Kubernetes principal.</p><p>Le <code>cloud-controller-manager</code> peut être lié à tout fournisseur de cloud satisfaisant l'interface <a href=https://github.com/kubernetes/cloud-provider/blob/master/cloud.go>cloudprovider.Interface</a>.
Pour des raisons de retro-compatibilité, le <a href=https://github.com/kubernetes/kubernetes/tree/master/cmd/cloud-controller-manager>cloud-controller-manager</a> fourni dans le projet de base Kubernetes utilise les mêmes bibliothèques ​​que <code>kube-controller-manager</code>.
Les fournisseurs de cloud déjà pris en charge nativement par Kubernetes devraient utiliser le cloud-controller-manager ​disponible ​dans le code de Kubernetes pour effectuer une transition visant à faire sortir cette prise en charge du code de Kubernetes.
Dans les futures versions de Kubernetes, tous les cloud-controller-manager seront développés en dehors du projet de base de Kubernetes géré par des sig leads ou des fournisseurs de cloud.</p><h2 id=administration>Administration</h2><h3 id=pré-requis>Pré-requis</h3><p>Chaque cloud a ses propres exigences pour l'exécution de sa propre intégration, ces exigences sont similaires à celles requises pour l'exécution de <code>kube-controller-manager</code>.
En règle générale, vous aurez besoin de:</p><ul><li>cloud authentification/autorisation: votre cloud peut nécessiter un jeton ou des règles IAM pour permettre l'accès à leurs API</li><li>kubernetes authentification/autorisation: cloud-controller-manager peut avoir besoin de règles RBAC définies pour parler à l'apiserver kubernetes</li><li>la haute disponibilité: Comme pour kube-controller-manager, vous pouvez souhaiter une configuration hautement disponible pour le cloud controller mananger en utilisant l'élection de leader (activée par défaut).</li></ul><h3 id=lancer-cloud-controller-manager>Lancer cloud-controller-manager</h3><p>L'exécution réussie de cloud-controller-manager nécessite certaines modifications de la configuration de votre cluster.</p><ul><li><code>kube-apiserver</code> et <code>kube-controller-manager</code> NE DOIVENT PAS spécifier l'option <code>--cloud-provider</code>.
Cela garantit qu'il n'exécutera aucune boucle spécifique au cloud qui serait exécutée par le cloud-controller-manager.
À l'avenir, cet indicateur sera rendu obsolète et supprimé.</li><li><code>kubelet</code> doit s'exécuter avec <code>--cloud-provider=external</code>.
C’est pour nous assurer que le kubelet est conscient qu'il doit être initialisé par le cloud-controller-manager avant qu'il ne commence à travailler.</li></ul><p>N'oubliez pas que la configuration de votre cluster pour utiliser le cloud-controller-manager changera le comportement de votre cluster de plusieurs façons:</p><ul><li>Les kubelets lancés avec <code>--cloud-provider=external</code> auront un marquage <code>node.cloudprovider.kubernetes.io/uninitialized</code> avec un effet <code>NoSchedule</code> pendant l'initialisation.
Cela indique que le nœud nécessite une seconde initialisation à partir d'un contrôleur externe avant de pouvoir planifier un travail.
Notez que si le cloud-controller-manager n'est pas disponible, les nouveaux nœuds du cluster ne seront pas valides.
Le marquage est important car le planificateur peut nécessiter des informations spécifiques au cloud à propos des nœuds, telles que leur région ou leur type (CPU performant, gpu, mémoire importante, instance ponctuelle, etc.).</li><li>Les informations relatives aux nœuds s'exécutant dans le cloud ne seront plus récupérées à l'aide de métadonnées locales, mais tous les appels d'API pour récupérer les informations de ces nœuds passeront par le cloud-controller-manager.
Cela peut signifier que vous pouvez restreindre l'accès à votre API de cloud sur les kubelets pour une sécurité accrue.
Pour les clusters de plus grande taille, vous voudrez peut-être déterminer si le cloud-controller-manager atteindra les limites de requêtes sur les API de votre fournisseur de cloud puisqu'il est désormais responsable de la quasi-totalité des appels d'API vers votre cloud depuis le cluster.</li></ul><p>À partir de la version 1.8, le cloud-controller-manager peut implémenter:</p><ul><li>contrôleur de nœud - responsable de la mise à jour des nœud kubernetes à l’aide des API de cloud et de la suppression des nœud kubernetes supprimés sur votre cloud.</li><li>contrôleur de service - responsable des loadbalancers sur votre cloud vers des services de type LoadBalancer.</li><li>contrôleur de route - responsable de la configuration des routes réseau sur votre cloud</li><li>toute autre fonctionnalité que vous voudriez implémenter si vous exécutez en dehors de l'arborescence de Kubernetes.</li></ul><h2 id=exemples>Exemples</h2><p>Si vous utilisez un cloud actuellement pris en charge nativement dans Kubernetes et souhaitez adopter le cloud-controller-manager, reportez-vous à la section <a href=https://github.com/kubernetes/kubernetes/tree/master/cmd/cloud-controller-manager>cloud-controller-manager dans kubernetes core</a>.</p><p>Pour les cloud-controller-manager ne faisant pas partie de Kubernetes, vous pouvez trouver les projets respectifs dans des dépôts maintenus par des fournisseurs de cloud ou des sig leads.</p><ul><li><a href=https://github.com/digitalocean/digitalocean-cloud-controller-manager>DigitalOcean</a></li><li><a href=https://github.com/munnerz/keepalived-cloud-provider>keepalived</a></li><li><a href=https://github.com/oracle/oci-cloud-controller-manager>Oracle Cloud Infrastructure</a></li><li><a href=https://github.com/rancher/rancher-cloud-controller-manager>Rancher</a></li><li><a href=https://github.com/scaleway/scaleway-cloud-controller-manager>Scaleway</a></li></ul><p>Pour les fournisseurs qui se trouvent déjà dans Kubernetes, vous pouvez exécuter le cloud-controller-manager dans l'arborescence en tant que Daemonset dans votre cluster.
Utilisez ce qui suit comme guide:</p><div class=highlight><div class=copy-code-icon style=text-align:right><a href=https://raw.githubusercontent.com/kubernetes/website/main/content/fr/examples/admin/cloud/ccm-example.yaml download=admin/cloud/ccm-example.yaml><code>admin/cloud/ccm-example.yaml</code></a>
<img src=/images/copycode.svg style=max-height:24px;cursor:pointer onclick='copyCode("admin-cloud-ccm-example-yaml")' title="Copy admin/cloud/ccm-example.yaml to clipboard"></img></div><div class=includecode id=admin-cloud-ccm-example-yaml><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#080;font-style:italic># Voici un exemple de configuration de cloud-controller-manager en tant que Daemonset dans votre cluster.</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:#080;font-style:italic># Il suppose que vos masters peuvent executer des pods et ont le role node-role.kubernetes.io/master</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:#080;font-style:italic># Notez que ce Daemonset ne fonctionnera pas directement pour votre cloud, c’est juste un exemple.</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:#00f;font-weight:700>---</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>ServiceAccount<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>cloud-controller-manager<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>namespace</span>:<span style=color:#bbb> </span>kube-system<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:#00f;font-weight:700>---</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>rbac.authorization.k8s.io/v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>ClusterRoleBinding<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>system:cloud-controller-manager<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>roleRef</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>apiGroup</span>:<span style=color:#bbb> </span>rbac.authorization.k8s.io<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>ClusterRole<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>cluster-admin<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>subjects</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span>- <span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>ServiceAccount<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>cloud-controller-manager<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>namespace</span>:<span style=color:#bbb> </span>kube-system<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:#00f;font-weight:700>---</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>apps/v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>DaemonSet<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>labels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>k8s-app</span>:<span style=color:#bbb> </span>cloud-controller-manager<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>cloud-controller-manager<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>namespace</span>:<span style=color:#bbb> </span>kube-system<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>selector</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>matchLabels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>k8s-app</span>:<span style=color:#bbb> </span>cloud-controller-manager<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>template</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>labels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>k8s-app</span>:<span style=color:#bbb> </span>cloud-controller-manager<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>serviceAccountName</span>:<span style=color:#bbb> </span>cloud-controller-manager<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>cloud-controller-manager<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:#080;font-style:italic># pour les fournisseurs in-tree, nous utilisons k8s.gcr.io/cloud-controller-manager</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:#080;font-style:italic># cela peut être remplacé par n&#39;importe quelle autre image pour les fournisseurs out-of-tree</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>k8s.gcr.io/cloud-controller-manager:v1.8.0<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>command</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span>- /usr/local/bin/cloud-controller-manager<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span>- --cloud-provider=&lt;YOUR_CLOUD_PROVIDER&gt;  <span style=color:#bbb> </span><span style=color:#080;font-style:italic># Ajoutez votre propre fournisseur de cloud ici!</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span>- --leader-elect=true<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span>- --use-service-account-credentials<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:#080;font-style:italic># ces drapeaux varient pour chaque fournisseur de cloud</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span>- --allocate-node-cidrs=true<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span>- --configure-cloud-routes=true<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span>- --cluster-cidr=172.17.0.0/16<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>tolerations</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:#080;font-style:italic># cela est nécessaire pour que CCM puisse s&#39;initialiser</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- <span style=color:green;font-weight:700>key</span>:<span style=color:#bbb> </span>node.cloudprovider.kubernetes.io/uninitialized<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>value</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;true&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>effect</span>:<span style=color:#bbb> </span>NoSchedule<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:#080;font-style:italic># le daemonset doit pouvoir être exécuté sur les nœuds master. Le marquage peut varier en fonction de la configuration de votre cluster.</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- <span style=color:green;font-weight:700>key</span>:<span style=color:#bbb> </span>node-role.kubernetes.io/master<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>effect</span>:<span style=color:#bbb> </span>NoSchedule<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:#080;font-style:italic># ceci limite le fonctionnement du CCM sur des nœuds master</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:#080;font-style:italic># le sélecteur de nœud peut varier en fonction de la configuration de votre cluster</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>nodeSelector</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>node-role.kubernetes.io/master</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;&#34;</span><span style=color:#bbb>
</span></span></span></code></pre></div></div></div><h2 id=limitations>Limitations</h2><p>L'exécution du cloud-controller-manager est soumise à quelques limitations.
Bien que ces limitations soient levées dans les prochaines versions, il est important que vous connaissiez ces limitations pour les charges de travail de production.</p><h3 id=prise-en-charge-des-volumes>Prise en charge des volumes</h3><p>Le cloud-controller-manager n'implémente aucun des contrôleurs de volume trouvés dans <code>kube-controller-manager</code> car les intégrations de volume nécessitent également une coordination avec les kubelets.
Au fur et à mesure de l'évolution de CSI (interface de stockage de conteneur) et de la prise en charge renforcée des plug-ins de volume flexible, le cloud-controller-manager prendra en charge le support nécessaire afin que les clouds puissent pleinement s'intégrer aux volumes.
Pour en savoir plus sur les plug-ins de volume CSI en dehors des sources de Kubernetes consultez <a href=https://github.com/kubernetes/features/issues/178>ceci</a>.</p><h3 id=charge-sur-les-apis-cloud>Charge sur les APIs cloud</h3><p>Dans l'architecture précédente pour les fournisseurs de cloud, nous utilisions des kubelets utilisant un service de métadonnées local pour extraire des informations sur les nœuds.
Avec cette nouvelle architecture, nous comptons désormais entièrement sur les cloud-controller-manager pour extraire les informations de tous les nœuds.
Pour les très grand clusters, vous devez envisager les goulots d'étranglement tels que les besoins en ressources et la limitation de la vitesse des APIs de votre fournisseur cloud.</p><h3 id=problème-de-l-oeuf-et-de-la-poule>Problème de l'oeuf et de la poule</h3><p>L'objectif du projet des cloud-controller-manager est de dissocier le développement des fonctionnalités de cloud computing du projet de base Kubernetes.
Malheureusement, de nombreux aspects du projet Kubernetes supposent que les fonctionnalités de fournisseur de cloud soient étroitement intégrées au projet.
Par conséquent, l'adoption de cette nouvelle architecture peut créer plusieurs situations dans lesquelles une demande d'informations auprès d'un fournisseur de cloud est demandée, mais le cloud-controller-manager peut ne pas être en mesure de renvoyer ces informations sans que la demande d'origine soit complète.</p><p>La fonctionnalité d’amorçage TLS dans Kubelet en est un bon exemple.
Actuellement, l’amorçage TLS suppose que Kubelet aie la possibilité de demander au fournisseur de cloud (ou à un service de métadonnées local) tous ses types d’adresses (privé, public, etc.), mais le cloud-controller-manager ne peut pas définir les types d’adresse d’un nœud sans être initialisé dans le système. Ce qui nécessite que le kubelet possède des certificats TLS pour communiquer avec l’apiserver.</p><p>À mesure que cette initiative évoluera, des modifications seront apportées pour résoudre ces problèmes dans les prochaines versions.</p><h2 id=développer-votre-propre-cloud-controller-manager>Développer votre propre cloud-controller-manager</h2><p>Pour créer et développer votre propre cloud-controller-manager, lisez la documentation <a href=/docs/tasks/administer-cluster/developing-cloud-controller-manager.md>Développer un cloud-controller-manager</a>.</p></div><div class=td-content style=page-break-before:always><h1 id=pg-f5da33b976758a9183018c421eb83f58>5.3 - Configuration des Pods et des conteneurs</h1></div><div class=td-content><h1 id=pg-e6dd9300cf3a955f7cdfe77fb5d15292>5.3.1 - Allouer des ressources mémoire aux conteneurs et aux pods</h1><p>Cette page montre comment assigner une mémoire <em>request</em> et une mémoire <em>limit</em> à un conteneur. Un conteneur est garanti d'avoir autant de mémoire qu'il le demande, mais n'est pas autorisé à consommer plus de mémoire que sa limite.</p><h2 id=pré-requis>Pré-requis</h2><p><p>Vous devez disposer d'un cluster Kubernetes et l'outil de ligne de commande kubectl doit être configuré pour communiquer avec votre cluster.
Si vous ne possédez pas déjà de cluster, vous pouvez en créer un en utilisant <a href=/docs/setup/minikube>Minikube</a>, ou vous pouvez utiliser l'un de ces environnements Kubernetes:</p><ul><li><a href=https://killercoda.com/playgrounds/scenario/kubernetes>Killercoda</a></li><li><a href=http://labs.play-with-k8s.com/>Play with Kubernetes</a></li></ul>Pour consulter la version, entrez <code>kubectl version</code>.</p><p>Chaque nœud de votre cluster doit avoir au moins 300 MiB de mémoire.</p><p>Pour quelques étapes de cette page, vous devez lancer
[metrics-server] (<a href=https://github.com/kubernetes-incubator/metrics-server>https://github.com/kubernetes-incubator/metrics-server</a>)
dans votre cluster. Si vous avez déjà metrics-server vous pouvez sauter ces étapes.</p><p>Si vous utilisez Minikube, exécutez la commande suivante pour activer metrics-server :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>minikube addons <span style=color:#a2f>enable</span> metrics-server
</span></span></code></pre></div><p>Pour voir si le metrics-server fonctionne, ou un autre fournisseur de l'API des métriques de ressources (<code>metrics.k8s.io</code>), exécutez la commande suivante :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get apiservices
</span></span></code></pre></div><p>Si l'API des métriques de ressources est disponible, la sortie inclura une référence à <code>metrics.k8s.io</code>.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>NAME
</span></span><span style=display:flex><span>v1beta1.metrics.k8s.io
</span></span></code></pre></div><h2 id=créer-un-namespace>Créer un namespace</h2><p>Créez un namespace de manière à ce que les ressources que vous créez dans cet exercice soient isolées du reste de votre cluster.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl create namespace mem-example
</span></span></code></pre></div><h2 id=spécifier-une-demande-de-mémoire-et-une-limite-de-mémoire>Spécifier une demande de mémoire et une limite de mémoire</h2><p>Pour spécifier une demande de mémoire pour un conteneur, incluez le champ <code>resources:requests</code>.
dans le manifeste des ressources du conteneur. Pour spécifier une limite de mémoire, incluez <code>resources:limits</code>.</p><p>Dans cet exercice, vous créez un pod qui possède un seul conteneur. Le conteneur dispose d'une demande de mémoire de 100 MiB et une limite de mémoire de 200 MiB. Voici le fichier de configuration
pour le Pod :</p><div class=highlight><div class=copy-code-icon style=text-align:right><a href=https://raw.githubusercontent.com/kubernetes/website/main/content/fr/examples/pods/resource/memory-request-limit.yaml download=pods/resource/memory-request-limit.yaml><code>pods/resource/memory-request-limit.yaml</code></a>
<img src=/images/copycode.svg style=max-height:24px;cursor:pointer onclick='copyCode("pods-resource-memory-request-limit-yaml")' title="Copy pods/resource/memory-request-limit.yaml to clipboard"></img></div><div class=includecode id=pods-resource-memory-request-limit-yaml><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>memory-demo<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>namespace</span>:<span style=color:#bbb> </span>mem-example<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>memory-demo-ctr<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>polinux/stress<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>resources</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>limits</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>memory</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;200Mi&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>requests</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>memory</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;100Mi&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>command</span>:<span style=color:#bbb> </span>[<span style=color:#b44>&#34;stress&#34;</span>]<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>args</span>:<span style=color:#bbb> </span>[<span style=color:#b44>&#34;--vm&#34;</span>,<span style=color:#bbb> </span><span style=color:#b44>&#34;1&#34;</span>,<span style=color:#bbb> </span><span style=color:#b44>&#34;--vm-bytes&#34;</span>,<span style=color:#bbb> </span><span style=color:#b44>&#34;150M&#34;</span>,<span style=color:#bbb> </span><span style=color:#b44>&#34;--vm-hang&#34;</span>,<span style=color:#bbb> </span><span style=color:#b44>&#34;1&#34;</span>]<span style=color:#bbb>
</span></span></span></code></pre></div></div></div><p>La section <code>args</code> de votre fichier de configuration fournit des arguments pour le conteneur lorsqu'il démarre.
Les arguments <code>"--vm-bytes", "150M"</code> indiquent au conteneur d'allouer 150 MiB de mémoire.</p><p>Créez le Pod:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl apply -f https://k8s.io/examples/pods/resource/memory-request-limit.yaml --namespace<span style=color:#666>=</span>mem-example
</span></span></code></pre></div><p>Vérifiez que le Pod fonctionne :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get pod memory-demo --namespace<span style=color:#666>=</span>mem-example
</span></span></code></pre></div><p>Consultez des informations détaillées sur le Pod :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get pod memory-demo --output<span style=color:#666>=</span>yaml --namespace<span style=color:#666>=</span>mem-example
</span></span></code></pre></div><p>La sortie montre que le conteneur dans le Pod a une demande de mémoire de 100 MiB et une limite de mémoire de 200 MiB.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#00f;font-weight:700>...</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>resources</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>limits</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>memory</span>:<span style=color:#bbb> </span>200Mi<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>requests</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>memory</span>:<span style=color:#bbb> </span>100Mi<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:#00f;font-weight:700>...</span><span style=color:#bbb>
</span></span></span></code></pre></div><p>Exécutez <code>kubectl top</code> pour récupérer les métriques du pod :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl top pod memory-demo --namespace<span style=color:#666>=</span>mem-example
</span></span></code></pre></div><p>La sortie montre que le Pod utilise environ 162.900.000 bytes de mémoire, qui est d'environ 150 MiB. Ce qui est supérieur à la demande de 100 MiB du Pod, mais ne dépassant pas la limite de 200 Mio de Pod.</p><pre tabindex=0><code>NAME                        CPU(cores)   MEMORY(bytes)
memory-demo                 &lt;something&gt;  162856960
</code></pre><p>Supprimez votre Pod :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl delete pod memory-demo --namespace<span style=color:#666>=</span>mem-example
</span></span></code></pre></div><h2 id=dépasser-la-limite-de-mémoire-d-un-conteneur>Dépasser la limite de mémoire d'un conteneur</h2><p>Un conteneur peut dépasser sa demande de mémoire si le nœud dispose de la mémoire disponible. Cependant, un conteneur n'est pas autorisé à utiliser plus que sa limite de mémoire. Si un conteneur alloue plus de mémoire que sa limite, le Conteneur devient un candidat à la terminaison. Si le conteneur continue à consommer de la mémoire au-delà de sa limite, le conteneur est arrêté.
Si un conteneur terminé peut être redémarré, le kubelet le redémarre, comme pour tout autre type d'échec d'exécution.</p><p>Dans cet exercice, vous créez un Pod qui tente d'allouer plus de mémoire que sa limite.
Voici le fichier de configuration d'un Pod qui contient un conteneur avec une demande de mémoire de 50 MiB et une limite de mémoire de 100 MiB :</p><div class=highlight><div class=copy-code-icon style=text-align:right><a href=https://raw.githubusercontent.com/kubernetes/website/main/content/fr/examples/pods/resource/memory-request-limit-2.yaml download=pods/resource/memory-request-limit-2.yaml><code>pods/resource/memory-request-limit-2.yaml</code></a>
<img src=/images/copycode.svg style=max-height:24px;cursor:pointer onclick='copyCode("pods-resource-memory-request-limit-2-yaml")' title="Copy pods/resource/memory-request-limit-2.yaml to clipboard"></img></div><div class=includecode id=pods-resource-memory-request-limit-2-yaml><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>memory-demo-2<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>namespace</span>:<span style=color:#bbb> </span>mem-example<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>memory-demo-2-ctr<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>polinux/stress<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>resources</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>requests</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>memory</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;50Mi&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>limits</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>memory</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;100Mi&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>command</span>:<span style=color:#bbb> </span>[<span style=color:#b44>&#34;stress&#34;</span>]<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>args</span>:<span style=color:#bbb> </span>[<span style=color:#b44>&#34;--vm&#34;</span>,<span style=color:#bbb> </span><span style=color:#b44>&#34;1&#34;</span>,<span style=color:#bbb> </span><span style=color:#b44>&#34;--vm-bytes&#34;</span>,<span style=color:#bbb> </span><span style=color:#b44>&#34;250M&#34;</span>,<span style=color:#bbb> </span><span style=color:#b44>&#34;--vm-hang&#34;</span>,<span style=color:#bbb> </span><span style=color:#b44>&#34;1&#34;</span>]<span style=color:#bbb>
</span></span></span></code></pre></div></div></div><p>Dans la section <code>args</code> du fichier de configuration, vous pouvez voir que le conteneur
tentera d'allouer 250 MiB de mémoire, ce qui est bien au-dessus de la limite de 100 MiB.</p><p>Créez le Pod :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl apply -f https://k8s.io/examples/pods/resource/memory-request-limit-2.yaml --namespace<span style=color:#666>=</span>mem-example
</span></span></code></pre></div><p>Consultez des informations détaillées sur le Pod :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get pod memory-demo-2 --namespace<span style=color:#666>=</span>mem-example
</span></span></code></pre></div><p>A ce niveau, le conteneur est soit en train de tourner, soit stoppé. Répétez la commande précédente jusqu'à ce que le conteneur soit terminé :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>NAME            READY     STATUS      RESTARTS   AGE
</span></span><span style=display:flex><span>memory-demo-2   0/1       OOMKilled   <span style=color:#666>1</span>          24s
</span></span></code></pre></div><p>Obtenez une vue plus détaillée de l'état du conteneur :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get pod memory-demo-2 --output<span style=color:#666>=</span>yaml --namespace<span style=color:#666>=</span>mem-example
</span></span></code></pre></div><p>La sortie indique que le conteneur a été stoppé suite à un manque de mémoire (OOM) :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>lastState:
</span></span><span style=display:flex><span>   terminated:
</span></span><span style=display:flex><span>     containerID: docker://65183c1877aaec2e8427bc95609cc52677a454b56fcb24340dbd22917c23b10f
</span></span><span style=display:flex><span>     exitCode: <span style=color:#666>137</span>
</span></span><span style=display:flex><span>     finishedAt: 2017-06-20T20:52:19Z
</span></span><span style=display:flex><span>     reason: OOMKilled
</span></span><span style=display:flex><span>     startedAt: null
</span></span></code></pre></div><p>Le conteneur dans cet exercice pourra être redémarré, ainsi le kubelet le redémarre. Répéter
cette commande plusieurs fois pour s'assurer que le conteneur est stoppé et redémarré d'une manière répététive :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get pod memory-demo-2 --namespace<span style=color:#666>=</span>mem-example
</span></span></code></pre></div><p>La sortie permet de voir que le conteneur est stoppé, redémarré, stoppé à nouveau, redémarré, et ainsi de suite :</p><pre tabindex=0><code>kubectl get pod memory-demo-2 --namespace=mem-example
NAME            READY     STATUS      RESTARTS   AGE
memory-demo-2   0/1       OOMKilled   1          37s
</code></pre><pre tabindex=0><code>
kubectl get pod memory-demo-2 --namespace=mem-example
NAME            READY     STATUS    RESTARTS   AGE
memory-demo-2   1/1       Running   2          40s
</code></pre><p>Affichez des informations détaillées sur l'historique du Pod :</p><pre tabindex=0><code>kubectl describe pod memory-demo-2 --namespace=mem-example
</code></pre><p>La sortie indique que le conteneur se démarre et échoue continuellement :</p><pre tabindex=0><code>... Normal  Created   Created container with id 66a3a20aa7980e61be4922780bf9d24d1a1d8b7395c09861225b0eba1b1f8511
... Warning BackOff   Back-off restarting failed container
</code></pre><p>Affichez des informations détaillées sur les nœuds de votre cluster :</p><pre tabindex=0><code>kubectl describe nodes
</code></pre><p>La sortie inclut un enregistrement de la mise à mort du conteneur suite à une condition hors mémoire :</p><pre tabindex=0><code>Warning OOMKilling Memory cgroup out of memory: Kill process 4481 (stress) score 1994 or sacrifice child
</code></pre><p>Supprimez votre Pod :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl delete pod memory-demo-2 --namespace<span style=color:#666>=</span>mem-example
</span></span></code></pre></div><h2 id=spécifiez-une-demande-de-mémoire-trop-volumineuse-pour-vos-nœuds>Spécifiez une demande de mémoire trop volumineuse pour vos nœuds.</h2><p>Les demandes de mémoire et les limites sont associées aux conteneurs, mais il est utile de réfléchir avant tout à la capacité de demande et limite mémoire des pods.
La demande de mémoire pour le Pod est la somme des demandes de mémoire pour tous ses conteneurs. De même, la mémoire limite pour le Pod est la somme des limites de tous ses Conteneurs.</p><p>L'ordonnancement des modules est basé sur les demandes. Un Pod est schedulé pour se lancer sur un Nœud uniquement si le Nœud dispose de suffisamment de mémoire disponible pour répondre à la demande de mémoire du Pod.</p><p>Dans cet exercice, vous allez créer un Pod dont la demande de mémoire est si importante qu'elle dépasse la capacité de la mémoire de n'importe quel nœud de votre cluster. Voici le fichier de configuration d'un Pod qui possède un seul conteneur avec une demande de 1000 GiB de mémoire, qui dépasse probablement la capacité de tous les nœuds de votre cluster.</p><div class=highlight><div class=copy-code-icon style=text-align:right><a href=https://raw.githubusercontent.com/kubernetes/website/main/content/fr/examples/pods/resource/memory-request-limit-3.yaml download=pods/resource/memory-request-limit-3.yaml><code>pods/resource/memory-request-limit-3.yaml</code></a>
<img src=/images/copycode.svg style=max-height:24px;cursor:pointer onclick='copyCode("pods-resource-memory-request-limit-3-yaml")' title="Copy pods/resource/memory-request-limit-3.yaml to clipboard"></img></div><div class=includecode id=pods-resource-memory-request-limit-3-yaml><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>memory-demo-3<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>namespace</span>:<span style=color:#bbb> </span>mem-example<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>memory-demo-3-ctr<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>polinux/stress<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>resources</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>limits</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>memory</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;1000Gi&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>requests</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>memory</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;1000Gi&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>command</span>:<span style=color:#bbb> </span>[<span style=color:#b44>&#34;stress&#34;</span>]<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>args</span>:<span style=color:#bbb> </span>[<span style=color:#b44>&#34;--vm&#34;</span>,<span style=color:#bbb> </span><span style=color:#b44>&#34;1&#34;</span>,<span style=color:#bbb> </span><span style=color:#b44>&#34;--vm-bytes&#34;</span>,<span style=color:#bbb> </span><span style=color:#b44>&#34;150M&#34;</span>,<span style=color:#bbb> </span><span style=color:#b44>&#34;--vm-hang&#34;</span>,<span style=color:#bbb> </span><span style=color:#b44>&#34;1&#34;</span>]<span style=color:#bbb>
</span></span></span></code></pre></div></div></div><p>Créez le Pod :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl apply -f https://k8s.io/examples/pods/resource/memory-request-limit-3.yaml --namespace<span style=color:#666>=</span>mem-example
</span></span></code></pre></div><p>Affichez l'état du Pod :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get pod memory-demo-3 --namespace<span style=color:#666>=</span>mem-example
</span></span></code></pre></div><p>La sortie indique que l'état du Pod est PENDING. En d'autres termes, le Pod n'est pas programmé pour tourner sur aucun Nœud, et il restera indéfiniment dans l'état PENDING :</p><pre tabindex=0><code>kubectl get pod memory-demo-3 --namespace=mem-example
NAME            READY     STATUS    RESTARTS   AGE
memory-demo-3   0/1       Pending   0          25s
</code></pre><p>Affichez des informations détaillées sur le Pod, y compris les événements :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl describe pod memory-demo-3 --namespace<span style=color:#666>=</span>mem-example
</span></span></code></pre></div><p>La sortie indique que le conteneur ne peut pas être planifié par manque de mémoire sur les nœuds :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>Events:
</span></span><span style=display:flex><span>  ...  Reason            Message
</span></span><span style=display:flex><span>       ------            -------
</span></span><span style=display:flex><span>  ...  FailedScheduling  No nodes are available that match all of the following predicates:: Insufficient memory <span style=color:#666>(</span>3<span style=color:#666>)</span>.
</span></span></code></pre></div><h2 id=unités-de-mémoire>Unités de mémoire</h2><p>La ressource mémoire est mesurée en bytes. Vous pouvez exprimer la mémoire sous la forme d'un nombre entier simple ou d'un nombre avec l'un de ces suffixes : E, P, T, G, M, K, Ei, Pi, Ti, Gi, Mi, Ki.
Par exemple, les valeurs suivantes représentent approximativement la même valeur :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>128974848, 129e6, 129M , 123Mi
</span></span></code></pre></div><p>Supprimez votre Pod :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl delete pod memory-demo-3 --namespace<span style=color:#666>=</span>mem-example
</span></span></code></pre></div><h2 id=si-vous-ne-spécifiez-pas-de-limite-de-mémoire>Si vous ne spécifiez pas de limite de mémoire</h2><p>Si vous ne spécifiez pas de limite de mémoire pour un conteneur, l'une des situations suivantes s'applique :</p><ul><li><p>Le conteneur n'a pas de limite maximale quant à la quantité de mémoire qu'il utilise. Le conteneur
pourrait utiliser toute la mémoire disponible sur le nœud où il est en cours d'exécution, ce qui pourrait à son tour invoquer le OOM killer. De plus, dans le cas d'un OOM Kill, un conteneur sans limite de ressources aura plus de chance d'être stoppé.</p></li><li><p>Le conteneur s'exécute dans un namespace qui a une limite de mémoire par défaut, d'ou le conteneur est automatiquement affecté cette limite par defaut. Les administrateurs du cluster peuvent utiliser un <a href=/docs/reference/generated/kubernetes-api/v1.25/#limitrange-v1-core>LimitRange</a>
pour spécifier une valeur par défaut pour la limite de mémoire.</p></li></ul><h2 id=motivation-pour-les-demandes-et-les-limites-de-mémoire>Motivation pour les demandes et les limites de mémoire</h2><p>En configurant les demandes de mémoire et les limites pour les conteneurs qui s'exécutent dans votre cluster.
vous pouvez utiliser efficacement les ressources mémoire disponibles sur les noeuds de votre cluster. En gardant la demande de mémoire d'un Pod basse, vous donnez au Pod une bonne chance d'être schedulé. En ayant une limite de mémoire supérieure à la demande de mémoire, vous accomplissez deux choses :</p><ul><li>Le Pod peut avoir des éclats d'activités où il fait usage de la mémoire qui se trouve être disponible.</li><li>La quantité de mémoire qu'un Pod peut utiliser pendant un éclat d'activité est limitée à une quantité raisonnable.</li></ul><h2 id=clean-up>Clean up</h2><p>Supprimez votre namespace. Ceci va supprimer tous les Pods que vous avez créés dans cet exercice :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl delete namespace mem-example
</span></span></code></pre></div><h2 id=a-suivre>A suivre</h2><h3 id=pour-les-développeurs-d-applications>Pour les développeurs d'applications</h3><ul><li><p><a href=/docs/tasks/configure-pod-container/assign-cpu-resource/>Allocation des ressources CPU aux conteneurs et pods</a></p></li><li><p><a href=/docs/tasks/configure-pod-container/quality-service-pod/>Configuration de la qualité de service pour les pods</a></p></li></ul><h3 id=pour-les-administrateurs-de-cluster>Pour les administrateurs de cluster</h3><ul><li><p><a href=/docs/tasks/administer-cluster/memory-default-namespace/>Configuration des demandes et des limites de mémoire par défaut pour un Namespace</a></p></li><li><p><a href=/docs/tasks/administer-cluster/cpu-default-namespace/>Configuration des demandes et des limites par défaut de CPU pour un Namespace</a></p></li><li><p><a href=/docs/tasks/administer-cluster/memory-constraint-namespace/>Configuration des contraintes de mémoire minimales et maximales pour un Namespace</a></p></li><li><p><a href=/docs/tasks/administer-cluster/cpu-constraint-namespace/>Configuration des contraintes minimales et maximales du CPU pour un Namespace</a></p></li><li><p><a href=/docs/tasks/administer-cluster/quota-memory-cpu-namespace/>Configuration des quotas de mémoire et de CPU pour un Namespace</a></p></li><li><p><a href=/docs/tasks/administer-cluster/quota-pod-namespace/>Configuration du quota de pods pour un Namespace</a></p></li><li><p><a href=/docs/tasks/administer-cluster/quota-api-object/>Configuration des quotas pour les objets API</a></p></li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-8555af270ae7122cc0464bab3f5d1609>5.3.2 - Allouer des ressources CPU aux conteneurs et aux pods</h1><p>Cette page montre comment assigner une <em>demande</em> (request en anglais) de CPU et une <em>limite</em> de CPU à un conteneur.
Un conteneur est garanti d'avoir autant de CPU qu'il le demande, mais n'est pas autorisé à utiliser plus de CPU que sa limite.</p><h2 id=pré-requis>Pré-requis</h2><p><p>Vous devez disposer d'un cluster Kubernetes et l'outil de ligne de commande kubectl doit être configuré pour communiquer avec votre cluster.
Si vous ne possédez pas déjà de cluster, vous pouvez en créer un en utilisant <a href=/docs/setup/minikube>Minikube</a>, ou vous pouvez utiliser l'un de ces environnements Kubernetes:</p><ul><li><a href=https://killercoda.com/playgrounds/scenario/kubernetes>Killercoda</a></li><li><a href=http://labs.play-with-k8s.com/>Play with Kubernetes</a></li></ul>Pour consulter la version, entrez <code>kubectl version</code>.</p><p>Chaque nœud de votre cluster doit avoir au moins 1 CPU.</p><p>Pour certaines des étapes de cette page, vous devez lancer <a href=https://github.com/kubernetes-incubator/metrics-server>metrics-server</a> dans votre cluster. Si le serveur de métriques est déja lancé,
vous pouvez sauter ces étapes.</p><p>Si vous utilisez minikube, exécutez la commande suivante pour activer metrics-server :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>minikube addons <span style=color:#a2f>enable</span> metrics-server
</span></span></code></pre></div><p>Pour voir si metrics-server (ou un autre fournisseur de l'API des métriques de ressources <code>metrics.k8s.io</code>) est lancé, tapez la commande suivante:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get apiservices
</span></span></code></pre></div><p>Si l'API de métriques de ressources est disponible, la sortie inclura une
référence à <code>metrics.k8s.io</code>.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>NAME
</span></span><span style=display:flex><span>v1beta1.metrics.k8s.io
</span></span></code></pre></div><h2 id=créer-un-namespace>Créer un namespace</h2><p>Créez un namespace de manière à ce que les ressources que vous créez dans cet exercice soient isolés du reste de votre cluster.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl create namespace cpu-example
</span></span></code></pre></div><h2 id=spécifier-une-demande-de-cpu-et-une-limite-de-cpu>Spécifier une demande de CPU et une limite de CPU</h2><p>Pour spécifier une demande de CPU pour un conteneur, incluez le champ <code>resources:requests</code>.
dans le manifeste des ressources du conteneur. Pour spécifier une limite de CPU, incluez <code>resources:limits</code>.</p><p>Dans cet exercice, vous allez créer un Pod qui a un seul conteneur. Le conteneur a une demande de 0.5 CPU et une limite de 1 CPU. Voici le fichier de configuration du Pod :</p><div class=highlight><div class=copy-code-icon style=text-align:right><a href=https://raw.githubusercontent.com/kubernetes/website/main/content/fr/examples/pods/resource/cpu-request-limit.yaml download=pods/resource/cpu-request-limit.yaml><code>pods/resource/cpu-request-limit.yaml</code></a>
<img src=/images/copycode.svg style=max-height:24px;cursor:pointer onclick='copyCode("pods-resource-cpu-request-limit-yaml")' title="Copy pods/resource/cpu-request-limit.yaml to clipboard"></img></div><div class=includecode id=pods-resource-cpu-request-limit-yaml><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>cpu-demo<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>namespace</span>:<span style=color:#bbb> </span>cpu-example<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>cpu-demo-ctr<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>vish/stress<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>resources</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>limits</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>cpu</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;1&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>requests</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>cpu</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;0.5&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>args</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- -cpus<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:#b44>&#34;2&#34;</span><span style=color:#bbb>
</span></span></span></code></pre></div></div></div><p>La section <code>args</code> du fichier de configuration fournit des arguments pour le conteneur lorsqu'il démarre. L'argument <code>-cpus "2"</code> demande au conteneur d'utiliser 2 CPUs.</p><p>Créez le Pod:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl apply -f https://k8s.io/examples/pods/resource/cpu-request-limit.yaml --namespace<span style=color:#666>=</span>cpu-example
</span></span></code></pre></div><p>Vérifiez que le Pod fonctionne :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get pod cpu-demo --namespace<span style=color:#666>=</span>cpu-example
</span></span></code></pre></div><p>Consultez des informations détaillées sur le Pod :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get pod cpu-demo --output<span style=color:#666>=</span>yaml --namespace<span style=color:#666>=</span>cpu-example
</span></span></code></pre></div><p>La sortie indique que le conteneur dans le Pod a une demande CPU de 500 milliCPU.
et une limite de CPU de 1 CPU.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>resources</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>limits</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>cpu</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;1&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>requests</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>cpu</span>:<span style=color:#bbb> </span>500m<span style=color:#bbb>
</span></span></span></code></pre></div><p>Utilisez <code>kubectl top</code> pour récupérer les métriques du pod :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl top pod cpu-demo --namespace<span style=color:#666>=</span>cpu-example
</span></span></code></pre></div><p>La sortie montre que le Pod utilise 974 milliCPU, ce qui est légèrement inférieur à
la limite de 1 CPU spécifiée dans le fichier de configuration du Pod.</p><pre tabindex=0><code>NAME                        CPU(cores)   MEMORY(bytes)
cpu-demo                    974m         &lt;something&gt;
</code></pre><p>Souvenez-vous qu'en réglant <code>-cpu "2"</code>, vous avez configuré le conteneur pour faire en sorte qu'il utilise 2 CPU, mais que le conteneur ne peut utiliser qu'environ 1 CPU. L'utilisation du CPU du conteneur est entravée, car le conteneur tente d'utiliser plus de ressources CPU que sa limite.</p><div class="alert alert-info note callout" role=alert><strong>Note:</strong> Une autre explication possible de la restriction du CPU est que le Nœud pourrait ne pas avoir
suffisamment de ressources CPU disponibles. Rappelons que les conditions préalables à cet exercice exigent que chacun de vos Nœuds doit avoir au moins 1 CPU.
Si votre conteneur fonctionne sur un nœud qui n'a qu'un seul CPU, le conteneur ne peut pas utiliser plus que 1 CPU, quelle que soit la limite de CPU spécifiée pour le conteneur.</div><h2 id=unités-de-cpu>Unités de CPU</h2><p>La ressource CPU est mesurée en unités <em>CPU</em>. Un CPU, à Kubernetes, est équivalent à:</p><ul><li>1 AWS vCPU</li><li>1 GCP Core</li><li>1 Azure vCore</li><li>1 Hyperthread sur un serveur physique avec un processeur Intel qui a de l'hyperthreading.</li></ul><p>Les valeurs fractionnelles sont autorisées. Un conteneur qui demande 0,5 CPU est garanti deux fois moins CPU par rapport à un conteneur qui demande 1 CPU. Vous pouvez utiliser le suffixe m pour signifier milli. Par exemple 100m CPU, 100 milliCPU, et 0.1 CPU sont tous égaux. Une précision plus fine que 1m n'est pas autorisée.</p><p>Le CPU est toujours demandé en tant que quantité absolue, jamais en tant que quantité relative, 0.1 est la même quantité de CPU sur une machine single-core, dual-core ou 48-core.</p><p>Supprimez votre pod :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl delete pod cpu-demo --namespace<span style=color:#666>=</span>cpu-example
</span></span></code></pre></div><h2 id=spécifier-une-demande-de-cpu-trop-élevée-pour-vos-nœuds>Spécifier une demande de CPU trop élevée pour vos nœuds.</h2><p>Les demandes et limites de CPU sont associées aux conteneurs, mais il est utile de réfléchir à la demande et à la limite de CPU d'un pod. La demande de CPU pour un Pod est la somme des demandes de CPU pour tous les conteneurs du Pod. De même, la limite de CPU pour les un Pod est la somme des limites de CPU pour tous les conteneurs du Pod.</p><p>L'ordonnancement des pods est basé sur les demandes. Un Pod est prévu pour se lancer sur un Nœud uniquement si le nœud dispose de suffisamment de ressources CPU pour satisfaire la demande de CPU du Pod.</p><p>Dans cet exercice, vous allez créer un Pod qui a une demande de CPU si importante qu'elle dépassera la capacité de n'importe quel nœud de votre cluster. Voici le fichier de configuration d'un Pod
qui a un seul conteneur. Le conteneur nécessite 100 CPU, ce qui est susceptible de dépasser la capacité de tous les nœuds de votre cluster.</p><div class=highlight><div class=copy-code-icon style=text-align:right><a href=https://raw.githubusercontent.com/kubernetes/website/main/content/fr/examples/pods/resource/cpu-request-limit-2.yaml download=pods/resource/cpu-request-limit-2.yaml><code>pods/resource/cpu-request-limit-2.yaml</code></a>
<img src=/images/copycode.svg style=max-height:24px;cursor:pointer onclick='copyCode("pods-resource-cpu-request-limit-2-yaml")' title="Copy pods/resource/cpu-request-limit-2.yaml to clipboard"></img></div><div class=includecode id=pods-resource-cpu-request-limit-2-yaml><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>cpu-demo-2<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>namespace</span>:<span style=color:#bbb> </span>cpu-example<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>cpu-demo-ctr-2<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>vish/stress<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>resources</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>limits</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>cpu</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;100&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>requests</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>cpu</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;100&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>args</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- -cpus<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:#b44>&#34;2&#34;</span><span style=color:#bbb>
</span></span></span></code></pre></div></div></div><p>Créez le Pod :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl apply -f https://k8s.io/examples/pods/resource/cpu-request-limit-2.yaml --namespace<span style=color:#666>=</span>cpu-example
</span></span></code></pre></div><p>Affichez l'état du Pod :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get pod cpu-demo-2 --namespace<span style=color:#666>=</span>cpu-example
</span></span></code></pre></div><p>La sortie montre que l'état du Pod est en attente. En d'autres termes, le Pod n'a pas été
planifié pour tourner sur n'importe quel Nœud, et il restera à l'état PENDING indéfiniment :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get pod cpu-demo-2 --namespace<span style=color:#666>=</span>cpu-example
</span></span><span style=display:flex><span>NAME         READY     STATUS    RESTARTS   AGE
</span></span><span style=display:flex><span>cpu-demo-2   0/1       Pending   <span style=color:#666>0</span>          7m
</span></span></code></pre></div><p>Afficher des informations détaillées sur le Pod, y compris les événements:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl describe pod cpu-demo-2 --namespace<span style=color:#666>=</span>cpu-example
</span></span></code></pre></div><p>la sortie signale que le conteneur ne peut pas être planifié en raison d'une quantité insuffisante de ressources de CPU sur les Nœuds :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>Events:
</span></span><span style=display:flex><span>  Reason			Message
</span></span><span style=display:flex><span>  ------			-------
</span></span><span style=display:flex><span>  FailedScheduling	No nodes are available that match all of the following predicates:: Insufficient cpu <span style=color:#666>(</span>3<span style=color:#666>)</span>.
</span></span></code></pre></div><p>Supprimez votre Pod :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl delete pod cpu-demo-2 --namespace<span style=color:#666>=</span>cpu-example
</span></span></code></pre></div><h2 id=si-vous-ne-spécifiez-pas-de-limite-cpu>Si vous ne spécifiez pas de limite CPU</h2><p>Si vous ne spécifiez pas de limite CPU pour un conteneur, une de ces situations s'applique :</p><ul><li><p>Le conteneur n'a pas de limite maximale quant aux ressources CPU qu'il peut utiliser. Le conteneur
pourrait utiliser toutes les ressources CPU disponibles sur le nœud où il est lancé.</p></li><li><p>Le conteneur est lancé dans un namespace qui a une limite par défaut de CPU, ainsi le conteneur reçoit automatiquement cette limite par défaut. Les administrateurs du cluster peuvent utiliser un
<a href=/docs/reference/generated/kubernetes-api/v1.25/#limitrange-v1-core/>LimitRange</a>
pour spécifier une valeur par défaut pour la limite de CPU.</p></li></ul><h2 id=motivation-pour-les-demandes-et-les-limites-du-cpu>Motivation pour les demandes et les limites du CPU</h2><p>En configurant les demandes et les limites de CPU des conteneurs qui se lancent sur votre cluster,
vous pouvez utiliser efficacement les ressources CPU disponibles sur les Nœuds de votre cluster.
En gardant une demande faible de CPU de pod, vous donnez au Pod une bonne chance d'être ordonnancé.
En ayant une limite CPU supérieure à la demande de CPU, vous accomplissez deux choses :</p><ul><li>Le Pod peut avoir des pics d'activité où il utilise les ressources CPU qui sont déjà disponibles.</li><li>La quantité de ressources CPU qu'un Pod peut utiliser pendant une pic d'activité est limitée à une quantité raisonnable.</li></ul><h2 id=nettoyage>Nettoyage</h2><p>Supprimez votre namespace :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl delete namespace cpu-example
</span></span></code></pre></div><h2 id=a-suivre>A suivre</h2><h3 id=pour-les-développeurs-d-applications>Pour les développeurs d'applications</h3><ul><li><p><a href=/fr/docs/tasks/configure-pod-container/assign-memory-resource/>Allocation des ressources mémoire aux conteneurs et aux pods</a></p></li><li><p><a href=/docs/tasks/configure-pod-container/quality-service-pod/>Configuration de la qualité de service pour les pods</a></p></li></ul><h3 id=pour-les-administrateurs-de-cluster>Pour les administrateurs de cluster</h3><ul><li><p><a href=/docs/tasks/administer-cluster/memory-default-namespace/>Configuration des demandes et des limites de mémoire par défaut pour un Namespace</a></p></li><li><p><a href=/docs/tasks/administer-cluster/cpu-default-namespace/>Configuration des demandes et des limites par défaut de CPU pour un Namespace</a></p></li><li><p><a href=/docs/tasks/administer-cluster/memory-constraint-namespace/>Configuration des contraintes de mémoire minimales et maximales pour un Namespace</a></p></li><li><p><a href=/docs/tasks/administer-cluster/cpu-constraint-namespace/>Configuration des contraintes minimales et maximales du CPU pour un Namespace</a></p></li><li><p><a href=/docs/tasks/administer-cluster/quota-memory-cpu-namespace/>Configuration des quotas de mémoire et de CPU pour un Namespace</a></p></li><li><p><a href=/docs/tasks/administer-cluster/quota-pod-namespace/>Configuration du quota de pods pour un Namespace</a></p></li><li><p><a href=/docs/tasks/administer-cluster/quota-api-object/>Configuration des quotas pour les objets API</a></p></li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-904cea8c8efd5c0d33adbfe579ec2dd2>5.3.3 - Configurer la qualité de service pour les pods</h1><p>Cette page montre comment configurer les Pods pour qu'ils soient affectés à des classes particulières de qualité de service (QoS). Kubernetes utilise des classes de QoS pour prendre des décisions concernant l'ordonnancement et les évictions des pods.</p><h2 id=pré-requis>Pré-requis</h2><p><p>Vous devez disposer d'un cluster Kubernetes et l'outil de ligne de commande kubectl doit être configuré pour communiquer avec votre cluster.
Si vous ne possédez pas déjà de cluster, vous pouvez en créer un en utilisant <a href=/docs/setup/minikube>Minikube</a>, ou vous pouvez utiliser l'un de ces environnements Kubernetes:</p><ul><li><a href=https://killercoda.com/playgrounds/scenario/kubernetes>Killercoda</a></li><li><a href=http://labs.play-with-k8s.com/>Play with Kubernetes</a></li></ul>Pour consulter la version, entrez <code>kubectl version</code>.</p><h2 id=les-classes-de-qos>Les Classes de QoS</h2><p>Quand Kubernetes crée un Pod, il affecte une de ces classes QoS au Pod :</p><ul><li>Guaranteed</li><li>Burstable</li><li>BestEffort</li></ul><h2 id=créez-un-namespace>Créez un namespace</h2><p>Créez un namespace de manière à ce que les ressources que vous créez dans cet exercice soient isolées du reste de votre cluster.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl create namespace qos-example
</span></span></code></pre></div><h2 id=créez-un-pod-qui-se-fait-attribuer-une-classe-qos-de-guaranteed>Créez un Pod qui se fait attribuer une classe QoS de Guaranteed</h2><p>Pour qu'un Pod reçoive une classe de QoS Guaranteed :</p><ul><li>Chaque conteneur du Pod doit avoir une limite de mémoire et une demande de mémoire, et elles doivent être les mêmes.</li><li>Chaque conteneur dans le Pod doit avoir une limite CPU et une demande CPU, et ils doivent être les mêmes.</li></ul><p>Ci-dessous le fichier de configuration d'un Pod qui a un seul conteneur.
Le conteneur dispose d'une limite de mémoire et d'une demande de mémoire, tous deux égaux à 200 MiB. Le conteneur a également une limite CPU et une demande CPU, toutes deux égales à 700 milliCPU :</p><div class=highlight><div class=copy-code-icon style=text-align:right><a href=https://raw.githubusercontent.com/kubernetes/website/main/content/fr/examples/pods/qos/qos-pod.yaml download=pods/qos/qos-pod.yaml><code>pods/qos/qos-pod.yaml</code></a>
<img src=/images/copycode.svg style=max-height:24px;cursor:pointer onclick='copyCode("pods-qos-qos-pod-yaml")' title="Copy pods/qos/qos-pod.yaml to clipboard"></img></div><div class=includecode id=pods-qos-qos-pod-yaml><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>qos-demo<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>namespace</span>:<span style=color:#bbb> </span>qos-example<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>qos-demo-ctr<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>nginx<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>resources</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>limits</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>memory</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;200Mi&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>cpu</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;700m&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>requests</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>memory</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;200Mi&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>cpu</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;700m&#34;</span><span style=color:#bbb>
</span></span></span></code></pre></div></div></div><p>Créez le Pod :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl apply -f https://k8s.io/examples/pods/qos/qos-pod.yaml --namespace<span style=color:#666>=</span>qos-example
</span></span></code></pre></div><p>Consultez des informations détaillées sur le Pod :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get pod qos-demo --namespace<span style=color:#666>=</span>qos-example --output<span style=color:#666>=</span>yaml
</span></span></code></pre></div><p>Le résultat indique que Kubernetes a donné au pod une classe de qualité de service de type Guaranteed. De plus, il affiche que la demande de mémoire du conteneur du pod correspond à sa limite de mémoire, et que la demande de CPU correspond à sa limite de CPU.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>...<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>resources</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>limits</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>cpu</span>:<span style=color:#bbb> </span>700m<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>memory</span>:<span style=color:#bbb> </span>200Mi<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>requests</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>cpu</span>:<span style=color:#bbb> </span>700m<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>memory</span>:<span style=color:#bbb> </span>200Mi<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>...<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>status</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>qosClass</span>:<span style=color:#bbb> </span>Guaranteed<span style=color:#bbb>
</span></span></span></code></pre></div><div class="alert alert-info note callout" role=alert><strong>Note:</strong> Si un conteneur spécifie sa propre limite de mémoire, mais ne spécifie pas de demande de mémoire, Kubernetes attribue automatiquement une demande de mémoire correspondant à la limite. De même, si un conteneur spécifie sa propre limite CPU, mais ne spécifie pas de demande de CPU, Kubernetes lui attribue automatiquement une demande de CPU qui correspond à cette limite.</div><p>Supprimez votre Pod :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl delete pod qos-demo --namespace<span style=color:#666>=</span>qos-example
</span></span></code></pre></div><h2 id=créez-un-pod-qui-se-fait-attribuer-une-classe-qos-de-type-burstable>Créez un Pod qui se fait attribuer une classe QoS de type Burstable</h2><p>Un Pod reçoit une classe QoS de Burstable si :</p><ul><li>Le Pod ne répond pas aux critères de la classe QoS Guaranteed.</li><li>Au moins un conteneur dans le Pod dispose d'une demande de mémoire ou de CPU.</li></ul><p>Voici le fichier de configuration d'un pod qui a un seul conteneur. Le conteneur a une limite de mémoire de 200 MiB et une demande de mémoire de 100 MiB.</p><div class=highlight><div class=copy-code-icon style=text-align:right><a href=https://raw.githubusercontent.com/kubernetes/website/main/content/fr/examples/pods/qos/qos-pod-2.yaml download=pods/qos/qos-pod-2.yaml><code>pods/qos/qos-pod-2.yaml</code></a>
<img src=/images/copycode.svg style=max-height:24px;cursor:pointer onclick='copyCode("pods-qos-qos-pod-2-yaml")' title="Copy pods/qos/qos-pod-2.yaml to clipboard"></img></div><div class=includecode id=pods-qos-qos-pod-2-yaml><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>qos-demo-2<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>namespace</span>:<span style=color:#bbb> </span>qos-example<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>qos-demo-2-ctr<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>nginx<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>resources</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>limits</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>memory</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;200Mi&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>requests</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>memory</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;100Mi&#34;</span><span style=color:#bbb>
</span></span></span></code></pre></div></div></div><p>Créez le Pod :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl apply -f https://k8s.io/examples/pods/qos/qos-pod-2.yaml --namespace<span style=color:#666>=</span>qos-example
</span></span></code></pre></div><p>Consultez des informations détaillées sur le Pod :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get pod qos-demo-2 --namespace<span style=color:#666>=</span>qos-example --output<span style=color:#666>=</span>yaml
</span></span></code></pre></div><p>La sortie montre que Kubernetes a accordé au pod une classe QoS de type Burstable.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>nginx<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>imagePullPolicy</span>:<span style=color:#bbb> </span>Always<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>qos-demo-2-ctr<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>resources</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>limits</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>memory</span>:<span style=color:#bbb> </span>200Mi<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>requests</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>memory</span>:<span style=color:#bbb> </span>100Mi<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>...<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>status</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>qosClass</span>:<span style=color:#bbb> </span>Burstable<span style=color:#bbb>
</span></span></span></code></pre></div><p>Supprimez votre Pod :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl delete pod qos-demo-2 --namespace<span style=color:#666>=</span>qos-example
</span></span></code></pre></div><h2 id=créez-un-pod-qui-se-fait-attribuer-une-classe-qos-de-type-besteffort>Créez un Pod qui se fait attribuer une classe QoS de type BestEffort</h2><p>Pour qu'un pod puisse avoir la classe QoS de BestEffort, les conteneurs dans le pod ne doivent pas
avoir des limites ou des demandes de mémoire ou de CPU.</p><p>Voici le fichier de configuration d'un Pod qui a un seul conteneur. Le conteneur n'a pas des limites ou des demandes de mémoire ou de CPU :</p><div class=highlight><div class=copy-code-icon style=text-align:right><a href=https://raw.githubusercontent.com/kubernetes/website/main/content/fr/examples/pods/qos/qos-pod-3.yaml download=pods/qos/qos-pod-3.yaml><code>pods/qos/qos-pod-3.yaml</code></a>
<img src=/images/copycode.svg style=max-height:24px;cursor:pointer onclick='copyCode("pods-qos-qos-pod-3-yaml")' title="Copy pods/qos/qos-pod-3.yaml to clipboard"></img></div><div class=includecode id=pods-qos-qos-pod-3-yaml><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>qos-demo-3<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>namespace</span>:<span style=color:#bbb> </span>qos-example<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>qos-demo-3-ctr<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>nginx<span style=color:#bbb>
</span></span></span></code></pre></div></div></div><p>Créez le Pod :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl apply -f https://k8s.io/examples/pods/qos/qos-pod-3.yaml --namespace<span style=color:#666>=</span>qos-example
</span></span></code></pre></div><p>Consultez des informations détaillées sur le Pod :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get pod qos-demo-3 --namespace<span style=color:#666>=</span>qos-example --output<span style=color:#666>=</span>yaml
</span></span></code></pre></div><p>Le résultat montre que Kubernetes a accordé au pod une classe QoS de BestEffort.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>...<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>resources</span>:<span style=color:#bbb> </span>{}<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>...<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>status</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>qosClass</span>:<span style=color:#bbb> </span>BestEffort<span style=color:#bbb>
</span></span></span></code></pre></div><p>Supprimez votre Pod :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl delete pod qos-demo-3 --namespace<span style=color:#666>=</span>qos-example
</span></span></code></pre></div><h2 id=créez-un-pod-qui-contient-deux-conteneurs>Créez un pod qui contient deux conteneurs</h2><p>Voici le fichier de configuration d'un Pod qui a deux conteneurs. Un conteneur spécifie une
demande de mémoire de 200 MiB. L'autre conteneur ne spécifie aucune demande ou limite.</p><div class=highlight><div class=copy-code-icon style=text-align:right><a href=https://raw.githubusercontent.com/kubernetes/website/main/content/fr/examples/pods/qos/qos-pod-4.yaml download=pods/qos/qos-pod-4.yaml><code>pods/qos/qos-pod-4.yaml</code></a>
<img src=/images/copycode.svg style=max-height:24px;cursor:pointer onclick='copyCode("pods-qos-qos-pod-4-yaml")' title="Copy pods/qos/qos-pod-4.yaml to clipboard"></img></div><div class=includecode id=pods-qos-qos-pod-4-yaml><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>qos-demo-4<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>namespace</span>:<span style=color:#bbb> </span>qos-example<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>qos-demo-4-ctr-1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>nginx<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>resources</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>requests</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>memory</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;200Mi&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>qos-demo-4-ctr-2<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>redis<span style=color:#bbb>
</span></span></span></code></pre></div></div></div><p>Notez que le pod répond aux critères de la classe QoS Burstable. En d'autres termes, il ne répond pas aux exigences de la classe de qualité de service Guaranteed, et l'un de ses conteneurs dispose d'une demande de mémoire.</p><p>Créez le Pod :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl apply -f https://k8s.io/examples/pods/qos/qos-pod-4.yaml --namespace<span style=color:#666>=</span>qos-example
</span></span></code></pre></div><p>Consultez des informations détaillées sur le Pod :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get pod qos-demo-4 --namespace<span style=color:#666>=</span>qos-example --output<span style=color:#666>=</span>yaml
</span></span></code></pre></div><p>Le résultat montre que Kubernetes a accordé au pod une classe QoS de Burstable:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>...<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>qos-demo-4-ctr-1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>resources</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>requests</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>memory</span>:<span style=color:#bbb> </span>200Mi<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>...<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>qos-demo-4-ctr-2<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>resources</span>:<span style=color:#bbb> </span>{}<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>...<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>status</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>qosClass</span>:<span style=color:#bbb> </span>Burstable<span style=color:#bbb>
</span></span></span></code></pre></div><p>Supprimez votre pod :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl delete pod qos-demo-4 --namespace<span style=color:#666>=</span>qos-example
</span></span></code></pre></div><h2 id=nettoyage>Nettoyage</h2><p>Supprimez votre namespace.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl delete namespace qos-example
</span></span></code></pre></div><h2 id=a-suivre>A suivre</h2><h3 id=pour-les-développeurs-d-applications>Pour les développeurs d'applications</h3><ul><li><p><a href=/docs/tasks/configure-pod-container/assign-cpu-resource/>Allocation des ressources CPU aux conteneurs et pods</a></p></li><li><p><a href=/fr/docs/tasks/configure-pod-container/assign-memory-resource/>Allocation des ressources mémoire aux conteneurs et pods</a></p></li></ul><h3 id=pour-les-administrateurs-de-cluster>Pour les administrateurs de cluster</h3><ul><li><p><a href=/docs/tasks/administer-cluster/memory-default-namespace/>Configuration des demandes et des limites de mémoire par défaut pour un Namespace</a></p></li><li><p><a href=/docs/tasks/administer-cluster/cpu-default-namespace/>Configuration des demandes et des limites par défaut de CPU pour un Namespace</a></p></li><li><p><a href=/docs/tasks/administer-cluster/memory-constraint-namespace/>Configuration des contraintes de mémoire minimales et maximales pour un Namespace</a></p></li><li><p><a href=/docs/tasks/administer-cluster/cpu-constraint-namespace/>Configuration des contraintes minimales et maximales du CPU pour un Namespace</a></p></li><li><p><a href=/docs/tasks/administer-cluster/quota-memory-cpu-namespace/>Configuration des quotas de mémoire et de CPU pour un Namespace</a></p></li><li><p><a href=/docs/tasks/administer-cluster/quota-pod-namespace/>Configuration du quota de pods pour un Namespace</a></p></li><li><p><a href=/docs/tasks/administer-cluster/quota-api-object/>Configuration des quotas pour les objets API</a></p></li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-4219ac6ab56a3b88d20305083d57d03c>5.3.4 - Affecter des ressources supplémentaires à un conteneur</h1><p>Cette page montre comment affecter des ressources supplémentaires à un conteneur.</p><div style=margin-top:10px;margin-bottom:10px><b>FEATURE STATE:</b> <code>Kubernetes v1.25 [stable]</code></div><h2 id=pré-requis>Pré-requis</h2><p><p>Vous devez disposer d'un cluster Kubernetes et l'outil de ligne de commande kubectl doit être configuré pour communiquer avec votre cluster.
Si vous ne possédez pas déjà de cluster, vous pouvez en créer un en utilisant <a href=/docs/setup/minikube>Minikube</a>, ou vous pouvez utiliser l'un de ces environnements Kubernetes:</p><ul><li><a href=https://killercoda.com/playgrounds/scenario/kubernetes>Killercoda</a></li><li><a href=http://labs.play-with-k8s.com/>Play with Kubernetes</a></li></ul>Pour consulter la version, entrez <code>kubectl version</code>.</p><p>Avant de commencer cet exercice, procédez à l'exercice en
<a href=/docs/tasks/administer-cluster/extended-resource-node/>Annoncer des ressources supplémentaires pour un nœud</a>.
Cela configurera l'un de vos nœuds pour qu'il annoncera une ressource dongle.</p><h2 id=affecter-une-ressource-supplémentaire-à-un-pod>Affecter une ressource supplémentaire à un Pod</h2><p>Pour demander une ressource supplémentaire, incluez le champ <code>resources:requests</code> dans votre fichier de manifeste du conteneur. Les ressources supplémentaires sont entièrement qualifiées dans n'importe quel domaine à l'extérieur de <code>*.kubernetes.io/</code>.
Les noms de ressources supplémentaires valides ont la forme <code>example.com/foo</code> où <code>example.com</code> est remplacé par le domaine de votre organisation et <code>foo</code> est le nom descriptif de la ressource.</p><p>Voici le fichier de configuration d'un Pod qui a un seul conteneur :</p><div class=highlight><div class=copy-code-icon style=text-align:right><a href=https://raw.githubusercontent.com/kubernetes/website/main/content/fr/examples/pods/resource/extended-resource-pod.yaml download=pods/resource/extended-resource-pod.yaml><code>pods/resource/extended-resource-pod.yaml</code></a>
<img src=/images/copycode.svg style=max-height:24px;cursor:pointer onclick='copyCode("pods-resource-extended-resource-pod-yaml")' title="Copy pods/resource/extended-resource-pod.yaml to clipboard"></img></div><div class=includecode id=pods-resource-extended-resource-pod-yaml><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>extended-resource-demo<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>extended-resource-demo-ctr<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>nginx<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>resources</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>requests</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>example.com/dongle</span>:<span style=color:#bbb> </span><span style=color:#666>3</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>limits</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>example.com/dongle</span>:<span style=color:#bbb> </span><span style=color:#666>3</span><span style=color:#bbb>
</span></span></span></code></pre></div></div></div><p>Dans le fichier de configuration, vous pouvez constater que le conteneur demande 3 dongles.</p><p>Créez un pod :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl apply -f https://k8s.io/examples/pods/resource/extended-resource-pod.yaml
</span></span></code></pre></div><p>Vérifiez que le Pod fonctionne :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get pod extended-resource-demo
</span></span></code></pre></div><p>Décrivez le Pod :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl describe pod extended-resource-demo
</span></span></code></pre></div><p>La sortie affiche les demandes des dongles :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>Limits</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>example.com/dongle</span>:<span style=color:#bbb> </span><span style=color:#666>3</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>Requests</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>example.com/dongle</span>:<span style=color:#bbb> </span><span style=color:#666>3</span><span style=color:#bbb>
</span></span></span></code></pre></div><h2 id=tentative-de-création-d-un-deuxième-pod>Tentative de création d'un deuxième Pod</h2><p>Voici le fichier de configuration d'un Pod qui a un seul conteneur. Le conteneur demande
deux dongles.</p><div class=highlight><div class=copy-code-icon style=text-align:right><a href=https://raw.githubusercontent.com/kubernetes/website/main/content/fr/examples/pods/resource/extended-resource-pod-2.yaml download=pods/resource/extended-resource-pod-2.yaml><code>pods/resource/extended-resource-pod-2.yaml</code></a>
<img src=/images/copycode.svg style=max-height:24px;cursor:pointer onclick='copyCode("pods-resource-extended-resource-pod-2-yaml")' title="Copy pods/resource/extended-resource-pod-2.yaml to clipboard"></img></div><div class=includecode id=pods-resource-extended-resource-pod-2-yaml><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>extended-resource-demo-2<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>extended-resource-demo-2-ctr<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>nginx<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>resources</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>requests</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>example.com/dongle</span>:<span style=color:#bbb> </span><span style=color:#666>2</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>limits</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>example.com/dongle</span>:<span style=color:#bbb> </span><span style=color:#666>2</span><span style=color:#bbb>
</span></span></span></code></pre></div></div></div><p>Kubernetes ne pourra pas satisfaire la demande de deux dongles, parce que le premier Pod
a utilisé trois des quatre dongles disponibles.</p><p>Essayez de créer un Pod :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl apply -f https://k8s.io/examples/pods/resource/extended-resource-pod-2.yaml
</span></span></code></pre></div><p>Décrivez le Pod :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl describe pod extended-resource-demo-2
</span></span></code></pre></div><p>La sortie montre que le Pod ne peut pas être planifié, du fait qu'il n'y a pas de Nœud qui a
2 dongles disponibles :</p><pre tabindex=0><code>Conditions:
  Type    Status
  PodScheduled  False
...
Events:
  ...
  ... Warning   FailedScheduling  pod (extended-resource-demo-2) failed to fit in any node
fit failure summary on nodes : Insufficient example.com/dongle (1)
</code></pre><p>Affichez l'état du Pod :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get pod extended-resource-demo-2
</span></span></code></pre></div><p>La sortie indique que le Pod a été créé, mais pas programmé pour tourner sur un Nœud.
Il a le statut Pending :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span>NAME                       READY     STATUS    RESTARTS   AGE<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span>extended-resource-demo-2   0/1       Pending   0          6m<span style=color:#bbb>
</span></span></span></code></pre></div><h2 id=nettoyage>Nettoyage</h2><p>Supprimez les Pods que vous avez créés dans cet exercice :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl delete pod extended-resource-demo
</span></span><span style=display:flex><span>kubectl delete pod extended-resource-demo-2
</span></span></code></pre></div><h2 id=a-suivre>A suivre</h2><h3 id=pour-les-développeurs-d-applications>Pour les développeurs d'applications</h3><ul><li><a href=/fr/docs/tasks/configure-pod-container/assign-memory-resource/>Allocation des ressources mémoire aux conteneurs et pods</a></li><li><a href=/docs/tasks/configure-pod-container/assign-cpu-resource/>Allocation des ressources CPU aux conteneurs et pods</a></li></ul><h3 id=pour-les-administrateurs-de-cluster>Pour les administrateurs de cluster</h3><ul><li><a href=/docs/tasks/administer-cluster/extended-resource-node/>Annoncer des ressources supplémentaires pour un nœud</a></li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-484833fb880d1e179cc2965d15f84da5>5.3.5 - Configurer un pod en utilisant un volume pour le stockage</h1><p>Cette page montre comment configurer un Pod pour utiliser un Volume pour le stockage.</p><p>Le système de fichiers d'un conteneur ne vit que tant que le conteneur vit. Ainsi, quand un conteneur se termine et redémarre, les modifications apportées au système de fichiers sont perdues. Pour un stockage plus consistant et indépendant du conteneur, vous pouvez utiliser un
<a href=/fr/docs/concepts/storage/volumes/>Volume</a>.
C'est particulièrement important pour les applications Stateful, telles que les key-value stores (comme par exemple Redis) et les bases de données.</p><h2 id=pré-requis>Pré-requis</h2><p><p>Vous devez disposer d'un cluster Kubernetes et l'outil de ligne de commande kubectl doit être configuré pour communiquer avec votre cluster.
Si vous ne possédez pas déjà de cluster, vous pouvez en créer un en utilisant <a href=/docs/setup/minikube>Minikube</a>, ou vous pouvez utiliser l'un de ces environnements Kubernetes:</p><ul><li><a href=https://killercoda.com/playgrounds/scenario/kubernetes>Killercoda</a></li><li><a href=http://labs.play-with-k8s.com/>Play with Kubernetes</a></li></ul>Pour consulter la version, entrez <code>kubectl version</code>.</p><h2 id=configurer-un-volume-pour-un-pod>Configurer un volume pour un Pod</h2><p>Dans cet exercice, vous créez un pod qui contient un seul conteneur. Ce Pod a un Volume de type
<a href=/fr/docs/concepts/storage/volumes/#emptydir>emptyDir</a> qui dure toute la vie du Pod, même si le conteneur se termine et redémarre.
Voici le fichier de configuration du Pod :</p><div class=highlight><div class=copy-code-icon style=text-align:right><a href=https://raw.githubusercontent.com/kubernetes/website/main/content/fr/examples/pods/storage/redis.yaml download=pods/storage/redis.yaml><code>pods/storage/redis.yaml</code></a>
<img src=/images/copycode.svg style=max-height:24px;cursor:pointer onclick='copyCode("pods-storage-redis-yaml")' title="Copy pods/storage/redis.yaml to clipboard"></img></div><div class=includecode id=pods-storage-redis-yaml><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>redis<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>redis<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>redis<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>volumeMounts</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>redis-storage<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>mountPath</span>:<span style=color:#bbb> </span>/data/redis<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>volumes</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>redis-storage<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>emptyDir</span>:<span style=color:#bbb> </span>{}<span style=color:#bbb>
</span></span></span></code></pre></div></div></div><ol><li><p>Créez le Pod :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl apply -f https://k8s.io/examples/pods/storage/redis.yaml
</span></span></code></pre></div></li><li><p>Vérifiez que le conteneur du pod est en cours d'exécution, puis surveillez les modifications apportées au pod :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get pod redis --watch
</span></span></code></pre></div><p>La sortie ressemble à ceci :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>NAME      READY     STATUS    RESTARTS   AGE
</span></span><span style=display:flex><span>redis     1/1       Running   <span style=color:#666>0</span>          13s
</span></span></code></pre></div></li><li><p>Dans un autre terminal, accédez à la console shell du conteneur en cours d'exécution :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl <span style=color:#a2f>exec</span> -it redis -- /bin/bash
</span></span></code></pre></div></li><li><p>Dans votre shell, allez dans <code>/data/redis</code>, puis créez un fichier :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>root@redis:/data# <span style=color:#a2f>cd</span> /data/redis/
</span></span><span style=display:flex><span>root@redis:/data/redis# <span style=color:#a2f>echo</span> Hello &gt; test-file
</span></span></code></pre></div></li><li><p>Dans votre shell, listez les processus en cours d'exécution :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>root@redis:/data/redis# apt-get update
</span></span><span style=display:flex><span>root@redis:/data/redis# apt-get install procps
</span></span><span style=display:flex><span>root@redis:/data/redis# ps aux
</span></span></code></pre></div><p>La sortie ressemble à ceci :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>USER       PID %CPU %MEM    VSZ   RSS TTY      STAT START   TIME COMMAND
</span></span><span style=display:flex><span>redis        <span style=color:#666>1</span>  0.1  0.1  <span style=color:#666>33308</span>  <span style=color:#666>3828</span> ?        Ssl  00:46   0:00 redis-server *:6379
</span></span><span style=display:flex><span>root        <span style=color:#666>12</span>  0.0  0.0  <span style=color:#666>20228</span>  <span style=color:#666>3020</span> ?        Ss   00:47   0:00 /bin/bash
</span></span><span style=display:flex><span>root        <span style=color:#666>15</span>  0.0  0.0  <span style=color:#666>17500</span>  <span style=color:#666>2072</span> ?        R+   00:48   0:00 ps aux
</span></span></code></pre></div></li><li><p>Dans votre shell, arrêtez le processus Redis :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>root@redis:/data/redis# <span style=color:#a2f>kill</span> &lt;pid&gt;
</span></span></code></pre></div><p>où <code>&lt;pid></code> est l'ID de processus Redis (PID).</p></li><li><p>Dans votre terminal initial, surveillez les changements apportés au Pod de Redis. Éventuellement,
vous verrez quelque chose comme ça :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>NAME      READY     STATUS     RESTARTS   AGE
</span></span><span style=display:flex><span>redis     1/1       Running    <span style=color:#666>0</span>          13s
</span></span><span style=display:flex><span>redis     0/1       Completed  <span style=color:#666>0</span>         6m
</span></span><span style=display:flex><span>redis     1/1       Running    <span style=color:#666>1</span>         6m
</span></span></code></pre></div></li></ol><p>A ce stade, le conteneur est terminé et redémarré. C'est dû au fait que le Pod de Redis a une
<a href=/docs/reference/generated/kubernetes-api/v1.25/#podspec-v1-core>restartPolicy</a>
fixé à <code>Always</code>.</p><ol><li><p>Accédez à la console shell du conteneur redémarré :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl <span style=color:#a2f>exec</span> -it redis -- /bin/bash
</span></span></code></pre></div></li><li><p>Dans votre shell, allez dans <code>/data/redis</code>, et vérifiez que <code>test-file</code> est toujours là.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>root@redis:/data/redis# <span style=color:#a2f>cd</span> /data/redis/
</span></span><span style=display:flex><span>root@redis:/data/redis# ls
</span></span><span style=display:flex><span>test-file
</span></span></code></pre></div></li><li><p>Supprimez le pod que vous avez créé pour cet exercice :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl delete pod redis
</span></span></code></pre></div></li></ol><h2 id=a-suivre>A suivre</h2><ul><li><p>Voir <a href=/docs/reference/generated/kubernetes-api/v1.25/#volume-v1-core>Volume</a>.</p></li><li><p>Voir <a href=/docs/reference/generated/kubernetes-api/v1.25/#pod-v1-core>Pod</a>.</p></li><li><p>En plus du stockage sur disque local fourni par <code>emptyDir</code>, Kubernetes supporte de nombreuses solutions de stockage connectées au réseau, y compris PD sur GCE et EBS sur EC2, qui sont préférés pour les données critiques et qui s'occuperont des autres détails tels que le montage et le démontage sur les nœuds. Voir <a href=/fr/docs/concepts/storage/volumes/>Volumes</a> pour plus de détails.</p></li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-2c0d882359718c4c69c67099bed2156c>5.3.6 - Configurer les comptes de service pour les pods</h1><p>Un ServiceAccount (compte de service) fournit une identité pour les processus qui s'exécutent dans un Pod.</p><p><em>Ceci est une introduction aux comptes de service pour les utilisateurs. Voir aussi
<a href=/docs/reference/access-authn-authz/service-accounts-admin/>Guide de l'administrateur du cluster des comptes de service</a>.</em></p><div class="alert alert-info note callout" role=alert><strong>Note:</strong> Ce document décrit le comportement des comptes de service dans un cluster mis en place conformément aux recommandations du projet Kubernetes. L'administrateur de votre cluster a peut-être personnalisé le comportement dans votre cluster, dans ce cas cette documentation pourrait être non applicable.</div><p>Lorsque vous (un humain) accédez au cluster (par exemple, en utilisant <code>kubectl</code>), vous êtes
authentifié par l'apiserver en tant que compte d'utilisateur particulier (actuellement, il s'agit
généralement de l'utilisateur <code>admin</code>, à moins que votre administrateur de cluster n'ait personnalisé votre cluster). Les processus dans les conteneurs dans les Pods peuvent également contacter l'apiserver. Dans ce cas, ils sont authentifiés en tant que compte de service particulier (par exemple, <code>default</code>).</p><h2 id=pré-requis>Pré-requis</h2><p><p>Vous devez disposer d'un cluster Kubernetes et l'outil de ligne de commande kubectl doit être configuré pour communiquer avec votre cluster.
Si vous ne possédez pas déjà de cluster, vous pouvez en créer un en utilisant <a href=/docs/setup/minikube>Minikube</a>, ou vous pouvez utiliser l'un de ces environnements Kubernetes:</p><ul><li><a href=https://killercoda.com/playgrounds/scenario/kubernetes>Killercoda</a></li><li><a href=http://labs.play-with-k8s.com/>Play with Kubernetes</a></li></ul>Pour consulter la version, entrez <code>kubectl version</code>.</p><h2 id=utiliser-le-compte-de-service-par-défaut-pour-accéder-au-api-server>Utiliser le compte de service par défaut pour accéder au API server.</h2><p>Si vous obtenez le raw json ou yaml pour un Pod que vous avez créé (par exemple, <code>kubectl get pods/&lt;podname> -o yaml</code>), vous pouvez voir que le champ <code>spec.serviceAccountName</code> a été <a href=/docs/user-guide/working-with-resources/#resources-are-automatically-modified>automatiquement assigné</a>.</p><p>Vous pouvez accéder à l'API depuis l'intérieur d'un Pod en utilisant les identifiants de compte de service montés automatiquement, comme décrit dans <a href=/docs/user-guide/accessing-the-cluster/#accessing-the-api-from-a-pod>Accès au cluster</a>.
Les permissions API du compte de service dépendent du <a href=/docs/reference/access-authn-authz/authorization/#authorization-modules>plugin d'autorisation et de la politique</a> en usage.</p><p>Dans la version 1.6+, vous pouvez choisir de ne pas utiliser le montage automatique des identifiants API pour un compte de service en définissant <code>automountServiceAccountToken: false</code> sur le compte de service :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>ServiceAccount<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>build-robot<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>automountServiceAccountToken</span>:<span style=color:#bbb> </span><span style=color:#a2f;font-weight:700>false</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:#00f;font-weight:700>...</span><span style=color:#bbb>
</span></span></span></code></pre></div><p>Dans la version 1.6+, vous pouvez également choisir de ne pas monter automatiquement les identifiants API pour un Pod particulier :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>my-pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>serviceAccountName</span>:<span style=color:#bbb> </span>build-robot<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>automountServiceAccountToken</span>:<span style=color:#bbb> </span><span style=color:#a2f;font-weight:700>false</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>...<span style=color:#bbb>
</span></span></span></code></pre></div><p>La spéc de Pod a prépondérance par rapport au compte de service si les deux spécifient la valeur <code>automountServiceAccountToken</code>.</p><h2 id=utiliser-plusieurs-comptes-de-services>Utiliser plusieurs comptes de services.</h2><p>Chaque Namespace possède une ressource ServiceAccount par défaut appelée <code>default</code>.
Vous pouvez lister cette ressource et toutes les autres ressources de ServiceAccount dans le Namespace avec cette commande :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get serviceAccounts
</span></span></code></pre></div><p>La sortie est comme la suivante :</p><pre tabindex=0><code>NAME      SECRETS    AGE
default   1          1d
</code></pre><p>Vous pouvez créer des objets ServiceAccount supplémentaires comme ceci :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl apply -f - <span style=color:#b44>&lt;&lt;EOF
</span></span></span><span style=display:flex><span><span style=color:#b44>apiVersion: v1
</span></span></span><span style=display:flex><span><span style=color:#b44>kind: ServiceAccount
</span></span></span><span style=display:flex><span><span style=color:#b44>metadata:
</span></span></span><span style=display:flex><span><span style=color:#b44>  name: build-robot
</span></span></span><span style=display:flex><span><span style=color:#b44>EOF</span>
</span></span></code></pre></div><p>Si vous obtenez un dump complet de l'objet compte de service, par exemple :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get serviceaccounts/build-robot -o yaml
</span></span></code></pre></div><p>La sortie est comme la suivante :</p><pre tabindex=0><code>apiVersion: v1
kind: ServiceAccount
metadata:
  creationTimestamp: 2015-06-16T00:12:59Z
  name: build-robot
  namespace: default
  resourceVersion: &#34;272500&#34;
  selfLink: /api/v1/namespaces/default/serviceaccounts/build-robot
  uid: 721ab723-13bc-11e5-aec2-42010af0021e
secrets:
- name: build-robot-token-bvbk5
</code></pre><p>vous verrez alors qu'un token a été automatiquement créé et est référencé par le compte de service.</p><p>Vous pouvez utiliser des plugins d'autorisation pour <a href=/docs/reference/access-authn-authz/rbac/#service-account-permissions>définir les permissions sur les comptes de service</a>.</p><p>Pour utiliser un compte de service autre que par défaut, il suffit de spécifier le <code>spec.serviceAccountName</code> d'un Pod au nom du compte de service que vous souhaitez utiliser.</p><p>Le compte de service doit exister au moment de la création du Pod, sinon il sera rejeté.</p><p>Vous ne pouvez pas mettre à jour le compte de service d'un Pod déjà créé.</p><p>Vous pouvez supprimer le compte de service de cet exemple comme ceci :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl delete serviceaccount/build-robot
</span></span></code></pre></div><h2 id=créez-manuellement-un-api-token-de-compte-de-service>Créez manuellement un API token de compte de service.</h2><p>Supposons que nous ayons un compte de service existant nommé "build-robot" comme mentionné ci-dessus,et que nous allons créer un nouveau Secret manuellement.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl apply -f - <span style=color:#b44>&lt;&lt;EOF
</span></span></span><span style=display:flex><span><span style=color:#b44>apiVersion: v1
</span></span></span><span style=display:flex><span><span style=color:#b44>kind: Secret
</span></span></span><span style=display:flex><span><span style=color:#b44>metadata:
</span></span></span><span style=display:flex><span><span style=color:#b44>  name: build-robot-secret
</span></span></span><span style=display:flex><span><span style=color:#b44>  annotations:
</span></span></span><span style=display:flex><span><span style=color:#b44>    kubernetes.io/service-account.name: build-robot
</span></span></span><span style=display:flex><span><span style=color:#b44>type: kubernetes.io/service-account-token
</span></span></span><span style=display:flex><span><span style=color:#b44>EOF</span>
</span></span></code></pre></div><p>Vous pouvez maintenant confirmer que le Secret nouvellement construit est rempli d'un API token pour le compte de service "build-robot".</p><p>Tous les tokens pour des comptes de service non-existants seront nettoyés par le contrôleur de token.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl describe secrets/build-robot-secret
</span></span></code></pre></div><p>La sortie est comme la suivante :</p><pre tabindex=0><code>Name:           build-robot-secret
Namespace:      default
Labels:         &lt;none&gt;
Annotations:    kubernetes.io/service-account: name=build-robot
                kubernetes.io/service-account: uid=da68f9c6-9d26-11e7-b84e-002dc52800da

Type:   kubernetes.io/service-account-token

Data
====
ca.crt:         1338 bytes
namespace:      7 bytes
token:          ...
</code></pre><div class="alert alert-info note callout" role=alert><strong>Note:</strong> Le contenu de <code>token</code> est éludé ici.</div><h2 id=ajouter-imagepullsecrets-à-un-compte-de-service>Ajouter ImagePullSecrets à un compte de service</h2><p>Tout d'abord, créez un imagePullSecret, comme décrit <a href=/docs/concepts/containers/images/#specifying-imagepullsecrets-on-a-pod>ici</a>.
Puis, vérifiez qu'il a été créé. Par exemple :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get secrets myregistrykey
</span></span></code></pre></div><p>La sortie est comme la suivante :</p><pre tabindex=0><code>NAME             TYPE                              DATA    AGE
myregistrykey    kubernetes.io/.dockerconfigjson   1       1d
</code></pre><p>Ensuite, modifiez le compte de service par défaut du Namespace pour utiliser ce Secret comme un <code>imagePullSecret</code>.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl patch serviceaccount default -p <span style=color:#b44>&#39;{&#34;imagePullSecrets&#34;: [{&#34;name&#34;: &#34;myregistrykey&#34;}]}&#39;</span>
</span></span></code></pre></div><p>La version interactive nécessite un traitement manuel :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get serviceaccounts default -o yaml &gt; ./sa.yaml
</span></span></code></pre></div><p>La sortie du fichier <code>sa.yaml</code> est similaire à celle-ci :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>apiVersion: v1
</span></span><span style=display:flex><span>kind: ServiceAccount
</span></span><span style=display:flex><span>metadata:
</span></span><span style=display:flex><span>  creationTimestamp: 2015-08-07T22:02:39Z
</span></span><span style=display:flex><span>  name: default
</span></span><span style=display:flex><span>  namespace: default
</span></span><span style=display:flex><span>  resourceVersion: <span style=color:#b44>&#34;243024&#34;</span>
</span></span><span style=display:flex><span>  selfLink: /api/v1/namespaces/default/serviceaccounts/default
</span></span><span style=display:flex><span>  uid: 052fb0f4-3d50-11e5-b066-42010af0d7b6
</span></span><span style=display:flex><span>secrets:
</span></span><span style=display:flex><span>- name: default-token-uudge
</span></span></code></pre></div><p>En utilisant l'éditeur de votre choix (par exemple <code>vi</code>), ouvrez le fichier <code>sa.yaml</code>, supprimez la ligne avec la clé <code>resourceVersion</code>, ajoutez les lignes avec <code>imagePullSecrets:</code> et sauvegardez.</p><p>La sortie du fichier <code>sa.yaml</code> est similaire à celle-ci :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>apiVersion: v1
</span></span><span style=display:flex><span>kind: ServiceAccount
</span></span><span style=display:flex><span>metadata:
</span></span><span style=display:flex><span>  creationTimestamp: 2015-08-07T22:02:39Z
</span></span><span style=display:flex><span>  name: default
</span></span><span style=display:flex><span>  namespace: default
</span></span><span style=display:flex><span>  selfLink: /api/v1/namespaces/default/serviceaccounts/default
</span></span><span style=display:flex><span>  uid: 052fb0f4-3d50-11e5-b066-42010af0d7b6
</span></span><span style=display:flex><span>secrets:
</span></span><span style=display:flex><span>- name: default-token-uudge
</span></span><span style=display:flex><span>imagePullSecrets:
</span></span><span style=display:flex><span>- name: myregistrykey
</span></span></code></pre></div><p>Enfin, remplacez le compte de service par le nouveau fichier <code>sa.yaml</code> mis à jour.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl replace serviceaccount default -f ./sa.yaml
</span></span></code></pre></div><p>Maintenant, tous les nouveaux Pods créés dans le Namespace courant auront ceci ajouté à leurs spécifications :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>imagePullSecrets</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>myregistrykey<span style=color:#bbb>
</span></span></span></code></pre></div><h2 id=projection-du-volume-des-tokens-de-compte-de-service>Projection du volume des tokens de compte de service</h2><div style=margin-top:10px;margin-bottom:10px><b>FEATURE STATE:</b> <code>Kubernetes v1.12 [beta]</code></div><div class="alert alert-info note callout" role=alert><strong>Note:</strong><p>Ce ServiceAccountTokenVolumeProjection est <strong>beta</strong> en 1.12 et
activé en passant tous les paramètres suivants au serveur API :</p><ul><li><code>--service-account-issuer</code></li><li><code>--service-account-signing-key-file</code></li><li><code>--service-account-api-audiences</code></li></ul></div><p>Kubelet peut également projeter un token de compte de service dans un Pod. Vous pouvez spécifier les propriétés souhaitées du token, telles que l'audience et la durée de validité.
Ces propriétés ne sont pas configurables sur le compte de service par défaut. Le token de compte de service devient également invalide par l'API lorsque le Pod ou le ServiceAccount est supprimé</p><p>Ce comportement est configuré sur un PodSpec utilisant un type de ProjectedVolume appelé
<a href=/docs/concepts/storage/volumes/#projected>ServiceAccountToken</a>. Pour fournir un
Pod avec un token avec une audience de "vault" et une durée de validité de deux heures, vous devriez configurer ce qui suit dans votre PodSpec :</p><div class=highlight><div class=copy-code-icon style=text-align:right><a href=https://raw.githubusercontent.com/kubernetes/website/main/content/fr/examples/pods/pod-projected-svc-token.yaml download=pods/pod-projected-svc-token.yaml><code>pods/pod-projected-svc-token.yaml</code></a>
<img src=/images/copycode.svg style=max-height:24px;cursor:pointer onclick='copyCode("pods-pod-projected-svc-token-yaml")' title="Copy pods/pod-projected-svc-token.yaml to clipboard"></img></div><div class=includecode id=pods-pod-projected-svc-token-yaml><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>nginx<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>nginx<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>nginx<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>volumeMounts</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:green;font-weight:700>mountPath</span>:<span style=color:#bbb> </span>/var/run/secrets/tokens<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>vault-token<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>serviceAccountName</span>:<span style=color:#bbb> </span>build-robot<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>volumes</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>vault-token<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>projected</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>sources</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- <span style=color:green;font-weight:700>serviceAccountToken</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>path</span>:<span style=color:#bbb> </span>vault-token<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>expirationSeconds</span>:<span style=color:#bbb> </span><span style=color:#666>7200</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>audience</span>:<span style=color:#bbb> </span>vault<span style=color:#bbb>
</span></span></span></code></pre></div></div></div><p>Créez le Pod</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl create -f https://k8s.io/examples/pods/pod-projected-svc-token.yaml
</span></span></code></pre></div><p>Kubelet demandera et stockera le token a la place du Pod, rendra le token disponible pour le Pod à un chemin d'accès configurable, et rafraîchissez le token à l'approche de son expiration. Kubelet fait tourner le token de manière proactive s'il est plus vieux que 80% de son TTL total, ou si le token est plus vieux que 24 heures.</p><p>L'application est responsable du rechargement du token lorsque celui ci est renouvelé. Un rechargement périodique (par ex. toutes les 5 minutes) est suffisant pour la plupart des cas d'utilisation.</p></div><div class=td-content style=page-break-before:always><h1 id=pg-d385b86a7cb496d3b1c3b2a47280ca70>5.3.7 - Récupération d'une image d'un registre privé</h1><p>Cette page montre comment créer un Pod qui utilise un Secret pour récupérer une image d'un registre privé.</p><h2 id=pré-requis>Pré-requis</h2><ul><li><p><p>Vous devez disposer d'un cluster Kubernetes et l'outil de ligne de commande kubectl doit être configuré pour communiquer avec votre cluster.
Si vous ne possédez pas déjà de cluster, vous pouvez en créer un en utilisant <a href=/docs/setup/minikube>Minikube</a>, ou vous pouvez utiliser l'un de ces environnements Kubernetes:</p><ul><li><a href=https://killercoda.com/playgrounds/scenario/kubernetes>Killercoda</a></li><li><a href=http://labs.play-with-k8s.com/>Play with Kubernetes</a></li></ul>Pour consulter la version, entrez <code>kubectl version</code>.</p></li><li><p>Pour faire cet exercice, vous avez besoin d'un
<a href=https://docs.docker.com/docker-id/>Docker ID</a> et un mot de passe.</p></li></ul><h2 id=connectez-vous-à-docker>Connectez-vous à Docker</h2><p>Sur votre ordinateur, vous devez vous authentifier à un registre afin de récupérer une image privée :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>docker login
</span></span></code></pre></div><p>Une fois que c'est fait, entrez votre nom d'utilisateur et votre mot de passe Docker.</p><p>Le processus de connexion crée ou met à jour un fichier <code>config.json</code> qui contient un token d'autorisation.</p><p>Consultez le fichier <code>config.json</code> :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>cat ~/.docker/config.json
</span></span></code></pre></div><p>La sortie comporte une section similaire à celle-ci :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-json data-lang=json><span style=display:flex><span>{
</span></span><span style=display:flex><span>    <span style=color:green;font-weight:700>&#34;auths&#34;</span>: {
</span></span><span style=display:flex><span>        <span style=color:green;font-weight:700>&#34;https://index.docker.io/v1/&#34;</span>: {
</span></span><span style=display:flex><span>            <span style=color:green;font-weight:700>&#34;auth&#34;</span>: <span style=color:#b44>&#34;c3R...zE2&#34;</span>
</span></span><span style=display:flex><span>        }
</span></span><span style=display:flex><span>    }
</span></span><span style=display:flex><span>}
</span></span></code></pre></div><div class="alert alert-info note callout" role=alert><strong>Note:</strong> Si vous utilisez le credentials store de Docker, vous ne verrez pas cette entrée <code>auth</code> mais une entrée <code>credsStore</code> avec le nom du Store comme valeur.</div><h2 id=registry-secret-existing-credentials>Créez un Secret basé sur les identifiants existants du Docker</h2><p>Le cluster Kubernetes utilise le type Secret de <code>docker-registry</code> pour s'authentifier avec
un registre de conteneurs pour y récupérer une image privée.</p><p>Si vous avez déjà lancé <code>docker login</code>, vous pouvez copier ces identifiants dans Kubernetes</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl create secret generic regcred <span style=color:#b62;font-weight:700>\
</span></span></span><span style=display:flex><span><span style=color:#b62;font-weight:700></span>    --from-file<span style=color:#666>=</span>.dockerconfigjson<span style=color:#666>=</span>&lt;path/to/.docker/config.json&gt; <span style=color:#b62;font-weight:700>\
</span></span></span><span style=display:flex><span><span style=color:#b62;font-weight:700></span>    --type<span style=color:#666>=</span>kubernetes.io/dockerconfigjson
</span></span></code></pre></div><p>Si vous avez besoin de plus de contrôle (par exemple, pour définir un Namespace ou un label sur le nouveau secret), vous pouvez alors personnaliser le secret avant de le stocker.
Assurez-vous de :</p><ul><li>Attribuer la valeur <code>.dockerconfigjson</code> dans le nom de l'élément data</li><li>Encoder le fichier docker en base64 et colle cette chaîne, non interrompue, comme valeur du champ <code>data[".dockerconfigjson"]</code>.</li><li>Mettre <code>type</code> à <code>kubernetes.io/dockerconfigjson</code>.</li></ul><p>Exemple:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Secret<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>myregistrykey<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>namespace</span>:<span style=color:#bbb> </span>awesomeapps<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>data</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>.dockerconfigjson</span>:<span style=color:#bbb> </span>UmVhbGx5IHJlYWxseSByZWVlZWVlZWVlZWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWxsbGxsbGxsbGxsbGxsbGxsbGxsbGxsbGxsbGxsbGx5eXl5eXl5eXl5eXl5eXl5eXl5eSBsbGxsbGxsbGxsbGxsbG9vb29vb29vb29vb29vb29vb29vb29vb29vb25ubm5ubm5ubm5ubm5ubm5ubm5ubm5ubmdnZ2dnZ2dnZ2dnZ2dnZ2dnZ2cgYXV0aCBrZXlzCg==<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>type</span>:<span style=color:#bbb> </span>kubernetes.io/dockerconfigjson<span style=color:#bbb>
</span></span></span></code></pre></div><p>Si vous obtenez le message d'erreur <code>error: no objects passed to create</code>, cela peut signifier que la chaîne encodée en base64 est invalide.
Si vous obtenez un message d'erreur comme <code>Secret "myregistrykey" is invalid: data[.dockerconfigjson]: invalid value ...</code>, cela signifie que la chaîne encodée en base64 a été décodée avec succès, mais n'a pas pu être interprétée comme un fichier <code>.docker/config.json</code>.</p><h2 id=créez-un-secret-en-fournissant-les-identifiants-sur-la-ligne-de-commande>Créez un Secret en fournissant les identifiants sur la ligne de commande</h2><p>Créez ce secret, en le nommant <code>regcred</code> :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl create secret docker-registry regcred --docker-server<span style=color:#666>=</span>&lt;your-registry-server&gt; --docker-username<span style=color:#666>=</span>&lt;your-name&gt; --docker-password<span style=color:#666>=</span>&lt;your-pword&gt; --docker-email<span style=color:#666>=</span>&lt;your-email&gt;
</span></span></code></pre></div><p>où :</p><ul><li><code>&lt;your-registry-server></code> est votre FQDN de registre de docker privé. (<a href=https://index.docker.io/v1/>https://index.docker.io/v1/</a> for DockerHub)</li><li><code>&lt;your-name></code> est votre nom d'utilisateur Docker.</li><li><code>&lt;your-pword></code> est votre mot de passe Docker.</li><li><code>&lt;your-email></code> est votre email Docker.</li></ul><p>Vous avez réussi à définir vos identifiants Docker dans le cluster comme un secret appelé <code>regcred</code>.</p><div class="alert alert-info note callout" role=alert><strong>Note:</strong> Saisir des secrets sur la ligne de commande peut les conserver dans l'historique de votre shell sans protection, et ces secrets peuvent également être visibles par d'autres utilisateurs sur votre ordinateur pendant l'exécution de <code>kubectl</code>.</div><h2 id=inspection-du-secret-regcred>Inspection du secret <code>regcred</code></h2><p>Pour comprendre le contenu du Secret <code>regcred</code> que vous venez de créer, commencez par visualiser le Secret au format YAML :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get secret regcred --output<span style=color:#666>=</span>yaml
</span></span></code></pre></div><p>La sortie est similaire à celle-ci :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Secret<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>...<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>regcred<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>...<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>data</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>.dockerconfigjson</span>:<span style=color:#bbb> </span>eyJodHRwczovL2luZGV4L ... J0QUl6RTIifX0=<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>type</span>:<span style=color:#bbb> </span>kubernetes.io/dockerconfigjson<span style=color:#bbb>
</span></span></span></code></pre></div><p>La valeur du champ <code>.dockerconfigjson</code> est une représentation en base64 de vos identifiants Docker.</p><p>Pour comprendre ce que contient le champ <code>.dockerconfigjson</code>, convertissez les données secrètes en un format lisible :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get secret regcred --output<span style=color:#666>=</span><span style=color:#b44>&#34;jsonpath={.data.\.dockerconfigjson}&#34;</span> | base64 --decode
</span></span></code></pre></div><p>La sortie est similaire à celle-ci :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-json data-lang=json><span style=display:flex><span>{<span style=color:green;font-weight:700>&#34;auths&#34;</span>:{<span style=color:green;font-weight:700>&#34;your.private.registry.example.com&#34;</span>:{<span style=color:green;font-weight:700>&#34;username&#34;</span>:<span style=color:#b44>&#34;janedoe&#34;</span>,<span style=color:green;font-weight:700>&#34;password&#34;</span>:<span style=color:#b44>&#34;xxxxxxxxxxx&#34;</span>,<span style=color:green;font-weight:700>&#34;email&#34;</span>:<span style=color:#b44>&#34;jdoe@example.com&#34;</span>,<span style=color:green;font-weight:700>&#34;auth&#34;</span>:<span style=color:#b44>&#34;c3R...zE2&#34;</span>}}}
</span></span></code></pre></div><p>Pour comprendre ce qui se cache dans le champ `auth', convertissez les données encodées en base64 dans un format lisible :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span><span style=color:#a2f>echo</span> <span style=color:#b44>&#34;c3R...zE2&#34;</span> | base64 --decode
</span></span></code></pre></div><p>La sortie en tant que nom d'utilisateur et mot de passe concaténés avec un <code>:</code>, est similaire à ceci :</p><pre tabindex=0><code class=language-none data-lang=none>janedoe:xxxxxxxxxxx
</code></pre><p>Remarquez que les données secrètes contiennent le token d'autorisation similaire à votre fichier local <code>~/.docker/config.json</code>.</p><p>Vous avez réussi à définir vos identifiants de Docker comme un Secret appelé <code>regcred</code> dans le cluster.</p><h2 id=créez-un-pod-qui-utilise-votre-secret>Créez un Pod qui utilise votre Secret</h2><p>Voici un fichier de configuration pour un Pod qui a besoin d'accéder à vos identifiants Docker dans <code>regcred</code> :</p><div class=highlight><div class=copy-code-icon style=text-align:right><a href=https://raw.githubusercontent.com/kubernetes/website/main/content/fr/examples/pods/private-reg-pod.yaml download=pods/private-reg-pod.yaml><code>pods/private-reg-pod.yaml</code></a>
<img src=/images/copycode.svg style=max-height:24px;cursor:pointer onclick='copyCode("pods-private-reg-pod-yaml")' title="Copy pods/private-reg-pod.yaml to clipboard"></img></div><div class=includecode id=pods-private-reg-pod-yaml><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>private-reg<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>private-reg-container<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>&lt;your-private-image&gt;<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>imagePullSecrets</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>regcred<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>
</span></span></span></code></pre></div></div></div><p>Téléchargez le fichier ci-dessus :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>wget -O my-private-reg-pod.yaml https://k8s.io/examples/pods/private-reg-pod.yaml
</span></span></code></pre></div><p>Dans le fichier <code>my-private-reg-pod.yaml</code>, remplacez <code>&lt;your-private-image></code> par le chemin d'accès à une image dans un registre privé tel que</p><pre tabindex=0><code class=language-none data-lang=none>your.private.registry.example.com/janedoe/jdoe-private:v1
</code></pre><p>Pour récupérer l'image du registre privé, Kubernetes a besoin des identifiants.
Le champ <code>imagePullSecrets</code> dans le fichier de configuration spécifie que Kubernetes doit obtenir les informations d'identification d'un Secret nommé <code>regcred</code>.</p><p>Créez un Pod qui utilise votre secret et vérifiez que le Pod est bien lancé :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl apply -f my-private-reg-pod.yaml
</span></span><span style=display:flex><span>kubectl get pod private-reg
</span></span></code></pre></div><h2 id=a-suivre>A suivre</h2><ul><li>Pour en savoir plus sur les <a href=/docs/concepts/configuration/secret/>Secrets</a>.</li><li>Pour en savoir plus sur l'<a href=/docs/concepts/containers/images/#using-a-private-registry>utilisation d'un registre privé</a>.</li><li>Pour en savoir plus sur l'<a href=/docs/tasks/configure-pod-container/configure-service-account/#add-imagepullsecrets-to-a-service-account>ajout d'un imagePullSecrets à un compte de service</a>.</li><li>Voir <a href=/docs/reference/generated/kubectl/kubectl-commands/#-em-secret-docker-registry-em->kubectl crée un Secret de registre de docker</a>.</li><li>Voir <a href=/docs/reference/generated/kubernetes-api/v1.25/#secret-v1-core>Secret</a>.</li><li>Voir le champ <code>imagePullSecrets</code> de <a href=/docs/reference/generated/kubernetes-api/v1.25/#podspec-v1-core>PodSpec</a>.</li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-eb54daf87df373096b5e830680194dfc>5.3.8 - Configurer les Liveness, Readiness et Startup Probes</h1><p>Cette page montre comment configurer les liveness, readiness et startup probes pour les conteneurs.</p><p>Le <a href=/docs/admin/kubelet/>Kubelet</a> utilise les liveness probes pour détecter quand redémarrer un conteneur. Par exemple, les Liveness probes pourraient attraper un deadlock dans le cas où une application est en cours d'exécution, mais qui est incapable de traiter les requêtes. Le redémarrage d'un conteneur dans un tel état rend l'application plus disponible malgré les bugs.</p><p>Le Kubelet utilise readiness probes pour savoir quand un conteneur est prêt à accepter le trafic. Un Pod est considéré comme prêt lorsque tous ses conteneurs sont prêts.
Ce signal sert notamment à contrôler les pods qui sont utilisés comme backends pour les Services. Lorsqu'un Pod n'est pas prêt, il est retiré des équilibreurs de charge des Services.</p><p>Le Kubelet utilise startup probes pour savoir quand une application d'un conteneur a démarré.
Si une telle probe est configurée, elle désactive les contrôles de liveness et readiness jusqu'à cela réussit, en s'assurant que ces probes n'interfèrent pas avec le démarrage de l'application.
Cela peut être utilisé dans le cas des liveness checks sur les conteneurs à démarrage lent, en les évitant de se faire tuer par le Kubelet avant qu'ils ne soient opérationnels.</p><h2 id=pré-requis>Pré-requis</h2><p><p>Vous devez disposer d'un cluster Kubernetes et l'outil de ligne de commande kubectl doit être configuré pour communiquer avec votre cluster.
Si vous ne possédez pas déjà de cluster, vous pouvez en créer un en utilisant <a href=/docs/setup/minikube>Minikube</a>, ou vous pouvez utiliser l'un de ces environnements Kubernetes:</p><ul><li><a href=https://killercoda.com/playgrounds/scenario/kubernetes>Killercoda</a></li><li><a href=http://labs.play-with-k8s.com/>Play with Kubernetes</a></li></ul>Pour consulter la version, entrez <code>kubectl version</code>.</p><h2 id=définir-une-commande-de-liveness>Définir une commande de liveness</h2><p>De nombreuses applications fonctionnant pour des longues périodes finissent par passer à des états de rupture et ne peuvent pas se rétablir, sauf en étant redémarrées. Kubernetes fournit des liveness probes pour détecter et remédier à ces situations.</p><p>Dans cet exercice, vous allez créer un Pod qui exécute un conteneur basé sur l'image <code>k8s.gcr.io/busybox</code>. Voici le fichier de configuration pour le Pod :</p><div class=highlight><div class=copy-code-icon style=text-align:right><a href=https://raw.githubusercontent.com/kubernetes/website/main/content/fr/examples/pods/probe/exec-liveness.yaml download=pods/probe/exec-liveness.yaml><code>pods/probe/exec-liveness.yaml</code></a>
<img src=/images/copycode.svg style=max-height:24px;cursor:pointer onclick='copyCode("pods-probe-exec-liveness-yaml")' title="Copy pods/probe/exec-liveness.yaml to clipboard"></img></div><div class=includecode id=pods-probe-exec-liveness-yaml><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>labels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>test</span>:<span style=color:#bbb> </span>liveness<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>liveness-exec<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>liveness<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>k8s.gcr.io/busybox<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>args</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- /bin/sh<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- -c<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- touch /tmp/healthy; sleep 30; rm -f /tmp/healthy; sleep 600<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>livenessProbe</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>exec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>command</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span>- cat<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span>- /tmp/healthy<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>initialDelaySeconds</span>:<span style=color:#bbb> </span><span style=color:#666>5</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>periodSeconds</span>:<span style=color:#bbb> </span><span style=color:#666>5</span><span style=color:#bbb>
</span></span></span></code></pre></div></div></div><p>Dans le fichier de configuration, vous constatez que le Pod a un seul conteneur.
Le champ <code>periodSeconds</code> spécifie que le Kubelet doit effectuer un check de liveness toutes les 5 secondes. Le champ <code>initialDelaySeconds</code> indique au Kubelet qu'il devrait attendre 5 secondes avant d'effectuer la première probe. Pour effectuer une probe, le Kubelet exécute la commande <code>cat /tmp/healthy</code> dans le conteneur. Si la commande réussit, elle renvoie 0, et le Kubelet considère que le conteneur est vivant et en bonne santé. Si la commande renvoie une valeur non nulle, le Kubelet tue le conteneur et le redémarre.</p><p>Au démarrage, le conteneur exécute cette commande :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>/bin/sh -c <span style=color:#b44>&#34;touch /tmp/healthy; sleep 30; rm -f /tmp/healthy; sleep 600&#34;</span>
</span></span></code></pre></div><p>Pour les 30 premières secondes de la vie du conteneur, il y a un fichier <code>/tmp/healthy</code>.
Donc pendant les 30 premières secondes, la commande <code>cat /tmp/healthy</code> renvoie un code de succès. Après 30 secondes, <code>cat /tmp/healthy</code> renvoie un code d'échec.</p><p>Créez le Pod :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl apply -f https://k8s.io/examples/pods/probe/exec-liveness.yaml
</span></span></code></pre></div><p>Dans les 30 secondes, visualisez les événements du Pod :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl describe pod liveness-exec
</span></span></code></pre></div><p>La sortie indique qu'aucune liveness probe n'a encore échoué :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>FirstSeen    LastSeen    Count   From            SubobjectPath           Type        Reason      Message
</span></span><span style=display:flex><span>--------- --------    -----   ----            -------------           --------    ------      -------
</span></span><span style=display:flex><span>24s       24s     <span style=color:#666>1</span>   <span style=color:#666>{</span>default-scheduler <span style=color:#666>}</span>                    Normal      Scheduled   Successfully assigned liveness-exec to worker0
</span></span><span style=display:flex><span>23s       23s     <span style=color:#666>1</span>   <span style=color:#666>{</span>kubelet worker0<span style=color:#666>}</span>   spec.containers<span style=color:#666>{</span>liveness<span style=color:#666>}</span>   Normal      Pulling     pulling image <span style=color:#b44>&#34;k8s.gcr.io/busybox&#34;</span>
</span></span><span style=display:flex><span>23s       23s     <span style=color:#666>1</span>   <span style=color:#666>{</span>kubelet worker0<span style=color:#666>}</span>   spec.containers<span style=color:#666>{</span>liveness<span style=color:#666>}</span>   Normal      Pulled      Successfully pulled image <span style=color:#b44>&#34;k8s.gcr.io/busybox&#34;</span>
</span></span><span style=display:flex><span>23s       23s     <span style=color:#666>1</span>   <span style=color:#666>{</span>kubelet worker0<span style=color:#666>}</span>   spec.containers<span style=color:#666>{</span>liveness<span style=color:#666>}</span>   Normal      Created     Created container with docker id 86849c15382e; Security:<span style=color:#666>[</span><span style=color:#b8860b>seccomp</span><span style=color:#666>=</span>unconfined<span style=color:#666>]</span>
</span></span><span style=display:flex><span>23s       23s     <span style=color:#666>1</span>   <span style=color:#666>{</span>kubelet worker0<span style=color:#666>}</span>   spec.containers<span style=color:#666>{</span>liveness<span style=color:#666>}</span>   Normal      Started     Started container with docker id 86849c15382e
</span></span></code></pre></div><p>Après 35 secondes, visualisez à nouveau les événements du Pod :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl describe pod liveness-exec
</span></span></code></pre></div><p>Au bas de la sortie, il y a des messages indiquant que les liveness probes ont échoué, et que les conteneurs ont été tués et recréés.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>FirstSeen LastSeen    Count   From            SubobjectPath           Type        Reason      Message
</span></span><span style=display:flex><span>--------- --------    -----   ----            -------------           --------    ------      -------
</span></span><span style=display:flex><span>37s       37s     <span style=color:#666>1</span>   <span style=color:#666>{</span>default-scheduler <span style=color:#666>}</span>                    Normal      Scheduled   Successfully assigned liveness-exec to worker0
</span></span><span style=display:flex><span>36s       36s     <span style=color:#666>1</span>   <span style=color:#666>{</span>kubelet worker0<span style=color:#666>}</span>   spec.containers<span style=color:#666>{</span>liveness<span style=color:#666>}</span>   Normal      Pulling     pulling image <span style=color:#b44>&#34;k8s.gcr.io/busybox&#34;</span>
</span></span><span style=display:flex><span>36s       36s     <span style=color:#666>1</span>   <span style=color:#666>{</span>kubelet worker0<span style=color:#666>}</span>   spec.containers<span style=color:#666>{</span>liveness<span style=color:#666>}</span>   Normal      Pulled      Successfully pulled image <span style=color:#b44>&#34;k8s.gcr.io/busybox&#34;</span>
</span></span><span style=display:flex><span>36s       36s     <span style=color:#666>1</span>   <span style=color:#666>{</span>kubelet worker0<span style=color:#666>}</span>   spec.containers<span style=color:#666>{</span>liveness<span style=color:#666>}</span>   Normal      Created     Created container with docker id 86849c15382e; Security:<span style=color:#666>[</span><span style=color:#b8860b>seccomp</span><span style=color:#666>=</span>unconfined<span style=color:#666>]</span>
</span></span><span style=display:flex><span>36s       36s     <span style=color:#666>1</span>   <span style=color:#666>{</span>kubelet worker0<span style=color:#666>}</span>   spec.containers<span style=color:#666>{</span>liveness<span style=color:#666>}</span>   Normal      Started     Started container with docker id 86849c15382e
</span></span><span style=display:flex><span>2s        2s      <span style=color:#666>1</span>   <span style=color:#666>{</span>kubelet worker0<span style=color:#666>}</span>   spec.containers<span style=color:#666>{</span>liveness<span style=color:#666>}</span>   Warning     Unhealthy   Liveness probe failed: cat: can<span style=color:#b44>&#39;t open &#39;</span>/tmp/healthy<span>&#39;</span>: No such file or directory
</span></span></code></pre></div><p>Attendez encore 30 secondes et vérifiez que le conteneur a été redémarré :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get pod liveness-exec
</span></span></code></pre></div><p>La sortie montre que <code>RESTARTS</code> a été incrémenté :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>NAME            READY     STATUS    RESTARTS   AGE
</span></span><span style=display:flex><span>liveness-exec   1/1       Running   <span style=color:#666>1</span>          1m
</span></span></code></pre></div><h2 id=définir-une-requête-http-de-liveness>Définir une requête HTTP de liveness</h2><p>Un autre type de liveness probe utilise une requête GET HTTP. Voici la configuration
d'un Pod qui fait fonctionner un conteneur basé sur l'image <code>k8s.gcr.io/liveness</code>.</p><div class=highlight><div class=copy-code-icon style=text-align:right><a href=https://raw.githubusercontent.com/kubernetes/website/main/content/fr/examples/pods/probe/http-liveness.yaml download=pods/probe/http-liveness.yaml><code>pods/probe/http-liveness.yaml</code></a>
<img src=/images/copycode.svg style=max-height:24px;cursor:pointer onclick='copyCode("pods-probe-http-liveness-yaml")' title="Copy pods/probe/http-liveness.yaml to clipboard"></img></div><div class=includecode id=pods-probe-http-liveness-yaml><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>labels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>test</span>:<span style=color:#bbb> </span>liveness<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>liveness-http<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>liveness<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>k8s.gcr.io/liveness<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>args</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- /server<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>livenessProbe</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>httpGet</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>path</span>:<span style=color:#bbb> </span>/healthz<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>port</span>:<span style=color:#bbb> </span><span style=color:#666>8080</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>httpHeaders</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>Custom-Header<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>value</span>:<span style=color:#bbb> </span>Awesome<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>initialDelaySeconds</span>:<span style=color:#bbb> </span><span style=color:#666>3</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>periodSeconds</span>:<span style=color:#bbb> </span><span style=color:#666>3</span><span style=color:#bbb>
</span></span></span></code></pre></div></div></div><p>Dans le fichier de configuration, vous pouvez voir que le Pod a un seul conteneur.
Le champ <code>periodSeconds</code> spécifie que le Kubelet doit effectuer une liveness probe toutes les 3 secondes. Le champ <code>initialDelaySeconds</code> indique au Kubelet qu'il devrait attendre 3 secondes avant d'effectuer la première probe. Pour effectuer une probe, le Kubelet envoie une requête HTTP GET au serveur qui s'exécute dans le conteneur et écoute sur le port 8080. Si le handler du chemin <code>/healthz</code> du serveur renvoie un code de succès, le Kubelet considère que le conteneur est vivant et en bonne santé. Si le handler renvoie un code d'erreur, le Kubelet tue le conteneur et le redémarre.</p><p>Tout code supérieur ou égal à 200 et inférieur à 400 indique un succès. Tout autre code indique un échec.</p><p>Vous pouvez voir le code source du serveur dans
<a href=https://github.com/kubernetes/kubernetes/blob/master/test/images/agnhost/liveness/server.go>server.go</a>.</p><p>Pendant les 10 premières secondes où le conteneur est en vie, le handler <code>/healthz</code> renvoie un statut de 200. Après cela, le handler renvoie un statut de 500.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-go data-lang=go><span style=display:flex><span>http.<span style=color:#00a000>HandleFunc</span>(<span style=color:#b44>&#34;/healthz&#34;</span>, <span style=color:#a2f;font-weight:700>func</span>(w http.ResponseWriter, r <span style=color:#666>*</span>http.Request) {
</span></span><span style=display:flex><span>    duration <span style=color:#666>:=</span> time.<span style=color:#00a000>Now</span>().<span style=color:#00a000>Sub</span>(started)
</span></span><span style=display:flex><span>    <span style=color:#a2f;font-weight:700>if</span> duration.<span style=color:#00a000>Seconds</span>() &gt; <span style=color:#666>10</span> {
</span></span><span style=display:flex><span>        w.<span style=color:#00a000>WriteHeader</span>(<span style=color:#666>500</span>)
</span></span><span style=display:flex><span>        w.<span style=color:#00a000>Write</span>([]<span style=color:#a2f>byte</span>(fmt.<span style=color:#00a000>Sprintf</span>(<span style=color:#b44>&#34;erreur: %v&#34;</span>, duration.<span style=color:#00a000>Seconds</span>())))
</span></span><span style=display:flex><span>    } <span style=color:#a2f;font-weight:700>else</span> {
</span></span><span style=display:flex><span>        w.<span style=color:#00a000>WriteHeader</span>(<span style=color:#666>200</span>)
</span></span><span style=display:flex><span>        w.<span style=color:#00a000>Write</span>([]<span style=color:#a2f>byte</span>(<span style=color:#b44>&#34;ok&#34;</span>))
</span></span><span style=display:flex><span>    }
</span></span><span style=display:flex><span>})
</span></span></code></pre></div><p>Le Kubelet commence à effectuer des contrôles de santé 3 secondes après le démarrage du conteneur.
Ainsi, les premiers contrôles de santé seront réussis. Mais après 10 secondes, les contrôles de santé échoueront, et le Kubelet tuera et redémarrera le conteneur.</p><p>Pour essayer le HTTP liveness check, créez un Pod :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl apply -f https://k8s.io/examples/pods/probe/http-liveness.yaml
</span></span></code></pre></div><p>Après 10 secondes, visualisez les événements du Pod pour vérifier que les liveness probes ont échoué et le conteneur a été redémarré :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl describe pod liveness-http
</span></span></code></pre></div><p>Dans les versions antérieures à la v1.13 (y compris la v1.13), au cas où la variable d'environnement <code>http_proxy</code> (ou <code>HTTP_PROXY</code>) est définie sur le noeud où tourne un Pod, le HTTP liveness probe utilise ce proxy.
Dans les versions postérieures à la v1.13, les paramètres de la variable d'environnement du HTTP proxy local n'affectent pas le HTTP liveness probe.</p><h2 id=définir-une-tcp-liveness-probe>Définir une TCP liveness probe</h2><p>Un troisième type de liveness probe utilise un TCP Socket. Avec cette configuration, le Kubelet tentera d'ouvrir un socket vers votre conteneur sur le port spécifié.
S'il arrive à établir une connexion, le conteneur est considéré comme étant en bonne santé, s'il n'y arrive pas, c'est un échec.</p><div class=highlight><div class=copy-code-icon style=text-align:right><a href=https://raw.githubusercontent.com/kubernetes/website/main/content/fr/examples/pods/probe/tcp-liveness-readiness.yaml download=pods/probe/tcp-liveness-readiness.yaml><code>pods/probe/tcp-liveness-readiness.yaml</code></a>
<img src=/images/copycode.svg style=max-height:24px;cursor:pointer onclick='copyCode("pods-probe-tcp-liveness-readiness-yaml")' title="Copy pods/probe/tcp-liveness-readiness.yaml to clipboard"></img></div><div class=includecode id=pods-probe-tcp-liveness-readiness-yaml><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>goproxy<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>labels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>app</span>:<span style=color:#bbb> </span>goproxy<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>goproxy<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>k8s.gcr.io/goproxy:0.1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>ports</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:green;font-weight:700>containerPort</span>:<span style=color:#bbb> </span><span style=color:#666>8080</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>readinessProbe</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>tcpSocket</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>port</span>:<span style=color:#bbb> </span><span style=color:#666>8080</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>initialDelaySeconds</span>:<span style=color:#bbb> </span><span style=color:#666>5</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>periodSeconds</span>:<span style=color:#bbb> </span><span style=color:#666>10</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>livenessProbe</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>tcpSocket</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>port</span>:<span style=color:#bbb> </span><span style=color:#666>8080</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>initialDelaySeconds</span>:<span style=color:#bbb> </span><span style=color:#666>15</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>periodSeconds</span>:<span style=color:#bbb> </span><span style=color:#666>20</span><span style=color:#bbb>
</span></span></span></code></pre></div></div></div><p>Comme vous le voyez, la configuration pour un check TCP est assez similaire à un check HTTP.
Cet exemple utilise à la fois des readiness et liveness probes. Le Kubelet transmettra la première readiness probe 5 secondes après le démarrage du conteneur. Il tentera de se connecter au conteneur <code>goproxy</code> sur le port 8080. Si la probe réussit, le conteneur sera marqué comme prêt. Kubelet continuera à effectuer ce check tous les 10 secondes.</p><p>En plus de la readiness probe, cette configuration comprend une liveness probe.
Le Kubelet effectuera la première liveness probe 15 secondes après que le conteneur démarre. Tout comme la readiness probe, celle-ci tentera de se connecter au conteneur de <code>goproxy</code> sur le port 8080. Si la liveness probe échoue, le conteneur sera redémarré.</p><p>Pour essayer la TCP liveness check, créez un Pod :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl apply -f https://k8s.io/examples/pods/probe/tcp-liveness-readiness.yaml
</span></span></code></pre></div><p>Après 15 secondes, visualisez les événements de Pod pour vérifier les liveness probes :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl describe pod goproxy
</span></span></code></pre></div><h2 id=utilisation-d-un-port-nommé>Utilisation d'un port nommé</h2><p>Vous pouvez utiliser un <a href=/docs/reference/generated/kubernetes-api/v1.25/#containerport-v1-core>ContainerPort</a> nommé pour les HTTP or TCP liveness probes :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>ports</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>liveness-port<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>containerPort</span>:<span style=color:#bbb> </span><span style=color:#666>8080</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>hostPort</span>:<span style=color:#bbb> </span><span style=color:#666>8080</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>livenessProbe</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>httpGet</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>path</span>:<span style=color:#bbb> </span>/healthz<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>port</span>:<span style=color:#bbb> </span>liveness-port<span style=color:#bbb>
</span></span></span></code></pre></div><h2 id=define-startup-probes>Protéger les conteneurs à démarrage lent avec des startup probes</h2><p>Parfois, vous devez faire face à des applications legacy qui peuvent nécessiter un temps de démarrage supplémentaire lors de leur première initialisation.
Dans de telles situations, il peut être compliqué de régler les paramètres de la liveness probe sans compromettant la réponse rapide aux blocages qui ont motivé une telle probe.
L'astuce est de configurer une startup probe avec la même commande, HTTP ou TCP check avec un <code>failureThreshold * periodSeconds</code> assez long pour couvrir le pire des scénarios des temps de démarrage.</p><p>Ainsi, l'exemple précédent deviendrait :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>ports</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>liveness-port<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>containerPort</span>:<span style=color:#bbb> </span><span style=color:#666>8080</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>hostPort</span>:<span style=color:#bbb> </span><span style=color:#666>8080</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>livenessProbe</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>httpGet</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>path</span>:<span style=color:#bbb> </span>/healthz<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>port</span>:<span style=color:#bbb> </span>liveness-port<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>failureThreshold</span>:<span style=color:#bbb> </span><span style=color:#666>1</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>periodSeconds</span>:<span style=color:#bbb> </span><span style=color:#666>10</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>startupProbe</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>httpGet</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>path</span>:<span style=color:#bbb> </span>/healthz<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>port</span>:<span style=color:#bbb> </span>liveness-port<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>failureThreshold</span>:<span style=color:#bbb> </span><span style=color:#666>30</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>periodSeconds</span>:<span style=color:#bbb> </span><span style=color:#666>10</span><span style=color:#bbb>
</span></span></span></code></pre></div><p>Grâce à la startup probe, l'application aura un maximum de 5 minutes (30 * 10 = 300s) pour terminer son démarrage.
Une fois que la startup probe a réussi, la liveness probe prend le relais pour fournir une réponse rapide aux blocages de conteneurs.
Si la startup probe ne réussit jamais, le conteneur est tué après 300s puis soumis à la <code>restartPolicy</code> (politique de redémarrage) du Pod.</p><h2 id=définir-les-readiness-probes>Définir les readiness probes</h2><p>Parfois, les applications sont temporairement incapables de servir le trafic.
Par exemple, une application peut avoir besoin de charger des larges données ou des fichiers de configuration pendant le démarrage, ou elle peut dépendre de services externes après le démarrage.
Dans ces cas, vous ne voulez pas tuer l'application, mais vous ne voulez pas non plus lui envoyer de requêtes. Kubernetes fournit des readiness probes pour détecter et atténuer ces situations. Un pod avec des conteneurs qui signale qu'elle n'est pas prête ne reçoit pas de trafic par les services de Kubernetes.</p><div class="alert alert-info note callout" role=alert><strong>Note:</strong> Readiness probes fonctionnent sur le conteneur pendant tout son cycle de vie.</div><p>Readiness probes sont configurées de la même façon que les liveness probes. La seule différence est que vous utilisez le champ <code>readinessProbe</code> au lieu du champ <code>livenessProbe</code>.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>readinessProbe</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>exec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>command</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- cat<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- /tmp/healthy<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>initialDelaySeconds</span>:<span style=color:#bbb> </span><span style=color:#666>5</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>periodSeconds</span>:<span style=color:#bbb> </span><span style=color:#666>5</span><span style=color:#bbb>
</span></span></span></code></pre></div><p>La configuration des readiness probes HTTP et TCP reste également identique à celle des liveness probes.</p><p>Les readiness et liveness probes peuvent être utilisées en parallèle pour le même conteneur.
L'utilisation des deux peut garantir que le trafic n'atteigne pas un conteneur qui n'est pas prêt et que les conteneurs soient redémarrés en cas de défaillance.</p><h2 id=configurer-les-probes>Configurer les Probes</h2><p><a href=/docs/reference/generated/kubernetes-api/v1.25/#probe-v1-core>Probes</a> ont un certain nombre de champs qui vous pouvez utiliser pour contrôler plus précisément le comportement de la vivacité et de la disponibilité des probes :</p><ul><li><code>initialDelaySeconds</code>: Nombre de secondes après le démarrage du conteneur avant que les liveness et readiness probes ne soient lancées. La valeur par défaut est de 0 seconde. La valeur minimale est 0.</li><li><code>periodSeconds</code>: La fréquence (en secondes) à laquelle la probe doit être effectuée. La valeur par défaut est de 10 secondes. La valeur minimale est de 1.</li><li><code>timeoutSeconds</code>: Nombre de secondes après lequel la probe time out. Valeur par défaut à 1 seconde. La valeur minimale est de 1.</li><li><code>successThreshold</code>: Le minimum de succès consécutifs pour que la probe soit considérée comme réussie après avoir échoué. La valeur par défaut est 1. Doit être 1 pour la liveness probe. La valeur minimale est de 1.</li><li><code>failureThreshold</code>: Quand un Pod démarre et que la probe échoue, Kubernetes va tenter <code>failureThreshold</code> fois avant d'abandonner. Abandonner en cas de liveness probe signifie le redémarrage du conteneur. En cas de readiness probe, le Pod sera marqué Unready.
La valeur par défaut est 3, la valeur minimum est 1.</li></ul><p><a href=/docs/reference/generated/kubernetes-api/v1.25/#httpgetaction-v1-core>HTTP probes</a>
ont des champs supplémentaires qui peuvent être définis sur <code>httpGet</code> :</p><ul><li><code>host</code>: Nom de l'hôte auquel se connecter, par défaut l'IP du pod. Vous voulez peut être mettre "Host" en httpHeaders à la place.</li><li><code>scheme</code>: Schéma à utiliser pour se connecter à l'hôte (HTTP ou HTTPS). La valeur par défaut est HTTP.</li><li><code>path</code>: Chemin d'accès sur le serveur HTTP.</li><li><code>httpHeaders</code>: En-têtes personnalisés à définir dans la requête. HTTP permet des en-têtes répétés.</li><li><code>port</code>: Nom ou numéro du port à accéder sur le conteneur. Le numéro doit être dans un intervalle de 1 à 65535.</li></ul><p>Pour une probe HTTP, le Kubelet envoie une requête HTTP au chemin et au port spécifiés pour effectuer la vérification. Le Kubelet envoie la probe à l'adresse IP du Pod, à moins que l'adresse ne soit surchargée par le champ optionnel <code>host</code> dans <code>httpGet</code>. Si Le champ <code>scheme</code> est mis à <code>HTTPS</code>, le Kubelet envoie une requête HTTPS en ignorant la vérification du certificat. Dans la plupart des scénarios, vous ne voulez pas définir le champ <code>host</code>.
Voici un scénario où vous le mettriez en place. Supposons que le conteneur écoute sur 127.0.0.1 et que le champ <code>hostNetwork</code> du Pod a la valeur true. Alors <code>host</code>, sous <code>httpGet</code>, devrait être défini à 127.0.0.1. Si votre Pod repose sur des hôtes virtuels, ce qui est probablement plus courant, vous ne devriez pas utiliser <code>host</code>, mais plutôt mettre l'en-tête <code>Host</code> dans <code>httpHeaders</code>.</p><p>Le Kubelet fait la connexion de la probe au noeud, pas dans le Pod, ce qui signifie que vous ne pouvez pas utiliser un nom de service dans le paramètre <code>host</code> puisque le Kubelet est incapable pour le résoudre.</p><h2 id=a-suivre>A suivre</h2><ul><li>Pour en savoir plus sur
<a href=/docs/concepts/workloads/pods/pod-lifecycle/#container-probes>Probes des Conteneurs</a>.</li></ul><h3 id=référence>Référence</h3><ul><li><a href=/docs/reference/generated/kubernetes-api/v1.25/#pod-v1-core>Pod</a></li><li><a href=/docs/reference/generated/kubernetes-api/v1.25/#container-v1-core>Container</a></li><li><a href=/docs/reference/generated/kubernetes-api/v1.25/#probe-v1-core>Probe</a></li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-bbc17480da6d051c696489654c64064a>5.3.9 - Assigner des pods aux nœuds</h1><p>Cette page montre comment assigner un Pod à un nœud particulier dans un cluster Kubernetes.</p><h2 id=pré-requis>Pré-requis</h2><p><p>Vous devez disposer d'un cluster Kubernetes et l'outil de ligne de commande kubectl doit être configuré pour communiquer avec votre cluster.
Si vous ne possédez pas déjà de cluster, vous pouvez en créer un en utilisant <a href=/docs/setup/minikube>Minikube</a>, ou vous pouvez utiliser l'un de ces environnements Kubernetes:</p><ul><li><a href=https://killercoda.com/playgrounds/scenario/kubernetes>Killercoda</a></li><li><a href=http://labs.play-with-k8s.com/>Play with Kubernetes</a></li></ul>Pour consulter la version, entrez <code>kubectl version</code>.</p><h2 id=ajouter-un-label-à-un-nœud>Ajouter un label à un nœud</h2><ol><li><p>Listez les nœuds de votre cluster :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get nodes
</span></span></code></pre></div><p>La sortie est la suivante :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>NAME      STATUS    ROLES     AGE     VERSION
</span></span><span style=display:flex><span>worker0   Ready     &lt;none&gt;    1d      v1.13.0
</span></span><span style=display:flex><span>worker1   Ready     &lt;none&gt;    1d      v1.13.0
</span></span><span style=display:flex><span>worker2   Ready     &lt;none&gt;    1d      v1.13.0
</span></span></code></pre></div></li><li><p>Choisissez l'un de vos nœuds et ajoutez-y un label :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl label nodes &lt;your-node-name&gt; <span style=color:#b8860b>disktype</span><span style=color:#666>=</span>ssd
</span></span></code></pre></div><p>où <code>&lt;your-node-name></code> est le nom du noeud que vous avez choisi.</p></li><li><p>Vérifiez que le nœud que vous avez choisi a le label <code>disktype=ssd</code> :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get nodes --show-labels
</span></span></code></pre></div><p>La sortie est la suivante :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>NAME      STATUS    ROLES    AGE     VERSION        LABELS
</span></span><span style=display:flex><span>worker0   Ready     &lt;none&gt;   1d      v1.13.0        ...,disktype<span style=color:#666>=</span>ssd,kubernetes.io/hostname<span style=color:#666>=</span>worker0
</span></span><span style=display:flex><span>worker1   Ready     &lt;none&gt;   1d      v1.13.0        ...,kubernetes.io/hostname<span style=color:#666>=</span>worker1
</span></span><span style=display:flex><span>worker2   Ready     &lt;none&gt;   1d      v1.13.0        ...,kubernetes.io/hostname<span style=color:#666>=</span>worker2
</span></span></code></pre></div><p>Dans la sortie précédente, vous constatez que le nœud <code>worker0</code> possède le label <code>disktype=ssd</code>.</p></li></ol><h2 id=créez-un-pod-qui-sera-planifié-sur-un-nœud-sélectionné>Créez un pod qui sera planifié sur un nœud sélectionné.</h2><p>Le fichier de configuration de pod décrit un pod qui possède un selector de nœud de type <code>disktype:ssd</code>. Cela signifie que le pod sera planifié sur un nœud ayant le label <code>disktype=ssd</code>.</p><div class=highlight><div class=copy-code-icon style=text-align:right><a href=https://raw.githubusercontent.com/kubernetes/website/main/content/fr/examples/pods/pod-nginx.yaml download=pods/pod-nginx.yaml><code>pods/pod-nginx.yaml</code></a>
<img src=/images/copycode.svg style=max-height:24px;cursor:pointer onclick='copyCode("pods-pod-nginx-yaml")' title="Copy pods/pod-nginx.yaml to clipboard"></img></div><div class=includecode id=pods-pod-nginx-yaml><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>nginx<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>labels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>env</span>:<span style=color:#bbb> </span>test<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>nginx<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>nginx<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>imagePullPolicy</span>:<span style=color:#bbb> </span>IfNotPresent<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>nodeSelector</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>disktype</span>:<span style=color:#bbb> </span>ssd<span style=color:#bbb>
</span></span></span></code></pre></div></div></div><ol><li><p>Utilisez le fichier de configuration pour créer un pod qui sera ordonnancé sur votre nœud choisi :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl apply -f https://k8s.io/examples/pods/pod-nginx.yaml
</span></span></code></pre></div></li><li><p>Vérifiez que le pod fonctionne sur le nœud que vous avez choisi :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get pods --output<span style=color:#666>=</span>wide
</span></span></code></pre></div><p>La sortie est la suivante :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>NAME     READY     STATUS    RESTARTS   AGE    IP           NODE
</span></span><span style=display:flex><span>nginx    1/1       Running   <span style=color:#666>0</span>          13s    10.200.0.4   worker0
</span></span></code></pre></div></li></ol><h2 id=créez-un-pod-qui-va-être-planifié-sur-un-nœud-spécifique>Créez un pod qui va être planifié sur un nœud spécifique</h2><p>Vous pouvez également ordonnancer un pod sur un nœud spécifique via le paramètre <code>nodeName</code>.</p><div class=highlight><div class=copy-code-icon style=text-align:right><a href=https://raw.githubusercontent.com/kubernetes/website/main/content/fr/examples/pods/pod-nginx-specific-node.yaml download=pods/pod-nginx-specific-node.yaml><code>pods/pod-nginx-specific-node.yaml</code></a>
<img src=/images/copycode.svg style=max-height:24px;cursor:pointer onclick='copyCode("pods-pod-nginx-specific-node-yaml")' title="Copy pods/pod-nginx-specific-node.yaml to clipboard"></img></div><div class=includecode id=pods-pod-nginx-specific-node-yaml><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>nginx<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>nodeName</span>:<span style=color:#bbb> </span>foo-node<span style=color:#bbb> </span><span style=color:#080;font-style:italic># schedule pod to specific node</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>nginx<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>nginx<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>imagePullPolicy</span>:<span style=color:#bbb> </span>IfNotPresent<span style=color:#bbb>
</span></span></span></code></pre></div></div></div><p>Utilisez le fichier de configuration pour créer un pod qui sera ordonnancé sur <code>foo-node</code> uniquement.</p><h2 id=a-suivre>A suivre</h2><p>Pour en savoir plus sur
<a href=/docs/concepts/overview/working-with-objects/labels/>labels et selectors</a>.</p></div><div class=td-content style=page-break-before:always><h1 id=pg-1e7baac1825631a5af5d2aebcf059249>5.3.10 - Configurer l'initialisation du pod</h1><p>Cette page montre comment utiliser un Init conteneur pour initialiser un Pod avant de lancer un conteneur d'application.</p><h2 id=pré-requis>Pré-requis</h2><p><p>Vous devez disposer d'un cluster Kubernetes et l'outil de ligne de commande kubectl doit être configuré pour communiquer avec votre cluster.
Si vous ne possédez pas déjà de cluster, vous pouvez en créer un en utilisant <a href=/docs/setup/minikube>Minikube</a>, ou vous pouvez utiliser l'un de ces environnements Kubernetes:</p><ul><li><a href=https://killercoda.com/playgrounds/scenario/kubernetes>Killercoda</a></li><li><a href=http://labs.play-with-k8s.com/>Play with Kubernetes</a></li></ul>Pour consulter la version, entrez <code>kubectl version</code>.</p><h2 id=créer-un-pod-qui-a-un-init-container>Créer un Pod qui a un Init Container</h2><p>Dans cet exercice, vous allez créer un Pod qui a un conteneur d'application et Init conteneur. Le conteneur d'initialisation est achevé avant que le conteneur d'application ne démarre.</p><p>Voici le fichier de configuration du Pod :</p><div class=highlight><div class=copy-code-icon style=text-align:right><a href=https://raw.githubusercontent.com/kubernetes/website/main/content/fr/examples/pods/init-containers.yaml download=pods/init-containers.yaml><code>pods/init-containers.yaml</code></a>
<img src=/images/copycode.svg style=max-height:24px;cursor:pointer onclick='copyCode("pods-init-containers-yaml")' title="Copy pods/init-containers.yaml to clipboard"></img></div><div class=includecode id=pods-init-containers-yaml><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>init-demo<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>nginx<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>nginx<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>ports</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:green;font-weight:700>containerPort</span>:<span style=color:#bbb> </span><span style=color:#666>80</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>volumeMounts</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>workdir<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>mountPath</span>:<span style=color:#bbb> </span>/usr/share/nginx/html<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:#080;font-style:italic># These containers are run during pod initialization</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>initContainers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>install<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>busybox<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>command</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- wget<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:#b44>&#34;-O&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:#b44>&#34;/work-dir/index.html&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- http://kubernetes.io<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>volumeMounts</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>workdir<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>mountPath</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;/work-dir&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>dnsPolicy</span>:<span style=color:#bbb> </span>Default<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>volumes</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>workdir<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>emptyDir</span>:<span style=color:#bbb> </span>{}<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>
</span></span></span></code></pre></div></div></div><p>Dans le fichier de configuration, vous pouvez voir que le Pod a un Volume que le conteneur d'initialisation et le conteneur d'application partagent.</p><p>Le conteneur d'initialisation monte le volume partagé à <code>/work-dir</code>, et le conteneur d'application monte le volume partagé à <code>/usr/share/nginx/html</code>. Le conteneur d'initialisation exécute la commande suivante puis se termine :</p><pre><code>wget -O /work-dir/index.html http://kubernetes.io
</code></pre><p>Remarquez que le conteneur d'initialisation écrit le fichier <code>index.html</code> dans le répertoire racine
du serveur nginx.</p><p>Créez le Pod :</p><pre><code>kubectl apply -f https://k8s.io/examples/pods/init-containers.yaml
</code></pre><p>Vérifiez que le conteneur nginx fonctionne :</p><pre><code>kubectl get pod init-demo
</code></pre><p>La sortie montre que le conteneur nginx est en cours d'exécution :</p><pre><code>NAME        READY     STATUS    RESTARTS   AGE
init-demo   1/1       Running   0          1m
</code></pre><p>Entrez dans la console shell du conteneur nginx du Pod init-demo :</p><pre><code>kubectl exec -it init-demo -- /bin/bash
</code></pre><p>Dans votre shell, envoyez une requête GET au serveur nginx :</p><pre><code>root@nginx:~# apt-get update
root@nginx:~# apt-get install curl
root@nginx:~# curl localhost
</code></pre><p>La sortie montre que nginx sert la page web qui a été écrite par le conteneur d'initialisation :</p><pre><code>&lt;!Doctype html&gt;
&lt;html id=&quot;home&quot;&gt;

&lt;head&gt;
...
&quot;url&quot;: &quot;http://kubernetes.io/&quot;}&lt;/script&gt;
&lt;/head&gt;
&lt;body&gt;
  ...
  &lt;p&gt;Kubernetes is open source giving you the freedom to take advantage ...&lt;/p&gt;
  ...
</code></pre><h2 id=a-suivre>A suivre</h2><ul><li>Pour en savoir plus sur
<a href=/docs/tasks/access-application-cluster/communicate-containers-same-pod-shared-volume/>communiquer entre conteneurs fonctionnant dans le même Pod</a>.</li><li>Pour en savoir plus sur <a href=/docs/concepts/workloads/pods/init-containers/>Init Conteneurs</a>.</li><li>Pour en savoir plus sur <a href=/docs/concepts/storage/volumes/>Volumes</a>.</li><li>Pour en savoir plus sur <a href=/docs/tasks/debug/debug-application/debug-init-containers/>Débogage des Init Conteneurs</a></li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-ed34e761c3dbd00fa79577fa78e30020>5.3.11 - Configurer un pod pour utiliser une ConfigMap</h1><p>Les ConfigMaps vous permettent de découpler les artefacts de configuration du contenu de l'image pour garder les applications conteneurisées portables.
Cette page fournit une série d'exemples d'utilisation montrant comment créer des ConfigMaps et configurer des pods à l'aide des données stockées dans des ConfigMaps.</p><h2 id=pré-requis>Pré-requis</h2><p><p>Vous devez disposer d'un cluster Kubernetes et l'outil de ligne de commande kubectl doit être configuré pour communiquer avec votre cluster.
Si vous ne possédez pas déjà de cluster, vous pouvez en créer un en utilisant <a href=/docs/setup/minikube>Minikube</a>, ou vous pouvez utiliser l'un de ces environnements Kubernetes:</p><ul><li><a href=https://killercoda.com/playgrounds/scenario/kubernetes>Killercoda</a></li><li><a href=http://labs.play-with-k8s.com/>Play with Kubernetes</a></li></ul>Pour consulter la version, entrez <code>kubectl version</code>.</p><h2 id=créer-un-configmap>Créer un ConfigMap</h2><p>Vous pouvez utiliser soit <code>kubectl create configmap</code> ou un générateur ConfigMap dans <code>kustomization.yaml</code> pour créer un ConfigMap.
Notez que <code>kubectl</code> prends en charge <code>kustomization.yaml</code> à partir de la version 1.14.</p><h3 id=créer-un-configmap-à-l-aide-de-kubectl-create-configmap>Créer un ConfigMap à l'aide de kubectl create configmap</h3><p>Utilisez la commande <code>kubectl create configmap</code> pour créer des Configmaps depuis des <a href=#create-configmaps-from-directories>dossiers</a>, <a href=#create-configmaps-from-files>fichiers</a>, ou des <a href=#create-configmaps-from-literal-values>valeurs littérales</a>:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl create configmap &lt;map-name&gt; &lt;data-source&gt;
</span></span></code></pre></div><p>où &lt;map-name> est le nom que vous souhaitez attribuer à ConfigMap et &lt;data-source> est le répertoire, le fichier ou la valeur littérale à partir de laquelle récupérer les données.</p><p>La source de données correspond à une paire clé-valeur dans ConfigMap, où</p><ul><li>clé = le nom du fichier ou la clé que vous avez fournie sur la ligne de commande, et</li><li>valeur = le contenu du fichier ou la valeur littérale que vous avez fournie sur la ligne de commande.</li></ul><p>Vous pouvez utiliser <a href=/docs/reference/generated/kubectl/kubectl-commands/#describe><code>kubectl describe</code></a> ou <a href=/docs/reference/generated/kubectl/kubectl-commands/#get><code>kubectl get</code></a> pour récupérer des informations sur un ConfigMap.</p><h4 id=créer-des-configmaps-à-partir-de-répertoires>Créer des ConfigMaps à partir de répertoires</h4><p>Vous pouvez utiliser <code>kubectl create configmap</code> pour créer un ConfigMap à partir de plusieurs fichiers dans le même répertoire.</p><p>Par exemple:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span><span style=color:#080;font-style:italic># Créez le répertoire local</span>
</span></span><span style=display:flex><span>mkdir -p configure-pod-container/configmap/
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#080;font-style:italic># Téléchargez les exemples de fichiers dans le répertoire `configure-pod-container/configmap/`</span>
</span></span><span style=display:flex><span>wget https://kubernetes.io/examples/configmap/game.properties -O configure-pod-container/configmap/game.properties
</span></span><span style=display:flex><span>wget https://kubernetes.io/examples/configmap/ui.properties -O configure-pod-container/configmap/ui.properties
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#080;font-style:italic># Créer la configmap</span>
</span></span><span style=display:flex><span>kubectl create configmap game-config --from-file<span style=color:#666>=</span>configure-pod-container/configmap/
</span></span></code></pre></div><p>combine le contenu du répertoire <code>configure-pod-container/configmap/</code></p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>game.properties
</span></span><span style=display:flex><span>ui.properties
</span></span></code></pre></div><p>dans le ConfigMap suivant:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl describe configmaps game-config
</span></span></code></pre></div><p>où la sortie est similaire à ceci:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-text data-lang=text><span style=display:flex><span>Name:           game-config
</span></span><span style=display:flex><span>Namespace:      default
</span></span><span style=display:flex><span>Labels:         &lt;none&gt;
</span></span><span style=display:flex><span>Annotations:    &lt;none&gt;
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>Data
</span></span><span style=display:flex><span>====
</span></span><span style=display:flex><span>game.properties:        158 bytes
</span></span><span style=display:flex><span>ui.properties:          83 bytes
</span></span></code></pre></div><p>Les fichiers <code>game.properties</code> et <code>ui.properties</code> dans le répertoire <code>configure-pod-container/configmap/</code> sont représentés dans la section <code>data</code> de la ConfigMap.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get configmaps game-config -o yaml
</span></span></code></pre></div><p>La sortie est similaire à ceci:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>ConfigMap<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>creationTimestamp</span>:<span style=color:#bbb> </span>2016-02-18T18:52:05Z<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>game-config<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>namespace</span>:<span style=color:#bbb> </span>default<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>resourceVersion</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;516&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>uid</span>:<span style=color:#bbb> </span>b4952dc3-d670-11e5-8cd0-68f728db1985<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>data</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>game.properties</span>:<span style=color:#bbb> </span>|<span style=color:#b44;font-style:italic>
</span></span></span><span style=display:flex><span><span style=color:#b44;font-style:italic>    enemies=aliens
</span></span></span><span style=display:flex><span><span style=color:#b44;font-style:italic>    lives=3
</span></span></span><span style=display:flex><span><span style=color:#b44;font-style:italic>    enemies.cheat=true
</span></span></span><span style=display:flex><span><span style=color:#b44;font-style:italic>    enemies.cheat.level=noGoodRotten
</span></span></span><span style=display:flex><span><span style=color:#b44;font-style:italic>    secret.code.passphrase=UUDDLRLRBABAS
</span></span></span><span style=display:flex><span><span style=color:#b44;font-style:italic>    secret.code.allowed=true
</span></span></span><span style=display:flex><span><span style=color:#b44;font-style:italic>    secret.code.lives=30</span><span style=color:#bbb>    
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>ui.properties</span>:<span style=color:#bbb> </span>|<span style=color:#b44;font-style:italic>
</span></span></span><span style=display:flex><span><span style=color:#b44;font-style:italic>    color.good=purple
</span></span></span><span style=display:flex><span><span style=color:#b44;font-style:italic>    color.bad=yellow
</span></span></span><span style=display:flex><span><span style=color:#b44;font-style:italic>    allow.textmode=true
</span></span></span><span style=display:flex><span><span style=color:#b44;font-style:italic>    how.nice.to.look=fairlyNice</span><span style=color:#bbb>    
</span></span></span></code></pre></div><h4 id=créer-des-configmaps-à-partir-de-fichiers>Créer des ConfigMaps à partir de fichiers</h4><p>Vous pouvez utiliser <code>kubectl create configmap</code> pour créer un ConfigMap à partir d'un fichier individuel ou de plusieurs fichiers.</p><p>Par exemple,</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl create configmap game-config-2 --from-file<span style=color:#666>=</span>configure-pod-container/configmap/game.properties
</span></span></code></pre></div><p>produirait le ConfigMap suivant:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl describe configmaps game-config-2
</span></span></code></pre></div><p>où la sortie est similaire à ceci:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-text data-lang=text><span style=display:flex><span>Name:           game-config-2
</span></span><span style=display:flex><span>Namespace:      default
</span></span><span style=display:flex><span>Labels:         &lt;none&gt;
</span></span><span style=display:flex><span>Annotations:    &lt;none&gt;
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>Data
</span></span><span style=display:flex><span>====
</span></span><span style=display:flex><span>game.properties:        158 bytes
</span></span></code></pre></div><p>Vous pouvez passer l'argument <code>--from-file</code> plusieurs fois pour créer un ConfigMap à partir de plusieurs sources de données.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl create configmap game-config-2 --from-file<span style=color:#666>=</span>configure-pod-container/configmap/game.properties --from-file<span style=color:#666>=</span>configure-pod-container/configmap/ui.properties
</span></span></code></pre></div><p>Décrivez la ConfigMap crée <code>game-config-2</code>:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl describe configmaps game-config-2
</span></span></code></pre></div><p>La sortie est similaire à ceci:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-text data-lang=text><span style=display:flex><span>Name:           game-config-2
</span></span><span style=display:flex><span>Namespace:      default
</span></span><span style=display:flex><span>Labels:         &lt;none&gt;
</span></span><span style=display:flex><span>Annotations:    &lt;none&gt;
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>Data
</span></span><span style=display:flex><span>====
</span></span><span style=display:flex><span>game.properties:        158 bytes
</span></span><span style=display:flex><span>ui.properties:          83 bytes
</span></span></code></pre></div><p>Utilisez l'option <code>--from-env-file</code> pour créer un ConfigMap à partir d'un fichier env, par exemple:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span><span style=color:#080;font-style:italic># Les fichiers env contiennent une liste de variables d&#39;environnement.</span>
</span></span><span style=display:flex><span><span style=color:#080;font-style:italic># Ces règles de syntaxe s&#39;appliquent:</span>
</span></span><span style=display:flex><span><span style=color:#080;font-style:italic>#   Chaque ligne d&#39;un fichier env doit être au format VAR=VAL.</span>
</span></span><span style=display:flex><span><span style=color:#080;font-style:italic>#   Les lignes commençant par # (c&#39;est-à-dire les commentaires) sont ignorées.</span>
</span></span><span style=display:flex><span><span style=color:#080;font-style:italic>#   Les lignes vides sont ignorées.</span>
</span></span><span style=display:flex><span><span style=color:#080;font-style:italic>#   Il n&#39;y a pas de traitement spécial des guillemets (c&#39;est-à-dire qu&#39;ils feront partie de la valeur ConfigMap)).</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#080;font-style:italic># Téléchargez les exemples de fichiers dans le dossier `configure-pod-container/configmap/`</span>
</span></span><span style=display:flex><span>wget https://kubernetes.io/examples/configmap/game-env-file.properties -O configure-pod-container/configmap/game-env-file.properties
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#080;font-style:italic># Le fichier env `game-env-file.properties` ressemble à ceci</span>
</span></span><span style=display:flex><span>cat configure-pod-container/configmap/game-env-file.properties
</span></span><span style=display:flex><span><span style=color:#b8860b>enemies</span><span style=color:#666>=</span>aliens
</span></span><span style=display:flex><span><span style=color:#b8860b>lives</span><span style=color:#666>=</span><span style=color:#666>3</span>
</span></span><span style=display:flex><span><span style=color:#b8860b>allowed</span><span style=color:#666>=</span><span style=color:#b44>&#34;true&#34;</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#080;font-style:italic># Ce commentaire et la ligne vide au-dessus sont ignorés</span>
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl create configmap game-config-env-file <span style=color:#b62;font-weight:700>\
</span></span></span><span style=display:flex><span><span style=color:#b62;font-weight:700></span>       --from-env-file<span style=color:#666>=</span>configure-pod-container/configmap/game-env-file.properties
</span></span></code></pre></div><p>produirait le ConfigMap suivant:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get configmap game-config-env-file -o yaml
</span></span></code></pre></div><p>où la sortie est similaire à ceci:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>ConfigMap<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>creationTimestamp</span>:<span style=color:#bbb> </span>2017-12-27T18:36:28Z<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>game-config-env-file<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>namespace</span>:<span style=color:#bbb> </span>default<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>resourceVersion</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;809965&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>uid</span>:<span style=color:#bbb> </span>d9d1ca5b-eb34-11e7-887b-42010a8002b8<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>data</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>allowed</span>:<span style=color:#bbb> </span><span style=color:#b44>&#39;&#34;true&#34;&#39;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>enemies</span>:<span style=color:#bbb> </span>aliens<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>lives</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;3&#34;</span><span style=color:#bbb>
</span></span></span></code></pre></div><div class="alert alert-warning caution callout" role=alert><strong>Avertissement:</strong> Lorsque vous passez plusieurs fois <code>--from-env-file</code> pour créer un ConfigMap à partir de plusieurs sources de données, seul le dernier fichier env est utilisé.</div><p>Le comportement consistant à passer plusieurs fois <code>--from-env-file</code> est démontré par:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span><span style=color:#080;font-style:italic># Téléchargez les exemples de fichiers dans le répertoire `configure-pod-container/configmap/`</span>
</span></span><span style=display:flex><span>wget https://k8s.io/examples/configmap/ui-env-file.properties -O configure-pod-container/configmap/ui-env-file.properties
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#080;font-style:italic># Créez le configmap</span>
</span></span><span style=display:flex><span>kubectl create configmap config-multi-env-files <span style=color:#b62;font-weight:700>\
</span></span></span><span style=display:flex><span><span style=color:#b62;font-weight:700></span>        --from-env-file<span style=color:#666>=</span>configure-pod-container/configmap/game-env-file.properties <span style=color:#b62;font-weight:700>\
</span></span></span><span style=display:flex><span><span style=color:#b62;font-weight:700></span>        --from-env-file<span style=color:#666>=</span>configure-pod-container/configmap/ui-env-file.properties
</span></span></code></pre></div><p>produirait le ConfigMap suivant:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get configmap config-multi-env-files -o yaml
</span></span></code></pre></div><p>où la sortie est similaire à ceci:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>ConfigMap<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>creationTimestamp</span>:<span style=color:#bbb> </span>2017-12-27T18:38:34Z<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>config-multi-env-files<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>namespace</span>:<span style=color:#bbb> </span>default<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>resourceVersion</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;810136&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>uid</span>:<span style=color:#bbb> </span>252c4572-eb35-11e7-887b-42010a8002b8<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>data</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>color</span>:<span style=color:#bbb> </span>purple<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>how</span>:<span style=color:#bbb> </span>fairlyNice<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>textmode</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;true&#34;</span><span style=color:#bbb>
</span></span></span></code></pre></div><h4 id=définissez-la-clé-à-utiliser-lors-de-la-création-d-un-configmap-à-partir-d-un-fichier>Définissez la clé à utiliser lors de la création d'un ConfigMap à partir d'un fichier</h4><p>Vous pouvez définir une clé autre que le nom de fichier à utiliser dans la section <code>data</code> de votre ConfigMap lorsque vous utilisez l'argument <code>--from-file</code>:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl create configmap game-config-3 --from-file<span style=color:#666>=</span>&lt;my-key-name&gt;<span style=color:#666>=</span>&lt;path-to-file&gt;
</span></span></code></pre></div><p>où <code>&lt;my-key-name></code> est la clé que vous souhaitez utiliser dans la ConfigMap et <code>&lt;path-to-file></code> est l'emplacement du fichier de source de données que vous souhaitez que la clé représente.</p><p>Par exemple:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl create configmap game-config-3 --from-file<span style=color:#666>=</span>game-special-key<span style=color:#666>=</span>configure-pod-container/configmap/game.properties
</span></span></code></pre></div><p>produirait la ConfigMap suivante:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get configmaps game-config-3 -o yaml
</span></span></code></pre></div><p>où la sortie est similaire à ceci:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>ConfigMap<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>creationTimestamp</span>:<span style=color:#bbb> </span>2016-02-18T18:54:22Z<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>game-config-3<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>namespace</span>:<span style=color:#bbb> </span>default<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>resourceVersion</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;530&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>uid</span>:<span style=color:#bbb> </span>05f8da22-d671-11e5-8cd0-68f728db1985<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>data</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>game-special-key</span>:<span style=color:#bbb> </span>|<span style=color:#b44;font-style:italic>
</span></span></span><span style=display:flex><span><span style=color:#b44;font-style:italic>    enemies=aliens
</span></span></span><span style=display:flex><span><span style=color:#b44;font-style:italic>    lives=3
</span></span></span><span style=display:flex><span><span style=color:#b44;font-style:italic>    enemies.cheat=true
</span></span></span><span style=display:flex><span><span style=color:#b44;font-style:italic>    enemies.cheat.level=noGoodRotten
</span></span></span><span style=display:flex><span><span style=color:#b44;font-style:italic>    secret.code.passphrase=UUDDLRLRBABAS
</span></span></span><span style=display:flex><span><span style=color:#b44;font-style:italic>    secret.code.allowed=true
</span></span></span><span style=display:flex><span><span style=color:#b44;font-style:italic>    secret.code.lives=30</span><span style=color:#bbb>    
</span></span></span></code></pre></div><h4 id=créer-des-configmaps-à-partir-de-valeurs-littérales>Créer des ConfigMaps à partir de valeurs littérales</h4><p>Vous pouvez utiliser <code>kubectl create configmap</code> avec l'argument <code>--from-literal</code> définir une valeur littérale à partir de la ligne de commande:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl create configmap special-config --from-literal<span style=color:#666>=</span>special.how<span style=color:#666>=</span>very --from-literal<span style=color:#666>=</span>special.type<span style=color:#666>=</span>charm
</span></span></code></pre></div><p>Vous pouvez transmettre plusieurs paires clé-valeur.
Chaque paire fournie sur la ligne de commande est représentée comme une entrée distincte dans la section <code>data</code> de la ConfigMap.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get configmaps special-config -o yaml
</span></span></code></pre></div><p>La sortie est similaire à ceci:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>ConfigMap<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>creationTimestamp</span>:<span style=color:#bbb> </span>2016-02-18T19:14:38Z<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>special-config<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>namespace</span>:<span style=color:#bbb> </span>default<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>resourceVersion</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;651&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>uid</span>:<span style=color:#bbb> </span>dadce046-d673-11e5-8cd0-68f728db1985<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>data</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>special.how</span>:<span style=color:#bbb> </span>very<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>special.type</span>:<span style=color:#bbb> </span>charm<span style=color:#bbb>
</span></span></span></code></pre></div><h3 id=créer-un-configmap-à-partir-du-générateur>Créer un ConfigMap à partir du générateur</h3><p><code>kubectl</code> supporte <code>kustomization.yaml</code> depuis 1.14.
Vous pouvez également créer un ConfigMap à partir de générateurs, puis l'appliquer pour créer l'objet sur l'Apiserver.
Les générateurs doivent être spécifiés dans un <code>kustomization.yaml</code> à l'intérieur d'un répertoire.</p><h4 id=générer-des-configmaps-à-partir-de-fichiers>Générer des ConfigMaps à partir de fichiers</h4><p>Par exemple, pour générer un ConfigMap à partir de fichiers <code>configure-pod-container/configmap/game.properties</code></p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span><span style=color:#080;font-style:italic># Create a kustomization.yaml file with ConfigMapGenerator</span>
</span></span><span style=display:flex><span>cat <span style=color:#b44>&lt;&lt;EOF &gt;./kustomization.yaml
</span></span></span><span style=display:flex><span><span style=color:#b44>configMapGenerator:
</span></span></span><span style=display:flex><span><span style=color:#b44>- name: game-config-4
</span></span></span><span style=display:flex><span><span style=color:#b44>  files:
</span></span></span><span style=display:flex><span><span style=color:#b44>  - configure-pod-container/configmap/game.properties
</span></span></span><span style=display:flex><span><span style=color:#b44>EOF</span>
</span></span></code></pre></div><p>Appliquer le dossier kustomization pour créer l'objet ConfigMap.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl apply -k .
</span></span><span style=display:flex><span>configmap/game-config-4-m9dm2f92bt created
</span></span></code></pre></div><p>Vous pouvez vérifier que le ConfigMap a été créé comme ceci:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-text data-lang=text><span style=display:flex><span>kubectl get configmap
</span></span><span style=display:flex><span>NAME                       DATA   AGE
</span></span><span style=display:flex><span>game-config-4-m9dm2f92bt   1      37s
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>kubectl describe configmaps/game-config-4-m9dm2f92bt
</span></span><span style=display:flex><span>Name:         game-config-4-m9dm2f92bt
</span></span><span style=display:flex><span>Namespace:    default
</span></span><span style=display:flex><span>Labels:       &lt;none&gt;
</span></span><span style=display:flex><span>Annotations:  kubectl.kubernetes.io/last-applied-configuration:
</span></span><span style=display:flex><span>                {&#34;apiVersion&#34;:&#34;v1&#34;,&#34;data&#34;:{&#34;game.properties&#34;:&#34;enemies=aliens\nlives=3\nenemies.cheat=true\nenemies.cheat.level=noGoodRotten\nsecret.code.p...
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>Data
</span></span><span style=display:flex><span>====
</span></span><span style=display:flex><span>game.properties:
</span></span><span style=display:flex><span>----
</span></span><span style=display:flex><span>enemies=aliens
</span></span><span style=display:flex><span>lives=3
</span></span><span style=display:flex><span>enemies.cheat=true
</span></span><span style=display:flex><span>enemies.cheat.level=noGoodRotten
</span></span><span style=display:flex><span>secret.code.passphrase=UUDDLRLRBABAS
</span></span><span style=display:flex><span>secret.code.allowed=true
</span></span><span style=display:flex><span>secret.code.lives=30
</span></span><span style=display:flex><span>Events:  &lt;none&gt;
</span></span></code></pre></div><p>Notez que le nom ConfigMap généré a un suffixe obtenu par hachage de son contenu.
Cela garantit qu'un nouveau ConfigMap est généré chaque fois que le contenu est modifié.</p><h4 id=définissez-la-clé-à-utiliser-lors-de-la-génération-d-un-configmap-à-partir-d-un-fichier>Définissez la clé à utiliser lors de la génération d'un ConfigMap à partir d'un fichier</h4><p>Vous pouvez définir une clé autre que le nom de fichier à utiliser dans le générateur ConfigMap.
Par exemple, pour générer un ConfigMap à partir du fichier <code>configure-pod-container/configmap/game.properties</code>
avec la clé <code>game-special-key</code></p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span><span style=color:#080;font-style:italic># Créer un fichier kustomization.yaml avec ConfigMapGenerator</span>
</span></span><span style=display:flex><span>cat <span style=color:#b44>&lt;&lt;EOF &gt;./kustomization.yaml
</span></span></span><span style=display:flex><span><span style=color:#b44>configMapGenerator:
</span></span></span><span style=display:flex><span><span style=color:#b44>- name: game-config-5
</span></span></span><span style=display:flex><span><span style=color:#b44>  files:
</span></span></span><span style=display:flex><span><span style=color:#b44>  - game-special-key=configure-pod-container/configmap/game.properties
</span></span></span><span style=display:flex><span><span style=color:#b44>EOF</span>
</span></span></code></pre></div><p>Appliquer le dossier kustomization pour créer l'objet ConfigMap.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-text data-lang=text><span style=display:flex><span>kubectl apply -k .
</span></span><span style=display:flex><span>configmap/game-config-5-m67dt67794 created
</span></span></code></pre></div><h4 id=générer-des-configmaps-à-partir-de-littéraux>Générer des ConfigMaps à partir de littéraux</h4><p>Pour générer un ConfigMap à partir de littéraux <code>special.type=charm</code> et <code>special.how=very</code>, vous pouvez spécifier le générateur ConfigMap dans <code>kustomization.yaml</code> comme</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span><span style=color:#080;font-style:italic># Create a kustomization.yaml file with ConfigMapGenerator</span>
</span></span><span style=display:flex><span>cat <span style=color:#b44>&lt;&lt;EOF &gt;./kustomization.yaml
</span></span></span><span style=display:flex><span><span style=color:#b44>configMapGenerator:
</span></span></span><span style=display:flex><span><span style=color:#b44>- name: special-config-2
</span></span></span><span style=display:flex><span><span style=color:#b44>  literals:
</span></span></span><span style=display:flex><span><span style=color:#b44>  - special.how=very
</span></span></span><span style=display:flex><span><span style=color:#b44>  - special.type=charm
</span></span></span><span style=display:flex><span><span style=color:#b44>EOF</span>
</span></span></code></pre></div><p>Appliquez le dossier kustomization pour créer l'objet ConfigMap.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-text data-lang=text><span style=display:flex><span>kubectl apply -k .
</span></span><span style=display:flex><span>configmap/special-config-2-c92b5mmcf2 created
</span></span></code></pre></div><h2 id=définir-des-variables-d-environnement-de-conteneur-à-l-aide-des-données-configmap>Définir des variables d'environnement de conteneur à l'aide des données ConfigMap</h2><h3 id=définissez-une-variable-d-environnement-de-conteneur-avec-les-données-d-une-seule-configmap>Définissez une variable d'environnement de conteneur avec les données d'une seule ConfigMap</h3><ol><li><p>Définissez une variable d'environnement comme paire clé-valeur dans un ConfigMap:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl create configmap special-config --from-literal<span style=color:#666>=</span>special.how<span style=color:#666>=</span>very
</span></span></code></pre></div></li><li><p>Attribuez la valeur <code>special.how</code> défini dans ConfigMap à la variable d'environnement <code>SPECIAL_LEVEL_KEY</code> dans la spécification du Pod.</p><div class=highlight><div class=copy-code-icon style=text-align:right><a href=https://raw.githubusercontent.com/kubernetes/website/main/content/fr/examples/pods/pod-single-configmap-env-variable.yaml download=pods/pod-single-configmap-env-variable.yaml><code>pods/pod-single-configmap-env-variable.yaml</code></a>
<img src=/images/copycode.svg style=max-height:24px;cursor:pointer onclick='copyCode("pods-pod-single-configmap-env-variable-yaml")' title="Copy pods/pod-single-configmap-env-variable.yaml to clipboard"></img></div><div class=includecode id=pods-pod-single-configmap-env-variable-yaml><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
   </span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Pod<span style=color:#bbb>
   </span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
   </span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>dapi-test-pod<span style=color:#bbb>
   </span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
   </span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
   </span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>test-container<span style=color:#bbb>
   </span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>k8s.gcr.io/busybox<span style=color:#bbb>
   </span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>command</span>:<span style=color:#bbb> </span>[<span style=color:#bbb> </span><span style=color:#b44>&#34;/bin/sh&#34;</span>,<span style=color:#bbb> </span><span style=color:#b44>&#34;-c&#34;</span>,<span style=color:#bbb> </span><span style=color:#b44>&#34;env&#34;</span><span style=color:#bbb> </span>]<span style=color:#bbb>
   </span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>env</span>:<span style=color:#bbb>
   </span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:#080;font-style:italic># Définie la variable d&#39;environnement</span><span style=color:#bbb>
   </span></span></span><span style=display:flex><span><span style=color:#bbb>        </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>SPECIAL_LEVEL_KEY<span style=color:#bbb>
   </span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>valueFrom</span>:<span style=color:#bbb>
   </span></span></span><span style=display:flex><span><span style=color:#bbb>            </span><span style=color:green;font-weight:700>configMapKeyRef</span>:<span style=color:#bbb>
   </span></span></span><span style=display:flex><span><span style=color:#bbb>              </span><span style=color:#080;font-style:italic># La ConfigMap contenant la valeur que vous voulez attribuer à SPECIAL_LEVEL_KEY</span><span style=color:#bbb>
   </span></span></span><span style=display:flex><span><span style=color:#bbb>              </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>special-config<span style=color:#bbb>
   </span></span></span><span style=display:flex><span><span style=color:#bbb>              </span><span style=color:#080;font-style:italic># Spécifier la clé associée à la valeur</span><span style=color:#bbb>
   </span></span></span><span style=display:flex><span><span style=color:#bbb>              </span><span style=color:green;font-weight:700>key</span>:<span style=color:#bbb> </span>special.how<span style=color:#bbb>
   </span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>restartPolicy</span>:<span style=color:#bbb> </span>Never<span style=color:#bbb>
   </span></span></span></code></pre></div></div></div><p>Créez le pod:</p></li></ol><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl create -f https://kubernetes.io/examples/pods/pod-single-configmap-env-variable.yaml
</span></span></code></pre></div><p>Maintenant, la sortie du Pod comprend une variable d'environnement <code>SPECIAL_LEVEL_KEY=very</code>.</p><h3 id=définir-des-variables-d-environnement-de-conteneur-avec-des-données-de-plusieurs-configmaps>Définir des variables d'environnement de conteneur avec des données de plusieurs ConfigMaps</h3><ul><li><p>Comme avec l'exemple précédent, créez d'abord les ConfigMaps.</p><div class=highlight><div class=copy-code-icon style=text-align:right><a href=https://raw.githubusercontent.com/kubernetes/website/main/content/fr/examples/configmap/configmaps.yaml download=configmap/configmaps.yaml><code>configmap/configmaps.yaml</code></a>
<img src=/images/copycode.svg style=max-height:24px;cursor:pointer onclick='copyCode("configmap-configmaps-yaml")' title="Copy configmap/configmaps.yaml to clipboard"></img></div><div class=includecode id=configmap-configmaps-yaml><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
   </span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>ConfigMap<span style=color:#bbb>
   </span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
   </span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>special-config<span style=color:#bbb>
   </span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>namespace</span>:<span style=color:#bbb> </span>default<span style=color:#bbb>
   </span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>data</span>:<span style=color:#bbb>
   </span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>special.how</span>:<span style=color:#bbb> </span>very<span style=color:#bbb>
   </span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:#00f;font-weight:700>---</span><span style=color:#bbb>
   </span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
   </span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>ConfigMap<span style=color:#bbb>
   </span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
   </span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>env-config<span style=color:#bbb>
   </span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>namespace</span>:<span style=color:#bbb> </span>default<span style=color:#bbb>
   </span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>data</span>:<span style=color:#bbb>
   </span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>log_level</span>:<span style=color:#bbb> </span>INFO<span style=color:#bbb>
   </span></span></span></code></pre></div></div></div><p>Créez le ConfigMap:</p></li></ul><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl create -f https://kubernetes.io/examples/configmap/configmaps.yaml
</span></span></code></pre></div><ul><li><p>Définissez les variables d'environnement dans la spécification Pod.</p><div class=highlight><div class=copy-code-icon style=text-align:right><a href=https://raw.githubusercontent.com/kubernetes/website/main/content/fr/examples/pods/pod-multiple-configmap-env-variable.yaml download=pods/pod-multiple-configmap-env-variable.yaml><code>pods/pod-multiple-configmap-env-variable.yaml</code></a>
<img src=/images/copycode.svg style=max-height:24px;cursor:pointer onclick='copyCode("pods-pod-multiple-configmap-env-variable-yaml")' title="Copy pods/pod-multiple-configmap-env-variable.yaml to clipboard"></img></div><div class=includecode id=pods-pod-multiple-configmap-env-variable-yaml><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
  </span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Pod<span style=color:#bbb>
  </span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
  </span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>dapi-test-pod<span style=color:#bbb>
  </span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
  </span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
  </span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>test-container<span style=color:#bbb>
  </span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>k8s.gcr.io/busybox<span style=color:#bbb>
  </span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>command</span>:<span style=color:#bbb> </span>[<span style=color:#bbb> </span><span style=color:#b44>&#34;/bin/sh&#34;</span>,<span style=color:#bbb> </span><span style=color:#b44>&#34;-c&#34;</span>,<span style=color:#bbb> </span><span style=color:#b44>&#34;env&#34;</span><span style=color:#bbb> </span>]<span style=color:#bbb>
  </span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>env</span>:<span style=color:#bbb>
  </span></span></span><span style=display:flex><span><span style=color:#bbb>        </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>SPECIAL_LEVEL_KEY<span style=color:#bbb>
  </span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>valueFrom</span>:<span style=color:#bbb>
  </span></span></span><span style=display:flex><span><span style=color:#bbb>            </span><span style=color:green;font-weight:700>configMapKeyRef</span>:<span style=color:#bbb>
  </span></span></span><span style=display:flex><span><span style=color:#bbb>              </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>special-config<span style=color:#bbb>
  </span></span></span><span style=display:flex><span><span style=color:#bbb>              </span><span style=color:green;font-weight:700>key</span>:<span style=color:#bbb> </span>special.how<span style=color:#bbb>
  </span></span></span><span style=display:flex><span><span style=color:#bbb>        </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>LOG_LEVEL<span style=color:#bbb>
  </span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>valueFrom</span>:<span style=color:#bbb>
  </span></span></span><span style=display:flex><span><span style=color:#bbb>            </span><span style=color:green;font-weight:700>configMapKeyRef</span>:<span style=color:#bbb>
  </span></span></span><span style=display:flex><span><span style=color:#bbb>              </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>env-config<span style=color:#bbb>
  </span></span></span><span style=display:flex><span><span style=color:#bbb>              </span><span style=color:green;font-weight:700>key</span>:<span style=color:#bbb> </span>log_level<span style=color:#bbb>
  </span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>restartPolicy</span>:<span style=color:#bbb> </span>Never<span style=color:#bbb>
  </span></span></span></code></pre></div></div></div><p>Créez le pod:</p></li></ul><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl create -f https://kubernetes.io/examples/pods/pod-multiple-configmap-env-variable.yaml
</span></span></code></pre></div><p>Maintenant, la sortie du Pod comprend des variables d'environnement <code>SPECIAL_LEVEL_KEY=very</code> et <code>LOG_LEVEL=INFO</code>.</p><h2 id=configurer-toutes-les-paires-clé-valeur-dans-un-configmap-en-tant-que-variables-d-environnement-de-conteneur>Configurer toutes les paires clé-valeur dans un ConfigMap en tant que variables d'environnement de conteneur</h2><div class="alert alert-info note callout" role=alert><strong>Note:</strong> Cette fonctionnalité est disponible dans Kubernetes v1.6 et versions ultérieures.</div><ul><li><p>Créez un ConfigMap contenant plusieurs paires clé-valeur.</p><div class=highlight><div class=copy-code-icon style=text-align:right><a href=https://raw.githubusercontent.com/kubernetes/website/main/content/fr/examples/configmap/configmap-multikeys.yaml download=configmap/configmap-multikeys.yaml><code>configmap/configmap-multikeys.yaml</code></a>
<img src=/images/copycode.svg style=max-height:24px;cursor:pointer onclick='copyCode("configmap-configmap-multikeys-yaml")' title="Copy configmap/configmap-multikeys.yaml to clipboard"></img></div><div class=includecode id=configmap-configmap-multikeys-yaml><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
  </span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>ConfigMap<span style=color:#bbb>
  </span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
  </span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>special-config<span style=color:#bbb>
  </span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>namespace</span>:<span style=color:#bbb> </span>default<span style=color:#bbb>
  </span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>data</span>:<span style=color:#bbb>
  </span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>SPECIAL_LEVEL</span>:<span style=color:#bbb> </span>very<span style=color:#bbb>
  </span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>SPECIAL_TYPE</span>:<span style=color:#bbb> </span>charm<span style=color:#bbb>
  </span></span></span></code></pre></div></div></div><p>Créez le ConfigMap:</p></li></ul><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl create -f https://kubernetes.io/examples/configmap/configmap-multikeys.yaml
</span></span></code></pre></div><ul><li>Utilisez <code>envFrom</code> pour définir toutes les données du ConfigMap en tant que variables d'environnement du conteneur.
La clé de ConfigMap devient le nom de la variable d'environnement dans le pod.</li></ul><div class=highlight><div class=copy-code-icon style=text-align:right><a href=https://raw.githubusercontent.com/kubernetes/website/main/content/fr/examples/pods/pod-configmap-envFrom.yaml download=pods/pod-configmap-envFrom.yaml><code>pods/pod-configmap-envFrom.yaml</code></a>
<img src=/images/copycode.svg style=max-height:24px;cursor:pointer onclick='copyCode("pods-pod-configmap-envfrom-yaml")' title="Copy pods/pod-configmap-envFrom.yaml to clipboard"></img></div><div class=includecode id=pods-pod-configmap-envfrom-yaml><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
 </span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Pod<span style=color:#bbb>
 </span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
 </span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>dapi-test-pod<span style=color:#bbb>
 </span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
 </span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
 </span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>test-container<span style=color:#bbb>
 </span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>k8s.gcr.io/busybox<span style=color:#bbb>
 </span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>command</span>:<span style=color:#bbb> </span>[<span style=color:#bbb> </span><span style=color:#b44>&#34;/bin/sh&#34;</span>,<span style=color:#bbb> </span><span style=color:#b44>&#34;-c&#34;</span>,<span style=color:#bbb> </span><span style=color:#b44>&#34;env&#34;</span><span style=color:#bbb> </span>]<span style=color:#bbb>
 </span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>envFrom</span>:<span style=color:#bbb>
 </span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- <span style=color:green;font-weight:700>configMapRef</span>:<span style=color:#bbb>
 </span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>special-config<span style=color:#bbb>
 </span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>restartPolicy</span>:<span style=color:#bbb> </span>Never<span style=color:#bbb>
 </span></span></span></code></pre></div></div></div><p>Créez le pod:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl create -f https://kubernetes.io/examples/pods/pod-configmap-envFrom.yaml
</span></span></code></pre></div><p>Maintenant, la sortie du Pod comprend les variables d'environnement <code>SPECIAL_LEVEL=very</code> et <code>SPECIAL_TYPE=charm</code>.</p><h2 id=utiliser-des-variables-d-environnement-définies-par-configmap-dans-les-commandes-du-pod>Utiliser des variables d'environnement définies par ConfigMap dans les commandes du Pod</h2><p>Vous pouvez utiliser des variables d'environnement définies par ConfigMap dans la section <code>command</code> de la spécification du Pod en utilisant la syntaxe de substitution Kubernetes <code>$(VAR_NAME)</code>.</p><p>Par exemple, la spécification de pod suivante</p><div class=highlight><div class=copy-code-icon style=text-align:right><a href=https://raw.githubusercontent.com/kubernetes/website/main/content/fr/examples/pods/pod-configmap-env-var-valueFrom.yaml download=pods/pod-configmap-env-var-valueFrom.yaml><code>pods/pod-configmap-env-var-valueFrom.yaml</code></a>
<img src=/images/copycode.svg style=max-height:24px;cursor:pointer onclick='copyCode("pods-pod-configmap-env-var-valuefrom-yaml")' title="Copy pods/pod-configmap-env-var-valueFrom.yaml to clipboard"></img></div><div class=includecode id=pods-pod-configmap-env-var-valuefrom-yaml><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>dapi-test-pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>test-container<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>k8s.gcr.io/busybox<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>command</span>:<span style=color:#bbb> </span>[<span style=color:#bbb> </span><span style=color:#b44>&#34;/bin/echo&#34;</span>,<span style=color:#bbb> </span><span style=color:#b44>&#34;$(SPECIAL_LEVEL_KEY) $(SPECIAL_TYPE_KEY)&#34;</span><span style=color:#bbb> </span>]<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>env</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>SPECIAL_LEVEL_KEY<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>valueFrom</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>            </span><span style=color:green;font-weight:700>configMapKeyRef</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>              </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>special-config<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>              </span><span style=color:green;font-weight:700>key</span>:<span style=color:#bbb> </span>SPECIAL_LEVEL<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>SPECIAL_TYPE_KEY<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>valueFrom</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>            </span><span style=color:green;font-weight:700>configMapKeyRef</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>              </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>special-config<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>              </span><span style=color:green;font-weight:700>key</span>:<span style=color:#bbb> </span>SPECIAL_TYPE<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>restartPolicy</span>:<span style=color:#bbb> </span>Never<span style=color:#bbb>
</span></span></span></code></pre></div></div></div><p>créé en exécutant</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl create -f https://kubernetes.io/examples/pods/pod-configmap-env-var-valueFrom.yaml
</span></span></code></pre></div><p>produit la sortie suivante dans le conteneur <code>test-container</code>:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>very charm
</span></span></code></pre></div><h2 id=ajouter-des-données-configmap-à-un-volume>Ajouter des données ConfigMap à un volume</h2><p>Comme expliqué dans <a href=#create-configmaps-from-files>Créer des ConfigMaps à partir de fichiers</a>, lorsque vous créez un ConfigMap à l'aide <code>--from-file</code>, le nom de fichier devient une clé stockée dans la section <code>data</code> du ConfigMap.
Le contenu du fichier devient la valeur de la clé.</p><p>Les exemples de cette section se réfèrent à un ConfigMap nommé special-config, illustré ci-dessous.</p><div class=highlight><div class=copy-code-icon style=text-align:right><a href=https://raw.githubusercontent.com/kubernetes/website/main/content/fr/examples/configmap/configmap-multikeys.yaml download=configmap/configmap-multikeys.yaml><code>configmap/configmap-multikeys.yaml</code></a>
<img src=/images/copycode.svg style=max-height:24px;cursor:pointer onclick='copyCode("configmap-configmap-multikeys-yaml")' title="Copy configmap/configmap-multikeys.yaml to clipboard"></img></div><div class=includecode id=configmap-configmap-multikeys-yaml><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>ConfigMap<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>special-config<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>namespace</span>:<span style=color:#bbb> </span>default<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>data</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>SPECIAL_LEVEL</span>:<span style=color:#bbb> </span>very<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>SPECIAL_TYPE</span>:<span style=color:#bbb> </span>charm<span style=color:#bbb>
</span></span></span></code></pre></div></div></div><p>Créez le ConfigMap:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl create -f https://kubernetes.io/examples/configmap/configmap-multikeys.yaml
</span></span></code></pre></div><h3 id=remplissez-un-volume-avec-des-données-stockées-dans-un-configmap>Remplissez un volume avec des données stockées dans un ConfigMap</h3><p>Ajoutez le nom ConfigMap sous la section <code>volumes</code> de la spécification Pod.
Ceci ajoute les données ConfigMap au répertoire spécifié comme <code>volumeMounts.mountPath</code> (dans ce cas, <code>/etc/config</code>).
La section <code>command</code> répertorie les fichiers de répertoire dont les noms correspondent aux clés de ConfigMap.</p><div class=highlight><div class=copy-code-icon style=text-align:right><a href=https://raw.githubusercontent.com/kubernetes/website/main/content/fr/examples/pods/pod-configmap-volume.yaml download=pods/pod-configmap-volume.yaml><code>pods/pod-configmap-volume.yaml</code></a>
<img src=/images/copycode.svg style=max-height:24px;cursor:pointer onclick='copyCode("pods-pod-configmap-volume-yaml")' title="Copy pods/pod-configmap-volume.yaml to clipboard"></img></div><div class=includecode id=pods-pod-configmap-volume-yaml><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>dapi-test-pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>test-container<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>k8s.gcr.io/busybox<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>command</span>:<span style=color:#bbb> </span>[<span style=color:#bbb> </span><span style=color:#b44>&#34;/bin/sh&#34;</span>,<span style=color:#bbb> </span><span style=color:#b44>&#34;-c&#34;</span>,<span style=color:#bbb> </span><span style=color:#b44>&#34;ls /etc/config/&#34;</span><span style=color:#bbb> </span>]<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>volumeMounts</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>config-volume<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>mountPath</span>:<span style=color:#bbb> </span>/etc/config<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>volumes</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>config-volume<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>configMap</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:#080;font-style:italic># Indiquez le nom de la ConfigMap contenant les fichiers que vous souhaitez ajouter au conteneur</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>special-config<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>restartPolicy</span>:<span style=color:#bbb> </span>Never<span style=color:#bbb>
</span></span></span></code></pre></div></div></div><p>Créez le pod:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl create -f https://kubernetes.io/examples/pods/pod-configmap-volume.yaml
</span></span></code></pre></div><p>Lorsque le pod s'exécute, la commande <code>ls /etc/config/</code> produit la sortie ci-dessous:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>SPECIAL_LEVEL
</span></span><span style=display:flex><span>SPECIAL_TYPE
</span></span></code></pre></div><div class="alert alert-warning caution callout" role=alert><strong>Avertissement:</strong> S'il y a des fichiers dans le dossier <code>/etc/config/</code>, ils seront supprimés.</div><h3 id=ajouter-un-configmap-à-un-chemin-spécifique-dans-un-volume>Ajouter un configmap à un chemin spécifique dans un volume</h3><p>Utilisez le champ <code>path</code> pour spécifier le chemin de fichier souhaité pour les éléments de configmap spécifiques.
Dans ce cas, le <code>SPECIAL_LEVEL</code> sera monté dans le volume <code>config-volume</code> au chemin <code>/etc/config/keys</code>.</p><div class=highlight><div class=copy-code-icon style=text-align:right><a href=https://raw.githubusercontent.com/kubernetes/website/main/content/fr/examples/pods/pod-configmap-volume-specific-key.yaml download=pods/pod-configmap-volume-specific-key.yaml><code>pods/pod-configmap-volume-specific-key.yaml</code></a>
<img src=/images/copycode.svg style=max-height:24px;cursor:pointer onclick='copyCode("pods-pod-configmap-volume-specific-key-yaml")' title="Copy pods/pod-configmap-volume-specific-key.yaml to clipboard"></img></div><div class=includecode id=pods-pod-configmap-volume-specific-key-yaml><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>dapi-test-pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>test-container<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>k8s.gcr.io/busybox<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>command</span>:<span style=color:#bbb> </span>[<span style=color:#bbb> </span><span style=color:#b44>&#34;/bin/sh&#34;</span>,<span style=color:#b44>&#34;-c&#34;</span>,<span style=color:#b44>&#34;cat /etc/config/keys&#34;</span><span style=color:#bbb> </span>]<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>volumeMounts</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>config-volume<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>mountPath</span>:<span style=color:#bbb> </span>/etc/config<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>volumes</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>config-volume<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>configMap</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>special-config<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>items</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span>- <span style=color:green;font-weight:700>key</span>:<span style=color:#bbb> </span>SPECIAL_LEVEL<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>path</span>:<span style=color:#bbb> </span>keys<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>restartPolicy</span>:<span style=color:#bbb> </span>Never<span style=color:#bbb>
</span></span></span></code></pre></div></div></div><p>Créez le Pod :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl create -f https://kubernetes.io/examples/pods/pod-configmap-volume-specific-key.yaml
</span></span></code></pre></div><p>Lorsque le pod fonctionne, la commande <code>cat /etc/config/keys</code> produit la sortie ci-dessous :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>very
</span></span></code></pre></div><div class="alert alert-warning caution callout" role=alert><strong>Avertissement:</strong> Comme avant, tous les fichiers précédents dans le répertoire <code>/etc/config/</code> seront supprimés.</div><h3 id=projections-de-clés-pour-des-chemins-et-des-autorisations-de-fichiers-spécifiques>Projections de clés pour des chemins et des autorisations de fichiers spécifiques</h3><p>Vous pouvez projeter des clés vers des chemins spécifiques avec des autorisations spécifiques fichiers par fichiers.
Le guide de l'utilisateur <a href=/docs/concepts/configuration/secret/#using-secrets-as-files-from-a-pod>Secrets</a> explique la syntaxe.</p><h3 id=les-configmaps-montées-sont-mises-à-jour-automatiquement>Les ConfigMaps montées sont mises à jour automatiquement</h3><p>Lorsqu'une ConfigMap déjà consommée dans un volume est mise à jour, les clés projetées sont éventuellement mises à jour elles aussi.
Kubelet vérifie si la ConfigMap montée est fraîche à chaque synchronisation périodique.
Cependant, il utilise son cache local basé sur le ttl pour obtenir la valeur actuelle de la ConfigMap.
Par conséquent, le délai total entre le moment où la ConfigMap est mise à jour et le moment où les nouvelles clés sont projetées vers le pod peut être aussi long que la période de synchronisation de kubelet (1 minute par défaut) + le ttl du cache ConfigMaps (1 minute par défaut) dans kubelet.
Vous pouvez déclencher un rafraîchissement immédiat en mettant à jour l'une des annotations du pod.</p><div class="alert alert-info note callout" role=alert><strong>Note:</strong> Un conteneur utilisant un ConfigMap comme volume <a href=/docs/concepts/storage/volumes/#using-subpath>subPath</a> ne recevra pas les mises à jour de ConfigMap.</div><h2 id=comprendre-le-lien-entre-les-configmaps-et-les-pods>Comprendre le lien entre les ConfigMaps et les Pods</h2><p>La ressource API ConfigMap stocke les données de configuration sous forme de paires clé-valeur.
Les données peuvent être consommées dans des pods ou fournir les configurations des composants du système tels que les contrôleurs.
ConfigMap est similaire à <a href=/docs/concepts/configuration/secret/>Secrets</a>, mais fournit un moyen de travailler avec des chaînes de caractères qui ne contiennent pas d'informations sensibles.
Les utilisateurs comme les composants du système peuvent stocker des données de configuration dans un ConfigMap.</p><div class="alert alert-info note callout" role=alert><strong>Note:</strong> Les ConfigMaps doivent faire référence aux fichiers de propriétés, et non les remplacer.
Pensez à la ConfigMap comme représentant quelque chose de similaire au répertoire <code>/etc</code> de Linux et à son contenu.
Par exemple, si vous créez un <a href=/docs/concepts/storage/volumes/>volume Kubernetes</a> à partir d'une ConfigMap, chaque élément de données de la ConfigMap est représenté par un fichier individuel dans le volume.</div><p>Le champ <code>data</code> de la ConfigMap contient les données de configuration.
Comme le montre l'exemple ci-dessous, cela peut être simple -- comme des propriétés individuelles définies à l'aide de <code>--from-literal</code> -- ou complexe -- comme des fichiers de configuration ou des blobs JSON définis à l'aide de <code>--from-file</code>.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>ConfigMap<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>creationTimestamp</span>:<span style=color:#bbb> </span>2016-02-18T19:14:38Z<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>example-config<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>namespace</span>:<span style=color:#bbb> </span>default<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>data</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:#080;font-style:italic># example of a simple property defined using --from-literal</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>example.property.1</span>:<span style=color:#bbb> </span>hello<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>example.property.2</span>:<span style=color:#bbb> </span>world<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:#080;font-style:italic># example of a complex property defined using --from-file</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>example.property.file</span>:<span style=color:#bbb> </span>|-<span style=color:#b44;font-style:italic>
</span></span></span><span style=display:flex><span><span style=color:#b44;font-style:italic>    property.1=value-1
</span></span></span><span style=display:flex><span><span style=color:#b44;font-style:italic>    property.2=value-2
</span></span></span><span style=display:flex><span><span style=color:#b44;font-style:italic>    property.3=value-3</span><span style=color:#bbb>    
</span></span></span></code></pre></div><h3 id=restrictions>Restrictions</h3><ul><li><p>Vous devez créer un ConfigMap avant de le référencer dans une spécification de Pod (sauf si vous marquez le ConfigMap comme "facultatif").
Si vous faites référence à un ConfigMap qui n'existe pas, le Pod ne démarrera pas.
De même, les références à des clés qui n'existent pas dans la ConfigMap empêcheront le pod de démarrer.</p></li><li><p>Si vous utilisez <code>envFrom</code> pour définir des variables d'environnement à partir de ConfigMaps, les clés considérées comme invalides seront ignorées.
Le pod sera autorisé à démarrer, mais les noms invalides seront enregistrés dans le journal des événements (<code>InvalidVariableNames</code>).
Le message du journal énumère chaque clé sautée.
Par exemple :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get events
</span></span></code></pre></div><p>Le résultat est similaire à celui-ci :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-text data-lang=text><span style=display:flex><span>LASTSEEN FIRSTSEEN COUNT NAME          KIND  SUBOBJECT  TYPE      REASON                            SOURCE                MESSAGE
</span></span><span style=display:flex><span>0s       0s        1     dapi-test-pod Pod              Warning   InvalidEnvironmentVariableNames   {kubelet, 127.0.0.1}  Keys [1badkey, 2alsobad] from the EnvFrom configMap default/myconfig were skipped since they are considered invalid environment variable names.
</span></span></code></pre></div></li><li><p>Les ConfigMaps résident dans un <a class=glossary-tooltip title='An abstraction used by Kubernetes to support isolation of groups of resources within a single cluster.' data-toggle=tooltip data-placement=top href=/docs/concepts/overview/working-with-objects/namespaces target=_blank aria-label=Namespace>Namespace</a>.
Un ConfigMap ne peut être référencé que par des pods résidant dans le même namespace.</p></li><li><p>Vous ne pouvez pas utiliser des ConfigMaps pour <a class=glossary-tooltip title='A pod managed directly by the kubelet daemon on a specific node.' data-toggle=tooltip data-placement=top href=/docs/tasks/configure-pod-container/static-pod/ target=_blank aria-label='static pods'>static pods</a>, car le Kubelet ne le supporte pas.</p></li></ul><p>A suivre</p><ul><li>Suivez un exemple concret de <a href=/docs/tutorials/configuration/configure-redis-using-configmap/>Configurer Redis en utilisant un ConfigMap</a>.</li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-3d7b9cb24a647c36ba63f7a02ec49010>5.3.12 - Partager l'espace de nommage des processus entre les conteneurs d'un Pod</h1><div style=margin-top:10px;margin-bottom:10px><b>FEATURE STATE:</b> <code>Kubernetes v1.17 [stable]</code></div><p>Cette page montre comment configurer le partage de l'espace de noms d'un processus pour un pod. Lorsque le partage de l'espace de noms des processus est activé, les processus d'un conteneur sont visibles pour tous les autres conteneurs de ce pod.</p><p>Vous pouvez utiliser cette fonctionnalité pour configurer les conteneurs coopérants, comme un conteneur de sidecar de gestionnaire de journaux, ou pour dépanner les images de conteneurs qui n'incluent pas d'utilitaires de débogage comme un shell.</p><h2 id=pré-requis>Pré-requis</h2><p><p>Vous devez disposer d'un cluster Kubernetes et l'outil de ligne de commande kubectl doit être configuré pour communiquer avec votre cluster.
Si vous ne possédez pas déjà de cluster, vous pouvez en créer un en utilisant <a href=/docs/setup/minikube>Minikube</a>, ou vous pouvez utiliser l'un de ces environnements Kubernetes:</p><ul><li><a href=https://killercoda.com/playgrounds/scenario/kubernetes>Killercoda</a></li><li><a href=http://labs.play-with-k8s.com/>Play with Kubernetes</a></li></ul>Votre serveur Kubernetes doit être au moins à la version v1.10.
Pour consulter la version, entrez <code>kubectl version</code>.</p><h2 id=configurer-un-pod>Configurer un Pod</h2><p>Le partage de l'espace de nommage du processus est activé en utilisant le champ <code>shareProcessNamespace</code> de <code>v1.PodSpec</code>. Par exemple:</p><div class=highlight><div class=copy-code-icon style=text-align:right><a href=https://raw.githubusercontent.com/kubernetes/website/main/content/fr/examples/pods/share-process-namespace.yaml download=pods/share-process-namespace.yaml><code>pods/share-process-namespace.yaml</code></a>
<img src=/images/copycode.svg style=max-height:24px;cursor:pointer onclick='copyCode("pods-share-process-namespace-yaml")' title="Copy pods/share-process-namespace.yaml to clipboard"></img></div><div class=includecode id=pods-share-process-namespace-yaml><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>nginx<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>shareProcessNamespace</span>:<span style=color:#bbb> </span><span style=color:#a2f;font-weight:700>true</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>nginx<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>nginx<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>shell<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>busybox<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>securityContext</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>capabilities</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>add</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span>- SYS_PTRACE<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>stdin</span>:<span style=color:#bbb> </span><span style=color:#a2f;font-weight:700>true</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>tty</span>:<span style=color:#bbb> </span><span style=color:#a2f;font-weight:700>true</span><span style=color:#bbb>
</span></span></span></code></pre></div></div></div><ol><li><p>Créez le pod <code>nginx</code> sur votre cluster :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl apply -f https://k8s.io/examples/pods/share-process-namespace.yaml
</span></span></code></pre></div></li><li><p>Attachez-le au conteneur <code>shell</code> et lancez <code>ps</code> :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl attach -it nginx -c shell
</span></span></code></pre></div><p>Si vous ne verrez pas d'invite de commande, appuyez sur la touche Entrée.</p><pre tabindex=0><code>/ # ps ax
PID   USER     TIME  COMMAND
    1 root      0:00 /pause
    8 root      0:00 nginx: master process nginx -g daemon off;
   14 101       0:00 nginx: worker process
   15 root      0:00 sh
   21 root      0:00 ps ax
</code></pre></li></ol><p>Vous pouvez signaler les processus dans d'autres conteneurs. Par exemple, envoyez <code>SIGHUP</code> à
nginx pour relancer le processus de worker. Cela nécessite la fonctionnalité <code>SYS_PTRACE</code>.</p><pre tabindex=0><code>/ # kill -HUP 8
/ # ps ax
PID   USER     TIME  COMMAND
    1 root      0:00 /pause
    8 root      0:00 nginx: master process nginx -g daemon off;
   15 root      0:00 sh
   22 101       0:00 nginx: worker process
   23 root      0:00 ps ax
</code></pre><p>Il est même possible d'accéder aux autres conteneurs en utilisant le lien <code>/proc/$pid/root</code>.</p><pre tabindex=0><code>/ # head /proc/8/root/etc/nginx/nginx.conf

user  nginx;
worker_processes  1;

error_log  /var/log/nginx/error.log warn;
pid        /var/run/nginx.pid;


events {
    worker_connections  1024;
</code></pre><h2 id=comprendre-le-processus-de-partage-de-l-espace-de-nommage>Comprendre le processus de partage de l'espace de nommage</h2><p>Les pods partagent de nombreuses ressources, il est donc logique qu'elles partagent également un espace de noms des processus. Pour certaines images de conteneur, on peut envisager de les isoler les uns des autres. Il est donc important de comprendre ces différences :</p><ol><li><p><strong>Le processus de conteneur n'a plus de PID 1.</strong> Certaines images de conteneurs refusent de démarrer sans PID 1 (par exemple, les conteneurs utilisant <code>systemd</code>) ou exécuter des commandes comme <code>kill -HUP 1</code> pour signaler le processus du conteneur. Dans les pods avec un espace de noms partagé du processus, <code>kill -HUP 1</code> signalera la sandbox du pod. (<code>/pause</code> dans l'exemple ci-dessus.)</p></li><li><p><strong>Les processus sont visibles par les autres conteneurs du pod.</strong> Cela inclut tout les informations visibles dans <code>/proc</code>, comme les mots de passe passés en argument ou les variables d'environnement. Celles-ci ne sont protégées que par des permissions Unix régulières.</p></li><li><p><strong>Les systèmes de fichiers des conteneurs sont visibles par les autres conteneurs du pod à travers le lien <code>/proc/$pid/root</code>.</strong> Cela rend le débogage plus facile, mais cela signifie aussi que les secrets du système de fichiers ne sont protégés que par les permissions du système de fichiers.</p></li></ol></div><div class=td-content style=page-break-before:always><h1 id=pg-1bb997c61a85de753d9994e7a312a291>5.3.13 - Convertir un fichier Docker Compose en ressources Kubernetes</h1><p>C'est quoi Kompose ? C'est un outil de conversion de tout ce qui compose (notamment Docker Compose) en orchestrateurs de conteneurs (Kubernetes ou OpenShift).
Vous trouverez plus d'informations sur le site web de Kompose à <a href=http:/kompose.io>http://kompose.io</a>.</p><h2 id=pré-requis>Pré-requis</h2><p><p>Vous devez disposer d'un cluster Kubernetes et l'outil de ligne de commande kubectl doit être configuré pour communiquer avec votre cluster.
Si vous ne possédez pas déjà de cluster, vous pouvez en créer un en utilisant <a href=/docs/setup/minikube>Minikube</a>, ou vous pouvez utiliser l'un de ces environnements Kubernetes:</p><ul><li><a href=https://killercoda.com/playgrounds/scenario/kubernetes>Killercoda</a></li><li><a href=http://labs.play-with-k8s.com/>Play with Kubernetes</a></li></ul>Pour consulter la version, entrez <code>kubectl version</code>.</p><h2 id=installer-kompose>Installer Kompose</h2><p>Nous disposons de plusieurs façons d'installer Kompose. Notre méthode préférée est de télécharger le binaire de la dernière version de GitHub.</p><ul class="nav nav-tabs" id=install-ways role=tablist><li class=nav-item><a data-toggle=tab class="nav-link active" href=#install-ways-0 role=tab aria-controls=install-ways-0 aria-selected=true>GitHub download</a></li><li class=nav-item><a data-toggle=tab class=nav-link href=#install-ways-1 role=tab aria-controls=install-ways-1>Build from source</a></li><li class=nav-item><a data-toggle=tab class=nav-link href=#install-ways-2 role=tab aria-controls=install-ways-2>CentOS package</a></li><li class=nav-item><a data-toggle=tab class=nav-link href=#install-ways-3 role=tab aria-controls=install-ways-3>Fedora package</a></li><li class=nav-item><a data-toggle=tab class=nav-link href=#install-ways-4 role=tab aria-controls=install-ways-4>Homebrew (macOS)</a></li></ul><div class=tab-content id=install-ways><div id=install-ways-0 class="tab-pane show active" role=tabpanel aria-labelledby=install-ways-0><p><p>Kompose est publié via GitHub sur un cycle de trois semaines, vous pouvez voir toutes les versions actuelles sur <a href=https://github.com/kubernetes/kompose/releases>la page des releases de Github</a>.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh><span style=display:flex><span><span style=color:#080;font-style:italic># Linux</span>
</span></span><span style=display:flex><span>curl -L https://github.com/kubernetes/kompose/releases/download/v1.16.0/kompose-linux-amd64 -o kompose
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#080;font-style:italic># macOS</span>
</span></span><span style=display:flex><span>curl -L https://github.com/kubernetes/kompose/releases/download/v1.16.0/kompose-darwin-amd64 -o kompose
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#080;font-style:italic># Windows</span>
</span></span><span style=display:flex><span>curl -L https://github.com/kubernetes/kompose/releases/download/v1.16.0/kompose-windows-amd64.exe -o kompose.exe
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>chmod +x kompose
</span></span><span style=display:flex><span>sudo mv ./kompose /usr/local/bin/kompose
</span></span></code></pre></div><p>Alternativement, vous pouvez télécharger le <a href=https://github.com/kubernetes/kompose/releases>tarball</a>.</p></div><div id=install-ways-1 class=tab-pane role=tabpanel aria-labelledby=install-ways-1><p><p>L'installation en utilisant <code>go get</code> extrait de la branche master avec les derniers changements de développement.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh><span style=display:flex><span>go get -u github.com/kubernetes/kompose
</span></span></code></pre></div></div><div id=install-ways-2 class=tab-pane role=tabpanel aria-labelledby=install-ways-2><p><p>Kompose est dans le dépôt CentOS <a href=https://fedoraproject.org/wiki/EPEL>EPEL</a>.
Si vous n'avez pas le dépôt <a href=https://fedoraproject.org/wiki/EPEL>EPEL</a> déjà installé et activé, vous pouvez le faire en lançant <code>sudo yum install epel-release</code></p><p>Si vous avez <a href=https://fedoraproject.org/wiki/EPEL>EPEL</a> activé dans votre système, vous pouvez installer Kompose comme n'importe quel autre logiciel.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>sudo yum -y install kompose
</span></span></code></pre></div></div><div id=install-ways-3 class=tab-pane role=tabpanel aria-labelledby=install-ways-3><p><p>Kompose est dans les dépôts Fedora 24, 25 et 26. Vous pouvez l'installer comme n'importe quel autre paquetage.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>sudo dnf -y install kompose
</span></span></code></pre></div></div><div id=install-ways-4 class=tab-pane role=tabpanel aria-labelledby=install-ways-4><p><p>Sur macOS, vous pouvez installer la dernière version via <a href=https://brew.sh>Homebrew</a>:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>brew install kompose
</span></span></code></pre></div></div></div><h2 id=utiliser-kompose>Utiliser Kompose</h2><p>En quelques étapes, nous vous emmenons de Docker Compose à Kubernetes. Tous dont vous avez besoin est un fichier <code>docker-compose.yml</code>.</p><ol><li><p>Allez dans le répertoire contenant votre fichier <code>docker-compose.yml</code>. Si vous n'en avez pas, faites un test en utilisant celui-ci.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>version</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;2&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>services</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>redis-master</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>k8s.gcr.io/redis:e2e<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>ports</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- <span style=color:#b44>&#34;6379&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>redis-slave</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>gcr.io/google_samples/gb-redisslave:v3<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>ports</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- <span style=color:#b44>&#34;6379&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>environment</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- GET_HOSTS_FROM=dns<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>frontend</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>gcr.io/google-samples/gb-frontend:v4<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>ports</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- <span style=color:#b44>&#34;80:80&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>environment</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- GET_HOSTS_FROM=dns<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>labels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>kompose.service.type</span>:<span style=color:#bbb> </span>LoadBalancer<span style=color:#bbb>
</span></span></span></code></pre></div></li><li><p>Pour convertir le fichier <code>docker-compose.yml</code> en fichiers que vous pouvez utiliser avec <code>kubectl</code>, lancez <code>kompose convert</code> et ensuite <code>kubectl apply -f &lt;output file></code>.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>$ kompose convert                           
</span></span><span style=display:flex><span>INFO Kubernetes file <span style=color:#b44>&#34;frontend-service.yaml&#34;</span> created         
</span></span><span style=display:flex><span>INFO Kubernetes file <span style=color:#b44>&#34;redis-master-service.yaml&#34;</span> created     
</span></span><span style=display:flex><span>INFO Kubernetes file <span style=color:#b44>&#34;redis-slave-service.yaml&#34;</span> created      
</span></span><span style=display:flex><span>INFO Kubernetes file <span style=color:#b44>&#34;frontend-deployment.yaml&#34;</span> created      
</span></span><span style=display:flex><span>INFO Kubernetes file <span style=color:#b44>&#34;redis-master-deployment.yaml&#34;</span> created  
</span></span><span style=display:flex><span>INFO Kubernetes file <span style=color:#b44>&#34;redis-slave-deployment.yaml&#34;</span> created   
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>$ kubectl apply -f frontend-service.yaml,redis-master-service.yaml,redis-slave-service.yaml,frontend-deployment.yaml,redis-master-deployment.yaml,redis-slave-deployment.yaml
</span></span><span style=display:flex><span>service/frontend created
</span></span><span style=display:flex><span>service/redis-master created
</span></span><span style=display:flex><span>service/redis-slave created
</span></span><span style=display:flex><span>deployment.apps/frontend created
</span></span><span style=display:flex><span>deployment.apps/redis-master created
</span></span><span style=display:flex><span>deployment.apps/redis-slave created
</span></span></code></pre></div><p>Vos déploiements fonctionnent sur Kubernetes.</p></li><li><p>Accédez à votre application.</p><p>Si vous utilisez déjà <code>minikube</code> pour votre processus de développement :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>$ minikube service frontend
</span></span></code></pre></div><p>Sinon, regardons quelle IP votre service utilise !</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh><span style=display:flex><span>$ kubectl describe svc frontend
</span></span><span style=display:flex><span>Name:                   frontend
</span></span><span style=display:flex><span>Namespace:              default
</span></span><span style=display:flex><span>Labels:                 <span style=color:#b8860b>service</span><span style=color:#666>=</span>frontend
</span></span><span style=display:flex><span>Selector:               <span style=color:#b8860b>service</span><span style=color:#666>=</span>frontend
</span></span><span style=display:flex><span>Type:                   LoadBalancer
</span></span><span style=display:flex><span>IP:                     10.0.0.183
</span></span><span style=display:flex><span>LoadBalancer Ingress:   192.0.2.89
</span></span><span style=display:flex><span>Port:                   <span style=color:#666>80</span>      80/TCP
</span></span><span style=display:flex><span>NodePort:               <span style=color:#666>80</span>      31144/TCP
</span></span><span style=display:flex><span>Endpoints:              172.17.0.4:80
</span></span><span style=display:flex><span>Session Affinity:       None
</span></span><span style=display:flex><span>No events.
</span></span></code></pre></div><p>Si vous utilisez un fournisseur de cloud computing, votre IP sera listée à côté de <code>LoadBalancer Ingress</code>.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh><span style=display:flex><span>$ curl http://192.0.2.89
</span></span></code></pre></div></li></ol><h2 id=guide-de-l-utilisateur>Guide de l'utilisateur</h2><ul><li>CLI<ul><li><a href=#kompose-convert><code>kompose convert</code></a></li></ul></li><li>Documentation<ul><li><a href=#alternative-conversions>Conversions alternatives</a></li><li><a href=#labels>Etiquettes</a></li><li><a href=#restart>Redémarrage</a></li><li><a href=#docker-compose-versions>Les Versions de Docker Compose</a></li></ul></li></ul><p>Kompose supporte deux fournisseurs : OpenShift et Kubernetes.
Vous pouvez choisir un fournisseur ciblé en utilisant l'option globale <code>--provider</code>. Si aucun fournisseur n'est spécifié, Kubernetes est défini par défaut.</p><h2 id=kompose-convert><code>kompose convert</code></h2><p>Kompose prend en charge la conversion des fichiers Docker Compose V1, V2 et V3 en objets Kubernetes et OpenShift.</p><h3 id=kubernetes>Kubernetes</h3><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh><span style=display:flex><span>$ kompose --file docker-voting.yml convert
</span></span><span style=display:flex><span>WARN Unsupported key networks - ignoring
</span></span><span style=display:flex><span>WARN Unsupported key build - ignoring
</span></span><span style=display:flex><span>INFO Kubernetes file <span style=color:#b44>&#34;worker-svc.yaml&#34;</span> created
</span></span><span style=display:flex><span>INFO Kubernetes file <span style=color:#b44>&#34;db-svc.yaml&#34;</span> created
</span></span><span style=display:flex><span>INFO Kubernetes file <span style=color:#b44>&#34;redis-svc.yaml&#34;</span> created
</span></span><span style=display:flex><span>INFO Kubernetes file <span style=color:#b44>&#34;result-svc.yaml&#34;</span> created
</span></span><span style=display:flex><span>INFO Kubernetes file <span style=color:#b44>&#34;vote-svc.yaml&#34;</span> created
</span></span><span style=display:flex><span>INFO Kubernetes file <span style=color:#b44>&#34;redis-deployment.yaml&#34;</span> created
</span></span><span style=display:flex><span>INFO Kubernetes file <span style=color:#b44>&#34;result-deployment.yaml&#34;</span> created
</span></span><span style=display:flex><span>INFO Kubernetes file <span style=color:#b44>&#34;vote-deployment.yaml&#34;</span> created
</span></span><span style=display:flex><span>INFO Kubernetes file <span style=color:#b44>&#34;worker-deployment.yaml&#34;</span> created
</span></span><span style=display:flex><span>INFO Kubernetes file <span style=color:#b44>&#34;db-deployment.yaml&#34;</span> created
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>$ ls
</span></span><span style=display:flex><span>db-deployment.yaml  docker-compose.yml         docker-gitlab.yml  redis-deployment.yaml  result-deployment.yaml  vote-deployment.yaml  worker-deployment.yaml
</span></span><span style=display:flex><span>db-svc.yaml         docker-voting.yml          redis-svc.yaml     result-svc.yaml        vote-svc.yaml           worker-svc.yaml
</span></span></code></pre></div><p>Vous pouvez également fournir plusieurs fichiers de composition du Docker en même temps :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh><span style=display:flex><span>$ kompose -f docker-compose.yml -f docker-guestbook.yml convert
</span></span><span style=display:flex><span>INFO Kubernetes file <span style=color:#b44>&#34;frontend-service.yaml&#34;</span> created         
</span></span><span style=display:flex><span>INFO Kubernetes file <span style=color:#b44>&#34;mlbparks-service.yaml&#34;</span> created         
</span></span><span style=display:flex><span>INFO Kubernetes file <span style=color:#b44>&#34;mongodb-service.yaml&#34;</span> created          
</span></span><span style=display:flex><span>INFO Kubernetes file <span style=color:#b44>&#34;redis-master-service.yaml&#34;</span> created     
</span></span><span style=display:flex><span>INFO Kubernetes file <span style=color:#b44>&#34;redis-slave-service.yaml&#34;</span> created      
</span></span><span style=display:flex><span>INFO Kubernetes file <span style=color:#b44>&#34;frontend-deployment.yaml&#34;</span> created      
</span></span><span style=display:flex><span>INFO Kubernetes file <span style=color:#b44>&#34;mlbparks-deployment.yaml&#34;</span> created      
</span></span><span style=display:flex><span>INFO Kubernetes file <span style=color:#b44>&#34;mongodb-deployment.yaml&#34;</span> created       
</span></span><span style=display:flex><span>INFO Kubernetes file <span style=color:#b44>&#34;mongodb-claim0-persistentvolumeclaim.yaml&#34;</span> created
</span></span><span style=display:flex><span>INFO Kubernetes file <span style=color:#b44>&#34;redis-master-deployment.yaml&#34;</span> created  
</span></span><span style=display:flex><span>INFO Kubernetes file <span style=color:#b44>&#34;redis-slave-deployment.yaml&#34;</span> created   
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>$ ls
</span></span><span style=display:flex><span>mlbparks-deployment.yaml  mongodb-service.yaml                       redis-slave-service.jsonmlbparks-service.yaml  
</span></span><span style=display:flex><span>frontend-deployment.yaml  mongodb-claim0-persistentvolumeclaim.yaml  redis-master-service.yaml
</span></span><span style=display:flex><span>frontend-service.yaml     mongodb-deployment.yaml                    redis-slave-deployment.yaml
</span></span><span style=display:flex><span>redis-master-deployment.yaml
</span></span></code></pre></div><p>Lorsque plusieurs fichiers de docker-compose sont fournis, la configuration est fusionnée. Toute configuration qui est commune sera surchargée par le fichier suivant.</p><h3 id=openshift>OpenShift</h3><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh><span style=display:flex><span>$ kompose --provider openshift --file docker-voting.yml convert
</span></span><span style=display:flex><span>WARN <span style=color:#666>[</span>worker<span style=color:#666>]</span> Service cannot be created because of missing port.
</span></span><span style=display:flex><span>INFO OpenShift file <span style=color:#b44>&#34;vote-service.yaml&#34;</span> created             
</span></span><span style=display:flex><span>INFO OpenShift file <span style=color:#b44>&#34;db-service.yaml&#34;</span> created               
</span></span><span style=display:flex><span>INFO OpenShift file <span style=color:#b44>&#34;redis-service.yaml&#34;</span> created            
</span></span><span style=display:flex><span>INFO OpenShift file <span style=color:#b44>&#34;result-service.yaml&#34;</span> created           
</span></span><span style=display:flex><span>INFO OpenShift file <span style=color:#b44>&#34;vote-deploymentconfig.yaml&#34;</span> created    
</span></span><span style=display:flex><span>INFO OpenShift file <span style=color:#b44>&#34;vote-imagestream.yaml&#34;</span> created         
</span></span><span style=display:flex><span>INFO OpenShift file <span style=color:#b44>&#34;worker-deploymentconfig.yaml&#34;</span> created  
</span></span><span style=display:flex><span>INFO OpenShift file <span style=color:#b44>&#34;worker-imagestream.yaml&#34;</span> created       
</span></span><span style=display:flex><span>INFO OpenShift file <span style=color:#b44>&#34;db-deploymentconfig.yaml&#34;</span> created      
</span></span><span style=display:flex><span>INFO OpenShift file <span style=color:#b44>&#34;db-imagestream.yaml&#34;</span> created           
</span></span><span style=display:flex><span>INFO OpenShift file <span style=color:#b44>&#34;redis-deploymentconfig.yaml&#34;</span> created   
</span></span><span style=display:flex><span>INFO OpenShift file <span style=color:#b44>&#34;redis-imagestream.yaml&#34;</span> created        
</span></span><span style=display:flex><span>INFO OpenShift file <span style=color:#b44>&#34;result-deploymentconfig.yaml&#34;</span> created  
</span></span><span style=display:flex><span>INFO OpenShift file <span style=color:#b44>&#34;result-imagestream.yaml&#34;</span> created  
</span></span></code></pre></div><p>Il supporte également la création de buildconfig pour la directive de build dans un service. Par défaut, il utilise le répertoire distant de la branche git courante comme répertoire source, et la branche courante comme branche source pour le build. Vous pouvez spécifier un repo source et une branche différents en utilisant respectivement les options <code>--build-repo</code> et <code>--build-branch</code>.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh><span style=display:flex><span>$ kompose --provider openshift --file buildconfig/docker-compose.yml convert
</span></span><span style=display:flex><span>WARN <span style=color:#666>[</span>foo<span style=color:#666>]</span> Service cannot be created because of missing port.
</span></span><span style=display:flex><span>INFO OpenShift Buildconfig using git@github.com:rtnpro/kompose.git::master as source.
</span></span><span style=display:flex><span>INFO OpenShift file <span style=color:#b44>&#34;foo-deploymentconfig.yaml&#34;</span> created     
</span></span><span style=display:flex><span>INFO OpenShift file <span style=color:#b44>&#34;foo-imagestream.yaml&#34;</span> created          
</span></span><span style=display:flex><span>INFO OpenShift file <span style=color:#b44>&#34;foo-buildconfig.yaml&#34;</span> created
</span></span></code></pre></div><div class="alert alert-info note callout" role=alert><strong>Note:</strong> Si vous poussez manuellement les artefacts OpenShift en utilisant <code>oc create -f</code>, vous devez vous assurer que vous poussez l'artefact imagestream avant l'artefact buildconfig, pour contourner ce problème OpenShift : <a href=https://github.com/openshift/origin/issues/4518>https://github.com/openshift/origin/issues/4518</a> .</div><h2 id=autres-conversions>Autres conversions</h2><p>La transformation par défaut <code>komposer</code> va générer des <a href=/docs/concepts/workloads/controllers/deployment/>Déploiements</a> et <a href=/docs/concepts/services-networking/service/>Services</a> de Kubernetes, au format yaml. Vous avez une autre option pour générer json avec <code>-j</code>. Vous pouvez aussi générer des objets de <a href=/docs/concepts/workloads/controllers/replicationcontroller/>Replication Controllers</a>, <a href=/docs/concepts/workloads/controllers/daemonset/>Daemon Sets</a>, ou <a href=https://github.com/helm/helm>Helm</a> charts.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh><span style=display:flex><span>$ kompose convert -j
</span></span><span style=display:flex><span>INFO Kubernetes file <span style=color:#b44>&#34;redis-svc.json&#34;</span> created
</span></span><span style=display:flex><span>INFO Kubernetes file <span style=color:#b44>&#34;web-svc.json&#34;</span> created
</span></span><span style=display:flex><span>INFO Kubernetes file <span style=color:#b44>&#34;redis-deployment.json&#34;</span> created
</span></span><span style=display:flex><span>INFO Kubernetes file <span style=color:#b44>&#34;web-deployment.json&#34;</span> created
</span></span></code></pre></div><p>Les fichiers <code>*-deployment.json</code> contiennent les objets Déploiements.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh><span style=display:flex><span>$ kompose convert --replication-controller
</span></span><span style=display:flex><span>INFO Kubernetes file <span style=color:#b44>&#34;redis-svc.yaml&#34;</span> created
</span></span><span style=display:flex><span>INFO Kubernetes file <span style=color:#b44>&#34;web-svc.yaml&#34;</span> created
</span></span><span style=display:flex><span>INFO Kubernetes file <span style=color:#b44>&#34;redis-replicationcontroller.yaml&#34;</span> created
</span></span><span style=display:flex><span>INFO Kubernetes file <span style=color:#b44>&#34;web-replicationcontroller.yaml&#34;</span> created
</span></span></code></pre></div><p>Les fichiers <code>*-replicationcontroller.yaml</code> contiennent les objets du Contrôleur de Réplication. Si vous voulez spécifier des répliques (la valeur par défaut est 1), utilisez l'option <code>--replicas</code> : <code>$ kompose convert --replication-controller --replicas 3</code></p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh><span style=display:flex><span>$ kompose convert --daemon-set
</span></span><span style=display:flex><span>INFO Kubernetes file <span style=color:#b44>&#34;redis-svc.yaml&#34;</span> created
</span></span><span style=display:flex><span>INFO Kubernetes file <span style=color:#b44>&#34;web-svc.yaml&#34;</span> created
</span></span><span style=display:flex><span>INFO Kubernetes file <span style=color:#b44>&#34;redis-daemonset.yaml&#34;</span> created
</span></span><span style=display:flex><span>INFO Kubernetes file <span style=color:#b44>&#34;web-daemonset.yaml&#34;</span> created
</span></span></code></pre></div><p>Les fichiers <code>*-daemonset.yaml</code> contiennent les objets du Daemon Set</p><p>Si vous voulez générer un Chart à utiliser avec <a href=https://github.com/kubernetes/helm>Helm</a>, faites-le simplement :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh><span style=display:flex><span>$ kompose convert -c
</span></span><span style=display:flex><span>INFO Kubernetes file <span style=color:#b44>&#34;web-svc.yaml&#34;</span> created
</span></span><span style=display:flex><span>INFO Kubernetes file <span style=color:#b44>&#34;redis-svc.yaml&#34;</span> created
</span></span><span style=display:flex><span>INFO Kubernetes file <span style=color:#b44>&#34;web-deployment.yaml&#34;</span> created
</span></span><span style=display:flex><span>INFO Kubernetes file <span style=color:#b44>&#34;redis-deployment.yaml&#34;</span> created
</span></span><span style=display:flex><span>chart created in <span style=color:#b44>&#34;./docker-compose/&#34;</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>$ tree docker-compose/
</span></span><span style=display:flex><span>docker-compose
</span></span><span style=display:flex><span>├── Chart.yaml
</span></span><span style=display:flex><span>├── README.md
</span></span><span style=display:flex><span>└── templates
</span></span><span style=display:flex><span>    ├── redis-deployment.yaml
</span></span><span style=display:flex><span>    ├── redis-svc.yaml
</span></span><span style=display:flex><span>    ├── web-deployment.yaml
</span></span><span style=display:flex><span>    └── web-svc.yaml
</span></span></code></pre></div><p>La structure du Chart est destinée à fournir un modèle pour la construction de vos chartes de Helm.</p><h2 id=étiquettes>Étiquettes</h2><p><code>kompose</code> supporte les étiquettes spécifiques à Kompose dans le fichier <code>docker-compose.yml</code> afin de définir explicitement le comportement d'un service lors de la conversion.</p><ul><li>Le fichier <code>kompose.service.type</code> définit le type de service à créer.</li></ul><p>Par exemple :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>version</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;2&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>services</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>nginx</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>nginx<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>dockerfile</span>:<span style=color:#bbb> </span>foobar<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>build</span>:<span style=color:#bbb> </span>./foobar<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>cap_add</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- ALL<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>container_name</span>:<span style=color:#bbb> </span>foobar<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>labels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>kompose.service.type</span>:<span style=color:#bbb> </span>nodeport<span style=color:#bbb>
</span></span></span></code></pre></div><ul><li><code>kompose.service.expose</code> définit si le service doit être accessible depuis l'extérieur du cluster ou non. Si la valeur est fixée à "true", le fournisseur définit automatiquement l'extrémité, et pour toute autre valeur, la valeur est définie comme le nom d'hôte. Si plusieurs ports sont définis dans un service, le premier est choisi pour être l'exposé.<ul><li>Pour le fournisseur Kubernetes, une ressource ingress est créée et il est supposé qu'un contrôleur ingress a déjà été configuré.</li><li>Pour le fournisseur OpenShift, une route est créée.</li></ul></li></ul><p>Par exemple :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>version</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;2&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>services</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>web</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>tuna/docker-counter23<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>ports</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>     </span>- <span style=color:#b44>&#34;5000:5000&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>links</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>     </span>- redis<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>labels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>kompose.service.expose</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;counter.example.com&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>redis</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>redis:3.0<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>ports</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>     </span>- <span style=color:#b44>&#34;6379&#34;</span><span style=color:#bbb>
</span></span></span></code></pre></div><p>Les options actuellement supportées sont :</p><table><thead><tr><th>Key</th><th>Value</th></tr></thead><tbody><tr><td>kompose.service.type</td><td>nodeport / clusterip / loadbalancer</td></tr><tr><td>kompose.service.expose</td><td>true / hostname</td></tr></tbody></table><div class="alert alert-info note callout" role=alert><strong>Note:</strong> Le label <code>kompose.service.type</code> doit être défini avec <code>ports</code> uniquement, sinon <code>kompose</code> échouera.</div><h2 id=redémarrer>Redémarrer</h2><p>Si vous voulez créer des pods normaux sans contrôleurs, vous pouvez utiliser la construction
<code>restart</code> de docker-compose pour définir cela. Suivez le tableau ci-dessous pour voir ce qui se passe avec la valeur de <code>restart</code>.</p><table><thead><tr><th><code>docker-compose</code> <code>restart</code></th><th>object created</th><th>Pod <code>restartPolicy</code></th></tr></thead><tbody><tr><td><code>""</code></td><td>controller object</td><td><code>Always</code></td></tr><tr><td><code>always</code></td><td>controller object</td><td><code>Always</code></td></tr><tr><td><code>on-failure</code></td><td>Pod</td><td><code>OnFailure</code></td></tr><tr><td><code>no</code></td><td>Pod</td><td><code>Never</code></td></tr></tbody></table><div class="alert alert-info note callout" role=alert><strong>Note:</strong> L'objet contrôleur peut être <code>déploiement</code> ou <code>replicationcontroller</code>, etc.</div><p>Par exemple, le service <code>pival</code> deviendra un Pod. Ce conteneur a calculé la valeur de <code>pi</code>.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>version</span>:<span style=color:#bbb> </span><span style=color:#b44>&#39;2&#39;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>services</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>pival</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>perl<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>command</span>:<span style=color:#bbb> </span>[<span style=color:#b44>&#34;perl&#34;</span>,<span style=color:#bbb>  </span><span style=color:#b44>&#34;-Mbignum=bpi&#34;</span>,<span style=color:#bbb> </span><span style=color:#b44>&#34;-wle&#34;</span>,<span style=color:#bbb> </span><span style=color:#b44>&#34;print bpi(2000)&#34;</span>]<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>restart</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;on-failure&#34;</span><span style=color:#bbb>
</span></span></span></code></pre></div><h3 id=avertissement-concernant-les-configurations-de-déploiement>Avertissement concernant les configurations de déploiement</h3><p>Si le fichier Docker Compose a un volume spécifié pour un service, la stratégie Deployment (Kubernetes) ou DeploymentConfig (OpenShift) est changée en "Recreate" au lieu de "RollingUpdate" (par défaut). Ceci est fait pour éviter que plusieurs instances d'un service n'accèdent à un volume en même temps.</p><p>Si le fichier Docker Compose a un nom de service avec <code>_</code> dedans (par exemple <code>web_service</code>), alors il sera remplacé par <code>-</code> et le nom du service sera renommé en conséquence (par exemple <code>web-service</code>). Kompose fait cela parce que "Kubernetes" n'autorise pas <code>_</code> dans le nom de l'objet.</p><p>Veuillez noter que changer le nom du service peut casser certains fichiers <code>docker-compose</code>.</p><h2 id=versions-du-docker-compose>Versions du Docker Compose</h2><p>Kompose supporte les versions Docker Compose : 1, 2 et 3. Nous avons un support limité sur les versions 2.1 et 3.2 en raison de leur nature expérimentale.</p><p>Une liste complète sur la compatibilité entre les trois versions est donnée dans notre <a href=https://github.com/kubernetes/kompose/blob/master/docs/conversion.md>document de conversion</a> incluant une liste de toutes les clés Docker Compose incompatibles.</p></div><div class=td-content style=page-break-before:always><h1 id=pg-aa0731e8aa8e2f6cc9e3c1a5e9895863>5.4 - Gérez vos objets Kubernetes</h1></div><div class=td-content style=page-break-before:always><h1 id=pg-866924fa095f897ede8dfdcab9e97942>5.5 - Injection des données dans les applications</h1></div><div class=td-content style=page-break-before:always><h1 id=pg-a78a5e7e765fd8c49c8f7c0d72499f72>5.6 - Exécution des applications</h1></div><div class=td-content style=page-break-before:always><h1 id=pg-ca3bc4e31dfe46d5044a3b93eb804ee9>5.7 - Exécution des jobs</h1></div><div class=td-content style=page-break-before:always><h1 id=pg-b74b959f5a531003dd0653dfbfc2e88b>5.8 - Accès aux applications dans un cluster</h1></div><div class=td-content><h1 id=pg-777447042cd4e81df3fa5beb3357a485>5.8.1 - Tableau de bord (Dashboard)</h1><p>Le tableau de bord (Dashboard) est une interface web pour Kubernetes.
Vous pouvez utiliser ce tableau de bord pour déployer des applications conteneurisées dans un cluster Kubernetes, dépanner votre application conteneurisée et gérer les ressources du cluster.
Vous pouvez utiliser le tableau de bord pour obtenir une vue d'ensemble des applications en cours d'exécution dans votre cluster, ainsi que pour créer ou modifier des ressources Kubernetes individuelles. (comme des Deployments, Jobs, DaemonSets, etc).
Par exemple, vous pouvez redimensionner un Deployment, lancer une mise à jour progressive, recréer un pod ou déployez de nouvelles applications à l'aide d'un assistant de déploiement.</p><p>Le tableau de bord fournit également des informations sur l'état des ressources Kubernetes de votre cluster et sur les erreurs éventuelles.</p><p><img src=/images/docs/ui-dashboard.png alt="Tableau de bord Kubernetes"></p><h2 id=déploiement-du-tableau-de-bord>Déploiement du tableau de bord</h2><p>L'interface utilisateur du tableau de bord n'est pas déployée par défaut.
Pour le déployer, exécutez la commande suivante:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-text data-lang=text><span style=display:flex><span>kubectl apply -f https://raw.githubusercontent.com/kubernetes/dashboard/master/aio/deploy/recommended.yaml
</span></span></code></pre></div><h2 id=accès-à-l-interface-utilisateur-du-tableau-de-bord>Accès à l'interface utilisateur du tableau de bord</h2><p>Pour protéger vos données dans le cluster, le tableau de bord se déploie avec une configuration RBAC minimale par défaut.
Actuellement, le tableau de bord prend uniquement en charge la connexion avec un jeton de support.
Pour créer un jeton pour cette démo, vous pouvez suivre notre guide sur <a href=https://github.com/kubernetes/dashboard/blob/master/docs/user/access-control/creating-sample-user.md>créer un exemple d'utilisateur</a>.</p><div class="alert alert-danger warning callout" role=alert><strong>Attention:</strong> L’exemple d’utilisateur créé dans le didacticiel disposera de privilèges d’administrateur et servira uniquement à des fins pédagogiques.</div><h3 id=proxy-en-ligne-de-commande>Proxy en ligne de commande</h3><p>Vous pouvez accéder au tableau de bord à l'aide de l'outil en ligne de commande kubectl en exécutant la commande suivante:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-text data-lang=text><span style=display:flex><span>kubectl proxy
</span></span></code></pre></div><p>Kubectl mettra le tableau de bord à disposition à l'adresse suivante: <a href=http://localhost:8001/api/v1/namespaces/kubernetes-dashboard/services/https:kubernetes-dashboard:/proxy/>http://localhost:8001/api/v1/namespaces/kubernetes-dashboard/services/https:kubernetes-dashboard:/proxy/</a>.</p><p>Vous ne pouvez accéder à l'interface utilisateur <em>que</em> depuis la machine sur laquelle la commande est exécutée.
Voir <code>kubectl proxy --help</code> pour plus d'options.</p><div class="alert alert-info note callout" role=alert><strong>Note:</strong> La méthode d'authentification Kubeconfig ne prend pas en charge les fournisseurs d'identité externes ni l'authentification basée sur un certificat x509.</div><h2 id=page-de-bienvenue>Page de bienvenue</h2><p>Lorsque vous accédez au tableau de bord sur un cluster vide, la page d'accueil s'affiche.
Cette page contient un lien vers ce document ainsi qu'un bouton pour déployer votre première application.
De plus, vous pouvez voir quelles applications système sont exécutées par défaut dans le <a href=/docs/tasks/administer-cluster/namespaces/>namespace</a> <code>kubernetes-dashboard</code> de votre cluster, par exemple le tableau de bord lui-même.</p><p><img src=/images/docs/ui-dashboard-zerostate.png alt="Page d'accueil du tableau de bord Kubernetes"></p><h2 id=déploiement-d-applications-conteneurisées>Déploiement d'applications conteneurisées</h2><p>Le tableau de bord vous permet de créer et de déployer une application conteneurisée en tant que Deployment et optionnellement un Service avec un simple assistant.
Vous pouvez spécifier manuellement les détails de l'application ou charger un fichier YAML ou JSON contenant la configuration de l'application.</p><p>Cliquez sur le bouton <strong>CREATE</strong> dans le coin supérieur droit de n’importe quelle page pour commencer.</p><h3 id=spécifier-les-détails-de-l-application>Spécifier les détails de l'application</h3><p>L'assistant de déploiement s'attend à ce que vous fournissiez les informations suivantes:</p><ul><li><p><strong>App name</strong> (obligatoire): Nom de votre application.
Un <a href=/docs/concepts/overview/working-with-objects/labels/>label</a> avec le nom sera ajouté au Deployment et Service, le cas échéant, qui sera déployé.</p><p>Le nom de l'application doit être unique dans son <a href=/docs/tasks/administer-cluster/namespaces/>namespace</a> Kubernetes.
Il doit commencer par une lettre minuscule et se terminer par une lettre minuscule ou un chiffre et ne contenir que des lettres minuscules, des chiffres et des tirets (-).
Il est limité à 24 caractères.
Les espaces de début et de fin sont ignorés.</p></li><li><p><strong>Container image</strong> (obligatoire): L'URL d'une <a href=/docs/concepts/containers/images/>image de conteneur</a> sur n'importe quel registre, ou une image privée (généralement hébergée sur le registre de conteneurs Google ou le hub Docker).
La spécification d'image de conteneur doit se terminer par un deux-points.</p></li><li><p><strong>Number of pods</strong> (obligatoire): Nombre cible de pods dans lesquels vous souhaitez déployer votre application.
La valeur doit être un entier positif.</p><p>Un objet <a href=/docs/concepts/workloads/controllers/deployment/>Deployment</a> sera créé pour maintenir le nombre souhaité de pods dans votre cluster.</p></li><li><p><strong>Service</strong> (optionnel): Pour certaines parties de votre application (par exemple les serveurs frontaux), vous souhaiterez peut-être exposer un <a href=/docs/concepts/services-networking/service/>Service</a> sur une adresse IP externe, peut-être publique, en dehors de votre cluster (Service externe).
Pour les Services externes, vous devrez peut-être ouvrir un ou plusieurs ports pour le faire.
Trouvez plus de détails <a href=/docs/tasks/access-application-cluster/configure-cloud-provider-firewall/>ici</a>.</p><p>Les autres services visibles uniquement de l'intérieur du cluster sont appelés Services internes.</p><p>Quel que soit le type de service, si vous choisissez de créer un service et que votre conteneur écoute sur un port (entrant), vous devez spécifier deux ports.
Le Service sera créé en mappant le port (entrant) sur le port cible vu par le conteneur.
Ce Service acheminera le trafic vers vos pods déployés.
Les protocoles pris en charge sont TCP et UDP.
Le nom DNS interne de ce service sera la valeur que vous avez spécifiée comme nom d'application ci-dessus.</p></li></ul><p>Si nécessaire, vous pouvez développer la section <strong>Options avancées</strong> dans laquelle vous pouvez spécifier davantage de paramètres:</p><ul><li><p><strong>Description</strong>: Le texte que vous entrez ici sera ajouté en tant qu'<a href=/docs/concepts/overview/working-with-objects/annotations/>annotation</a> au Deployment et affiché dans les détails de l'application.</p></li><li><p><strong>Labels</strong>: Les <a href=/docs/concepts/overview/working-with-objects/labels/>labels</a> par défaut à utiliser pour votre application sont le nom et la version de l’application.
Vous pouvez spécifier des labels supplémentaires à appliquer au Deployment, Service (le cas échéant), et Pods, tels que la release, l'environnement, le niveau, la partition et la piste d'édition.</p><p>Exemple:</p><pre tabindex=0><code class=language-conf data-lang=conf>release=1.0
tier=frontend
environment=pod
track=stable
</code></pre></li><li><p><strong>Namespace</strong>: Kubernetes prend en charge plusieurs clusters virtuels s'exécutant sur le même cluster physique.
Ces clusters virtuels sont appelés <a href=/docs/tasks/administer-cluster/namespaces/>namespaces</a>.
Ils vous permettent de partitionner les ressources en groupes nommés de manière logique.</p><p>Le tableau de bord propose tous les namespaces disponibles dans une liste déroulante et vous permet de créer un nouveau namespace.
Le nom du namespace peut contenir au maximum 63 caractères alphanumériques et des tirets (-), mais ne peut pas contenir de lettres majuscules.
Les noms de Namespace ne devraient pas être composés uniquement de chiffres.
Si le nom est défini sous la forme d’un nombre, tel que 10, le pod sera placé dans le namespace par défaut.</p><p>Si la création du namespace réussit, celle-ci est sélectionnée par défaut.
Si la création échoue, le premier namespace est sélectionné.</p></li><li><p><strong>Image Pull Secret</strong>: Si l'image de conteneur spécifiée est privée, il peut être nécessaire de configurer des identifiants de <a href=/docs/concepts/configuration/secret/>pull secret</a>.</p><p>Le tableau de bord propose tous les secrets disponibles dans une liste déroulante et vous permet de créer un nouveau secret.
Le nom de secret doit respecter la syntaxe du nom de domaine DNS, par exemple. <code>new.image-pull.secret</code>.
Le contenu d'un secret doit être codé en base64 et spécifié dans un fichier <a href=/docs/concepts/containers/images/#specifying-imagepullsecrets-on-a-pod><code>.dockercfg</code></a>.
Le nom du secret peut contenir 253 caractères maximum.</p><p>Si la création du secret d’extraction d’image est réussie, celle-ci est sélectionnée par défaut.
Si la création échoue, aucun secret n'est appliqué.</p></li><li><p><strong>CPU requirement (cores)</strong> et <strong>Memory requirement (MiB)</strong>: Vous pouvez spécifier les <a href=/docs/tasks/configure-pod-container/limit-range/>limites de ressource</a> minimales pour le conteneur.
Par défaut, les pods fonctionnent avec des limites de CPU et de mémoire illimitées.</p></li><li><p><strong>Run command</strong> et <strong>Run command arguments</strong>: Par défaut, vos conteneurs exécutent les valeurs par défaut de la <a href=/docs/user-guide/containers/#containers-and-commands>commande d'entrée</a> de l'image spécifiée.
Vous pouvez utiliser les options de commande et les arguments pour remplacer la valeur par défaut.</p></li><li><p><strong>Run as privileged</strong>: Ce paramètre détermine si les processus dans <a href=/docs/user-guide/pods/#privileged-mode-for-pod-containers>conteneurs privilégiés</a> sont équivalents aux processus s'exécutant en tant que root sur l'hôte.
Les conteneurs privilégiés peuvent utiliser des fonctionnalités telles que la manipulation de la pile réseau et l'accès aux périphériques.</p></li><li><p><strong>Environment variables</strong>: Kubernetes expose ses Services via des <a href=/docs/tasks/inject-data-application/environment-variable-expose-pod-information/>variables d'environnement</a>.
Vous pouvez composer une variable d'environnement ou transmettre des arguments à vos commandes en utilisant les valeurs des variables d'environnement.<br>Ils peuvent être utilisés dans les applications pour trouver un Service.
Les valeurs peuvent référencer d'autres variables à l'aide de la syntaxe <code>$(VAR_NAME)</code>.</p></li></ul><h3 id=téléchargement-d-un-fichier-yaml-ou-json>Téléchargement d'un fichier YAML ou JSON</h3><p>Kubernetes supporte la configuration déclarative.
Dans ce style, toute la configuration est stockée dans des fichiers de configuration YAML ou JSON à l'aide des schémas de ressources de l'<a href=/docs/concepts/overview/kubernetes-api/>API</a> de Kubernetes.</p><p>Au lieu de spécifier les détails de l'application dans l'assistant de déploiement, vous pouvez définir votre application dans des fichiers YAML ou JSON et télécharger les fichiers à l'aide du tableau de bord.</p><h2 id=utilisation-du-tableau-de-bord>Utilisation du tableau de bord</h2><p>Les sections suivantes décrivent des vues du tableau de bord de Kubernetes; ce qu'elles fournissent et comment peuvent-elles être utilisées.</p><h3 id=navigation>Navigation</h3><p>Lorsque des objets Kubernetes sont définis dans le cluster, le tableau de bord les affiche dans la vue initiale.
Par défaut, seuls les objets du namespace <em>default</em> sont affichés, ce qui peut être modifié à l'aide du sélecteur d'espace de nom situé dans le menu de navigation.</p><p>Le tableau de bord montre la plupart des types d'objets Kubernetes et les regroupe dans quelques catégories de menus.</p><h4 id=vue-d-ensemble-de-l-administrateur>Vue d'ensemble de l'administrateur</h4><p>Pour les administrateurs de cluster et de namespace, le tableau de bord répertorie les noeuds, les namespaces et les volumes persistants et propose des vues de détail pour ceux-ci.
La vue Liste de nœuds contient les mesures d'utilisation de CPU et de la mémoire agrégées sur tous les nœuds.
La vue détaillée affiche les métriques d'un nœud, ses spécifications, son statut, les ressources allouées, les événements et les pods s'exécutant sur le nœud.</p><h4 id=charges-de-travail>Charges de travail</h4><p>Affiche toutes les applications en cours d'exécution dans le namespace selectionné.
La vue répertorie les applications par type de charge de travail. (e.g., Deployments, Replica Sets, Stateful Sets, etc.) et chaque type de charge de travail peut être visualisé séparément.
Les listes récapitulent les informations exploitables sur les charges de travail, telles que le nombre de Pods prêts pour un Replica Set ou l'utilisation actuelle de la mémoire pour un Pod.</p><p>Les vues détaillées des charges de travail affichent des informations sur l'état et les spécifications, ainsi que les relations de surface entre les objets.
Par exemple, les Pods qu'un Replica Set controle ou bien les nouveaux Replica Sets et Horizontal Pod Autoscalers pour les Deployments.</p><h4 id=services>Services</h4><p>Affiche les ressources Kubernetes permettant d’exposer les services au monde externe et de les découvrir au sein d’un cluster.
Pour cette raison, les vues Service et Ingress montrent les Pods ciblés par eux, les points de terminaison internes pour les connexions au cluster et les points de terminaison externes pour les utilisateurs externes.</p><h4 id=stockage>Stockage</h4><p>La vue de stockage montre les ressources Persistent Volume Claim qui sont utilisées par les applications pour stocker des données.</p><h4 id=config-maps-et-secrets>Config Maps et Secrets</h4><p>Affiche toutes les ressources Kubernetes utilisées pour la configuration en temps réel d'applications s'exécutant dans des clusters.
La vue permet d’éditer et de gérer des objets de configuration et d’afficher les secrets cachés par défaut.</p><h4 id=visualisation-de-journaux>Visualisation de journaux</h4><p>Les listes de Pod et les pages de détail renvoient à une visionneuse de journaux intégrée au tableau de bord.
Le visualiseur permet d’exploiter les logs des conteneurs appartenant à un seul Pod.</p><p><img src=/images/docs/ui-dashboard-logs-view.png alt="Visualisation de journaux"></p><h2 id=a-suivre>A suivre</h2><p>Pour plus d'informations, voir la page du projet <a href=https://github.com/kubernetes/dashboard>Kubernetes Dashboard</a>.</p></div><div class=td-content style=page-break-before:always><h1 id=pg-5a233e14205d77fe1294917d2da6f876>5.8.2 - Configurer l'accès à plusieurs clusters</h1><p>Cette page montre comment configurer l'accès à plusieurs clusters à l'aide de fichiers de configuration.
Une fois vos clusters, utilisateurs et contextes définis dans un ou plusieurs fichiers de configuration, vous pouvez basculer rapidement entre les clusters en utilisant la commande <code>kubectl config use-context</code>.</p><div class="alert alert-info note callout" role=alert><strong>Note:</strong> Un fichier utilisé pour configurer l'accès à un cluster est parfois appelé <em>fichier kubeconfig</em>.
C'est une manière générique de se référer aux fichiers de configuration.
Cela ne signifie pas qu'il existe un fichier nommé <code>kubeconfig</code>.</div><h2 id=pré-requis>Pré-requis</h2><p>Vous devez disposer d'un cluster Kubernetes et l'outil de ligne de commande kubectl doit être configuré pour communiquer avec votre cluster.
Si vous ne possédez pas déjà de cluster, vous pouvez en créer un en utilisant <a href=/docs/setup/minikube>Minikube</a>, ou vous pouvez utiliser l'un de ces environnements Kubernetes:</p><ul><li><a href=https://killercoda.com/playgrounds/scenario/kubernetes>Killercoda</a></li><li><a href=http://labs.play-with-k8s.com/>Play with Kubernetes</a></li></ul><p>Pour vérifier que <a class=glossary-tooltip title='A command line tool for communicating with a Kubernetes cluster.' data-toggle=tooltip data-placement=top href=/docs/user-guide/kubectl-overview/ target=_blank aria-label=kubectl>kubectl</a> est installé, executez <code>kubectl version --client</code>.
La version kubectl doit être <a href=/docs/setup/release/version-skew-policy/#kubectl>dans une version mineure</a> de votre
serveur API du cluster.</p><h2 id=définir-des-clusters-des-utilisateurs-et-des-contextes>Définir des clusters, des utilisateurs et des contextes</h2><p>Supposons que vous ayez deux clusters, un pour le développement et un pour le travail <code>scratch</code>.
Dans le cluster <code>development</code>, vos développeurs frontend travaillent dans un espace de noms appelé <code>frontend</code>, et vos développeurs de stockage travaillent dans un espace de noms appelé <code>storage</code>.
Dans votre cluster <code>scratch</code>, les développeurs travaillent dans le namespace par défaut ou créent des namespaces auxiliaires comme bon leur semble.
L'accès au cluster <code>development</code> nécessite une authentification par certificat.
L'accès au cluster <code>scratch</code> nécessite une authentification par nom d'utilisateur et mot de passe.</p><p>Créez un répertoire nommé <code>config-exercice</code>.
Dans votre répertoire <code>config-exercice</code>, créez un fichier nommé <code>config-demo</code> avec ce contenu:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>apiVersion: v1
</span></span><span style=display:flex><span>kind: Config
</span></span><span style=display:flex><span>preferences: <span style=color:#666>{}</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>clusters:
</span></span><span style=display:flex><span>- cluster:
</span></span><span style=display:flex><span>  name: development
</span></span><span style=display:flex><span>- cluster:
</span></span><span style=display:flex><span>  name: scratch
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>users:
</span></span><span style=display:flex><span>- name: developer
</span></span><span style=display:flex><span>- name: experimenter
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>contexts:
</span></span><span style=display:flex><span>- context:
</span></span><span style=display:flex><span>  name: dev-frontend
</span></span><span style=display:flex><span>- context:
</span></span><span style=display:flex><span>  name: dev-storage
</span></span><span style=display:flex><span>- context:
</span></span><span style=display:flex><span>  name: exp-scratch
</span></span></code></pre></div><p>Un fichier de configuration décrit les clusters, les utilisateurs et les contextes.
Votre fichier <code>config-demo</code> a le cadre pour décrire deux clusters, deux utilisateurs et trois contextes.</p><p>Allez dans votre répertoire <code>config-exercice</code>.
Entrez ces commandes pour ajouter les détails du cluster à votre fichier de configuration:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl config --kubeconfig<span style=color:#666>=</span>config-demo set-cluster development --server<span style=color:#666>=</span>https://1.2.3.4 --certificate-authority<span style=color:#666>=</span>fake-ca-file
</span></span><span style=display:flex><span>kubectl config --kubeconfig<span style=color:#666>=</span>config-demo set-cluster scratch --server<span style=color:#666>=</span>https://5.6.7.8 --insecure-skip-tls-verify
</span></span></code></pre></div><p>Ajoutez les détails de l'utilisateur à votre fichier de configuration:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl config --kubeconfig<span style=color:#666>=</span>config-demo set-credentials developer --client-certificate<span style=color:#666>=</span>fake-cert-file --client-key<span style=color:#666>=</span>fake-key-seefile
</span></span><span style=display:flex><span>kubectl config --kubeconfig<span style=color:#666>=</span>config-demo set-credentials experimenter --username<span style=color:#666>=</span>exp --password<span style=color:#666>=</span>some-password
</span></span></code></pre></div><div class="alert alert-info note callout" role=alert><strong>Note:</strong><ul><li>Pour supprimer un utilisateur, vous pouvez exécuter <code>kubectl --kubeconfig=config-demo config unset users.&lt;name></code></li><li>Pour supprimer un cluster, vous pouvez exécuter <code>kubectl --kubeconfig=config-demo config unset clusters.&lt;name></code></li><li>Pour supprimer un contexte, vous pouvez exécuter <code>kubectl --kubeconfig=config-demo config unset contexts.&lt;name></code></li></ul></div><p>Ajoutez des détails de contexte à votre fichier de configuration:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl config --kubeconfig<span style=color:#666>=</span>config-demo set-context dev-frontend --cluster<span style=color:#666>=</span>development --namespace<span style=color:#666>=</span>frontend --user<span style=color:#666>=</span>developer
</span></span><span style=display:flex><span>kubectl config --kubeconfig<span style=color:#666>=</span>config-demo set-context dev-storage --cluster<span style=color:#666>=</span>development --namespace<span style=color:#666>=</span>storage --user<span style=color:#666>=</span>developer
</span></span><span style=display:flex><span>kubectl config --kubeconfig<span style=color:#666>=</span>config-demo set-context exp-scratch --cluster<span style=color:#666>=</span>scratch --namespace<span style=color:#666>=</span>default --user<span style=color:#666>=</span>experimenter
</span></span></code></pre></div><p>Ouvrez votre fichier <code>config-demo</code> pour voir les détails ajoutés.
Au lieu d'ouvrir le fichier <code>config-demo</code>, vous pouvez utiliser la commande <code>kubectl config view</code>.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl config --kubeconfig<span style=color:#666>=</span>config-demo view
</span></span></code></pre></div><p>La sortie montre les deux clusters, deux utilisateurs et trois contextes:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>apiVersion: v1
</span></span><span style=display:flex><span>clusters:
</span></span><span style=display:flex><span>- cluster:
</span></span><span style=display:flex><span>    certificate-authority: fake-ca-file
</span></span><span style=display:flex><span>    server: https://1.2.3.4
</span></span><span style=display:flex><span>  name: development
</span></span><span style=display:flex><span>- cluster:
</span></span><span style=display:flex><span>    insecure-skip-tls-verify: <span style=color:#a2f>true</span>
</span></span><span style=display:flex><span>    server: https://5.6.7.8
</span></span><span style=display:flex><span>  name: scratch
</span></span><span style=display:flex><span>contexts:
</span></span><span style=display:flex><span>- context:
</span></span><span style=display:flex><span>    cluster: development
</span></span><span style=display:flex><span>    namespace: frontend
</span></span><span style=display:flex><span>    user: developer
</span></span><span style=display:flex><span>  name: dev-frontend
</span></span><span style=display:flex><span>- context:
</span></span><span style=display:flex><span>    cluster: development
</span></span><span style=display:flex><span>    namespace: storage
</span></span><span style=display:flex><span>    user: developer
</span></span><span style=display:flex><span>  name: dev-storage
</span></span><span style=display:flex><span>- context:
</span></span><span style=display:flex><span>    cluster: scratch
</span></span><span style=display:flex><span>    namespace: default
</span></span><span style=display:flex><span>    user: experimenter
</span></span><span style=display:flex><span>  name: exp-scratch
</span></span><span style=display:flex><span>current-context: <span style=color:#b44>&#34;&#34;</span>
</span></span><span style=display:flex><span>kind: Config
</span></span><span style=display:flex><span>preferences: <span style=color:#666>{}</span>
</span></span><span style=display:flex><span>users:
</span></span><span style=display:flex><span>- name: developer
</span></span><span style=display:flex><span>  user:
</span></span><span style=display:flex><span>    client-certificate: fake-cert-file
</span></span><span style=display:flex><span>    client-key: fake-key-file
</span></span><span style=display:flex><span>- name: experimenter
</span></span><span style=display:flex><span>  user:
</span></span><span style=display:flex><span>    password: some-password
</span></span><span style=display:flex><span>    username: exp
</span></span></code></pre></div><p>Le <code>fake-ca-file</code>, <code>fake-cert-file</code> et <code>fake-key-file</code> ci-dessus sont les espaces réservés pour les noms de chemin des fichiers de certificat.
Vous devez les remplacer par les noms de chemin réels des fichiers de certificat dans votre environnement.</p><p>Parfois, vous souhaiterez peut-être utiliser des données encodées en Base64 incorporées ici au lieu de fichiers de certificat séparés; dans ce cas, vous devez ajouter le suffixe <code>-data</code> aux clés, par exemple, <code>certificate-Authority-data</code>, <code>client-certificate-data</code>, <code>client-key-data</code>.</p><p>Chaque contexte est un triplet (cluster, utilisateur, namespace).
Par exemple, le contexte <code>dev-frontend</code> dit, "Utilisez les informations d'identification de l'utilisateur <code>developer</code> pour accéder au namespace <code>frontend</code> du cluster <code>development</code>".</p><p>Définissez le contexte actuel:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl config --kubeconfig<span style=color:#666>=</span>config-demo use-context dev-frontend
</span></span></code></pre></div><p>Maintenant, chaque fois que vous entrez une commande <code>kubectl</code>, l'action s'appliquera au cluster et au namespace répertorié dans le contexte <code>dev-frontend</code>.
Et la commande utilisera les informations d'identification de l'utilisateur répertoriées dans le contexte <code>dev-frontend</code>.</p><p>Pour voir uniquement les informations de configuration associées au contexte actuel, utilisez l'indicateur <code>--minify</code>.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl config --kubeconfig<span style=color:#666>=</span>config-demo view --minify
</span></span></code></pre></div><p>La sortie affiche les informations de configuration associées au contexte <code>dev-frontend</code>:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>apiVersion: v1
</span></span><span style=display:flex><span>clusters:
</span></span><span style=display:flex><span>- cluster:
</span></span><span style=display:flex><span>    certificate-authority: fake-ca-file
</span></span><span style=display:flex><span>    server: https://1.2.3.4
</span></span><span style=display:flex><span>  name: development
</span></span><span style=display:flex><span>contexts:
</span></span><span style=display:flex><span>- context:
</span></span><span style=display:flex><span>    cluster: development
</span></span><span style=display:flex><span>    namespace: frontend
</span></span><span style=display:flex><span>    user: developer
</span></span><span style=display:flex><span>  name: dev-frontend
</span></span><span style=display:flex><span>current-context: dev-frontend
</span></span><span style=display:flex><span>kind: Config
</span></span><span style=display:flex><span>preferences: <span style=color:#666>{}</span>
</span></span><span style=display:flex><span>users:
</span></span><span style=display:flex><span>- name: developer
</span></span><span style=display:flex><span>  user:
</span></span><span style=display:flex><span>    client-certificate: fake-cert-file
</span></span><span style=display:flex><span>    client-key: fake-key-file
</span></span></code></pre></div><p>Supposons maintenant que vous souhaitiez travailler pendant un certain temps dans le cluster scratch.</p><p>Changez le contexte actuel en <code>exp-scratch</code>:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl config --kubeconfig<span style=color:#666>=</span>config-demo use-context exp-scratch
</span></span></code></pre></div><p>Maintenant, toute commande <code>kubectl</code> que vous donnez s'appliquera au namespace par défaut du cluster <code>scratch</code>.
Et la commande utilisera les informations d'identification de l'utilisateur répertoriées dans le contexte <code>exp-scratch</code>.</p><p>Afficher la configuration associée au nouveau contexte actuel, <code>exp-scratch</code>.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl config --kubeconfig<span style=color:#666>=</span>config-demo view --minify
</span></span></code></pre></div><p>Enfin, supposons que vous vouliez travailler pendant un certain temps dans le namespace <code>storage</code> du cluster <code>development</code>.</p><p>Changez le contexte actuel en <code>dev-storage</code>:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl config --kubeconfig<span style=color:#666>=</span>config-demo use-context dev-storage
</span></span></code></pre></div><p>Afficher la configuration associée au nouveau contexte actuel, <code>dev-storage</code>.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl config --kubeconfig<span style=color:#666>=</span>config-demo view --minify
</span></span></code></pre></div><h2 id=créer-un-deuxième-fichier-de-configuration>Créer un deuxième fichier de configuration</h2><p>Dans votre répertoire <code>config-exercice</code>, créez un fichier nommé <code>config-demo-2</code> avec ce contenu:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>apiVersion: v1
</span></span><span style=display:flex><span>kind: Config
</span></span><span style=display:flex><span>preferences: <span style=color:#666>{}</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>contexts:
</span></span><span style=display:flex><span>- context:
</span></span><span style=display:flex><span>    cluster: development
</span></span><span style=display:flex><span>    namespace: ramp
</span></span><span style=display:flex><span>    user: developer
</span></span><span style=display:flex><span>  name: dev-ramp-up
</span></span></code></pre></div><p>Le fichier de configuration précédent définit un nouveau contexte nommé <code>dev-ramp-up</code>.</p><h2 id=définissez-la-variable-d-environnement-kubeconfig>Définissez la variable d'environnement KUBECONFIG</h2><p>Vérifiez si vous avez une variable d'environnement nommée <code>KUBECONFIG</code>.
Si tel est le cas, enregistrez la valeur actuelle de votre variable d'environnement <code>KUBECONFIG</code>, afin de pouvoir la restaurer ultérieurement.
Par exemple:</p><h3 id=linux>Linux</h3><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span><span style=color:#a2f>export</span> <span style=color:#b8860b>KUBECONFIG_SAVED</span><span style=color:#666>=</span><span style=color:#b8860b>$KUBECONFIG</span>
</span></span></code></pre></div><h3 id=windows-powershell>Windows PowerShell</h3><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span><span style=color:#b8860b>$Env</span>:KUBECONFIG_SAVED<span style=color:#666>=</span><span style=color:#b8860b>$ENV</span>:KUBECONFIG
</span></span></code></pre></div><p>La variable d'environnement <code>KUBECONFIG</code> est une liste de chemins vers les fichiers de configuration.
La liste est délimitée par deux-points pour Linux et Mac et par des points-virgules pour Windows.
Si vous avez une variable d'environnement <code>KUBECONFIG</code>, familiarisez-vous avec les fichiers de configuration de la liste.</p><p>Ajoutez temporairement deux chemins à votre variable d'environnement <code>KUBECONFIG</code>.
Par exemple:</p><h3 id=linux-1>Linux</h3><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span><span style=color:#a2f>export</span> <span style=color:#b8860b>KUBECONFIG</span><span style=color:#666>=</span><span style=color:#b8860b>$KUBECONFIG</span>:config-demo:config-demo-2
</span></span></code></pre></div><h3 id=windows-powershell-1>Windows PowerShell</h3><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span><span style=color:#b8860b>$Env</span>:KUBECONFIG<span style=color:#666>=(</span><span style=color:#b44>&#34;config-demo;config-demo-2&#34;</span><span style=color:#666>)</span>
</span></span></code></pre></div><p>Dans votre répertoire <code>config-exercice</code>, entrez cette commande:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl config view
</span></span></code></pre></div><p>La sortie affiche les informations fusionnées de tous les fichiers répertoriés dans votre variable d'environnement <code>KUBECONFIG</code>.
En particulier, notez que les informations fusionnées ont le contexte <code>dev-ramp-up</code> du fichier <code>config-demo-2</code> et les trois contextes du fichier <code>config-demo</code>:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>contexts:
</span></span><span style=display:flex><span>- context:
</span></span><span style=display:flex><span>    cluster: development
</span></span><span style=display:flex><span>    namespace: frontend
</span></span><span style=display:flex><span>    user: developer
</span></span><span style=display:flex><span>  name: dev-frontend
</span></span><span style=display:flex><span>- context:
</span></span><span style=display:flex><span>    cluster: development
</span></span><span style=display:flex><span>    namespace: ramp
</span></span><span style=display:flex><span>    user: developer
</span></span><span style=display:flex><span>  name: dev-ramp-up
</span></span><span style=display:flex><span>- context:
</span></span><span style=display:flex><span>    cluster: development
</span></span><span style=display:flex><span>    namespace: storage
</span></span><span style=display:flex><span>    user: developer
</span></span><span style=display:flex><span>  name: dev-storage
</span></span><span style=display:flex><span>- context:
</span></span><span style=display:flex><span>    cluster: scratch
</span></span><span style=display:flex><span>    namespace: default
</span></span><span style=display:flex><span>    user: experimenter
</span></span><span style=display:flex><span>  name: exp-scratch
</span></span></code></pre></div><p>Pour plus d'informations sur la manière dont les fichiers kubeconfig sont fusionnés, consultez <a href=/docs/concepts/configuration/organize-cluster-access-kubeconfig/>Organisation de l'accès au cluster à l'aide des fichiers kubeconfig</a></p><h2 id=explorez-le-répertoire-home-kube>Explorez le répertoire $HOME/.kube</h2><p>Si vous avez déjà un cluster, et vous pouvez utiliser <code>kubectl</code> pour interagir avec le cluster, alors vous avez probablement un fichier nommé <code>config</code> dans le repertoire <code>$HOME/.kube</code>.</p><p>Allez dans <code>$ HOME/.kube</code>, et voyez quels fichiers sont là.
En règle générale, il existe un fichier nommé <code>config</code>.
Il peut également y avoir d'autres fichiers de configuration dans ce répertoire.
Familiarisez-vous brièvement avec le contenu de ces fichiers.</p><h2 id=ajoutez-home-kube-config-à-votre-variable-d-environnement-kubeconfig>Ajoutez $HOME/.kube/config à votre variable d'environnement KUBECONFIG</h2><p>Si vous avez un fichier <code>$ HOME/.kube/config</code>, et qu'il n'est pas déjà répertorié dans votre variable d'environnement <code>KUBECONFIG</code>, ajoutez-le maintenant à votre variable d'environnement <code>KUBECONFIG</code>.
Par exemple:</p><h3 id=linux-2>Linux</h3><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span><span style=color:#a2f>export</span> <span style=color:#b8860b>KUBECONFIG</span><span style=color:#666>=</span><span style=color:#b8860b>$KUBECONFIG</span>:<span style=color:#b8860b>$HOME</span>/.kube/config
</span></span></code></pre></div><h3 id=windows-powershell-2>Windows Powershell</h3><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span><span style=color:#b8860b>$Env</span>:KUBECONFIG<span style=color:#666>=</span><span style=color:#b44>&#34;</span><span style=color:#b8860b>$Env</span><span style=color:#b44>:KUBECONFIG;</span><span style=color:#b8860b>$HOME</span><span style=color:#b44>\.kube\config&#34;</span>
</span></span></code></pre></div><p>Affichez les informations de configuration fusionnées à partir de tous les fichiers qui sont maintenant répertoriés dans votre variable d'environnement <code>KUBECONFIG</code>.
Dans votre répertoire config-exercice, entrez:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl config view
</span></span></code></pre></div><h2 id=nettoyage>Nettoyage</h2><p>Remettez votre variable d'environnement <code>KUBECONFIG</code> à sa valeur d'origine.</p><p>Par exemple:</p><h3 id=linux-3>Linux</h3><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span><span style=color:#a2f>export</span> <span style=color:#b8860b>KUBECONFIG</span><span style=color:#666>=</span><span style=color:#b8860b>$KUBECONFIG_SAVED</span>
</span></span></code></pre></div><h3 id=windows-powershell-3>Windows PowerShell</h3><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span><span style=color:#b8860b>$Env</span>:KUBECONFIG<span style=color:#666>=</span><span style=color:#b8860b>$ENV</span>:KUBECONFIG_SAVED
</span></span></code></pre></div><h2 id=a-suivre>A suivre</h2><ul><li><a href=/docs/concepts/configuration/organize-cluster-access-kubeconfig/>Organisation de l'accès au cluster à l'aide des fichiers kubeconfig</a></li><li><a href=/docs/reference/generated/kubectl/kubectl-commands#config>kubectl config</a></li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-48e8f306f919c5b81265e265a2b76ab4>5.8.3 - Lister toutes les images de conteneur exécutées dans un cluster</h1><p>Cette page montre comment utiliser kubectl pour répertorier toutes les images de conteneur pour les pods s'exécutant dans un cluster.</p><h2 id=pré-requis>Pré-requis</h2><p><p>Vous devez disposer d'un cluster Kubernetes et l'outil de ligne de commande kubectl doit être configuré pour communiquer avec votre cluster.
Si vous ne possédez pas déjà de cluster, vous pouvez en créer un en utilisant <a href=/docs/setup/minikube>Minikube</a>, ou vous pouvez utiliser l'un de ces environnements Kubernetes:</p><ul><li><a href=https://killercoda.com/playgrounds/scenario/kubernetes>Killercoda</a></li><li><a href=http://labs.play-with-k8s.com/>Play with Kubernetes</a></li></ul>Pour consulter la version, entrez <code>kubectl version</code>.</p><p>Dans cet exercice, vous allez utiliser kubectl pour récupérer tous les pods exécutés dans un cluster et formater la sortie pour extraire la liste des conteneurs pour chacun.</p><h2 id=répertorier-toutes-les-images-de-conteneurs-dans-tous-les-namespaces>Répertorier toutes les images de conteneurs dans tous les namespaces</h2><ul><li>Récupérez tous les pods dans tous les namespace à l'aide de <code>kubectl get pods --all-namespaces</code></li><li>Formatez la sortie pour inclure uniquement la liste des noms d'image de conteneur à l'aide de <code>-o jsonpath={.items[*].spec.containers[*].image}</code>.
Cela analysera récursivement le champ <code>image</code> du json retourné.<ul><li>Voir la <a href=/docs/reference/kubectl/jsonpath/>reference jsonpath</a> pour plus d'informations sur l'utilisation de jsonpath.</li></ul></li><li>Formatez la sortie à l'aide des outils standard: <code>tr</code>, <code>sort</code>, <code>uniq</code><ul><li>Utilisez <code>tr</code> pour remplacer les espaces par des nouvelles lignes</li><li>Utilisez <code>sort</code> pour trier les résultats</li><li>Utilisez <code>uniq</code> pour agréger le nombre d'images</li></ul></li></ul><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get pods --all-namespaces -o <span style=color:#b8860b>jsonpath</span><span style=color:#666>=</span><span style=color:#b44>&#34;{.items[*].spec.containers[*].image}&#34;</span> |<span style=color:#b62;font-weight:700>\
</span></span></span><span style=display:flex><span><span style=color:#b62;font-weight:700></span>tr -s <span style=color:#b44>&#39;[[:space:]]&#39;</span> <span style=color:#b44>&#39;\n&#39;</span> |<span style=color:#b62;font-weight:700>\
</span></span></span><span style=display:flex><span><span style=color:#b62;font-weight:700></span>sort |<span style=color:#b62;font-weight:700>\
</span></span></span><span style=display:flex><span><span style=color:#b62;font-weight:700></span>uniq -c
</span></span></code></pre></div><p>La commande ci-dessus renverra récursivement tous les champs nommés <code>image</code> pour tous les éléments retournés.</p><p>Comme alternative, il est possible d'utiliser le chemin absolu vers le champ d'image dans le Pod.
Cela garantit que le champ correct est récupéré même lorsque le nom du champ est répété, par ex. de nombreux champs sont appelés <code>name</code> dans un élément donné:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get pods --all-namespaces -o <span style=color:#b8860b>jsonpath</span><span style=color:#666>=</span><span style=color:#b44>&#34;{.items[*].spec.containers[*].image}&#34;</span>
</span></span></code></pre></div><p>Le jsonpath est interprété comme suit:</p><ul><li><code>.items[*]</code>: pour chaque valeur renvoyée</li><li><code>.spec</code>: obtenir les spécifications</li><li><code>.containers[*]</code>: pour chaque conteneur</li><li><code>.image</code>: obtenir l'image</li></ul><div class="alert alert-info note callout" role=alert><strong>Note:</strong> Lors de la récupération d'un seul pod par son nom, par exemple <code>kubectl get pod nginx</code>, la portion <code>.items[*]</code> du chemin doit être omis car un seul pod est renvoyé au lieu d'une liste d'éléments.</div><h2 id=liste-des-images-de-conteneurs-par-pod>Liste des images de conteneurs par pod</h2><p>Le formatage peut être contrôlé davantage en utilisant l'opération <code>range</code> pour parcourir les éléments individuellement.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get pods --all-namespaces -o <span style=color:#b8860b>jsonpath</span><span style=color:#666>=</span><span style=color:#b44>&#39;{range .items[*]}{&#34;\n&#34;}{.metadata.name}{&#34;:\t&#34;}{range .spec.containers[*]}{.image}{&#34;, &#34;}{end}{end}&#39;</span> |<span style=color:#b62;font-weight:700>\
</span></span></span><span style=display:flex><span><span style=color:#b62;font-weight:700></span>sort
</span></span></code></pre></div><h2 id=filtrage-des-images-de-conteneur-de-liste-par-label-de-pod>Filtrage des images de conteneur de liste par label de pod</h2><p>Pour cibler uniquement les pods correspondant à un label spécifique, utilisez l'indicateur -l.
Les éléments suivants correspondent uniquement aux pods avec les labels <code>app=nginx</code>.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get pods --all-namespaces -o <span style=color:#b8860b>jsonpath</span><span style=color:#666>=</span><span style=color:#b44>&#34;{.items[*].spec.containers[*].image}&#34;</span> -l <span style=color:#b8860b>app</span><span style=color:#666>=</span>nginx
</span></span></code></pre></div><h2 id=filtrage-des-images-de-conteneur-de-liste-par-namespace-de-pod>Filtrage des images de conteneur de liste par namespace de pod</h2><p>Pour cibler uniquement les pods dans un namespace spécifique, utilisez l'indicateur de namespace.
Ce qui suit correspond uniquement aux pods du namespace <code>kube-system</code>.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get pods --namespace kube-system -o <span style=color:#b8860b>jsonpath</span><span style=color:#666>=</span><span style=color:#b44>&#34;{.items[*].spec.containers[*].image}&#34;</span>
</span></span></code></pre></div><h2 id=répertorier-les-images-de-conteneurs-en-utilisant-un-go-template-au-lieu-de-jsonpath>Répertorier les images de conteneurs en utilisant un go-template au lieu de jsonpath</h2><p>Comme alternative à jsonpath, Kubectl peut aussi utiliser les <a href=https://golang.org/pkg/text/template/>go-templates</a> pour formater la sortie:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get pods --all-namespaces -o go-template --template<span style=color:#666>=</span><span style=color:#b44>&#34;{{range .items}}{{range .spec.containers}}{{.image}} {{end}}{{end}}&#34;</span>
</span></span></code></pre></div><h2 id=a-suivre>A suivre</h2><h3 id=reference>Reference</h3><ul><li>Guide de référence pour <a href=/docs/reference/kubectl/jsonpath/>Jsonpath</a></li><li>Guide de référence pour les <a href=https://golang.org/pkg/text/template/>Go template</a></li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-f6a755efe831d24956501e4bcd49ff96>5.9 - Monitoring, Logging et Debugging</h1></div><div class=td-content><h1 id=pg-9713ac27b6d9e3034033200d968221f2>5.9.1 - Obtenez un shell dans un conteneur en cours d'exécution</h1><p>Cette page montre comment utiliser <code>kubectl exec</code> pour obtenir un shell dans un conteneur en cours d'exécution.</p><h2 id=pré-requis>Pré-requis</h2><p><p>Vous devez disposer d'un cluster Kubernetes et l'outil de ligne de commande kubectl doit être configuré pour communiquer avec votre cluster.
Si vous ne possédez pas déjà de cluster, vous pouvez en créer un en utilisant <a href=/docs/setup/minikube>Minikube</a>, ou vous pouvez utiliser l'un de ces environnements Kubernetes:</p><ul><li><a href=https://killercoda.com/playgrounds/scenario/kubernetes>Killercoda</a></li><li><a href=http://labs.play-with-k8s.com/>Play with Kubernetes</a></li></ul>Pour consulter la version, entrez <code>kubectl version</code>.</p><h2 id=obtenir-un-shell-dans-un-conteneur>Obtenir un shell dans un conteneur</h2><p>Dans cet exercice, vous allez créer un pod contenant un conteneur.
Le conteneur exécute une image nginx.
Voici le fichier de configuration du Pod:</p><div class=highlight><div class=copy-code-icon style=text-align:right><a href=https://raw.githubusercontent.com/kubernetes/website/main/content/fr/examples/application/shell-demo.yaml download=application/shell-demo.yaml><code>application/shell-demo.yaml</code></a>
<img src=/images/copycode.svg style=max-height:24px;cursor:pointer onclick='copyCode("application-shell-demo-yaml")' title="Copy application/shell-demo.yaml to clipboard"></img></div><div class=includecode id=application-shell-demo-yaml><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>shell-demo<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>volumes</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>shared-data<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>emptyDir</span>:<span style=color:#bbb> </span>{}<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>nginx<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>nginx<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>volumeMounts</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>shared-data<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>mountPath</span>:<span style=color:#bbb> </span>/usr/share/nginx/html<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>hostNetwork</span>:<span style=color:#bbb> </span><span style=color:#a2f;font-weight:700>true</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>dnsPolicy</span>:<span style=color:#bbb> </span>Default<span style=color:#bbb>
</span></span></span></code></pre></div></div></div><p>Créez le Pod:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl apply -f https://k8s.io/examples/application/shell-demo.yaml
</span></span></code></pre></div><p>Vérifiez que le conteneur est en cours d'exécution:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get pod shell-demo
</span></span></code></pre></div><p>Obtenez un shell pour le conteneur en cours d'exécution:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl <span style=color:#a2f>exec</span> -it shell-demo -- /bin/bash
</span></span></code></pre></div><div class="alert alert-info note callout" role=alert><strong>Note:</strong> Le double tiret "-" est utilisé pour séparer les arguments que vous souhaitez passer à la commande des arguments kubectl.</div><p>Dans votre shell, listez le répertoire racine:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>root@shell-demo:/# ls /
</span></span></code></pre></div><p>Dans votre shell, testez d'autres commandes.
Voici quelques exemples:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>root@shell-demo:/# ls /
</span></span><span style=display:flex><span>root@shell-demo:/# cat /proc/mounts
</span></span><span style=display:flex><span>root@shell-demo:/# cat /proc/1/maps
</span></span><span style=display:flex><span>root@shell-demo:/# apt-get update
</span></span><span style=display:flex><span>root@shell-demo:/# apt-get install -y tcpdump
</span></span><span style=display:flex><span>root@shell-demo:/# tcpdump
</span></span><span style=display:flex><span>root@shell-demo:/# apt-get install -y lsof
</span></span><span style=display:flex><span>root@shell-demo:/# lsof
</span></span><span style=display:flex><span>root@shell-demo:/# apt-get install -y procps
</span></span><span style=display:flex><span>root@shell-demo:/# ps aux
</span></span><span style=display:flex><span>root@shell-demo:/# ps aux | grep nginx
</span></span></code></pre></div><h2 id=écriture-de-la-page-racine-de-nginx>Écriture de la page racine de nginx</h2><p>Regardez à nouveau le fichier de configuration de votre Pod.
Le pod a un volume <code>emptyDir</code> et le conteneur monte le volume dans <code>/usr/share/nginx/html</code>.</p><p>Dans votre shell, créez un fichier <code>index.html</code> dans le répertoire <code>/usr/share/nginx/html</code>:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>root@shell-demo:/# <span style=color:#a2f>echo</span> Hello shell demo &gt; /usr/share/nginx/html/index.html
</span></span></code></pre></div><p>Dans votre shell, envoyez une requête GET au serveur nginx:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>root@shell-demo:/# apt-get update
</span></span><span style=display:flex><span>root@shell-demo:/# apt-get install curl
</span></span><span style=display:flex><span>root@shell-demo:/# curl localhost
</span></span></code></pre></div><p>La sortie affiche le texte que vous avez écrit dans le fichier <code>index.html</code>:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>Hello shell demo
</span></span></code></pre></div><p>Lorsque vous avez terminé avec votre shell, entrez <code>exit</code>.</p><h2 id=exécution-de-commandes-individuelles-dans-un-conteneur>Exécution de commandes individuelles dans un conteneur</h2><p>Dans une fenêtre de commande ordinaire, pas votre shell, répertoriez les variables d'environnement dans le conteneur en cours d'exécution:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl <span style=color:#a2f>exec</span> shell-demo env
</span></span></code></pre></div><p>Essayez d'exécuter d'autres commandes.
Voici quelques exemples:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl <span style=color:#a2f>exec</span> shell-demo ps aux
</span></span><span style=display:flex><span>kubectl <span style=color:#a2f>exec</span> shell-demo ls /
</span></span><span style=display:flex><span>kubectl <span style=color:#a2f>exec</span> shell-demo cat /proc/1/mounts
</span></span></code></pre></div><h2 id=ouverture-d-un-shell-lorsqu-un-pod-possède-plusieurs-conteneurs>Ouverture d'un shell lorsqu'un pod possède plusieurs conteneurs</h2><p>Si un pod a plusieurs conteneurs, utilisez <code>--container</code> ou <code>-c</code> pour spécifier un conteneur dans la commande <code>kubectl exec</code>.
Par exemple, supposons que vous ayez un pod nommé my-pod et que le pod ait deux conteneurs nommés main-app et helper-app.
La commande suivante ouvrirait un shell sur le conteneur de l'application principale.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl <span style=color:#a2f>exec</span> -it my-pod --container main-app -- /bin/bash
</span></span></code></pre></div><h2 id=a-suivre>A suivre</h2><ul><li><a href=/docs/reference/generated/kubectl/kubectl-commands/#exec>kubectl exec</a></li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-fd78dc15c135dedc24438431769d4d5b>5.10 - Extensions de Kubernetes</h1></div><div class=td-content><h1 id=pg-5b9d7df11699e8cb1a5a4414ff770efe>5.10.1 - Utilisation des ressources personnalisées</h1></div><div class=td-content style=page-break-before:always><h1 id=pg-d3c88a8663f58e9ec0bed73faff5b670>5.11 - TLS</h1></div><div class=td-content style=page-break-before:always><h1 id=pg-40e9293a348cfa50147082afc09ff77f>5.12 - Fédération</h1></div><div class=td-content><h1 id=pg-b61e5206fb2a30cabe2857ed4aaf7944>5.12.1 - Administration du Control Plane de la fédération</h1></div><div class=td-content style=page-break-before:always><h1 id=pg-ba58efa15c6d46f10e34d799be220965>5.13 - Gestion des démons du cluster</h1></div><div class=td-content style=page-break-before:always><h1 id=pg-5266308e17490aeee8b018316bf47e03>5.14 - Installation du catalogue de services</h1></div><div class=td-content style=page-break-before:always><h1 id=pg-68ec2370d0409cc27325be36693f9368>6 - Tutoriels</h1><p>Cette section de la documentation de Kubernetes contient des tutoriels.</p><p>Un tutoriel montre comment atteindre un objectif qui est plus grand qu'une simple <a href=/docs/tasks/>tâche</a>. Il contient différentes sections, et une section contient différentes étapes.</p><p>Avant d'explorer chacun des tutoriels, il peut-être utile de garder un signet pour le <a href=/docs/reference/glossary/>Glossaire standardisé</a> pour pouvoir le consulter plus facilement par la suite.</p><h2 id=elémentaires>Elémentaires</h2><ul><li><p><a href=/docs/tutorials/kubernetes-basics/>Kubernetes Élémentaire (EN)</a> est un tutoriel interactif en profondeur qui vous aidera à comprendre le système de Kubernetes et de commencer avec des fonctionnalités élémentaires de Kubernetes.</p></li><li><p><a href=https://www.udacity.com/course/scalable-microservices-with-kubernetes--ud615>Microservices Evolutifs avec Kubernetes (Udacity) (EN)</a></p></li><li><p><a href=https://www.edx.org/course/introduction-kubernetes-linuxfoundationx-lfs158x#>Introduction à Kubernetes (edX) (EN)</a></p></li><li><p><a href=/fr/docs/tutorials/hello-minikube/>Bonjour Minikube!(FR)</a></p></li></ul><h2 id=configuration>Configuration</h2><ul><li><a href=/docs/tutorials/configuration/configure-redis-using-configmap/>Configurer Redis en utilisant un ConfigMap (EN)</a></li></ul><h2 id=applications-sans-états-stateless-applications>Applications Sans États (stateless applications)</h2><ul><li><p><a href=/docs/tutorials/stateless-application/expose-external-ip-address/>Exposer une adresse IP externe pour accéder a une application dans un cluster (EN)</a></p></li><li><p><a href=/docs/tutorials/stateless-application/guestbook/>Exemple: Déployer l'application PHP Guestbook avec Redis (EN)</a></p></li></ul><h2 id=applications-avec-états-stateful-applications>Applications Avec États (stateful applications)</h2><ul><li><p><a href=/docs/tutorials/stateful-application/basic-stateful-set/>StatefulSet Élémentaire (EN)</a></p></li><li><p><a href=/docs/tutorials/stateful-application/mysql-wordpress-persistent-volume/>Exemple: WordPress et MySQL avec des Persistent Volumes (volumes persistants) (EN)</a></p></li><li><p><a href=/docs/tutorials/stateful-application/cassandra/>Exemple: Déployer Cassandra avec un StatefulSet (EN)</a></p></li><li><p><a href=/docs/tutorials/stateful-application/zookeeper/>Exécuter ZooKeeper, un système distribué CP (EN)</a></p></li></ul><h2 id=clusters>Clusters</h2><ul><li><a href=/docs/tutorials/clusters/apparmor/>AppArmor (EN)</a></li></ul><h2 id=services>Services</h2><ul><li><a href=/docs/tutorials/services/source-ip/>Utiliser Source IP (EN)</a></li></ul><h2 id=a-suivre>A suivre</h2><p>Si vous voulez écrire un tutoriel, regardez la section des modèles de page de tutoriel dans l'<a href=/docs/home/contribute/page-templates/>Utilisation des modèles de pages </a>.</p></div><div class=td-content style=page-break-before:always><h1 id=pg-5e3051fff9e84735871d9fb5e7b93f33>6.1 - Hello Minikube</h1><div class=lead>Tutoriel Minikube</div><p>Ce tutoriel vous montre comment exécuter une simple application Hello World Node.js sur Kubernetes en utilisant <a href=/docs/getting-started-guides/minikube/>Minikube</a> et Katacoda.
Katacoda fournit un environnement Kubernetes gratuit dans le navigateur.</p><div class="alert alert-info note callout" role=alert><strong>Note:</strong> Vous pouvez également suivre ce tutoriel si vous avez installé <a href=/docs/tasks/tools/install-minikube/>Minikube localement</a>.</div><h2 id=objectifs>Objectifs</h2><ul><li>Déployez une application Hello World sur Minikube.</li><li>Lancez l'application.</li><li>Afficher les journaux des applications.</li></ul><h2 id=pré-requis>Pré-requis</h2><p>Ce tutoriel fournit une image de conteneur construite à partir des fichiers suivants :</p><div class=highlight><div class=copy-code-icon style=text-align:right><a href=https://raw.githubusercontent.com/kubernetes/website/main/content/fr/examples/minikube/server.js download=minikube/server.js><code>minikube/server.js</code></a>
<img src=/images/copycode.svg style=max-height:24px;cursor:pointer onclick='copyCode("minikube-server-js")' title="Copy minikube/server.js to clipboard"></img></div><div class=includecode id=minikube-server-js><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-js data-lang=js><span style=display:flex><span><span style=color:#a2f;font-weight:700>var</span> http <span style=color:#666>=</span> require(<span style=color:#b44>&#39;http&#39;</span>);
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#a2f;font-weight:700>var</span> handleRequest <span style=color:#666>=</span> <span style=color:#a2f;font-weight:700>function</span>(request, response) {
</span></span><span style=display:flex><span>  console.log(<span style=color:#b44>&#39;Received request for URL: &#39;</span> <span style=color:#666>+</span> request.url);
</span></span><span style=display:flex><span>  response.writeHead(<span style=color:#666>200</span>);
</span></span><span style=display:flex><span>  response.end(<span style=color:#b44>&#39;Hello World!&#39;</span>);
</span></span><span style=display:flex><span>};
</span></span><span style=display:flex><span><span style=color:#a2f;font-weight:700>var</span> www <span style=color:#666>=</span> http.createServer(handleRequest);
</span></span><span style=display:flex><span>www.listen(<span style=color:#666>8080</span>);
</span></span></code></pre></div></div></div><div class=highlight><div class=copy-code-icon style=text-align:right><a href=https://raw.githubusercontent.com/kubernetes/website/main/content/fr/examples/minikube/Dockerfile download=minikube/Dockerfile><code>minikube/Dockerfile</code></a>
<img src=/images/copycode.svg style=max-height:24px;cursor:pointer onclick='copyCode("minikube-dockerfile")' title="Copy minikube/Dockerfile to clipboard"></img></div><div class=includecode id=minikube-dockerfile><pre tabindex=0><code class=language-conf data-lang=conf>FROM node:6.14.2
EXPOSE 8080
COPY server.js .
CMD node server.js
</code></pre></div></div><p>Pour plus d'informations sur la commande <code>docker build</code>, lisez la documentation de <a href=https://docs.docker.com/engine/reference/commandline/build/>Docker</a>.</p><h2 id=créer-un-cluster-minikube>Créer un cluster Minikube</h2><ol><li><p>Cliquez sur <strong>Lancer le terminal</strong>.</p><script defer src=https://katacoda.com/embed.js></script>
<button class=button onclick=window.katacoda.init()>Launch Terminal</button><div class="alert alert-info note callout" role=alert><strong>Note:</strong> Si vous avez installé Minikube localement, lancez <code>minikube start</code>.</div></li><li><p>Ouvrez le tableau de bord Kubernetes dans un navigateur :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>minikube dashboard
</span></span></code></pre></div></li><li><p>Environnement Katacoda seulement : En haut du volet du terminal, cliquez sur le signe plus, puis cliquez sur <strong>Sélectionner le port pour afficher sur l'hôte 1</strong>.</p></li><li><p>Environnement Katacoda seulement : Tapez <code>30000</code>, puis cliquez sur <strong>Afficher le port</strong>.</p></li></ol><h2 id=créer-un-déploiement>Créer un déploiement</h2><p>Un <a href=/fr/docs/concepts/workloads/pods/pod/><em>Pod</em></a> Kubernetes est un groupe d'un ou plusieurs conteneurs, liés entre eux à des fins d'administration et de mise en réseau.
Dans ce tutoriel, le Pod n'a qu'un seul conteneur.
Un <a href=/docs/concepts/workloads/controllers/deployment/><em>Déploiement</em></a> Kubernetes vérifie l'état de santé de votre Pod et redémarre le conteneur du Pod s'il se termine.
Les déploiements sont le moyen recommandé pour gérer la création et la mise à l'échelle des Pods.</p><ol><li><p>Utilisez la commande <code>kubectl create</code> pour créer un déploiement qui gère un Pod. Le
Pod utilise un conteneur basé sur l'image Docker fournie.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl create deployment hello-node --image<span style=color:#666>=</span>k8s.gcr.io/echoserver:1.4
</span></span></code></pre></div></li><li><p>Affichez le déploiement :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get deployments
</span></span></code></pre></div><p>Sortie :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>NAME         DESIRED   CURRENT   UP-TO-DATE   AVAILABLE   AGE
</span></span><span style=display:flex><span>hello-node   <span style=color:#666>1</span>         <span style=color:#666>1</span>         <span style=color:#666>1</span>            <span style=color:#666>1</span>           1m
</span></span></code></pre></div></li><li><p>Voir le Pod :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get pods
</span></span></code></pre></div><p>Sortie :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>NAME                          READY     STATUS    RESTARTS   AGE
</span></span><span style=display:flex><span>hello-node-5f76cf6ccf-br9b5   1/1       Running   <span style=color:#666>0</span>          1m
</span></span></code></pre></div></li><li><p>Afficher les événements du cluster :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get events
</span></span></code></pre></div></li><li><p>Voir la configuration de <code>kubectl</code> :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl config view
</span></span></code></pre></div><p><div class="alert alert-info note callout" role=alert><strong>Note:</strong> Pour plus d'informations sur les commandes <code>kubectl</code>, voir la <a href=/docs/user-guide/kubectl-overview/>vue d'ensemble de kubectl</a></div>.</p></li></ol><h2 id=créer-un-service>Créer un service</h2><p>Par défaut, le Pod n'est accessible que par son adresse IP interne dans le cluster Kubernetes.
Pour rendre le conteneur <code>hello-node</code> accessible depuis l'extérieur du réseau virtuel Kubernetes, vous devez exposer le Pod comme un <a href=/docs/concepts/services-networking/service/><em>Service</em></a> Kubernetes.</p><ol><li><p>Exposez le Pod à internet en utilisant la commande <code>kubectl expose</code> :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl expose deployment hello-node --type<span style=color:#666>=</span>LoadBalancer --port<span style=color:#666>=</span><span style=color:#666>8080</span>
</span></span></code></pre></div><p>L'indicateur <code>--type=LoadBalancer</code> indique que vous voulez exposer votre Service
à l'extérieur du cluster.</p></li><li><p>Affichez le Service que vous venez de créer :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get services
</span></span></code></pre></div><p>Sortie :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>NAME         TYPE           CLUSTER-IP      EXTERNAL-IP   PORT<span style=color:#666>(</span>S<span style=color:#666>)</span>          AGE
</span></span><span style=display:flex><span>hello-node   LoadBalancer   10.108.144.78   &lt;pending&gt;     8080:30369/TCP   21s
</span></span><span style=display:flex><span>kubernetes   ClusterIP      10.96.0.1       &lt;none&gt;        443/TCP          23m
</span></span></code></pre></div><p>Sur les fournisseurs de cloud qui supportent les load balancers, une adresse IP externe serait fournie pour accéder au Service.
Sur Minikube, le type <code>LoadBalancer</code> rend le Service accessible via la commande <code>minikube service</code>.</p></li><li><p>Exécutez la commande suivante :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>minikube service hello-node
</span></span></code></pre></div></li><li><p>Environnement Katacoda seulement : Cliquez sur le signe plus, puis cliquez sur <strong>Sélectionner le port pour afficher sur l'hôte 1</strong>.</p></li><li><p>Environnement Katacoda seulement : Tapez <code>30369</code> (voir port en face de <code>8080</code> dans la sortie services), puis cliquez sur <strong>Afficher le port</strong>.</p><p>Cela ouvre une fenêtre de navigateur qui sert votre application et affiche le message <code>Hello World</code>.</p></li></ol><h2 id=activer-les-extensions>Activer les extensions</h2><p>Minikube dispose d'un ensemble d'extensions intégrées qui peuvent être activées, désactivées et ouvertes dans l'environnement Kubernetes local.</p><ol><li><p>Énumérer les extensions actuellement pris en charge :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>minikube addons list
</span></span></code></pre></div><p>Sortie:</p><pre tabindex=0><code>addon-manager: enabled
coredns: disabled
dashboard: enabled
default-storageclass: enabled
efk: disabled
freshpod: disabled
heapster: disabled
ingress: disabled
kube-dns: enabled
metrics-server: disabled
nvidia-driver-installer: disabled
nvidia-gpu-device-plugin: disabled
registry: disabled
registry-creds: disabled
storage-provisioner: enabled
</code></pre></li><li><p>Activez une extension, par exemple, <code>heapster</code> :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>minikube addons <span style=color:#a2f>enable</span> heapster
</span></span></code></pre></div><p>Sortie :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>heapster was successfully enabled
</span></span></code></pre></div></li><li><p>Affichez le pod et le service que vous venez de créer :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get pod,svc -n kube-system
</span></span></code></pre></div><p>Sortie :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>NAME                                        READY     STATUS    RESTARTS   AGE
</span></span><span style=display:flex><span>pod/heapster-9jttx                          1/1       Running   <span style=color:#666>0</span>          26s
</span></span><span style=display:flex><span>pod/influxdb-grafana-b29w8                  2/2       Running   <span style=color:#666>0</span>          26s
</span></span><span style=display:flex><span>pod/kube-addon-manager-minikube             1/1       Running   <span style=color:#666>0</span>          34m
</span></span><span style=display:flex><span>pod/kube-dns-6dcb57bcc8-gv7mw               3/3       Running   <span style=color:#666>0</span>          34m
</span></span><span style=display:flex><span>pod/kubernetes-dashboard-5498ccf677-cgspw   1/1       Running   <span style=color:#666>0</span>          34m
</span></span><span style=display:flex><span>pod/storage-provisioner                     1/1       Running   <span style=color:#666>0</span>          34m
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>NAME                           TYPE        CLUSTER-IP      EXTERNAL-IP   PORT<span style=color:#666>(</span>S<span style=color:#666>)</span>             AGE
</span></span><span style=display:flex><span>service/heapster               ClusterIP   10.96.241.45    &lt;none&gt;        80/TCP              26s
</span></span><span style=display:flex><span>service/kube-dns               ClusterIP   10.96.0.10      &lt;none&gt;        53/UDP,53/TCP       34m
</span></span><span style=display:flex><span>service/kubernetes-dashboard   NodePort    10.109.29.1     &lt;none&gt;        80:30000/TCP        34m
</span></span><span style=display:flex><span>service/monitoring-grafana     NodePort    10.99.24.54     &lt;none&gt;        80:30002/TCP        26s
</span></span><span style=display:flex><span>service/monitoring-influxdb    ClusterIP   10.111.169.94   &lt;none&gt;        8083/TCP,8086/TCP   26s
</span></span></code></pre></div></li><li><p>Désactivez <code>heapster</code> :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>minikube addons disable heapster
</span></span></code></pre></div><p>Sortie :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>heapster was successfully disabled
</span></span></code></pre></div></li></ol><h2 id=nettoyage>Nettoyage</h2><p>Vous pouvez maintenant nettoyer les ressources que vous avez créées dans votre cluster :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl delete service hello-node
</span></span><span style=display:flex><span>kubectl delete deployment hello-node
</span></span></code></pre></div><p>Si nécessaire, arrêtez la machine virtuelle Minikube (VM) :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>minikube stop
</span></span></code></pre></div><p>Si nécessaire, effacez la VM Minikube :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>minikube delete
</span></span></code></pre></div><h2 id=a-suivre>A suivre</h2><ul><li>En savoir plus sur les <a href=/docs/concepts/workloads/controllers/deployment/>déploiement</a>.</li><li>En savoir plus sur le <a href=/docs/user-guide/deploying-applications/>Déploiement d'applications</a>.</li><li>En savoir plus sur les <a href=/docs/concepts/services-networking/service/>Services</a>.</li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-3c83f53a74233ace9b289ac5e24c3e62>6.2 - Apprendre les bases de Kubernetes</h1><!doctype html><html lang=fr><body><link href=/docs/tutorials/kubernetes-basics/public/css/styles.css rel=stylesheet><div class=layout id=top><main class=content><div class=row><div class=col-md-9><h2>Les bases de Kubernetes</h2><p>Ce tutoriel offre une présentation des bases du système d’orchestration de cluster Kubernetes. Chaque module contient des informations de base sur les principales caractéristiques et concepts de Kubernetes, ainsi qu'un didacticiel en ligne interactif. Ces tutoriels interactifs vous permettent de gérer vous-même un cluster simple et ses applications conteneurisées.</p><p>À l'aide des didacticiels interactifs, vous pouvez apprendre à:</p><ul><li>Déployer une application conteneurisée sur un cluster</li><li>Passage à l'échelle du déploiement</li><li>Mettre à jour l'application conteneurisée avec une nouvelle version du logiciel</li><li>Déboguer l'application conteneurisée</li></ul><p>Les didacticiels utilisent Katacoda pour exécuter un navigateur virtuel dans votre navigateur Web, qui exécute Minikube, un déploiement local à petite échelle de Kubernetes pouvant être exécuté n’importe où. Il n'est pas nécessaire d'installer un logiciel ou de configurer quoi que ce soit; chaque didacticiel interactif s’exécute directement à partir de votre navigateur Web.</p></div></div><br><div class=row><div class=col-md-9><h2>Qu'est-ce que Kubernetes peut faire pour vous?</h2><p>Avec les services Web modernes, les utilisateurs s'attendent à ce que les applications soient disponibles 24 heures sur 24, 7 jours sur 7 et les développeurs prévoient de déployer de nouvelles versions de ces applications plusieurs fois par jour. La conteneurisation aide les progiciels à atteindre ces objectifs, en permettant aux applications d'être publiées et mises à jour de manière simple et rapide sans temps d'arrêt. Kubernetes vous aide à vous assurer que ces applications conteneurisées s'exécutent où et quand vous le souhaitez, et les aide à trouver les ressources et les outils dont elles ont besoin pour travailler. Kubernetes est une plate-forme open source prête pour la production, conçue avec l'expérience accumulée de Google dans l'orchestration de conteneurs, associée aux meilleures idées de la communauté.</p></div></div><div id=basics-modules class=content__modules><h2>Modules de base Kubernetes</h2><div class=row><div class=col-md-12><div class=row><div class=col-md-4><div class=thumbnail><a href=/fr/docs/tutorials/kubernetes-basics/create-cluster/cluster-intro/><img src="/docs/tutorials/kubernetes-basics/public/images/module_01.svg?v=1469803628347" alt></a><div class=caption><a href=/fr/docs/tutorials/kubernetes-basics/create-cluster/cluster-intro/><h5>1. Créer un cluster Kubernetes</h5></a></div></div></div><div class=col-md-4><div class=thumbnail><a href=/fr/docs/tutorials/kubernetes-basics/deploy-app/deploy-intro/><img src="/docs/tutorials/kubernetes-basics/public/images/module_02.svg?v=1469803628347" alt></a><div class=caption><a href=/fr/docs/tutorials/kubernetes-basics/deploy-app/deploy-intro/><h5>2. Déployer une application</h5></a></div></div></div><div class=col-md-4><div class=thumbnail><a href=/docs/tutorials/kubernetes-basics/explore/explore-intro/><img src="/docs/tutorials/kubernetes-basics/public/images/module_03.svg?v=1469803628347" alt></a><div class=caption><a href=/docs/tutorials/kubernetes-basics/explore/explore-intro/><h5>3. Explorez votre application</h5></a></div></div></div></div></div><div class=col-md-12><div class=row><div class=col-md-4><div class=thumbnail><a href=/docs/tutorials/kubernetes-basics/expose/expose-intro/><img src="/docs/tutorials/kubernetes-basics/public/images/module_04.svg?v=1469803628347" alt></a><div class=caption><a href=/docs/tutorials/kubernetes-basics/expose/expose-intro/><h5>4. Exposez votre application publiquement</h5></a></div></div></div><div class=col-md-4><div class=thumbnail><a href=/docs/tutorials/kubernetes-basics/scale/scale-intro/><img src="/docs/tutorials/kubernetes-basics/public/images/module_05.svg?v=1469803628347" alt></a><div class=caption><a href=/docs/tutorials/kubernetes-basics/scale/scale-intro/><h5>5. Mettre à l'échelle votre application</h5></a></div></div></div><div class=col-md-4><div class=thumbnail><a href=/docs/tutorials/kubernetes-basics/update/update-intro/><img src="/docs/tutorials/kubernetes-basics/public/images/module_06.svg?v=1469803628347" alt></a><div class=caption><a href=/docs/tutorials/kubernetes-basics/update/update-intro/><h5>6. Mettre à jour votre application</h5></a></div></div></div></div></div></div></div><div class=row><div class=col-md-12><a class="btn btn-lg btn-success" href=/docs/tutorials/kubernetes-basics/create-cluster/cluster-intro/ role=button>Lancer le tutoriel<span class=btn__next>›</span></a></div></div></main></div></body></html></div><div class=td-content style=page-break-before:always><h1 id=pg-7df66040311338d6098ebeab43ba9afb>6.2.1 - Créer un cluster</h1></div><div class=td-content><h1 id=pg-de49316920e97a82e36763cb66781ada>6.2.1.1 - Utiliser Minikube pour créer un cluster</h1><!doctype html><html lang=fr><body><link href=/docs/tutorials/kubernetes-basics/public/css/styles.css rel=stylesheet><div class=layout id=top><main class=content><div class=row><div class=col-md-8><h3>Objectifs</h3><ul><li>Découvrez ce qu'est un cluster Kubernetes.</li><li>Apprenez ce qu'est Minikube.</li><li>Démarrez un cluster Kubernetes à l'aide d'un terminal en ligne.</li></ul></div><div class=col-md-8><h3>Kubernetes Clusters</h3><p><b>Kubernetes coordonne un groupe d'ordinateurs hautement disponibles qui sont connectés pour fonctionner comme une seule et même unité.</b> Les abstractions de Kubernetes vous permettent de déployer des applications conteneurisées dans un cluster sans les lier spécifiquement à des ordinateurs individuels. Pour utiliser ce nouveau modèle de déploiement, les applications doivent être empaquetées de manière à les dissocier des hôtes individuels: elles doivent être conteneurisées. Les applications conteneurisées sont plus flexibles et disponibles que dans les modèles de déploiement précédents, dans lesquels les applications étaient installées directement sur des machines spécifiques sous la forme de packages profondément intégrés à l'hôte. <b>Kubernetes automatise plus efficacement la distribution et la planification des conteneurs d'applications dans un cluster.</b> Kubernetes est une plate-forme open source prête pour la production.</p><p>Un cluster Kubernetes est constitué de deux types de ressources:<ul><li>Le <b>maître</b> coordonne le cluster.</li><li>Les <b>nœuds</b> sont les serveurs qui exécutent des applications.</li></ul></p></div><div class=col-md-4><div class="content__box content__box_lined"><h3>Sommaire:</h3><ul><li>Kubernetes cluster</li><li>Minikube</li></ul></div><div class="content__box content__box_fill"><p><i>Kubernetes est une plate-forme open source pour la production qui orchestre le placement (planification) et l'exécution de conteneurs d'applications à l'intérieur et à travers des clusters d'ordinateur.</i></p></div></div></div><br><div class=row><div class=col-md-8><h2 style=color:#3771e3>Schéma du Cluster</h2></div></div><div class=row><div class=col-md-8><p><img src=/docs/tutorials/kubernetes-basics/public/images/module_01_cluster.svg></p></div></div><br><div class=row><div class=col-md-8><p><b>Le maître est responsable de la gestion du cluster.</b> Le maître coordonne toutes les activités de votre cluster, telles que la planification des applications, la gestion de l'état souhaité des applications, la mise à l'échelle des applications et le déploiement de nouvelles mises à jour.</p><p><b>Un nœud est une machine virtuelle ou un ordinateur physique servant d’ordinateur de travail dans un cluster Kubernetes.</b> Chaque nœud est doté d’un Kubelet, qui est un agent permettant de gérer le nœud et de communiquer avec le maître Kubernetes. Le nœud doit également disposer d'outils permettant de gérer les opérations de conteneur, telles que Docker ou rkt. Un cluster Kubernetes qui gère le trafic de production doit comporter au moins trois nœuds.</p></div><div class=col-md-4><div class="content__box content__box_fill"><p><i>Les maîtres gèrent le cluster et les nœuds sont utilisés pour héberger les applications en cours d'exécution.</i></p></div></div></div><div class=row><div class=col-md-8><p>Lorsque vous déployez des applications sur Kubernetes, vous indiquez au maître de démarrer les conteneurs d'applications. Le maître planifie l'exécution des conteneurs sur les nœuds du cluster. <b>Les nœuds communiquent avec le maître à l'aide de l'API Kubernetes </b>, que le maître expose. Les utilisateurs finaux peuvent également utiliser l'API Kubernetes directement pour interagir avec le cluster.</p><p>Un cluster Kubernetes peut être déployé sur des machines physiques ou virtuelles. Pour démarrer avec le développement de Kubernetes, vous pouvez utiliser Minikube. Minikube est une implémentation Kubernetes légère qui crée une machine virtuelle sur votre machine locale et déploie un cluster simple contenant un seul nœud. Minikube est disponible pour les systèmes Linux, macOS et Windows. La CLI Minikube fournit des opérations d’amorçage de base permettant d’utiliser votre cluster, notamment les fonctions de démarrage, d’arrêt, de statut et de suppression. Pour ce tutoriel, toutefois, vous utiliserez un terminal en ligne fourni avec Minikube pré-installé.</p><p>Maintenant que vous savez ce qu'est Kubernetes, allons au didacticiel en ligne et commençons notre premier cluster!</p></div></div><br><div class=row><div class=col-md-12><a class="btn btn-lg btn-success" href=/docs/tutorials/kubernetes-basics/create-cluster/cluster-interactive/ role=button>Lancer le didacticiel interactif <span class=btn__next>›</span></a></div></div></main></div></body></html></div><div class=td-content style=page-break-before:always><h1 id=pg-323b75976001e8dfe35d67d61bc74f1a>6.2.1.2 - Didacticiel interactif - Création d'un cluster</h1><!doctype html><html lang=fr><body><link href=/docs/tutorials/kubernetes-basics/public/css/styles.css rel=stylesheet><link href=/docs/tutorials/kubernetes-basics/public/css/overrides.css rel=stylesheet><script src=https://katacoda.com/embed.js></script><div class=layout id=top><main class="content katacoda-content"><div class=katacoda><div class=katacoda__alert>Pour interagir avec le terminal, veuillez utiliser la version bureau / tablette.</div><div class=katacoda__box id=inline-terminal-1 data-katacoda-id=kubernetes-bootcamp/1 data-katacoda-color=326de6 data-katacoda-secondary=273d6d data-katacoda-hideintro=false data-katacoda-prompt="Kubernetes Bootcamp Terminal" style=height:600px></div></div><div class=row><div class=col-md-12><a class="btn btn-lg btn-success" href=/fr/docs/tutorials/kubernetes-basics/deploy-app/deploy-intro/ role=button>Continuer au module 2<span class=btn__next>›</span></a></div></div></main></div></body></html></div><div class=td-content style=page-break-before:always><h1 id=pg-76d78b3fba507f7ed33cef14a35b631d>6.2.2 - Déployer une application</h1></div><div class=td-content><h1 id=pg-2b1bba431989008c7493109a0f049ece>6.2.2.1 - Utiliser kubectl pour créer un déploiement</h1><!doctype html><html lang=fr><body><link href=/docs/tutorials/kubernetes-basics/public/css/styles.css rel=stylesheet><div class=layout id=top><main class=content><div class=row><div class=col-md-8><h3>Objectifs</h3><ul><li>En savoir plus sur les déploiements d'applications.</li><li>Déployez votre première application sur Kubernetes avec kubectl.</li></ul></div><div class=col-md-8><h3>Déploiements Kubernetes</h3><p>Une fois que vous avez un cluster Kubernetes en cours d'exécution, vous pouvez déployer vos applications conteneurisées par dessus. Pour ce faire, vous créez une configuration de <b>Déploiement (Deployments)</b> Kubernetes. Le déploiement instruit Kubernetes de comment créer et mettre à jour des instances de votre application. Une fois que vous avez créé un déploiement, le plannificateur de Kubernetes (kube-scheduler) planifient les instanciations d'application sur des nœuds du cluster.</p><p>Une fois les instances d’application créées, un contrôleur de déploiement Kubernetes surveille en permanence ces instances. Si le nœud hébergeant une instance tombe en panne ou est supprimé, le contrôleur de déploiement remplace l'instance par une instance située sur un autre nœud du cluster. <b>Ceci fournit un mécanisme d'auto-réparation pour faire face aux pannes ou à la maintenance de la machine.</b></p><p>Dans le monde de pré-orchestration, les scripts d'installation étaient souvent utilisés pour démarrer des applications, mais ils ne permettaient pas une récupération après une panne d'ordinateur. En créant et en maintenant vos instances d’application sur plusieurs nœuds, les Déploiements Kubernetes offre une approche fondamentalement différente de la gestion des applications.</p></div><div class=col-md-4><div class="content__box content__box_lined"><h3>Sommaire:</h3><ul><li>Déploiements</li><li>Kubectl</li></ul></div><div class="content__box content__box_fill"><p><i>Un déploiement est responsable de la création et de la mise à jour des instances de votre application.</i></p></div></div></div><br><div class=row><div class=col-md-8><h2 style=color:#3771e3>Déploiement de votre première application sur Kubernetes</h2></div></div><div class=row><div class=col-md-8><p><img src=/docs/tutorials/kubernetes-basics/public/images/module_02_first_app.svg></p></div></div><br><div class=row><div class=col-md-8><p>Vous pouvez créer et gérer un déploiement à l'aide de l'interface de ligne de commande, <b>Kubectl</b>.</p><p>Kubectl utilise l'API Kubernetes pour interagir avec le cluster. Dans ce module, vous apprendrez les commandes Kubectl les plus courantes nécessaires à la création de déploiements exécutant vos applications sur un cluster Kubernetes.</p><p>Lorsque vous créez un déploiement, vous devez spécifier l'image de conteneur de votre application et le nombre de réplicas que vous souhaitez exécuter. Vous pouvez modifier ces informations ultérieurement en mettant à jour votre déploiement.; Modules <a href=/docs/tutorials/kubernetes-basics/scale-intro/>5</a> et <a href=/docs/tutorials/kubernetes-basics/update-intro/>6</a> du bootcamp, expliquez comment vous pouvez faire évoluer et mettre à jour vos déploiements.</p></div><div class=col-md-4><div class="content__box content__box_fill"><p><i>Les applications doivent être regroupées dans l’un des formats de conteneur pris en charge pour pouvoir être déployées sur Kubernetes.</i></p></div></div></div><div class=row><div class=col-md-8><p>Pour notre premier déploiement, nous utiliserons une application Node.js intégrée dans un conteneur Docker.
Pour créer l'application Node.js et déployer le conteneur Docker, suivez les instructions du
<a href=/fr/docs/tutorials/hello-minikube/>Tutoriel Hello Minikube</a>.</p><p>Maintenant que vous savez ce que sont les déploiements, allons au didacticiel en ligne et déployons notre première application!</p></div></div><br><div class=row><div class=col-md-12><a class="btn btn-lg btn-success" href=/docs/tutorials/kubernetes-basics/deploy-app/deploy-interactive/ role=button>Lancer le didacticiel interactif <span class=btn__next>›</span></a></div></div></main></div></body></html></div><div class=td-content style=page-break-before:always><h1 id=pg-f8997ec143b382fa6c9621941ea62ca3>6.2.2.2 - Tutoriel interactif - Déploiement d'une application</h1><!doctype html><html lang=fr><body><link href=/docs/tutorials/kubernetes-basics/public/css/styles.css rel=stylesheet><link href=/docs/tutorials/kubernetes-basics/public/css/overrides.css rel=stylesheet><script src=https://katacoda.com/embed.js></script><div class=layout id=top><main class="content katacoda-content"><br><div class=katacoda><div class=katacoda__alert>Pour interagir avec le terminal, veuillez utiliser la version bureau / tablette.</div><div class=katacoda__box id=inline-terminal-1 data-katacoda-id=kubernetes-bootcamp/7 data-katacoda-color=326de6 data-katacoda-secondary=273d6d data-katacoda-hideintro=false data-katacoda-prompt="Kubernetes Bootcamp Terminal" style=height:600px></div></div><div class=row><div class=col-md-12><a class="btn btn-lg btn-success" href=/docs/tutorials/kubernetes-basics/explore/explore-intro/ role=button>Continuer au module 3<span class=btn__next>›</span></a></div></div></main></div></body></html></div><div class=td-content style=page-break-before:always><h1 id=pg-250d620a73ec8be7e1f7d835574c4596>6.2.3 - Explorez vos applications</h1></div><div class=td-content><h1 id=pg-2771f4e8c45321b17cb0114a2d266453>6.2.3.1 - Affichage des pods et des nœuds</h1><!doctype html><html lang=fr><body><div class=layout id=top><main class=content><div class=row><div class=col-md-8><h3>Objectifs</h3><ul><li>En savoir plus sur les pods Kubernetes.</li><li>En savoir plus sur les nœuds Kubernetes.</li><li>Dépannez les applications déployées.</li></ul></div><div class=col-md-8><h2>Pods de Kubernetes</h2><p>Lorsque vous avez créé un déploiement dans le Module <a href=/fr/docs/tutorials/kubernetes-basics/deploy-app/deploy-intro/>2</a>, Kubernetes a créé un <b>Pod</b> pour héberger votre instance d'application. Un pod est une abstraction Kubernetes qui représente un groupe d'un ou plusieurs conteneurs d'application (tels que Docker), et certaines ressources partagées pour ces conteneurs. Ces ressources comprennent:</p><ul><li>Stockage partagé, en tant que Volumes</li><li>Mise en réseau, en tant qu'adresse IP d'un unique cluster</li><li>Informations sur l'exécution de chaque conteneur, telles que la version de l'image du conteneur ou les ports spécifiques à utiliser</li></ul><p>Un pod modélise un "hôte logique" spécifique à l'application et peut contenir différents conteneurs d'applications qui sont relativement étroitement couplés. Par exemple, un pod peut inclure à la fois le conteneur avec votre application Node.js ainsi qu'un conteneur différent qui alimente les données à être publiées par le serveur Web Node.js. Les conteneurs d'un pod partagent une adresse IP et un espace de port, sont toujours co-localisés et co-planifiés, et exécutés dans un contexte partagé sur le même nœud.</p><p>Les pods sont l'unité atomique de la plate-forme Kubernetes. Lorsque nous créons un déploiement sur Kubernetes, ce déploiement crée des pods avec des conteneurs à l'intérieur (par opposition à la création directe de conteneurs). Chaque pod est lié au nœud où il est planifié et y reste jusqu'à la résiliation (selon la politique de redémarrage) ou la suppression. En cas de défaillance d'un nœud, des pods identiques sont programmés sur d'autres nœuds disponibles dans le cluster.</p></div><div class=col-md-4><div class="content__box content__box_lined"><h3>Sommaire:</h3><ul><li>Pods</li><li>Nœuds</li><li>Commandes principales de Kubectl</li></ul></div><div class="content__box content__box_fill"><p><i>Un pod est un groupe d'un ou plusieurs conteneurs applicatifs (tels que Docker) et comprend un stockage partagé (volumes), une adresse IP et des informations sur la façon de les exécuter.</i></p></div></div></div><br><div class=row><div class=col-md-8><h2 style=color:#3771e3>Aperçu des Pods</h2></div></div><div class=row><div class=col-md-8><p><img src=/docs/tutorials/kubernetes-basics/public/images/module_03_pods.svg></p></div></div><br><div class=row><div class=col-md-8><h2>Nœuds</h2><p>Un Pod s'exécute toujours sur un <b>Nœud</b>. Un nœud est une machine de travail dans Kubernetes et peut être une machine virtuelle ou physique, selon le cluster. Chaque nœud est géré par le planificateur. Un nœud peut avoir plusieurs pods, et le planificateur Kubernetes gère automatiquement la planification des pods sur les nœuds du cluster. La planification automatique du planificateur tient compte des ressources disponibles sur chaque nœud.</p><p>Chaque nœud Kubernetes exécute au moins:</p><ul><li>Kubelet, un processus responsable de la communication entre le planificateur Kubernetes et le nœud ; il gère les Pods et les conteneurs s'exécutant sur une machine.</li><li>Un environnement d'exécution de conteneur (comme Docker) chargé d'extraire l'image du conteneur d'un registre, de décompresser le conteneur et d'exécuter l'application.</li></ul></div><div class=col-md-4><div class="content__box content__box_fill"><p><i>Les conteneurs ne doivent être planifiés ensemble dans un seul pod que s'ils sont étroitement couplés et doivent partager des ressources telles que le disque.</i></p></div></div></div><br><div class=row><div class=col-md-8><h2 style=color:#3771e3>Aperçu des Nœuds</h2></div></div><div class=row><div class=col-md-8><p><img src=/docs/tutorials/kubernetes-basics/public/images/module_03_nodes.svg></p></div></div><br><div class=row><div class=col-md-8><h2>Dépannage avec kubectl</h2><p>Dans le module <a href=/docs/tutorials/kubernetes-basics/deploy-app/deploy-intro/>2</a>, vous avez utilisé l'interface de ligne de commande Kubectl. Vous continuerez à l'utiliser dans le module 3 pour obtenir des informations sur les applications déployées et leurs environnements. Les opérations les plus courantes peuvent être effectuées avec les commandes kubectl suivantes:</p><ul><li><b>kubectl get</b> - liste les ressources</li><li><b>kubectl describe</b> - affiche des informations détaillées sur une ressource</li><li><b>kubectl logs</b> - imprime les journaux d'un conteneur dans un pod</li><li><b>kubectl exec</b> - exécute une commande sur un conteneur dans un pod</li></ul><p>Vous pouvez utiliser ces commandes pour voir quand les applications ont été déployées, quels sont leurs statuts actuels, où elles s'exécutent et quelles sont leurs configurations.</p><p>Maintenant que nous en savons plus sur nos composants de cluster et la ligne de commande, explorons notre application.</p></div><div class=col-md-4><div class="content__box content__box_fill"><p><i>Un nœud est une machine de travail dans Kubernetes et peut être une machine virtuelle ou une machine physique, selon le cluster. Plusieurs pods peuvent s'exécuter sur un nœud.</i></p></div></div></div><br><div class=row><div class=col-md-12><a class="btn btn-lg btn-success" href=/docs/tutorials/kubernetes-basics/explore/explore-interactive/ role=button>Démarrer le didacticiel interactif <span class=btn__next>›</span></a></div></div></main></div></body></html></div><div class=td-content style=page-break-before:always><h1 id=pg-4b0e31c9e0eae68bbb0a358b4042ada9>6.2.4 - Rendre publique votre application</h1></div><div class=td-content style=page-break-before:always><h1 id=pg-be4996c93fb39c459a30b6669569d423>6.2.5 - Mise à l'échelle des applications</h1></div><div class=td-content style=page-break-before:always><h1 id=pg-62b8b17dadfb55f1801cf8439e944e58>6.2.6 - Mise à jour des applications</h1></div><div class=td-content style=page-break-before:always><h1 id=pg-327beaa8e74d617d5ed749137ae5dfd9>6.3 - Formations en ligne</h1></div><div class=td-content style=page-break-before:always><h1 id=pg-a3a0f1c6af19fc89ce24d8cd42c0249f>6.4 - Configuration</h1></div><div class=td-content style=page-break-before:always><h1 id=pg-1efbbc2c3015389f835b1661d5effb29>6.5 - Applications sans états</h1></div><div class=td-content style=page-break-before:always><h1 id=pg-d6336d9712aa433eb5f0fb8cbed6bef7>6.6 - Applications avec états</h1></div><div class=td-content style=page-break-before:always><h1 id=pg-1ea281893eade34904c0cbd26b4228cb>6.7 - Clusters</h1></div><div class=td-content style=page-break-before:always><h1 id=pg-97489f0aa8ac2df31a0d6b444a7bde62>6.8 - Services</h1></div><div class=td-content style=page-break-before:always><h1 id=pg-b00a88a07ceb21b1a83e5822e0c86c1d>7 - Documents de Référence</h1><p>Cette section de la documentation de Kubernetes contient les informations de références.</p><h2 id=documents-de-référence-de-l-api>Documents de Référence de l'API</h2><ul><li><a href=/docs/reference/using-api/api-overview/>Vue d'ensemble de l'API de Kubernetes</a></li><li>Documentation de référence de l'API de Kubernetes par version:<ul><li><a href=/docs/reference/generated/kubernetes-api/v1.14/>1.14</a></li><li><a href=/docs/reference/generated/kubernetes-api/v1.13/>1.13</a></li><li><a href=/docs/reference/generated/kubernetes-api/v1.12/>1.12</a></li><li><a href=/docs/reference/generated/kubernetes-api/v1.11/>1.11</a></li><li><a href=/docs/reference/generated/kubernetes-api/v1.10/>1.10</a></li></ul></li></ul><h2 id=bibliothèques-client-de-l-api>Bibliothèques client de l'API</h2><p>Pour appeler l'API de Kubernetes depuis un langage de programmation on peut utiliser une <a href=/docs/reference/using-api/client-libraries/>bibliothèque client</a>. Les bibliothèques client officiellement supportées sont:</p><ul><li><a href=https://github.com/kubernetes/client-go/>Kubernetes Go client library</a></li><li><a href=https://github.com/kubernetes-client/python>Kubernetes Python client library</a></li><li><a href=https://github.com/kubernetes-client/java>Kubernetes Java client library</a></li><li><a href=https://github.com/kubernetes-client/javascript>Kubernetes JavaScript client library</a></li></ul><h2 id=documents-de-référence-des-outils-en-ligne-de-commande-cli>Documents de Référence des outils en ligne de commande (CLI)</h2><ul><li><a href=/docs/reference/kubectl/overview/>kubectl</a> - Principal outil en ligne de commande (CLI) pour exécuter et gérer un cluster Kubernetes.<ul><li><a href=/docs/user-guide/jsonpath/>JSONPath</a> - Guide de la syntaxe des <a href=http://goessner.net/articles/JsonPath/>expressions JSONPath</a> avec kubectl.</li></ul></li><li><a href=/docs/admin/kubeadm/>kubeadm</a> - Outil en ligne de commande (CLI) pour provisionner facilement un cluster Kubernetes sécurisé.</li><li><a href=/docs/admin/kubefed/>kubefed</a> - Outil en ligne de commande (CLI) pour aider à administrer des clusters fédérés.</li></ul><h2 id=documents-de-référence-pour-la-configuration>Documents de Référence pour la configuration</h2><ul><li><a href=/docs/admin/kubelet/>kubelet</a> - Le principal <em>agent</em> qui s'exécute sur chaque noeud. Kubelet prends un ensemble de PodSpecs et s'assure que les conteneurs qui y sont décrit s'exécutent correctement.</li><li><a href=/docs/admin/kube-apiserver/>kube-apiserver</a> - L'API REST qui valide et configure les données des objects de l'API tels que les Pods, Services, Deployments ...</li><li><a href=/docs/admin/kube-controller-manager/>kube-controller-manager</a> - Démon en charge de la principale boucle de régulation (core control loop) de Kubernetes.</li><li><a href=/docs/admin/kube-proxy/>kube-proxy</a> - S'occupe de reacheminer (forwarding) simplement les flux TCP/UDP ou bien en utilisant un Round-Robin sur un ensemble de back-ends.</li><li><a href=/docs/admin/kube-scheduler/>kube-scheduler</a> - Ordonnanceur (scheduler) qui gère la disponibilité, la performance et la capacité.</li><li><a href=/docs/admin/federation-apiserver/>federation-apiserver</a> - Serveur API pour les clusters fédérés.</li><li><a href=/docs/admin/federation-controller-manager/>federation-controller-manager</a> - Démon en charge de la boucle de régulation (core control loop) d'une fédération de clusters Kubernetes.</li></ul><h2 id=documents-de-conception>Documents de Conception</h2><ul><li><a href=https://git.k8s.io/community/contributors/design-proposals/architecture/architecture.md>Architecture de Kubernetes</a></li><li><a href=https://git.k8s.io/community/contributors/design-proposals>Vue d'ensemble des documents de conception de Kubernetes</a>.</li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-2b03679960950df772fb4fe7d78427b9>7.1 - Glossary</h1></div><div class=td-content style=page-break-before:always><h1 id=pg-af7c1f9168ec67f957edc504f43faf9a>7.2 - Problèmes et alertes de sécurité de Kubernetes</h1></div><div class=td-content style=page-break-before:always><h1 id=pg-882c82a32bfb4d7946585a93a966b442>7.3 - Utilisation de l'API Kubernetes</h1></div><div class=td-content style=page-break-before:always><h1 id=pg-99b26586d8a33ec06996dcf7892a9683>7.4 - Accéder à l'API</h1></div><div class=td-content style=page-break-before:always><h1 id=pg-60a16da3955f1de774f1f8dd756f2251>7.5 - Référence de l'API</h1></div><div class=td-content style=page-break-before:always><h1 id=pg-5bbbc5163b35431b3bff029ab9ec57d3>7.6 - Référence des outils d'installation</h1></div><div class=td-content><h1 id=pg-f351ced098abbb076bc8c4be1053672b>7.6.1 - Kubeadm</h1></div><div class=td-content><h1 id=pg-ac27ec04cad4f711698a27637c3c8300>7.6.1.1 - Aperçu de kubeadm</h1><p><img src=https://raw.githubusercontent.com/cncf/artwork/master/projects/kubernetes/certified-kubernetes/versionless/color/certified-kubernetes-color.png align=right width=150px>Kubeadm est un outil conçu afin que les commandes <code>kubeadm init</code> et <code>kubeadm join</code> soient la meilleure façon de créer rapidement des clusters Kubernetes.</p><p>Kubeadm effectue les actions nécessaires afin d'obtenir un cluster minimal mais fonctionnel et en état de marche. Son objectif est d'assembler le cluster sans pour autant provisioner les machines qui le composent. De la même façon, kubeadm ne supporte pas l'installation des extensions habituelles comme le Dashboard (tableau de bord), les solutions de surveillance ou bien encore les extensions spécifiques aux fournisseurs cloud.</p><p>On préférera des outils plus spécifiques et de plus haut niveau, construits autour de kubeadm, et qui, idéalement, utiliseront kubeadm comme base de déploiement afin de créer facilement des clusters conformes.</p><h2 id=prochaines-étapes>Prochaines étapes</h2><ul><li><a href=/docs/reference/setup-tools/kubeadm/kubeadm-init>kubeadm init</a> pour assembler un noeud Kubernetes control-plane</li><li><a href=/docs/reference/setup-tools/kubeadm/kubeadm-join>kubeadm join</a> pour assembler un noeud Kubernetes worker node et le joindre au cluster</li><li><a href=/docs/reference/setup-tools/kubeadm/kubeadm-upgrade>kubeadm upgrade</a> pour mettre à jour un cluster Kubernetes vers une version plus récente</li><li><a href=/docs/reference/setup-tools/kubeadm/kubeadm-config>kubeadm config</a> si vous avez initialisé votre cluster en utilisant kubeadm v1.7.x ou antérieur, pour configurer votre cluster avec <code>kubeadm upgrade</code></li><li><a href=/docs/reference/setup-tools/kubeadm/kubeadm-token>kubeadm token</a> pour gérer vos jetons avec <code>kubeadm join</code></li><li><a href=/docs/reference/setup-tools/kubeadm/kubeadm-reset>kubeadm reset</a> pour annuler des changements faits avec <code>kubeadm init</code> ou <code>kubeadm join</code> à cet hôte</li><li><a href=/docs/reference/setup-tools/kubeadm/kubeadm-version>kubeadm version</a> pour afficher la version de kubeadm</li><li><a href=/docs/reference/setup-tools/kubeadm/kubeadm-alpha>kubeadm alpha</a> pour utiliser un lot de fonctionnalités rendus disponibles afin d'obtenir le retour de la communauté</li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-36c22b52e8447eb3d2452d4f56fbea9b>7.6.1.2 - Kubeadm généré</h1></div><div class=td-content><h1 id=pg-dcfffcaafb438cd650475945ddc129ee>7.6.1.2.1 -</h1><p>Utilisez cette commande afin de configurer le control plane Kubernetes</p><h3 id=synopsis>Synopsis</h3><p>Utilisez cette commande afin de configurer le control plane Kubernetes</p><p>La commande "init" exécute les phases suivantes :</p><pre tabindex=0><code>preflight                  Exécute les vérifications en amont
kubelet-start              Sauvegarde les réglages kubelet et (re)démarre kubelet
certs                      Génération de certificats
  /etcd-ca                   Génère le certificat CA auto signé pour fournir les identités à etcd
  /apiserver-etcd-client     Génère le certificat que l&#39;apiserver utilisera pour communiquer avec etcd
  /etcd-healthcheck-client   Génère le certificat pour les sondes de vivacité (liveness) qui contrôlent etcd
  /etcd-server               Génère le certificat pour l&#39;accès à etcd
  /etcd-peer                 Génère le certificat pour que les noeuds etcd puissent communiquer ensemble
  /ca                        Génère le certificat CA auto signé  de Kubernetes pour fournir les identités aux autres composants Kubernetes
  /apiserver                 Génère le certificat pour l&#39;accès à l&#39;API Kubernetes
  /apiserver-kubelet-client  Génère le certificat pour permettre à l&#39;API server de se connecter à kubelet
  /front-proxy-ca            Génère le certificat CA auto signé pour fournir les identités au proxy frontal (front proxy)
  /front-proxy-client        Génère le certificat pour le client du proxy frontal
  /sa                        Génère une clef privée pour signer les jetons ainsi que la clef publique du compte service
kubeconfig                 Génère tous les fichiers kubeconfig nécessaires pour la création du control plane et du fichier kubeconfig admin
  /admin                     Génère un fichier kubeconfig pour utilisation par l&#39;administrateur et kubeadm
  /kubelet                   Génère un fichier kubeconfig pour utilisation par kubelet seulement à des fins d&#39;installation initiale
  /controller-manager        Génère un fichier fichier kubeconfig for the controller manager to use
  /scheduler                 Génère un fichier kubeconfig pour utilisation par le scheduler
control-plane              Génère tous les manifests de Pod statiques nécessaires à la création du control plane
  /apiserver                 Génère le manifest de Pod statique de l&#39;apiserver
  /controller-manager        Génère le manifest de Pod statique du kube-controller-manager
  /scheduler                 Génère le manifest de Pod statique du kube-schedule
etcd                       Génère le manifest de Pod statique pour l&#39;etcd local
  /local                     Génère le manifest de Pod statique pour une instance etcd locale, à un seul noeud
upload-config              Téléverse les configurations kubeadm et kubelet vers une ConfigMap
  /kubeadm                   Téléverse la ClusterConfiguration de kubeadm vers une ConfigMap
  /kubelet                   Téléverse la configuration kubelet vers une ConfigMap
upload-certs               Téléverse les certificats vers kubeadm-certs
mark-control-plane         Marque un noeud en tant que control-plane
bootstrap-token            Génère les jetons d&#39;installation utilisés pour faire joindre un noeud à un cluster
addon                      Installe les extensions requises pour l&#39;exécution des tests de Conformance
  /coredns                   Installe l&#39;extension CoreDNS à un cluster Kubernetes
  /kube-proxy                Installe l&#39;extension kube-proxy à un cluster Kubernetes
</code></pre><pre tabindex=0><code>kubeadm init [flags]
</code></pre><h3 id=options>Options</h3><pre tabindex=0><code>      --apiserver-advertise-address string   L&#39;adresse IP que l&#39;API Server utilisera pour s&#39;annoncer. Si non spécifiée, l&#39;interface réseau par défaut sera utilisée.
      --apiserver-bind-port int32            Port d&#39;écoute de l&#39;API Server.  (par default 6443)
      --apiserver-cert-extra-sans strings    Noms alternatifs (Subject Alternative Names  ou encore SANs) optionnels, utilisés dans les certificats servis par l&#39;API Server. Peuvent êtres des adresses IPs ou des noms DNS.
      --cert-dir string                      Le répertoire où sauvegarder les certificats. (par défaut &#34;/etc/kubernetes/pki&#34;)
      --certificate-key string               Clef utilisée pour chiffrer les certificats control-plane dans le Secret the kubeadm-certs.
      --config string                        Chemin vers un fichier de configuration kubeadm.
      --cri-socket string                    Chemin vers la socket CRI à laquelle la connexion doit s&#39;effectuer. S&#39;il n&#39;est pas spécifié, kubeadm essaiera de le détecter; utiliser cette option seulement si vous avez plus d&#39;un CRI installé ou si vous utilisez des sockets CRI non standard.
      --dry-run                              N&#39;effectue aucun changement; affiche seulement la sortie standard de ce qui serait effectué.
      --feature-gates string                 Un ensemble de paires clef=valeur qui décrivent l&#39;entrée de configuration pour des fonctionnalités diverses. Il n&#39;y en a aucune dans cette version.
  -h, --help                                 aide pour l&#39;initialisation (init)
      --ignore-preflight-errors strings      Une liste de contrôles dont les erreurs seront catégorisées comme &#34;warnings&#34; (avertissements). Par exemple : &#39;IsPrivilegedUser,Swap&#39;. La valeur &#39;all&#39; ignore les erreurs de tous les contrôles.
      --image-repository string              Choisis un container registry d&#39;où télécharger les images du control plane. (par défaut &#34;k8s.gcr.io&#34;)
      --kubernetes-version string            Choisis une version Kubernetes spécifique pour le control plane. (par défaut &#34;stable-1&#34;)
      --node-name string                     Spécifie le nom du noeud.
      --pod-network-cidr string              Spécifie l&#39;intervalle des adresses IP pour le réseau des pods. Si fournie, le control plane allouera automatiquement les CIDRs pour chacun des noeuds.
      --service-cidr string                  Utilise un intervalle différent pour les adresses IP des services prioritaires (VIPs). (par défaut &#34;10.96.0.0/12&#34;)
      --service-dns-domain string            Utilise un domaine alternatif pour les services, par exemple : &#34;myorg.internal&#34;. (par défaut &#34;cluster.local&#34;)
      --skip-certificate-key-print           N&#39;affiche pas la clef utilisée pour chiffrer les certificats du control-plane.
      --skip-phases strings                  List des des phases à sauter
      --skip-token-print                     N&#39;affiche pas le jeton par défaut de l&#39;installation qui a été généré lors de &#39;kubeadm init&#39;.
      --token string                         Le jeton à utiliser pour établir la confiance mutuelle  entre les noeuds et les noeuds du control-plane. Le format correspond à la regexp : [a-z0-9]{6}\.[a-z0-9]{16} - par exemple : abcdef.0123456789abcdef
      --token-ttl duration                   La durée au bout de laquelle le jeton sera automatiquement détruit (par exemple :  1s, 2m, 3h). Si réglée à &#39;0&#39;, le jeton n&#39;expirera jamais (par défaut 24h0m0s)
      --upload-certs                         Téléverse les certificats du control-plane vers le Secret kubeadm-certs.
</code></pre><h3 id=options-héritées-depuis-la-commande-parent>Options héritées depuis la commande parent</h3><pre tabindex=0><code>      --rootfs string   [EXPERIMENTALE] Le chemin vers la &#34;vraie&#34; racine du système de fichiers de l&#39;hôte.
</code></pre></div><div class=td-content style=page-break-before:always><h1 id=pg-82b2fcf985bae77dcb754387a9fcc64f>7.6.1.3 - kubeadm init</h1><p>Cette commande initialise un noeud Kubernetes control-plane.</p><p>Utilisez cette commande afin de configurer le control plane Kubernetes</p><h3 id=synopsis>Synopsis</h3><p>Utilisez cette commande afin de configurer le control plane Kubernetes</p><p>La commande "init" exécute les phases suivantes :</p><pre tabindex=0><code>preflight                  Exécute les vérifications en amont
kubelet-start              Sauvegarde les réglages kubelet et (re)démarre kubelet
certs                      Génération de certificats
  /etcd-ca                   Génère le certificat CA auto signé pour fournir les identités à etcd
  /apiserver-etcd-client     Génère le certificat que l&#39;apiserver utilisera pour communiquer avec etcd
  /etcd-healthcheck-client   Génère le certificat pour les sondes de vivacité (liveness) qui contrôlent etcd
  /etcd-server               Génère le certificat pour l&#39;accès à etcd
  /etcd-peer                 Génère le certificat pour que les noeuds etcd puissent communiquer ensemble
  /ca                        Génère le certificat CA auto signé  de Kubernetes pour fournir les identités aux autres composants Kubernetes
  /apiserver                 Génère le certificat pour l&#39;accès à l&#39;API Kubernetes
  /apiserver-kubelet-client  Génère le certificat pour permettre à l&#39;API server de se connecter à kubelet
  /front-proxy-ca            Génère le certificat CA auto signé pour fournir les identités au proxy frontal (front proxy)
  /front-proxy-client        Génère le certificat pour le client du proxy frontal
  /sa                        Génère une clef privée pour signer les jetons ainsi que la clef publique du compte service
kubeconfig                 Génère tous les fichiers kubeconfig nécessaires pour la création du control plane et du fichier kubeconfig admin
  /admin                     Génère un fichier kubeconfig pour utilisation par l&#39;administrateur et kubeadm
  /kubelet                   Génère un fichier kubeconfig pour utilisation par kubelet seulement à des fins d&#39;installation initiale
  /controller-manager        Génère un fichier fichier kubeconfig for the controller manager to use
  /scheduler                 Génère un fichier kubeconfig pour utilisation par le scheduler
control-plane              Génère tous les manifests de Pod statiques nécessaires à la création du control plane
  /apiserver                 Génère le manifest de Pod statique de l&#39;apiserver
  /controller-manager        Génère le manifest de Pod statique du kube-controller-manager
  /scheduler                 Génère le manifest de Pod statique du kube-schedule
etcd                       Génère le manifest de Pod statique pour l&#39;etcd local
  /local                     Génère le manifest de Pod statique pour une instance etcd locale, à un seul noeud
upload-config              Téléverse les configurations kubeadm et kubelet vers une ConfigMap
  /kubeadm                   Téléverse la ClusterConfiguration de kubeadm vers une ConfigMap
  /kubelet                   Téléverse la configuration kubelet vers une ConfigMap
upload-certs               Téléverse les certificats vers kubeadm-certs
mark-control-plane         Marque un noeud en tant que control-plane
bootstrap-token            Génère les jetons d&#39;installation utilisés pour faire joindre un noeud à un cluster
addon                      Installe les extensions requises pour l&#39;exécution des tests de Conformance
  /coredns                   Installe l&#39;extension CoreDNS à un cluster Kubernetes
  /kube-proxy                Installe l&#39;extension kube-proxy à un cluster Kubernetes
</code></pre><pre tabindex=0><code>kubeadm init [flags]
</code></pre><h3 id=options>Options</h3><pre tabindex=0><code>      --apiserver-advertise-address string   L&#39;adresse IP que l&#39;API Server utilisera pour s&#39;annoncer. Si non spécifiée, l&#39;interface réseau par défaut sera utilisée.
      --apiserver-bind-port int32            Port d&#39;écoute de l&#39;API Server.  (par default 6443)
      --apiserver-cert-extra-sans strings    Noms alternatifs (Subject Alternative Names  ou encore SANs) optionnels, utilisés dans les certificats servis par l&#39;API Server. Peuvent êtres des adresses IPs ou des noms DNS.
      --cert-dir string                      Le répertoire où sauvegarder les certificats. (par défaut &#34;/etc/kubernetes/pki&#34;)
      --certificate-key string               Clef utilisée pour chiffrer les certificats control-plane dans le Secret the kubeadm-certs.
      --config string                        Chemin vers un fichier de configuration kubeadm.
      --cri-socket string                    Chemin vers la socket CRI à laquelle la connexion doit s&#39;effectuer. S&#39;il n&#39;est pas spécifié, kubeadm essaiera de le détecter; utiliser cette option seulement si vous avez plus d&#39;un CRI installé ou si vous utilisez des sockets CRI non standard.
      --dry-run                              N&#39;effectue aucun changement; affiche seulement la sortie standard de ce qui serait effectué.
      --feature-gates string                 Un ensemble de paires clef=valeur qui décrivent l&#39;entrée de configuration pour des fonctionnalités diverses. Il n&#39;y en a aucune dans cette version.
  -h, --help                                 aide pour l&#39;initialisation (init)
      --ignore-preflight-errors strings      Une liste de contrôles dont les erreurs seront catégorisées comme &#34;warnings&#34; (avertissements). Par exemple : &#39;IsPrivilegedUser,Swap&#39;. La valeur &#39;all&#39; ignore les erreurs de tous les contrôles.
      --image-repository string              Choisis un container registry d&#39;où télécharger les images du control plane. (par défaut &#34;k8s.gcr.io&#34;)
      --kubernetes-version string            Choisis une version Kubernetes spécifique pour le control plane. (par défaut &#34;stable-1&#34;)
      --node-name string                     Spécifie le nom du noeud.
      --pod-network-cidr string              Spécifie l&#39;intervalle des adresses IP pour le réseau des pods. Si fournie, le control plane allouera automatiquement les CIDRs pour chacun des noeuds.
      --service-cidr string                  Utilise un intervalle différent pour les adresses IP des services prioritaires (VIPs). (par défaut &#34;10.96.0.0/12&#34;)
      --service-dns-domain string            Utilise un domaine alternatif pour les services, par exemple : &#34;myorg.internal&#34;. (par défaut &#34;cluster.local&#34;)
      --skip-certificate-key-print           N&#39;affiche pas la clef utilisée pour chiffrer les certificats du control-plane.
      --skip-phases strings                  List des des phases à sauter
      --skip-token-print                     N&#39;affiche pas le jeton par défaut de l&#39;installation qui a été généré lors de &#39;kubeadm init&#39;.
      --token string                         Le jeton à utiliser pour établir la confiance mutuelle  entre les noeuds et les noeuds du control-plane. Le format correspond à la regexp : [a-z0-9]{6}\.[a-z0-9]{16} - par exemple : abcdef.0123456789abcdef
      --token-ttl duration                   La durée au bout de laquelle le jeton sera automatiquement détruit (par exemple :  1s, 2m, 3h). Si réglée à &#39;0&#39;, le jeton n&#39;expirera jamais (par défaut 24h0m0s)
      --upload-certs                         Téléverse les certificats du control-plane vers le Secret kubeadm-certs.
</code></pre><h3 id=options-héritées-depuis-la-commande-parent>Options héritées depuis la commande parent</h3><pre tabindex=0><code>      --rootfs string   [EXPERIMENTALE] Le chemin vers la &#34;vraie&#34; racine du système de fichiers de l&#39;hôte.
</code></pre><h3 id=init-workflow>Séquence d'initialisation</h3><p><code>kubeadm init</code> assemble un noeud Kubernetes control-plane en effectuant les étapes suivantes :</p><ol><li><p>Exécute une série de contrôles pour valider l'état du système avant d'y apporter des changements.
Certaines validations peuvent émettre seulement des avertissements (warnings),
d'autres peuvent générer des erreurs qui forceront l'interruption de kubeadm
jusqu'à ce que le problème soit résolu
ou jusqu'à ce que l'utilisateur spécifie <code>--ignore-preflight-errors=&lt;list-des-erreurs></code>.</p></li><li><p>Génère une autorité de certification (CA) auto signée (ou utilise une existante si spécifiée) pour
installer les identités de chaque composant du cluster. Si l'utilisateur a fourni son propre certificat
et/ou clef de CA en le (la) copiant dans le répertoire des certificats, configuré avec <code>--cert-dir</code>
(<code>/etc/kubernetes/pki</code> par défaut) cette étape est sautée comme expliqué dans le document
<a href=#custom-certificates>utiliser ses propres certificats</a>.
Les certificats de l'API Server auront des entrées SAN additionnelles pour chaque argument <code>--apiserver-cert-extra-sans</code>.</p></li><li><p>Ecrit les fichiers kubeconfig dans <code>/etc/kubernetes/</code> pour
kubelet, le controller-manager et l'ordonnanceur (scheduler)
qui seront utlisés pour les connexions à l'API server, chacun avec sa propre identité,
ainsi qu'un fichier kubeconfig supplémentaire pour l'administration, nommé <code>admin.conf</code>.</p></li><li><p>Génère des manifestes statiques de Pod pour l'API server,
le controller manager et l'ordonnanceur. Au cas où aucun etcd externe n'est fourni,
un manifeste statique de Pod pour etcd est généré.</p><p>Les manifestes statiques de Pod sont écrits dans <code>/etc/kubernetes/manifestes</code>;
kubelet surveille ce répertoire afin que les Pods soient créés au démarrage.</p><p>Dès lors que les pods de control-plane sont démarrés, la séquence de <code>kubeadm init</code> peut alors continuer.</p></li><li><p>Applique les étiquettes (labels) et marques (taints) au noeud control-plane afin qu'aucune charge de travail additionnelle ne s'y exécute.</p></li><li><p>Génère le jeton que les noeuds additionnels peuvent utiliser pour s'enregistrer avec un control-plane. Il est possible que l'utilisateur fournisse un jeton en utilisant <code>--token</code>,
comme décrit dans la documentation <a href=/docs/reference/setup-tools/kubeadm/kubeadm-token/>à propos du jeton kubeadm</a>.</p></li><li><p>Produit tous les fichiers de configuration requis pour autoriser les noeuds à rejoindre le cluster avec les
<a href=/docs/reference/access-authn-authz/bootstrap-tokens/>jetons d'assemblage</a> et le mécanisme
<a href=/docs/reference/command-line-tools-reference/kubelet-tls-bootstrapping/>d'assemblage TLS</a> :</p><ul><li><p>Ecrit une ConfigMap pour produire toute la configuration nécessaire
pour rejoindre le cluster et installer les règles d'accès RBAC sous jacentes.</p></li><li><p>Permet aux jetons d'assemblage d'accéder à l'API CSR (Certificate Signing Request, requête de signature de certificat).</p></li><li><p>Configure l'acceptation automatique des nouvelles requêtes CSR.</p></li></ul><p>Voir <a href=/docs/reference/setup-tools/kubeadm/kubeadm-join/>kubeadm join</a> pour de l'information complémentaire.</p></li><li><p>Installe un serveur DNS (CoreDNS) et les modules de l'extension kube-proxy en utilisant l'API Server.
Dans la version 1.11 (et au delà) de Kubernetes, CoreDNS est le serveur DNS par défaut.
Pour installer kube-dns au lieu de CoreDNS, l'extension DNS doit être configurée dans la <code>ClusterConfiguration</code> de kubeadm.
Pour plus d'information, se référer à la section ci-dessous intitulée :
<code>Utiliser kubeadm init avec un fichier de configuration</code>.
Vous remarquerez que bien que le serveur DNS soit déployé, il ne sera pas programmé pour exécution avant que le CNI soit installé.</p></li></ol><h3 id=init-phases>Utiliser les phases d'initialisation avec kubeadm</h3><p>Kubeadm vous permet de créer un noeud de type control-plane en plusieurs phases. Dans 1.13 la commande <code>kubeadm init phase</code> a été promue GA (disponibilité générale) alors que précédemment ce n'était qu'une commande alpha : <code>kubeadm alpha phase</code>.</p><p>Pour voir la liste des phases et sous phases dans l'ordre, vous pouvez utiliser <code>kubeadm init --help</code>. La liste sera affichée en haut de l'écran d'aide et chaque phase aura une description associée.
Bon à savoir : en appelant <code>kubeadm init</code> toutes les phases et sous phases seront executées dans cet ordre.</p><p>Certaines phases ont des options uniques, si vous désirez consulter la liste de ces options, ajoutez <code>--help</code>, par exemple :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>sudo kubeadm init phase control-plane controller-manager --help
</span></span></code></pre></div><p>Vous pouvez aussi utiliser <code>--help</code> pour voir la liste des sous-phases pour une phase parent :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>sudo kubeadm init phase control-plane --help
</span></span></code></pre></div><p><code>kubeadm init</code> a aussi une option nommée <code>--skip-phases</code> qui peut être utilisée pour passer outre. Cette option accepte une liste de noms de phases, qui peuvent être retrouvées à partir de la liste ordonée précédente.</p><p>Par exemple :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>sudo kubeadm init phase control-plane all --config<span style=color:#666>=</span>configfile.yaml
</span></span><span style=display:flex><span>sudo kubeadm init phase etcd <span style=color:#a2f>local</span> --config<span style=color:#666>=</span>configfile.yaml
</span></span><span style=display:flex><span><span style=color:#080;font-style:italic># vous pouvez modifier les fichiers manifestes du control-plane et d&#39;etcd</span>
</span></span><span style=display:flex><span>sudo kubeadm init --skip-phases<span style=color:#666>=</span>control-plane,etcd --config<span style=color:#666>=</span>configfile.yaml
</span></span></code></pre></div><p>Cet exemple écrirait les fichiers manifestes pour le control plane et etcd dans <code>/etc/kubernetes/manifestes</code> à partir de la configuration dans <code>configfile.yaml</code>. Cela permet de modifier les fichiers et d'ensuite sauter ces phases en utilisant <code>--skip-phases</code>. En invoquant la dernière commande, vous créerez un noeud de type control plane avec les les fichiers manifestes personnalisés.</p><h3 id=config-file>Utiliser kubeadm init avec un fichier de configuration</h3><div class="alert alert-warning caution callout" role=alert><strong>Avertissement:</strong> L'utilisation d'un fichier de configuration est toujours considérée beta et le format du fichier pourrait changer dans les prochaines versions.</div><p>C'est possible de configurer <code>kubeadm init</code> avec un fichier de configuration plutôt qu'avec des options en ligne de commande, et certaines fonctionnalités avancées sont d'ailleurs uniquement disponibles en tant qu'options du fichier de configuration. Ce fichier est passé à kubeadm avec l'option <code>--config</code>.</p><p>Dans Kubernetes 1.11 et au delà, la configuration par défaut peut être affichée en utilisant la commande
<a href=/docs/reference/setup-tools/kubeadm/kubeadm-config/>kubeadm config print</a>.</p><p>Il est <strong>recommandé</strong> que vous migriez votre configuration <code>v1alpha3</code> vers <code>v1beta1</code> en utilisant
la commande <a href=/docs/reference/setup-tools/kubeadm/kubeadm-config/>kubeadm config migrate</a>,
car le support de <code>v1alpha3</code> sera supprimé dans Kubernetes 1.15.</p><p>Pour plus de détails à propos de chaque option de la configuration <code>v1beta1</code> vous pouvez consulter la
<a href=https://godoc.org/k8s.io/kubernetes/cmd/kubeadm/app/apis/kubeadm/v1beta1>référence de l'API</a>.</p><h3 id=kube-proxy>Ajouter des paramètres kube-proxy</h3><p>Pour de l'information à propos des paramètres kube-proxy dans la configuration kubeadm, se référer à :
<a href=https://godoc.org/k8s.io/kubernetes/pkg/proxy/apis/config#KubeProxyConfiguration>kube-proxy</a></p><p>Pour de l'information sur comment activer le mode IPVS avec kubeadm, se référer à :
<a href=https://github.com/kubernetes/kubernetes/blob/master/pkg/proxy/ipvs/README.md>IPVS</a></p><h3 id=control-plane-flags>Passer des options personnalisées aux composants du control plane</h3><p>Pour de l'information sur comment passer des options aux composants du control plane, se référer à :
<a href=/docs/setup/production-environment/tools/kubeadm/control-plane-flags/>control-plane-flags</a></p><h3 id=custom-images>Utiliser des images personnalisées</h3><p>Par défaut, kubeadm télécharge les images depuis <code>k8s.gcr.io</code>, à moins que la version demandée de Kubernetes soit une version Intégration Continue (CI). Dans ce cas, <code>gcr.io/k8s-staging-ci-images</code> est utilisé.</p><p>Vous pouvez outrepasser ce comportement en utilisant <a href=#config-file>kubeadm avec un fichier de configuration</a>.
Les personnalisations permises sont :</p><ul><li>fournir un <code>imageRepository</code> à utiliser à la place de <code>k8s.gcr.io</code>.</li><li>régler <code>useHyperKubeImage</code> à <code>true</code> pour utiliser l'image HyperKube.</li><li>fournir un <code>imageRepository</code> et un <code>imageTag</code> pour etcd et l'extension (add-on) DNS.</li></ul><p>Notez que le champ de configurtation <code>kubernetesVersion</code> ou l'option ligne de commande <code>--kubernetes-version</code> affectent la version des images.</p><h3 id=custom-certificates>Utiliser des certificats personnalisés</h3><p>Par défaut, kubeadm génère tous les certificats requis pour que votre cluster fonctionne.
Vous pouvez outrepasser ce comportement en fournissant vos propres certificats.</p><p>Pour ce faire, vous devez les placer dans le répertoire spécifié via l'option <code>--cert-dir</code> ou spécifié via la propriété <code>CertificatesDir</code> de votre fichier de configuration.
Par défaut, le répertoire est <code>/etc/kubernetes/pki</code>.</p><p>S'il existe un certificat et une clef privée dans ce répertoire, alors kubeadm sautera l'étape de génération et les fichiers fournis seront utilisés.
Cela signifie que vous pouvez, par exemple, copier un CA (Certificate Authority) existant vers <code>/etc/kubernetes/pki/ca.crt</code>
et <code>/etc/kubernetes/pki/ca.key</code>, et kubeadm utilisera ce CA pour signer le reste des certificats.</p><h4 id=external-ca-mode>Mode CA externe</h4><p>Il est aussi possible de fournir seulement le fichier <code>ca.crt</code> sans le fichier
<code>ca.key</code> (seulement dans le cas d'un fichier CA racine, pas pour d'autres paires de certificats).
Si tous les certificats et fichiers kubeconfig sont en place, kubeadm activera le mode "CA externe".
Kubeadm continuera sans clef CA locale.</p><p>Ou alors, vous pouvez utiliser l'outil controller-manager avec <code>--controllers=csrsigner</code> en fournissant les emplacements du certificat CA et la clef.</p><h3 id=kubelet-drop-in>Gérer le fichier kubeadm ad-hoc pour kubelet</h3><p>Le paquet kubeadm vient avec de la configuration concernant comment kubelet doit se comporter.
Vous remarquerez que la commande CLI <code>kubeadm</code> ne modifiera jamais ce fichier.
Ce fichier ad-hoc appartient au paquet deb/rpm de kubeadm.</p><p>Pour en savoir plus sur comment kubeadm gère kubelet, vous pouvez consulter
<a href=/fr/docs/setup/production-environment/tools/kubeadm/kubelet-integration>cette page</a>.</p><h3 id=utilisation-de-kubeadm-avec-des-runtimes-cri>Utilisation de kubeadm avec des runtimes CRI</h3><p>Depuis la version v1.6.0, Kubernetes a rendu possible par défaut l'utilisation de CRI, Container Runtime Interface.
Le runtime utilisé par défaut est Docker, activé à travers l'adaptateur fourni <code>dockershim</code>, une implémentation CRI, à l'intérieur de <code>kubelet</code>.</p><p>Parmi les autres runtimes CRI, on retrouvera :</p><ul><li><a href=https://github.com/containerd/cri-containerd>cri-containerd</a></li><li><a href=https://cri-o.io/>cri-o</a></li><li><a href=https://github.com/kubernetes/frakti>frakti</a></li><li><a href=https://github.com/kubernetes-incubator/rktlet>rkt</a></li></ul><p>Se référer aux <a href=/docs/setup/cri>instructions d'installation CRI</a> pour plus d'information.</p><p>Après avoir installé <code>kubeadm</code> et <code>kubelet</code>, exécuter ces étapes additionnelles :</p><ol><li><p>Installer l'adaptateur runtime sur chaque noeud, en suivant les instructions d'installation du projet mentionné ci-dessus.</p></li><li><p>Configurer kubelet pour utiliser le runtime CRI distant. Ne pas oublier de modifier
<code>RUNTIME_ENDPOINT</code> en utilisant la valeur adéquate <code>/var/run/{your_runtime}.sock</code>:</p></li></ol><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>cat &gt; /etc/systemd/system/kubelet.service.d/20-cri.conf <span style=color:#b44>&lt;&lt;EOF
</span></span></span><span style=display:flex><span><span style=color:#b44>[Service]
</span></span></span><span style=display:flex><span><span style=color:#b44>Environment=&#34;KUBELET_EXTRA_ARGS=--container-runtime=remote --container-runtime-endpoint=$RUNTIME_ENDPOINT&#34;
</span></span></span><span style=display:flex><span><span style=color:#b44>EOF</span>
</span></span><span style=display:flex><span>systemctl daemon-reload
</span></span></code></pre></div><p>Maintenant <code>kubelet</code> est prête à utiliser le runtime CRI spécifié, et vous pouvez reprendre la séquence de déploiement avec <code>kubeadm init</code> et <code>kubeadm join</code>pour déployer votre cluster Kubernetes.</p><p>Il est aussi possible de configurer <code>--cri-socket</code> à <code>kubeadm init</code> et <code>kubeadm reset</code> lorsque vous utilisez une implémentation CRI externe.</p><h3 id=paramétrer-le-nom-du-noeud>Paramétrer le nom du noeud</h3><p>Par défaut, <code>kubeadm</code> donne un nom au noeud en utilisant l'adresse de la machine. Vous pouvez outrepasser ce réglage en utilisant l'option <code>--node-name</code>.
Cette option se chargera de passer la valeur appropriée pour <a href=/docs/reference/command-line-tools-reference/kubelet/#options><code>--hostname-override</code></a> à kubelet.</p><p>Faîtes attention car forcer un nom d'hôte peut <a href=https://github.com/kubernetes/website/pull/8873>interférer avec les fournisseurs de cloud</a>.</p><h3 id=self-hosting>Héberger soi même le control plane Kubernetes</h3><p>A partir de la version 1.8, vous pouvez expérimentalement créer un control plane Kubernetes <em>auto-hébergé (self-hosted)</em> .
Cela signifie que des composants clefs comme le serveur d'API, le controller manager et l'ordonnanceur sont démarrés en tant que
<a href=/docs/concepts/workloads/controllers/daemonset/>pods DaemonSet</a>, configurés via l'API Kubernetes
plutôt qu'en tant que <a href=/docs/tasks/administer-cluster/static-pod/>pods static</a> configurés avec des fichiers statiques dans kubelet.</p><p>Pour créer un cluster auto-hébergé, se référer à la commande <code>kubeadm alpha selfhosting</code>.</p><h4 id=avertissements>Avertissements</h4><ol><li><p>L'auto-hébergement dans la version 1.8 et au delà comporte de sérieuses limitations.
En particulier, un cluster auto-hébergé <em>ne peut pas survivre au redémarrage du noeud control plane</em> sans intervention manuelle.</p></li><li><p>Un cluster auto-hébergé ne peut pas être mis à jour via la commande <code>kubeadm upgrade</code>.</p></li><li><p>Par défaut, les Pods d'un control plane auto-hébergé dépendent des identifiants chargés depuis des volumes de type
<a href=https://kubernetes.io/docs/concepts/storage/volumes/#hostpath><code>hostPath</code></a>
A part pour la création initiale, ces identifiants ne sont pas gérés par kubeadm.</p></li><li><p>La partie auto-hébergée du control plane n'inclut pas etcd,
qui fonctionne toujours en tant que Pod statique.</p></li></ol><h4 id=procédé>Procédé</h4><p>Le procédé de démarrage auto-hébergé est documenté dans le <a href=https://github.com/kubernetes/kubeadm/blob/master/docs/design/design_v1.9.md#optional-self-hosting>document de conception de kubeadm</a>.</p><p>En bref, <code>kubeadm alpha selfhosting</code> fonctionne de la manière suivante :</p><ol><li><p>Attend que le control plane statique soit démarré correctement. C'est la même chose que le procédé <code>kubeadm init</code> lorsque non auto-hébergé.</p></li><li><p>Utilise les manifestes du Pod statique du control plane pour construire un ensemble de manifestes DaemonSet qui vont lancer le control plane auto-hébergé.
Cela modifie aussi les manifestes si nécessaires, par example pour ajouter des nouveaux volumes pour des secrets.</p></li><li><p>Crée des DaemonSets dans le namespace <code>kube-system</code> et attend que les pods ainsi créés soient démarrés.</p></li><li><p>Une fois que les Pods auto-hébergés sont opérationnels, les Pods statiques qui leurs sont associés sont supprimés et kubeadm installe ensuite le prochain composant.
Cela déclenche l'arrêt par kubelet de ces Pods statiques.</p></li><li><p>Quand le control plane statique d'origine s'arrête, le nouveau control plane auto-hébergé est capable d'écouter sur les mêmes ports et devenir actif.</p></li></ol><h3 id=utiliser-kubeadm-sans-connexion-internet>Utiliser kubeadm sans connexion internet</h3><p>Pour utiliser kubeadm sans connexion internet, vous devez télécharger les images requises par le control plane à l'avance.</p><p>A partir de Kubernetes 1.11, vous pouvez lister et télécharger les images en utilisant les sous commandes à <code>kubeadm config images</code> :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubeadm config images list
</span></span><span style=display:flex><span>kubeadm config images pull
</span></span></code></pre></div><p>A partir de Kubernetes 1.12, les images prefixées par <code>k8s.gcr.io/kube-*</code>, <code>k8s.gcr.io/etcd</code> et <code>k8s.gcr.io/pause</code>
ne nécessitent pas un suffix <code>-${ARCH}</code>.</p><h3 id=automatiser-kubeadm>Automatiser kubeadm</h3><p>Plutôt que copier sur chaque noeud le jeton que vous avez obtenu avec <code>kubeadm init</code>, comme décrit dans
le <a href=/docs/setup/production-environment/tools/kubeadm/create-cluster-kubeadm/>tutoriel basique de kubeadm</a>, vous pouvez paralléliser la distribution du jeton afin d'automatiser cette tâche.
Pour ce faire, vous devez connaître l'adresse IP que le noeud control plane obtiendra après son démarrage.</p><ol><li><p>Générer un jeton. Ce jeton doit avoir correspondre à la chaîne suivante : <code>&lt;6 caractères>.&lt;16 caractères></code>. Plus simplement, il doit correspondre à la regexp suivante :
<code>[a-z0-9]{6}\.[a-z0-9]{16}</code>.</p><p>kubeadm peut générer un jeton pour vous :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubeadm token generate
</span></span></code></pre></div></li><li><p>Démarrer en parallèle le noeud control plane et les noeuds worker nodes avec ce jeton.
Lors de leurs démarrages, ils devraient pouvoir se trouver les uns les autres et former le cluster.
L'option <code>--token</code> peut être utilisée aussi bien pour <code>kubeadm init</code> que pour <code>kubeadm join</code>.</p></li></ol><p>Une fois que le cluster est correctement démarré, vous pouvez obtenir les identifiants admin depuis le noeud control plane depuis le fichier <code>/etc/kubernetes/admin.conf</code>
et les utiliser pour communiquer avec le cluster.</p><p>Vous remarquerez que ce type d'installation présente un niveau de sécurité inférieur puisqu'il ne permet pas la validation du hash du certificat racine avec <code>--discovery-token-ca-cert-hash</code>
(puisqu'il n'est pas généré quand les noeuds sont provisionnés). Pour plus d'information, se référer à <a href=/docs/reference/setup-tools/kubeadm/kubeadm-join/>kubeadm join</a>.</p><h2 id=a-suivre>A suivre</h2><ul><li><a href=/docs/reference/setup-tools/kubeadm/kubeadm-init-phase/>kubeadm init phase</a> pour mieux comprendre les phases <code>kubeadm init</code></li><li><a href=/docs/reference/setup-tools/kubeadm/kubeadm-join/>kubeadm join</a> pour amorcer un noeud Kubernetes worker node Kubernetes et le faire joindre le cluster</li><li><a href=/docs/reference/setup-tools/kubeadm/kubeadm-upgrade/>kubeadm upgrade</a> pour mettre à jour un cluster Kubernetes vers une version plus récente</li><li><a href=/docs/reference/setup-tools/kubeadm/kubeadm-reset/>kubeadm reset</a> pour annuler les changements appliqués avec <code>kubeadm init</code> ou <code>kubeadm join</code> à un noeud</li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-d8df553bae844c94dada72f2d4a75485>7.6.2 - kubefed</h1></div><div class=td-content style=page-break-before:always><h1 id=pg-03460a7254c6c73eb2a1bb3dd7d25910>7.7 - CLI kubectl</h1><div class=lead>kubectl CLI description</div></div><div class=td-content><h1 id=pg-f14fe15ecc2d41b5e901ef5e872ca657>7.7.1 - Aperçu de kubectl</h1><div class=lead>kubectl référence</div><p>Kubectl est un outil en ligne de commande pour contrôler des clusters Kubernetes. <code>kubectl</code> recherche un fichier appelé config dans le répertoire $HOME/.kube. Vous pouvez spécifier d'autres fichiers [kubeconfig](https://kube
rnetes.io/docs/concepts/configuration/organize-cluster-access-kubeconfig/) en définissant la variable d'environnement KUBECONFIG ou en utilisant le paramètre <a href=https://kubernetes.io/docs/concepts/configuration/organize-cluster-access-kubeconfig/><code>--kubeconfig</code></a>.</p><p>Cet aperçu couvre la syntaxe <code>kubectl</code>, décrit les opérations et fournit des exemples classiques. Pour des détails sur chaque commande, incluant toutes les options et sous-commandes autorisées, voir la documentation de référence de <a href=/docs/reference/generated/kubectl/kubectl-commands/>kubectl</a>. Pour des instructions d'installation, voir <a href=/docs/tasks/kubectl/install/>installer kubectl</a>.</p><h2 id=syntaxe>Syntaxe</h2><p>Utilisez la syntaxe suivante pour exécuter des commandes <code>kubectl</code> depuis votre fenêtre de terminal :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl <span style=color:#666>[</span>commande<span style=color:#666>]</span> <span style=color:#666>[</span>TYPE<span style=color:#666>]</span> <span style=color:#666>[</span>NOM<span style=color:#666>]</span> <span style=color:#666>[</span>flags<span style=color:#666>]</span>
</span></span></code></pre></div><p>où <code>commande</code>, <code>TYPE</code>, <code>NOM</code> et <code>flags</code> sont :</p><ul><li><p><code>commande</code>: Indique l'opération que vous désirez exécuter sur une ou plusieurs ressources, par exemple <code>create</code>, <code>get</code>, <code>describe</code>, <code>delete</code>.</p></li><li><p><code>TYPE</code>: Indique le <a href=#resource-types>type de ressource</a>. Les types de ressources sont insensibles à la casse et vous pouvez utiliser les formes singulier, pluriel ou abrégé. Par exemple, les commandes suivantes produisent le même résultat :</p><pre><code>```shell
$ kubectl get pod pod1
$ kubectl get pods pod1
$ kubectl get po pod1
```
</code></pre></li><li><p><code>NOM</code>: Indique le nom de la ressource. Les noms sont sensibles à la casse. Si le nom est omis, des détails pour toutes les ressources sont affichés, par exemple <code>$ kubectl get pods</code>.</p><p>En effectuant une opération sur plusieurs ressources, vous pouvez soit indiquer chaque ressource par leur type et nom soit indiquer un ou plusieurs fichiers :</p><ul><li><p>Pour indiquer des ressources par leur type et nom :</p><ul><li><p>Pour regrouper des ressources si elles ont toutes le même type : <code>TYPE1 nom1 nom2 nom&lt;#></code>.<br>Example: <code>$ kubectl get pod exemple-pod1 exemple-pod2</code></p></li><li><p>Pour indiquer plusieurs types de ressources individuellement : <code>TYPE1/nom1 TYPE1/nom2 TYPE2/nom3 TYPE&lt;#>/nom&lt;#></code>.<br>Exemple: <code>$ kubectl get pod/exemple-pod1 replicationcontroller/exemple-rc1</code></p></li></ul></li><li><p>Pour indiquer des ressources avec un ou plusieurs fichiers : <code>-f fichier1 -f fichier2 -f fichier&lt;#></code></p><ul><li><a href=/docs/concepts/configuration/overview/#general-configuration-tips>Utilisez YAML plutôt que JSON</a>, YAML tendant à être plus facile à utiliser, particulièrement pour des fichiers de configuration.<br>Exemple: <code>$ kubectl get pod -f ./pod.yaml</code></li></ul></li></ul></li><li><p><code>flags</code>: Indique des flags optionnels. Par exemple, vous pouvez utiliser les flags <code>-s</code> ou <code>--server</code> pour indiquer l'adresse et le port de l'API server Kubernetes.<br></p></li></ul><div class="alert alert-warning caution callout" role=alert><strong>Avertissement:</strong> Les flags indiqués en ligne de commande écrasent les valeurs par défaut et les variables d'environnement correspondantes.</div><p>Si vous avez besoin d'aide, exécutez <code>kubectl help</code> depuis la fenêtre de terminal.</p><h2 id=opérations>Opérations</h2><p>Le tableau suivant inclut une courte description et la syntaxe générale pour chaque opération <code>kubectl</code> :</p><table><thead><tr><th>Opération</th><th>Syntaxe</th><th>Description</th></tr></thead><tbody><tr><td><code>alpha</code></td><td><code>kubectl alpha SOUS-COMMANDE [flags]</code></td><td>Liste les commandes disponibles qui correspondent à des fonctionnalités alpha, qui ne sont pas activées par défaut dans les clusters Kubernetes.</td></tr><tr><td><code>annotate</code></td><td><code>kubectl annotate (-f FICHIER | TYPE NOM | TYPE/NOM) CLE_1=VAL_1 ... CLE_N=VAL_N [--overwrite] [--all] [--resource-version=version] [flags]</code></td><td>Ajoute ou modifie les annotations d'une ou plusieurs ressources.</td></tr><tr><td><code>api-resources</code></td><td><code>kubectl api-resources [flags]</code></td><td>Liste les ressources d'API disponibles.</td></tr><tr><td><code>api-versions</code></td><td><code>kubectl api-versions [flags]</code></td><td>Liste les versions d'API disponibles.</td></tr><tr><td><code>apply</code></td><td><code>kubectl apply -f FICHIER [flags]</code></td><td>Applique un changement de configuration à une ressource depuis un fichier ou stdin.</td></tr><tr><td><code>attach</code></td><td><code>kubectl attach POD -c CONTENEUR [-i] [-t] [flags]</code></td><td>Attache à un conteneur en cours d'exécution soit pour voir la sortie standard soit pour interagir avec le conteneur (stdin).</td></tr><tr><td><code>auth</code></td><td><code>kubectl auth [flags] [options]</code></td><td>Inspecte les autorisations.</td></tr><tr><td><code>autoscale</code></td><td><code>kubectl autoscale (-f FICHIER | TYPE NOM | TYPE/NOM) [--min=MINPODS] --max=MAXPODS [--cpu-percent=CPU] [flags]</code></td><td>Scale automatiquement l'ensemble des pods gérés par un replication controller.</td></tr><tr><td><code>certificate</code></td><td><code>kubectl certificate SOUS-COMMANDE [options]</code></td><td>Modifie les ressources de type certificat.</td></tr><tr><td><code>cluster-info</code></td><td><code>kubectl cluster-info [flags]</code></td><td>Affiche les informations des endpoints du master et des services du cluster.</td></tr><tr><td><code>completion</code></td><td><code>kubectl completion SHELL [options]</code></td><td>Affiche le code de complétion pour le shell spécifié (bash ou zsh).</td></tr><tr><td><code>config</code></td><td><code>kubectl config SOUS-COMMANDE [flags]</code></td><td>Modifie les fichiers kubeconfig. Voir les sous-commandes individuelles pour plus de détails.</td></tr><tr><td><code>convert</code></td><td><code>kubectl convert -f FICHIER [options]</code></td><td>Convertit des fichiers de configuration entre différentes versions d'API. Les formats YAML et JSON sont acceptés.</td></tr><tr><td><code>cordon</code></td><td><code>kubectl cordon NOEUD [options]</code></td><td>Marque un nœud comme non programmable.</td></tr><tr><td><code>cp</code></td><td><code>kubectl cp &lt;ficher-src> &lt;fichier-dest> [options]</code></td><td>Copie des fichiers et des répertoires vers et depuis des conteneurs.</td></tr><tr><td><code>create</code></td><td><code>kubectl create -f FICHIER [flags]</code></td><td>Crée une ou plusieurs ressources depuis un fichier ou stdin.</td></tr><tr><td><code>delete</code></td><td><code>kubectl delete (-f FICHIER | TYPE [NOM | /NOM | -l label | --all]) [flags]</code></td><td>Supprime des ressources soit depuis un fichier ou stdin, ou en indiquant des sélecteurs de label, des noms, des sélecteurs de ressources ou des ressources.</td></tr><tr><td><code>describe</code></td><td><code>kubectl describe (-f FICHIER | TYPE [PREFIXE_NOM | /NOM | -l label]) [flags]</code></td><td>Affiche l'état détaillé d'une ou plusieurs ressources.</td></tr><tr><td><code>diff</code></td><td><code>kubectl diff -f FICHIER [flags]</code></td><td>Diff un fichier ou stdin par rapport à la configuration en cours</td></tr><tr><td><code>drain</code></td><td><code>kubectl drain NOEUD [options]</code></td><td>Vide un nœud en préparation de sa mise en maintenance.</td></tr><tr><td><code>edit</code></td><td><code>kubectl edit (-f FICHIER | TYPE NOM | TYPE/NOM) [flags]</code></td><td>Édite et met à jour la définition d'une ou plusieurs ressources sur le serveur en utilisant l'éditeur par défaut.</td></tr><tr><td><code>exec</code></td><td><code>kubectl exec POD [-c CONTENEUR] [-i] [-t] [flags] [-- COMMANDE [args...]]</code></td><td>Exécute une commande à l'intérieur d'un conteneur dans un pod.</td></tr><tr><td><code>explain</code></td><td><code>kubectl explain [--recursive=false] [flags]</code></td><td>Obtient des informations sur différentes ressources. Par exemple pods, nœuds, services, etc.</td></tr><tr><td><code>expose</code></td><td><code>kubectl expose (-f FICHIER | TYPE NOM | TYPE/NOM) [--port=port] [--protocol=TCP|UDP] [--target-port=nombre-ou-nom] [--name=nom] [--external-ip=ip-externe-ou-service] [--type=type] [flags]</code></td><td>Expose un replication controller, service ou pod comme un nouveau service Kubernetes.</td></tr><tr><td><code>get</code></td><td><code>kubectl get (-f FICHIER | TYPE [NOM | /NOM | -l label]) [--watch] [--sort-by=CHAMP] [[-o | --output]=FORMAT_AFFICHAGE] [flags]</code></td><td>Liste une ou plusieurs ressources.</td></tr><tr><td><code>kustomize</code></td><td><code>kubectl kustomize &lt;répertoire> [flags] [options]</code></td><td>Liste un ensemble de ressources d'API généré à partir d'instructions d'un fichier kustomization.yaml. Le paramètre doit être le chemin d'un répertoire contenant ce fichier, ou l'URL d'un dépôt git incluant un suffixe de chemin par rapport à la racine du dépôt.</td></tr><tr><td><code>label</code></td><td><code>kubectl label (-f FICHIER | TYPE NOM | TYPE/NOM) CLE_1=VAL_1 ... CLE_N=VAL_N [--overwrite] [--all] [--resource-version=version] [flags]</code></td><td>Ajoute ou met à jour les labels d'une ou plusieurs ressources.</td></tr><tr><td><code>logs</code></td><td><code>kubectl logs POD [-c CONTENEUR] [--follow] [flags]</code></td><td>Affiche les logs d'un conteneur dans un pod.</td></tr><tr><td><code>options</code></td><td><code>kubectl options</code></td><td>Liste des options globales, s'appliquant à toutes commandes.</td></tr><tr><td><code>patch</code></td><td><code>kubectl patch (-f FICHIER | TYPE NOM | TYPE/NOM) --patch PATCH [flags]</code></td><td>Met à jour un ou plusieurs champs d'une resource en utilisant le processus de merge patch stratégique.</td></tr><tr><td><code>plugin</code></td><td><code>kubectl plugin [flags] [options]</code></td><td>Fournit des utilitaires pour interagir avec des plugins.</td></tr><tr><td><code>port-forward</code></td><td><code>kubectl port-forward POD [PORT_LOCAL:]PORT_DISTANT [...[PORT_LOCAL_N:]PORT_DISTANT_N] [flags]</code></td><td>Transfère un ou plusieurs ports locaux vers un pod.</td></tr><tr><td><code>proxy</code></td><td><code>kubectl proxy [--port=PORT] [--www=static-dir] [--www-prefix=prefix] [--api-prefix=prefix] [flags]</code></td><td>Exécute un proxy vers un API server Kubernetes.</td></tr><tr><td><code>replace</code></td><td><code>kubectl replace -f FICHIER</code></td><td>Remplace une ressource depuis un fichier ou stdin.</td></tr><tr><td><code>rollout</code></td><td><code>kubectl rollout SOUS-COMMANDE [options]</code></td><td>Gère le rollout d'une ressource. Les types de ressources valides sont : deployments, daemonsets et statefulsets.</td></tr><tr><td><code>run</code></td><td><code>kubectl run NOM --image=image [--env="cle=valeur"] [--port=port] [--replicas=replicas] [--dry-run=server&amp;#124;client&amp;#124;none] [--overrides=inline-json] [flags]</code></td><td>Exécute dans le cluster l'image indiquée.</td></tr><tr><td><code>scale</code></td><td><code>kubectl scale (-f FICHIER | TYPE NOM | TYPE/NOM) --replicas=QUANTITE [--resource-version=version] [--current-replicas=quantité] [flags]</code></td><td>Met à jour la taille du replication controller indiqué.</td></tr><tr><td><code>set</code></td><td><code>kubectl set SOUS-COMMANDE [options]</code></td><td>Configure les ressources de l'application.</td></tr><tr><td><code>taint</code></td><td><code>kubectl taint NOEUD NNOM CLE_1=VAL_1:EFFET_TAINT_1 ... CLE_N=VAL_N:EFFET_TAINT_N [options]</code></td><td>Met à jour les marques (taints) d'un ou plusieurs nœuds.</td></tr><tr><td><code>top</code></td><td><code>kubectl top [flags] [options]</code></td><td>Affiche l'utilisation des ressources (CPU/Mémoire/Stockage).</td></tr><tr><td><code>uncordon</code></td><td><code>kubectl uncordon NOEUD [options]</code></td><td>Marque un noeud comme programmable.</td></tr><tr><td><code>version</code></td><td><code>kubectl version [--client] [flags]</code></td><td>Affiche la version de Kubernetes du serveur et du client.</td></tr><tr><td><code>wait</code></td><td><code>kubectl wait ([-f FICHIER] | ressource.groupe/ressource.nom | ressource.groupe [(-l label | --all)]) [--for=delete|--for condition=available] [options]</code></td><td>Expérimental : Attend un condition spécifique sur une ou plusieurs ressources.</td></tr></tbody></table><p>Rappelez-vous : Pour tout savoir sur les opérations, voir la documentation de référence de <a href=/docs/user-guide/kubectl/>kubectl</a>.</p><h2 id=types-de-ressources>Types de ressources</h2><p>Le tableau suivant inclut la liste de tous les types de ressources pris en charge et leurs alias abrégés.</p><p>(cette sortie peut être obtenue depuis <code>kubectl api-resources</code>, et correspond à Kubernetes 1.13.3.)</p><table><thead><tr><th>Nom de la ressource</th><th>Noms abrégés</th><th>Groupe API</th><th>Par namespace</th><th>Genre de la ressource</th></tr></thead><tbody><tr><td><code>bindings</code></td><td></td><td></td><td>true</td><td>Binding</td></tr><tr><td><code>componentstatuses</code></td><td><code>cs</code></td><td></td><td>false</td><td>ComponentStatus</td></tr><tr><td><code>configmaps</code></td><td><code>cm</code></td><td></td><td>true</td><td>ConfigMap</td></tr><tr><td><code>endpoints</code></td><td><code>ep</code></td><td></td><td>true</td><td>Endpoints</td></tr><tr><td><code>limitranges</code></td><td><code>limits</code></td><td></td><td>true</td><td>LimitRange</td></tr><tr><td><code>namespaces</code></td><td><code>ns</code></td><td></td><td>false</td><td>Namespace</td></tr><tr><td><code>nodes</code></td><td><code>no</code></td><td></td><td>false</td><td>Node</td></tr><tr><td><code>persistentvolumeclaims</code></td><td><code>pvc</code></td><td></td><td>true</td><td>PersistentVolumeClaim</td></tr><tr><td><code>persistentvolumes</code></td><td><code>pv</code></td><td></td><td>false</td><td>PersistentVolume</td></tr><tr><td><code>pods</code></td><td><code>po</code></td><td></td><td>true</td><td>Pod</td></tr><tr><td><code>podtemplates</code></td><td></td><td></td><td>true</td><td>PodTemplate</td></tr><tr><td><code>replicationcontrollers</code></td><td><code>rc</code></td><td></td><td>true</td><td>ReplicationController</td></tr><tr><td><code>resourcequotas</code></td><td><code>quota</code></td><td></td><td>true</td><td>ResourceQuota</td></tr><tr><td><code>secrets</code></td><td></td><td></td><td>true</td><td>Secret</td></tr><tr><td><code>serviceaccounts</code></td><td><code>sa</code></td><td></td><td>true</td><td>ServiceAccount</td></tr><tr><td><code>services</code></td><td><code>svc</code></td><td></td><td>true</td><td>Service</td></tr><tr><td><code>mutatingwebhookconfigurations</code></td><td></td><td>admissionregistration.k8s.io</td><td>false</td><td>MutatingWebhookConfiguration</td></tr><tr><td><code>validatingwebhookconfigurations</code></td><td></td><td>admissionregistration.k8s.io</td><td>false</td><td>ValidatingWebhookConfiguration</td></tr><tr><td><code>customresourcedefinitions</code></td><td><code>crd</code>, <code>crds</code></td><td>apiextensions.k8s.io</td><td>false</td><td>CustomResourceDefinition</td></tr><tr><td><code>apiservices</code></td><td></td><td>apiregistration.k8s.io</td><td>false</td><td>APIService</td></tr><tr><td><code>controllerrevisions</code></td><td></td><td>apps</td><td>true</td><td>ControllerRevision</td></tr><tr><td><code>daemonsets</code></td><td><code>ds</code></td><td>apps</td><td>true</td><td>DaemonSet</td></tr><tr><td><code>deployments</code></td><td><code>deploy</code></td><td>apps</td><td>true</td><td>Deployment</td></tr><tr><td><code>replicasets</code></td><td><code>rs</code></td><td>apps</td><td>true</td><td>ReplicaSet</td></tr><tr><td><code>statefulsets</code></td><td><code>sts</code></td><td>apps</td><td>true</td><td>StatefulSet</td></tr><tr><td><code>tokenreviews</code></td><td></td><td>authentication.k8s.io</td><td>false</td><td>TokenReview</td></tr><tr><td><code>localsubjectaccessreviews</code></td><td></td><td>authorization.k8s.io</td><td>true</td><td>LocalSubjectAccessReview</td></tr><tr><td><code>selfsubjectaccessreviews</code></td><td></td><td>authorization.k8s.io</td><td>false</td><td>SelfSubjectAccessReview</td></tr><tr><td><code>selfsubjectrulesreviews</code></td><td></td><td>authorization.k8s.io</td><td>false</td><td>SelfSubjectRulesReview</td></tr><tr><td><code>subjectaccessreviews</code></td><td></td><td>authorization.k8s.io</td><td>false</td><td>SubjectAccessReview</td></tr><tr><td><code>horizontalpodautoscalers</code></td><td><code>hpa</code></td><td>autoscaling</td><td>true</td><td>HorizontalPodAutoscaler</td></tr><tr><td><code>cronjobs</code></td><td><code>cj</code></td><td>batch</td><td>true</td><td>CronJob</td></tr><tr><td><code>jobs</code></td><td></td><td>batch</td><td>true</td><td>Job</td></tr><tr><td><code>certificatesigningrequests</code></td><td><code>csr</code></td><td>certificates.k8s.io</td><td>false</td><td>CertificateSigningRequest</td></tr><tr><td><code>leases</code></td><td></td><td>coordination.k8s.io</td><td>true</td><td>Lease</td></tr><tr><td><code>events</code></td><td><code>ev</code></td><td>events.k8s.io</td><td>true</td><td>Event</td></tr><tr><td><code>ingresses</code></td><td><code>ing</code></td><td>extensions</td><td>true</td><td>Ingress</td></tr><tr><td><code>networkpolicies</code></td><td><code>netpol</code></td><td>networking.k8s.io</td><td>true</td><td>NetworkPolicy</td></tr><tr><td><code>poddisruptionbudgets</code></td><td><code>pdb</code></td><td>policy</td><td>true</td><td>PodDisruptionBudget</td></tr><tr><td><code>podsecuritypolicies</code></td><td><code>psp</code></td><td>policy</td><td>false</td><td>PodSecurityPolicy</td></tr><tr><td><code>clusterrolebindings</code></td><td></td><td>rbac.authorization.k8s.io</td><td>false</td><td>ClusterRoleBinding</td></tr><tr><td><code>clusterroles</code></td><td></td><td>rbac.authorization.k8s.io</td><td>false</td><td>ClusterRole</td></tr><tr><td><code>rolebindings</code></td><td></td><td>rbac.authorization.k8s.io</td><td>true</td><td>RoleBinding</td></tr><tr><td><code>roles</code></td><td></td><td>rbac.authorization.k8s.io</td><td>true</td><td>Role</td></tr><tr><td><code>priorityclasses</code></td><td><code>pc</code></td><td>scheduling.k8s.io</td><td>false</td><td>PriorityClass</td></tr><tr><td><code>csidrivers</code></td><td></td><td>storage.k8s.io</td><td>false</td><td>CSIDriver</td></tr><tr><td><code>csinodes</code></td><td></td><td>storage.k8s.io</td><td>false</td><td>CSINode</td></tr><tr><td><code>storageclasses</code></td><td><code>sc</code></td><td>storage.k8s.io</td><td>false</td><td>StorageClass</td></tr><tr><td><code>volumeattachments</code></td><td></td><td>storage.k8s.io</td><td>false</td><td>VolumeAttachment</td></tr></tbody></table><h2 id=options-de-sortie>Options de sortie</h2><p>Utilisez les sections suivantes pour savoir comment vous pouvez formater ou ordonner les sorties de certaines commandes.
Pour savoir exactgement quelles commandes prennent en charge quelles options de sortie, voir la documentation de référence de <a href=/docs/user-guide/kubectl/>kubectl</a>.</p><h3 id=formater-la-sortie>Formater la sortie</h3><p>Le format de sortie par défaut pour toutes les commandes <code>kubectl</code> est le format texte lisible par l'utilisateur. Pour afficher des détails dans votre fenêtre de terminal dans un format spécifique, vous pouvez ajouter une des options <code>-o</code> ou <code>--output</code> à une des commandes <code>kubectl</code> les prenant en charge.</p><h4 id=syntaxe-1>Syntaxe</h4><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl <span style=color:#666>[</span>commande<span style=color:#666>]</span> <span style=color:#666>[</span>TYPE<span style=color:#666>]</span> <span style=color:#666>[</span>NOM<span style=color:#666>]</span> -o &lt;format_sortie&gt;
</span></span></code></pre></div><p>Selon l'opération <code>kubectl</code>, les formats de sortie suivants sont pris en charge :</p><table><thead><tr><th>Format de sortie</th><th>Description</th></tr></thead><tbody><tr><td><code>-o custom-columns=&lt;spec></code></td><td>Affiche un tableau en utilisant une liste de <a href=#custom-columns>colonnes personnalisées</a> séparées par des virgules.</td></tr><tr><td><code>-o custom-columns-file=&lt;fichier></code></td><td>Affiche un tableau en utilisant un modèle de <a href=#custom-columns>colonnes personnalisées</a> dans le fichier <code>&lt;fichier></code>.</td></tr><tr><td><code>-o json</code></td><td>Affiche un objet de l'API formaté en JSON.</td></tr><tr><td><code>-o jsonpath=&lt;modèle></code></td><td>Affiche les champs définis par une expression <a href=/docs/reference/kubectl/jsonpath/>jsonpath</a>.</td></tr><tr><td><code>-o jsonpath-file=&lt;ffichier></code></td><td>Affiche les champs définis par une expression <a href=/docs/reference/kubectl/jsonpath/>jsonpath</a> dans le fichier <code>&lt;fichier></code>.</td></tr><tr><td><code>-o name</code></td><td>Affiche uniquement le nom de la ressource et rien de plus.</td></tr><tr><td><code>-o wide</code></td><td>Affiche dans le format texte avec toute information supplémentaire. Pour les pods, le nom du nœud est inclus.</td></tr><tr><td><code>-o yaml</code></td><td>Affiche un objet de l'API formaté en YAML.</td></tr></tbody></table><h5 id=exemple>Exemple</h5><p>Dans cet exemple, la commande suivante affiche les détails d'un unique pod sous forme d'un objet formaté en YAML :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>$ kubectl get pod web-pod-13je7 -o yaml
</span></span></code></pre></div><p>Souvenez-vous : Voir la documentation de référence de <a href=/docs/user-guide/kubectl/>kubectl</a> pour voir quels formats de sortie sont pris en charge par chaque commande.</p><h4 id=colonnes-personnalisées>Colonnes personnalisées</h4><p>Pour définir des colonnes personnalisées et afficher uniquement les détails voulus dans un tableau, vous pouvez utiliser l'option <code>custom-columns</code>. Vous pouvez choisir de définir les colonnes personnalisées soit en ligne soit dans un fichier modèle : <code>-o custom-columns=&lt;spec></code> ou <code>-o custom-columns-file=&lt;fichier></code>.</p><h5 id=exemples>Exemples</h5><p>En ligne :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>$ kubectl get pods &lt;nom-pod&gt; -o custom-columns<span style=color:#666>=</span>NOM:.metadata.name,RSRC:.metadata.resourceVersion
</span></span></code></pre></div><p>Fichier modèle :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>$ kubectl get pods &lt;nom-pod&gt; -o custom-columns-file<span style=color:#666>=</span>modele.txt
</span></span></code></pre></div><p>où le fichier <code>modele.txt</code> contient :</p><pre tabindex=0><code>NOM           RSRC
metadata.name metadata.resourceVersion
</code></pre><p>Le résultat de ces commandes est :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>NOM            RSRC
</span></span><span style=display:flex><span>submit-queue   <span style=color:#666>610995</span>
</span></span></code></pre></div><h4 id=colonnes-côté-serveur>Colonnes côté serveur</h4><p><code>kubectl</code> est capable de recevoir des informations de colonnes spécifiques d'objets depuis le serveur.
Cela veut dire que pour toute ressource donnée, le serveur va retourner les colonnes et lignes pour cette ressource, que le client pourra afficher.
Cela permet un affichage de sortie lisible par l'utilisateur cohérent entre les clients utilisés sur le même cluster, le serveur encapsulant les détails d'affichage.</p><p>Cette fonctionnalité est activée par défaut dans <code>kubectl</code> version 1.11 et suivantes. Pour la désactiver, ajoutez l'option
<code>--server-print=false</code> à la commande <code>kubectl get</code>.</p><h5 id=exemples-1>Exemples</h5><p>Pour afficher les informations sur le status d'un pod, utilisez une commande similaire à :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get pods &lt;nom-pod&gt; --server-print<span style=color:#666>=</span><span style=color:#a2f>false</span>
</span></span></code></pre></div><p>La sortie ressemble à :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>NAME       AGE
</span></span><span style=display:flex><span>nom-pod    1m
</span></span></code></pre></div><h3 id=ordonner-les-listes-d-objets>Ordonner les listes d'objets</h3><p>Pour afficher les objets dans une liste ordonnée dans une fenêtre de terminal, vous pouvez ajouter l'option <code>--sort-by</code> à une commande <code>kubectl</code> qui la prend en charge. Ordonnez vos objets en spécifiant n'importe quel champ numérique ou textuel avec l'option <code>--sort-by</code>. Pour spécifier un champ, utilisez une expression <a href=/docs/reference/kubectl/jsonpath/>jsonpath</a>.</p><h4 id=syntaxe-2>Syntaxe</h4><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl <span style=color:#666>[</span>commande<span style=color:#666>]</span> <span style=color:#666>[</span>TYPE<span style=color:#666>]</span> <span style=color:#666>[</span>NOM<span style=color:#666>]</span> --sort-by<span style=color:#666>=</span>&lt;exp_jsonpath&gt;
</span></span></code></pre></div><h5 id=exemple-1>Exemple</h5><p>Pour afficher une liste de pods ordonnés par nom, exécutez :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>$ kubectl get pods --sort-by<span style=color:#666>=</span>.metadata.name
</span></span></code></pre></div><h2 id=exemples-opérations-courantes>Exemples : Opérations courantes</h2><p>Utilisez les exemples suivants pour vous familiariser avec les opérations de <code>kubectl</code> fréquemment utilisées :</p><p><code>kubectl apply</code> - Créer une ressource depuis un fichier ou stdin.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span><span style=color:#080;font-style:italic># Crée un service en utilisant la définition dans exemple-service.yaml.</span>
</span></span><span style=display:flex><span>$ kubectl apply -f exemple-service.yaml
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#080;font-style:italic># Crée un replication controller en utilisant la définition dans exemple-controller.yaml.</span>
</span></span><span style=display:flex><span>$ kubectl apply -f exemple-controller.yaml
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#080;font-style:italic># Crée les objets qui sont définis dans les fichiers .yaml, .yml ou .json du répertoire &lt;répertoire&gt;.</span>
</span></span><span style=display:flex><span>$ kubectl apply -f &lt;répertoire&gt;
</span></span></code></pre></div><p><code>kubectl get</code> - Liste une ou plusieurs ressources.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span><span style=color:#080;font-style:italic># Liste tous les pods dans le format de sortie texte.</span>
</span></span><span style=display:flex><span>$ kubectl get pods
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#080;font-style:italic># Liste tous les pods dans le format de sortie texte et inclut des informations additionnelles (comme le nom du nœud).</span>
</span></span><span style=display:flex><span>$ kubectl get pods -o wide
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#080;font-style:italic># Liste le replication controller ayant le nom donné dans le format de sortie texte.</span>
</span></span><span style=display:flex><span><span style=color:#080;font-style:italic># Astuce : Vous pouvez raccourcir et remplacer le type de ressource &#39;replicationcontroller&#39; avec l&#39;alias &#39;rc&#39;.</span>
</span></span><span style=display:flex><span>$ kubectl get replicationcontroller &lt;nom-rc&gt;
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#080;font-style:italic># Liste ensemble tous les replication controller et les services dans le format de sortie texte.</span>
</span></span><span style=display:flex><span>$ kubectl get rc,services
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#080;font-style:italic># Liste tous les daemon sets dans le format de sortie texte.</span>
</span></span><span style=display:flex><span>kubectl get ds
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#080;font-style:italic># Liste tous les pods s&#39;exécutant sur le nœud serveur01</span>
</span></span><span style=display:flex><span>$ kubectl get pods --field-selector<span style=color:#666>=</span>spec.nodeName<span style=color:#666>=</span>serveur01
</span></span></code></pre></div><p><code>kubectl describe</code> - Affiche l'état détaillé d'une ou plusieurs ressources, en incluant par défaut les ressources non initialisées.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span><span style=color:#080;font-style:italic># Affiche les détails du nœud ayant le nom &lt;nom-nœud&gt;.</span>
</span></span><span style=display:flex><span>$ kubectl describe nodes &lt;nom-nœud&gt;
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#080;font-style:italic># Affiche les détails du pod ayant le nom &lt;nom-pod&gt;.</span>
</span></span><span style=display:flex><span>$ kubectl describe pods/&lt;nom-pod&gt;
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#080;font-style:italic># Affiche les détails de tous les pods gérés par le replication controller dont le nom est &lt;nom-rc&gt;.</span>
</span></span><span style=display:flex><span><span style=color:#080;font-style:italic># Rappelez-vous : les noms des pods étant créés par un replication controller sont préfixés par le nom du replication controller.</span>
</span></span><span style=display:flex><span>$ kubectl describe pods &lt;nom-rc&gt;
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#080;font-style:italic># Décrit tous les pods</span>
</span></span><span style=display:flex><span>$ kubectl describe pods
</span></span></code></pre></div><div class="alert alert-info note callout" role=alert><strong>Note:</strong> La commande <code>kubectl get</code> est habituellement utilisée pour afficher une ou plusieurs ressources d'un même type. Elle propose un ensemble complet d'options permettant de personnaliser le format de sortie avec les options <code>-o</code> ou <code>--output</code>, par exemple.
Vous pouvez utiliser les options <code>-w</code> ou <code>--watch</code> pour initier l'écoute des modifications d'un objet particulier. La commande <code>kubectl describe</code> est elle plutôt utilisée pour décrire les divers aspects d'une ressource voulue. Elle peut invoquer plusieurs appels d'API à l'API server pour construire une vue complète pour l'utilisateur. Par exemple, la commande <code>kubectl describe node</code> retourne non seulement les informations sur les nœuds, mais aussi un résumé des pods s'exécutant dessus, les événements générés pour chaque nœud, etc.nœud</div><p><code>kubectl delete</code> - Supprime des ressources soit depuis un fichier, stdin, ou en spécifiant des sélecteurs de labels, des noms, des sélecteurs de ressource ou des ressources.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span><span style=color:#080;font-style:italic># Supprime un pod en utilisant le type et le nom spécifiés dans le fichier pod.yaml.</span>
</span></span><span style=display:flex><span>$ kubectl delete -f pod.yaml
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#080;font-style:italic># Supprime tous les pods et services ayant le label &lt;clé-label&gt;=&lt;valeur-label&gt;</span>
</span></span><span style=display:flex><span>$ kubectl delete pods,services -l &lt;clé-label&gt;<span style=color:#666>=</span>&lt;valeur-label&gt;
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#080;font-style:italic># Supprime tous les pods, en incluant les non initialisés.</span>
</span></span><span style=display:flex><span>$ kubectl delete pods --all
</span></span></code></pre></div><p><code>kubectl exec</code> - Exécute une commande depuis un conteneur d'un pod.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span><span style=color:#080;font-style:italic># Affiche la sortie de la commande &#39;date&#39; depuis le pod &lt;nom-pod&gt;. Par défaut, la sortie se fait depuis le premier conteneur.</span>
</span></span><span style=display:flex><span>$ kubectl <span style=color:#a2f>exec</span> &lt;nom-pod&gt; -- date
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#080;font-style:italic># Affiche la sortie de la commande &#39;date&#39; depuis le conteneur &lt;nom-conteneur&gt; du pod &lt;nom-pod&gt;.</span>
</span></span><span style=display:flex><span>$ kubectl <span style=color:#a2f>exec</span> &lt;nom-pod&gt; -c &lt;nom-conteneur&gt; -- date
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#080;font-style:italic># Obtient un TTY interactif et exécute /bin/bash depuis le pod &lt;nom-pod&gt;. Par défaut, la sortie se fait depuis le premier conteneur.</span>
</span></span><span style=display:flex><span>$ kubectl <span style=color:#a2f>exec</span> -ti &lt;nom-pod&gt; -- /bin/bash
</span></span></code></pre></div><p><code>kubectl logs</code> - Affiche les logs d'un conteneur dans un pod.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span><span style=color:#080;font-style:italic># Retourne un instantané des logs du pod &lt;nom-pod&gt;.</span>
</span></span><span style=display:flex><span>$ kubectl logs &lt;nom-pod&gt;
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#080;font-style:italic># Commence à streamer les logs du pod &lt;nom-pod&gt;. Ceci est similaire à la commande Linux &#39;tail -f&#39;.</span>
</span></span><span style=display:flex><span>$ kubectl logs -f &lt;nom-pod&gt;
</span></span></code></pre></div><p><code>kubectl diff</code> - Affiche un diff des mises à jour proposées au cluster.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span><span style=color:#080;font-style:italic># Diff les ressources présentes dans &#34;pod.json&#34;.</span>
</span></span><span style=display:flex><span>kubectl diff -f pod.json
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#080;font-style:italic># Diff les ressources présentes dans le fichier lu sur l&#39;entrée standard.</span>
</span></span><span style=display:flex><span>cat service.yaml | kubectl diff -f -
</span></span></code></pre></div><h2 id=exemples-créer-et-utiliser-des-plugins>Exemples : Créer et utiliser des plugins</h2><p>Utilisez les exemples suivants pour vous familiariser avec l'écriture et l'utilisation de plugins <code>kubectl</code> :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span><span style=color:#080;font-style:italic># créez un plugin simple dans n&#39;importe quel langage et nommez</span>
</span></span><span style=display:flex><span><span style=color:#080;font-style:italic># l&#39;exécutable de telle sorte qu&#39;il commence par &#34;kubectl-&#34;</span>
</span></span><span style=display:flex><span>$ cat ./kubectl-hello
</span></span><span style=display:flex><span><span style=color:#080;font-style:italic>#!/bin/bash</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#080;font-style:italic># ce plugin affiche les mots &#34;hello world&#34;</span>
</span></span><span style=display:flex><span><span style=color:#a2f>echo</span> <span style=color:#b44>&#34;hello world&#34;</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#080;font-style:italic># une fois votre plugin écrit, rendez-le exécutable</span>
</span></span><span style=display:flex><span>$ sudo chmod +x ./kubectl-hello
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#080;font-style:italic># et déplacez-le dans un répertoire de votre PATH</span>
</span></span><span style=display:flex><span>$ sudo mv ./kubectl-hello /usr/local/bin
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#080;font-style:italic># vous avez maintenant créé et &#34;installé&#34; un plugin kubectl.</span>
</span></span><span style=display:flex><span><span style=color:#080;font-style:italic># vous pouvez commencer à l&#39;utiliser en l&#39;invoquant depuis kubectl</span>
</span></span><span style=display:flex><span><span style=color:#080;font-style:italic># comme s&#39;il s&#39;agissait d&#39;une commande ordinaire</span>
</span></span><span style=display:flex><span>$ kubectl hello
</span></span><span style=display:flex><span>hello world
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#080;font-style:italic># vous pouvez &#34;désinstaller&#34; un plugin,</span>
</span></span><span style=display:flex><span><span style=color:#080;font-style:italic># simplement en le supprimant de votre PATH</span>
</span></span><span style=display:flex><span>$ sudo rm /usr/local/bin/kubectl-hello
</span></span></code></pre></div><p>Pour voir tous les plugins disponibles pour <code>kubectl</code>, vous pouvez utiliser la sous-commande <code>kubectl plugin list</code> :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>$ kubectl plugin list
</span></span><span style=display:flex><span>The following kubectl-compatible plugins are available:
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>/usr/local/bin/kubectl-hello
</span></span><span style=display:flex><span>/usr/local/bin/kubectl-foo
</span></span><span style=display:flex><span>/usr/local/bin/kubectl-bar
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#080;font-style:italic># cette commande peut aussi vous avertir de plugins qui ne sont pas exécutables,</span>
</span></span><span style=display:flex><span><span style=color:#080;font-style:italic># ou qui sont cachés par d&#39;autres plugins, par exemple :</span>
</span></span><span style=display:flex><span>$ sudo chmod -x /usr/local/bin/kubectl-foo
</span></span><span style=display:flex><span>$ kubectl plugin list
</span></span><span style=display:flex><span>The following kubectl-compatible plugins are available:
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>/usr/local/bin/kubectl-hello
</span></span><span style=display:flex><span>/usr/local/bin/kubectl-foo
</span></span><span style=display:flex><span>  - warning: /usr/local/bin/kubectl-foo identified as a plugin, but it is not executable
</span></span><span style=display:flex><span>/usr/local/bin/kubectl-bar
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>error: one plugin warning was found
</span></span></code></pre></div><p>Vous pouvez voir les plugins comme un moyen de construire des fonctionnalités plus complexes au dessus des commandes kubectl existantes :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>$ cat ./kubectl-whoami
</span></span><span style=display:flex><span><span style=color:#080;font-style:italic>#!/bin/bash</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#080;font-style:italic># ce plugin utilise la commande `kubectl config` pour afficher</span>
</span></span><span style=display:flex><span><span style=color:#080;font-style:italic># l&#39;information sur l&#39;utilisateur courant, en se basant sur</span>
</span></span><span style=display:flex><span><span style=color:#080;font-style:italic># le contexte couramment sélectionné</span>
</span></span><span style=display:flex><span>kubectl config view --template<span style=color:#666>=</span><span style=color:#b44>&#39;{{ range .contexts }}{{ if eq .name &#34;&#39;</span><span style=color:#a2f;font-weight:700>$(</span>kubectl config current-context<span style=color:#a2f;font-weight:700>)</span><span style=color:#b44>&#39;&#34; }}Current user: {{ printf &#34;%s\n&#34; .context.user }}{{ end }}{{ end }}&#39;</span>
</span></span></code></pre></div><p>Exécuter le plugin ci-dessus vous donne une sortie contenant l'utilisateur du contexte couramment sélectionné dans votre fichier KUBECONFIG :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span><span style=color:#080;font-style:italic># rendre le fichier exécutable executable</span>
</span></span><span style=display:flex><span>$ sudo chmod +x ./kubectl-whoami
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#080;font-style:italic># et le déplacer dans le PATH</span>
</span></span><span style=display:flex><span>$ sudo mv ./kubectl-whoami /usr/local/bin
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>$ kubectl whoami
</span></span><span style=display:flex><span>Current user: plugins-user
</span></span></code></pre></div><p>Pour en savoir plus sur les plugins, examinez <a href=https://github.com/kubernetes/sample-cli-plugin>l'exemple de plugin CLI</a>.</p><h2 id=a-suivre>A suivre</h2><p>Commencez à utiliser les commandes <a href=/docs/reference/generated/kubectl/kubectl-commands/>kubectl</a>.</p></div><div class=td-content style=page-break-before:always><h1 id=pg-a938176c695852fe70362c29cf615f1c>7.7.2 - Support de JSONPath</h1><div class=lead>JSONPath kubectl Kubernetes</div><p>Kubectl prend en charge les modèles JSONPath.</p><p>Un modèle JSONPath est composé d'expressions JSONPath entourées par des accolades {}.
Kubectl utilise les expressions JSONPath pour filtrer sur des champs spécifiques de l'objet JSON et formater la sortie.
En plus de la syntaxe de modèle JSONPath originale, les fonctions et syntaxes suivantes sont valides :</p><ol><li>Utilisez des guillemets doubles pour marquer du texte dans les expressions JSONPath.</li><li>Utilisez les opérateurs <code>range</code> et <code>end</code> pour itérer sur des listes.</li><li>Utilisez des indices négatifs pour parcourir une liste à reculons. Les indices négatifs ne "bouclent pas" sur une liste et sont valides tant que <code>-index + longeurListe >= 0</code>.</li></ol><div class="alert alert-info note callout" role=alert><strong>Note:</strong><ul><li><p>L'opérateur <code>$</code> est optionnel, l'expression commençant toujours, par défaut, à la racine de l'objet.</p></li><li><p>L'objet résultant est affiché via sa fonction String().</p></li></ul></div><p>Étant donné l'entrée JSON :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-json data-lang=json><span style=display:flex><span>{
</span></span><span style=display:flex><span>  <span style=color:green;font-weight:700>&#34;kind&#34;</span>: <span style=color:#b44>&#34;List&#34;</span>,
</span></span><span style=display:flex><span>  <span style=color:green;font-weight:700>&#34;items&#34;</span>:[
</span></span><span style=display:flex><span>    {
</span></span><span style=display:flex><span>      <span style=color:green;font-weight:700>&#34;kind&#34;</span>:<span style=color:#b44>&#34;None&#34;</span>,
</span></span><span style=display:flex><span>      <span style=color:green;font-weight:700>&#34;metadata&#34;</span>:{<span style=color:green;font-weight:700>&#34;name&#34;</span>:<span style=color:#b44>&#34;127.0.0.1&#34;</span>},
</span></span><span style=display:flex><span>      <span style=color:green;font-weight:700>&#34;status&#34;</span>:{
</span></span><span style=display:flex><span>        <span style=color:green;font-weight:700>&#34;capacity&#34;</span>:{<span style=color:green;font-weight:700>&#34;cpu&#34;</span>:<span style=color:#b44>&#34;4&#34;</span>},
</span></span><span style=display:flex><span>        <span style=color:green;font-weight:700>&#34;addresses&#34;</span>:[{<span style=color:green;font-weight:700>&#34;type&#34;</span>: <span style=color:#b44>&#34;LegacyHostIP&#34;</span>, <span style=color:green;font-weight:700>&#34;address&#34;</span>:<span style=color:#b44>&#34;127.0.0.1&#34;</span>}]
</span></span><span style=display:flex><span>      }
</span></span><span style=display:flex><span>    },
</span></span><span style=display:flex><span>    {
</span></span><span style=display:flex><span>      <span style=color:green;font-weight:700>&#34;kind&#34;</span>:<span style=color:#b44>&#34;None&#34;</span>,
</span></span><span style=display:flex><span>      <span style=color:green;font-weight:700>&#34;metadata&#34;</span>:{<span style=color:green;font-weight:700>&#34;name&#34;</span>:<span style=color:#b44>&#34;127.0.0.2&#34;</span>},
</span></span><span style=display:flex><span>      <span style=color:green;font-weight:700>&#34;status&#34;</span>:{
</span></span><span style=display:flex><span>        <span style=color:green;font-weight:700>&#34;capacity&#34;</span>:{<span style=color:green;font-weight:700>&#34;cpu&#34;</span>:<span style=color:#b44>&#34;8&#34;</span>},
</span></span><span style=display:flex><span>        <span style=color:green;font-weight:700>&#34;addresses&#34;</span>:[
</span></span><span style=display:flex><span>          {<span style=color:green;font-weight:700>&#34;type&#34;</span>: <span style=color:#b44>&#34;LegacyHostIP&#34;</span>, <span style=color:green;font-weight:700>&#34;address&#34;</span>:<span style=color:#b44>&#34;127.0.0.2&#34;</span>},
</span></span><span style=display:flex><span>          {<span style=color:green;font-weight:700>&#34;type&#34;</span>: <span style=color:#b44>&#34;another&#34;</span>, <span style=color:green;font-weight:700>&#34;address&#34;</span>:<span style=color:#b44>&#34;127.0.0.3&#34;</span>}
</span></span><span style=display:flex><span>        ]
</span></span><span style=display:flex><span>      }
</span></span><span style=display:flex><span>    }
</span></span><span style=display:flex><span>  ],
</span></span><span style=display:flex><span>  <span style=color:green;font-weight:700>&#34;users&#34;</span>:[
</span></span><span style=display:flex><span>    {
</span></span><span style=display:flex><span>      <span style=color:green;font-weight:700>&#34;name&#34;</span>: <span style=color:#b44>&#34;myself&#34;</span>,
</span></span><span style=display:flex><span>      <span style=color:green;font-weight:700>&#34;user&#34;</span>: {}
</span></span><span style=display:flex><span>    },
</span></span><span style=display:flex><span>    {
</span></span><span style=display:flex><span>      <span style=color:green;font-weight:700>&#34;name&#34;</span>: <span style=color:#b44>&#34;e2e&#34;</span>,
</span></span><span style=display:flex><span>      <span style=color:green;font-weight:700>&#34;user&#34;</span>: {<span style=color:green;font-weight:700>&#34;username&#34;</span>: <span style=color:#b44>&#34;admin&#34;</span>, <span style=color:green;font-weight:700>&#34;password&#34;</span>: <span style=color:#b44>&#34;secret&#34;</span>}
</span></span><span style=display:flex><span>    }
</span></span><span style=display:flex><span>  ]
</span></span><span style=display:flex><span>}
</span></span></code></pre></div><table><thead><tr><th>Fonction</th><th>Description</th><th>Exemple</th><th>Résultat</th></tr></thead><tbody><tr><td><code>text</code></td><td>le texte en clair</td><td><code>le type est {.kind}</code></td><td><code>le type est List</code></td></tr><tr><td><code>@</code></td><td>l'objet courant</td><td><code>{@}</code></td><td>identique à l'entrée</td></tr><tr><td><code>.</code> ou <code>[]</code></td><td>opérateur fils</td><td><code>{.kind}</code>, <code>{['kind']}</code> ou <code>{['name\.type']}</code></td><td><code>List</code></td></tr><tr><td><code>..</code></td><td>descente récursive</td><td><code>{..name}</code></td><td><code>127.0.0.1 127.0.0.2 myself e2e</code></td></tr><tr><td><code>*</code></td><td>joker. Tous les objets</td><td><code>{.items[*].metadata.name}</code></td><td><code>[127.0.0.1 127.0.0.2]</code></td></tr><tr><td><code>[start:end:step]</code></td><td>opérateur d'indice</td><td><code>{.users[0].name}</code></td><td><code>myself</code></td></tr><tr><td><code>[,]</code></td><td>opérateur d'union</td><td><code>{.items[*]['metadata.name', 'status.capacity']}</code></td><td><code>127.0.0.1 127.0.0.2 map[cpu:4] map[cpu:8]</code></td></tr><tr><td><code>?()</code></td><td>filtre</td><td><code>{.users[?(@.name=="e2e")].user.password}</code></td><td><code>secret</code></td></tr><tr><td><code>range</code>, <code>end</code></td><td>itération de liste</td><td><code>{range .items[*]}[{.metadata.name}, {.status.capacity}] {end}</code></td><td><code>[127.0.0.1, map[cpu:4]] [127.0.0.2, map[cpu:8]]</code></td></tr><tr><td><code>''</code></td><td>protège chaîne interprétée</td><td><code>{range .items[*]}{.metadata.name}{'\t'}{end}</code></td><td><code>127.0.0.1 127.0.0.2</code></td></tr></tbody></table><p>Exemples utilisant <code>kubectl</code> et des expressions JSONPath :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get pods -o json
</span></span><span style=display:flex><span>kubectl get pods -o<span style=color:#666>=</span><span style=color:#b8860b>jsonpath</span><span style=color:#666>=</span><span style=color:#b44>&#39;{@}&#39;</span>
</span></span><span style=display:flex><span>kubectl get pods -o<span style=color:#666>=</span><span style=color:#b8860b>jsonpath</span><span style=color:#666>=</span><span style=color:#b44>&#39;{.items[0]}&#39;</span>
</span></span><span style=display:flex><span>kubectl get pods -o<span style=color:#666>=</span><span style=color:#b8860b>jsonpath</span><span style=color:#666>=</span><span style=color:#b44>&#39;{.items[0].metadata.name}&#39;</span>
</span></span><span style=display:flex><span>kubectl get pods -o<span style=color:#666>=</span><span style=color:#b8860b>jsonpath</span><span style=color:#666>=</span><span style=color:#b44>&#34;{.items[*][&#39;metadata.name&#39;, &#39;status.capacity&#39;]}&#34;</span>
</span></span><span style=display:flex><span>kubectl get pods -o<span style=color:#666>=</span><span style=color:#b8860b>jsonpath</span><span style=color:#666>=</span><span style=color:#b44>&#39;{range .items[*]}{.metadata.name}{&#34;\t&#34;}{.status.startTime}{&#34;\n&#34;}{end}&#39;</span>
</span></span></code></pre></div><div class="alert alert-info note callout" role=alert><strong>Note:</strong><p>Sous Windows, vous devez utiliser des guillemets <em>doubles</em> autour des modèles JSONPath qui contiennent des espaces (et non des guillemets simples comme ci-dessus pour bash). Ceci entraîne que vous devez utiliser un guillemet simple ou un double guillemet échappé autour des chaînes litérales dans le modèle. Par exemple :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-cmd data-lang=cmd><span style=display:flex><span>kubectl get pods -o=jsonpath=<span style=color:#b44>&#34;{range .items[*]}{.metadata.name}{&#39;\t&#39;}{.status.startTime}{&#39;\n&#39;}{end}&#34;</span>
</span></span><span style=display:flex><span>kubectl get pods -o=jsonpath=<span style=color:#b44>&#34;{range .items[*]}{.metadata.name}{\&#34;</span>\t\<span style=color:#b44>&#34;}{.status.startTime}{\&#34;</span>\n\<span style=color:#b44>&#34;}{end}&#34;</span>
</span></span></code></pre></div></div></div><div class=td-content style=page-break-before:always><h1 id=pg-8aba901ac13f124e5782b90ddb166ee2>7.7.3 - Aide-mémoire kubectl</h1><div class=lead>Cheatsheet kubectl aide-mémoire</div><p>Voir aussi : <a href=/docs/reference/kubectl/overview/>Aperçu Kubectl</a> et <a href=/docs/reference/kubectl/jsonpath>Guide JsonPath</a>.</p><p>Cette page donne un aperçu de la commande <code>kubectl</code>.</p><h1 id=aide-mémoire-kubectl>Aide-mémoire kubectl</h1><h2 id=auto-complétion-avec-kubectl>Auto-complétion avec Kubectl</h2><h3 id=bash>BASH</h3><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#a2f>source</span> &lt;<span style=color:#666>(</span>kubectl completion bash<span style=color:#666>)</span> <span style=color:#080;font-style:italic># active l&#39;auto-complétion pour bash dans le shell courant, le paquet bash-completion devant être installé au préalable</span>
</span></span><span style=display:flex><span><span style=color:#a2f>echo</span> <span style=color:#b44>&#34;source &lt;(kubectl completion bash)&#34;</span> &gt;&gt; ~/.bashrc <span style=color:#080;font-style:italic># ajoute l&#39;auto-complétion de manière permanente à votre shell bash</span>
</span></span></code></pre></div><p>Vous pouvez de plus déclarer un alias pour <code>kubectl</code> qui fonctionne aussi avec l'auto-complétion :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#a2f>alias</span> <span style=color:#b8860b>k</span><span style=color:#666>=</span>kubectl
</span></span><span style=display:flex><span><span style=color:#a2f>complete</span> -o default -F __start_kubectl k
</span></span></code></pre></div><h3 id=zsh>ZSH</h3><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#a2f>source</span> &lt;<span style=color:#666>(</span>kubectl completion zsh<span style=color:#666>)</span>  <span style=color:#080;font-style:italic># active l&#39;auto-complétion pour zsh dans le shell courant</span>
</span></span><span style=display:flex><span><span style=color:#a2f>echo</span> <span style=color:#b44>&#34;[[ </span><span style=color:#b8860b>$commands</span><span style=color:#b44>[kubectl] ]] &amp;&amp; source &lt;(kubectl completion zsh)&#34;</span> &gt;&gt; ~/.zshrc <span style=color:#080;font-style:italic># ajoute l&#39;auto-complétion de manière permanente à votre shell zsh</span>
</span></span></code></pre></div><h2 id=contexte-et-configuration-de-kubectl>Contexte et configuration de Kubectl</h2><p>Indique avec quel cluster Kubernetes <code>kubectl</code> communique et modifie les informations de configuration. Voir la documentation <a href=/docs/tasks/access-application-cluster/configure-access-multiple-clusters/>Authentification multi-clusters avec kubeconfig</a> pour des informations détaillées sur le fichier de configuration.
Information. Voir la documentation <a href=/docs/tasks/access-application-cluster/configure-access-multiple-clusters/>Authentification à travers des clusters avec kubeconfig</a>
pour des informations détaillées sur le fichier de configuration.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>kubectl config view <span style=color:#080;font-style:italic># Affiche les paramètres fusionnés de kubeconfig</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#080;font-style:italic># Utilise plusieurs fichiers kubeconfig en même temps et affiche la configuration fusionnée</span>
</span></span><span style=display:flex><span><span style=color:#b8860b>KUBECONFIG</span><span style=color:#666>=</span>~/.kube/config:~/.kube/kubconfig2
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>kubectl config view
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#080;font-style:italic># Affiche le mot de passe pour l&#39;utilisateur e2e</span>
</span></span><span style=display:flex><span>kubectl config view -o <span style=color:#b8860b>jsonpath</span><span style=color:#666>=</span><span style=color:#b44>&#39;{.users[?(@.name == &#34;e2e&#34;)].user.password}&#39;</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>kubectl config view -o <span style=color:#b8860b>jsonpath</span><span style=color:#666>=</span><span style=color:#b44>&#39;{.users[].name}&#39;</span>  <span style=color:#080;font-style:italic># Affiche le premier utilisateur</span>
</span></span><span style=display:flex><span>kubectl config view -o <span style=color:#b8860b>jsonpath</span><span style=color:#666>=</span><span style=color:#b44>&#39;{.users[*].name}&#39;</span> <span style=color:#080;font-style:italic># Affiche une liste d&#39;utilisateurs</span>
</span></span><span style=display:flex><span>kubectl config get-contexts                        <span style=color:#080;font-style:italic># Affiche la liste des contextes</span>
</span></span><span style=display:flex><span>kubectl config current-context                     <span style=color:#080;font-style:italic># Affiche le contexte courant (current-context)</span>
</span></span><span style=display:flex><span>kubectl config use-context my-cluster-name         <span style=color:#080;font-style:italic># Définit my-cluster-name comme contexte courant</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#080;font-style:italic># Ajoute un nouveau cluster à votre kubeconf, prenant en charge l&#39;authentification de base (basic auth)</span>
</span></span><span style=display:flex><span>kubectl config set-credentials kubeuser/foo.kubernetes.com --username<span style=color:#666>=</span>kubeuser --password<span style=color:#666>=</span>kubepassword
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#080;font-style:italic># Enregistre de manière permanente le namespace pour toutes les commandes kubectl suivantes dans ce contexte</span>
</span></span><span style=display:flex><span>kubectl config set-context --current --namespace<span style=color:#666>=</span>ggckad-s2
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#080;font-style:italic># Définit et utilise un contexte qui utilise un nom d&#39;utilisateur et un namespace spécifiques</span>
</span></span><span style=display:flex><span>kubectl config set-context gce --user<span style=color:#666>=</span>cluster-admin --namespace<span style=color:#666>=</span>foo <span style=color:#b62;font-weight:700>\
</span></span></span><span style=display:flex><span><span style=color:#b62;font-weight:700></span>  <span style=color:#666>&amp;&amp;</span> kubectl config use-context gce
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>kubectl config <span style=color:#a2f>unset</span> users.foo                       <span style=color:#080;font-style:italic># Supprime l&#39;utilisateur foo</span>
</span></span></code></pre></div><h2 id=apply>Apply</h2><p><code>apply</code> gère des applications en utilisant des fichiers définissant des ressources Kubernetes. Elle crée et met à jour des ressources dans un cluster en exécutant <code>kubectl apply</code>. C'est la manière recommandée de gérer des applications Kubernetes en production. Voir le <a href=https://kubectl.docs.kubernetes.io>Livre Kubectl</a>.</p><h2 id=création-d-objets>Création d'objets</h2><p>Les manifests Kubernetes peuvent être définis en YAML ou JSON. Les extensions de fichier <code>.yaml</code>,
<code>.yml</code>, et <code>.json</code> peuvent être utilisés.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>kubectl apply -f ./my-manifest.yaml            <span style=color:#080;font-style:italic># Crée une ou plusieurs ressources</span>
</span></span><span style=display:flex><span>kubectl apply -f ./my1.yaml -f ./my2.yaml      <span style=color:#080;font-style:italic># Crée depuis plusieurs fichiers</span>
</span></span><span style=display:flex><span>kubectl apply -f ./dir                         <span style=color:#080;font-style:italic># Crée une ou plusieurs ressources depuis tous les manifests dans dir</span>
</span></span><span style=display:flex><span>kubectl apply -f https://git.io/vPieo          <span style=color:#080;font-style:italic># Crée une ou plusieurs ressources depuis une url</span>
</span></span><span style=display:flex><span>kubectl create deployment nginx --image<span style=color:#666>=</span>nginx  <span style=color:#080;font-style:italic># Démarre une instance unique de nginx</span>
</span></span><span style=display:flex><span>kubectl explain pods                           <span style=color:#080;font-style:italic># Affiche la documentation pour les manifests pod</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#080;font-style:italic># Crée plusieurs objets YAML depuis l&#39;entrée standard (stdin)</span>
</span></span><span style=display:flex><span>cat <span style=color:#b44>&lt;&lt;EOF | kubectl apply -f -
</span></span></span><span style=display:flex><span><span style=color:#b44>apiVersion: v1
</span></span></span><span style=display:flex><span><span style=color:#b44>kind: Pod
</span></span></span><span style=display:flex><span><span style=color:#b44>metadata:
</span></span></span><span style=display:flex><span><span style=color:#b44>  name: busybox-sleep
</span></span></span><span style=display:flex><span><span style=color:#b44>spec:
</span></span></span><span style=display:flex><span><span style=color:#b44>  containers:
</span></span></span><span style=display:flex><span><span style=color:#b44>  - name: busybox
</span></span></span><span style=display:flex><span><span style=color:#b44>    image: busybox
</span></span></span><span style=display:flex><span><span style=color:#b44>    args:
</span></span></span><span style=display:flex><span><span style=color:#b44>    - sleep
</span></span></span><span style=display:flex><span><span style=color:#b44>    - &#34;1000000&#34;
</span></span></span><span style=display:flex><span><span style=color:#b44>---
</span></span></span><span style=display:flex><span><span style=color:#b44>apiVersion: v1
</span></span></span><span style=display:flex><span><span style=color:#b44>kind: Pod
</span></span></span><span style=display:flex><span><span style=color:#b44>metadata:
</span></span></span><span style=display:flex><span><span style=color:#b44>  name: busybox-sleep-less
</span></span></span><span style=display:flex><span><span style=color:#b44>spec:
</span></span></span><span style=display:flex><span><span style=color:#b44>  containers:
</span></span></span><span style=display:flex><span><span style=color:#b44>  - name: busybox
</span></span></span><span style=display:flex><span><span style=color:#b44>    image: busybox
</span></span></span><span style=display:flex><span><span style=color:#b44>    args:
</span></span></span><span style=display:flex><span><span style=color:#b44>    - sleep
</span></span></span><span style=display:flex><span><span style=color:#b44>    - &#34;1000&#34;
</span></span></span><span style=display:flex><span><span style=color:#b44>EOF</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#080;font-style:italic># Crée un Secret contenant plusieurs clés</span>
</span></span><span style=display:flex><span>cat <span style=color:#b44>&lt;&lt;EOF | kubectl apply -f -
</span></span></span><span style=display:flex><span><span style=color:#b44>apiVersion: v1
</span></span></span><span style=display:flex><span><span style=color:#b44>kind: Secret
</span></span></span><span style=display:flex><span><span style=color:#b44>metadata:
</span></span></span><span style=display:flex><span><span style=color:#b44>  name: mysecret
</span></span></span><span style=display:flex><span><span style=color:#b44>type: Opaque
</span></span></span><span style=display:flex><span><span style=color:#b44>data:
</span></span></span><span style=display:flex><span><span style=color:#b44>  password: $(echo -n &#34;s33msi4&#34; | base64 -w0)
</span></span></span><span style=display:flex><span><span style=color:#b44>  username: $(echo -n &#34;jane&#34; | base64 -w0)
</span></span></span><span style=display:flex><span><span style=color:#b44>EOF</span>
</span></span></code></pre></div><h2 id=visualisation-et-recherche-de-ressources>Visualisation et Recherche de ressources</h2><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#080;font-style:italic># Commandes Get avec un affichage basique</span>
</span></span><span style=display:flex><span>kubectl get services                     <span style=color:#080;font-style:italic># Liste tous les services d&#39;un namespace</span>
</span></span><span style=display:flex><span>kubectl get pods --all-namespaces        <span style=color:#080;font-style:italic># Liste tous les Pods de tous les namespaces</span>
</span></span><span style=display:flex><span>kubectl get pods -o wide                 <span style=color:#080;font-style:italic># Liste tous les Pods du namespace courant, avec plus de détails</span>
</span></span><span style=display:flex><span>kubectl get deployment my-dep            <span style=color:#080;font-style:italic># Liste un déploiement particulier</span>
</span></span><span style=display:flex><span>kubectl get pods                         <span style=color:#080;font-style:italic># Liste tous les Pods dans un namespace</span>
</span></span><span style=display:flex><span>kubectl get pod my-pod -o yaml           <span style=color:#080;font-style:italic># Affiche le YAML du Pod</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#080;font-style:italic># Commandes Describe avec un affichage verbeux</span>
</span></span><span style=display:flex><span>kubectl describe nodes my-node
</span></span><span style=display:flex><span>kubectl describe pods my-pod
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#080;font-style:italic># Liste les services triés par nom</span>
</span></span><span style=display:flex><span>kubectl get services --sort-by<span style=color:#666>=</span>.metadata.name
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#080;font-style:italic># Liste les pods classés par nombre de redémarrages</span>
</span></span><span style=display:flex><span>kubectl get pods --sort-by<span style=color:#666>=</span><span style=color:#b44>&#39;.status.containerStatuses[0].restartCount&#39;</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#080;font-style:italic># Affiche les volumes persistants classés par capacité de stockage</span>
</span></span><span style=display:flex><span>kubectl get pv --sort-by<span style=color:#666>=</span>.spec.capacity.storage
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#080;font-style:italic># Affiche la version des labels de tous les pods ayant un label app=cassandra</span>
</span></span><span style=display:flex><span>kubectl get pods --selector<span style=color:#666>=</span><span style=color:#b8860b>app</span><span style=color:#666>=</span>cassandra -o <span style=color:#b62;font-weight:700>\
</span></span></span><span style=display:flex><span><span style=color:#b62;font-weight:700></span>  <span style=color:#b8860b>jsonpath</span><span style=color:#666>=</span><span style=color:#b44>&#39;{.items[*].metadata.labels.version}&#39;</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#080;font-style:italic># Affiche tous les noeuds (en utilisant un sélecteur pour exclure ceux ayant un label</span>
</span></span><span style=display:flex><span><span style=color:#080;font-style:italic># nommé &#39;node-role.kubernetes.io/master&#39;)</span>
</span></span><span style=display:flex><span>kubectl get node --selector<span style=color:#666>=</span><span style=color:#b44>&#39;!node-role.kubernetes.io/master&#39;</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#080;font-style:italic># Affiche tous les pods en cours d&#39;exécution (Running) dans le namespace</span>
</span></span><span style=display:flex><span>kubectl get pods --field-selector<span style=color:#666>=</span>status.phase<span style=color:#666>=</span>Running
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#080;font-style:italic># Affiche les IPs externes (ExternalIPs) de tous les noeuds</span>
</span></span><span style=display:flex><span>kubectl get nodes -o <span style=color:#b8860b>jsonpath</span><span style=color:#666>=</span><span style=color:#b44>&#39;{.items[*].status.addresses[?(@.type==&#34;ExternalIP&#34;)].address}&#39;</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#080;font-style:italic># Liste les noms des pods appartenant à un ReplicationController particulier</span>
</span></span><span style=display:flex><span><span style=color:#080;font-style:italic># &#34;jq&#34; est une commande utile pour des transformations non prises en charge par jsonpath, il est disponible ici : https://stedolan.github.io/jq/</span>
</span></span><span style=display:flex><span><span style=color:#b8860b>sel</span><span style=color:#666>=</span><span style=color:#b68;font-weight:700>${</span><span style=color:#a2f;font-weight:700>$(</span>kubectl get rc my-rc --output<span style=color:#666>=</span>json | jq -j <span style=color:#b44>&#39;.spec.selector | to_entries | .[] | &#34;\(.key)=\(.value),&#34;&#39;</span><span style=color:#a2f;font-weight:700>)</span>%?<span style=color:#b68;font-weight:700>}</span>
</span></span><span style=display:flex><span><span style=color:#a2f>echo</span> <span style=color:#a2f;font-weight:700>$(</span>kubectl get pods --selector<span style=color:#666>=</span><span style=color:#b8860b>$sel</span> --output<span style=color:#666>=</span><span style=color:#b8860b>jsonpath</span><span style=color:#666>={</span>.items..metadata.name<span style=color:#666>}</span><span style=color:#a2f;font-weight:700>)</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#080;font-style:italic># Affiche les labels pour tous les pods (ou tout autre objet Kubernetes prenant en charge les labels)</span>
</span></span><span style=display:flex><span>kubectl get pods --show-labels
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#080;font-style:italic># Vérifie quels noeuds sont prêts</span>
</span></span><span style=display:flex><span><span style=color:#b8860b>JSONPATH</span><span style=color:#666>=</span><span style=color:#b44>&#39;{range .items[*]}{@.metadata.name}:{range @.status.conditions[*]}{@.type}={@.status};{end}{end}&#39;</span> <span style=color:#b62;font-weight:700>\
</span></span></span><span style=display:flex><span><span style=color:#b62;font-weight:700></span> <span style=color:#666>&amp;&amp;</span> kubectl get nodes -o <span style=color:#b8860b>jsonpath</span><span style=color:#666>=</span><span style=color:#b44>&#34;</span><span style=color:#b8860b>$JSONPATH</span><span style=color:#b44>&#34;</span> | grep <span style=color:#b44>&#34;Ready=True&#34;</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#080;font-style:italic># Liste tous les Secrets actuellement utilisés par un pod</span>
</span></span><span style=display:flex><span>kubectl get pods -o json | jq <span style=color:#b44>&#39;.items[].spec.containers[].env[]?.valueFrom.secretKeyRef.name&#39;</span> | grep -v null | sort | uniq
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#080;font-style:italic># Liste les containerIDs des initContainer de tous les Pods</span>
</span></span><span style=display:flex><span><span style=color:#080;font-style:italic># Utile lors du nettoyage des conteneurs arrêtés, tout en évitant de retirer les initContainers.</span>
</span></span><span style=display:flex><span>kubectl get pods --all-namespaces -o <span style=color:#b8860b>jsonpath</span><span style=color:#666>=</span><span style=color:#b44>&#39;{range .items[*].status.initContainerStatuses[*]}{.containerID}{&#34;\n&#34;}{end}&#39;</span> | cut -d/ -f3
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#080;font-style:italic># Liste les événements (Events) classés par timestamp</span>
</span></span><span style=display:flex><span>kubectl get events --sort-by<span style=color:#666>=</span>.metadata.creationTimestamp
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#080;font-style:italic># Compare l&#39;état actuel du cluster à l&#39;état du cluster si le manifeste était appliqué.</span>
</span></span><span style=display:flex><span>kubectl diff -f ./my-manifest.yaml
</span></span></code></pre></div><h2 id=mise-à-jour-de-ressources>Mise à jour de ressources</h2><p>Depuis la version 1.11, <code>rolling-update</code> a été déprécié (voir <a href=https://github.com/kubernetes/kubernetes/blob/master/CHANGELOG/CHANGELOG-1.11.md>CHANGELOG-1.11.md</a>), utilisez plutôt <code>rollout</code>.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>kubectl <span style=color:#a2f>set</span> image deployment/frontend <span style=color:#b8860b>www</span><span style=color:#666>=</span>image:v2               <span style=color:#080;font-style:italic># Rolling update du conteneur &#34;www&#34; du déploiement &#34;frontend&#34;, par mise à jour de son image</span>
</span></span><span style=display:flex><span>kubectl rollout <span style=color:#a2f>history</span> deployment/frontend                      <span style=color:#080;font-style:italic># Vérifie l&#39;historique de déploiements incluant la révision</span>
</span></span><span style=display:flex><span>kubectl rollout undo deployment/frontend                         <span style=color:#080;font-style:italic># Rollback du déploiement précédent</span>
</span></span><span style=display:flex><span>kubectl rollout undo deployment/frontend --to-revision<span style=color:#666>=</span><span style=color:#666>2</span>         <span style=color:#080;font-style:italic># Rollback à une version spécifique</span>
</span></span><span style=display:flex><span>kubectl rollout status -w deployment/frontend                    <span style=color:#080;font-style:italic># Écoute (Watch) le status du rolling update du déploiement &#34;frontend&#34; jusqu&#39;à ce qu&#39;il se termine</span>
</span></span><span style=display:flex><span>kubectl rollout restart deployment/frontend                      <span style=color:#080;font-style:italic># Rolling restart du déploiement &#34;frontend&#34;</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>cat pod.json | kubectl replace -f -                              <span style=color:#080;font-style:italic># Remplace un pod, en utilisant un JSON passé en entrée standard</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#080;font-style:italic># Remplace de manière forcée (Force replace), supprime puis re-crée la ressource. Provoque une interruption de service.</span>
</span></span><span style=display:flex><span>kubectl replace --force -f ./pod.json
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#080;font-style:italic># Crée un service pour un nginx repliqué, qui rend le service sur le port 80 et se connecte aux conteneurs sur le port 8000</span>
</span></span><span style=display:flex><span>kubectl expose rc nginx --port<span style=color:#666>=</span><span style=color:#666>80</span> --target-port<span style=color:#666>=</span><span style=color:#666>8000</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#080;font-style:italic># Modifie la version (tag) de l&#39;image du conteneur unique du pod à v4</span>
</span></span><span style=display:flex><span>kubectl get pod mypod -o yaml | sed <span style=color:#b44>&#39;s/\(image: myimage\):.*$/\1:v4/&#39;</span> | kubectl replace -f -
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>kubectl label pods my-pod new-label<span style=color:#666>=</span>awesome                      <span style=color:#080;font-style:italic># Ajoute un Label</span>
</span></span><span style=display:flex><span>kubectl annotate pods my-pod icon-url<span style=color:#666>=</span>http://goo.gl/XXBTWq       <span style=color:#080;font-style:italic># Ajoute une annotation</span>
</span></span><span style=display:flex><span>kubectl autoscale deployment foo --min<span style=color:#666>=</span><span style=color:#666>2</span> --max<span style=color:#666>=</span><span style=color:#666>10</span>                <span style=color:#080;font-style:italic># Mise à l&#39;échelle automatique (Auto scale) d&#39;un déploiement &#34;foo&#34;</span>
</span></span></code></pre></div><h2 id=mise-à-jour-partielle-de-ressources>Mise à jour partielle de ressources</h2><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#080;font-style:italic># Mise à jour partielle d&#39;un node</span>
</span></span><span style=display:flex><span>kubectl patch node k8s-node-1 -p <span style=color:#b44>&#39;{&#34;spec&#34;:{&#34;unschedulable&#34;:true}}&#39;</span> <span style=color:#080;font-style:italic># Met à jour partiellement un noeud</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#080;font-style:italic># Met à jour l&#39;image d&#39;un conteneur ; spec.containers[*].name est requis car c&#39;est une clé du merge</span>
</span></span><span style=display:flex><span>kubectl patch pod valid-pod -p <span style=color:#b44>&#39;{&#34;spec&#34;:{&#34;containers&#34;:[{&#34;name&#34;:&#34;kubernetes-serve-hostname&#34;,&#34;image&#34;:&#34;new image&#34;}]}}&#39;</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#080;font-style:italic># Met à jour l&#39;image d&#39;un conteneur en utilisant un patch json avec tableaux indexés</span>
</span></span><span style=display:flex><span>kubectl patch pod valid-pod --type<span style=color:#666>=</span><span style=color:#b44>&#39;json&#39;</span> -p<span style=color:#666>=</span><span style=color:#b44>&#39;[{&#34;op&#34;: &#34;replace&#34;, &#34;path&#34;: &#34;/spec/containers/0/image&#34;, &#34;value&#34;:&#34;new image&#34;}]&#39;</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#080;font-style:italic># Désactive la livenessProbe d&#39;un déploiement en utilisant un patch json avec tableaux indexés</span>
</span></span><span style=display:flex><span>kubectl patch deployment valid-deployment  --type json   -p<span style=color:#666>=</span><span style=color:#b44>&#39;[{&#34;op&#34;: &#34;remove&#34;, &#34;path&#34;: &#34;/spec/template/spec/containers/0/livenessProbe&#34;}]&#39;</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#080;font-style:italic># Ajoute un nouvel élément à un tableau indexé</span>
</span></span><span style=display:flex><span>kubectl patch sa default --type<span style=color:#666>=</span><span style=color:#b44>&#39;json&#39;</span> -p<span style=color:#666>=</span><span style=color:#b44>&#39;[{&#34;op&#34;: &#34;add&#34;, &#34;path&#34;: &#34;/secrets/1&#34;, &#34;value&#34;: {&#34;name&#34;: &#34;whatever&#34; } }]&#39;</span>
</span></span></code></pre></div><h2 id=édition-de-ressources>Édition de ressources</h2><p>Édite n'importe quelle ressource de l'API dans un éditeur.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>kubectl edit svc/docker-registry                      <span style=color:#080;font-style:italic># Édite le service nommé docker-registry</span>
</span></span><span style=display:flex><span><span style=color:#b8860b>KUBE_EDITOR</span><span style=color:#666>=</span><span style=color:#b44>&#34;nano&#34;</span> kubectl edit svc/docker-registry   <span style=color:#080;font-style:italic># Utilise un autre éditeur</span>
</span></span></code></pre></div><h2 id=mise-à-l-échelle-de-ressources>Mise à l'échelle de ressources</h2><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>kubectl scale --replicas<span style=color:#666>=</span><span style=color:#666>3</span> rs/foo                                 <span style=color:#080;font-style:italic># Scale un replicaset nommé &#39;foo&#39; à 3</span>
</span></span><span style=display:flex><span>kubectl scale --replicas<span style=color:#666>=</span><span style=color:#666>3</span> -f foo.yaml                            <span style=color:#080;font-style:italic># Scale une ressource spécifiée dans foo.yaml&#34; à 3</span>
</span></span><span style=display:flex><span>kubectl scale --current-replicas<span style=color:#666>=</span><span style=color:#666>2</span> --replicas<span style=color:#666>=</span><span style=color:#666>3</span> deployment/mysql  <span style=color:#080;font-style:italic># Si la taille du déploiement nommé mysql est actuellement 2, scale mysql à 3</span>
</span></span><span style=display:flex><span>kubectl scale --replicas<span style=color:#666>=</span><span style=color:#666>5</span> rc/foo rc/bar rc/baz                   <span style=color:#080;font-style:italic># Scale plusieurs contrôleurs de réplication</span>
</span></span></code></pre></div><h2 id=suppression-de-ressources>Suppression de ressources</h2><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>kubectl delete -f ./pod.json                                              <span style=color:#080;font-style:italic># Supprime un pod en utilisant le type et le nom spécifiés dans pod.json</span>
</span></span><span style=display:flex><span>kubectl delete pod,service baz foo                                        <span style=color:#080;font-style:italic># Supprime les pods et services ayant les mêmes noms &#34;baz&#34; et &#34;foo&#34;</span>
</span></span><span style=display:flex><span>kubectl delete pods,services -l <span style=color:#b8860b>name</span><span style=color:#666>=</span>myLabel                              <span style=color:#080;font-style:italic># Supprime les pods et services ayant le label name=myLabel</span>
</span></span><span style=display:flex><span>kubectl -n my-ns delete pod,svc --all                                     <span style=color:#080;font-style:italic># Supprime tous les pods et services dans le namespace my-ns</span>
</span></span><span style=display:flex><span><span style=color:#080;font-style:italic># Supprime tous les pods correspondants à pattern1 ou pattern2 avec awk</span>
</span></span><span style=display:flex><span>kubectl get pods  -n mynamespace --no-headers<span style=color:#666>=</span><span style=color:#a2f>true</span> | awk <span style=color:#b44>&#39;/pattern1|pattern2/{print $1}&#39;</span> | xargs  kubectl delete -n mynamespace pod
</span></span></code></pre></div><h2 id=interaction-avec-des-pods-en-cours-d-exécution>Interaction avec des Pods en cours d'exécution</h2><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>kubectl logs my-pod                                 <span style=color:#080;font-style:italic># Affiche les logs du pod (stdout)</span>
</span></span><span style=display:flex><span>kubectl logs -l <span style=color:#b8860b>name</span><span style=color:#666>=</span>myLabel                        <span style=color:#080;font-style:italic># Affiche les logs des pods ayant le label name=myLabel (stdout)</span>
</span></span><span style=display:flex><span>kubectl logs my-pod --previous                      <span style=color:#080;font-style:italic># Affiche les logs du pod (stdout) pour une instance précédente du conteneur</span>
</span></span><span style=display:flex><span>kubectl logs my-pod -c my-container                 <span style=color:#080;font-style:italic># Affiche les logs d&#39;un conteneur particulier du pod (stdout, cas d&#39;un pod multi-conteneurs)</span>
</span></span><span style=display:flex><span>kubectl logs -l <span style=color:#b8860b>name</span><span style=color:#666>=</span>myLabel -c my-container        <span style=color:#080;font-style:italic># Affiche les logs des pods avec le label name=myLabel (stdout, cas d&#39;un pod multi-conteneurs)</span>
</span></span><span style=display:flex><span>kubectl logs my-pod -c my-container --previous      <span style=color:#080;font-style:italic># Affiche les logs d&#39;un conteneur particulier du pod (stdout, cas d&#39;un pod multi-conteneurs) pour une instance précédente du conteneur</span>
</span></span><span style=display:flex><span>kubectl logs -f my-pod                              <span style=color:#080;font-style:italic># Fait défiler (stream) les logs du pod (stdout)</span>
</span></span><span style=display:flex><span>kubectl logs -f my-pod -c my-container              <span style=color:#080;font-style:italic># Fait défiler (stream) les logs d&#39;un conteneur particulier du pod (stdout, cas d&#39;un pod multi-conteneurs)</span>
</span></span><span style=display:flex><span>kubectl logs -f -l <span style=color:#b8860b>name</span><span style=color:#666>=</span>myLabel --all-containers    <span style=color:#080;font-style:italic># Fait défiler (stream) les logs de tous les pods ayant le label name=myLabel (stdout)</span>
</span></span><span style=display:flex><span>kubectl run -i --tty busybox --image<span style=color:#666>=</span>busybox -- sh  <span style=color:#080;font-style:italic># Exécute un pod comme un shell interactif</span>
</span></span><span style=display:flex><span>kubectl run nginx --image<span style=color:#666>=</span>nginx --restart<span style=color:#666>=</span>Never -n
</span></span><span style=display:flex><span>mynamespace                                         <span style=color:#080;font-style:italic># Exécute le pod nginx dans un namespace spécifique</span>
</span></span><span style=display:flex><span>kubectl run nginx --image<span style=color:#666>=</span>nginx --restart<span style=color:#666>=</span>Never     <span style=color:#080;font-style:italic># Simule l&#39;exécution du pod nginx et écrit sa spécification dans un fichier pod.yaml</span>
</span></span><span style=display:flex><span>--dry-run -o yaml &gt; pod.yaml
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>kubectl attach my-pod -i                            <span style=color:#080;font-style:italic># Attache à un conteneur en cours d&#39;exécution</span>
</span></span><span style=display:flex><span>kubectl port-forward my-pod 5000:6000               <span style=color:#080;font-style:italic># Écoute le port 5000 de la machine locale et forwarde vers le port 6000 de my-pod</span>
</span></span><span style=display:flex><span>kubectl <span style=color:#a2f>exec</span> my-pod -- ls /                         <span style=color:#080;font-style:italic># Exécute une commande dans un pod existant (cas d&#39;un seul conteneur)</span>
</span></span><span style=display:flex><span>kubectl <span style=color:#a2f>exec</span> my-pod -c my-container -- ls /         <span style=color:#080;font-style:italic># Exécute une commande dans un pod existant (cas multi-conteneurs)</span>
</span></span><span style=display:flex><span>kubectl top pod POD_NAME --containers               <span style=color:#080;font-style:italic># Affiche les métriques pour un pod donné et ses conteneurs</span>
</span></span></code></pre></div><h2 id=interaction-avec-des-noeuds-et-clusters>Interaction avec des Noeuds et Clusters</h2><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>kubectl cordon mon-noeud                                              <span style=color:#080;font-style:italic># Marque mon-noeud comme non assignable (unschedulable)</span>
</span></span><span style=display:flex><span>kubectl drain mon-noeud                                               <span style=color:#080;font-style:italic># Draine mon-noeud en préparation d&#39;une mise en maintenance</span>
</span></span><span style=display:flex><span>kubectl uncordon mon-noeud                                            <span style=color:#080;font-style:italic># Marque mon-noeud comme assignable</span>
</span></span><span style=display:flex><span>kubectl top node mon-noeud                                            <span style=color:#080;font-style:italic># Affiche les métriques pour un noeud donné</span>
</span></span><span style=display:flex><span>kubectl cluster-info                                                  <span style=color:#080;font-style:italic># Affiche les adresses du master et des services</span>
</span></span><span style=display:flex><span>kubectl cluster-info dump                                             <span style=color:#080;font-style:italic># Affiche l&#39;état courant du cluster sur stdout</span>
</span></span><span style=display:flex><span>kubectl cluster-info dump --output-directory<span style=color:#666>=</span>/path/to/cluster-state   <span style=color:#080;font-style:italic># Affiche l&#39;état courant du cluster sur /path/to/cluster-state</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#080;font-style:italic># Si une teinte avec cette clé et cet effet existe déjà, sa valeur est remplacée comme spécifié.</span>
</span></span><span style=display:flex><span>kubectl taint nodes foo <span style=color:#b8860b>dedicated</span><span style=color:#666>=</span>special-user:NoSchedule
</span></span></code></pre></div><h3 id=types-de-ressources>Types de ressources</h3><p>Liste tous les types de ressources pris en charge avec leurs noms courts (shortnames), <a href=/docs/concepts/overview/kubernetes-api/#api-groups>groupe d'API (API group)</a>, si elles sont <a href=/docs/concepts/overview/working-with-objects/namespaces>cantonnées à un namespace (namespaced)</a>, et leur <a href=/docs/concepts/overview/working-with-objects/kubernetes-objects>Genre (Kind)</a>:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>kubectl api-resources
</span></span></code></pre></div><p>Autres opérations pour explorer les ressources de l'API :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>kubectl api-resources --namespaced<span style=color:#666>=</span><span style=color:#a2f>true</span>      <span style=color:#080;font-style:italic># Toutes les ressources cantonnées à un namespace</span>
</span></span><span style=display:flex><span>kubectl api-resources --namespaced<span style=color:#666>=</span><span style=color:#a2f>false</span>     <span style=color:#080;font-style:italic># Toutes les ressources non cantonnées à un namespace</span>
</span></span><span style=display:flex><span>kubectl api-resources -o name                <span style=color:#080;font-style:italic># Toutes les ressources avec un affichage simple (uniquement le nom de la ressource)</span>
</span></span><span style=display:flex><span>kubectl api-resources -o wide                <span style=color:#080;font-style:italic># Toutes les ressources avec un affichage étendu (alias &#34;wide&#34;)</span>
</span></span><span style=display:flex><span>kubectl api-resources --verbs<span style=color:#666>=</span>list,get       <span style=color:#080;font-style:italic># Toutes les ressources prenant en charge les verbes de requête &#34;list&#34; et &#34;get&#34;</span>
</span></span><span style=display:flex><span>kubectl api-resources --api-group<span style=color:#666>=</span>extensions <span style=color:#080;font-style:italic># Toutes les ressources dans le groupe d&#39;API &#34;extensions&#34;</span>
</span></span></code></pre></div><h3 id=formattage-de-l-affichage>Formattage de l'affichage</h3><p>Pour afficher les détails sur votre terminal dans un format spécifique, utilisez l'option <code>-o</code> (ou <code>--output</code>) avec les commandes <code>kubectl</code> qui la prend en charge.</p><table><thead><tr><th>Format d'affichage</th><th>Description</th></tr></thead><tbody><tr><td><code>-o=custom-columns=&lt;spec></code></td><td>Affiche un tableau en spécifiant une liste de colonnes séparées par des virgules</td></tr><tr><td><code>-o=custom-columns-file=&lt;filename></code></td><td>Affiche un tableau en utilisant les colonnes spécifiées dans le fichier <code>&lt;filename></code></td></tr><tr><td><code>-o=json</code></td><td>Affiche un objet de l'API formaté en JSON</td></tr><tr><td><code>-o=jsonpath=&lt;template></code></td><td>Affiche les champs définis par une expression <a href=/docs/reference/kubectl/jsonpath>jsonpath</a></td></tr><tr><td><code>-o=jsonpath-file=&lt;filename></code></td><td>Affiche les champs définis par l'expression <a href=/docs/reference/kubectl/jsonpath>jsonpath</a> dans le fichier <code>&lt;filename></code></td></tr><tr><td><code>-o=name</code></td><td>Affiche seulement le nom de la ressource et rien de plus</td></tr><tr><td><code>-o=wide</code></td><td>Affiche dans le format texte avec toute information supplémentaire, et pour des pods, le nom du noeud est inclus</td></tr><tr><td><code>-o=yaml</code></td><td>Affiche un objet de l'API formaté en YAML</td></tr></tbody></table><p>Exemples utilisant <code>-o=custom-columns</code> :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#080;font-style:italic># Toutes les images s&#39;exécutant dans un cluster</span>
</span></span><span style=display:flex><span>kubectl get pods -A -o<span style=color:#666>=</span>custom-columns<span style=color:#666>=</span><span style=color:#b44>&#39;DATA:spec.containers[*].image&#39;</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span> <span style=color:#080;font-style:italic># Toutes les images excepté &#34;k8s.gcr.io/coredns:1.6.2&#34;</span>
</span></span><span style=display:flex><span>kubectl get pods -A -o<span style=color:#666>=</span>custom-columns<span style=color:#666>=</span><span style=color:#b44>&#39;DATA:spec.containers[?(@.image!=&#34;k8s.gcr.io/coredns:1.6.2&#34;)].image&#39;</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#080;font-style:italic># Tous les champs dans metadata quel que soit leur nom</span>
</span></span><span style=display:flex><span>kubectl get pods -A -o<span style=color:#666>=</span>custom-columns<span style=color:#666>=</span><span style=color:#b44>&#39;DATA:metadata.*&#39;</span>
</span></span></code></pre></div><p>Plus d'exemples dans la <a href=/fr/docs/reference/kubectl/overview/#colonnes-personnalis%C3%A9es>documentation de référence</a> de kubectl.</p><h3 id=verbosité-de-l-affichage-de-kubectl-et-débogage>Verbosité de l'affichage de Kubectl et débogage</h3><p>La verbosité de Kubectl est contrôlée par une des options <code>-v</code> ou <code>--v</code> suivie d'un entier représentant le niveau de log. Les conventions générales de logging de Kubernetes et les niveaux de log associés sont décrits <a href=https://github.com/kubernetes/community/blob/master/contributors/devel/sig-instrumentation/logging.md>ici</a>.</p><table><thead><tr><th>Verbosité</th><th>Description</th></tr></thead><tbody><tr><td><code>--v=0</code></td><td>Le minimum qui doit <em>toujours</em> être affiché à un opérateur.</td></tr><tr><td><code>--v=1</code></td><td>Un niveau de log par défaut raisonnable si vous n'avez pas besoin de verbosité.</td></tr><tr><td><code>--v=2</code></td><td>Informations utiles sur l'état stable du service et messages de logs importants qui peuvent être corrélés à des changements significatifs dans le système. C'est le niveau de log par défaut recommandé pour la plupart des systèmes.</td></tr><tr><td><code>--v=3</code></td><td>Informations étendues sur les changements.</td></tr><tr><td><code>--v=4</code></td><td>Verbosité de Debug.</td></tr><tr><td><code>--v=6</code></td><td>Affiche les ressources requêtées.</td></tr><tr><td><code>--v=7</code></td><td>Affiche les entêtes des requêtes HTTP.</td></tr><tr><td><code>--v=8</code></td><td>Affiche les contenus des requêtes HTTP.</td></tr><tr><td><code>--v=9</code></td><td>Affiche les contenus des requêtes HTTP sans les tronquer.</td></tr></tbody></table><h2 id=a-suivre>A suivre</h2><ul><li><p>En savoir plus sur l'<a href=/docs/reference/kubectl/overview/>Aperçu de kubectl</a>.</p></li><li><p>Voir les options <a href=/docs/reference/kubectl/kubectl/>kubectl</a>.</p></li><li><p>Voir aussi les <a href=/docs/reference/kubectl/conventions/>Conventions d'usage de kubectl</a> pour comprendre comment l'utiliser dans des scripts réutilisables.</p></li><li><p>Voir plus d'<a href=https://github.com/dennyzhang/cheatsheet-kubernetes-A4>aides-mémoire kubectl</a>.</p></li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-d7ffbf04ffbefb241fd0722423b80f5a>7.7.4 - Commandes kubectl</h1><div class=lead>Commandes kubectl</div><p><a href=/docs/reference/generated/kubectl/kubectl-commands/>Référence des commandes kubectl</a></p></div><div class=td-content style=page-break-before:always><h1 id=pg-8de6aceb8bf692c06cced446bac5bc92>7.7.5 - Conventions d'utilisation de kubectl</h1><div class=lead>kubectl conventions</div><p>Conventions d'utilisation recommandées pour <code>kubectl</code>.</p><h2 id=utiliser-kubectl-dans-des-scripts-réutilisables>Utiliser <code>kubectl</code> dans des scripts réutilisables</h2><p>Pour une sortie stable dans un script :</p><ul><li>Demandez un des formats de sortie orienté machine, comme <code>-o name</code>, <code>-o json</code>, <code>-o yaml</code>, <code>-o go-template</code> ou <code>-o jsonpath</code>.</li><li>Spécifiez complètement la version. Par exemple, <code>jobs.v1.batch/monjob</code>. Cela va assurer que kubectl n'utilise pas sa version par défaut, qui risque d'évoluer avec le temps.</li><li>Ne vous basez pas sur un contexte, des préférences ou tout autre état implicite.</li></ul><h2 id=bonnes-pratiques>Bonnes pratiques</h2><h3 id=kubectl-run><code>kubectl run</code></h3><p>Pour que <code>kubectl run</code> satisfasse l'infrastructure as code :</p><ul><li>Taggez les images avec un tag spécifique à une version et n'utilisez pas ce tag pour une nouvelle version. Par exemple, utilisez <code>:v1234</code>, <code>v1.2.3</code>, <code>r03062016-1-4</code>, plutôt que <code>:latest</code> (Pour plus d'informations, voir <a href=/docs/concepts/configuration/overview/#container-images>Bonnes pratiques pour la configuration</a>).</li><li>Capturez le script pour une image fortement paramétrée.</li><li>Passez à des fichiers de configuration enregistrés dans un système de contrôle de source pour des fonctionnalités désirées mais non exprimables avec des flags de <code>kubectl run</code>.</li></ul><p>Vous pouvez utiliser l'option <code>--dry-run</code> pour prévisualiser l'objet qui serait envoyé à votre cluster, sans réellement l'envoyer.</p><div class="alert alert-info note callout" role=alert><strong>Note:</strong> Tous les générateurs <code>kubectl</code> sont dépréciés. Voir la documentation de Kubernetes v1.17 pour une <a href=https://v1-17.docs.kubernetes.io/fr/docs/reference/kubectl/conventions/#g%C3%A9n%C3%A9rateurs>liste</a> de générateurs et comment ils étaient utilisés.</div><h4 id=générateurs>Générateurs</h4><p>Vous pouvez générer les ressources suivantes avec une commande kubectl, <code>kubectl create --dry-run -o yaml</code>:</p><pre tabindex=0><code>  clusterrole         Crée un ClusterRole.
  clusterrolebinding  Crée un ClusterRoleBinding pour un ClusterRole particulier.
  configmap           Crée une configmap à partir d&#39;un fichier local, un répertoire ou une valeur litérale.
  cronjob             Crée un cronjob avec le nom spécifié.
  deployment          Crée un deployment avec le nom spécifié.
  job                 Crée un job avec le nom spécifié.
  namespace           Crée un namespace avec le nom spécifié.
  poddisruptionbudget Crée un pod disruption budget avec le nom spécifié.
  priorityclass       Crée une priorityclass avec le nom spécifié.
  quota               Crée un quota avec le nom spécifié.
  role                Crée un role avec une unique règle.
  rolebinding         Crée un RoleBinding pour un Role ou ClusterRole particulier.
  secret              Crée un secret en utilisant la sous-commande spécifiée.
  service             Crée un service en utilisant la sous-commande spécifiée.
  serviceaccount      Crée un service account avec le nom spécifié.
</code></pre><h3 id=kubectl-apply><code>kubectl apply</code></h3><ul><li>Vous pouvez utiliser <code>kubectl apply</code> pour créer ou mettre à jour des ressources. Pour plus d'informations sur l'utilisation de <code>kubectl apply</code> pour la mise à jour de ressources, voir le <a href=https://kubectl.docs.kubernetes.io>livre Kubectl</a>.</li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-4d3e62632c189fcc3c1357cd8fb8799c>7.7.6 - kubectl</h1><div class=lead>Référence kubectl</div><h2 id=synopsis>Synopsis</h2><p>kubectl contrôle le manager d'un cluster Kubernetes</p><p>Vous trouverez plus d'informations ici : <a href=https://kubernetes.io/fr/docs/reference/kubectl/overview/>https://kubernetes.io/fr/docs/reference/kubectl/overview/</a></p><pre tabindex=0><code>kubectl [flags]
</code></pre><h2 id=options>Options</h2><table style=width:100%;table-layout:fixed><col span=1 style=width:10px><col span=1><tbody><tr><td colspan=2>--add-dir-header</td></tr><tr><td></td><td style=line-height:130%;word-wrap:break-word>Si vrai, ajoute le répertoire du fichier à l'entête</td></tr><tr><td colspan=2>--alsologtostderr</td></tr><tr><td></td><td style=line-height:130%;word-wrap:break-word>log sur l'erreur standard en plus d'un fichier</td></tr><tr><td colspan=2>--application-metrics-count-limit int&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Défaut : 100</td></tr><tr><td></td><td style=line-height:130%;word-wrap:break-word>Nombre max de métriques d'applications à stocker (par conteneur)</td></tr><tr><td colspan=2>--as chaîne</td></tr><tr><td></td><td style=line-height:130%;word-wrap:break-word>Nom d'utilisateur à utiliser pour l'opération</td></tr><tr><td colspan=2>--as-group tableauDeChaînes</td></tr><tr><td></td><td style=line-height:130%;word-wrap:break-word>Groupe à utiliser pour l'opération, ce flag peut être répété pour spécifier plusieurs groupes</td></tr><tr><td colspan=2>--azure-container-registry-config chaîne</td></tr><tr><td></td><td style=line-height:130%;word-wrap:break-word>Chemin du fichier contenant les informations de configuration du registre de conteneurs Azure</td></tr><tr><td colspan=2>--boot-id-file string&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Défaut : "/proc/sys/kernel/random/boot_id"</td></tr><tr><td></td><td style=line-height:130%;word-wrap:break-word>Liste séparée par des virgules de fichiers dans lesquels rechercher le boot-id. Utilise le premier trouvé.</td></tr><tr><td colspan=2>--cache-dir chaîne&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Défaut: "/home/karen/.kube/http-cache"</td></tr><tr><td></td><td style=line-height:130%;word-wrap:break-word>Répertoire de cache HTTP par défaut</td></tr><tr><td colspan=2>--certificate-authority chaîne</td></tr><tr><td></td><td style=line-height:130%;word-wrap:break-word>Chemin vers un fichier cert pour l'autorité de certification</td></tr><tr><td colspan=2>--client-certificate chaîne</td></tr><tr><td></td><td style=line-height:130%;word-wrap:break-word>Chemin vers un fichier de certificat client pour TLS</td></tr><tr><td colspan=2>--client-key chaîne</td></tr><tr><td></td><td style=line-height:130%;word-wrap:break-word>Chemin vers un fichier de clé client pour TLS</td></tr><tr><td colspan=2>--cloud-provider-gce-lb-src-cidrs cidrs&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Défaut: 130.211.0.0/22,209.85.152.0/22,209.85.204.0/22,35.191.0.0/16</td></tr><tr><td></td><td style=line-height:130%;word-wrap:break-word>CIDRs ouverts dans le firewall GCE pour le proxy de trafic LB & health checks</td></tr><tr><td colspan=2>--cluster chaîne</td></tr><tr><td></td><td style=line-height:130%;word-wrap:break-word>Le nom du cluster kubeconfig à utiliser</td></tr><tr><td colspan=2>--container-hints chaîne&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Défaut : "/etc/cadvisor/container_hints.json"</td></tr><tr><td></td><td style=line-height:130%;word-wrap:break-word>location du fichier hints du conteneur</td></tr><tr><td colspan=2>--containerd chaîne&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Défaut : "/run/containerd/containerd.sock"</td></tr><tr><td></td><td style=line-height:130%;word-wrap:break-word>Point de terminaison de containerd</td></tr><tr><td colspan=2>--containerd-namespace chaîne&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Défaut : "k8s.io"</td></tr><tr><td></td><td style=line-height:130%;word-wrap:break-word>namespace de containerd</td></tr><tr><td colspan=2>--context chaîne</td></tr><tr><td></td><td style=line-height:130%;word-wrap:break-word>Le nom du contexte kubeconfig à utiliser</td></tr><tr><td colspan=2>--default-not-ready-toleration-seconds int&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Défaut: 300</td></tr><tr><td></td><td style=line-height:130%;word-wrap:break-word>Indique les tolerationSeconds de la tolérance pour notReady:NoExecute qui sont ajoutées par défaut à tous les pods qui n'ont pas défini une telle tolérance</td></tr><tr><td colspan=2>--default-unreachable-toleration-seconds int&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Défaut: 300</td></tr><tr><td></td><td style=line-height:130%;word-wrap:break-word>Indique les tolerationSeconds de la tolérance pour unreachable:NoExecute qui sont ajoutées par défaut à tous les pods qui n'ont pas défini une telle tolérance</td></tr><tr><td colspan=2>--disable-root-cgroup-stats</td></tr><tr><td></td><td style=line-height:130%;word-wrap:break-word>Désactive la collecte des stats du Cgroup racine</td></tr><tr><td colspan=2>--docker chaîne&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Défaut : "unix:///var/run/docker.sock"</td></tr><tr><td></td><td style=line-height:130%;word-wrap:break-word>Point de terminaison docker</td></tr><tr><td colspan=2>--docker-env-metadata-whitelist chaîne</td></tr><tr><td></td><td style=line-height:130%;word-wrap:break-word>une liste séparée par des virgules de variables d'environnement qui doivent être collectées pour les conteneurs docker</td></tr><tr><td colspan=2>--docker-only</td></tr><tr><td></td><td style=line-height:130%;word-wrap:break-word>Remonte uniquement les stats Docker en plus des stats racine</td></tr><tr><td colspan=2>--docker-root chaîne&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Défaut : "/var/lib/docker"</td></tr><tr><td></td><td style=line-height:130%;word-wrap:break-word>DÉPRÉCIÉ : la racine de docker est lue depuis docker info (ceci est une solution de secours, défaut : /var/lib/docker)</td></tr><tr><td colspan=2>--docker-tls</td></tr><tr><td></td><td style=line-height:130%;word-wrap:break-word>utiliser TLS pour se connecter à docker</td></tr><tr><td colspan=2>--docker-tls-ca chaîne&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Défaut : "ca.pem"</td></tr><tr><td></td><td style=line-height:130%;word-wrap:break-word>chemin vers CA de confiance</td></tr><tr><td colspan=2>--docker-tls-cert chaîne&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Défaut : "cert.pem"</td></tr><tr><td></td><td style=line-height:130%;word-wrap:break-word>chemin vers le certificat client</td></tr><tr><td colspan=2>--docker-tls-key chaîne&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Défaut : "key.pem"</td></tr><tr><td></td><td style=line-height:130%;word-wrap:break-word>chemin vers la clef privée</td></tr><tr><td colspan=2>--enable-load-reader</td></tr><tr><td></td><td style=line-height:130%;word-wrap:break-word>Activer le lecteur de la charge CPU</td></tr><tr><td colspan=2>--event-storage-age-limit chaîne&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Défaut : "default=0"</td></tr><tr><td></td><td style=line-height:130%;word-wrap:break-word>Durée maximale pendant laquelle stocker les événements (par type). La valeur est une liste séparée par des virgules de clefs/valeurs, où les clefs sont des types d'événements (par ex: creation, oom) ou "default" et la valeur est la durée. La valeur par défaut est appliquée à tous les types d'événements non spécifiés</td></tr><tr><td colspan=2>--event-storage-event-limit chaîne&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Défaut : "default=0"</td></tr><tr><td></td><td style=line-height:130%;word-wrap:break-word>Nombre max d'événements à stocker (par type). La valeur est une liste séparée par des virgules de clefs/valeurs, où les clefs sont les types d'événements (par ex: creation, oom) ou "default" et la valeur est un entier. La valeur par défaut est appliquée à tous les types d'événements non spécifiés</td></tr><tr><td colspan=2>--global-housekeeping-interval durée&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Défaut : 1m0s</td></tr><tr><td></td><td style=line-height:130%;word-wrap:break-word>Intevalle entre ménages globaux</td></tr><tr><td colspan=2>-h, --help</td></tr><tr><td></td><td style=line-height:130%;word-wrap:break-word>aide pour kubectl</td></tr><tr><td colspan=2>--housekeeping-interval durée&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Défaut : 10s</td></tr><tr><td></td><td style=line-height:130%;word-wrap:break-word>Intervalle entre ménages des conteneurs</td></tr><tr><td colspan=2>--insecure-skip-tls-verify</td></tr><tr><td></td><td style=line-height:130%;word-wrap:break-word>Si vrai, la validité du certificat du serveur ne sera pas vérifiée. Ceci rend vos connexions HTTPS non sécurisées</td></tr><tr><td colspan=2>--kubeconfig chaîne</td></tr><tr><td></td><td style=line-height:130%;word-wrap:break-word>Chemin du fichier kubeconfig à utiliser pour les requêtes du CLI</td></tr><tr><td colspan=2>--log-backtrace-at traceLocation&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Défaut: :0</td></tr><tr><td></td><td style=line-height:130%;word-wrap:break-word>lorsque les logs arrivent à la ligne fichier:N, émet une stack trace</td></tr><tr><td colspan=2>--log-cadvisor-usage</td></tr><tr><td></td><td style=line-height:130%;word-wrap:break-word>Activer les logs d'usage du conteneur cAdvisor</td></tr><tr><td colspan=2>--log-dir chaîne</td></tr><tr><td></td><td style=line-height:130%;word-wrap:break-word>Si non vide, écrit les fichiers de log dans ce répertoire</td></tr><tr><td colspan=2>--log-file chaîne</td></tr><tr><td></td><td style=line-height:130%;word-wrap:break-word>Si non vide, utilise ce fichier de log</td></tr><tr><td colspan=2>--log-file-max-size uint&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Défaut : 1800</td></tr><tr><td></td><td style=line-height:130%;word-wrap:break-word>Définit la taille maximale d'un fichier de log. L'unité est le mega-octet. Si la valeur est 0, la taille de fichier maximale est illimitée.</td></tr><tr><td colspan=2>--log-flush-frequency durée&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Défaut: 5s</td></tr><tr><td></td><td style=line-height:130%;word-wrap:break-word>Nombre de secondes maximum entre flushs des logs</td></tr><tr><td colspan=2>--logtostderr&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Défaut: true</td></tr><tr><td></td><td style=line-height:130%;word-wrap:break-word>log sur l'erreur standard plutôt que dans un fichier</td></tr><tr><td colspan=2>--machine-id-file chaîne&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Défaut : "/etc/machine-id,/var/lib/dbus/machine-id"</td></tr><tr><td></td><td style=line-height:130%;word-wrap:break-word>liste séparée par des virgules de fichiers dans lesquels rechercher le machine-id. Utiliser le premier trouvé.</td></tr><tr><td colspan=2>--match-server-version</td></tr><tr><td></td><td style=line-height:130%;word-wrap:break-word>La version du serveur doit correspondre à la version du client</td></tr><tr><td colspan=2>-n, --namespace chaîne</td></tr><tr><td></td><td style=line-height:130%;word-wrap:break-word>Si présent, la portée de namespace pour la requête du CLI</td></tr><tr><td colspan=2>--password chaîne</td></tr><tr><td></td><td style=line-height:130%;word-wrap:break-word>Mot de passe pour l'authentification de base au serveur d'API</td></tr><tr><td colspan=2>--profile chaîne&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Défaut: "none"</td></tr><tr><td></td><td style=line-height:130%;word-wrap:break-word>Nom du profil à capturer. Parmi (none|cpu|heap|goroutine|threadcreate|block|mutex)</td></tr><tr><td colspan=2>--profile-output chaîne&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Défaut: "profile.pprof"</td></tr><tr><td></td><td style=line-height:130%;word-wrap:break-word>Nom du fichier dans lequel écrire le profil</td></tr><tr><td colspan=2>--request-timeout chaîne&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Défaut: "0"</td></tr><tr><td></td><td style=line-height:130%;word-wrap:break-word>La durée à attendre avant d'abandonner une requête au serveur. Les valeurs non égales à zéro doivent contenir une unité de temps correspondante (ex 1s, 2m, 3h). Une valeur à zéro indique de ne pas abandonner les requêtes</td></tr><tr><td colspan=2>-s, --server chaîne</td></tr><tr><td></td><td style=line-height:130%;word-wrap:break-word>L'adresse et le port de l'API server Kubernetes</td></tr><tr><td colspan=2>--skip-headers</td></tr><tr><td></td><td style=line-height:130%;word-wrap:break-word>Si vrai, n'affiche pas les entêtes dans les messages de log</td></tr><tr><td colspan=2>--skip-log-headers</td></tr><tr><td></td><td style=line-height:130%;word-wrap:break-word>Si vrai, évite les entêtes lors de l'ouverture des fichiers de log</td></tr><tr><td colspan=2>--stderrthreshold sévérité&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Défaut: 2</td></tr><tr><td></td><td style=line-height:130%;word-wrap:break-word>logs à cette sévérité et au dessus de ce seuil vont dans stderr</td></tr><tr><td colspan=2>--storage-driver-buffer-duration durée&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Défaut : 1m0s</td></tr><tr><td></td><td style=line-height:130%;word-wrap:break-word>Les écritures dans le driver de stockage seront bufferisés pour cette durée, et seront envoyés aux backends non-mémoire en une seule transaction</td></tr><tr><td colspan=2>--storage-driver-db chaîne&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Défaut : "cadvisor"</td></tr><tr><td></td><td style=line-height:130%;word-wrap:break-word>nom de la base de données</td></tr><tr><td colspan=2>--storage-driver-host chaîne&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Défaut : "localhost:8086"</td></tr><tr><td></td><td style=line-height:130%;word-wrap:break-word>hôte:port de la base de données</td></tr><tr><td colspan=2>--storage-driver-password chaîne&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Défaut : "root"</td></tr><tr><td></td><td style=line-height:130%;word-wrap:break-word>Mot de passe de la base de données</td></tr><tr><td colspan=2>--storage-driver-secure</td></tr><tr><td></td><td style=line-height:130%;word-wrap:break-word>utiliser une connexion sécurisée avec la base de données</td></tr><tr><td colspan=2>--storage-driver-table chaîne&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Défaut : "stats"</td></tr><tr><td></td><td style=line-height:130%;word-wrap:break-word>Nom de la table dans la base de données</td></tr><tr><td colspan=2>--storage-driver-user chaîne&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Défaut : "root"</td></tr><tr><td></td><td style=line-height:130%;word-wrap:break-word>nom d'utilisateur de la base de données</td></tr><tr><td colspan=2>--token chaîne</td></tr><tr><td></td><td style=line-height:130%;word-wrap:break-word>Bearer token pour l'authentification auprès de l'API server</td></tr><tr><td colspan=2>--update-machine-info-interval durée&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Défaut : 5m0s</td></tr><tr><td></td><td style=line-height:130%;word-wrap:break-word>Intevalle entre mises à jour des infos machine.</td></tr><tr><td colspan=2>--user chaîne</td></tr><tr><td></td><td style=line-height:130%;word-wrap:break-word>Le nom de l'utilisateur kubeconfig à utiliser</td></tr><tr><td colspan=2>--username chaîne</td></tr><tr><td></td><td style=line-height:130%;word-wrap:break-word>Nom d'utilisateur pour l'authentification de base au serveur d'API</td></tr><tr><td colspan=2>-v, --v Niveau</td></tr><tr><td></td><td style=line-height:130%;word-wrap:break-word>Niveau de verbosité des logs</td></tr><tr><td colspan=2>--version version[=true]</td></tr><tr><td></td><td style=line-height:130%;word-wrap:break-word>Affiche les informations de version et quitte</td></tr><tr><td colspan=2>--vmodule moduleSpec</td></tr><tr><td></td><td style=line-height:130%;word-wrap:break-word>Liste de settings pattern=N séparés par des virgules pour le logging filtré par fichiers</td></tr></tbody></table><h2 id=see-also>See Also</h2><ul><li><a href=/docs/reference/generated/kubectl/kubectl-commands#alpha>kubectl alpha</a> - Commandes pour fonctionnalités alpha</li><li><a href=/docs/reference/generated/kubectl/kubectl-commands#annotate>kubectl annotate</a> - Met à jour les annotations d'une ressource</li><li><a href=/docs/reference/generated/kubectl/kubectl-commands#api-resources>kubectl api-resources</a> - Affiche les ressources de l'API prises en charge sur le serveur</li><li><a href=/docs/reference/generated/kubectl/kubectl-commands#api-versions>kubectl api-versions</a> - Affiche les versions de l'API prises en charge sur le serveur, sous la forme "groupe/version"</li><li><a href=/docs/reference/generated/kubectl/kubectl-commands#apply>kubectl apply</a> - Applique une configuration à une ressource depuis un fichier ou stdin</li><li><a href=/docs/reference/generated/kubectl/kubectl-commands#attach>kubectl attach</a> - Attache à un conteneur en cours d'exécution</li><li><a href=/docs/reference/generated/kubectl/kubectl-commands#auth>kubectl auth</a> - Inspecte les autorisations</li><li><a href=/docs/reference/generated/kubectl/kubectl-commands#autoscale>kubectl autoscale</a> - Auto-scale un Deployment, ReplicaSet, ou ReplicationController</li><li><a href=/docs/reference/generated/kubectl/kubectl-commands#certificate>kubectl certificate</a> - Modifie des ressources certificat</li><li><a href=/docs/reference/generated/kubectl/kubectl-commands#cluster-info>kubectl cluster-info</a> - Affiche les informations du cluster</li><li><a href=/docs/reference/generated/kubectl/kubectl-commands#completion>kubectl completion</a> - Génère le code de complétion pour le shell spécifié (bash ou zsh)</li><li><a href=/docs/reference/generated/kubectl/kubectl-commands#config>kubectl config</a> - Modifie les fichiers kubeconfig</li><li><a href=/docs/reference/generated/kubectl/kubectl-commands#convert>kubectl convert</a> - Convertit des fichiers de config entre différentes versions d'API</li><li><a href=/docs/reference/generated/kubectl/kubectl-commands#cordon>kubectl cordon</a> - Marque un nœud comme non assignable (unschedulable)</li><li><a href=/docs/reference/generated/kubectl/kubectl-commands#cp>kubectl cp</a> - Copie des fichiers et répertoires depuis et vers des conteneurs</li><li><a href=/docs/reference/generated/kubectl/kubectl-commands#create>kubectl create</a> - Crée une ressource depuis un fichier ou stdin</li><li><a href=/docs/reference/generated/kubectl/kubectl-commands#delete>kubectl delete</a> - Supprime des ressources par fichiers ou stdin, par ressource et nom, ou par ressource et sélecteur de label</li><li><a href=/docs/reference/generated/kubectl/kubectl-commands#describe>kubectl describe</a> - Affiche les informations d'une ressource spécifique ou d'un groupe de ressources</li><li><a href=/docs/reference/generated/kubectl/kubectl-commands#diff>kubectl diff</a> - Différence entre la version live et la version désirée</li><li><a href=/docs/reference/generated/kubectl/kubectl-commands#drain>kubectl drain</a> - Draine un nœud en préparation d'une mise en maintenance</li><li><a href=/docs/reference/generated/kubectl/kubectl-commands#edit>kubectl edit</a> - Édite une ressource du serveur</li><li><a href=/docs/reference/generated/kubectl/kubectl-commands#exec>kubectl exec</a> - Exécute une commande dans un conteneur</li><li><a href=/docs/reference/generated/kubectl/kubectl-commands#explain>kubectl explain</a> - Documentation sur les ressources</li><li><a href=/docs/reference/generated/kubectl/kubectl-commands#expose>kubectl expose</a> - Prend un replication controller, service, deployment ou pod et l'expose comme un nouveau Service Kubernetes</li><li><a href=/docs/reference/generated/kubectl/kubectl-commands#get>kubectl get</a> - Affiche une ou plusieurs ressources</li><li><a href=/docs/reference/generated/kubectl/kubectl-commands#kustomize>kubectl kustomize</a> - Construit une cible kustomization à partir d'un répertoire ou d'une URL distante.</li><li><a href=/docs/reference/generated/kubectl/kubectl-commands#label>kubectl label</a> - Met à jour les labels d'une ressource</li><li><a href=/docs/reference/generated/kubectl/kubectl-commands#logs>kubectl logs</a> - Affiche les logs d'un conteneur dans un pod</li><li><a href=/docs/reference/generated/kubectl/kubectl-commands#options>kubectl options</a> - Affiche la liste des flags hérités par toutes les commandes</li><li><a href=/docs/reference/generated/kubectl/kubectl-commands#patch>kubectl patch</a> - Met à jour un ou plusieurs champs d'une ressource par merge patch stratégique</li><li><a href=/docs/reference/generated/kubectl/kubectl-commands#plugin>kubectl plugin</a> - Fournit des utilitaires pour interagir avec des plugins</li><li><a href=/docs/reference/generated/kubectl/kubectl-commands#port-forward>kubectl port-forward</a> - Redirige un ou plusieurs ports vers un pod</li><li><a href=/docs/reference/generated/kubectl/kubectl-commands#proxy>kubectl proxy</a> - Exécute un proxy vers l'API server Kubernetes</li><li><a href=/docs/reference/generated/kubectl/kubectl-commands#replace>kubectl replace</a> - Remplace une ressource par fichier ou stdin</li><li><a href=/docs/reference/generated/kubectl/kubectl-commands#rollout>kubectl rollout</a> - Gère le rollout d'une ressource</li><li><a href=/docs/reference/generated/kubectl/kubectl-commands#run>kubectl run</a> - Exécute une image donnée dans le cluster</li><li><a href=/docs/reference/generated/kubectl/kubectl-commands#scale>kubectl scale</a> - Définit une nouvelle taille pour un Deployment, ReplicaSet ou Replication Controller</li><li><a href=/docs/reference/generated/kubectl/kubectl-commands#set>kubectl set</a> - Définit des fonctionnalités spécifiques sur des objets</li><li><a href=/docs/reference/generated/kubectl/kubectl-commands#taint>kubectl taint</a> - Met à jour les marques (taints) sur un ou plusieurs nœuds</li><li><a href=/docs/reference/generated/kubectl/kubectl-commands#top>kubectl top</a> - Affiche l'utilisation de ressources matérielles (CPU/Memory/Storage)</li><li><a href=/docs/reference/generated/kubectl/kubectl-commands#uncordon>kubectl uncordon</a> - Marque un nœud comme assignable (schedulable)</li><li><a href=/docs/reference/generated/kubectl/kubectl-commands#version>kubectl version</a> - Affiche les informations de version du client et du serveur</li><li><a href=/docs/reference/generated/kubectl/kubectl-commands#wait>kubectl wait</a> - Expérimental : Attend une condition particulière sur une ou plusieurs ressources</li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-54e562dd1441d0195970a6526b0055cc>7.8 - Référence sur les outils en ligne de commande</h1></div><div class=td-content style=page-break-before:always><h1 id=pg-4985cb55ddfb184639d767ec54b9f0f7>8 - Contribuer à la documentation Kubernetes</h1><div class=lead>Contribution documentation Kubernetes</div><hr><p><em>Kubernetes accueille les améliorations de tous les contributeurs, nouveaux et expérimentés!</em></p><div class="alert alert-info note callout" role=alert><strong>Note:</strong><p>Pour en savoir plus sur comment contribuer à Kubernetes en général, consultez la
<a href=https://www.kubernetes.dev/docs/>documentation des contributeurs</a>.</p><p>Vous pouvez également lire la
<a href=https://contribute.cncf.io/contributors/projects/#kubernetes>page</a>
de <a class=glossary-tooltip title='Cloud Native Computing Foundation' data-toggle=tooltip data-placement=top href=https://cncf.io/ target=_blank aria-label=CNCF>CNCF</a> sur la contribution à Kubernetes.</p></div><hr><p>Ce site Web est maintenu par <a href=/docs/contribute/#get-involved-with-sig-docs>Kubernetes SIG Docs</a>.</p><p>Contributeurs à la documentation Kubernetes:</p><ul><li>Améliorer le contenu existant</li><li>Créer du nouveau contenu</li><li>Traduire la documentation</li><li>Gérer et publier la documentation faisant partie du cycle de mise à jour de Kubernetes</li></ul><h2 id=démarrage>Démarrage</h2><p>Tout le monde peut ouvrir un ticket concernant la documentation ou contribuer à une modification avec une pull request (PR) au
<a href=https://github.com/kubernetes/website>répertoire de GitHub <code>kubernetes/website</code></a>.
Vous devez être à l'aise avec <a href=https://git-scm.com/>git</a> et <a href=https://lab.github.com/>GitHub</a> pour travailler effectivement dans la communauté Kubernetes.</p><p>Pour participer à la documentation:</p><ol><li>Signez le <a href=https://github.com/kubernetes/community/blob/master/CLA.md>Contributor License Agreement (CLA)</a> du CNCF.</li><li>Familiarisez-vous avec le <a href=https://github.com/kubernetes/website>répertoire de documentation</a> et le
<a href=https://gohugo.io>générateur de site statique</a> du site Web.</li><li>Assurez-vous de comprendre les processus de base pour
<a href=/docs/contribute/new-content/open-a-pr/>soumettre un pull request</a> et
<a href=/docs/contribute/review/reviewing-prs/>examiner les modifications</a>.</li></ol><p><figure><div class=mermaid>flowchart TB
subgraph third[Soumettre PR]
direction TB
U[ ] -.-
Q[Améliorer contenu] --- N[Créer contenu]
N --- O[Traduire docs]
O --- P[Gérer/publier docs faisant partie<br>du cycle de mise à jour de K8s]
end
subgraph second[Révision]
direction TB
T[ ] -.-
D[Regarder<br>le site Web et<br>répertoire de K8s] --- E[Consulter le<br>générateur de<br>site statique Hugo]
E --- F[Comprendre les commandes<br>de base de GitHub]
F --- G[Réviser PR existantes<br>et changer les<br>procès de révision]
end
subgraph first[Inscription]
direction TB
S[ ] -.-
B[Signer le<br>Contributor License<br>Agreement de CNCF] ---
C[Joindre le canal Slack<br>appelé sig-docs] --- M[Participer aux<br>réunions vidéo hebdomadaires<br>ou réunion sur Slack]
end
A([fa:fa-user Nouveau<br>Contributeur]) --> first
A --> second
A --> third
A --> H[Posez des questions!!!]
classDef grey fill:#dddddd,stroke:#ffffff,stroke-width:px,color:#000000, font-size:15px;
classDef white fill:#ffffff,stroke:#000,stroke-width:px,color:#000,font-weight:bold
classDef spacewhite fill:#ffffff,stroke:#fff,stroke-width:0px,color:#000
class A,B,C,D,E,F,G,H,M,Q,N,O,P grey
class S,T,U spacewhite
class first,second,third white</div></figure><noscript><div class="alert alert-secondary callout" role=alert><em class=javascript-required>JavaScript must be <a href=https://www.enable-javascript.com/>enabled</a> to view this content</em></div></noscript>Figure 1. Premiers pas pour un nouveau contributeur.</p><p>La figure 1 présente une feuille de route pour les nouveaux contributeurs. Vous pouvez suivre certaines ou toutes les étapes pour <code>Inscription</code> et <code>Révision</code>. Vous êtes maintenant prêt à soumettre des PRs qui atteignent vos objectifs de contribution, dont certains listés sous <code>Soumettre PR</code>. Encore une fois, les questions sont toujours les bienvenues !</p><p>Certaines tâches nécessitent plus de confiance et plus d'accès dans l'organisation Kubernetes.
Visitez <a href=/docs/contribute/participate/>Participer à SIG Docs</a> pour plus de détails sur les rôles et les autorisations.</p><h2 id=votre-première-contribution>Votre première contribution</h2><p>Vous pouvez préparer votre première contribution en révisant à l'avance plusieurs étapes. La figure 2 décrit les étapes et les détails suivent.</p><p><figure><div class=mermaid>flowchart LR
subgraph second[Première Contribution]
direction TB
S[ ] -.-
G[Révisez les PRs des<br>autres membres de K8s] -->
A[Vérifiez la liste de problèmes<br>de K8s/website pour<br>des bon premiers PRs] --> B[Soumettez une PR!!]
end
subgraph first[Suggested Prep]
direction TB
T[ ] -.-
D[Lisez l'aperçu de contribution] -->E[Lisez le contenu de K8s<br>et guide de style]
E --> F[Étudiez sur les types de contenu<br>et shortcodes de Hugo]
end
first ----> second
classDef grey fill:#dddddd,stroke:#ffffff,stroke-width:px,color:#000000, font-size:15px;
classDef white fill:#ffffff,stroke:#000,stroke-width:px,color:#000,font-weight:bold
classDef spacewhite fill:#ffffff,stroke:#fff,stroke-width:0px,color:#000
class A,B,D,E,F,G grey
class S,T spacewhite
class first,second white</div></figure><noscript><div class="alert alert-secondary callout" role=alert><em class=javascript-required>JavaScript must be <a href=https://www.enable-javascript.com/>enabled</a> to view this content</em></div></noscript>Figure 2. Préparation pour votre première contribution.</p><ul><li>Lisez <a href=/docs/contribute/new-content/>l'aperçu de la contribution</a> pour en savoir plus sur les différentes façons dont vous pouvez contribuer.</li><li>Vérifiez la <a href=https://github.com/kubernetes/website/issues/>liste de problèmes <code>kubernetes/website</code></a> pour les problèmes qui constituent de bons points d'entrée.</li><li><a href=/docs/contribute/new-content/open-a-pr/#changes-using-github>Soumettez un pull request dans GitHub</a> sur la documentation existante et apprenez-en plus sur comment créer des tickets dans GitHub.</li><li><a href=/docs/contribute/review/reviewing-prs/>Révisez des pull requests</a> d'autres membres de la communauté Kubernetes pour en vérifier l'exactitude et la langue.</li><li>Lisez le <a href=/docs/contribute/style/content-guide/>contenu</a> et les <a href=/docs/contribute/style/style-guide/>guides de style</a>de Kubernetes afin de pouvoir laisser des commentaires éclairés.</li><li>Étudiez sur les <a href=/docs/contribute/style/page-content-types/>types de contenu de page</a>
et <a href=/docs/contribute/style/hugo-shortcodes/>shortcodes</a>de Hugo.</li></ul><h2 id=prochaines-étapes>Prochaines étapes</h2><ul><li><p>Apprenez à <a href=/docs/contribute/new-content/open-a-pr/#fork-the-repo>travailler à partir d'un clone local</a> du répertoire.</p></li><li><p>Documentez <a href=/docs/contribute/new-content/new-features/>les fonctionnalités</a> d'une nouvelle version.</p></li><li><p>Participez à <a href=/docs/contribute/participate/>SIG Docs</a>, et devenez un
<a href=/docs/contribute/participate/roles-and-responsibilities/>membre ou réviseur</a>.</p></li><li><p>Demarrez ou aidez avec une <a href=/docs/contribute/localization/>localisation</a>.</p></li></ul><h2 id=engagez-vous-dans-sig-docs>Engagez-vous dans SIG Docs</h2><p><a href=/docs/contribute/participate/>SIG Docs</a> est le groupe de contributeurs qui publient et maintiennent la documentation Kubernetes et le site Web. S'impliquer dans SIG Docs est un excellent moyen pour les contributeurs Kubernetes (développement de fonctionnalités ou autre) d'avoir un impact important sur le projet Kubernetes.</p><p>SIG Docs communique avec différentes méthodes:</p><ul><li><a href=https://slack.k8s.io/>Joignez <code>#sig-docs</code> à l'instance Kubernetes sur Slack</a>. Assurez-vous de vous présenter!</li><li><a href=https://groups.google.com/forum/#!forum/kubernetes-sig-docs>Joignez la liste de diffusion <code>kubernetes-sig-docs</code></a>, où des discussions plus larges ont lieu et les décisions officielles sont enregistrées.</li><li>Joignez la <a href=https://github.com/kubernetes/community/tree/master/sig-docs>réunion vidéo SIG Docs</a> qui a lieu toutes les deux semaines. Les réunions sont toujours annoncées sur <code>#sig-docs</code> et ajoutées au <a href="https://calendar.google.com/calendar/embed?src=cgnt364vd8s86hr2phapfjc6uk%40group.calendar.google.com&ctz=America/Los_Angeles">calendrier des réunions de la communauté Kubernetes</a>. Vous devrez télécharger <a href=https://zoom.us/download>Zoom</a> ou vous connecter à l'aide d'un téléphone.</li><li>Joignez la réunion stand-up de SIG Docs sur Slack (async) les semaines où la réunion vidéo Zoom en personne n'a pas lieu. Les rendez-vous sont toujours annoncés sur <code>#sig-docs</code>. Vous pouvez contribuer à l'un des fils de discussion jusqu'à 24 heures après l'annonce de la réunion.</li></ul><h2 id=autres-façons-de-contribuer>Autres façons de contribuer</h2><ul><li>Visitez le site de la <a href=/community/>communauté Kubernetes</a>. Participez sur Twitter ou Stack Overflow, découvrez les meetups et événements Kubernetes locaux, et davantage encore.</li><li>Lisez le <a href=https://www.kubernetes.dev/docs/contributor-cheatsheet/>cheatsheet de contributor</a> pour vous impliquer dans le développement des fonctionnalités de Kubernetes.</li><li>Visitez le site des contributeurs pour en savoir plus sur <a href=https://www.kubernetes.dev/>les contributeurs Kubernetes</a> et des <a href=https://www.kubernetes.dev/resources/>ressources supplémentaires pour les contributeurs</a>.</li><li>Soumettez un article de <a href=/docs/contribute/new-content/blogs-case-studies/>blog ou une étude de cas</a>.</li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-3609b0e10614f1dc39ed781858319204>8.1 - Commencez à contribuer</h1><div class=lead>Démarrage contribution Kubernetes</div><p>Si vous souhaitez commencer à contribuer à la documentation de Kubernetes, cette page et les rubriques associées peuvent vous aider à démarrer.
Vous n'avez pas besoin d'être un développeur ou un rédacteur technique pour avoir un impact important sur la documentation et l'expérience utilisateur de Kubernetes !
Tout ce dont vous avez besoin pour les sujets de cette page est un compte <a href=https://github.com/join>GitHub</a> et un navigateur web.</p><p>Si vous recherchez des informations sur la façon de commencer à contribuer aux référentiels de code Kubernetes, reportez-vous à la section sur <a href=https://github.com/kubernetes/community/blob/master/governance.md>les directives de la communauté Kubernetes</a>.</p><h2 id=les-bases-de-notre-documentation>Les bases de notre documentation</h2><p>La documentation de Kubernetes est écrite en Markdown puis traitée et déployée à l’aide de Hugo.
Le code source est sur GitHub: <a href=https://github.com/kubernetes/website>https://github.com/kubernetes/website</a>.
La majeure partie de la documentation anglaise est stockée dans <code>/content/en/docs/</code>.
Une partie de la documentation de référence est automatiquement générée à partir de scripts du répertoire <code>update-imported-docs/</code>.</p><p>Vous pouvez trier les demandes, modifier le contenu et passer en revue les modifications des autres, le tout à partir du site Web de GitHub.
Vous pouvez également utiliser l'historique intégré et les outils de recherche de GitHub.</p><p>Toutes les tâches ne peuvent pas être effectuées dans l’interface utilisateur GitHub, mais elles sont décrites dans les guides de contribution <a href=/docs/contribute/intermediate/>intermédiaire</a> et <a href=/docs/contribute/advanced/>avancé</a>.</p><h3 id=participer-à-sig-docs>Participer à SIG Docs</h3><p>La documentation de Kubernetes est gérée par un groupe d'intérêt spécial (Special Interest Group (SIG)) appelé SIG Docs.
Nous communiquons via un canal Slack, une liste de diffusion et des réunions vidéo hebdomadaires.
Les nouveaux participants sont les bienvenus.
Pour plus d'informations, voir <a href=/docs/contribute/participating/>Participer au SIG-docs</a>.</p><h3 id=guides-de-style>Guides de style</h3><p>Nous maintenons un <a href=/docs/contribute/style/style-guide/>guide de style</a> avec des informations sur les choix de la communauté SIG Docs concernant la grammaire, la syntaxe, le format des sources et les conventions typographiques.
Avant de faire votre première contribution, parcourez le guide de style et utilisez-le lorsque vous avez des questions.</p><p>Les modifications apportées au guide de style sont effectuées par SIG Docs en tant que groupe.
Pour proposer un changement ou un ajout, <a href=https://docs.google.com/document/d/1Ds87eRiNZeXwRBEbFr6Z7ukjbTow5RQcNZLaSvWWQsE/edit#>ajoutez-le à l'ordre du jour</a> pour une réunion à venir sur les documents SIG et assister à la réunion pour participer à la discussion.
Voir le sujet <a href=/docs/contribute/advanced/>contribution avancée</a> pour plus d'informations.</p><h3 id=modèle-de-page>Modèle de page</h3><p>Nous utilisons des modèles de page pour contrôler la présentation de nos pages de documentation.
Assurez-vous de comprendre le fonctionnement de ces modèles en consultant <a href=/docs/contribute/style/page-templates/>Utilisation de modèles de page</a>.</p><h3 id=shortcodes-hugo>Shortcodes Hugo</h3><p>La documentation de Kubernetes est convertie de Markdown à HTML avec Hugo.
Nous utilisons les shortcodes standard Hugo, ainsi que quelques-uns qui sont personnalisés dans la documentation Kubernetes.
Voyez "<a href=/docs/contribute/style/hugo-shortcodes/>Shortcodes Hugo personnalisés</a>" pour savoir comment les utiliser.</p><h3 id=multilingue>Multilingue</h3><p>La source de la documentation est disponible en plusieurs langues dans <code>/content/</code>.
Chaque langue a son propre dossier avec un code à deux lettres déterminé par le <a href=https://www.loc.gov/standards/iso639-2/php/code_list.php>standard ISO 639-1</a>.
Par exemple, la source de la documentation anglaise est stockée dans <code>/content/en/docs/</code>.</p><p>Pour plus d'informations sur la contribution à la documentation dans plusieurs langues, consultez <a href=/docs/contribute/intermediate#localize-content>"Traduire le contenu"</a> dans le guide de contribution intermédiaire.</p><p>Si vous souhaitez démarrer une nouvelle traduction, voir <a href=/docs/contribute/localization/>"Traduction"</a>.</p><h2 id=créer-des-demandes-recevables>Créer des demandes recevables</h2><p>Toute personne possédant un compte GitHub peut soumettre un problème (rapport de bogue) à la documentation de Kubernetes.
Si vous voyez quelque chose qui ne va pas, même si vous ne savez pas comment le réparer, <a href=#how-to-file-an-issue>ouvrez un ticket</a>.
L'exception à cette règle est un petit bug, comme une faute de frappe, que vous souhaitez réparer vous-même.
Dans ce cas, vous pouvez plutôt <a href=#improve-existing-content>le réparer</a> sans déposer un bogue d'abord.</p><h3 id=comment-ouvrir-un-ticket>Comment ouvrir un ticket</h3><ul><li><p><strong>Sur une page existante</strong></p><p>Si vous voyez un problème dans une page existante de <a href=/docs/>la documentation Kubernetes</a>, allez au bas de la page et cliquez sur le bouton <strong>Create an Issue</strong>.
Si vous n'êtes pas actuellement connecté à GitHub, connectez-vous.
Un formulaire de ticket GitHub apparaît avec du contenu pré-rempli.</p><p>À l’aide de Markdown, renseignez autant de détails que possible.
Aux endroits où vous voyez des crochets vides (<code>[ ]</code>), mettre un <code>x</code> entre les crochets qui représente le choix approprié.
Si vous avez une solution proposée pour résoudre le problème, ajoutez-la.</p></li><li><p><strong>Demander une nouvelle page</strong></p><p>Si vous pensez que du contenu est manquant, mais que vous ne savez pas où il doit aller ou si vous pensez qu'il ne correspond pas aux pages existantes, vous pouvez toujours ouvrir un ticket.
Vous pouvez soit choisir une page existante à proximité du lieu où le nouveau contenu doit aller et classer le problème à partir de cette page, soit aller directement à <a href=https://github.com/kubernetes/website/issues/new/>https://github.com/kubernetes/website/issues/new/</a> et déposer le problème à partir de là.</p></li></ul><h3 id=comment-créer-de-bons-tickets>Comment créer de bons tickets</h3><p>Pour nous assurer que nous comprenons votre problème et pouvons y donner suite, gardez à l’esprit ces directives:</p><ul><li><p>Utilisez le modèle de ticket et renseignez autant de détails que possible.</p></li><li><p>Expliquez clairement l’impact spécifique du problème sur les utilisateurs.</p></li><li><p>Limiter la portée d'un problème à une unité de travail raisonnable.
Pour les problèmes de grande envergure, décomposez-les en problèmes plus petits.</p><p>Par exemple, "Corriger les docs de sécurité" n'est pas une question pouvant donner lieu à une action, mais "Ajouter des détails au thème 'Restreindre l'accès au réseau'" pourrait l'être.</p></li><li><p>Si la demande concerne un autre problème ou une pull request, vous pouvez y faire référence soit par son URL complète, soit par le problème ou par un numéro de demande d'extraction précédé du caractère "#".
Par exemple, <code>Introduced by #987654</code>.</p></li><li><p>Soyez respectueux et restez constructif.
Par exemple, "La documentation sur X est nulle" n'est ni utile ni constructif.
Le <a href=/community/code-of-conduct/>Code de conduite</a> s'applique également aux interactions sur les dépôts Kubernetes GitHub.</p></li></ul><h2 id=participer-aux-discussions-sig-docs>Participer aux discussions SIG Docs</h2><p>L'équipe SIG Docs communique à l'aide des mécanismes suivants:</p><ul><li><a href=http://slack.k8s.io/>Rejoindre l'instance Slack de Kubernetes</a>, puis rejoignez le canal <code>#sig-docs</code>, où nous discutons des problèmes de documentation en temps réel.
Présentez-vous quand vous arrivez!</li><li><a href=https://groups.google.com/forum/#!forum/kubernetes-sig-docs>Rejoignez la liste de diffusion <code>kubernetes-sig-docs</code></a>, où des discussions plus larges ont lieu et où les décisions officielles sont enregistrées.</li><li>Participer à l'<a href=https://github.com/kubernetes/community/tree/master/sig-docs>hebdomadaire SIG Docs</a>, une réunion vidéo, qui est annoncée sur le canal Slack et la liste de diffusion.
Actuellement, ces réunions ont lieu sur Zoom.
Vous devez donc télécharger le logiciel <a href=https://zoom.us/download>Zoom</a> ou rejoindre la conférence par téléphone.</li><li>Pour les utilisateurs francophones, vous pouvez également rejoindre le canal Slack <a href=https://kubernetes.slack.com/messages/CG838BFT9/><code>#kubernetes-docs-fr</code></a>, où nous discutons des traductions en Français de la documentation de Kubernetes.</li></ul><div class="alert alert-info note callout" role=alert><strong>Note:</strong> Vous pouvez également consulter la réunion hebdomadaire de SIG Docs sur <a href="https://calendar.google.com/calendar/embed?src=cgnt364vd8s86hr2phapfjc6uk%40group.calendar.google.com&ctz=America/Los_Angeles">Calendrier des réunions de la communauté Kubernetes</a>.</div><h2 id=améliorer-le-contenu-existant>Améliorer le contenu existant</h2><p>Pour améliorer le contenu existant, vous déposez une <em>pull request (PR)</em> après avoir créé un <em>fork</em>.
Ces deux termes sont <a href=https://help.github.com/categories/collaborating-with-issues-and-pull-requests/>spécifiques à GitHub</a>.
Pour les besoins de cette rubrique, vous n'avez pas besoin de tout savoir à leur sujet, car vous pouvez tout faire à l'aide de votre navigateur Web.
Quand vous passerez au <a href=/docs/contribute/intermediate/>Guide des contributeurs docs intermédiaires</a>, vous aurez besoin de plus de connaissances en terminologie Git.</p><div class="alert alert-info note callout" role=alert><strong>Note:</strong> <strong>Développeurs Kubernetes</strong>: Si vous documentez une nouvelle fonctionnalité pour une prochaine version de Kubernetes, votre processus est un peu différent.
Voir <a href=/docs/contribute/intermediate/#sig-members-documenting-new-features>Documenter une fonctionnalité</a> pour des instructions sur le processus et pour des des informations à propos des échéances.</div><h3 id=signer-le-cla>Signer le CLA</h3><p>Avant de pouvoir apporter du code ou de la documentation à Kubernetes, vous <strong>devez</strong> lire le <a href=https://github.com/kubernetes/community/blob/master/contributors/guide/README.md>Guide du contributeur</a> et <a href=https://github.com/kubernetes/community/blob/master/CLA.md>signer le Contributor License Agreement (CLA)</a>.
Ne vous inquiétez pas, cela ne prend pas longtemps !</p><h3 id=trouvez-quelque-chose-sur-lequel-travailler>Trouvez quelque chose sur lequel travailler</h3><p>Si vous voyez quelque chose que vous souhaitez réparer immédiatement, suivez simplement les instructions ci-dessous.
Vous n'avez pas besoin d'<a href=#file-actionable-issues>ouvrir un ticket</a> (bien que vous puissiez aussi).</p><p>Si vous souhaitez commencer par trouver un problème existant sur lequel travailler, allez à <a href=https://github.com/kubernetes/website/issues>https://github.com/kubernetes/website/issues</a> et chercher des problèmes avec le label <code>good first issue</code> (vous pouvez utiliser <a href="https://github.com/kubernetes/website/issues?q=is%3Aopen+is%3Aissue+label%3A%22good+first+issue%22">ce</a> raccourci).
Lisez tous les commentaires et assurez-vous qu’il n’y a pas de pull request existante pour ce même problème et que personne n’a laissé de commentaire indiquant qu’ils travaillent sur le problème récemment (une durée de 3 jours est une bonne règle).
Laissez un commentaire indiquant que vous souhaitez travailler sur la question.</p><h3 id=choisissez-quelle-branche-git-utiliser>Choisissez quelle branche Git utiliser</h3><p>L'aspect le plus important de la soumission d'une pull request c'est choisir la branche sur laquelle baser votre travail.
Utilisez ces directives pour prendre la décision:</p><ul><li>Utilisez <code>master</code> pour résoudre les problèmes de contenu déjà publié ou pour améliorer le contenu déjà existant.<ul><li>Utiliser une branche de publication (tel que <code>dev-release-1.25</code> pour le release-1.25 release) pour documenter les fonctionnalités ou modifications à venir pour une version à venir non encore publiée.</li></ul></li><li>Utilisez une branche de fonctionnalités approuvée par SIG Docs pour collaborer à de grandes améliorations ou modifications de la documentation existante, y compris la réorganisation du contenu ou des modifications apportées à l'apparence du site Web.</li></ul><p>Si vous ne savez toujours pas quelle branche choisir, demandez <code>#sig-docs</code> sur Slack ou assistez à une réunion hebdomadaire de documents SIG pour obtenir des précisions.</p><h3 id=soumettre-une-pull-request>Soumettre une pull request</h3><p>Suivez ces étapes pour soumettre une pull request afin d'améliorer la documentation de Kubernetes.</p><ol><li><p>Sur la page où vous voyez le problème, cliquez sur l'icône en forme de crayon en haut à gauche.
Une nouvelle page apparaît avec un texte d'aide.</p></li><li><p>Cliquez sur le premier bouton bleu, qui a le texte <strong>Edit &lt;page name></strong>.</p><p>Si vous n'avez jamais créé de fork du dépôt de documentation Kubernetes, vous êtes invité à le faire.
Créez le fork sous votre nom d'utilisateur GitHub, plutôt que celui d'une autre organisation dont vous pourriez être membre.
Le fork a généralement une URL telle que <code>https://github.com/&lt;nom d'utilisateur>/website</code>, à moins que vous n'ayez déjà un dépôt avec un nom en conflit (website).</p><p>La raison pour laquelle vous êtes invité à créer un fork est que vous n'avez pas le droit de pousser une branche directement vers le dépôt Kubernetes officiel.</p></li><li><p>L'éditeur GitHub Markdown apparaît avec le fichier source Markdown chargé.
Faites vos changements.
Sous l'éditeur, remplissez le formulaire <strong>Propose file change</strong>.
Le premier champ est le résumé de votre message de validation et ne doit pas dépasser 50 caractères.
Le deuxième champ est facultatif, mais peut inclure plus de détails si nécessaire.</p><div class="alert alert-info note callout" role=alert><strong>Note:</strong> Ne pas inclure de références à d’autres demandes GitHub ou pull requests dans votre message de commit.
Vous pouvez les ajouter ultérieurement à la description de la demande d'extraction.</div><p>Cliquez sur <strong>Propose file change</strong>.
La modification est enregistrée en tant que commit dans une nouvelle branche de votre fork, qui porte automatiquement le nom suivant: <code>patch-1</code>.</p></li><li><p>L’écran suivant récapitule les modifications que vous avez apportées en comparant votre nouvelle branche (les boîtes de sélection <strong>head fork</strong> et <strong>compare</strong>) à l'état actuel de <strong>base fork</strong> et <strong>base</strong> branche (<code>master</code> sur le dépôt <code>kubernetes/website</code> par défaut).
Vous pouvez modifier n'importe quelle boîte de sélection, mais ne le faites pas maintenant.
Jetez un coup d’œil à la visionneuse de différences en bas de l’écran et, si tout se présente bien, cliquez sur <strong>Create pull request</strong>.</p><div class="alert alert-info note callout" role=alert><strong>Note:</strong> Si vous ne voulez pas créer la pull request maintenant, vous pouvez le faire plus tard, en accédant à l'URL principale du référentiel de site Web Kubernetes ou du référentiel de votre fork.
Le site Web GitHub vous invitera à créer la pull request s'il détecte que vous avez poussé une nouvelle branche vers votre fork.</div></li><li><p>L'écran <strong>Open a pull request</strong> apparaît.
Le sujet de la pull request est identique au message du commit, mais vous pouvez le modifier si nécessaire.
Le corps est rempli par le reste du message du commit (s'il est présent) et par un modèle.
Lisez le modèle et remplissez les informations demandées, puis supprimez le texte supplémentaire.
Laissez la case à cocher sélectionnée <strong>Allow edits from maintainers</strong>.
Cliquez sur <strong>Create pull request</strong>.</p><p>Toutes nos félicitations !
Votre pull request est disponible dans <a href=https://github.com/kubernetes/website/pulls>Pull requests</a>.</p><p>Après quelques minutes, vous pouvez prévisualiser le site Web contenant les modifications apportées par votre PR.
Aller sur l'onglet <strong>Conversation</strong> de votre PR et cliquez sur le lien <strong>Details</strong> pour le déploiement <code>deploy/netlify</code>, près du bas de la page.
Il s'ouvrira dans la même fenêtre.</p></li><li><p>Attendez la revue.
En général, les relecteurs sont suggérés par le <code>k8s-ci-robot</code>.
Si un relecteur vous demande d’apporter des modifications, vous pouvez aller à l'onglet <strong>Files changed</strong> et cliquez sur l'icône en forme de crayon sur les fichiers modifiés par la pull request.
Lorsque vous enregistrez le fichier modifié, un nouveau commit est créé dans la branche surveillée par la pull request.</p></li><li><p>Si votre modification est acceptée, un relecteur fusionnera votre pull request, et le changement sera visible sur le site Web de Kubernetes quelques minutes plus tard.</p></li></ol><p>Ce n’est qu’un des différents moyens de soumettre une pull request.
Si vous êtes déjà un utilisateur expérimenté de Git et GitHub, vous pouvez utiliser une interface graphique locale ou un client Git en ligne de commande au lieu d'utiliser l'interface utilisateur de GitHub.
Quelques notions de base sur l’utilisation du client Git en ligne de commande sont abordées dans la section <a href=/docs/contribute/intermediate/>intermédiaire</a> du guide des contributeurs.</p><h2 id=relecture-des-pull-requests-de-documentation>Relecture des pull requests de documentation</h2><p>Les personnes qui ne sont pas encore des approbateurs ou des relecteurs peuvent quand même relire des pull requests.
Leurs avis ne font pas autorité, ce qui signifie que ces avis seuls ne causeront pas une fusion de la pull request.
Cependant, cela peut toujours être utile.
Même si vous ne laissez aucun commentaire, vous pourrez avoir une idée des conventions des pull requests, de l'étiquette des interactions entre les différents membres et ainsi vous habituer au processus.</p><ol><li><p>Allez à <a href=https://github.com/kubernetes/website/pulls>https://github.com/kubernetes/website/pulls</a>.
Vous verrez une liste de toutes les pull requests ouvertes visant site web Kubernetes et la documentation.</p></li><li><p>Par défaut, le seul filtre appliqué est <code>open</code>, donc vous ne voyez pas les pull requests qui ont déjà été fermées ou fusionnées.
C'est une bonne idée d'appliquer le filtre <code>cncf-cla: yes</code>, et pour votre premier examen, c'est une bonne idée d'ajouter <code>size/S</code> ou <code>size/XS</code>.
Le label <code>size</code> est appliqué automatiquement en fonction du nombre de lignes de code que la PR modifie.
Vous pouvez appliquer des filtres en utilisation les boites de sélection en haut de la page, ou utilisez directement <a href="https://github.com/kubernetes/website/pulls?q=is%3Aopen+is%3Apr+label%3A%22cncf-cla%3A+yes%22+label%3Asize%2FS">ce raccourci</a> pour voir seulement les petites PRs.
Tous les filtres sont combinés (opérateur <code>AND</code>), de sorte que vous ne pouvez pas rechercher <code>size/XS</code> et <code>size/S</code> dans la même requête.</p></li><li><p>Allez à l'onglet <strong>Files changed</strong>.
Parcourez les modifications introduites dans la PR et, le cas échéant, les problèmes liés.
Si vous constatez un problème ou des améliorations à apporter, passez la souris sur la ligne et cliquez sur le symbole <code>+</code> qui apparaît.</p><p>Vous pouvez taper un commentaire et choisir soit <strong>Add single comment</strong> ou <strong>Start a review</strong>.
En règle générale, il est préférable de commencer une revue, car elle vous permet de laisser plusieurs commentaires et d’avertir le propriétaire de la PR uniquement lorsque vous avez terminé la revue, plutôt qu'envoyer une notification distincte pour chaque commentaire.</p></li><li><p>Lorsque vous avez terminé, cliquez sur <strong>Review changes</strong> en haut de la page.
Vous pouvez résumer votre avis et choisir de commenter, approuver ou demander des modifications.
Les nouveaux contributeurs doivent toujours choisir <strong>Comment</strong>.</p></li></ol><p>Merci d'avoir commenté une pull request !
Lorsque vous débutez dans le projet, il est judicieux de demander votre avis sur votre pull request.
Le canal Slack <code>#sig-docs</code> est un excellent endroit pour faire cela.</p><h2 id=écrire-un-article-dans-le-blog>Écrire un article dans le blog</h2><p>Tout le monde peut écrire un article et le soumettre pour examen.
Les articles ne doivent pas être de nature commerciale et doivent comporter un contenu qui s’appliquera de manière large à la communauté Kubernetes.</p><p>Pour soumettre un article, vous pouvez soit le soumettre en utilisant le <a href=https://docs.google.com/forms/d/e/1FAIpQLSch_phFYMTYlrTDuYziURP6nLMijoXx_f7sLABEU5gWBtxJHQ/viewform>Formulaire de soumission de blog Kubernetes</a>, soit en suivant les étapes ci-dessous :</p><ol><li><a href=#sign-the-cla>Signez le CLA</a> si vous ne l'avez pas encore fait.</li><li>Consultez le format Markdown pour les articles de blog existants dans le <a href=https://github.com/kubernetes/website/tree/master/content/en/blog/_posts>dépôt du site web</a>.</li><li>Rédigez votre article dans l'éditeur de texte de votre choix.</li><li>Sur le même lien à partir de l'étape 2, cliquez sur le bouton <strong>Create new file</strong>.
Collez votre contenu dans l'éditeur.
Nommez le fichier pour qu'il corresponde au titre proposé de l'article, mais ne mettez pas la date dans le nom du fichier.
Les réviseurs de blog travailleront avec vous sur le nom de fichier final et la date de publication du blog.</li><li>Lorsque vous enregistrez le fichier, GitHub vous guidera à travers le processus d'une pull request.</li><li>Un critique de publication de blog examinera votre soumission et travaillera avec vous sur les commentaires et les détails finaux.
Lorsque l'article du blog est approuvé, la publication du blog est planifiée.</li></ol><h2 id=soumettre-une-étude-de-cas>Soumettre une étude de cas</h2><p>Des études de cas montrent comment les entreprises utilisent Kubernetes pour résoudre des problèmes concrets.
Elles sont écrites en collaboration avec l'équipe marketing de Kubernetes, qui est gérée par la CNCF.</p><p>Regardez la source des <a href=https://github.com/kubernetes/website/tree/master/content/en/case-studies>études de cas existantes</a>.
Utilisez le <a href=https://www.cncf.io/people/end-user-community/>Formulaire de soumission d'étude de cas Kubernetes</a> pour soumettre votre proposition.</p><h2 id=a-suivre>A suivre</h2><p>Si vous êtes à l'aise avec toutes les tâches décrites dans cette rubrique et que vous souhaitez vous engager plus profondément dans l'équipe de documentation de Kubernetes, lisez le <a href=/docs/contribute/intermediate/>guide de contribution de la documentation intermédiaire</a>.</p></div><div class=td-content style=page-break-before:always><h1 id=pg-8111429863728051b460e1f3a75b6fea>8.2 - Contributions avancées</h1><p>Cette page suppose que vous avez lu et maîtrisé les sujets suivants : <a href=/docs/contribute/start/>Commencez à contribuer</a> et <a href=/docs/contribute/intermediate/>Contribution Intermédiaire</a> et êtes prêts à apprendre plus de façons de contribuer.
Vous devez utiliser Git et d'autres outils pour certaines de ces tâches.</p><h2 id=soyez-le-trieur-de-pr-pendant-une-semaine>Soyez le trieur de PR pendant une semaine</h2><p>Les <a href=/docs/contribute/participating/#approvers>approbateurs SIG Docs</a> peuvent être trieurs de Pull Request (PR).</p><p>Les approbateurs SIG Docs sont ajoutés au <a href=https://github.com/kubernetes/website/wiki/PR-Wranglers>PR Wrangler rotation scheduler</a> pour les rotations hebdomadaires.
Les fonctions de trieur de PR incluent:</p><ul><li>Faire une revue quotidienne des nouvelles pull requests.<ul><li>Aidez les nouveaux contributeurs à signer le CLA et fermez toutes les PR où le CLA n'a pas été signé depuis deux semaines.
Les auteurs de PR peuvent rouvrir la PR après avoir signé le CLA, c’est donc un moyen à faible risque de s’assurer que rien n’est merged sans un CLA signé.</li><li>Fournir des informations sur les modifications proposées, notamment en facilitant les examens techniques des membres d'autres SIGs.</li><li>Faire un merge des PRs quand elles sont prêtes, ou fermer celles qui ne devraient pas être acceptées.</li></ul></li><li>Triez et étiquetez les tickets entrants (Github Issues) chaque jour.
Consultez <a href=/docs/contribute/intermediate/>Contributions Intermédiaires</a> pour obtenir des instructions sur la manière dont SIG Docs utilise les métadonnées.</li></ul><h3 id=requêtes-github-utiles-pour-les-trieurs>Requêtes Github utiles pour les trieurs</h3><p>Les requêtes suivantes sont utiles lors des opérations de triage.
Après avoir utilisé ces trois requêtes, la liste restante de PRs devant être examinées est généralement petite.
Ces requêtes excluent spécifiquement les PRs de localisation, et n'incluent que la branche <code>master</code> (sauf la derniere).</p><ul><li><a href="https://github.com/kubernetes/website/pulls?q=is%3Aopen+is%3Apr+label%3A%22cncf-cla%3A+no%22+-label%3Ado-not-merge+label%3Alanguage%2Fen">Pas de CLA, non éligible au merge</a>:
Rappelez au contributeur de signer le CLA. S’ils ont déjà été rappelés à la fois par le bot et par un humain, fermez la PR et rappelez-leur qu'ils peuvent l'ouvrir après avoir signé le CLA.
<strong>Nous ne pouvons même pas passer en revue les PR dont les auteurs n'ont pas signé le CLA !</strong></li><li><a href="https://github.com/kubernetes/website/pulls?utf8=%E2%9C%93&q=is%3Aopen+is%3Apr+-label%3Ado-not-merge+label%3Alanguage%2Fen+-label%3Algtm+">A besoin de LGTM</a>:
Si cela nécessite une révision technique, contactez l'un des réviseurs proposés par le bot.
Si cela nécessite une révision de la documentation ou une édition, vous pouvez soit suggérer des modifications, soit ajouter un commit d'édition à la PR pour la faire avancer.</li><li><a href="https://github.com/kubernetes/website/pulls?q=is%3Aopen+is%3Apr+-label%3Ado-not-merge+label%3Alanguage%2Fen+label%3Algtm">A des LGTM, a besoin de docs approval</a>:
Voyez si vous pouvez comprendre ce qui doit se passer pour que la PR soit mergée.</li><li><a href="https://github.com/kubernetes/website/pulls?utf8=%E2%9C%93&q=is%3Aopen+is%3Apr+-label%3Ado-not-merge+label%3Alanguage%2Fen+-base%3Amaster">Not against master</a>: Si c'est basé sur une branche <code>dev-</code>, c'est pour une release prochaine.
Assurez vous que le <a href=https://github.com/kubernetes/sig-release/tree/master/release-team>release meister</a> est au courant.
Si elle se base sur une branche obsolète, aidez l'auteur de la PR à comprendre comment choisir la meilleure branche.</li></ul><h2 id=proposer-des-améliorations>Proposer des améliorations</h2><p>Les <a href=/docs/contribute/participating/#members>membres</a> SIG Docs peuvent proposer des améliorations.</p><p>Après avoir contribué à la documentation de Kubernetes pendant un certain temps, vous pouvez avoir des idées pour améliorer le guide de style, les outils utilisés pour construire la documentation, le style du site, les processus de révision et faire un merge de pull requests, ou d'autres aspects de la documentation.
Pour une transparence maximale, ces types de propositions doivent être discutées lors d’une réunion SIG Docs ou sur la <a href=https://groups.google.com/forum/#!forum/kubernetes-sig-docs>liste de diffusion kubernetes-sig-docs</a>.
En outre, il peut être vraiment utile de situer le fonctionnement actuel et de déterminer les raisons pour lesquelles des décisions antérieures ont été prises avant de proposer des changements radicaux.
Le moyen le plus rapide d’obtenir des réponses aux questions sur le fonctionnement actuel de la documentation est de le demander dans le canal <code>#sig-docs</code> sur le Slack officiel <a href=https://kubernetes.slack.com>kubernetes.slack.com</a></p><p>Une fois que la discussion a eu lieu et que le SIG est d'accord sur le résultat souhaité, vous pouvez travailler sur les modifications proposées de la manière la plus appropriée.
Par exemple, une mise à jour du guide de style ou du fonctionnement du site Web peut impliquer l’ouverture d’une pull request, une modification liée aux tests de documentation peut impliquer de travailler avec sig-testing.</p><h2 id=coordonner-la-documentation-pour-une-version-de-kubernetes>Coordonner la documentation pour une version de Kubernetes</h2><p><a href=/docs/contribute/participating/#approvers>Les approbateurs</a> SIG Docs peuvent coordonner les tâches liées à la documentation pour une release de Kubernetes.</p><p>Chaque release de Kubernetes est coordonnée par une équipe de personnes participant au sig-release Special Interest Group (SIG).
Les autres membres de l'équipe de publication pour une release donnée incluent un responsable général de la publication, ainsi que des représentants de sig-pm, de sig-testing et d'autres.
Pour en savoir plus sur les processus de release de Kubernetes, reportez-vous à la section <a href=https://github.com/kubernetes/sig-release>https://github.com/kubernetes/sig-release</a>.</p><p>Le représentant de SIG Docs pour une release donnée coordonne les tâches suivantes:</p><ul><li>Surveillez le feature-tracking spreadsheet pour les fonctionnalités nouvelles ou modifiées ayant un impact sur la documentation.
Si la documentation pour une fonctionnalité donnée ne sera pas prête pour la release, la fonctionnalité peut ne pas être autorisée à entrer dans la release.</li><li>Assistez régulièrement aux réunions de sig-release et donnez des mises à jour sur l'état de la documentation pour la release.</li><li>Consultez et copiez la documentation de la fonctionnalité rédigée par le SIG responsable de la mise en œuvre de la fonctionnalité.</li><li>Mergez les pull requests liées à la release et maintenir la branche de fonctionnalité Git pour la version.</li><li>Encadrez d'autres contributeurs SIG Docs qui souhaitent apprendre à jouer ce rôle à l'avenir.
  Ceci est connu comme "l'observation" (shadowing en anglais).</li><li>Publiez les modifications de la documentation relatives à la version lorsque les artefacts de la version sont publiés.</li></ul><p>La coordination d'une publication est généralement un engagement de 3 à 4 mois et les tâches sont alternées entre les approbateurs SIG Docs.</p><h2 id=parrainez-un-nouveau-contributeur>Parrainez un nouveau contributeur</h2><p>Les <a href=/docs/contribute/participating/#reviewers>relecteurs</a> SIG Docs peuvent parrainer de nouveaux contributeurs.</p><p>Après que les nouveaux contributeurs aient soumis avec succès 5 pull requests significatives vers un ou plusieurs dépôts Kubernetes, ils/elles sont éligibles pour postuler à l'<a href=/docs/contribute/participating#members>adhésion</a> dans l'organisation Kubernetes.
L'adhésion des contributeurs doit être soutenue par deux sponsors qui sont déjà des réviseurs.</p><p>Les nouveaux contributeurs docs peuvent demander des sponsors dans le canal #sig-docs sur le <a href=https://kubernetes.slack.com>Slack Kubernetes</a> ou sur la <a href=https://groups.google.com/forum/#!forum/kubernetes-sig-docs>mailing list SIG Docs</a>.
Si vous vous sentez confiant dans le travail des candidats, vous vous portez volontaire pour les parrainer.
Lorsqu’ils soumettent leur demande d’adhésion, répondez-y avec un "+1" et indiquez les raisons pour lesquelles vous estimez que les demandeurs sont des candidat(e)s valables pour devenir membre de l’organisation Kubernetes.</p></div><div class=td-content style=page-break-before:always><h1 id=pg-a2d946282df02cdeb47d9f54dfef198e>8.3 - Aperçu du style de documentation</h1><div class=lead>Style de la documentation francophone</div><p>Les rubriques de cette section fournissent des informations sur le style d'écriture, la mise en forme et l'organisation du contenu, ainsi que sur l'utilisation des personnalisations Hugo spécifiques à la documentation Kubernetes.</p></div><div class=td-content><h1 id=pg-75de610057816ac48210db20ec633217>8.3.1 - Documentation Style Guide</h1><p>Cette page donne des directives de style d'écriture pour la documentation de Kubernetes.
Ce sont des lignes directrices, pas des règles.
Faites preuve de discernement et n'hésitez pas à proposer des modifications à ce document dans le cadre d'une pull request.</p><p>Pour plus d'informations sur la création de nouveau contenu pour les documents Kubernetes, suivez les instructions sur<a href=/fr/docs/contribute/style/page-templates/>l'utilisation des templates</a> et <a href=/fr/docs/contribute/start/#improve-existing-content>création d'une pull request de documentation</a>.</p><div class="alert alert-info note callout" role=alert><strong>Note:</strong> La documentation de Kubernetes utilise <a href=https://github.com/russross/blackfriday>Blackfriday Markdown Renderer</a> ainsi que quelques <a href=/docs/home/contribute/includes/>Hugo Shortcodes</a> pour prendre en charge les entrées de glossaire, les onglets et la représentation de l'état des fonctionnalités.</div><h2 id=language>Language</h2><p>La documentation de Kubernetes utilise l'anglais américain comme langue de référence.</p><h2 id=normes-de-formatage-de-la-documentation>Normes de formatage de la documentation</h2><h3 id=utilisez-le-camel-case-pour-les-objets-d-api>Utilisez le camel case pour les objets d'API</h3><p>Lorsque vous faites référence à un objet API, utilisez les mêmes lettres majuscules et minuscules que celles utilisées dans le nom d'objet réel.
Typiquement, les noms des objets de l'API utilisent le <a href=https://en.wikipedia.org/wiki/Camel_case>camel case</a>.</p><p>Ne divisez pas le nom de l'objet API en mots séparés.
Par exemple, utilisez PodTemplateList, et pas Pod Template List.</p><p>Référez-vous aux objets de l'API sans dire "objet", à moins que l'omission de "objet" n'entraîne une construction maladroite.</p><table><thead><tr><th>À faire</th><th>À éviter</th></tr></thead><tbody><tr><td>Le Pod dispose de deux conteneurs.</td><td>La pod a deux conteneurs.</td></tr><tr><td>Le Deployment est responsable de ce qui suit ...</td><td>L'objet Déployment est responsable de ...</td></tr><tr><td>Une PodList est une liste de Pod.</td><td>Une Pod List est une liste de pods.</td></tr><tr><td>Les deux ContainerPorts ...</td><td>Les deux objets ContainerPort ...</td></tr><tr><td>Les deux objets ContainerStateTerminated ...</td><td>Les deux ContainerStateTerminateds ...</td></tr></tbody></table><h3 id=use-angle-brackets-for-placeholders>Use angle brackets for placeholders</h3><p>Use angle brackets for placeholders.
Tell the reader what a placeholder represents.</p><ol><li><p>Affiche des informations sur un Pod :</p><pre><code>kubectl describe pod &lt;pod-name&gt;
</code></pre><p>where <code>&lt;pod-name></code> is the name of one of your Pods.</p></li></ol><h3 id=use-bold-for-user-interface-elements>Use bold for user interface elements</h3><table><thead><tr><th>À faire</th><th>À éviter</th></tr></thead><tbody><tr><td>Cliquez sur <strong>Fork</strong>.</td><td>Cliquez sur "Fork".</td></tr><tr><td>Sélectionnez <strong>Other</strong>.</td><td>Sélectionnez 'Other'.</td></tr></tbody></table><h3 id=utiliser-l-italique-pour-définir-ou-introduire-de-nouveaux-termes>Utiliser l'italique pour définir ou introduire de nouveaux termes.</h3><table><thead><tr><th>À faire</th><th>À éviter</th></tr></thead><tbody><tr><td>Un <em>cluster</em> est un ensemble de nœuds ...</td><td>Un "cluster" est un ensemble de nœuds ...</td></tr><tr><td>Ces composantes forment le <em>control plane</em>.</td><td>Ces composantes forment le <strong>control plane</strong>.</td></tr></tbody></table><h3 id=utiliser-un-style-de-code-pour-les-noms-de-fichiers-les-répertoires-et-les-chemins-d-accès>Utiliser un style de code pour les noms de fichiers, les répertoires et les chemins d'accès</h3><table><tr><th>À faire</th><th>À éviter</th></tr><tr><td>Open the <code>envars.yaml</code> file.</td><td>Open the envars.yaml file.</td></tr><tr><td>Aller dans le répertoire <code>/docs/tutorials</code>.</td><td>Go to the /docs/tutorials directory.</td></tr><tr><td>Open the <code>/_data/concepts.yaml</code> file.</td><td>Open the /_data/concepts.yaml file.</td></tr></table><h3 id=utiliser-la-norme-internationale-pour-la-ponctuation-entre-guillemets>Utiliser la norme internationale pour la ponctuation entre guillemets</h3><table><thead><tr><th>À faire</th><th>À éviter</th></tr></thead><tbody><tr><td>events are recorded with an associated "stage".</td><td>events are recorded with an associated "stage."</td></tr><tr><td>The copy is called a "fork".</td><td>The copy is called a "fork."</td></tr></tbody></table><h2 id=inline-code-formatting>Inline code formatting</h2><h3 id=use-code-style-for-inline-code-and-commands>Use code style for inline code and commands</h3><p>For inline code in an HTML document, use the <code>&lt;code></code> tag. In a Markdown document, use the backtick (`).</p><table><tr><th>À faire</th><th>À éviter</th></tr><tr><td>The <code>kubectl run</code> command creates a Deployment.</td><td>The "kubectl run" command creates a Deployment.</td></tr><tr><td>For declarative management, use <code>kubectl apply</code>.</td><td>For declarative management, use "kubectl apply".</td></tr><tr><td>Enclose code samples with triple backticks. <code>(```)</code></td><td>Enclose code samples with any other syntax.</td></tr></table><div class="alert alert-info note callout" role=alert><strong>Note:</strong> Le site Web prend en charge la coloration syntaxique pour les échantillons de code, mais la spécification d'une langue est facultative.</div><h3 id=utiliser-le-style-de-code-pour-les-noms-de-champs-d-objets>Utiliser le style de code pour les noms de champs d'objets</h3><table><tr><th>À faire</th><th>À éviter</th></tr><tr><td>Set the value of the <code>replicas</code> field in the configuration file.</td><td>Définissez la valeur du champ "replicas" dans le fichier de configuration.</td></tr><tr><td>The value of the <code>exec</code> field is an ExecAction object.</td><td>La valeur du champ "exec" est un objet ExecAction.</td></tr></table><h3 id=utiliser-le-style-normal-pour-les-chaînes-de-caractères-et-les-valeurs-de-champs-entiers>Utiliser le style normal pour les chaînes de caractères et les valeurs de champs entiers</h3><p>Pour les valeurs de champ de type chaîne de caractères ou entier, utilisez un style normal sans guillemets.</p><table><thead><tr><th>À faire</th><th>À éviter</th></tr></thead><tbody><tr><td>Set the value of <code>imagePullPolicy</code> to Always.</td><td>Set the value of <code>imagePullPolicy</code> to "Always".</td></tr><tr><td>Set the value of <code>image</code> to nginx:1.8.</td><td>Set the value of <code>image</code> to <code>nginx:1.8</code>.</td></tr><tr><td>Set the value of the <code>replicas</code> field to 2.</td><td>Set the value of the <code>replicas</code> field to <code>2</code>.</td></tr></tbody></table><h2 id=code-snippet-formatting>Code snippet formatting</h2><h3 id=ne-pas-inclure-l-invite-de-commande>Ne pas inclure l'invite de commande</h3><table><thead><tr><th>À faire</th><th>À éviter</th></tr></thead><tbody><tr><td>kubectl get pods</td><td>$ kubectl get pods</td></tr></tbody></table><h3 id=séparer-les-commandes-de-la-sortie>Séparer les commandes de la sortie</h3><p>Vérifiez que le Pod fonctionne sur le nœud que vous avez choisi :</p><pre><code>kubectl get pods --output=wide
</code></pre><p>La sortie est similaire à celle-ci :</p><pre><code>NAME     READY     STATUS    RESTARTS   AGE    IP           NODE
nginx    1/1       Running   0          13s    10.200.0.4   worker0
</code></pre><h3 id=versioning-kubernetes-examples>Versioning Kubernetes examples</h3><p>Code examples and configuration examples that include version information should be consistent with the accompanying text.</p><p>If the information is version specific, the Kubernetes version needs to be defined in the <code>prerequisites</code> section of the <a href=/docs/contribute/style/page-templates/#task-template>Task template</a> or the [Tutorial template] (/docs/contribute/style/page-templates/#tutorial-template).
Once the page is saved, the <code>prerequisites</code> section is shown as <strong>Before you begin</strong>.</p><p>Pour spécifier la version de Kubernetes pour une tâche ou une page de tutoriel, incluez <code>min-kubernetes-server-version</code> dans l'entête de la page.</p><p>Si l'exemple YAML se trouve dans un fichier autonome, recherchez et passez en revue les sujets qui l'incluent comme référence.
Vérifiez que toutes les rubriques utilisant le YAML autonome ont les informations de version appropriées définies.
Si un fichier YAML autonome n'est référencé à partir d'aucun sujet, pensez à le supprimer au lieu de le mettre à jour.</p><p>Par exemple, si vous écrivez un tutoriel pertinent pour Kubernetes version 1.8, la première partie de votre fichier de démarque doit ressembler à ceci :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#00f;font-weight:700>---</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>title</span>:<span style=color:#bbb> </span>&lt;your tutorial title here&gt;<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>min-kubernetes-server-version</span>:<span style=color:#bbb> </span>v1.8<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:#00f;font-weight:700>---</span><span style=color:#bbb>
</span></span></span></code></pre></div><p>Dans les exemples de code et de configuration, n'incluez pas de commentaires sur les versions alternatives.
Veillez à ne pas inclure d'énoncés incorrects dans vos exemples sous forme de commentaires, tels que :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb> </span><span style=color:#080;font-style:italic># earlier versions use...</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:#00f;font-weight:700>...</span><span style=color:#bbb>
</span></span></span></code></pre></div><h2 id=liste-de-mots-kubernetes-io>Liste de mots Kubernetes.io</h2><p>Une liste de termes et de mots spécifiques à Kubernetes à utiliser de manière cohérente sur le site.</p><table><thead><tr><th>Term</th><th>Usage</th></tr></thead><tbody><tr><td>Kubernetes</td><td>Kubernetes a toujours une majuscule.</td></tr><tr><td>Docker</td><td>Docker a toujours une majuscule.</td></tr><tr><td>SIG Docs</td><td>SIG Docs plutôt que SIG-DOCS ou d'autres variantes.</td></tr></tbody></table><h2 id=shortcodes>Shortcodes</h2><p>Hugo <a href=https://gohugo.io/content-management/shortcodes>Shortcodes</a> help create different rhetorical appeal levels.
Notre documentation prend en charge trois shortcodes différents dans cette catégorie : <strong>Note</strong> {{&lt; note >}}, <strong>Mise en garde</strong> {{&lt; caution >}}, et <strong>Avertissement</strong> {{&lt; warning >}}.</p><ol><li><p>Entourez le texte d'un raccourci d'ouverture et de fermeture.</p></li><li><p>Utilisez la syntaxe suivante pour appliquer un style :</p><pre tabindex=0><code>{{&lt; note &gt;}}
Il n&#39;est pas nécessaire d&#39;inclure un préfixe ; le shortcode fournit automatiquement (Note:, Caution:, etc.).
{{&lt; /note &gt;}}
</code></pre></li></ol><p>La sortie est :</p><div class="alert alert-info note callout" role=alert><strong>Note:</strong> Le préfixe que vous choisissez est le même que le texte de la balise.</div><h3 id=note>Note</h3><p>Utilisez {{&lt; note *//>}} pour mettre en surbrillance un conseil ou une information qu'il peut être utile de connaître.</p><p>Par exemple :</p><pre tabindex=0><code>{{&lt;/* note &gt;}}
Vous pouvez _toujours_ utiliser Markdown à l&#39;intérieur de ces légendes.
{{&lt; /note &gt;}}
</code></pre><p>La sortie est :</p><div class="alert alert-info note callout" role=alert><strong>Note:</strong> Vous pouvez <em>toujours</em> utiliser Markdown à l'intérieur de ces légendes.</div><h3 id=mise-en-garde>Mise en garde</h3><p>Utilisez {{&lt; caution *//>}} pour attirer l'attention sur une information importante afin d'éviter les pièges.</p><p>Par exemple :</p><pre tabindex=0><code>{{&lt;/* caution &gt;}}
Le style de légende ne s&#39;applique qu&#39;à la ligne directement au-dessus de la balise.
{{&lt; /caution &gt;}}
</code></pre><p>La sortie est :</p><div class="alert alert-warning caution callout" role=alert><strong>Avertissement:</strong> Le style de légende ne s'applique qu'à la ligne directement au-dessus de la balise.</div><h3 id=avertissement>Avertissement</h3><p>Utilisez {{&lt; warning *//>}} pour indiquer un danger ou une information cruciale à suivre.</p><p>Par exemple :</p><pre tabindex=0><code>{{&lt;/* warning &gt;}}
Méfiez-vous.
{{&lt; /warning &gt;}}
</code></pre><p>La sortie est :</p><div class="alert alert-danger warning callout" role=alert><strong>Attention:</strong> Méfiez-vous.</div><h3 id=katacoda-embedded-live-environment>Katacoda Embedded Live Environment</h3><p>Ce bouton permet aux utilisateurs d'exécuter Minikube dans leur navigateur en utilisant le <a href=https://www.katacoda.com/embed/panel>Katacoda Terminal</a>.
Il abaisse le seuil d'entrée en permettant aux utilisateurs d'utiliser Minikube en un seul clic au lieu de passer par l'ensemble du processus d'installation Minikube et Kubectl localement.</p><p>The Embedded Live Environment is configured to run <code>minikube start</code> and lets users complete tutorials in the same window as the documentation.</p><div class="alert alert-warning caution callout" role=alert><strong>Avertissement:</strong> La session est limitée à 15 minutes.</div><p>For example:</p><pre tabindex=0><code>{{&lt; kat-button &gt;}}
</code></pre><p>La sortie est :</p><script defer src=https://katacoda.com/embed.js></script>
<button class=button onclick=window.katacoda.init()>Launch Terminal</button><h2 id=common-shortcode-issues>Common Shortcode Issues</h2><h3 id=ordered-lists>Ordered Lists</h3><p>Un Shortcode interrompra les listes numérotées à moins que vous ne mettiez une indentation de 4 espaces avant l'avis et l'étiquette.</p><p>Par exemple :</p><pre><code>1. Préchauffer le four à 350˚F

1. Préparer la pâte et la verser dans un moule à charnière.
   {{&lt; note &gt;}}**Note:** Graisser la casserole pour de meilleurs résultats.{{&lt; /note &gt;}}

1. Cuire au four de 20 à 25 minutes ou jusqu'à ce que ce soit pris.
</code></pre><p>La sortie est :</p><ol><li><p>Préchauffer le four à 350˚F</p></li><li><p>Préparer la pâte et la verser dans un moule à charnière.</p><div class="alert alert-info note callout" role=alert><strong>Note:</strong> Graisser la casserole pour de meilleurs résultats.</div></li><li><p>Cuire au four de 20 à 25 minutes ou jusqu'à ce que ce soit pris.</p></li></ol><h3 id=expressions-includes>Expressions Includes</h3><p>Les Shortcodes dans les expressions d'include brisera la compilation du site.
Vous devez les insérer dans le document parent, avant et après avoir appelé l'include.
Par exemple :</p><pre tabindex=0><code>{{&lt; note &gt;}}
{{&lt; include &#34;task-tutorial-prereqs.md&#34; &gt;}}
{{&lt; /note &gt;}}
</code></pre><h2 id=meilleures-pratiques-en-matière-de-contenu>Meilleures pratiques en matière de contenu</h2><p>Cette section contient des suggestions de pratiques exemplaires pour un contenu clair, concis et cohérent.</p><h3 id=utiliser-le-présent>Utiliser le présent</h3><table><thead><tr><th>À faire</th><th>À éviter</th></tr></thead><tbody><tr><td>Cette commande lance un proxy.</td><td>Cette commande lancera un proxy.</td></tr></tbody></table><p>Exception : Utilisez le futur ou le passé s'il est nécessaire pour transmettre le sens correct.</p><h3 id=utiliser-la-voix-active>Utiliser la voix active</h3><table><thead><tr><th>À faire</th><th>À éviter</th></tr></thead><tbody><tr><td>Vous pouvez explorer l'API à l'aide d'un navigateur.</td><td>L'API peut être explorée à l'aide d'un navigateur.</td></tr><tr><td>Le fichier YAML spécifie le nombre de répliques.</td><td>Le nombre de répliques est spécifié dans le fichier YAML.</td></tr></tbody></table><p>Exception : Utilisez la voix passive si la voix active conduit à une construction maladroite.</p><h3 id=utiliser-un-langage-simple-et-direct>Utiliser un langage simple et direct</h3><p>Utilisez un langage simple et direct.
Évitez d'utiliser des expressions inutiles, comme "s'il vous plaît".</p><table><thead><tr><th>À faire</th><th>À éviter</th></tr></thead><tbody><tr><td>Pour créer un ReplicaSet, ...</td><td>Afin de créer un ReplicaSet, ...</td></tr><tr><td>Voir le fichier de configuration.</td><td>Veuillez consulter le fichier de configuration.</td></tr><tr><td>Voir les Pods.</td><td>Avec cette prochaine commande, nous allons voir les Pods.</td></tr></tbody></table><h3 id=s-adresser-au-lecteur-en-tant-que-vous>S'adresser au lecteur en tant que "vous"</h3><table><thead><tr><th>À faire</th><th>À éviter</th></tr></thead><tbody><tr><td>Vous pouvez créer un déploiement en ...</td><td>Nous allons créer un déploiement en ...</td></tr><tr><td>Dans l'édition précédente, vous pouvez voir...</td><td>Dans la sortie précédente, on peut voir ...</td></tr></tbody></table><h3 id=évitez-les-phrases-latines>Évitez les phrases latines</h3><p>Préférez les termes français aux abréviations latines.</p><table><thead><tr><th>À faire</th><th>À éviter</th></tr></thead><tbody><tr><td>Par exemple, ...</td><td>e.g., ...</td></tr><tr><td>C'est à dire, ...</td><td>i.e., ...</td></tr></tbody></table><p>Exception : Utilisez "etc." pour et cetera.</p><h2 id=tendances-à-éviter>Tendances à éviter</h2><h3 id=évitez-d-utiliser-nous>Évitez d'utiliser "nous"</h3><p>L'utilisation du "nous" dans une phrase peut prêter à confusion, car le lecteur pourrait ne pas savoir s'ils font partie du "nous" que vous décrivez.</p><table><thead><tr><th>À faire</th><th>À éviter</th></tr></thead><tbody><tr><td>La version 1.4 comprend ...</td><td>Dans la version 1.4, nous avons ajouté ...</td></tr><tr><td>Kubernetes offre une nouvelle fonctionnalité pour ...</td><td>Nous proposons une nouvelle fonctionnalité ...</td></tr><tr><td>Cette page vous apprend à utiliser les Pods.</td><td>Dans cette page, nous allons en savoir plus sur les Pods.</td></tr></tbody></table><h3 id=évitez-le-jargon-et-les-expressions-idiomatiques>Évitez le jargon et les expressions idiomatiques</h3><p>Certains lecteurs parlent le français comme seconde langue.
Évitez le jargon et les expressions idiomatiques pour les aider à mieux comprendre.</p><table><thead><tr><th>À faire</th><th>À éviter</th></tr></thead><tbody><tr><td>En interne, ...</td><td>Sous le capot, ...</td></tr><tr><td>Créer un nouveau cluster.</td><td>Monter un nouveau cluster.</td></tr></tbody></table><h3 id=évitez-les-déclarations-sur-l-avenir>Évitez les déclarations sur l'avenir</h3><p>Évitez de faire des promesses ou de donner des conseils sur l'avenir.
Si vous avez besoin de parler d'une fonctionnalité alpha, placez le texte sous un titre qui l'identifie comme une fonctionnalité alpha.</p><h3 id=évitez-les-déclarations-qui-seront-bientôt-périmées>Évitez les déclarations qui seront bientôt périmées</h3><p>Évitez les mots comme "actuellement" et "nouveau".
Une caractéristique qui est nouvelle aujourd'hui pourrait ne pas être considérée comme nouvelle dans quelques mois.</p><table><thead><tr><th>À faire</th><th>À éviter</th></tr></thead><tbody><tr><td>Dans la version 1.4, ...</td><td>Dans la version actuelle, ...</td></tr><tr><td>La fonction de fédération offre ...</td><td>La nouvelle fonctionnalité de la Fédération offre ...</td></tr></tbody></table><h2 id=a-suivre>A suivre</h2><ul><li>En savoir plus sur <a href=/docs/home/contribute/write-new-topic/>writing a new topic</a>.</li><li>En savoir plus sur <a href=/docs/home/contribute/page-templates/>using page templates</a>.</li><li>En savoir plus sur <a href=/docs/home/contribute/stage-documentation-changes/>staging your changes</a></li><li>En savoir plus sur <a href=/docs/home/contribute/create-pull-request/>creating a pull request</a>.</li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-4f09c4b708d2dd4ac9eac1080dab6728>8.3.2 - Rédiger une nouveau sujet</h1><p>Cette page montre comment créer un nouveau sujet pour la documentation Kubernetes.</p><h2 id=pré-requis>Pré-requis</h2><p>Créez un fork du dépôt de la documentation de Kubernetes comme décrit dans <a href=/fr/docs/contribute/start/>Commencez à contribuer</a>.</p><h2 id=choisir-un-type-de-page>Choisir un type de page</h2><p>Alors que vous vous préparez à écrire un nouveau sujet, pensez au type de page qui convient le mieux à votre contenu :</p><table><tr><td>Concept</td><td>Une page de concept explique certains aspects de Kubernetes. Par exemple, une page conceptuelle pourrait décrire l'objet Kubernetes `Déploiement` et expliquer le rôle qu'il joue en tant qu'application pendant son déploiement, sa mise à l'échelle, ou sa mise à jour. Généralement, les pages conceptuelles n'incluent pas de séquences d'étapes, mais fournissent plutôt des liens vers des tâches ou des tutoriels. Pour un exemple de sujet de concept, voir <a href=/fr/docs/concepts/architecture/nodes/>Noeuds</a>.</td></tr><tr><td>Tâche</td><td>Une page de tâches montre comment faire une seule chose. L'idée est de donner aux lecteurs une séquence d'étapes qu'ils peuvent suivre en lisant la page. Une page de tâches peut être courte ou longue, à condition qu'elle reste concentrée sur un domaine. Dans une page de tâches, il est acceptable de mélanger de brèves explications avec les étapes à effectuer, mais si vous avez besoin de fournir une longue explication, vous devriez le faire dans un sujet de concept. Les tâches et les concepts connexes devraient être reliés les uns aux autres. Pour un exemple d'une courte page de tâches, consultez <a href=/fr/docs/tasks/configure-pod-container/configure-volume-storage/>Configurer un pod en utilisant un volume pour le stockage
</a>. Pour un exemple de page de tâches plus longue, voir <a href=/docs/tasks/configure-pod-container/configure-liveness-readiness-probes/>Configure Liveness and Readiness Probes</a></td></tr><tr><td>Tutoriel</td><td>Une page de tutoriel montre comment atteindre un objectif qui relie plusieurs fonctionnalités de Kubernetes. Un tutoriel peut fournir plusieurs séquences d'étapes que les lecteurs peuvent suivre en lisant la page. Ou il peut fournir des explications sur des éléments de code connexes. Par exemple, un tutoriel pourrait fournir un aperçu d'un exemple de code. Un tutoriel peut inclure de brèves explications sur les caractéristiques de Kubernetes qui sont liées entre elles, mais devrait comporter des liens vers des sujets de concepts connexes pour une explication approfondie des caractéristiques individuelles.</td></tr></table><p>Utilisez un modèle pour chaque nouvelle page.
Chaque type de page a un <a href=/docs/contribute/style/page-templates/>template</a> que vous pouvez utiliser lorsque vous écrivez votre sujet.
L'utilisation de templates permet d'assurer la cohérence entre les sujets d'un type donné.</p><h2 id=choisir-un-titre-et-un-nom-de-fichier>Choisir un titre et un nom de fichier</h2><p>Choisissez un titre qui contient les mots-clés que vous voulez que les moteurs de recherche trouvent.
Créez un nom de fichier qui utilise les mots de votre titre séparés par des tirets.
Par exemple, le sujet avec titre <a href=/docs/tasks/access-kubernetes-api/http-proxy-access-api/>Using an HTTP Proxy to Access the Kubernetes API</a> has filename <code>http-proxy-access-api.md</code>.
Vous n'avez pas besoin de mettre "kubernetes" dans le nom du fichier, car "kubernetes" est déjà dans l'URL du sujet, par exemple :</p><pre><code>   /docs/tasks/access-kubernetes-api/http-proxy-access-api/
</code></pre><h2 id=ajout-du-titre-du-sujet-à-l-entête>Ajout du titre du sujet à l'entête</h2><p>Dans votre sujet, insérez un champ <code>title</code> dans l'entête <a href=https://jekyllrb.com/docs/frontmatter/>frontmatter</a>.
L'entête est le bloc YAML qui se trouve entre les lignes à trois tirets en haut de la page.
En voici un exemple :</p><pre><code>---
title: Using an HTTP Proxy to Access the Kubernetes API
---
</code></pre><h2 id=choisir-un-répertoire>Choisir un répertoire</h2><p>En fonction de votre type de page, placez votre nouveau fichier dans un sous-répertoire de l'un d'entre eux :</p><ul><li>/content/en/docs/tasks/</li><li>/content/en/docs/tutorials/</li><li>/content/en/docs/concepts/</li></ul><p>Vous pouvez placer votre fichier dans un sous-répertoire existant ou en créer un nouveau.</p><h2 id=placer-votre-sujet-dans-la-table-des-matières>Placer votre sujet dans la table des matières</h2><p>La table des matières est construite dynamiquement en utilisant la structure de répertoire de la source de documentation.
Les répertoires de niveau supérieur sous <code>/content/fr/docs/</code> créent une navigation de niveau supérieur, et les sous-répertoires ont chacun des entrées dans la table des matières.</p><p>Chaque sous-répertoire possède un fichier <code>_index.md</code>, qui représente la page d'accueil du contenu d'un sous-répertoire donné.
Le <code>_index.md</code> n'a pas besoin d'un template.
Il peut contenir une vue d'ensemble du contenu des rubriques du sous-répertoire.</p><p>Les autres fichiers d'un répertoire sont triés par ordre alphabétique par défaut.
Ce n'est presque jamais le meilleur ordre.
Pour contrôler le tri relatif des sujets dans un sous-répertoire, définissez la clé <code>weight:</code> front-matter sur un entier.
Généralement, nous utilisons des multiples de 10, pour tenir compte de l'ajout de sujets plus tard.
Par exemple, un sujet ayant un poids de <code>10</code> sera précédé d'un sujet ayant un poids de <code>20</code>.</p><h2 id=intégrer-du-code-dans-votre-sujet>Intégrer du code dans votre sujet</h2><p>Si vous voulez inclure du code dans votre sujet, vous pouvez incorporer le code dans votre fichier directement à l'aide de l'option de syntaxe de bloc de code de markdown.
Ceci est recommandé dans les cas suivants (liste non exhaustive) :</p><ul><li>Le code indique la sortie d'une commande telle que <code>kubectl get deploy mydeployment -o json | jq '.status'</code>.</li><li>Le code n'est pas assez générique pour que les utilisateurs puissent l'essayer.
Par exemple, vous pouvez intégrer le fichier YAML pour créer un Pod qui dépend d'une implementation <a href=/docs/concepts/storage/volumes#flexvolume>Flexvolume</a> spécifique.</li><li>Le code est un exemple incomplet parce qu'il a pour but de mettre en évidence une partie d'un fichier plus volumineux.
Par exemple, lorsque vous décrivez des façons de personnaliser l'attribut <a href=/docs/tasks/administer-cluster/sysctl-cluster/#podsecuritypolicy>PodSecurityPolicy</a> pour certaines raisons, vous pouvez fournir un court snippet directement dans le fichier.</li><li>Le code n'est pas destiné à être testé par les utilisateurs pour d'autres raisons.
Par exemple, lorsque vous décrivez comment un nouvel attribut doit être ajouté à une ressource à l'aide de la commande <code>kubectl edit</code>, vous pouvez fournir un court exemple qui inclut seulement l'attribut à ajouter.</li></ul><h2 id=inclure-le-code-d-un-autre-fichier>Inclure le code d'un autre fichier</h2><p>Une autre façon d'inclure du code dans votre sujet est de créer un nouveau fichier d'exemple complet (ou un groupe de fichiers d'exemple), puis de référencer l'exemple de votre sujet.
Utilisez cette méthode pour inclure des exemples de fichiers YAML lorsque l'échantillon est générique et réutilisable, et que vous voulez favoriser leur utilisation.</p><p>Lors de l'ajout d'un nouveau fichier d'exemple autonome, tel qu'un fichier YAML, placez le code dans l'un des sous-répertoires <code>&lt;LANG>/examples/</code> où <code>&lt;LANG></code> est la langue utilisé dans votre page.
Dans votre fichier, utilisez le shortcode <code>codenew</code> :</p><pre>&#123;&#123;&lt; codenew file="&lt;RELPATH&gt;/my-example-yaml&gt;" &gt;&#125;&#125;</pre><p>où <code>&lt;RELPATH></code> est le chemin vers le fichier à inclure, relatif au répertoire <code>examples</code>.
Le shortcode Hugo suivant fait référence à un fichier YAML situé sur <code>/content/en/examples/pods/storage/gce-volume.yaml</code>.</p><pre tabindex=0><code class=language-none data-lang=none>{{&lt; codenew file=&#34;pods/storage/gce-volume.yaml&#34; &gt;}}
</code></pre><div class="alert alert-info note callout" role=alert><strong>Note:</strong> Pour afficher les shortcodes Hugo bruts comme dans l'exemple ci-dessus et empêcher Hugo de les interpréter, utilisez des commentaires de style C directement après les caractères <code>&lt;</code> et avant les caractères <code>></code>.
Voir le code de cette page pour un exemple.</div><h2 id=montrer-comment-créer-un-objet-api-à-partir-d-un-fichier-de-configuration>Montrer comment créer un objet API à partir d'un fichier de configuration</h2><p>Si vous avez besoin de démontrer comment créer un objet API basé sur un fichier de configuration, placez le fichier de configuration dans l'un des sous-répertoires sous <code>&lt;LANG>/examples</code>.</p><p>Dans votre sujet, affichez cette commande :</p><pre tabindex=0><code>kubectl create -f https://k8s.io/examples/pods/storage/gce-volume.yaml
</code></pre><div class="alert alert-info note callout" role=alert><strong>Note:</strong> Lors de l'ajout de nouveaux fichiers YAML dans le répertoire <code>&lt;LANG>/examples</code>, assurez-vous que le fichier est également inclus dans le fichier <code>&lt;LANG>/examples_test.go</code>.
La CI pour le site Web exécute automatiquement ce scénario de test lorsque des PRs sont soumises pour s'assurer que tous les exemples réussissent les tests.</div><p>Pour un exemple d'un sujet qui utilise cette technique, voir <a href=/docs/tutorials/stateful-application/run-stateful-application/>Running a Single-Instance Stateful Application</a>.</p><h2 id=ajouter-des-images-à-un-sujet>Ajouter des images à un sujet</h2><p>Placez les fichiers images dans le répertoire <code>/images</code>.
Le format d'image préféré est SVG.</p><h2 id=a-suivre>A suivre</h2><ul><li>En savoir plus sur <a href=/docs/home/contribute/page-templates/>l'utilisation des templates de pages</a>.</li><li>En savoir plus sur <a href=/docs/home/contribute/stage-documentation-changes/>le staging de vos changements</a>.</li><li>En savoir plus sur <a href=/docs/home/contribute/create-pull-request/>la création d'une pull request</a>.</li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-6d95158118c9a27343edd2e6e23f0247>8.3.3 - Utilisation des modèles de page</h1><p>Lorsque vous ajoutez de nouveaux sujets, appliquez-leur l'un des templates suivants.
Ceci standardise l'expérience utilisateur d'une page donnée.</p><p>Les templates de page sont dans le répertoire <a href=https://git.k8s.io/website/layouts/partials/templates><code>layouts/partials/templates</code></a> du dépôt <a href=https://github.com/kubernetes/website><code>kubernetes/website</code></a>.</p><div class="alert alert-info note callout" role=alert><strong>Note:</strong> Chaque nouveau sujet doit utiliser un modèle.
Si vous n'êtes pas sûr du modèle à utiliser pour un nouveau sujet, commencez par un <a href=#concept-template>template concept</a>.</div><h2 id=concept-template>Concept template</h2><p>Une page de concept explique certains aspects de Kubernetes.
Par exemple, une page conceptuelle peut décrire l'objet Kubernetes <code>Deployment</code> et expliquer le rôle qu'il joue en tant qu'application une fois qu'il est déployé, dimensionné et mis à jour.
Généralement, les pages conceptuelles n'incluent pas de séquences d'étapes, mais fournissent plutôt des liens vers des tâches ou des tutoriels.</p><p>Pour écrire une nouvelle page concept, créez un fichier Markdown dans un sous-répertoire du répertoire <code>/content/fr/docs/concepts</code>, avec les caractéristiques suivantes :</p><ul><li><p>Dans l'entête YAML de la page, définissez <code>content_type: concept</code>.</p></li><li><p>Dans le corps de la page, définissez les variables <code>capture</code> requises et les variables optionnelles que vous voulez inclure :</p><table><thead><tr><th>Variable</th><th>Required?</th></tr></thead><tbody><tr><td>overview</td><td>yes</td></tr><tr><td>body</td><td>yes</td></tr><tr><td>whatsnext</td><td>no</td></tr></tbody></table><p>Le corps de la page ressemblera à ceci (supprimez toutes les captures optionnelles dont vous n'avez pas besoin) :</p><pre tabindex=0><code>{{% capture overview %}}

{{% /capture %}}

{{% capture body %}}

{{% /capture %}}

{{% capture whatsnext %}}

{{% /capture %}}
</code></pre></li><li><p>Remplissez chaque section de contenu. Suivez ces lignes directrices :</p><ul><li>Organiser le contenu avec les rubriques H2 et H3.</li><li>Pour <code>overview</code>, définir le contexte du sujet à l'aide d'un seul paragraphe.</li><li>Pour <code>body</code>, expliquer le concept.</li><li>Pour <code>whatsnext</code>, fournir une liste à puces de sujets (5 au maximum) pour en apprendre davantage sur le concept.</li></ul></li></ul><p><a href=/docs/concepts/overview/working-with-objects/annotations/>Annotations</a> est un exemple publié du template de concept.
Cette page utilise également le modèle de concept.</p><h2 id=template-de-tâche>Template de tâche</h2><p>Une page de tâches montre comment faire une seule chose, généralement en donnant une courte séquence d'étapes.
Les pages de tâches ont une explication minimale, mais fournissent souvent des liens vers des sujets conceptuels qui fournissent un contexte et des connaissances connexes.</p><p>Pour écrire une nouvelle page de tâches, créez un fichier Markdown dans un sous-répertoire du répertoire <code>/content/fr/docs/tasks</code>, avec les caractéristiques suivantes :</p><ul><li><p>Dans l'entête YAML de la page, définissez <code>content_type: task</code>.</p></li><li><p>Dans le corps de la page, définissez les variables <code>capture</code> requises et les variables optionnelles que vous voulez inclure :</p><table><thead><tr><th>Variable</th><th>Required?</th></tr></thead><tbody><tr><td>overview</td><td>yes</td></tr><tr><td>prerequisites</td><td>yes</td></tr><tr><td>steps</td><td>no</td></tr><tr><td>discussion</td><td>no</td></tr><tr><td>whatsnext</td><td>no</td></tr></tbody></table><p>Le corps de la page ressemblera à ceci (supprimez toutes les captures optionnelles dont vous n'avez pas besoin) :</p><pre tabindex=0><code>{{% capture overview %}}

{{% /capture %}}

{{% capture prerequisites %}}

{{&lt; include &#34;task-tutorial-prereqs.md&#34; &gt;}} {{&lt; version-check &gt;}}

{{% /capture %}}

{{% capture steps %}}

{{% /capture %}}

{{% capture discussion %}}

{{% /capture %}}

{{% capture whatsnext %}}

{{% /capture %}}
</code></pre></li><li><p>Dans chaque section, écrivez votre contenu.
Suivez les directives suivantes :</p><ul><li>Utilisez un minimum d'en-têtes H2 (avec deux caractères <code>#</code> en tête de liste).
Les sections elles-mêmes sont intitulées automatiquement par le modèle.</li><li>Pour <code>overview</code>, utilisez un paragraphe pour définir le contexte de l'ensemble du sujet.</li><li>Pour <code>prerequisites</code>, utiliser des listes à puces dans la mesure du possible.
Commencez à ajouter des prérequis supplémentaires sous la balise <code>include</code>.
Les conditions préalables par défaut incluent un cluster Kubernetes en cours d'exécution.</li><li>Pour <code>steps</code>, utiliser des listes numérotées.</li><li>Pour la discussion, utilisez le contenu normal pour développer l'information couverte dans la section <code>steps</code>.</li><li>Pour <code>whatsnext</code>, donnez une liste de 5 sujets au maximum qui peuvent être intéressant à lire ensuite.</li></ul></li></ul><p>Voici un exemple de sujet publié qui utilise le template de tasks <a href=/docs/tasks/access-kubernetes-api/http-proxy-access-api>Using an HTTP proxy to access the Kubernetes API</a>.</p><h2 id=tutorial-template>Tutorial template</h2><p>Une page de tutoriel montre comment atteindre un objectif qui est plus grand qu'une seule tâche.
Typiquement, une page de tutoriel comporte plusieurs sections, chacune d'entre elles ayant une séquence d'étapes.
Par exemple, un tutoriel pourrait fournir un aperçu d'un exemple de code qui illustre une certaine caractéristique de Kubernetes.
Les didacticiels peuvent inclure des explications au niveau de la surface, mais devraient être reliés à des sujets connexes sur les concepts pour des explications approfondies.</p><p>Pour écrire une nouvelle page de tutoriel, créez un fichier Markdown dans un sous-répertoire du répertoire <code>/content/fr/docs/tutorials</code>, avec les caractéristiques suivantes :</p><ul><li><p>Dans l'entête YAML de la page, définissez <code>content_type: tutorial</code>.</p></li><li><p>Dans le corps de la page, définissez les variables <code>capture</code> requises et les variables optionnelles que vous voulez inclure :</p><table><thead><tr><th>Variable</th><th>Required?</th></tr></thead><tbody><tr><td>overview</td><td>yes</td></tr><tr><td>prerequisites</td><td>yes</td></tr><tr><td>objectives</td><td>yes</td></tr><tr><td>lessoncontent</td><td>yes</td></tr><tr><td>cleanup</td><td>no</td></tr><tr><td>whatsnext</td><td>no</td></tr></tbody></table><p>Le corps de la page ressemblera à ceci (supprimez toutes les captures optionnelles dont vous n'avez pas besoin) :</p><pre tabindex=0><code>{{% capture overview %}}

{{% /capture %}}

{{% capture prerequisites %}}

{{&lt; include &#34;task-tutorial-prereqs.md&#34; &gt;}} {{&lt; version-check &gt;}}

{{% /capture %}}

{{% capture objectives %}}

{{% /capture %}}

{{% capture lessoncontent %}}

{{% /capture %}}

{{% capture cleanup %}}

{{% /capture %}}

{{% capture whatsnext %}}

{{% /capture %}}
</code></pre></li><li><p>Dans chaque section, écrivez votre contenu. Suivez les directives suivantes :</p><ul><li>Utilisez un minimum d'en-têtes H2 (avec deux caractères <code>#</code> en tête de liste).
Les sections elles-mêmes sont intitulées automatiquement par le template.</li><li>Pour <code>overview</code>, utiliser un paragraphe pour définir le contexte de l'ensemble du sujet.</li><li>Pour <code>prerequisites</code>, utiliser des listes à puces dans la mesure du possible.
Ajoutez des prérequis supplémentaires en dessous de ceux inclus par défaut.</li><li>Pour <code>objectives</code>, utiliser des listes à puces.</li><li>Pour <code>lessoncontent</code>, utiliser un mélange de listes numérotées et de contenu narratif, le cas échéant.</li><li>Pour <code>cleanup</code>, utiliser des listes numérotées pour décrire les étapes de nettoyage de l'état du cluster une fois la tâche terminée.</li><li>Pour <code>whatsnext</code>, Donnez une liste de 5 sujets au maximum qu'il serait intéressant à lire ensuite.</li></ul></li></ul><p>Voici un exemple de sujet publié qui utilise le modèle de tutoriel <a href=/docs/tutorials/stateless-application/run-stateless-application-deployment/>Running a Stateless Application Using a Deployment</a>.</p><h2 id=a-suivre>A suivre</h2><ul><li>En savoir plus sur le <a href=/docs/contribute/style/style-guide/>style guide</a></li><li>En savoir plus sur l'<a href=/docs/contribute/style/content-organization/>organisation des contenus</a></li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-357f2ddd61035f18c2aa63fe86203f9c>8.3.4 - Organisation du contenu</h1><p>Ce site utilise Hugo.
Dans Hugo, l'<a href=https://gohugo.io/content-management/organization/>organisation du contenu</a> est un concept de base.</p><div class="alert alert-info note callout" role=alert><strong>Note:</strong> <strong>Astuce Hugo:</strong> Démarrez Hugo avec <code>hugo server --navigateToChanged</code> pour les sessions d'édition de contenu.</div><h2 id=listes-de-pages>Listes de pages</h2><h3 id=ordre-des-pages>Ordre des pages</h3><p>Le menu latéral de la documentation, le navigateur de la page de documentation, etc. sont listés selon l'ordre de tri par défaut de Hugo, qui trie par poids (à partir de 1), par date (la plus récente en premier), et enfin par titre du lien.</p><p>Si vous voulez déplacer une page ou une section vers le haut, placez un poids dans l'entête de la page :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>title</span>:<span style=color:#bbb> </span>My Page<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>weight</span>:<span style=color:#bbb> </span><span style=color:#666>10</span><span style=color:#bbb>
</span></span></span></code></pre></div><div class="alert alert-info note callout" role=alert><strong>Note:</strong> Pour les poids de page, il peut être judicieux de ne pas utiliser 1, 2, 3..., mais un autre intervalle, disons 10, 20, 30... Ceci vous permet d'insérer des pages où vous voulez plus tard.</div><h3 id=menu-principal-de-la-documentation>Menu principal de la documentation</h3><p>Le menu principal <code>Documentation</code> est construit à partir des sections ci-dessous <code>docs/</code> avec le drapeau <code>main_menu</code> placé dans l'entête du fichier de contenu de la section `_index.md' :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>main_menu</span>:<span style=color:#bbb> </span><span style=color:#a2f;font-weight:700>true</span><span style=color:#bbb>
</span></span></span></code></pre></div><p>Notez que le titre du lien est récupéré à partir du <code>linkTitle</code> de la page, donc si vous voulez qu'il soit différent du titre, changez-le dans le fichier du contenu cible :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>main_menu</span>:<span style=color:#bbb> </span><span style=color:#a2f;font-weight:700>true</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>title</span>:<span style=color:#bbb> </span>Page Title<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>linkTitle</span>:<span style=color:#bbb> </span>Title used in links<span style=color:#bbb>
</span></span></span></code></pre></div><div class="alert alert-info note callout" role=alert><strong>Note:</strong> Ce qui précède doit être fait par langue.
Si vous ne voyez pas votre section dans le menu, c'est probablement parce qu'elle n'est pas identifiée comme une section par Hugo.
Créez un fichier de contenu <code>_index.md</code> dans le dossier de la section.</div><h3 id=menu-latéral-de-documentation>Menu latéral de documentation</h3><p>Le menu latéral de la barre de documentation est construit à partir de l'arborescence <em>de la section courante</em> commençant sous <code>docs/</code>.</p><p>Il affichera toutes les sections et leurs pages.</p><p>Si vous ne voulez pas lister une section ou une page, mettez l'option <code>toc_hide</code> à <code>true</code> dans l'entête :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>toc_hide</span>:<span style=color:#bbb> </span><span style=color:#a2f;font-weight:700>true</span><span style=color:#bbb>
</span></span></span></code></pre></div><p>Lorsque vous naviguez vers une section contenant du contenu, la section ou la page spécifique (par exemple <code>_index.md</code>) est affichée.
Sinon, la première page à l'intérieur de cette section est affichée.</p><h3 id=navigateur-de-documentation>Navigateur de documentation</h3><p>Le navigateur de page sur la page d'accueil de la documentation est construit en utilisant toutes les sections et pages qui sont directement sous la section <code>docs</code>.</p><p>Si vous ne voulez pas lister une section ou une page, mettez l'option <code>toc_hide</code> à <code>true</code> dans la partie avant :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>toc_hide</span>:<span style=color:#bbb> </span><span style=color:#a2f;font-weight:700>true</span><span style=color:#bbb>
</span></span></span></code></pre></div><h3 id=menu-principal>Menu principal</h3><p>Les liens du site dans le menu en haut à droite -- et aussi dans le pied de page -- sont construits par des recherches de pages.
C'est pour s'assurer que la page existe réellement.
Ainsi, si la section <code>case-studies</code> n'existe pas dans un site (langue), le lien n'apparaitra pas.</p><h2 id=paquets-de-pages>Paquets de pages</h2><p>In addition to standalone content pages (Markdown files), Hugo supports <a href=https://gohugo.io/content-management/page-bundles/>Page Bundles</a>.</p><p>One example is <a href=/docs/contribute/style/hugo-shortcodes/>Custom Hugo Shortcodes</a>.
On considère qu'il s'agit d'un "paquet de feuilles".
Tout ce qui se trouve sous le répertoire, y compris le fichier `index.md', fera partie du paquet.
Cela inclut également les liens relatifs aux pages, les images qui peuvent être traitées, etc :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>en/docs/home/contribute/includes
</span></span><span style=display:flex><span>├── example1.md
</span></span><span style=display:flex><span>├── example2.md
</span></span><span style=display:flex><span>├── index.md
</span></span><span style=display:flex><span>└── podtemplate.json
</span></span></code></pre></div><p>Un autre exemple largement utilisé est celui du paquet <code>includes</code>.
Il définit <code>headless : true</code> dans l'entête, ce qui signifie qu'il n'obtient pas son propre URL.
Il n'est utilisé que dans d'autres pages.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>en/includes
</span></span><span style=display:flex><span>├── default-storage-class-prereqs.md
</span></span><span style=display:flex><span>├── federated-task-tutorial-prereqs.md
</span></span><span style=display:flex><span>├── index.md
</span></span><span style=display:flex><span>├── partner-script.js
</span></span><span style=display:flex><span>├── partner-style.css
</span></span><span style=display:flex><span>├── task-tutorial-prereqs.md
</span></span><span style=display:flex><span>├── user-guide-content-moved.md
</span></span><span style=display:flex><span>└── user-guide-migration-notice.md
</span></span></code></pre></div><p>Quelques notes importantes sur les fichiers dans les paquets :</p><ul><li>Pour les paquets traduits, tous les fichiers non contenus manquants seront hérités des fichiers de langue anglaise.
Cela permet d'éviter les doublons.</li><li>Tous les fichiers d'un bundle sont ce que Hugo appelle <code>Resources</code> et vous pouvez fournir des métadonnées par langue, comme les paramètres et le titre, même s'il ne prend pas en charge les entêtes (fichiers YAML etc.).
Voir <a href=https://gohugo.io/content-management/page-resources/#page-resources-metadata>Page Resources Metadata</a>.</li><li>La valeur que vous obtenez de <code>.RelPermalink</code> d'un <code>Resource</code> est relative à la page.
Voir <a href=https://gohugo.io/content-management/urls/#permalinks>Permalinks</a>.</li></ul><h2 id=styles>Styles</h2><p>La source <code>SASS</code> des feuilles de style pour ce site est stockée sous <code>src/sass</code> et peut être construite avec <code>make sass</code> (notez que Hugo aura bientôt le support <code>SASS</code>, voir <a href=https://github.com/gohugoio/hugo/issues/4243>https://github.com/gohugoio/hugo/issues/4243</a>.</p><h2 id=a-suivre>A suivre</h2><ul><li><a href=/docs/contribute/style/hugo-shortcodes/>Hugo shortcodes personnalisés</a></li><li><a href=/docs/contribute/style/style-guide>Style guide</a></li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-6d76d18115f82583d526bdaf5d05edbc>8.3.5 - Hugo Shortcodes personnalisés</h1><p>Cette page explique les shortcodes Hugo personnalisés pouvant être utilisés dans la documentation de Kubernetes Markdown.</p><p>En savoir plus sur shortcodes dans la <a href=https://gohugo.io/content-management/shortcodes>documentation Hugo</a>.</p><h2 id=etat-de-la-fonctionnalité>Etat de la fonctionnalité</h2><p>Dans une page de Markdown (fichier <code>.md</code>) de ce site, vous pouvez ajouter un code court pour afficher la version et l'état de la fonction documentée.</p><h3 id=feature-state-demo>Feature state demo</h3><p>Ci-dessous se trouve une démo de l'extrait d'état de la fonctionnalité, qui affiche la fonctionnalité comme stable dans Kubernetes version 1.10.</p><pre tabindex=0><code>{{&lt; feature-state for_k8s_version=&#34;v1.10&#34; state=&#34;stable&#34; &gt;}}
</code></pre><p>Rend à :</p><div style=margin-top:10px;margin-bottom:10px><b>FEATURE STATE:</b> <code>Kubernetes v1.10 [stable]</code></div><p>Les valeurs valides pour <code>state</code> sont :</p><ul><li>alpha</li><li>beta</li><li>deprecated</li><li>stable</li></ul><h3 id=feature-state-code>Feature state code</h3><p>La version de Kubernetes affichée par défaut est celle de la page ou du site.
Ceci peut être modifié en passant le paramètre <code>for_k8s_version</code> shortcode.</p><pre tabindex=0><code>{{&lt; feature-state for_k8s_version=&#34;v1.10&#34; state=&#34;stable&#34; &gt;}}
</code></pre><p>Rend à :</p><div style=margin-top:10px;margin-bottom:10px><b>FEATURE STATE:</b> <code>Kubernetes v1.10 [stable]</code></div><h4 id=alpha-feature>Alpha feature</h4><pre tabindex=0><code>{{&lt; feature-state feature-state state=&#34;alpha&#34; &gt;}}
</code></pre><p>Rend à :</p><div style=margin-top:10px;margin-bottom:10px><b>FEATURE STATE:</b> <code>Kubernetes v1.25 [alpha]</code></div><h4 id=beta-feature>Beta feature</h4><pre tabindex=0><code>{{&lt; feature-state feature-state state=&#34;beta&#34; &gt;}}
</code></pre><p>Rend à :</p><div style=margin-top:10px;margin-bottom:10px><b>FEATURE STATE:</b> <code>Kubernetes v1.25 [beta]</code></div><h4 id=stable-feature>Stable feature</h4><pre tabindex=0><code>{{&lt; feature-state feature-state state=&#34;stable&#34; &gt;}}
</code></pre><p>Rend à :</p><div style=margin-top:10px;margin-bottom:10px><b>FEATURE STATE:</b> <code>Kubernetes v1.25 [stable]</code></div><h4 id=deprecated-feature>Deprecated feature</h4><pre tabindex=0><code>{{&lt; feature-state feature-state state=&#34;deprecated&#34; &gt;}}
</code></pre><p>Rend à :</p><div style=margin-top:10px;margin-bottom:10px><b>FEATURE STATE:</b> <code>Kubernetes v1.25 [deprecated]</code></div><h2 id=glossaire>Glossaire</h2><p>Vous pouvez faire référence à des termes du glossaire avec une inclusion qui met à jour et remplace automatiquement le contenu avec les liens pertinents de <a href=/fr/docs/reference/glossary/>notre glossaire</a>.
When the term is moused-over by someone using the online documentation, the glossary entry displays a tooltip.</p><p>The raw data for glossary terms is stored at <a href=https://github.com/kubernetes/website/tree/master/content/en/docs/reference/glossary>https://github.com/kubernetes/website/tree/master/content/en/docs/reference/glossary</a>, with a content file for each glossary term.</p><h3 id=démonstration-du-glossaire>Démonstration du glossaire</h3><p>Par exemple, le snippet suivant est rendu à <a class=glossary-tooltip title='Un ensemble de machines, appelées des "nœuds", qui exécutent des applications conteneurisées gérées par Kubernetes.' data-toggle=tooltip data-placement=top href='/fr/docs/reference/glossary/?all=true#term-cluster' target=_blank aria-label=cluster>cluster</a> avec une infobulle :</p><pre tabindex=0><code class=language-liquid data-lang=liquid>{{&lt; glossary_tooltip text=&#34;cluster&#34; term_id=&#34;cluster&#34; &gt;}}
</code></pre><h2 id=tabs>Tabs</h2><p>Dans une page de démarque (fichier <code>.md</code>) de ce site, vous pouvez ajouter un jeu d'onglets pour afficher plusieurs saveurs d'une solution donnée.</p><p>The <code>tabs</code> shortcode takes these parameters:</p><ul><li><code>name</code>: Le nom tel qu'il apparaît sur l'onglet.</li><li><code>codelang</code>: Si vous fournissez un contenu interne au shortcode <code>tab</code>, vous pouvez indiquer à Hugo quel langage de code utiliser pour activer la coloration syntaxique.</li><li><code>include</code>: Le fichier à inclure dans l'onglet.
Si l'onglet vit dans un Hugo <a href=https://gohugo.io/content-management/page-bundles/#leaf-bundles>leaf bundle</a>, le fichier -- qui peut être n'importe quel type MIME supporté par Hugo -- est recherché dans le bundle lui-même.
Si ce n'est pas le cas, la page de contenu qui doit être incluse est recherchée par rapport à la page en cours.
Notez qu'avec le <code>include</code>, vous n'avez pas de contenu interne de shortcode et devez utiliser la syntaxe de fermeture automatique.
Par exemple, <code>{{&lt; tab name="Content File #1" include="example1" />}}</code>.
La langue doit être spécifiée sous <code>codelang</code> ou la langue est prise en compte en fonction du nom du fichier.
Les fichiers non contenus sont mis en surbrillance par défaut.</li><li>Si votre contenu interne est Markdown, vous devez utiliser le délimiteur <code>%</code> pour entourer l'onglet.
Par exemple, <code>{{% tab name="Tab 1" %}}This is **markdown**{{% /tab %}}</code></li><li>Vous pouvez combiner les variations mentionnées ci-dessus dans un ensemble d'onglets.</li></ul><p>Ci-dessous se trouve une démo du raccourci des onglets.</p><div class="alert alert-info note callout" role=alert><strong>Note:</strong> L'onglet <strong>name</strong> d'une définition <code>tabs</code> doit être unique dans une page de contenu.</div><h3 id=tabs-demo-code-highlighting>Tabs demo: Code highlighting</h3><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-go-text-template data-lang=go-text-template><span style=display:flex><span><span style=color:#080>{{</span><span>&lt;</span><span style=color:#bbb> </span>tabs<span style=color:#bbb> </span>name<span style=color:#666>=</span><span style=color:#b44>&#34;tab_with_code&#34;</span><span style=color:#bbb> </span><span>&gt;</span><span style=color:#080>}}</span>
</span></span><span style=display:flex><span><span style=color:#080>{{</span><span>{&lt;</span><span style=color:#bbb> </span>tab<span style=color:#bbb> </span>name<span style=color:#666>=</span><span style=color:#b44>&#34;Tab 1&#34;</span><span style=color:#bbb> </span>codelang<span style=color:#666>=</span><span style=color:#b44>&#34;bash&#34;</span><span style=color:#bbb> </span><span>&gt;</span><span style=color:#080>}}</span>
</span></span><span style=display:flex><span>echo &#34;This is tab 1.&#34;
</span></span><span style=display:flex><span><span style=color:#080>{{</span><span>&lt;</span><span style=color:#bbb> </span><span>/</span>tab<span style=color:#bbb> </span><span>&gt;</span><span style=color:#080>}}</span>
</span></span><span style=display:flex><span><span style=color:#080>{{</span><span>&lt;</span><span style=color:#bbb> </span>tab<span style=color:#bbb> </span>name<span style=color:#666>=</span><span style=color:#b44>&#34;Tab 2&#34;</span><span style=color:#bbb> </span>codelang<span style=color:#666>=</span><span style=color:#b44>&#34;go&#34;</span><span style=color:#bbb> </span><span>&gt;</span><span style=color:#080>}}</span>
</span></span><span style=display:flex><span>println &#34;This is tab 2.&#34;
</span></span><span style=display:flex><span><span style=color:#080>{{</span><span>&lt;</span><span style=color:#bbb> </span><span>/</span>tab<span style=color:#bbb> </span><span>&gt;</span><span style=color:#080>}}</span>}
</span></span><span style=display:flex><span><span style=color:#080>{{</span><span>&lt;</span><span style=color:#bbb> </span><span>/</span>tabs<span style=color:#bbb> </span><span>&gt;</span><span style=color:#080>}}</span>
</span></span></code></pre></div><p>Rend à:</p><ul class="nav nav-tabs" id=tab-with-code role=tablist><li class=nav-item><a data-toggle=tab class="nav-link active" href=#tab-with-code-0 role=tab aria-controls=tab-with-code-0 aria-selected=true>Tab 1</a></li><li class=nav-item><a data-toggle=tab class=nav-link href=#tab-with-code-1 role=tab aria-controls=tab-with-code-1>Tab 2</a></li></ul><div class=tab-content id=tab-with-code><div id=tab-with-code-0 class="tab-pane show active" role=tabpanel aria-labelledby=tab-with-code-0><p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#a2f>echo</span> <span style=color:#b44>&#34;This is tab 1.&#34;</span>
</span></span></code></pre></div></div><div id=tab-with-code-1 class=tab-pane role=tabpanel aria-labelledby=tab-with-code-1><p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-go data-lang=go><span style=display:flex><span>
</span></span><span style=display:flex><span>println <span style=color:#b44>&#34;This is tab 2.&#34;</span>
</span></span></code></pre></div></div></div><h3 id=tabs-demo-inline-markdown-and-html>Tabs demo: Inline Markdown and HTML</h3><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-go-html-template data-lang=go-html-template><span style=display:flex><span><span style=color:#080>{{</span><span>&lt;</span><span style=color:#bbb> </span>tabs<span style=color:#bbb> </span>name<span style=color:#666>=</span><span style=color:#b44>&#34;tab_with_md&#34;</span><span style=color:#bbb> </span><span>&gt;</span><span style=color:#080>}}</span>
</span></span><span style=display:flex><span><span style=color:#080>{{</span><span>%</span><span style=color:#bbb> </span>tab<span style=color:#bbb> </span>name<span style=color:#666>=</span><span style=color:#b44>&#34;Markdown&#34;</span><span style=color:#bbb> </span><span>%</span><span style=color:#080>}}</span>
</span></span><span style=display:flex><span>This is **some markdown.**
</span></span><span style=display:flex><span><span style=color:#080>{{</span><span>&lt;</span><span style=color:#bbb> </span>note<span style=color:#bbb> </span><span>&gt;</span><span style=color:#080>}}</span>
</span></span><span style=display:flex><span>It can even contain shortcodes.
</span></span><span style=display:flex><span><span style=color:#080>{{</span><span>&lt;</span><span style=color:#bbb> </span><span>/</span>note<span style=color:#bbb> </span><span>&gt;</span><span style=color:#080>}}</span>
</span></span><span style=display:flex><span><span style=color:#080>{{</span><span>%</span><span style=color:#bbb> </span><span>/</span>tab<span style=color:#bbb> </span><span>%</span><span style=color:#080>}}</span>
</span></span><span style=display:flex><span><span style=color:#080>{{</span><span>&lt;</span><span style=color:#bbb> </span>tab<span style=color:#bbb> </span>name<span style=color:#666>=</span><span style=color:#b44>&#34;HTML&#34;</span><span style=color:#bbb> </span><span>&gt;</span><span style=color:#080>}}</span>
</span></span><span style=display:flex><span>&lt;<span style=color:green;font-weight:700>div</span>&gt;
</span></span><span style=display:flex><span>	&lt;<span style=color:green;font-weight:700>h3</span>&gt;Plain HTML&lt;/<span style=color:green;font-weight:700>h3</span>&gt;
</span></span><span style=display:flex><span>	&lt;<span style=color:green;font-weight:700>p</span>&gt;This is some &lt;<span style=color:green;font-weight:700>i</span>&gt;plain&lt;/<span style=color:green;font-weight:700>i</span>&gt; HTML.&lt;/<span style=color:green;font-weight:700>p</span>&gt;
</span></span><span style=display:flex><span>&lt;/<span style=color:green;font-weight:700>div</span>&gt;
</span></span><span style=display:flex><span><span style=color:#080>{{</span><span>&lt;</span><span style=color:#bbb> </span><span>/</span>tab<span style=color:#bbb> </span><span>&gt;</span><span style=color:#080>}}</span>
</span></span><span style=display:flex><span><span style=color:#080>{{</span><span>&lt;</span><span style=color:#bbb> </span><span>/</span>tabs<span style=color:#bbb> </span><span>&gt;</span><span style=color:#080>}}</span>
</span></span></code></pre></div><p>Rend à:</p><ul class="nav nav-tabs" id=tab-with-md role=tablist><li class=nav-item><a data-toggle=tab class="nav-link active" href=#tab-with-md-0 role=tab aria-controls=tab-with-md-0 aria-selected=true>Markdown</a></li><li class=nav-item><a data-toggle=tab class=nav-link href=#tab-with-md-1 role=tab aria-controls=tab-with-md-1>HTML</a></li></ul><div class=tab-content id=tab-with-md><div id=tab-with-md-0 class="tab-pane show active" role=tabpanel aria-labelledby=tab-with-md-0><p><p>This is <strong>some markdown.</strong></p><div class="alert alert-info note callout" role=alert><strong>Note:</strong> Il peut même contenir des shortcodes.</div></div><div id=tab-with-md-1 class=tab-pane role=tabpanel aria-labelledby=tab-with-md-1><p><div><h3>Plain HTML</h3><p>This is some <i>plain</i> HTML.</p></div></div></div><h3 id=tabs-demo-file-include>Tabs demo: File include</h3><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-go-text-template data-lang=go-text-template><span style=display:flex><span><span style=color:#080>{{</span><span>&lt;</span><span style=color:#bbb> </span>tabs<span style=color:#bbb> </span>name<span style=color:#666>=</span><span style=color:#b44>&#34;tab_with_file_include&#34;</span><span style=color:#bbb> </span><span>&gt;</span><span style=color:#080>}}</span>
</span></span><span style=display:flex><span><span style=color:#080>{{</span><span>&lt;</span><span style=color:#bbb> </span>tab<span style=color:#bbb> </span>name<span style=color:#666>=</span><span style=color:#b44>&#34;Content File #1&#34;</span><span style=color:#bbb> </span>include<span style=color:#666>=</span><span style=color:#b44>&#34;example1&#34;</span><span style=color:#bbb> </span><span>/&gt;</span><span style=color:#080>}}</span>
</span></span><span style=display:flex><span><span style=color:#080>{{</span><span>&lt;</span><span style=color:#bbb> </span>tab<span style=color:#bbb> </span>name<span style=color:#666>=</span><span style=color:#b44>&#34;Content File #2&#34;</span><span style=color:#bbb> </span>include<span style=color:#666>=</span><span style=color:#b44>&#34;example2&#34;</span><span style=color:#bbb> </span><span>/&gt;</span><span style=color:#080>}}</span>
</span></span><span style=display:flex><span><span style=color:#080>{{</span><span>&lt;</span><span style=color:#bbb> </span>tab<span style=color:#bbb> </span>name<span style=color:#666>=</span><span style=color:#b44>&#34;JSON File&#34;</span><span style=color:#bbb> </span>include<span style=color:#666>=</span><span style=color:#b44>&#34;podtemplate&#34;</span><span style=color:#bbb> </span><span>/&gt;</span><span style=color:#080>}}</span>
</span></span><span style=display:flex><span><span style=color:#080>{{</span><span>&lt;</span><span style=color:#bbb> </span><span>/</span>tabs<span style=color:#bbb> </span><span>&gt;</span><span style=color:#080>}}</span>
</span></span></code></pre></div><p>Rend à:</p><ul class="nav nav-tabs" id=tab-with-file-include role=tablist><li class=nav-item><a data-toggle=tab class="nav-link active" href=#tab-with-file-include-0 role=tab aria-controls=tab-with-file-include-0 aria-selected=true>Content File #1</a></li><li class=nav-item><a data-toggle=tab class=nav-link href=#tab-with-file-include-1 role=tab aria-controls=tab-with-file-include-1>Content File #2</a></li><li class=nav-item><a data-toggle=tab class=nav-link href=#tab-with-file-include-2 role=tab aria-controls=tab-with-file-include-2>JSON File</a></li></ul><div class=tab-content id=tab-with-file-include><div id=tab-with-file-include-0 class="tab-pane show active" role=tabpanel aria-labelledby=tab-with-file-include-0><p><p>Ceci est un fichier de contenu <strong>exemple</strong> à l'intérieur du paquet de feuilles <strong>includes</strong>.</p><div class="alert alert-info note callout" role=alert><strong>Note:</strong> Les fichiers de contenu inclus peuvent également contenir des codes abrégés.</div></div><div id=tab-with-file-include-1 class=tab-pane role=tabpanel aria-labelledby=tab-with-file-include-1><p><p>Ceci est un autre <strong>exemple</strong> fichier de contenu à l'intérieur du paquet de feuilles <strong>includes</strong>.</p></div><div id=tab-with-file-include-2 class=tab-pane role=tabpanel aria-labelledby=tab-with-file-include-2><p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-json data-lang=json><span style=display:flex><span>{
</span></span><span style=display:flex><span>  <span style=color:green;font-weight:700>&#34;apiVersion&#34;</span>: <span style=color:#b44>&#34;v1&#34;</span>,
</span></span><span style=display:flex><span>  <span style=color:green;font-weight:700>&#34;kind&#34;</span>: <span style=color:#b44>&#34;PodTemplate&#34;</span>,
</span></span><span style=display:flex><span>  <span style=color:green;font-weight:700>&#34;metadata&#34;</span>: {
</span></span><span style=display:flex><span>    <span style=color:green;font-weight:700>&#34;name&#34;</span>: <span style=color:#b44>&#34;nginx&#34;</span>
</span></span><span style=display:flex><span>  },
</span></span><span style=display:flex><span>  <span style=color:green;font-weight:700>&#34;template&#34;</span>: {
</span></span><span style=display:flex><span>    <span style=color:green;font-weight:700>&#34;metadata&#34;</span>: {
</span></span><span style=display:flex><span>      <span style=color:green;font-weight:700>&#34;labels&#34;</span>: {
</span></span><span style=display:flex><span>        <span style=color:green;font-weight:700>&#34;name&#34;</span>: <span style=color:#b44>&#34;nginx&#34;</span>
</span></span><span style=display:flex><span>      },
</span></span><span style=display:flex><span>      <span style=color:green;font-weight:700>&#34;generateName&#34;</span>: <span style=color:#b44>&#34;nginx-&#34;</span>
</span></span><span style=display:flex><span>    },
</span></span><span style=display:flex><span>    <span style=color:green;font-weight:700>&#34;spec&#34;</span>: {
</span></span><span style=display:flex><span>        <span style=color:green;font-weight:700>&#34;containers&#34;</span>: [{
</span></span><span style=display:flex><span>          <span style=color:green;font-weight:700>&#34;name&#34;</span>: <span style=color:#b44>&#34;nginx&#34;</span>,
</span></span><span style=display:flex><span>          <span style=color:green;font-weight:700>&#34;image&#34;</span>: <span style=color:#b44>&#34;dockerfile/nginx&#34;</span>,
</span></span><span style=display:flex><span>          <span style=color:green;font-weight:700>&#34;ports&#34;</span>: [{<span style=color:green;font-weight:700>&#34;containerPort&#34;</span>: <span style=color:#666>80</span>}]
</span></span><span style=display:flex><span>        }]
</span></span><span style=display:flex><span>    }
</span></span><span style=display:flex><span>  }
</span></span><span style=display:flex><span>}
</span></span></code></pre></div></div></div><h2 id=a-suivre>A suivre</h2><ul><li>En savoir plus sur <a href=https://gohugo.io/>Hugo</a>.</li><li>En savoir plus sur <a href=/docs/home/contribute/write-new-topic/>écrire un nouveau sujet</a>.</li><li>En savoir plus sur <a href=/docs/home/contribute/page-templates/>l'utilisation des page templates</a>.</li><li>En savoir plus sur <a href=/docs/home/contribute/stage-documentation-changes/>staging your changes</a></li><li>En savoir plus sur <a href=/docs/home/contribute/create-pull-request/>créer une pull request</a>.</li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-29765496ca296ad24e34e5c0cd42a63f>8.4 - Vue d'ensemble des documents de référence</h1><div class=lead>Documentation références Kubernetes</div><p>Une grande partie de la documentation de référence de Kubernetes est générée à partir du code source de Kubernetes, à l'aide de scripts.
Les rubriques de cette section expliquent comment générer ce type de contenu.</p></div><div class=td-content><h1 id=pg-6e4e78f20e40bac9bcad59941e974af6>8.4.1 - Génération de documentation de référence pour l'API Kubernetes</h1><div class=lead>Génération documentation référence API Kubernetes</div><p>Cette page montre comment mettre à jour les documents de référence générés automatiquement pour l'API Kubernetes.</p><h2 id=pré-requis>Pré-requis</h2><p>Vous devez avoir ces outils installés:</p><ul><li><a href=https://git-scm.com/book/en/v2/Getting-Started-Installing-Git>Git</a></li><li><a href=https://golang.org/doc/install>Golang</a> version 1.9.1 ou ultérieur</li><li><a href=https://docs.docker.com/engine/installation/>Docker</a></li><li><a href=https://github.com/coreos/etcd/>etcd</a></li></ul><p>Votre variable d'environnement $GOPATH doit être définie et l'emplacement de <code>etcd</code> doit être dans votre variable d'environnement $PATH.</p><p>Vous devez savoir comment créer une pull request dans un dépôt GitHub.
Généralement, cela implique la création d'un fork du dépôt.
Pour plus d'informations, voir <a href=/docs/home/contribute/create-pull-request/>Créer une Pull Request de documentation</a> et <a href=https://gist.github.com/Chaser324/ce0505fbed06b947d962>GitHub Standard Fork & Pull Request Workflow</a>.</p><h2 id=généralités>Généralités</h2><p>La mise à jour de la documentation de référence de l'API Kubernetes est un processus en deux étapes:</p><ol><li><p>Générez une spécification OpenAPI à partir du code source de Kubernetes.
Les outils pour cette étape sont <a href=https://github.com/kubernetes/kubernetes/tree/master/hack>kubernetes/kubernetes/hack</a>.</p></li><li><p>Générez un fichier HTML à partir de la spécification OpenAPI.
Les outils pour cette étape sont à <a href=https://github.com/kubernetes-incubator/reference-docs>kubernetes-incubator/reference-docs</a>.</p></li></ol><h2 id=obtenir-trois-dépôts>Obtenir trois dépôts</h2><p>Si vous ne possédez pas déjà le dépôt <code>kubernetes/kubernetes</code>, téléchargez-le maintenant:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>mkdir <span style=color:#b8860b>$GOPATH</span>/src
</span></span><span style=display:flex><span><span style=color:#a2f>cd</span> <span style=color:#b8860b>$GOPATH</span>/src
</span></span><span style=display:flex><span>go get github.com/kubernetes/kubernetes
</span></span></code></pre></div><p>Déterminez le dépôt de base de votre clone de <a href=https://github.com/kubernetes/kubernetes>kubernetes/kubernetes</a>.
Par exemple, si vous avez suivi l’étape précédente pour obtenir le dépôt, votre dépôt de base est <code>$GOPATH/src/github.com/kubernetes/kubernetes</code>.
Les étapes restantes se réfèrent à votre répertoire de base en tant que <code>&lt;k8s-base></code>.</p><p>Si vous ne possédez pas déjà le dépôt <code>kubernetes/website</code>, obtenez-le maintenant:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>mkdir <span style=color:#b8860b>$GOPATH</span>/src
</span></span><span style=display:flex><span><span style=color:#a2f>cd</span> <span style=color:#b8860b>$GOPATH</span>/src
</span></span><span style=display:flex><span>go get github.com/kubernetes/website
</span></span></code></pre></div><p>Déterminez le répertoire de base de votre dépôt <a href=https://github.com/kubernetes/website>kubernetes/website</a>.
Par exemple, si vous avez suivi l’étape précédente pour obtenir le dépôt, votre répertoire de base est <code>$GOPATH/src/github.com/kubernetes/website</code>.
Les étapes restantes se réfèrent à votre répertoire de base en tant que <code>&lt;web-base></code>.</p><p>Si vous n'avez pas déjà le dépôt <code>kubernetes-incubator/reference-docs</code>, obtenez-le maintenant:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>mkdir <span style=color:#b8860b>$GOPATH</span>/src
</span></span><span style=display:flex><span><span style=color:#a2f>cd</span> <span style=color:#b8860b>$GOPATH</span>/src
</span></span><span style=display:flex><span>go get github.com/kubernetes-incubator/reference-docs
</span></span></code></pre></div><p>Déterminez le répertoire de base de votre dépôt <a href=https://github.com/kubernetes-incubator/reference-docs>kubernetes-incubator/reference-docs</a>.
Par exemple, si vous avez suivi l’étape précédente pour obtenir le dépôt, votre répertoire de base est <code>$GOPATH/src/github.com/kubernetes-incubator/reference-docs</code>.
Les étapes restantes se réfèrent à votre répertoire de base en tant que <code>&lt;rdocs-base></code>.</p><h2 id=modification-du-code-source-de-kubernetes>Modification du code source de Kubernetes</h2><p>La documentation de référence de l'API Kubernetes est générée automatiquement à partir d'une spécification OpenAPI, générée à partir du code source de Kubernetes.
Si vous souhaitez modifier la documentation de référence, la première étape consiste à modifier un ou plusieurs commentaires dans le code source de Kubernetes.</p><h3 id=modification-des-commentaires-dans-le-code-source>Modification des commentaires dans le code source</h3><div class="alert alert-info note callout" role=alert><strong>Note:</strong> Les étapes suivantes sont un exemple et non une procédure générale.
Les détails seront différents dans votre situation.</div><p>Voici un exemple d'édition d'un commentaire dans le code source de Kubernetes.</p><p>Dans votre dépôt local <code>kubernetes/kubernetes</code>, vérifiez la branche master et assurez-vous qu'elle est à jour:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span><span style=color:#a2f>cd</span> &lt;k8s-base&gt;
</span></span><span style=display:flex><span>git checkout master
</span></span><span style=display:flex><span>git pull https://github.com/kubernetes/kubernetes master
</span></span></code></pre></div><p>Supposons que ce fichier source dans la branche principale ait la typo "atmost":</p><p><a href=https://github.com/kubernetes/kubernetes/blob/master/staging/src/k8s.io/api/apps/v1/types.go>kubernetes/kubernetes/staging/src/k8s.io/api/apps/v1/types.go</a></p><p>Dans votre environnement local, ouvrez <code>types.go</code> et remplacez "atmost" par "at most".</p><p>Vérifiez que vous avez modifié le fichier:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>git status
</span></span></code></pre></div><p>La sortie montre que vous êtes sur la branche master et que le fichier source <code>types.go</code> a été modifié:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>On branch master
</span></span><span style=display:flex><span>...
</span></span><span style=display:flex><span>    modified:   staging/src/k8s.io/api/apps/v1/types.go
</span></span></code></pre></div><h3 id=valider-votre-fichier-édité>Valider votre fichier édité</h3><p>Exécutez <code>git add</code> et <code>git commit</code> pour valider les modifications que vous avez apportées jusqu'à présent.
Dans l'étape suivante, vous ferez un deuxième commit.
Il est important de séparer vos modifications en deux commits.</p><h3 id=génération-de-la-spécification-openapi-et-des-fichiers-associés>Génération de la spécification OpenAPI et des fichiers associés</h3><p>Allez sur <code>&lt;k8s-base></code> et exécutez ces scripts:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>hack/update-generated-swagger-docs.sh
</span></span><span style=display:flex><span>hack/update-swagger-spec.sh
</span></span><span style=display:flex><span>hack/update-openapi-spec.sh
</span></span><span style=display:flex><span>hack/update-generated-protobuf.sh
</span></span></code></pre></div><p>Exécutez <code>git status</code> pour voir ce qui a été généré.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>On branch master
</span></span><span style=display:flex><span>...
</span></span><span style=display:flex><span>    modified:   api/openapi-spec/swagger.json
</span></span><span style=display:flex><span>    modified:   staging/src/k8s.io/api/apps/v1/generated.proto
</span></span><span style=display:flex><span>    modified:   staging/src/k8s.io/api/apps/v1/types.go
</span></span><span style=display:flex><span>    modified:   staging/src/k8s.io/api/apps/v1/types_swagger_doc_generated.go
</span></span></code></pre></div><p>Voir le contenu de <code>api/openapi-spec/swagger.json</code> pour vous assurer que la faute de frappe est corrigée.
Par exemple, vous pouvez exécuter <code>git diff -a api/openapi-spec/swagger.json</code>.
Ceci est important, car <code>swagger.json</code> sera l’entrée de la seconde étape du processus de génération de doc.</p><p>Exécutez <code>git add</code> et <code>git commit</code> pour valider vos modifications.
Vous avez maintenant deux validations: une avec le fichier <code>types.go</code> édité et une avec les spécifications OpenAPI générées et les fichiers associés.
Gardez ces deux commits séparés.
C'est-à-dire, ne faites pas un squash de vos commits.</p><p>Soumettez vos modifications en tant que <a href=https://help.github.com/articles/creating-a-pull-request/>pull request</a> à la branche principale du dépôt <a href=https://github.com/kubernetes/kubernetes>kubernetes/kubernetes</a>.
Surveillez votre pull request, et répondre aux commentaires des relecteurs au besoin.
Continuez à surveiller votre pull request jusqu'à ce qu'il ait été mergé.</p><p><a href=https://github.com/kubernetes/kubernetes/pull/57758>PR 57758</a> est un exemple de demande d'extraction qui corrige une faute de frappe dans le code source de Kubernetes.</p><div class="alert alert-info note callout" role=alert><strong>Note:</strong> Il peut être difficile de déterminer le fichier source correct à modifier.
Dans l'exemple précédent, le fichier source faisant autorité se trouve dans le répertoire <code>staging</code> du dépôt <code>kubernetes/kubernetes</code>.
Mais dans votre cas, le répertoire <code>staging</code> pourrait ne pas être l’endroit où trouver la source faisant autorité.
Pour vous guider, consultez les fichiers <code>README</code> dans le dépôt <a href=https://github.com/kubernetes/kubernetes/tree/master/staging>kubernetes/kubernetes</a> et dans le dépôt <a href=https://github.com/kubernetes/apiserver/blob/master/README.md>kubernetes/apiserver</a>.</div><h3 id=cherry-picking-votre-commit-dans-une-branche-release>Cherry picking votre commit dans une branche release</h3><p>Dans la section précédente, vous avez modifié un fichier dans la branche principale, puis exécuté des scripts pour générer une spécification OpenAPI et les fichiers associés.
Vous avez ensuite soumis vos modifications dans une demande d'extraction à la branche maître du dépôt <code>kubernetes/kubernetes</code>.
Supposons maintenant que vous souhaitiez faire un backport de votre modification dans une branche de publication.
Par exemple, supposons que la branche principale soit utilisée pour développer Kubernetes version 1.10 et que vous souhaitiez faire un backport de votre modification dans la branche de la version 1.9.</p><p>Rappelez-vous que votre pull request a deux commits: un pour l'édition <code>types.go</code> et un pour les fichiers générés par des scripts.
La prochaine étape consiste à proposer un cherry pick de votre premier commit dans la branche release-1.9.
L'idée est de cherry pick le commit qui a édité <code>types.go</code>, mais pas le commit qui a pour résultat l'exécution des scripts.
Pour les instructions, voir <a href=https://git.k8s.io/community/contributors/devel/sig-release/cherry-picks.md>Proposer un Cherry Pick</a>.</p><div class="alert alert-info note callout" role=alert><strong>Note:</strong> Proposer un cherry pick nécessite que vous ayez la permission de définir un label et un milestone dans votre pull request.
Si vous ne disposez pas de ces autorisations, vous devrez travailler avec une personne pouvant définir les labels et milestones pour vous.</div><p>Quand vous avez une pull request en place pour cherry picking votre seul commit dans la branche release-1.9, l’étape suivante consiste à exécuter ces scripts dans la branche release-1.9 de votre environnement local.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>hack/update-generated-swagger-docs.sh
</span></span><span style=display:flex><span>hack/update-swagger-spec.sh
</span></span><span style=display:flex><span>hack/update-openapi-spec.sh
</span></span><span style=display:flex><span>hack/update-generated-protobuf.sh
</span></span><span style=display:flex><span>hack/update-api-reference-docs.sh
</span></span></code></pre></div><p>Maintenant, ajoutez un commit à votre cherry-pick pull request qui contient la spécification OpenAPI récemment générée et les fichiers associés.
Surveillez votre pull request jusqu'à ce qu'elle soit mergée dans la branche release-1.9.</p><p>À ce stade, la branche master et la branche release-1.9 ont votre fichier <code>types.go</code> mis à jour et un ensemble de fichiers générés qui reflètent les modifications apportées à <code>types.go</code>.
Notez que la spécification OpenAPI générée et les autres fichiers générés dans la branche release-1.9 ne sont pas nécessairement identiques aux fichiers générés dans la branche master.
Les fichiers générés dans la branche release-1.9 contiennent des éléments API uniquement à partir de Kubernetes 1.9.
Les fichiers générés dans la branche maître peuvent contenir des éléments de l'API qui ne sont pas dans la version 1.9, mais sont en cours de développement pour la version 1.10.</p><h2 id=génération-des-documents-de-référence-publiés>Génération des documents de référence publiés</h2><p>La section précédente a montré comment modifier un fichier source, puis générer plusieurs fichiers, y compris <code>api/openapi-spec/swagger.json</code> dans le dépôt <code>kubernetes/kubernetes</code>.</p><p>Cette section montre comment générer la <a href=/docs/reference/generated/kubernetes-api/v1.25/>documentation de référence de l'API Kubernetes publiée</a>, qui est générée par les outils de <a href=https://github.com/kubernetes-incubator/reference-docs>kubernetes-incubator/reference-docs</a>.
Ces outils prennent le fichier <code>api/openapi-spec/swagger.json</code> comme entrée.</p><h3 id=modification-du-makefile-dans-kubernetes-incubator-reference-docs>Modification du Makefile dans kubernetes-incubator/reference-docs</h3><p>Aller à <code>&lt;rdocs-base></code>, et ouvrez <code>Makefile</code> pour l'édition:</p><p>Définissez <code>K8SROOT</code> dans le répertoire de base de votre dépôt local <code>kubernetes/kubernetes</code>.
Définissez <code>WEBROOT</code> sur le répertoire de base de votre référentiel <code>kubernetes/website</code>.
Définissez <code>MINOR_VERSION</code> sur la version mineure de la documentation que vous souhaitez créer.
Par exemple, si vous souhaitez créer des documents pour Kubernetes 1.9, définissez <code>MINOR_VERSION</code> sur 9.
Enregistrez et fermez <code>Makefile</code>.</p><h3 id=copier-la-spécification-openapi>Copier la spécification OpenAPI</h3><p>Le code de génération de document nécessite une copie locale de la spécification OpenAPI pour l'API Kubernetes.
Allez sur <code>&lt;k8s-base></code> et vérifiez la branche qui a la spécification OpenAPI que vous voulez utiliser.
Par exemple, si vous souhaitez générer des documents pour Kubernetes 1.9, consultez la branche release-1.9.</p><p>Retournez à <code>&lt;rdocs-base></code>.
Entrez la commande suivante pour copier la spécification OpenAPI à partir du dépôt <code>kubernetes/kubernetes</code> vers un répertoire local:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>make updateapispec
</span></span></code></pre></div><p>La sortie montre que le fichier a été copié:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>cp ~/src/github.com/kubernetes/kubernetes/api/openapi-spec/swagger.json gen-apidocs/generators/openapi-spec/swagger.json
</span></span></code></pre></div><h3 id=construire-l-image-brodocs>Construire l'image brodocs</h3><p>Le code de génération de doc nécessite l'image Docker <a href=https://github.com/pwittrock/brodocs>pwittrock/brodocs</a>.</p><p>Cette commande crée l’image Docker <code>pwittrock/brodocs</code>.
Il essaie également de transmettre l’image à DockerHub, mais c’est acceptable si cette étape échoue.
Tant que vous avez l'image localement, la génération de code peut réussir.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>make brodocs
</span></span></code></pre></div><p>Vérifiez que vous avez l'image brodocs:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>docker images
</span></span></code></pre></div><p>La sortie affiche <code>pwittrock / brodocs</code> comme l'une des images disponibles:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>REPOSITORY          TAG                 IMAGE ID            CREATED             SIZE
</span></span><span style=display:flex><span>pwittrock/brodocs   latest              999d34a50d56        <span style=color:#666>5</span> weeks ago         714MB
</span></span></code></pre></div><h3 id=exécuter-le-code-de-génération-de-doc>Exécuter le code de génération de doc</h3><p>Générez et exécutez le code de génération de doc.
Vous devrez peut-être exécuter la commande en tant que root:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span><span style=color:#a2f>cd</span> &lt;rdocs-base&gt;
</span></span><span style=display:flex><span>make api
</span></span></code></pre></div><h3 id=localiser-les-fichiers-générés>Localiser les fichiers générés</h3><p>Ces deux fichiers sont le résultat d’une construction réussie.
Vérifiez qu'ils existent:</p><ul><li><code>&lt;rdocs-base>/gen-apidocs/generators/build/index.html</code></li><li><code>&lt;rdocs-base>/gen-apidocs/generators/build/navData.js</code></li></ul><h2 id=copier-les-documents-générés-dans-le-dépôt-kubernetes-website>Copier les documents générés dans le dépôt kubernetes/website</h2><p>Les sections précédentes ont montré comment modifier un fichier source Kubernetes, générer une spécification OpenAPI, puis générer une documentation de référence pour la publication.</p><p>Cette section explique comment copier les documents générés sur le dépôt <a href=https://github.com/kubernetes/website>kubernetes/website</a>.
Les fichiers dans le dépôt <code>kubernetes/website</code> sont publiés sur le site web <a href=https://kubernetes.io>kubernetes.io</a>.
En particulier, le fichier généré <code>index.html</code> est publié <a href=/docs/reference/generated/kubernetes-api/v1.25/>ici</a>.</p><p>Entrez la commande suivante pour copier les fichiers générés dans votre dépôt local <code>kubernetes/website</code>:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>make copyapi
</span></span></code></pre></div><p>Allez à la base de votre dépôt local <code>kubernetes/kubernetes</code>, et regardez quels fichiers ont été modifiés:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span><span style=color:#a2f>cd</span> &lt;web-base&gt;
</span></span><span style=display:flex><span>git status
</span></span></code></pre></div><p>La sortie montre les fichiers modifiés:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>On branch master
</span></span><span style=display:flex><span>...
</span></span><span style=display:flex><span>   modified:   docs/reference/generated/kubernetes-api/v1.9/index.html
</span></span></code></pre></div><p>Dans cet exemple, un seul fichier a été modifié.
Rappelez-vous que vous avez généré les deux <code>index.html</code> et <code>navData.js</code>.
Mais apparemment le généré <code>navata.js</code> n'est pas différent du <code>navData.js</code> c'était déjà dans le dépôt <code>kubernetes/website</code>.</p><p>Dans <code>&lt;web-base></code> executez <code>git add</code> et <code>git commit</code> pour enregistrer le commit du changement.</p><p>Soumettez vos modifications en tant que <a href=/docs/home/contribute/create-pull-request/>pull request</a> au dépôt <a href=https://github.com/kubernetes/website>kubernetes/website</a>.
Surveillez votre pull request, et répondez aux commentaires des relecteurs au besoin.
Continuez à surveiller votre pull request jusqu'à ce qu'elle ait été mergée.</p><p>Quelques minutes après que votre pull request soit fusionnée, vos modifications seront visibles dans la <a href=/docs/reference/generated/kubernetes-api/v1.25/>documentation de référence publiée</a>.</p><h2 id=a-suivre>A suivre</h2><ul><li><a href=/docs/home/contribute/generated-reference/kubernetes-components/>Génération de documents de référence pour les composants et les outils Kubernetes</a></li><li><a href=/docs/home/contribute/generated-reference/kubectl/>Génération de documentation de référence pour les commandes kubectl</a></li><li><a href=/docs/home/contribute/generated-reference/federation-api/>Génération de documentation de référence pour l'API de fédération Kubernetes</a></li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-cb2951ff9bcf2a10d6658325c7a502c5>8.4.2 - Génération de la documentation de référence pour l'API de fédération Kubernetes</h1><div class=lead>Federation Référence API Kubernetes Documentation</div><p>Cette page montre comment générer automatiquement des pages de référence pour l'API de fédération Kubernetes.</p><h2 id=pré-requis>Pré-requis</h2><ul><li><p>Vous devez avoir <a href=https://git-scm.com/book/fr/v2/D%C3%A9marrage-rapide-Installation-de-Git>Git</a> installé.</p></li><li><p>Vous devez avoir <a href=https://golang.org/doc/install>Golang</a> version 1.9.1 ou ultérieur installé, et votre variable d'environnement <code>$GOPATH</code> doit être définie.</p></li><li><p>Vous devez avoir <a href=https://docs.docker.com/engine/installation/>Docker</a> installé.</p></li><li><p>Vous devez savoir comment créer une pull request sur un dépôt GitHub.
Généralement, cela implique la création d'un fork du dépôt.
Pour plus d'informations, voir <a href=/docs/home/contribute/create-pull-request/>Création d'une pull request de documentation</a>.</p></li></ul><h2 id=exécution-du-script-update-federation-api-docs-sh>Exécution du script update-federation-api-docs.sh</h2><p>Si vous ne possédez pas déjà le code source de la fédération Kubernetes, procurez-vous-le maintenant:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>mkdir <span style=color:#b8860b>$GOPATH</span>/src
</span></span><span style=display:flex><span><span style=color:#a2f>cd</span> <span style=color:#b8860b>$GOPATH</span>/src
</span></span><span style=display:flex><span>go get github.com/kubernetes/federation
</span></span></code></pre></div><p>Déterminez le répertoire de base de votre dépôt local <a href=https://github.com/kubernetes/federation>kubernetes/federation</a>.
Par exemple, si vous avez suivi l'étape précédente pour obtenir le code source de la fédération, votre répertoire de base est <code>$GOPATH/src/github.com/kubernetes/federation</code>.
Les étapes restantes se réfèrent à votre répertoire de base en tant que <code>&lt;fed-base></code>.</p><p>Exécutez le script de génération de documentation:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span><span style=color:#a2f>cd</span> &lt;fed-base&gt;
</span></span><span style=display:flex><span>hack/update-federation-api-reference-docs.sh
</span></span></code></pre></div><p>Le script exécute le <a href="https://console.cloud.google.com/gcr/images/google-containers/GLOBAL/gen-swagger-docs?gcrImageListquery=%255B%255D&gcrImageListpage=%257B%2522t%2522%253A%2522%2522%252C%2522i%2522%253A0%257D&gcrImageListsize=50&gcrImageListsort=%255B%257B%2522p%2522%253A%2522uploaded%2522%252C%2522s%2522%253Afalse%257D%255D">k8s.gcr.io/gen-swagger-docs</a> image pour générer cet ensemble de documents de référence:</p><ul><li>/docs/api-reference/extensions/v1beta1/operations.html</li><li>/docs/api-reference/extensions/v1beta1/definitions.html</li><li>/docs/api-reference/v1/operations.html</li><li>/docs/api-reference/v1/definitions.html</li></ul><p>Les fichiers générés ne sont pas publiés automatiquement.
Ils doivent être copiés manuellement sur dépôt <a href=https://github.com/kubernetes/website/tree/master/content/en/docs/reference/generated>kubernetes/website</a>.</p><p>Ces fichiers sont publiés à <a href=/docs/reference/>kubernetes.io/docs/reference</a>:</p><ul><li><a href=/docs/reference/federation/v1/operations/>Federation API v1 Operations</a></li><li><a href=/docs/reference/federation/v1/definitions/>Federation API v1 Definitions</a></li><li><a href=/docs/reference/federation/extensions/v1beta1/operations/>Federation API extensions/v1beta1 Operations</a></li><li><a href=/docs/reference/federation/extensions/v1beta1/definitions/>Federation API extensions/v1beta1 Definitions</a></li></ul><h2 id=a-suivre>A suivre</h2><ul><li><a href=/docs/home/contribute/generated-reference/kubernetes-api/>Génération de documentation de référence pour l'API Kubernetes</a></li><li><a href=/docs/home/contribute/generated-reference/kubectl/>Génération de documentation de référence pour les commandes kubectl</a></li><li><a href=/docs/home/contribute/generated-reference/kubernetes-components/>Génération de pages de référence pour les composants et les outils Kubernetes</a></li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-28fc50a0072b0b2b444aa24e552d2e60>8.4.3 - Génération de pages de référence pour les composants et les outils Kubernetes</h1><p>Cette page montre comment utiliser l'outil <code>update-importer-docs</code> pour générer une documentation de référence pour les outils et les composants des dépôts <a href=https://github.com/kubernetes/kubernetes>Kubernetes</a> et <a href=https://github.com/kubernetes/federation>Federation</a>.</p><h2 id=pré-requis>Pré-requis</h2><ul><li><p>Vous avez besoin d'une machine qui exécute Linux ou macOS.</p></li><li><p>Ces logiciels doivent être installés:</p><ul><li><p><a href=https://git-scm.com/book/en/v2/Getting-Started-Installing-Git>Git</a></p></li><li><p><a href=https://golang.org/doc/install>Golang</a> version 1.13 ou ultérieure</p></li><li><p><a href=https://www.gnu.org/software/make/>make</a></p></li><li><p><a href=https://gcc.gnu.org/>gcc compiler/linker</a></p></li></ul></li><li><p>Votre variable d'environnement <code>$GOPATH</code> doit être définie.</p></li><li><p>Vous devez savoir comment créer une pull request sur un dépôt GitHub.
Cela implique généralement la création d’un fork d'un dépôt.
Pour plus d'informations, consultez <a href=/docs/home/contribute/create-pull-request/>Créer une Pull Request de documentation</a>.</p></li></ul><h2 id=obtenir-deux-dépôts>Obtenir deux dépôts</h2><p>Si vous n'avez pas déjà le dépôt <code>kubernetes/website</code>, obtenez le maintenant:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>mkdir <span style=color:#b8860b>$GOPATH</span>/src
</span></span><span style=display:flex><span><span style=color:#a2f>cd</span> <span style=color:#b8860b>$GOPATH</span>/src
</span></span><span style=display:flex><span>go get github.com/kubernetes/website
</span></span></code></pre></div><p>Déterminez le répertoire de base de votre clone du dépôt <a href=https://github.com/kubernetes/website>kubernetes/website</a>.
Par exemple, si vous avez suivi l’étape précédente pour obtenir le dépôt, votre répertoire de base est <code>$GOPATH/src/github.com/kubernetes/website</code>.
Les étapes restantes se réfèrent à votre répertoire de base en tant que <code>&lt;web-base></code>.</p><p>Si vous envisagez d’apporter des modifications aux documents de référence et si vous ne disposez pas déjà du dépôt <code>kubernetes/kubernetes</code>, obtenez-le maintenant:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>mkdir <span style=color:#b8860b>$GOPATH</span>/src
</span></span><span style=display:flex><span><span style=color:#a2f>cd</span> <span style=color:#b8860b>$GOPATH</span>/src
</span></span><span style=display:flex><span>go get github.com/kubernetes/kubernetes
</span></span></code></pre></div><p>Déterminez le répertoire de base de votre clone du dépôt <a href=https://github.com/kubernetes/kubernetes>kubernetes/kubernetes</a>.
Par exemple, si vous avez suivi l’étape précédente pour obtenir le dépôt, votre répertoire de base est <code>$GOPATH/src/github.com/kubernetes/kubernetes</code>.
Les étapes restantes se réfèrent à votre répertoire de base en tant que <code>&lt;k8s-base></code>.</p><div class="alert alert-info note callout" role=alert><strong>Note:</strong> Si vous devez uniquement générer, sans modifier, les documents de référence, vous n'avez pas besoin d'obtenir manuellement le dépôt <code>kubernetes/kubernetes</code>.
Lorsque vous exécutez la commande <code>update-imported-docs</code>, il clone automatiquement le dépôt <code>kubernetes/kubernetes</code>.</div><h2 id=modification-du-code-source-de-kubernetes>Modification du code source de Kubernetes</h2><p>La documentation de référence pour les composants et les outils Kubernetes est générée automatiquement à partir du code source de Kubernetes.
Si vous souhaitez modifier la documentation de référence, commencez par modifier un ou plusieurs commentaires dans le code source de Kubernetes.
Faites le changement dans votre dépôt local <code>kubernetes/kubernetes</code>, puis soumettez une pull request sur la branche master <a href=https://github.com/kubernetes/kubernetes>github.com/kubernetes/kubernetes</a>.</p><p><a href=https://github.com/kubernetes/kubernetes/pull/56942>PR 56942</a> est un exemple de pull request qui modifie les commentaires dans le code source de Kubernetes.</p><p>Surveillez votre pull request, et répondez aux commentaires des relecteurs.
Continuez à surveiller votre pull request jusqu'à ce qu'elle soit mergée dans la branche master du dépot <code>kubernetes/kubernetes</code>.</p><h2 id=selectionnez-vos-commits-dans-une-branche-release>Selectionnez vos commits dans une branche release</h2><p>Vos commits sont sur la branche master, qui est utilisée pour le développement sur la prochaine sortie de Kubernetes.
Si vous souhaitez que vos commits apparaissent dans la documentation d'une version Kubernetes déjà publiée, vous devez proposer que vos commits soit sélectionnée dans la branche de publication.</p><p>Par exemple, supposons que la branche master est utilisée pour développer Kubernetes 1.10, et vous voulez transférer vos commits sur la branche release-1.9.
Pour savoir comment faire cela, consultez <a href=https://github.com/kubernetes/community/blob/master/contributors/devel/sig-release/cherry-picks.md>Propose a Cherry Pick</a>.</p><p>Surveillez votre pull request cherry-pick jusqu'à ce qu'elle soit mergée dans la branche release.</p><div class="alert alert-info note callout" role=alert><strong>Note:</strong> Proposer un cherry pick exige que vous ayez la permission de définir un label et un milestone dans votre pull request.
Si vous ne disposez pas de ces autorisations, vous devrez travailler avec une personne pouvant définir les paramètres de labels et de milestone pour vous.</div><h2 id=vue-générale-de-update-imported-docs>Vue générale de update-imported-docs</h2><p>L'outil <code>update-importer-docs</code> se trouve dans le répertoire <code>kubernetes/website/update-importer-docs/</code>.
L'outil effectue les étapes suivantes:</p><ol><li>Effectuez un clone des différents dépots spéciés dans le fichier de configuration.
Afin de générer des documents de référence, les dépôts clonés par défaut sont: <code>kubernetes-incubator/reference-docs</code> et <code>kubernetes/federation</code>.</li><li>Effectuez les commandes dans les dépôts clonés pour préparer le générateur de documentation et génerer les fichiers Markdown.</li><li>Copiez les fichiers markdown générés dans un copie locale du dépôt <code>kubernetes/website</code>. Les fichiers doivent être mis dans les dossiers spécifiés dans le fichier de configuration.</li></ol><p>Quand les fichiers Markdown sont dans votre clone local du dépot <code>kubernetes/website</code>, vous pouvez les soumettre dans une <a href=/docs/home/contribute/create-pull-request/>pull request</a> vers <code>kubernetes/website</code>.</p><h2 id=personnaliser-le-fichier-de-configuration>Personnaliser le fichier de configuration</h2><p>Ouvrez <code>&lt;web-base>/update-importer-docs/reference.yml</code> pour le modifier.
Ne modifiez pas le contenu de l'entrée <code>generate-command</code> sauf si vous comprenez ce qu'elle fait et devez modifier la branche de release spécifiée.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>repos:
</span></span><span style=display:flex><span>- name: reference-docs
</span></span><span style=display:flex><span>  remote: https://github.com/kubernetes-incubator/reference-docs.git
</span></span><span style=display:flex><span>  <span style=color:#080;font-style:italic># Ceci et la commande generate ci-dessous nécessitent une modification lorsque les branches de référence-docs sont correctement définies</span>
</span></span><span style=display:flex><span>  branch: master
</span></span><span style=display:flex><span>  generate-command: |
</span></span><span style=display:flex><span>    <span style=color:#a2f>cd</span> <span style=color:#b8860b>$GOPATH</span>
</span></span><span style=display:flex><span>    git clone https://github.com/kubernetes/kubernetes.git src/k8s.io/kubernetes
</span></span><span style=display:flex><span>    <span style=color:#a2f>cd</span> src/k8s.io/kubernetes
</span></span><span style=display:flex><span>    git checkout release-1.11
</span></span><span style=display:flex><span>    make generated_files
</span></span><span style=display:flex><span>    cp -L -R vendor <span style=color:#b8860b>$GOPATH</span>/src
</span></span><span style=display:flex><span>    rm -r vendor
</span></span><span style=display:flex><span>    <span style=color:#a2f>cd</span> <span style=color:#b8860b>$GOPATH</span>
</span></span><span style=display:flex><span>    go get -v github.com/kubernetes-incubator/reference-docs/gen-compdocs
</span></span><span style=display:flex><span>    <span style=color:#a2f>cd</span> src/github.com/kubernetes-incubator/reference-docs/
</span></span><span style=display:flex><span>    make comp
</span></span></code></pre></div><p>Dans reference.yml, les attributs <code>files</code> est une liste d'objets ayant des attributs <code>src</code> et <code>dst</code>.
L'attribut <code>src</code> spécifie l'emplacement d'un fichier Markdown généré, et l'attribut <code>dst</code> spécifie où copier ce fichier dans le dépôt local <code>kubernetes/website</code>.
Par exemple:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>repos</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>reference-docs<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>remote</span>:<span style=color:#bbb> </span>https://github.com/kubernetes-incubator/reference-docs.git<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>files</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>src</span>:<span style=color:#bbb> </span>gen-compdocs/build/kube-apiserver.md<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>dst</span>:<span style=color:#bbb> </span>content/en/docs/reference/command-line-tools-reference/kube-apiserver.md<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>...<span style=color:#bbb>
</span></span></span></code></pre></div><p>Notez que lorsqu'il y a beaucoup de fichiers à copier du même répertoire source dans le même répertoire de destination, vous pouvez utiliser des caractères génériques dans la valeur donnée à <code>src</code> et vous pouvez simplement fournir le nom du répertoire comme valeur pour <code>dst</code>.
Par exemple:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>  files:
</span></span><span style=display:flex><span>  - src: gen-compdocs/build/kubeadm*.md
</span></span><span style=display:flex><span>    dst: content/en/docs/reference/setup-tools/kubeadm/generated/
</span></span></code></pre></div><h2 id=exécution-de-l-outil-update-importer-docs>Exécution de l'outil update-importer-docs</h2><p>Après avoir revu et/ou personnalisé le fichier <code>reference.yaml</code>, vous pouvez exécuter l'outil <code>update-imports-docs</code>:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span><span style=color:#a2f>cd</span> &lt;web-base&gt;/update-imported-docs
</span></span><span style=display:flex><span>./update-imported-docs reference.yml
</span></span></code></pre></div><h2 id=ajouter-et-valider-des-modifications-dans-kubernetes-website>Ajouter et valider des modifications dans kubernetes/website</h2><p>Répertoriez les fichiers générés et copiés dans le dépôt <code>kubernetes/website</code>:</p><pre tabindex=0><code>cd &lt;web-base&gt;
git status
</code></pre><p>La sortie affiche les fichiers nouveaux et modifiés.
Par exemple, la sortie pourrait ressembler à ceci:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>...
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    modified:   content/en/docs/reference/command-line-tools-reference/cloud-controller-manager.md
</span></span><span style=display:flex><span>    modified:   content/en/docs/reference/command-line-tools-reference/federation-apiserver.md
</span></span><span style=display:flex><span>    modified:   content/en/docs/reference/command-line-tools-reference/federation-controller-manager.md
</span></span><span style=display:flex><span>    modified:   content/en/docs/reference/command-line-tools-reference/kube-apiserver.md
</span></span><span style=display:flex><span>    modified:   content/en/docs/reference/command-line-tools-reference/kube-controller-manager.md
</span></span><span style=display:flex><span>    modified:   content/en/docs/reference/command-line-tools-reference/kube-proxy.md
</span></span><span style=display:flex><span>    modified:   content/en/docs/reference/command-line-tools-reference/kube-scheduler.md
</span></span><span style=display:flex><span>...
</span></span></code></pre></div><p>Exécutez <code>git add</code> et <code>git commit</code> pour faire un commit de ces fichiers.</p><h2 id=créer-une-pull-request>Créer une pull request</h2><p>Créez une pull request vers le dépôt <code>kubernetes/website</code>.
Consultez votre pull request et répondez aux corrections suggérées par les rélecteurs jusqu'à ce que la pull request soit acceptée et mergée.</p><p>Quelques minutes après le merge votre pull request, vos références mises à jour seront visibles dans la <a href=/docs/home/>documentation publiée</a>.</p><h2 id=a-suivre>A suivre</h2><ul><li><a href=/docs/home/contribute/generated-reference/kubectl/>Génération de documentation de référence pour les commandes kubectl</a></li><li><a href=/fr/docs/contribute/generate-ref-docs/kubernetes-api/>Génération de documentation de référence pour l'API Kubernetes</a></li><li><a href=/docs/home/contribute/generated-reference/federation-api/>Génération de documentation de référence pour l'API de fédération Kubernetes</a></li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-e1098d3fca853af3d9dd514e4309cbba>8.5 - Participez au SIG Docs</h1><p>SIG Docs est l'un des <a href=https://github.com/kubernetes/community/blob/master/sig-list.md>groupes d'intérêts spéciaux</a> au sein du projet Kubernetes, axé sur la rédaction, la mise à jour et la maintenance de la documentation de Kubernetes dans son ensemble.
Pour plus d'informations sur le SIG consultez <a href=https://github.com/kubernetes/community/tree/master/sig-docs>le dépôt GitHub de la communauté</a>.</p><p>SIG Docs accueille le contenu et les critiques de tous les contributeurs.
Tout le monde peut ouvrir une pull request (PR), et tout le monde est invité à déposer des questions sur le contenu ou à commenter les pull requests ouvertes.</p><p>Dans SIG Docs, vous pouvez aussi devenir un <a href=#membres>membre</a>, <a href=#reviewers>relecteur</a>, ou <a href=#approvers>approbateur</a>.
Ces rôles nécessitent un plus grand accès et impliquent certaines responsabilités pour approuver et valider les changements.
Voir <a href=https://github.com/kubernetes/community/blob/master/community-membership.md>appartenance à la communauté</a> pour plus d'informations sur le fonctionnement de l'adhésion au sein de la communauté Kubernetes.
Le reste de ce document décrit certaines fonctions uniques de ces rôles au sein du SIG Docs, responsable de la gestion de l’un des aspects les plus accessibles du public de Kubernetes: le site Web et la documentation de Kubernetes.</p><h2 id=rôles-et-responsabilités>Rôles et responsabilités</h2><p>Lorsqu'une pull request est mergée à la branche utilisée pour publier le contenu (actuellement <code>master</code>), ce contenu est publié et disponible dans le monde entier.
Pour nous assurer que la qualité de notre contenu publié est élevée, nous limitons aux approbateurs SIG Docs le droit de merger des pull requests.
Voici comment ce processus fonctionne.</p><ul><li>Lorsqu'une pull request a les deux labels <code>lgtm</code> et <code>approve</code> et n'a pas de label <code>hold</code>, la pull request est mergée automatiquement.</li><li>Les membres de l'organisation Kubernetes et les approbateurs SIG Docs peuvent ajouter des commentaires à une pull request ou empêcher le merge automatique d'une pull request donnée (en ajoutant un commentaire <code>/hold</code> ou en retirant un commentaire <code>/lgtm</code>).</li><li>Tout membre de Kubernetes peut ajouter le label <code>lgtm</code>, en ajoutant un commentaire <code>/lgtm</code>.</li><li>Seul un approbateur membre de SIG Docs peut causer le merge d'une pull request en ajoutant un commentaire <code>/approve</code>.
Certains approbateurs remplissent également des rôles spécifiques supplémentaires, tels que <a href=#pr-wrangler>PR Wrangler</a> or <a href=#sig-docs-chairperson>président(e) du SIG Docs</a>.</li></ul><p>Pour plus d'informations sur les attentes et les différences entre les rôles de membre de l'organisation Kubernetes et d'approbateurs SIG Docs, voir <a href=/docs/contribute#types-of-contributor>Types de contributeur</a>.
Les sections suivantes couvrent plus de détails sur ces rôles et leur fonctionnement dans SIG-Docs.</p><h3 id=n-importe-qui>N'importe qui</h3><p>Tout le monde peut ouvrir un ticket sur n'importe quelle partie de Kubernetes, y compris la documentation.</p><p>Toute personne ayant signé le CLA peut ouvrir une Pull Request.
Si vous ne pouvez pas signer le CLA, le projet Kubernetes ne peut pas accepter votre contribution.</p><h3 id=membres>Membres</h3><p>Tout membre de l'<a href=https://github.com/kubernetes>organisation Kubernetes</a> peut faire une revue d'une pull request, et les membres de l’équipe SIG Docs demandent fréquemment aux membres d’autres SIG d'effectuer des révisions de documents pour des raisons de précision technique.
SIG Docs accueille également des critiques et des commentaires indépendamment du statut de membre d'une personne dans l'organisation Kubernetes.
Vous pouvez indiquer votre approbation en ajoutant un commentaire de <code>/lgtm</code> à une pull request.
Si vous n'êtes pas membre de l'organisation Kubernetes, votre <code>/lgtm</code> n'a aucun effet sur les systèmes automatisés.</p><p>Tout membre de l’organisation Kubernetes peut ajouter un commentaire <code>/ hold</code> pour empêcher la pull request d'être mergée.
Tout membre peut également supprimer un commentaire <code>/hold</code> pour merger une PR s'il a déjà les deux commentaires <code>/lgtm</code> et <code>/approve</code> appliqué par les personnes appropriées.</p><h4 id=devenir-membre>Devenir membre</h4><p>Après avoir soumis avec succès au moins 5 pull requests significatives, vous pouvez demander l'<a href=https://github.com/kubernetes/community/blob/master/community-membership.md#member>adhésion</a> dans l'organisation Kubernetes.
Suivez ces étapes:</p><ol><li><p>Trouvez deux relecteurs ou approbateurs pour <a href=/docs/contribute/advanced#sponsor-a-new-contributor>parrainer</a> votre adhésion.</p><p>Demander un parrainage dans le <a href=https://kubernetes.slack.com>canal #sig-docs sur l'instance de Kubernetes Slack</a> ou sur la <a href=https://groups.google.com/forum/#!forum/kubernetes-sig-docs>mailing list SIG Docs</a>.</p><div class="alert alert-info note callout" role=alert><strong>Note:</strong> N'envoyez pas de courrier électronique direct ou de message direct Slack à un membre individuel de SIG Docs.</div></li><li><p>Ouvrez un ticket Github dans le dépôt <code>kubernetes/org</code> pour adhérer à l'organisation.
Remplissez le modèle en suivant les directives de l'<a href=https://github.com/kubernetes/community/blob/master/community-membership.md>Adhésion à la communauté</a>.</p></li><li><p>Informez vos sponsors du ticket Github, soit en les mentionnant dans le ticket Github (en ajoutant un commentaire avec <code>@&lt;Github-username></code>) ou en leur envoyant directement le lien, afin qu’ils puissent ajouter un vote <code>+ 1</code>.</p></li><li><p>Lorsque votre adhésion est approuvée, le membre de l'équipe d'administration github affecté à votre demande met à jour le ticket Github pour indiquer son approbation, puis ferme le ticket Github.
Félicitations, vous êtes maintenant membre!</p></li></ol><p>Si, pour une raison quelconque, votre demande d'adhésion n'est pas acceptée immédiatement, le comité des membres fournit des informations ou des mesures à prendre avant de présenter une nouvelle demande.</p><h3 id=relecteurs>Relecteurs</h3><p>Les relecteurs sont membres du groupe Github <a href=https://github.com/orgs/kubernetes/teams/sig-docs-pr-reviews>@kubernetes/sig-docs-pr-reviews</a>.
Voir <a href=#teams-and-groups-within-sig-docs>Equipes et groupes au sein de SIG Docs</a>.</p><p>Les relecteurs examinent les Pull Request de documentation et font des commentaires sur les changements proposés.</p><p>L'automatisation assigne des relecteurs aux pull requests, et les contributeurs peuvent demander une revue d'un relecteur spécifique en laissant un commentaire tel que: <code>/assign [@_github_handle]</code>.
Pour indiquer qu'une pull request est techniquement exacte et ne nécessite aucune modification supplémentaire, un examinateur ajoute un commentaire <code>/lgtm</code> à la Pull Request.</p><p>Si le relecteur affecté n'a pas encore revu le contenu, un autre relecteur peut intervenir.
En outre, vous pouvez affecter des relecteurs techniques et attendre qu'ils fournissent des <code>/lgtm</code>.</p><p>Pour un changement trivial ou ne nécessitant aucun examen technique, l'<a href=#approvers>approbateur</a> SIG Docs peut fournir le <code>/lgtm</code> aussi.</p><p>Un commentaire <code>/approve</code> d'un relecteur est ignoré par l'automatisation.</p><p>Pour en savoir plus sur comment devenir un relecteur SIG Docs et sur les responsabilités et l’engagement de temps que cela implique, voir <a href=#becoming-an-approver-or-reviewer>Devenir relecteur ou approbateur</a>.</p><h4 id=devenir-relecteur>Devenir relecteur</h4><p>Lorsque vous remplissez les <a href=https://github.com/kubernetes/community/blob/master/community-membership.md#reviewer>conditions requises</a>, vous pouvez devenir un relecteur SIG Docs.
Les relecteurs d'autres SIG doivent demander séparément le statut de relecteur dans le SIG Docs.</p><p>Pour postuler, ouvrez une pull request et ajoutez vous à la section <code>reviewers</code> du fichier <a href=https://github.com/kubernetes/website/blob/main/OWNERS>top-level OWNERS</a> dans le dépôt <code>kubernetes/website</code>.
Affectez la PR à un ou plusieurs approbateurs SIG Docs.</p><p>Si votre pull request est approuvée, vous êtes maintenant un relecteur SIG Docs.
<a href=https://github.com/kubernetes/test-infra/tree/master/prow#bots-home>K8s-ci-robot</a> vous assignera et vous suggérera en tant que relecteur pour les nouvelles Pull Requests.</p><p>Si vous êtes approuvé, demandez qu’un approbateur SIG Docs en cours vous ajoute au groupe Github <a href=https://github.com/orgs/kubernetes/teams/sig-docs-pr-reviews>@kubernetes/sig-docs-pr-reviews</a>.
Seuls les membres du groupe Github <code>kubernetes-website-admins</code> peuvent ajouter de nouveaux membres à un groupe Github.</p><h3 id=approbateurs>Approbateurs</h3><p>Les approbateurs sont membres du groupe Github <a href=https://github.com/orgs/kubernetes/teams/sig-docs-maintainers>@kubernetes/sig-docs-maintainers</a>.
Voir <a href=#teams-and-groups-within-sig-docs>Equipes et groupes au sein de SIG Docs</a>.</p><p>Les approbateurs ont la capacité de merger une PR, et ainsi, publier du contenu sur le site Web de Kubernetes.
Pour approuver une PR, un approbateur laisse un commentaire <code>/approve</code> sur la PR.
Si quelqu'un qui n'est pas un approbateur laisse le commentaire d'approbation, l'automatisation l'ignore.</p><p>Si la PR a déjà un <code>/lgtm</code>, ou si l'approbateur fait également des commentaires avec <code>/lgtm</code>, la PR est mergée automatiquement.
Un approbateur SIG Docs ne doit laisser qu'un <code>/lgtm</code> sur un changement qui ne nécessite pas de relecture supplémentaire.</p><p>Pour en savoir plus sur comment devenir un approbateur SIG Docs et sur les responsabilités et l’engagement de temps que cela implique, voir <a href=#becoming-an-approver-or-reviewer>Devenir relecteur ou approbateur</a>.</p><h4 id=devenir-approbateur>Devenir approbateur</h4><p>Lorsque vous remplissez les <a href=https://github.com/kubernetes/community/blob/master/community-membership.md#approver>conditions requises</a>, vous pouvez devenir un approbateur SIG Docs.
Les approbateurs appartenant à d'autres SIG doivent demander séparément le statut d'approbateur dans SIG Docs.</p><p>Pour postuler, ouvrez une pull request pour vous ajouter à la section <code>approvers</code> du fichier <a href=https://github.com/kubernetes/website/blob/main/OWNERS>top-level OWNERS</a> dans le dépot <code>kubernetes/website</code>.
Affectez la PR à un ou plusieurs approbateurs SIG Docs.</p><p>Si votre Pull Request est approuvée, vous êtes à présent approbateur SIG Docs.
Le <a href=https://github.com/kubernetes/test-infra/tree/master/prow#bots-home>K8s-ci-robot</a> vous assignera et vous suggérera en tant que relecteur pour les nouvelles Pull Requests.</p><p>Si vous êtes approuvé, demandez qu’un approbateur SIG Docs en cours vous ajoute au groupe Github <a href=https://github.com/orgs/kubernetes/teams/sig-docs-maintainers>@kubernetes/sig-docs-maintainers</a>.
Seuls les membres du groupe Github <code>kubernetes-website-admins</code> peuvent ajouter de nouveaux membres à un groupe Github.</p><h4 id=devenir-un-administrateur-de-site-web>Devenir un administrateur de site Web</h4><p>Les membres du groupe GitHub <code>kubernetes-website-admins</code> peuvent gérer l’appartenance au groupe Github et disposer de tous les droits administratifs sur les paramètres du dépôt, y compris la possibilité d'ajouter, de supprimer et de debugger des Webhooks.
Tous les approbateurs SIG Docs n'ont pas besoin de ce niveau d'accès.</p><p>Si vous pensez avoir besoin de ce niveau d’accès, adressez-vous à un administrateur de site Web existant ou posez la question dans le canal Slack <a href=https://kubernetes.slack.com/messages/C1J0BPD2M/>#sig-docs</a>.</p><h4 id=auxiliaires-de-traitement-des-pull-requests>Auxiliaires de traitement des Pull Requests</h4><p>Les approbateurs SIG Docs sont ajoutés au <a href=https://github.com/kubernetes/website/wiki/PR-Wranglers>calendrier de rotations des auxiliaires de traitement des PullRequests</a> pour les rotations hebdomadaires.
Tous les approbateurs SIG Docs devraient participer à cette rotation.
Voir <a href=/docs/contribute/advanced#be-the-pr-wrangler-for-a-week>Soyez l'auxiliaire des PR pendant une semaine</a> pour plus de détails.</p><h4 id=présidence-du-sig-docs>Présidence du SIG Docs</h4><p>Chaque SIG, y compris SIG Docs, sélectionne un ou plusieurs membres du SIG qui assumeront les fonctions de président(e).
Ce sont des points de contact entre SIG Docs et d’autres parties de l’organisation Kubernetes.
Ils nécessitent une connaissance approfondie de la structure du projet Kubernetes dans son ensemble et du fonctionnement de SIG Docs au sein de celui-ci.
Voir <a href=https://github.com/kubernetes/community/tree/master/sig-docs#leadership>Direction</a> pour la liste actuelle des président(e)s.</p><h2 id=equipes-sig-docs-et-automatisation>Equipes SIG Docs et automatisation</h2><p>L'automatisation dans SIG Docs repose sur deux mécanismes différents:
Groupes Github et fichiers OWNERS.</p><h3 id=groupes-github>Groupes Github</h3><p>Le groupe SIG Docs définit deux équipes sur Github:</p><ul><li><a href=https://github.com/orgs/kubernetes/teams/sig-docs-maintainers>@kubernetes/sig-docs-maintainers</a></li><li><a href=https://github.com/orgs/kubernetes/teams/sig-docs-pr-reviews>@kubernetes/sig-docs-pr-reviews</a></li></ul><p>Chacun peut être référencé avec son <code>@name</code> dans Github, commentez pour communiquer avec tous les membres de ce groupe.</p><p>Ces équipes peuvent avoir des membres en commun.
Pour l'affectation des tickets, des pull requests, et aider la validation des PR, l'automatisation utilise les informations des fichiers OWNERS.</p><h3 id=owners-files-et-front-matter>OWNERS files et front-matter</h3><p>Le projet Kubernetes utilise un outil d'automatisation appelé prow pour l'automatisation liée aux Github issues et aux pull requests.
Le <a href=https://github.com/kubernetes/website>dépôt du site web Kubernetes</a> utilise deux <a href=https://github.com/kubernetes/test-infra/tree/master/prow/plugins>plugins prow</a>:</p><ul><li>blunderbuss</li><li>approve</li></ul><p>Ces deux plugins utilisent les fichiers <a href=https://github.com/kubernetes/website/blob/main/OWNERS>OWNERS</a> et <a href=https://github.com/kubernetes/website/blob/main/OWNERS_ALIASES>OWNERS_ALIASES</a> à la racine du dépôt Github <code>kubernetes/website</code> pour contrôler comment prow fonctionne.</p><p>Un fichier <a href=https://github.com/kubernetes/website/blob/main/OWNERS>OWNERS</a> contient une liste de personnes qui sont des relecteurs et des approbateurs SIG Docs.
Les fichiers OWNERS existent aussi dans les sous-dossiers, et peuvent ignorer qui peut agir en tant que relecteur ou approbateur des fichiers de ce sous-répertoire et de ses descendants.
Pour plus d'informations sur les fichiers OWNERS en général, voir <a href=https://github.com/kubernetes/community/blob/master/contributors/guide/owners.md>OWNERS</a>.</p><p>En outre, un fichier Markdown individuel peut répertorier les relecteurs et les approbateurs dans l'entête, soit en répertoriant les noms d’utilisateur ou les groupes de Github.</p><p>La combinaison des fichiers <code>OWNERS</code> et des entêtes dans les fichiers Markdown déterminent les suggestions automatiques de relecteurs dans la PullRequest.</p><h2 id=a-suivre>A suivre</h2><p>Pour plus d'informations sur la contribution à la documentation Kubernetes, voir:</p><ul><li><a href=/docs/contribute/start/>Commencez à contribuer</a></li><li><a href=/docs/contribute/style/>Documentation style</a></li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-849a2fdb87779db1c212fe5a9f88ff0d>8.6 - Traduction de la documentation Kubernetes</h1><p>La documentation de Kubernetes est disponible dans plusieurs langues.
Nous vous encourageons à ajouter de nouvelles <a href=https://blog.mozilla.org/l10n/2011/12/14/i18n-vs-l10n-whats-the-diff/>traductions</a>!</p><h2 id=commencer>Commencer</h2><p>Les traductions doivent avoir certains pré-requis pour le workflow (<em>comment</em> traduire) et la sortie (<em>quoi</em> traduire) avant de publier.</p><p>Pour ajouter une nouvelle localisation de la documentation de Kubernetes, vous devrez mettre à jour le site web en modifiant le paramètre <a href=#modify-the-site-configuration>site configuration</a> et <a href=#add-a-new-localization-directory>directory structure</a>. Alors vous pouvez commencer la <a href=#translating-documents>traduction de documents</a>!</p><div class="alert alert-info note callout" role=alert><strong>Note:</strong> Pour un exemple lié à la localisation <a href=../create-pull-request>pull request</a>, consultez <a href=https://github.com/kubernetes/website/pull/8636>cette pull request</a> vers le <a href=https://github.com/kubernetes/website>dépôt Kubernetes website</a> et concernant l'ajout de la localisation coréenne à la documentation de Kubernetes.</div><p>Indiquez à Kubernetes SIG Docs que vous souhaitez créer une traduction!
Rejoignez le canal Slack <a href=https://kubernetes.slack.com/messages/C1J0BPD2M/>SIG Docs</a>.
Nous sommes heureux de vous aider à démarrer et à répondre à toutes vos questions.</p><p>Toutes les équipes de traduction doivent être autonomes avec leurs propres ressources.
Nous sommes heureux d'accueillir votre travail, mais nous ne pouvons pas le traduire pour vous.</p><h3 id=fork-et-cloner-le-dépôt>Fork et cloner le dépôt</h3><p>D'abord, <a href=https://help.github.com/articles/fork-a-repo/>créez votre fork</a> du dépôt <a href=https://github.com/kubernetes/website>kubernetes/website</a>.</p><p>Ensuite, clonez ce dépôt et mettez vous dedans (avec une commande <code>cd</code>):</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>git clone https://github.com/kubernetes/website
</span></span><span style=display:flex><span><span style=color:#a2f>cd</span> website
</span></span></code></pre></div><div class="alert alert-info note callout" role=alert><strong>Note:</strong><p>Les contributeurs de <code>k/website</code> doivent <a href=/docs/contribute/start/#improve-existing-content>créer un fork</a> à partir duquel les pull requests seront ouvertes.
Pour les localisations, nous demandons en outre que :</p><ol><li>Les approbateurs d'équipe ouvrent des branches de développement directement à partir de <a href=https://github.com/kubernetes/website>https://github.com/kubernetes/website</a>.</li><li>Les contributeurs à la localisation travaillent à partir de forks, avec des branches basées sur la branche de développement actuelle.</li></ol><p>Cela s'explique par le fait que les projets de localisation sont des efforts de collaboration sur des branches à long terme, similaires aux branches de développement pour le cycle de release de Kubernetes.
Pour plus d'informations sur les pull request de localisation, voir <a href=#branching-strategy>"branching strategy"</a>.</p></div><h3 id=trouvez-votre-code-de-langue-à-deux-lettres>Trouvez votre code de langue à deux lettres</h3><p>Consultez la <a href=https://www.loc.gov/standards/iso639-2/php/code_list.php>norme ISO 639-1</a> pour le code de pays en deux lettres de votre localisation.
Par exemple, le code à deux lettres pour l'allemand est <code>de</code>.</p><div class="alert alert-info note callout" role=alert><strong>Note:</strong> These instructions use the <a href=https://www.loc.gov/standards/iso639-2/php/code_list.php>ISO 639-1</a> language code for German (<code>de</code>) as an example.</div><h3 id=modifier-la-configuration-du-site>Modifier la configuration du site</h3><p>Le site web de Kubernetes utilise Hugo comme son web framework.
La configuration Hugo du site Web se trouve dans le fichier <a href=https://github.com/kubernetes/website/tree/master/config.toml><code>config.toml</code></a>.
Pour prendre en charge une nouvelle localisation, vous devrez modifier <code>config.toml</code>.</p><p>Ajoutez un bloc de configuration pour la nouvelle langue dans <code>config.toml</code>, sous le bloc <code>[languages]</code> existant.
Le bloc allemand, par exemple, ressemble à :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-toml data-lang=toml><span style=display:flex><span>[languages.de]
</span></span><span style=display:flex><span>title = <span style=color:#b44>&#34;Kubernetes&#34;</span>
</span></span><span style=display:flex><span>description = <span style=color:#b44>&#34;Produktionsreife Container-Verwaltung&#34;</span>
</span></span><span style=display:flex><span>languageName = <span style=color:#b44>&#34;Deutsch&#34;</span>
</span></span><span style=display:flex><span>contentDir = <span style=color:#b44>&#34;content/de&#34;</span>
</span></span><span style=display:flex><span>weight = <span style=color:#666>3</span>
</span></span></code></pre></div><p>Lors de l'attribution d'un paramètre de <code>weight</code> à votre bloc, trouvez le bloc de langue ayant le <code>weight</code> le plus élevé et ajoutez 1 à cette valeur.</p><p>Pour plus d'informations sur le support multilingue de Hugo, voir "<a href=https://gohugo.io/content-management/multilingual/>Multilingual Mode</a>".</p><h3 id=ajouter-un-nouveau-répertoire-de-localisation>Ajouter un nouveau répertoire de localisation</h3><p>Ajoutez un sous-répertoire spécifique à la langue dans le répertoire <a href=https://github.com/kubernetes/website/tree/master/content><code>content</code></a> du dépôt.
Par exemple, le code à deux lettres pour l'allemand est "de" :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>mkdir content/de
</span></span></code></pre></div><h3 id=ajouter-un-readme-localisé>Ajouter un README localisé</h3><p>Pour guider les autres contributeurs à la localisation, ajoutez un nouveau <a href=https://help.github.com/articles/about-readmes/><code>README-**.md</code></a> au plus haut niveau de k/website, où <code>**</code> est le code de langue à deux lettres.
Par exemple, un fichier README allemand serait <code>README-de.md</code>.</p><p>Fournir des conseils aux contributeurs à la localisation dans le fichier localisé <code>README-**.md</code>.
Incluez les mêmes informations que celles contenues dans <code>README.md</code>ainsi que :</p><ul><li>Un point de contact pour le projet de localisation</li><li>Toute information spécifique à la localisation</li></ul><p>Après avoir créé le fichier README localisé, ajoutez un lien vers le fichier à partir du fichier anglais principal, [<code>README.md</code>'s Localizing Kubernetes Documentation] et incluez les coordonnées des personnes-ressources en anglais.
Vous pouvez fournir un identifiant GitHub, une adresse e-mail, <a href=https://slack.com/>Slack channel</a>, ou toute autre méthode de contact.</p><h2 id=translating-documents>Translating documents</h2><p>Localiser <em>toute</em> la documentation de Kubernetes est une tâche énorme.
Il n'y a pas de mal à commencer petit et progresser avec le temps.</p><p>Au minimum, toutes les localisations doivent inclure :</p><table><thead><tr><th>Description</th><th>URLs</th></tr></thead><tbody><tr><td>Home</td><td><a href=/docs/home/>All heading and subheading URLs</a></td></tr><tr><td>Setup</td><td><a href=/docs/setup/>All heading and subheading URLs</a></td></tr><tr><td>Tutorials</td><td><a href=/docs/tutorials/kubernetes-basics/>Kubernetes Basics</a>, <a href=/docs/tutorials/stateless-application/hello-minikube/>Hello Minikube</a></td></tr><tr><td>Site strings</td><td><a href=https://github.com/kubernetes/website/tree/master/i18n>All site strings in a new localized TOML file</a></td></tr></tbody></table><p>Les documents traduits doivent résider dans leur propre sous-répertoire <code>content/**/</code>, mais sinon suivre le même chemin URL que la source anglaise.
Par exemple, pour préparer le tutoriel <a href=/docs/tutorials/kubernetes-basics/>Kubernetes Basics</a> à traduire en allemand, créez un sous-dossier sous le dossier `content/de/' et copiez la source anglaise :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>mkdir -p content/de/docs/tutorials
</span></span><span style=display:flex><span>cp content/en/docs/tutorials/kubernetes-basics.md content/de/docs/tutorials/kubernetes-basics.md
</span></span></code></pre></div><p>Pour un exemple de demande liée à la localisation <a href=.../create-pull-request>pull request</a>, <a href=https://github.com/kubernetes/website/pull/10471>this pull request</a> au <a href=https://github.com/kubernetes/website>Kubernetes website repo</a> a ajouté la localisation coréenne aux documents Kubernetes.</p><h3 id=fichiers-sources>Fichiers sources</h3><p>Les localisations doivent utiliser les fichiers anglais de la version la plus récente comme source.
La version la plus récente est <strong>v1.25</strong>.</p><p>Pour trouver les fichiers sources de la version la plus récente :</p><ol><li>Accédez au dépôt du site web de Kubernetes à l'adresse suivante <a href=https://github.com/kubernetes/website>https://github.com/kubernetes/website</a>.</li><li>Sélectionnez la branche `release-1.X' pour la version la plus récente.</li></ol><p>La dernière version est <strong>v1.25</strong>, donc la branche de la release la plus récente est <a href=https://github.com/kubernetes/website/tree/release-1.25><code>release-1.25</code></a>.</p><h3 id=chaînes-de-sites-en-i18n>Chaînes de sites en i18n/</h3><p>Les localisations doivent inclure le contenu des éléments suivants <a href=https://github.com/kubernetes/website/blob/main/i18n/en.toml><code>i18n/en.toml</code></a> dans un nouveau fichier spécifique à la langue.
Prenons l'allemand comme exemple : <code>i18n/de.toml</code>.</p><p>Ajouter un nouveau fichier de localisation dans <code>i18n/</code>. Par exemple, avec l'allemand (de) :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>cp i18n/en.toml i18n/de.toml
</span></span></code></pre></div><p>Traduisez ensuite la valeur de chaque chaîne de caractères :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-TOML data-lang=TOML><span style=display:flex><span>[docs_label_i_am]
</span></span><span style=display:flex><span>other = <span style=color:#b44>&#34;ICH BIN...&#34;</span>
</span></span></code></pre></div><p>La localisation des chaînes de caractères du site vous permet de personnaliser le texte et les fonctionnalités du site : par exemple, le texte du copyright légal dans le pied de page de chaque page.</p><h2 id=logistique-de-projet>Logistique de projet</h2><h3 id=contactez-les-responsables-du-sig-docs>Contactez les responsables du SIG Docs</h3><p>Contactez l'un des présidents du Kubernetes <a href=https://github.com/kubernetes/community/tree/master/sig-docs#chairs>SIG Docs</a> lorsque vous démarrez une nouvelle localisation.</p><h3 id=mainteneurs>Mainteneurs</h3><p>Chaque traduction doit fournir ses propres responsables.
Les responsables peuvent appartenir à une ou plusieurs organisations.
Dans la mesure du possible, les pull requests de traduction doivent être approuvées par un relecteur d'une organisation différente de celle du traducteur.</p><p>Une traduction doit avoir un minimum de deux mainteneurs.
(Il n'est pas possible de relire et d'approuver son propre travail.)</p><h3 id=gestion-des-branches>Gestion des branches</h3><p>Étant donné que les projets de traduction sont des efforts hautement collaboratifs, nous encourageons les équipes à travailler à partir d’une branche de développement partagée.</p><p>Pour collaborer sur une branche de développement:</p><ol><li><p>A team member opens a development branch, usually by opening a new pull request against a source branch on <a href=https://github.com/kubernetes/website>https://github.com/kubernetes/website</a>.</p><p>Nous recommandons le schéma de nommage de branche suivant :</p><p><code>dev-&lt;source version>-&lt;language code>.&lt;team milestone></code></p><p>Par exemple, un approbateur d'une équipe de localisation allemande ouvre la branche développement <code>dev-1.12-de.1</code> directement contre le dépôt k/website, basé sur la branche source pour Kubernetes v1.12.</p></li><li><p>Les contributeurs individuels ouvrent des branches de fonctionnalités basées sur la branche de développement.</p><p>Par exemple, un contributeur allemand ouvre une pull request avec les modifications suivantes <code>kubernetes:dev-1.12-de.1</code> sur <code>username:local-branch-name</code>.</p></li><li><p>Les approbateurs examinent et mergent les branches de fonctionnalités dans la branche de développement.</p></li><li><p>Périodiquement, un approbateur fusionne la branche de développement à sa branche source.</p></li></ol><p>Répétez les étapes 1 à 4 au besoin jusqu'à ce que la localisation soit terminée.
Par exemple, les branches de développement allemandes suivantes le seraient : <code>dev-1.12-de.2</code>, <code>dev-1.12-de.3</code>, etc.</p><p>Les équipes doivent fusionner le contenu localisé dans la même branche de publication d'où provient le contenu.
Par exemple, une direction du développement provenant de release-1.25 doit se fonder sur release-1.25.</p><p>Un approbateur doit maintenir une branche de développement en la tenant à jour avec sa branche source et en résolvant les conflits entre les branches.
Plus une branche de développement reste ouverte longtemps, plus elle nécessite généralement de maintenance.
Envisagez de merger périodiquement les branches de développement et d’en ouvrir de nouvelles, plutôt que de conserver une branche de développement extrêmement ancienne.</p><p>Seuls les approbateurs peuvent accepter les pull requests, mais n'importe qui peut en ouvrir une avec une nouvelle branche de développement.
Aucune autorisation spéciale n'est requise.</p><p>Pour plus d'informations sur le travail à partir de forks ou directement à partir du dépôt, voir <a href=#fork-and-clone-the-repo>"fork and clone the repo"</a>.</p><h3 id=upstream-contributions>Upstream contributions</h3><p>SIG Docs souhaite la bienvenue aux <a href=/docs/contribute/intermediate#localize-content>contributions et corrections upstream</a> à la source anglaise.</p><h2 id=a-suivre>A suivre</h2><p>Une fois qu'une traduction répond aux exigences de logistique et à une couverture admissible, le SIG docs se chargera des taches suivantes:</p><ul><li>Activer la sélection de la langue sur le site Web</li><li>Publier la disponibilité de la traduction via les canaux de la <a href=https://www.cncf.io/>Cloud Native Computing Foundation</a>, y compris sur le blog de <a href=https://kubernetes.io/blog/>Kubernetes</a>.</li></ul></div></main></div></div><footer class=d-print-none><div class=footer__links><nav><a class=text-white href=/fr/docs/home/>Accueil</a>
<a class=text-white href=/fr/blog/>Blog</a>
<a class=text-white href=/fr/partners/>Partenaires</a>
<a class=text-white href=/fr/community/>Communauté</a>
<a class=text-white href=/fr/case-studies/>Études de cas</a></nav></div><div class=container-fluid><div class=row><div class="col-6 col-sm-2 text-xs-center order-sm-2"><ul class="list-inline mb-0"><li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title="User mailing list" aria-label="User mailing list"><a class=text-white target=_blank href=https://discuss.kubernetes.io><i class="fa fa-envelope"></i></a></li><li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title=Twitter aria-label=Twitter><a class=text-white target=_blank href=https://twitter.com/kubernetesio><i class="fab fa-twitter"></i></a></li><li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title=Calendar aria-label=Calendar><a class=text-white target=_blank href="https://calendar.google.com/calendar/embed?src=calendar%40kubernetes.io"><i class="fas fa-calendar-alt"></i></a></li><li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title=Youtube aria-label=Youtube><a class=text-white target=_blank href=https://youtube.com/kubernetescommunity><i class="fab fa-youtube"></i></a></li></ul></div><div class="col-6 col-sm-2 text-right text-xs-center order-sm-3"><ul class="list-inline mb-0"><li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title=GitHub aria-label=GitHub><a class=text-white target=_blank href=https://github.com/kubernetes/kubernetes><i class="fab fa-github"></i></a></li><li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title=Slack aria-label=Slack><a class=text-white target=_blank href=https://slack.k8s.io><i class="fab fa-slack"></i></a></li><li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title=Contribute aria-label=Contribute><a class=text-white target=_blank href=https://git.k8s.io/community/contributors/guide><i class="fas fa-edit"></i></a></li><li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title="Stack Overflow" aria-label="Stack Overflow"><a class=text-white target=_blank href=https://stackoverflow.com/questions/tagged/kubernetes><i class="fab fa-stack-overflow"></i></a></li></ul></div><div class="col-12 col-sm-8 text-center order-sm-2"><small class=text-white>&copy; 2023 The Kubernetes Authors | Documentation Distributed under <a href=https://git.k8s.io/website/LICENSE class=light-text>CC BY 4.0</a></small><br><small class=text-white>Copyright &copy; 2023 The Linux Foundation &reg;. All rights reserved. The Linux Foundation has registered trademarks and uses trademarks. For a list of trademarks of The Linux Foundation, please see our <a href=https://www.linuxfoundation.org/trademark-usage class=light-text>Trademark Usage page</a></small><br><small class=text-white>ICP license: 京ICP备17074266号-3</small></div></div></div></footer></div><script src=/js/jquery-3.6.0.min.js integrity=sha384-vtXRMe3mGCbOeY7l30aIg8H9p3GdeSe4IFlP6G8JMa7o7lXvnz3GFKzPxzJdPfGK crossorigin=anonymous></script>
<script src=/js/popper-1.16.1.min.js intregrity=sha384-9/reFTGAW83EW2RDu2S0VKaIzap3H66lZH81PoYlFhbGU+6BZp6G7niu735Sk7lN crossorigin=anonymous></script>
<script src=/js/bootstrap-4.6.1.min.js integrity=sha384-VHvPCCyXqtD5DqJeNxl2dtTyhF78xXNXdkwX1CZeRusQfRKp+tA7hAShOK/B/fQ2 crossorigin=anonymous></script>
<script src=/js/script.js></script>
<script async src=/js/mermaid-8.13.4.min.js integrity=sha384-5hHNvPeMrNH14oM3IcQofDoBhiclNK3g2+hnEinKzQ07C4AliMeVpnvxuiwEGpaO crossorigin=anonymous></script>
<script src=/js/main.min.5c0bf7f21dc4f66485f74efbbeeff28a7e4f8cddaac1bae47043159c922ff3a3.js integrity="sha256-XAv38h3E9mSF9077vu/yin5PjN2qwbrkcEMVnJIv86M=" crossorigin=anonymous></script></body></html>