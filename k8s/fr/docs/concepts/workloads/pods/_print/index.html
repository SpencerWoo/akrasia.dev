<!doctype html><html lang=fr class=no-js><head><meta name=robots content="noindex, nofollow"><link rel=alternate hreflang=en href=https://kubernetes.io/docs/concepts/workloads/pods/><link rel=alternate hreflang=zh-cn href=https://kubernetes.io/zh-cn/docs/concepts/workloads/pods/><link rel=alternate hreflang=ko href=https://kubernetes.io/ko/docs/concepts/workloads/pods/><link rel=alternate hreflang=ja href=https://kubernetes.io/ja/docs/concepts/workloads/pods/><link rel=alternate hreflang=de href=https://kubernetes.io/de/docs/concepts/workloads/pods/><link rel=alternate hreflang=es href=https://kubernetes.io/es/docs/concepts/workloads/pods/><link rel=alternate hreflang=id href=https://kubernetes.io/id/docs/concepts/workloads/pods/><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=generator content="Hugo 0.110.0"><link rel=canonical type=text/html href=https://kubernetes.io/fr/docs/concepts/workloads/pods/><link rel="shortcut icon" type=image/png href=/images/favicon.png><link rel=apple-touch-icon href=/favicons/apple-touch-icon-180x180.png sizes=180x180><link rel=manifest href=/manifest.webmanifest><link rel=apple-touch-icon href=/images/kubernetes-192x192.png><title>Pods | Kubernetes</title><meta property="og:title" content="Pods"><meta property="og:description" content="Solution professionnelle d’orchestration de conteneurs"><meta property="og:type" content="website"><meta property="og:url" content="https://kubernetes.io/fr/docs/concepts/workloads/pods/"><meta property="og:site_name" content="Kubernetes"><meta itemprop=name content="Pods"><meta itemprop=description content="Solution professionnelle d’orchestration de conteneurs"><meta name=twitter:card content="summary"><meta name=twitter:title content="Pods"><meta name=twitter:description content="Solution professionnelle d’orchestration de conteneurs"><link href=/scss/main.css rel=stylesheet><script type=application/ld+json>{"@context":"https://schema.org","@type":"Organization","url":"https://kubernetes.io","logo":"https://kubernetes.io/images/favicon.png","potentialAction":{"@type":"SearchAction","target":"https://kubernetes.io/search/?q={search_term_string}","query-input":"required name=search_term_string"}}</script><meta name=theme-color content="#326ce5"><link rel=stylesheet href=/css/feature-states.css><meta name=description content><meta property="og:description" content><meta name=twitter:description content><meta property="og:url" content="https://kubernetes.io/fr/docs/concepts/workloads/pods/"><meta property="og:title" content="Pods"><meta name=twitter:title content="Pods"><meta name=twitter:image content="https://kubernetes.io/images/favicon.png"><meta name=twitter:image:alt content="Kubernetes"><meta property="og:image" content="/images/kubernetes-horizontal-color.png"><meta property="og:type" content="article"><script src=/js/jquery-3.6.0.min.js intregrity=sha384-vtXRMe3mGCbOeY7l30aIg8H9p3GdeSe4IFlP6G8JMa7o7lXvnz3GFKzPxzJdPfGK crossorigin=anonymous></script></head><body class=td-section><header><nav class="js-navbar-scroll navbar navbar-expand navbar-dark flex-column flex-md-row td-navbar" data-auto-burger=primary><a class=navbar-brand href=/fr/></a><div class="td-navbar-nav-scroll ml-md-auto" id=main_navbar><ul class="navbar-nav mt-2 mt-lg-0"><li class="nav-item mr-2 mb-lg-0"><a class="nav-link active" href=/fr/docs/>Documentation</a></li><li class="nav-item mr-2 mb-lg-0"><a class=nav-link href=/fr/blog/>Blog de Kubernetes</a></li><li class="nav-item mr-2 mb-lg-0"><a class=nav-link href=/fr/partners/>Partenaires</a></li><li class="nav-item mr-2 mb-lg-0"><a class=nav-link href=/fr/community/>Communauté</a></li><li class="nav-item mr-2 mb-lg-0"><a class=nav-link href=/fr/case-studies/>Études de cas</a></li><li class="nav-item dropdown"><a class="nav-link dropdown-toggle" href=# id=navbarDropdown role=button data-toggle=dropdown aria-haspopup=true aria-expanded=false>Versions</a><div class="dropdown-menu dropdown-menu-right" aria-labelledby=navbarDropdownMenuLink><a class=dropdown-item href=/fr/releases>Release Information</a>
<a class=dropdown-item href=https://kubernetes.io/fr/docs/concepts/workloads/pods/>v1.25</a>
<a class=dropdown-item href=https://v1-24.docs.kubernetes.io/fr/docs/concepts/workloads/pods/>v1.24</a>
<a class=dropdown-item href=https://v1-23.docs.kubernetes.io/fr/docs/concepts/workloads/pods/>v1.23</a>
<a class=dropdown-item href=https://v1-22.docs.kubernetes.io/fr/docs/concepts/workloads/pods/>v1.22</a>
<a class=dropdown-item href=https://v1-21.docs.kubernetes.io/fr/docs/concepts/workloads/pods/>v1.21</a></div></li><li class="nav-item dropdown"><a class="nav-link dropdown-toggle" href=# id=navbarDropdownMenuLink role=button data-toggle=dropdown aria-haspopup=true aria-expanded=false>Français (French)</a><div class="dropdown-menu dropdown-menu-right" aria-labelledby=navbarDropdownMenuLink><a class=dropdown-item href=/docs/concepts/workloads/pods/>English</a>
<a class=dropdown-item href=/zh-cn/docs/concepts/workloads/pods/>中文 (Chinese)</a>
<a class=dropdown-item href=/ko/docs/concepts/workloads/pods/>한국어 (Korean)</a>
<a class=dropdown-item href=/ja/docs/concepts/workloads/pods/>日本語 (Japanese)</a>
<a class=dropdown-item href=/de/docs/concepts/workloads/pods/>Deutsch (German)</a>
<a class=dropdown-item href=/es/docs/concepts/workloads/pods/>Español (Spanish)</a>
<a class=dropdown-item href=/id/docs/concepts/workloads/pods/>Bahasa Indonesia</a></div></li></ul></div><button id=hamburger onclick=kub.toggleMenu() data-auto-burger-exclude><div></div></button></nav></header><div class="container-fluid td-outer"><div class=td-main><div class="row flex-xl-nowrap"><main class="col-12 col-md-9 col-xl-8 pl-md-5" role=main><div class=td-content><div class="pageinfo pageinfo-primary d-print-none"><p>Version imprimable multipages.
<a href=# onclick="return print(),!1">Cliquer ici pour imprimer</a>.</p><p><a href=/fr/docs/concepts/workloads/pods/>Retour à la version par défaut</a>.</p></div><h1 class=title>Pods</h1><ul><li>1: <a href=#pg-37afa6c66c74400d1579f10faf55e5b6>Aperçu du Pod</a></li><li>2: <a href=#pg-99cce294fe789317ee684a6e1f07f20f>Pods</a></li><li>3: <a href=#pg-c3c2b9cf30915ec9d46c147201da3332>Cycle de vie d'un Pod</a></li><li>4: <a href=#pg-c8d62295ca703fdcef1aaf89fb4c916a>Contraintes de propagation de topologie pour les Pods</a></li><li>5: <a href=#pg-1ccbd4eeded6ab138d98b59175bd557e>Init Containers</a></li></ul><div class=content></div></div><div class=td-content><h1 id=pg-37afa6c66c74400d1579f10faf55e5b6>1 - Aperçu du Pod</h1><div class=lead>Pod Concept Kubernetes</div><p>Cette page fournit un aperçu du <code>Pod</code>, l'objet déployable le plus petit dans le modèle d'objets Kubernetes.</p><h2 id=comprendre-les-pods>Comprendre les Pods</h2><p>Un <em>Pod</em> est l'unité d'exécution de base d'une application Kubernetes--l'unité la plus petite et la plus simple dans le modèle d'objets de Kubernetes--que vous créez ou déployez. Un Pod représente des process en cours d'exécution dans votre <a class=glossary-tooltip title='Un ensemble de machines, appelées des "nœuds", qui exécutent des applications conteneurisées gérées par Kubernetes.' data-toggle=tooltip data-placement=top href='/fr/docs/reference/glossary/?all=true#term-cluster' target=_blank aria-label=cluster>cluster</a>.</p><p>Un Pod encapsule un conteneur applicatif (ou, dans certains cas, plusieurs conteneurs), des ressources de stockage, une identité réseau (adresse IP) unique, ainsi que des options qui contrôlent comment le ou les conteneurs doivent s'exécuter. Un Pod représente une unité de déploiement : <em>une instance unique d'une application dans Kubernetes</em>, qui peut consister soit en un unique <a class=glossary-tooltip title='Une image exécutable légère et portable qui contient le logiciel et toutes ses dépendances.' data-toggle=tooltip data-placement=top href=/docs/concepts/overview/what-is-kubernetes/#why-containers target=_blank aria-label=container>container</a> soit en un petit nombre de conteneurs qui sont étroitement liés et qui partagent des ressources.</p><blockquote><p><a href=https://www.docker.com>Docker</a> est le runtime de conteneurs le plus courant utilisé dans un Pod Kubernetes, mais les Pods prennent également en charge d'autres <a href=/docs/setup/production-environment/container-runtimes/>runtimes de conteneurs</a>.</p></blockquote><p>Les Pods dans un cluster Kubernetes peuvent être utilisés de deux manières différentes :</p><ul><li><strong>les Pods exécutant un conteneur unique</strong>. Le modèle "un-conteneur-par-Pod" est le cas d'utilisation Kubernetes le plus courant ; dans ce cas, vous pouvez voir un Pod comme un wrapper autour d'un conteneur unique, et Kubernetes gère les Pods plutôt que directement les conteneurs.</li><li><strong>les Pods exécutant plusieurs conteneurs devant travailler ensemble</strong>. Un Pod peut encapsuler une application composée de plusieurs conteneurs co-localisés qui sont étroitement liés et qui doivent partager des ressources. Ces conteneurs co-localisés pourraient former une unique unité de service cohésive--un conteneur servant des fichiers d'un volume partagé au public, alors qu'un conteneur "sidecar" séparé rafraîchit ou met à jour ces fichiers. Le Pod enveloppe ensemble ces conteneurs et ressources de stockage en une entité maniable de base.</li></ul><p>Chaque Pod est destiné à exécuter une instance unique d'une application donnée. Si vous désirez mettre à l'échelle votre application horizontalement, (pour fournir plus de ressources au global en exécutant plus d'instances), vous devez utiliser plusieurs Pods, un pour chaque instance. Dans Kubernetes, on parle typiquement de <em>réplication</em>. Des Pods répliqués sont en général créés et gérés en tant que groupe par une ressource de charge de travail et son <a class=glossary-tooltip title="Boucle de contrôle surveillant l'état partagé du cluster à travers l'apiserver et effectuant des changements en essayant de déplacer l'état actuel vers l'état désiré." data-toggle=tooltip data-placement=top href=/docs/admin/kube-controller-manager/ target=_blank aria-label=_contrôleur_>_contrôleur_</a>. Voir <a href=#pods-et-controleurs>Pods et contrôleurs</a> pour plus d'informations.</p><h3 id=comment-les-pods-gèrent-plusieurs-conteneurs>Comment les Pods gèrent plusieurs conteneurs</h3><p>Les Pods sont conçus pour supporter plusieurs process coopérants (sous forme de conteneurs) qui forment une unité de service cohésive. Les conteneurs d'un même Pod sont automatiquement co-localisés et co-programmés sur la même machine physique ou virtuelle dans le cluster. Ces conteneurs peuvent partager des ressources et dépendances, communiquer entre eux, et coordonner quand et comment ils sont arrêtés.</p><p>Notez que grouper plusieurs conteneurs co-localisés et co-gérés dans un unique Pod est un cas d'utilisation relativement avancé. Vous devez utiliser ce pattern seulement dans des instances spécifiques dans lesquelles vos conteneurs sont étroitement liés. Par exemple, vous pourriez avoir un conteneur qui agit comme un serveur web pour des fichiers contenus dans un volume partagé, et un conteneur "sidecar" séparé qui met à jour ces fichiers depuis une source externe, comme dans le diagramme suivant :</p><figure><img src=/images/docs/pod.svg alt="example pod diagram" width=50%></figure><p>Certains Pods ont des <a class=glossary-tooltip title="Un ou plusieurs conteneurs d'initialisation qui doivent être exécutés jusqu'à la fin, avant l'exécution de tout conteneur d'application." data-toggle=tooltip data-placement=top href='/fr/docs/reference/glossary/?all=true#term-init-container' target=_blank aria-label='init containers'>init containers</a> en plus d'<a class=glossary-tooltip title="Un conteneur utilisé pour exécuter une partie d'une charge de travail, comparable à un init conteneur." data-toggle=tooltip data-placement=top href='/fr/docs/reference/glossary/?all=true#term-app-container' target=_blank aria-label='app containers'>app containers</a>. Les Init containers s'exécutent et terminent avant que les conteneurs d'application soient démarrés.</p><p>Les Pods fournissent deux types de ressources partagées pour leurs conteneurs : <em>réseau</em> et <em>stockage</em>.</p><h4 id=réseau>Réseau</h4><p>Chaque Pod se voit assigner une adresse IP unique pour chaque famille d'adresses. Tous les conteneurs d'un Pod partagent le même namespace réseau, y compris l'adresse IP et les ports réseau. Les conteneurs <em>à l'intérieur d'un Pod</em> peuvent communiquer entre eux en utilisant <code>localhost</code>. Lorsque les conteneurs dans un Pod communiquent avec des entités <em>en dehors du Pod</em>, ils doivent coordonner comment ils utilisent les ressources réseau partagées (comme les ports).</p><h4 id=stockage>Stockage</h4><p>Un Pod peut spécifier un jeu de <a class=glossary-tooltip title="Un répertoire contenant des données, accessible aux conteneurs d'un pod." data-toggle=tooltip data-placement=top href=/fr/docs/concepts/storage/volumes/ target=_blank aria-label=volumes>volumes</a> de stockage partagés. Tous les conteneurs dans le Pod peuvent accéder aux volumes partagés, permettant à ces conteneurs de partager des données. Les volumes permettent aussi les données persistantes d'un Pod de survivre au cas où un des conteneurs doit être redémarré. Voir <a href=/docs/concepts/storage/volumes/>Volumes</a> pour plus d'informations sur la façon dont Kubernetes implémente le stockage partagé dans un Pod.</p><h2 id=travailler-avec-des-pods>Travailler avec des Pods</h2><p>Vous aurez rarement à créer directement des Pods individuels dans Kubernetes--même des Pods à un seul conteneur. Ceci est dû au fait que les Pods sont conçus comme des entités relativement éphémères et jetables. Lorsqu'un Pod est créé (directement par vous ou indirectement par un <a class=glossary-tooltip title="Boucle de contrôle surveillant l'état partagé du cluster à travers l'apiserver et effectuant des changements en essayant de déplacer l'état actuel vers l'état désiré." data-toggle=tooltip data-placement=top href=/docs/admin/kube-controller-manager/ target=_blank aria-label=_contrôleur_>_contrôleur_</a>), il est programmé pour s'exécuter sur un <a class=glossary-tooltip title='A node is a worker machine in Kubernetes.' data-toggle=tooltip data-placement=top href=/docs/concepts/architecture/nodes/ target=_blank aria-label=Node>Node</a> dans votre cluster. Le Pod reste sur ce nœud jusqu'à ce que le process se termine, l'objet pod soit supprimé, le pod soit <em>expulsé</em> par manque de ressources, ou le nœud soit en échec.</p><div class="alert alert-info note callout" role=alert><strong>Note:</strong> Redémarrer un conteneur dans un Pod ne doit pas être confondu avec redémarrer un Pod. Un Pod n'est pas un process, mais un environnement pour exécuter un conteneur. Un Pod persiste jusqu'à ce qu'il soit supprimé.</div><p>Les Pods ne se guérissent pas par eux-mêmes. Si un Pod est programmé sur un Nœud qui échoue, ou si l'opération de programmation elle-même échoue, le Pod est supprimé ; de plus, un Pod ne survivra pas à une expulsion due à un manque de ressources ou une mise en maintenance du Nœud. Kubernetes utilise une abstraction de plus haut niveau, appelée un <em>contrôleur</em>, qui s'occupe de gérer les instances de Pods relativement jetables. Ainsi, même s'il est possible d'utiliser des Pods directement, il est beaucoup plus courant dans Kubernetes de gérer vos Pods en utilisant un contrôleur.</p><h3 id=pods-et-contrôleurs>Pods et contrôleurs</h3><p>Vous pouvez utiliser des ressources de charges de travail pour créer et gérer plusieurs Pods pour vous. Un contrôleur pour la ressource gère la réplication,
le plan de déploiement et la guérison automatique en cas de problèmes du Pod. Par exemple, si un noeud est en échec, un contrôleur note que les Pods de ce noeud
ont arrêté de fonctionner et créent des Pods pour les remplacer. L'ordonnanceur place le Pod de remplacement sur un noeud en fonctionnement.</p><p>Voici quelques exemples de ressources de charges de travail qui gèrent un ou plusieurs Pods :</p><ul><li><a class=glossary-tooltip title='Objet API gérant une application répliquée.' data-toggle=tooltip data-placement=top href=/docs/concepts/workloads/controllers/deployment/ target=_blank aria-label=Deployment>Deployment</a></li><li><a class=glossary-tooltip title="Gère le déploiement et la mise à l'échelle d'un ensemble de Pods, avec un stockage durable et des identifiants persistants pour chaque Pod." data-toggle=tooltip data-placement=top href=/fr/docs/concepts/workloads/controllers/statefulset/ target=_blank aria-label=StatefulSet>StatefulSet</a></li><li><a class=glossary-tooltip title="S'assure qu'une copie d'un Pod s'exécute sur un ensemble de nœuds d'un cluster." data-toggle=tooltip data-placement=top href=/docs/concepts/workloads/controllers/daemonset target=_blank aria-label=DaemonSet>DaemonSet</a></li></ul><h2 id=templates-de-pod>Templates de Pod</h2><p>Les Templates de Pod sont des spécifications pour créer des Pods, et sont inclus dans les ressources de charges de travail comme
les <a href=/fr/docs/concepts/workloads/controllers/deployment/>Deployments</a>, les <a href=/docs/concepts/jobs/run-to-completion-finite-workloads/>Jobs</a> et
les <a href=/docs/concepts/workloads/controllers/daemonset/>DaemonSets</a>.</p><p>Chaque contrôleur pour une ressource de charges de travail utilise le template de pod à l'intérieur de l'objet pour créer les Pods. Le template de pod fait partie de l'état désiré de la ressource de charges de travail que vous avez utilisé pour exécuter votre application.</p><p>L'exemple ci-dessous est un manifest pour un Job simple avec un <code>template</code> qui démarre un conteneur. Le conteneur dans ce Pod affiche un message puis se met en pause.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>batch/v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Job<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>hello<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>template</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:#080;font-style:italic># Ceci est un template de pod</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>hello<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>busybox<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>command</span>:<span style=color:#bbb> </span>[<span style=color:#b44>&#39;sh&#39;</span>,<span style=color:#bbb> </span><span style=color:#b44>&#39;-c&#39;</span>,<span style=color:#bbb> </span><span style=color:#b44>&#39;echo &#34;Hello, Kubernetes!&#34; &amp;&amp; sleep 3600&#39;</span>]<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>restartPolicy</span>:<span style=color:#bbb> </span>OnFailure<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:#080;font-style:italic># Le template de pod se termine ici</span><span style=color:#bbb>
</span></span></span></code></pre></div><p>Modifier le template de pod ou changer pour un nouvau template de pod n'a pas d'effet sur les pods déjà existants. Les Pods ne reçoivent pas une mise à jour
du template directement ; au lieu de cela, un nouveau Pod est créé pour correspondre au nouveau template de pod.</p><p>Par exemple, un contrôleur de Deployment s'assure que les Pods en cours d'exécution correspondent au template de pod en cours. Si le template est mis à jour,
le contrôleur doit supprimer les pods existants et créer de nouveaux Pods avec le nouveau template. Chaque contrôleur de charges de travail implémente ses propres
règles pour gérer les changements du template de Pod.</p><p>Sur les noeuds, le <a class=glossary-tooltip title="Un agent qui s'exécute sur chaque nœud du cluster. Il s'assure que les conteneurs fonctionnent dans un pod." data-toggle=tooltip data-placement=top href=/docs/reference/generated/kubelet target=_blank aria-label=kubelet>kubelet</a> n'observe ou ne gère pas directement les détails concernant les templates de pods et leurs mises à jours ; ces détails sont abstraits. Cette abstraction et cette séparation des préoccupations simplifie la sémantique du système, et rend possible l'extension du comportement du cluster sans changer le code existant.</p><h2 id=a-suivre>A suivre</h2><ul><li>En savoir plus sur les <a href=/docs/concepts/workloads/pods/pod/>Pods</a></li><li><a href=https://kubernetes.io/blog/2015/06/the-distributed-system-toolkit-patterns>The Distributed System Toolkit: Patterns for Composite Containers</a> explique les dispositions courantes pour des Pods avec plusieurs conteneurs</li><li>En savoir plus sur le comportement des Pods :<ul><li><a href=/docs/concepts/workloads/pods/pod/#termination-of-pods>Terminaison d'un Pod</a></li><li><a href=/docs/concepts/workloads/pods/pod-lifecycle/>Cycle de vie d'un Pod</a></li></ul></li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-99cce294fe789317ee684a6e1f07f20f>2 - Pods</h1><p>Les <em>Pods</em> sont les plus petites unités informatiques déployables
qui peuvent être créées et gérées dans Kubernetes.</p><h2 id=qu-est-ce-qu-un-pod>Qu'est-ce qu'un pod ?</h2><p>Un <em>pod</em> (terme anglo-saxon décrivant un groupe de baleines ou une gousse de pois) est un groupe d'un ou plusieurs conteneurs
(comme des conteneurs Docker), ayant du stockage/réseau partagé, et une spécification
sur la manière d'exécuter ces conteneurs. Les éléments d'un pod sont toujours co-localisés
et co-ordonnancés, et s'exécutent dans un contexte partagé. Un pod modélise un
"hôte logique" spécifique à une application - il contient un ou plusieurs conteneurs applicatifs
qui sont étroitement liés — dans un monde pré-conteneurs, être exécuté sur la même machine
physique ou virtuelle signifierait être exécuté sur le même hôte logique.</p><p>Bien que Kubernetes prenne en charge d'autres runtimes de conteneurs que Docker, Docker est le runtime
le plus connu, et cela aide à décrire des pods en termes Docker.</p><p>Le contexte partagé d'un pod est un ensemble de namespaces Linux, cgroups, et
potentiellement d'autres facettes d'isolation - les mêmes choses qui isolent un conteneur Docker.
Dans le contexte d'un pod, les applications individuelles peuvent se voir appliquer d'autres sous-isolations.</p><p>Les conteneurs d'un pod partagent une adresse IP et un espace de ports, et peuvent communiquer via <code>localhost</code>.
Ils peuvent aussi communiquer entre eux en utilisant des communications inter-process standard comme
les sémaphores SystemV ou la mémoire partagée POSIX. Les conteneurs appartenant à des pods distincts ont des adresses IP
distinctes et ne peuvent pas communiquer par IPC sans <a href=/docs/concepts/policy/pod-security-policy/>configuration spécifique</a>. Ces conteneurs communiquent en général entre eux via les adresses IP de leurs pods.</p><p>Les applications à l'intérieur d'un pod ont aussi accès à des volumes partagés,
qui sont définis dans le cadre d'un pod et sont mis à disposition pour être montés
dans le système de fichiers de chaque application.</p><p>En terme de concepts <a href=https://www.docker.com/>Docker</a>, un pod est modélisé par un groupe de conteneurs Docker
ayant des namespaces et des <a href=/docs/concepts/storage/volumes/>volumes</a> partagés.</p><p>Tout comme des conteneurs applicatifs individuels, les pods sont considérés comme des entités relativement éphémères (plutôt que durables).
Comme discuté dans <a href=/docs/concepts/workloads/pods/pod-lifecycle/>Cycle de vie d'un pod</a>, les pods sont créés, des ID uniques (UID) leurs sont assignés,
et ils sont ordonnancés sur des nœuds où il restent jusqu'à leur arrêt (selon la politique de redémarrage) ou suppression.
Si un nœud meurt, les pods ordonnancés sur ce nœud sont programmés pour être terminés, après un délai d'attente. Un pod donné (défini par un UID)
n'est pas "re-ordonnancé" sur un nouveau nœud ; par contre, il peut être remplacé par un pod identique,
ayant le même nom si désiré, mais avec un nouvel UID (voir <a href=/docs/concepts/workloads/controllers/replicationcontroller/>replication
controller</a> pour plus de détails).</p><p>Lorsque quelque chose, comme un volume, a le même cycle de vie qu'un pod, il existe aussi longtemps
que le pod (avec l'UID donné) existe. Si ce pod est supprimé pour une quelconque raison, même si un remplaçant
identique est recréé, la chose liée (par ex. le volume) est aussi détruite et créée à nouveau.</p><figure><img src=/images/docs/pod.svg width=50%><figcaption><h4>pod diagram</h4></figcaption></figure><p><em>Un pod multi-conteneurs contenant un extracteur de fichiers et un serveur web
utilisant un volume persistant comme espace de stockage partagé entre les conteneurs.</em></p><h2 id=intérêts-des-pods>Intérêts des pods</h2><h3 id=gestion>Gestion</h3><p>Les pods fournissent une unité de service cohérente afin d'avoir un modèle coopératif entre plusieurs processus.
Ils simplifient le déploiement et la gestion d'applications
en fournissant une abstraction de plus haut niveau que l'ensemble des applications les constituant.
Les pods servent d'unité de déploiement, de mise à l'échelle horizontale, et de réplication.
La co-localisation (co-ordonnancement), la fin partagée (par ex. l'arrêt),
la réplication coordonnée, le partage de ressources et la gestion des dépendances sont
traités automatiquement pour les conteneurs dans un pod.</p><h3 id=partage-de-ressources-et-communication>Partage de ressources et communication</h3><p>Les pods permettent le partage de ressources et la communication entre ses constituants.</p><p>Les applications dans un pod utilisent toutes le même réseau (même adresse IP et espace de ports)
et peuvent donc "se trouver" entre elles et communiquer en utilisant <code>localhost</code>.
À cause de cela, les applications dans un pod doivent coordonner leurs usages de ports.
Chaque pod a une adresse IP dans un réseau plat partagé ayant un accès complet
aux autres hôtes et pods à travers le réseau.</p><p>Le nom d'hôte est défini avec le nom du pod pour les conteneurs applicatifs à l'intérieur du pod.
<a href=/docs/concepts/cluster-administration/networking/>Plus de détails sur le réseau</a>.</p><p>En plus de définir les conteneurs applicatifs s'exécutant dans le pod, le pod spécifie
un ensemble de volumes de stockage partagés. Les volumes permettent aux données de survivre
aux redémarrages de conteneurs et d'être partagés entre les applications d'un même pod.</p><h2 id=cas-d-utilisation-de-pods>Cas d'utilisation de pods</h2><p>Des pods peuvent être utilisés pour héberger verticalement des piles applicatives intégrées (par ex. LAMP),
mais leur principal intérêt est la mise en place de programmes auxiliaires co-localisés et co-gérés, comme :</p><ul><li>systèmes de gestion de contenu, chargeurs de fichiers et de données, gestionnaires de cache local, etc.</li><li>sauvegarde de log et checkpoint, compression, rotation, prise d'instantanés, etc.</li><li>data change watchers, log tailers, adaptateurs de logs et monitoring, éditeurs d'événements, etc.</li><li>proxies, bridges et adaptateurs</li><li>contrôleurs, gestionnaires, configurateurs et gestionnaires de mise à jour</li></ul><p>Des pods individuels ne sont pas destinés à exécuter plusieurs instances de la même application, en général.</p><p>Pour une explication plus détaillée, voir <a href=https://kubernetes.io/blog/2015/06/the-distributed-system-toolkit-patterns>The Distributed System ToolKit: Patterns for
Composite
Containers</a>.</p><h2 id=alternatives-envisagées>Alternatives envisagées</h2><p><em>Pourquoi ne pas simplement exécuter plusieurs programmes dans un unique conteneur (Docker) ?</em></p><ol><li>Transparence. Rendre les conteneurs à l'intérieur du pod visibles par l'infrastucture
permet à l'infrastucture de fournir des services à ces conteneurs,
comme la gestion des processus et le monitoring des ressources. Ceci
apporte un certain nombre de facilités aux utilisateurs.</li><li>Découpler les dépendances logicielles. Les conteneurs individuels peuvent être
versionnés, reconstruits et redéployés de manière indépendante. Kubernetes pourrait
même un jour prendre en charge la mise à jour à chaud de conteneurs individuels.</li><li>Facilité d'utilisation. Les utilisateurs n'ont pas besoin d'exécuter leur propre gestionnaire
de processus, de se soucier de la propagation de signaux et de codes de sortie, etc.</li><li>Efficacité. L'infrastructure prenant plus de responsabilités, les conteneurs peuvent être plus légers.</li></ol><p><em>Pourquoi ne pas prendre en charge le co-ordonnancement de conteneurs basé sur les affinités ?</em></p><p>Cette approche pourrait fournir la co-localisation, mais ne fournirait pas la plupart
des bénéfices des pods, comme le partage de ressources, IPC, la garantie d'une fin partagée et une gestion simplifiée.</p><h2 id=durabilité-des-pods-ou-manque-de>Durabilité des pods (ou manque de)</h2><p>Les pods ne doivent pas être considérés comme des entités durables. Ils ne survivent pas à des erreurs d'ordonnancement, à un nœud en échec
ou à d'autres expulsions, suite à un manque de ressources ou une mise en maintenance d'un nœud.</p><p>En général, les utilisateurs n'ont pas à créer directement des pods. Ils doivent presque toujours
utiliser des contrôleurs, même pour des singletons, comme par exemple des <a href=/docs/concepts/workloads/controllers/deployment/>Deployments</a>.
Les contrôleurs fournissent l'auto-guérison à l'échelle du cluster, ainsi que la réplication et la gestion des déploiements (rollout).
Les contrôleurs comme <a href=/docs/concepts/workloads/controllers/statefulset.md>StatefulSet</a>
peuvent aussi prendre en charge des pods avec état (stateful).</p><p>L'utilisation d'APIs collectives comme principale primitive exposée à l'utilisateur est courante dans les systèmes d'ordonnancement de clusters, comme <a href=https://research.google.com/pubs/pub43438.html>Borg</a>, <a href=https://mesosphere.github.io/marathon/docs/rest-api.html>Marathon</a>, <a href=http://aurora.apache.org/documentation/latest/reference/configuration/#job-schema>Aurora</a>, et <a href=http://www.slideshare.net/Docker/aravindnarayanan-facebook140613153626phpapp02-37588997>Tupperware</a>.</p><p>Un Pod est exposé en tant que primitive afin de faciliter :</p><ul><li>la connexion du scheduler et du contrôleur</li><li>la possibilité d'opérations au niveau du pod sans besoin de passer par des APIs au niveau du contrôleur</li><li>le découplage du cycle de fin d'un pod de celui d'un contrôleur, comme pour l'amorçage (bootstrapping)</li><li>le découplage des contrôleurs et des services — le contrôleur d'endpoints examine uniquement des pods</li><li>la composition claire des fonctionnalités niveau Kubelet et des fonctionnalités niveau cluster — concrètement, Kubelet est le "contrôleur de pods"</li><li>les applications hautement disponibles, qui attendront que les pods soient remplacés avant leur arrêt et au moins avant leur suppression, comme dans les cas d'éviction programmée ou de pré-chargement d'image.</li></ul><h2 id=arrêt-de-pods>Arrêt de pods</h2><p>Les pods représentant des processus s'exécutant sur des nœuds d'un cluster, il est important de permettre à ces processus de se terminer proprement
lorsqu'ils ne sont plus nécessaires (plutôt que d'être violemment tués avec un signal KILL et n'avoir aucune chance de libérer ses ressources). Les
utilisateurs doivent pouvoir demander une suppression et savoir quand les processus se terminent, mais aussi être capable de s'assurer que la suppression
est réellement effective. Lorsqu'un utilisateur demande la suppression d'un pod, le système enregistre le délai de grâce prévu avant que le pod puisse
être tué de force, et qu'un signal TERM soit envoyé au processus principal de chaque conteneur. Une fois la période de grâce expirée, le signal KILL
est envoyé à ces processus, et le pod est alors supprimé de l'API server. Si Kubelet ou le gestionnaire de conteneurs est redémarré lors de l'attente de l'arrêt des processus, l'arrêt sera réessayé avec la période de grâce complète.</p><p>Un exemple de déroulement :</p><ol><li>Un utilisateur envoie une commande pour supprimer un Pod, avec une période de grâce par défaut (30s)</li><li>Le Pod dans l'API server est mis à jour avec le temps au delà duquel le Pod est considéré "mort" ainsi que la période de grâce.</li><li>Le Pod est affiché comme "Terminating" dans les listes des commandes client</li><li>(en même temps que 3) Lorsque Kubelet voit qu'un Pod a été marqué "Terminating", le temps ayant été mis en 2, il commence le processus de suppression du pod.<ol><li>Si un des conteneurs du Pod a défini un <a href=/fr/docs/concepts/containers/container-lifecycle-hooks/#hook-details>preStop hook</a>, il est exécuté à l'intérieur du conteneur. Si le <code>preStop</code> hook est toujours en cours d'exécution à la fin de la période de grâce, l'étape 2 est invoquée avec une courte (2 secondes) période de grâce supplémentaire une seule fois. Vous devez modifier <code>terminationGracePeriodSeconds</code> si le hook <code>preStop</code> a besoin de plus de temps pour se terminer.</li><li>Le signal TERM est envoyé aux conteneurs. Notez que tous les conteneurs du Pod ne recevront pas le signal TERM en même temps et il peut être nécessaire de définir des <code>preStop</code> hook si l'ordre d'arrêt est important.</li></ol></li><li>(en même temps que 3) Le Pod est supprimé des listes d'endpoints des services, et n'est plus considéré comme faisant partie des pods en cours d'exécution pour les contrôleurs de réplication. Les Pods s'arrêtant lentement ne peuvent pas continuer à servir du trafic, les load balancers (comme le service proxy) les supprimant de leurs rotations.</li><li>Lorsque la période de grâce expire, les processus s'exécutant toujours dans le Pod sont tués avec SIGKILL.</li><li>Kubelet va supprimer le Pod dans l'API server en indiquant une période de grâce de 0 (suppression immédiate). Le Pod disparaît de l'API et n'est plus visible par le client.</li></ol><p>Par défaut, toutes les suppressions ont une période de grâce de 30 secondes. La commande <code>kubectl delete</code> prend en charge l'option <code>--grace-period=&lt;secondes></code> permettant à l'utilisateur de spécifier sa propre valeur. La valeur <code>0</code> <a href=/docs/concepts/workloads/pods/pod/#force-deletion-of-pods>force la suppression</a> du pod. Avec kubectl version >= 1.5, vous devez spécifier un flag supplémentaire <code>--force</code> avec <code>--grace-period=0</code> pour pouvoir forcer la suppression.</p><h3 id=suppression-forcée-de-pods>Suppression forcée de pods</h3><p>La suppression forcée d'un pod est définie comme la suppression immédiate d'un pod de l'état du cluster et d'etcd. Lorqu'une suppression forcée est effectuée, l'apiserver n'attend pas la confirmation de kubelet que le pod a été terminé sur le nœud sur lequel il s'exécutait. Il supprime le pod de l'API immédiatement pour qu'un nouveau pod puisse être créé avec le même nom. Sur le nœud, les pods devant se terminer immédiatement se verront donner une courte période de grâce avant d'être tués de force.</p><p>Les suppressions forcées peuvent être potentiellement dangereuses pour certains pods et doivent être effectuées avec précaution. Dans le cas de pods d'un StatefulSet, veuillez vous référer à la documentation pour <a href=/docs/tasks/run-application/force-delete-stateful-set-pod/>supprimer des Pods d'un StatefulSet</a>.</p><h2 id=mode-privilégié-pour-les-conteneurs-d-un-pod>Mode privilégié pour les conteneurs d'un pod</h2><p>Depuis Kubernetes v1.1, tout conteneur d'un pod peut activer le mode privilégié, en utilisant le flag <code>privileged</code> du <code>SecurityContext</code> de la spec du conteneur. Ceci est utile pour les conteneurs voulant utiliser les capacités de Linux comme manipuler la pile réseau ou accéder aux périphériques. Les processus dans un tel conteneur ont pratiquement les mêmes privilèges que les processus en dehors d'un conteneur. En mode privilégié, il doit être plus facile d'écrire des plugins réseau et volume en tant que pods séparés ne devant pas être compilés dans kubelet.</p><p>Si le master exécute Kubernetes v1.1 ou supérieur, et les nœuds exécutent une version antérieure à v1.1, les nouveaux pods privilégiés seront acceptés par l'api-server, mais ne seront pas lancés. Il resteront en état "pending".
Si l'utilisateur appelle <code>kubectl describe pod FooPodName</code>, l'utilisateur peut voir la raison pour laquelle le pod est en état "pending". La table d'événements dans la sortie de la commande "describe" indiquera :
<code>Error validating pod "FooPodName"."FooPodNamespace" from api, ignoring: spec.containers[0].securityContext.privileged: forbidden '&lt;*>(0xc2089d3248)true'</code></p><p>Si le master exécute une version antérieure à v1.1, les pods privilégiés ne peuvent alors pas être créés. Si l'utilisateur tente de créer un pod ayant un conteneur privilégié, l'utilisateur obtiendra l'erreur suivante :
<code>The Pod "FooPodName" is invalid. spec.containers[0].securityContext.privileged: forbidden '&lt;*>(0xc20b222db0)true'</code></p><h2 id=objet-de-l-api>Objet de l'API</h2><p>Le Pod est une ressource au plus haut niveau dans l'API REST Kubernetes. Plus de détails sur l'objet de l'API peuvent être trouvés à :
<a href=/docs/reference/generated/kubernetes-api/v1.25/#pod-v1-core>Objet de l'API Pod</a>.</p><p>Lorsque vous créez un manifest pour un objet Pod, soyez certain que le nom spécifié est un <a href=/docs/concepts/overview/working-with-objects/names#dns-subdomain-names>nom de sous-domaine DNS</a> valide.</p></div><div class=td-content style=page-break-before:always><h1 id=pg-c3c2b9cf30915ec9d46c147201da3332>3 - Cycle de vie d'un Pod</h1><p>Cette page décrit le cycle de vie d'un Pod.</p><h2 id=phase-du-pod>Phase du Pod</h2><p>Le champ <code>status</code> d'un Pod est un objet
<a href=/docs/reference/generated/kubernetes-api/v1.25/#podstatus-v1-core>PodStatus</a>,
contenant un champ <code>phase</code>.</p><p>La phase d'un Pod est un résumé simple et de haut niveau de l'étape à laquelle le Pod se trouve
dans son cycle de vie.
La phase n'est pas faite pour être un cumul complet d'observations de l'état
du conteneur ou du Pod, ni pour être une machine à état compréhensible.</p><p>Le nombre et la signification des valeurs de phase d'un pod sont soigneusement gardés.
Hormis ce qui est documenté ici, rien ne doit être supposé sur des Pods
ayant une valeur de <code>phase</code> donnée.</p><p>Voici les valeurs possibles pour <code>phase</code> :</p><table><thead><tr><th style=text-align:left>Valeur</th><th style=text-align:left>Description</th></tr></thead><tbody><tr><td style=text-align:left><code>Pending</code></td><td style=text-align:left>Le Pod a été accepté par Kubernetes, mais une ou plusieurs images de conteneurs n'ont pas encore été créées. Ceci inclut le temps avant d'être affecté ainsi que le temps à télécharger les images à travers le réseau, ce qui peut prendre un certain temps.</td></tr><tr><td style=text-align:left><code>Running</code></td><td style=text-align:left>Le pod a été affecté à un nœud et tous les conteneurs ont été créés. Au moins un conteneur est toujours en cours d'exécution, ou est en train de démarrer ou redémarrer.</td></tr><tr><td style=text-align:left><code>Succeeded</code></td><td style=text-align:left>Tous les conteneurs du pod ont terminé avec succès et ne seront pas redémarrés.</td></tr><tr><td style=text-align:left><code>Failed</code></td><td style=text-align:left>Tous les conteneurs d'un pod ont terminé, et au moins un conteneur a terminé en échec : soit le conteneur a terminé avec un status non zéro, soit il a été arrêté par le système.</td></tr><tr><td style=text-align:left><code>Unknown</code></td><td style=text-align:left>Pour quelque raison l'état du pod ne peut pas être obtenu, en général en cas d'erreur de communication avec l'hôte du Pod.</td></tr></tbody></table><h2 id=conditions-du-pod>Conditions du Pod</h2><p>Un Pod a un PodStatus, qui contient un tableau de
<a href=/docs/reference/generated/kubernetes-api/v1.25/#podcondition-v1-core>PodConditions</a>
à travers lesquelles le Pod est ou non passé. Chaque élément
du tableau de PodCondition a six champs possibles :</p><ul><li><p>Le champ <code>lastProbeTime</code> fournit un timestamp auquel la condition du Pod
a été sondée pour la dernière fois.</p></li><li><p>Le champ <code>lastTransitionTime</code> fournit un timestamp auquel le Pod a changé de statut
pour la dernière fois.</p></li><li><p>Le champ <code>message</code> est un message lisible indiquant les détails de la transition.</p></li><li><p>Le champ <code>reason</code> est une raison unique, en un seul mot et en CamelCase de la transition
vers la dernière condition.</p></li><li><p>Le champ <code>status</code> est une chaîne de caractères avec les valeurs possibles "<code>True</code>", "<code>False</code>", et "<code>Unknown</code>".</p></li><li><p>Le champ <code>type</code> est une chaîne de caractères ayant une des valeurs suivantes :</p><ul><li><code>PodScheduled</code> : le Pod a été affecté à un nœud ;</li><li><code>Ready</code> : le Pod est prêt à servir des requêtes et doit être rajouté aux équilibreurs
de charge de tous les Services correspondants ;</li><li><code>Initialized</code> : tous les <a href=/fr/docs/concepts/workloads/pods/init-containers>init containers</a>
ont démarré correctement ;</li><li><code>ContainersReady</code> : tous les conteneurs du Pod sont prêts.</li></ul></li></ul><h2 id=sondes-du-conteneur>Sondes du Conteneur</h2><p>Une <a href=/docs/reference/generated/kubernetes-api/v1.25/#probe-v1-core>Sonde</a> (Probe) est un diagnostic
exécuté périodiquement par <a href=/docs/admin/kubelet/>kubelet</a>
sur un Conteneur. Pour exécuter un diagnostic, kubelet appelle un
<a href=https://godoc.org/k8s.io/kubernetes/pkg/api/v1#Handler>Handler</a> implémenté par
le Conteneur. Il existe trois types de handlers :</p><ul><li><p><a href=/docs/reference/generated/kubernetes-api/v1.25/#execaction-v1-core>ExecAction</a>:
Exécute la commande spécifiée à l'intérieur du Conteneur. Le diagnostic
est considéré réussi si la commande se termine avec un code de retour de 0.</p></li><li><p><a href=/docs/reference/generated/kubernetes-api/v1.25/#tcpsocketaction-v1-core>TCPSocketAction</a>:
Exécute un contrôle TCP sur l'adresse IP du Conteneur et sur un port spécifié.
Le diagnostic est considéré réussi si le port est ouvert.</p></li><li><p><a href=/docs/reference/generated/kubernetes-api/v1.25/#httpgetaction-v1-core>HTTPGetAction</a>:
Exécute une requête HTTP Get sur l'adresse IP du Conteneur et sur un port et
un chemin spécifiés. Le diagnostic est considéré réussi si la réponse a un code
de retour supérieur ou égal à 200 et inférieur à 400.</p></li></ul><p>Chaque sonde a un résultat parmi ces trois :</p><ul><li>Success: Le Conteneur a réussi le diagnostic.</li><li>Failure: Le Conteneur a échoué au diagnostic.</li><li>Unknown: L'exécution du diagnostic a échoué, et donc aucune action ne peut être prise.</li></ul><p>kubelet peut optionnellement exécuter et réagir à trois types de sondes sur des conteneurs
en cours d'exécution :</p><ul><li><p><code>livenessProbe</code> : Indique si le Conteneur est en cours d'exécution. Si
la liveness probe échoue, kubelet tue le Conteneur et le Conteneur
est soumis à sa <a href=#politique-de-redemarrage>politique de redémarrage</a> (restart policy).
Si un Conteneur ne fournit pas de liveness probe, l'état par défaut est <code>Success</code>.</p></li><li><p><code>readinessProbe</code> : Indique si le Conteneur est prêt à servir des requêtes.
Si la readiness probe échoue, le contrôleur de points de terminaison (Endpoints)
retire l'adresse IP du Pod des points de terminaison de tous les Services
correspodant au Pod. L'état par défaut avant le délai initial est
<code>Failure</code>. Si le Conteneur ne fournit pas de readiness probe, l'état par
défaut est <code>Success</code>.</p></li><li><p><code>startupProbe</code>: Indique si l'application à l'intérieur du conteneur a démarré.
Toutes les autres probes sont désactivées si une starup probe est fournie,
jusqu'à ce qu'elle réponde avec succès. Si la startup probe échoue, le kubelet
tue le conteneur, et le conteneur est assujetti à sa <a href=#politique-de-redemarrage>politique de redémarrage</a>.
Si un conteneur ne fournit pas de startup probe, l'état par défaut est <code>Success</code>.</p></li></ul><h3 id=quand-devez-vous-utiliser-une-liveness-probe>Quand devez-vous utiliser une liveness probe ?</h3><p>Si le process de votre Conteneur est capable de crasher de lui-même lorsqu'il
rencontre un problème ou devient inopérant, vous n'avez pas forcément besoin
d'une liveness probe ; kubelet va automatiquement exécuter l'action correcte
en accord avec la politique de redémarrage (<code>restartPolicy</code>) du Pod.</p><p>Si vous désirez que votre Conteneur soit tué et redémarré si une sonde échoue, alors
spécifiez une liveness probe et indiquez une valeur pour <code>restartPolicy</code> à Always
ou OnFailure.</p><h3 id=quand-devez-vous-utiliser-une-readiness-probe>Quand devez-vous utiliser une readiness probe ?</h3><div style=margin-top:10px;margin-bottom:10px><b>FEATURE STATE:</b> <code>Kubernetes v1.0 [stable]</code></div><p>Si vous voulez commencer à envoyer du trafic à un Pod seulement lorsqu'une sonde
réussit, spécifiez une readiness probe. Dans ce cas, la readiness probe peut être
la même que la liveness probe, mais l'existence de la readiness probe dans la spec
veut dire que le Pod va démarrer sans recevoir aucun trafic et va commencer
à recevoir du trafic après que la sonde réussisse.
Si votre Conteneur doit charger une grande quantité de données, des fichiers de
configuration ou exécuter des migrations au démarrage, spécifiez une readiness probe.</p><p>Si vous désirez que le Conteneur soit capable de se mettre en maintenance tout seul, vous
pouvez spécifier une readiness probe qui vérifie un point de terminaison spécifique au
readiness et différent de la liveness probe.</p><p>Notez que si vous voulez uniquement être capable de dérouter les requêtes lorsque
le Pod est supprimé, vous n'avez pas forcément besoin d'une readiness probe; lors
de sa suppression, le Pod se met automatiquement dans un état non prêt, que la
readiness probe existe ou non.
Le Pod reste dans le statut non prêt le temps que les Conteneurs du Pod s'arrêtent.</p><h3 id=quand-devez-vous-utiliser-une-startup-probe>Quand devez-vous utiliser une startup probe ?</h3><div style=margin-top:10px;margin-bottom:10px><b>FEATURE STATE:</b> <code>Kubernetes v1.16 [alpha]</code></div><p>Si votre conteneur démarre habituellement en plus de <code>initialDelaySeconds + failureThreshold × periodSeconds</code>,
vous devriez spécifier une startup probe qui vérifie le même point de terminaison que la liveness probe. La valeur par défaut pour <code>periodSeconds</code> est 30s.
Vous devriez alors mettre sa valeur <code>failureThreshold</code> suffisamment haute pour permettre au conteneur de démarrer, sans changer les valeurs par défaut de la liveness probe. Ceci aide à se protéger de deadlocks.</p><p>Pour plus d'informations sur la manière de mettre en place une liveness, readiness ou startup probe,
voir <a href=/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/>Configurer des Liveness, Readiness et Startup Probes</a>.</p><h2 id=statut-d-un-pod-et-d-un-conteneur>Statut d'un Pod et d'un Conteneur</h2><p>Pour des informations détaillées sur le statut d'un Pod et d'un Conteneur, voir
<a href=/docs/reference/generated/kubernetes-api/v1.25/#podstatus-v1-core>PodStatus</a>
et
<a href=/docs/reference/generated/kubernetes-api/v1.25/#containerstatus-v1-core>ContainerStatus</a>.
Notez que l'information rapportée comme statut d'un Pod dépend du
<a href=/docs/reference/generated/kubernetes-api/v1.25/#containerstatus-v1-core>ContainerState</a> actuel.</p><h2 id=états-d-un-conteneur>États d'un Conteneur</h2><p>Une fois que le Pod est assigné à un nœud par le scheduler, kubelet commence
à créer les conteneurs en utilisant le runtime de conteneurs. Il existe trois états possibles
pour les conteneurs : en attente (Waiting), en cours d'exécution (Running) et terminé (Terminated). Pour vérifier l'état d'un conteneur, vous pouvez utiliser <code>kubectl describe pod [POD_NAME]</code>. L'état est affiché pour chaque conteneur du Pod.</p><ul><li><p><code>Waiting</code> : état du conteneur par défaut. Si le conteneur n'est pas dans un état Running ou Terminated, il est dans l'état Waiting. Un conteneur dans l'état Waiting exécute
les opérations nécessaires, comme télécharger les images, appliquer des Secrets, etc. À côté
de cet état, un message et une raison sur l'état sont affichés pour vous fournir plus
d'informations.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#00f;font-weight:700>...</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>State</span>:<span style=color:#bbb>          </span>Waiting<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>   </span><span style=color:green;font-weight:700>Reason</span>:<span style=color:#bbb>       </span>ErrImagePull<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:#00f;font-weight:700>...</span><span style=color:#bbb>
</span></span></span></code></pre></div></li><li><p><code>Running</code> : Indique que le conteneur s'exécute sans problème. Le hook <code>postStart</code> (s'il existe) est exécuté avant que le conteneur entre dans l'état Running. Cet état affiche aussi le moment auquel le conteneur est entré dans l'état Running.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#00f;font-weight:700>...</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>   </span><span style=color:green;font-weight:700>State</span>:<span style=color:#bbb>          </span>Running<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>Started</span>:<span style=color:#bbb>      </span>Wed, 30 Jan 2019 16:46:38 +0530<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:#00f;font-weight:700>...</span><span style=color:#bbb>
</span></span></span></code></pre></div></li><li><p><code>Terminated</code>: Indique que le conteneur a terminé son exécution et s'est arrêté.
Un conteneur entre dans cet état lorsqu'il s'est exécuté avec succès ou lorsqu'il a
échoué pour une raison quelconque. De plus, une raison et un code de retour sont affichés,
ainsi que les moments de démarrage et d'arrêt du conteneur. Avant qu'un conteneur entre
dans l'état Terminated, le hook <code>preStop</code> est exécuté (s'il existe).</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#00f;font-weight:700>...</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>   </span><span style=color:green;font-weight:700>State</span>:<span style=color:#bbb>          </span>Terminated<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>     </span><span style=color:green;font-weight:700>Reason</span>:<span style=color:#bbb>       </span>Completed<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>     </span><span style=color:green;font-weight:700>Exit Code</span>:<span style=color:#bbb>    </span><span style=color:#666>0</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>     </span><span style=color:green;font-weight:700>Started</span>:<span style=color:#bbb>      </span>Wed, 30 Jan 2019 11:45:26 +0530<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>     </span><span style=color:green;font-weight:700>Finished</span>:<span style=color:#bbb>     </span>Wed, 30 Jan 2019 11:45:26 +0530<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb> </span>...<span style=color:#bbb>
</span></span></span></code></pre></div></li></ul><h2 id=pod-readiness-gate>Pod readiness</h2><div style=margin-top:10px;margin-bottom:10px><b>FEATURE STATE:</b> <code>Kubernetes v1.14 [stable]</code></div><p>Votre application peut injecter des données dans <code>PodStatus</code>.</p><p><em>Pod readiness</em>. Pour utiliser cette fonctionnalité, remplissez <code>readinessGates</code> dans le PodSpec avec
une liste de conditions supplémentaires que le kubelet évalue pour la disponibilité du Pod.</p><p>Les Readiness gates sont déterminées par l'état courant des champs <code>status.condition</code> du Pod.
Si Kubernetes ne peut pas trouver une telle condition dans le champs <code>status.conditions</code> d'un Pod, the statut de la condition
est mise par défaut à "<code>False</code>".</p><p>Voici un exemple :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:#00f;font-weight:700>...</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>readinessGates</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:green;font-weight:700>conditionType</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;www.example.com/feature-1&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>status</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>conditions</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:green;font-weight:700>type</span>:<span style=color:#bbb> </span>Ready <span style=color:#bbb> </span><span style=color:#080;font-style:italic># une PodCondition intégrée</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>status</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;False&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>lastProbeTime</span>:<span style=color:#bbb> </span><span style=color:#a2f;font-weight:700>null</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>lastTransitionTime</span>:<span style=color:#bbb> </span>2018-01-01T00:00:00Z<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:green;font-weight:700>type</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;www.example.com/feature-1&#34;</span><span style=color:#bbb>   </span><span style=color:#080;font-style:italic># une PodCondition supplémentaire</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>status</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;False&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>lastProbeTime</span>:<span style=color:#bbb> </span><span style=color:#a2f;font-weight:700>null</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>lastTransitionTime</span>:<span style=color:#bbb> </span>2018-01-01T00:00:00Z<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>containerStatuses</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:green;font-weight:700>containerID</span>:<span style=color:#bbb> </span>docker://abcd...<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>ready</span>:<span style=color:#bbb> </span><span style=color:#a2f;font-weight:700>true</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:#00f;font-weight:700>...</span><span style=color:#bbb>
</span></span></span></code></pre></div><p>Les conditions du Pod que vous ajoutez doivent avoir des noms qui sont conformes au <a href=/docs/concepts/overview/working-with-objects/labels/#syntax-and-character-set>format des étiquettes</a> de Kubernetes.</p><h3 id=statut-pod-disponibilité>Statut de la disponibilité d'un Pod</h3><p>La commande <code>kubectl patch</code> ne peut pas patcher le statut d'un objet.
Pour renseigner ces <code>status.conditions</code> pour le pod, les applications et
<a class=glossary-tooltip title='A specialized controller used to manage a custom resource' data-toggle=tooltip data-placement=top href=/docs/concepts/extend-kubernetes/operator/ target=_blank aria-label=operators>operators</a> doivent utiliser l'action <code>PATCH</code>.
Vous pouvez utiliser une <a href=/docs/reference/using-api/client-libraries/>bibliothèque client Kubernetes</a> pour
écrire du code qui renseigne les conditions particulières pour la disponibilité dun Pod.</p><p>Pour un Pod utilisant des conditions particulières, ce Pod est considéré prêt <strong>seulement</strong>
lorsque les deux déclarations ci-dessous sont vraies :</p><ul><li>Tous les conteneurs du Pod sont prêts.</li><li>Toutes les conditions spécifiées dans <code>ReadinessGates</code> sont <code>True</code>.</li></ul><p>Lorsque les conteneurs d'un Pod sont prêts mais qu'au moins une condition particulière
est manquante ou <code>False</code>, le kubelet renseigne la condition du Pod à <code>ContainersReady</code>.</p><h2 id=politique-de-redémarrage>Politique de redémarrage</h2><p>La structure PodSpec a un champ <code>restartPolicy</code> avec comme valeur possible
Always, OnFailure et Never. La valeur par défaut est Always.
<code>restartPolicy</code> s'applique à tous les Conteneurs du Pod. <code>restartPolicy</code> s'applique
seulement aux redémarrages des Conteneurs par kubelet sur le même nœud. Des conteneurs
terminés qui sont redémarrés par kubelet sont redémarrés avec un délai exponentiel
(10s, 20s, 40s ...) plafonné à cinq minutes, qui est réinitialisé après dix minutes
d'exécution normale. Comme discuté dans le
<a href=/docs/user-guide/pods/#durability-of-pods-or-lack-thereof>document sur les Pods</a>,
une fois attaché à un nœud, un Pod ne sera jamais rattaché à un autre nœud.</p><h2 id=durée-de-vie-d-un-pod>Durée de vie d'un Pod</h2><p>En général, les Pods restent jusqu'à ce qu'un humain ou un process de
<a class=glossary-tooltip title="Boucle de contrôle surveillant l'état partagé du cluster à travers l'apiserver et effectuant des changements en essayant de déplacer l'état actuel vers l'état désiré." data-toggle=tooltip data-placement=top href=/docs/admin/kube-controller-manager/ target=_blank aria-label=contrôleur>contrôleur</a> les supprime explicitement.</p><p>Le plan de contrôle nettoie les Pods terminés (avec une phase à <code>Succeeded</code> ou
<code>Failed</code>), lorsque le nombre de Pods excède le seuil configuré
(determiné par <code>terminated-pod-gc-threshold</code> dans le kube-controller-manager).
Ceci empêche une fuite de ressources lorsque les Pods sont créés et supprimés au fil du temps.</p><p>Il y a différents types de ressources pour créer des Pods :</p><ul><li><p>Utilisez un <a class=glossary-tooltip title='Objet API gérant une application répliquée.' data-toggle=tooltip data-placement=top href=/docs/concepts/workloads/controllers/deployment/ target=_blank aria-label=Déploiement>Déploiement</a>,
<a class=glossary-tooltip title='ReplicaSet ensures that a specified number of Pod replicas are running at one time' data-toggle=tooltip data-placement=top href=/docs/concepts/workloads/controllers/replicaset/ target=_blank aria-label=ReplicaSet>ReplicaSet</a> ou <a class=glossary-tooltip title="Gère le déploiement et la mise à l'échelle d'un ensemble de Pods, avec un stockage durable et des identifiants persistants pour chaque Pod." data-toggle=tooltip data-placement=top href=/fr/docs/concepts/workloads/controllers/statefulset/ target=_blank aria-label=StatefulSet>StatefulSet</a>
pour les Pods qui ne sont pas censés terminer, par exemple des serveurs web.</p></li><li><p>Utilisez un <a class=glossary-tooltip title='A finite or batch task that runs to completion.' data-toggle=tooltip data-placement=top href=/docs/concepts/workloads/controllers/job/ target=_blank aria-label=Job>Job</a>
pour les Pods qui sont censés se terminer une fois leur tâche accomplie. Les Jobs sont appropriés
seulement pour des Pods ayant <code>restartPolicy</code> égal à OnFailure ou Never.</p></li><li><p>Utilisez un <a class=glossary-tooltip title="S'assure qu'une copie d'un Pod s'exécute sur un ensemble de nœuds d'un cluster." data-toggle=tooltip data-placement=top href=/docs/concepts/workloads/controllers/daemonset target=_blank aria-label=DaemonSet>DaemonSet</a>
pour les Pods qui doivent s'exécuter sur chaque noeud éligible.</p></li></ul><p>Toutes les ressources de charges de travail contiennent une PodSpec. Il est recommandé de créer
la ressource de charges de travail appropriée et laisser le contrôleur de la ressource créer les Pods
pour vous, plutôt que de créer directement les Pods vous-même.</p><p>Si un nœud meurt ou est déconnecté du reste du cluster, Kubernetes applique
une politique pour mettre la <code>phase</code> de tous les Pods du nœud perdu à Failed.</p><h2 id=exemples>Exemples</h2><h3 id=exemple-avancé-de-liveness-probe>Exemple avancé de liveness probe</h3><p>Les Liveness probes sont exécutées par kubelet, toutes les requêtes sont donc faites
dans l'espace réseau de kubelet.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>labels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>test</span>:<span style=color:#bbb> </span>liveness<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>liveness-http<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>args</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- /server<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>k8s.gcr.io/liveness<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>livenessProbe</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>httpGet</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:#080;font-style:italic># lorsque &#34;host&#34; n&#39;est pas défini, &#34;PodIP&#34; sera utilisé</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:#080;font-style:italic># host: my-host</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:#080;font-style:italic># lorsque &#34;scheme&#34; n&#39;est pas défini, &#34;HTTP&#34; sera utilisé. &#34;HTTP&#34; et &#34;HTTPS&#34; sont les seules valeurs possibles</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:#080;font-style:italic># scheme: HTTPS</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>path</span>:<span style=color:#bbb> </span>/healthz<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>port</span>:<span style=color:#bbb> </span><span style=color:#666>8080</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>httpHeaders</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>X-Custom-Header<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>value</span>:<span style=color:#bbb> </span>Awesome<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>initialDelaySeconds</span>:<span style=color:#bbb> </span><span style=color:#666>15</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>timeoutSeconds</span>:<span style=color:#bbb> </span><span style=color:#666>1</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>liveness<span style=color:#bbb>
</span></span></span></code></pre></div><h3 id=exemples-d-états>Exemples d'états</h3><ul><li><p>Un Pod est en cours d'exécution et a un Conteneur. Le conteneur se termine avec succès.</p><ul><li>Écriture d'un événement de complétion.</li><li>Si <code>restartPolicy</code> est :<ul><li>Always : Redémarrage du Conteneur ; la <code>phase</code> du Pod reste à Running.</li><li>OnFailure : la <code>phase</code> du Pod passe à Succeeded.</li><li>Never : la <code>phase</code> du Pod passe à Succeeded.</li></ul></li></ul></li><li><p>Un Pod est en cours d'exécution et a un Conteneur. Le conteneur se termine en erreur.</p><ul><li>Écriture d'un événement d'échec.</li><li>Si <code>restartPolicy</code> est :<ul><li>Always : Redémarrage du Conteneur ; la <code>phase</code> du Pod reste à Running.</li><li>OnFailure : Redémarrage du Conteneur ; la <code>phase</code> du Pod reste à Running.</li><li>Never : la <code>phase</code> du Pod passe à Failed.</li></ul></li></ul></li><li><p>Un Pod est en cours d'exécution et a deux Conteneurs. Le conteneur 1 termine en erreur.</p><ul><li>Écriture d'un événement d'échec.</li><li>Si <code>restartPolicy</code> est :<ul><li>Always : Redémarrage du Conteneur ; la <code>phase</code> du Pod reste à Running.</li><li>OnFailure : Redémarrage du Conteneur ; la <code>phase</code> du Pod reste à Running.</li><li>Never : Le Conteneur n'est pas redémarré ; la <code>phase</code> du Pod reste à Running.</li></ul></li><li>Si Container 1 est arrêté, et Conteneur 2 se termine :<ul><li>Écriture d'un événement d'échec.</li><li>Si <code>restartPolicy</code> est :<ul><li>Always : Redémarrage du Conteneur ; la <code>phase</code> du Pod reste à Running.</li><li>OnFailure : Redémarrage du Conteneur ; la <code>phase</code> du Pod reste à Running.</li><li>Never : la <code>phase</code> du Pod passe à Failed.</li></ul></li></ul></li></ul></li><li><p>Un Pod est en cours d'exécution et a un Conteneur. Le Conteneur n'a plus assez de mémoire.</p><ul><li>Le Conteneur se termine en erreur.</li><li>Écriture d'un événement OOM.</li><li>Si <code>restartPolicy</code> est :<ul><li>Always : Redémarrage du Conteneur ; la <code>phase</code> du Pod reste à Running.</li><li>OnFailure : Redémarrage du Conteneur ; la <code>phase</code> du Pod reste à Running.</li><li>Never : Écriture d'un événement d'erreur ; la <code>phase</code> du Pod passe à Failed.</li></ul></li></ul></li><li><p>Le Pod est en cours d'exécution, et un disque meurt.</p><ul><li>Tous les conteneurs sont tués.</li><li>Écriture d'un événement approprié.</li><li>La <code>phase</code> du Pod devient Failed.</li><li>Si le Pod s'exécute sous un contrôleur, le Pod est recréé ailleurs.</li></ul></li><li><p>Le Pod est en cours d'exécution et son nœud est segmenté.</p><ul><li>Le contrôleur de Nœud attend un certain temps.</li><li>Le contrôleur de Nœud passe la <code>phase</code> du Pod à Failed.</li><li>Si le Pod s'exécute sous un contrôleur, le Pod est recréé ailleurs.</li></ul></li></ul><h2 id=a-suivre>A suivre</h2><ul><li><p>Apprenez par la pratique
<a href=/docs/tasks/configure-pod-container/attach-handler-lifecycle-event/>attacher des handlers à des événements de cycle de vie d'un conteneur</a>.</p></li><li><p>Apprenez par la pratique
<a href=/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/>configurer des liveness, readiness et startup probes</a>.</p></li><li><p>En apprendre plus sur les <a href=/docs/concepts/containers/container-lifecycle-hooks/>hooks de cycle de vie d'un Conteneur</a>.</p></li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-c8d62295ca703fdcef1aaf89fb4c916a>4 - Contraintes de propagation de topologie pour les Pods</h1><div style=margin-top:10px;margin-bottom:10px><b>FEATURE STATE:</b> <code>Kubernetes v1.18 [beta]</code></div><p>Vous pouvez utiliser des <em>contraintes de propagation de topologie</em> pour contrôler comment les <a class=glossary-tooltip title='Le plus petit et le plus simple des objets Kubernetes. Un Pod est un ensemble de conteneurs fonctionnant sur votre cluster.' data-toggle=tooltip data-placement=top href=/fr/docs/concepts/workloads/pods/pod-overview/ target=_blank aria-label=Pods>Pods</a> sont propagés à travers votre cluster parmi les domaines de défaillance comme les régions, zones, noeuds et autres domaines de topologie définis par l'utilisateur. Ceci peut aider à mettre en place de la haute disponibilité et à utiliser efficacement les ressources.</p><h2 id=conditions-préalables>Conditions préalables</h2><h3 id=autoriser-la-feature-gate>Autoriser la Feature Gate</h3><p>La <a href=/docs/reference/command-line-tools-reference/feature-gates/>feature gate</a> <code>EvenPodsSpread</code> doit être autorisée pour
<a class=glossary-tooltip title="Composant sur le master qui expose l'API Kubernetes. Il s'agit du front-end pour le plan de contrôle Kubernetes." data-toggle=tooltip data-placement=top href=/docs/reference/generated/kube-apiserver/ target=_blank aria-label="l'API Server">l'API Server</a> <strong>et</strong> le
<a class=glossary-tooltip title="Composant sur le master qui surveille les pods nouvellement créés qui ne sont pas assignés à un nœud et sélectionne un nœud sur lequel ils vont s'exécuter." data-toggle=tooltip data-placement=top href=/docs/reference/generated/kube-scheduler/ target=_blank aria-label=scheduler>scheduler</a>.</p><h3 id=labels-de-noeuds>Labels de noeuds</h3><p>Les contraintes de propagation de topologie reposent sur les labels de noeuds pour identifier le ou les domaines de topologie dans lesquels se trouve chacun des noeuds. Par exemple, un noeud pourrait avoir les labels: <code>node=node1,zone=us-east-1a,region=us-east-1</code></p><p>Supposons que vous ayez un cluster de 4 noeuds ayant les labels suivants:</p><pre tabindex=0><code>NAME    STATUS   ROLES    AGE     VERSION   LABELS
node1   Ready    &lt;none&gt;   4m26s   v1.16.0   node=node1,zone=zoneA
node2   Ready    &lt;none&gt;   3m58s   v1.16.0   node=node2,zone=zoneA
node3   Ready    &lt;none&gt;   3m17s   v1.16.0   node=node3,zone=zoneB
node4   Ready    &lt;none&gt;   2m43s   v1.16.0   node=node4,zone=zoneB
</code></pre><p>Une vue logique du cluster est celle-ci :</p><pre tabindex=0><code>+---------------+---------------+
|     zoneA     |     zoneB     |
+-------+-------+-------+-------+
| node1 | node2 | node3 | node4 |
+-------+-------+-------+-------+
</code></pre><p>Plutôt que d'appliquer des labels manuellement, vous pouvez aussi réutiliser les <a href=/docs/reference/kubernetes-api/labels-annotations-taints/>labels réputés</a> qui sont créés et renseignés automatiquement dans la plupart des clusters.</p><h2 id=contraintes-de-propagation-pour-les-pods>Contraintes de propagation pour les Pods</h2><h3 id=api>API</h3><p>Le champ <code>pod.spec.topologySpreadConstraints</code> est introduit dans 1.16 comme suit :</p><pre tabindex=0><code>apiVersion: v1
kind: Pod
metadata:
  name: mypod
spec:
  topologySpreadConstraints:
    - maxSkew: &lt;integer&gt;
      minDomains: &lt;integer&gt;
      topologyKey: &lt;string&gt;
      whenUnsatisfiable: &lt;string&gt;
      labelSelector: &lt;object&gt;
</code></pre><p>Vous pouvez définir une ou plusieurs <code>topologySpreadConstraint</code> pour indiquer au kube-scheduler comment placer chaque nouveau Pod par rapport aux Pods déjà existants dans votre cluster. Les champs sont :</p><ul><li><strong>maxSkew</strong> décrit le degré avec lequel les Pods peuvent être inégalement distribués. C'est la différence maximale permise entre le nombre de Pods correspondants entre deux quelconques domaines de topologie d'un type donné. Il doit être supérieur à zéro.</li><li><strong>topologyKey</strong> est la clé des labels de noeuds. Si deux noeuds sont étiquettés avec cette clé et ont des valeurs égales pour ce label, le scheduler considère les deux noeuds dans la même topologie. Le scheduler essaie de placer un nombre équilibré de Pods dans chaque domaine de topologie.</li><li><strong>whenUnsatisfiable</strong> indique comment traiter un Pod qui ne satisfait pas les contraintes de propagation :<ul><li><code>DoNotSchedule</code> (défaut) indique au scheduler de ne pas le programmer.</li><li><code>ScheduleAnyway</code> indique au scheduler de le programmer, tout en priorisant les noeuds minimisant le biais (<em>skew</em>).</li></ul></li><li><strong>labelSelector</strong> est utilisé pour touver les Pods correspondants. Les Pods correspondants à ce sélecteur de labels sont comptés pour déterminer le nombre de Pods dans leurs domaines de topologie correspodants. Voir <a href=/docs/concepts/overview/working-with-objects/labels/#label-selectors>Sélecteurs de labels</a> pour plus de détails.</li></ul><p>Vous pouvez en savoir plus sur ces champ en exécutant <code>kubectl explain Pod.spec.topologySpreadConstraints</code>.</p><h3 id=exemple-une-topologyspreadconstraint>Exemple : Une TopologySpreadConstraint</h3><p>Supposons que vous ayez un cluster de 4 noeuds où 3 Pods étiquettés <code>foo:bar</code> sont placés sur node1, node2 et node3 respectivement (<code>P</code> représente un Pod) :</p><pre tabindex=0><code>+---------------+---------------+
|     zoneA     |     zoneB     |
+-------+-------+-------+-------+
| node1 | node2 | node3 | node4 |
+-------+-------+-------+-------+
|   P   |   P   |   P   |       |
+-------+-------+-------+-------+
</code></pre><p>Si nous voulons qu'un nouveau Pod soit uniformément réparti avec les Pods existants à travers les zones, la spec peut être :</p><div class=highlight><div class=copy-code-icon style=text-align:right><a href=https://raw.githubusercontent.com/kubernetes/website/main/content/fr/examples/pods/topology-spread-constraints/one-constraint.yaml download=pods/topology-spread-constraints/one-constraint.yaml><code>pods/topology-spread-constraints/one-constraint.yaml</code></a>
<img src=/images/copycode.svg style=max-height:24px;cursor:pointer onclick='copyCode("pods-topology-spread-constraints-one-constraint-yaml")' title="Copy pods/topology-spread-constraints/one-constraint.yaml to clipboard"></img></div><div class=includecode id=pods-topology-spread-constraints-one-constraint-yaml><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>mypod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>labels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>foo</span>:<span style=color:#bbb> </span>bar<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>topologySpreadConstraints</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>maxSkew</span>:<span style=color:#bbb> </span><span style=color:#666>1</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>topologyKey</span>:<span style=color:#bbb> </span>zone<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>whenUnsatisfiable</span>:<span style=color:#bbb> </span>DoNotSchedule<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>labelSelector</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>matchLabels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>foo</span>:<span style=color:#bbb> </span>bar<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>pause<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>k8s.gcr.io/pause:3.1<span style=color:#bbb>
</span></span></span></code></pre></div></div></div><p><code>topologyKey: zone</code> implique que la distribution uniforme sera uniquement appliquée pour les noeuds ayant le label "zone:&lt;any value>" présent. <code>whenUnsatisfiable: DoNotSchedule</code> indique au scheduler de laisser le Pod dans l'état Pending si le Pod entrant ne peut pas satisfaire la contrainte.</p><p>Si le scheduler plaçait ce Pod entrant dans "zoneA", la distribution des Pods deviendrait [3, 1], et le biais serait de 2 (3 - 1) - ce qui va à l'encontre de <code>maxSkew: 1</code>. Dans cet exemple, le Pod entrant peut uniquement être placé dans "zoneB":</p><pre tabindex=0><code>+---------------+---------------+      +---------------+---------------+
|     zoneA     |     zoneB     |      |     zoneA     |     zoneB     |
+-------+-------+-------+-------+      +-------+-------+-------+-------+
| node1 | node2 | node3 | node4 |  OR  | node1 | node2 | node3 | node4 |
+-------+-------+-------+-------+      +-------+-------+-------+-------+
|   P   |   P   |   P   |   P   |      |   P   |   P   |  P P  |       |
+-------+-------+-------+-------+      +-------+-------+-------+-------+
</code></pre><p>Vous pouvez ajuster la spec du Pod pour pour répondre à divers types d'exigences :</p><ul><li>Changez <code>maxSkew</code> pour une valeur plus grande comme "2" pour que le Pod entrant puisse aussi être placé dans la "zoneA".</li><li>Changez <code>topologyKey</code> pour "node" pour distribuer les Pods uniformément à travers les noeuds et non plus les zones. Dans l'exemple ci-dessus, si <code>maxSkew</code> reste à "1", le Pod entrant peut être uniquement placé dans "node4".</li><li>Changez <code>whenUnsatisfiable: DoNotSchedule</code> en <code>whenUnsatisfiable: ScheduleAnyway</code> pour s'assurer que le Pod est toujours programmable (en supposant que les autres APIs de scheduling soient satisfaites). Cependant, il sera de préférence placé dans la topologie de domaine ayant le moins de Pods correspondants. (Prenez note que cette préférence est normalisée conjointement avec d'autres priorités de scheduling interne comme le ratio d'usage de ressources, etc.)</li></ul><h3 id=example-plusieurs-topologyspreadconstraints>Example: Plusieurs TopologySpreadConstraints</h3><p>Cela s'appuie sur l'exemple précédent. Supposons que vous ayez un cluster de 4 noeuds où 3 Pods étiquetés <code>foo:bar</code> sont placés sur node1, node2 et node3 respectivement (<code>P</code> représente un Pod):</p><pre tabindex=0><code>+---------------+---------------+
|     zoneA     |     zoneB     |
+-------+-------+-------+-------+
| node1 | node2 | node3 | node4 |
+-------+-------+-------+-------+
|   P   |   P   |   P   |       |
+-------+-------+-------+-------+
</code></pre><p>Vous pouvez utiliser 2 TopologySpreadConstraints pour contrôler la répartition des Pods aussi bien dans les zones que dans les noeuds :</p><div class=highlight><div class=copy-code-icon style=text-align:right><a href=https://raw.githubusercontent.com/kubernetes/website/main/content/fr/examples/pods/topology-spread-constraints/two-constraints.yaml download=pods/topology-spread-constraints/two-constraints.yaml><code>pods/topology-spread-constraints/two-constraints.yaml</code></a>
<img src=/images/copycode.svg style=max-height:24px;cursor:pointer onclick='copyCode("pods-topology-spread-constraints-two-constraints-yaml")' title="Copy pods/topology-spread-constraints/two-constraints.yaml to clipboard"></img></div><div class=includecode id=pods-topology-spread-constraints-two-constraints-yaml><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>mypod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>labels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>foo</span>:<span style=color:#bbb> </span>bar<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>topologySpreadConstraints</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>maxSkew</span>:<span style=color:#bbb> </span><span style=color:#666>1</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>topologyKey</span>:<span style=color:#bbb> </span>zone<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>whenUnsatisfiable</span>:<span style=color:#bbb> </span>DoNotSchedule<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>labelSelector</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>matchLabels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>foo</span>:<span style=color:#bbb> </span>bar<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>maxSkew</span>:<span style=color:#bbb> </span><span style=color:#666>1</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>topologyKey</span>:<span style=color:#bbb> </span>node<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>whenUnsatisfiable</span>:<span style=color:#bbb> </span>DoNotSchedule<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>labelSelector</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>matchLabels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>foo</span>:<span style=color:#bbb> </span>bar<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>pause<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>k8s.gcr.io/pause:3.1<span style=color:#bbb>
</span></span></span></code></pre></div></div></div><p>Dans ce cas, pour satisfaire la première contrainte, le Pod entrant peut uniquement être placé dans "zoneB" ; alors que pour satisfaire la seconde contrainte, le Pod entrant peut uniquement être placé dans "node4". Le résultat étant l'intersection des résultats des 2 contraintes, l'unique option possible est de placer le Pod entrant dans "node4".</p><p>Plusieurs contraintes peuvent entraîner des conflits. Supposons que vous ayez un cluster de 3 noeuds couvrant 2 zones :</p><pre tabindex=0><code>+---------------+-------+
|     zoneA     | zoneB |
+-------+-------+-------+
| node1 | node2 | node3 |
+-------+-------+-------+
|  P P  |   P   |  P P  |
+-------+-------+-------+
</code></pre><p>Si vous appliquez "two-constraints.yaml" à ce cluster, vous noterez que "mypod" reste dans l'état <code>Pending</code>. Cela parce que : pour satisfaire la première contrainte, "mypod" peut uniquement être placé dans "zoneB"; alors que pour satisfaire la seconde contrainte, "mypod" peut uniquement être placé sur "node2". Ainsi, le résultat de l'intersection entre "zoneB" et "node2" ne retourne rien.</p><p>Pour surmonter cette situation, vous pouvez soit augmenter <code>maxSkew</code>, soit modifier une des contraintes pour qu'elle utilise <code>whenUnsatisfiable: ScheduleAnyway</code>.</p><h3 id=conventions>Conventions</h3><p>Il existe quelques conventions implicites qu'il est intéressant de noter ici :</p><ul><li><p>Seuls le Pods du même espace de noms que le Pod entrant peuvent être des candidats pour la correspondance.</p></li><li><p>Les noeuds sans label <code>topologySpreadConstraints[*].topologyKey</code> seront ignorés. Cela induit que :</p><ol><li>les Pods localisés sur ces noeuds n'impactent pas le calcul de <code>maxSkew</code> - dans l'exemple ci-dessus, supposons que "node1" n'a pas de label "zone", alors les 2 Pods ne seront pas comptés, et le Pod entrant sera placé dans "zoneA".</li><li>le Pod entrant n'a aucune chance d'être programmé sur ce type de noeuds - dans l'exemple ci-dessus, supposons qu'un "node5" portant un label <code>{zone-typo: zoneC}</code> joigne le cluster ; il sera ignoré, en raison de l'absence de label "zone".</li></ol></li><li><p>Faites attention à ce qui arrive lorsque le <code>topologySpreadConstraints[*].labelSelector</code> du Pod entrant ne correspond pas à ses propres labels. Dans l'exemple ci-dessus, si nous supprimons les labels du Pod entrant, il sera toujours placé dans "zoneB" car les contraintes sont toujours satisfaites. Cependant, après le placement, le degré de déséquilibre du cluster reste inchangé - zoneA contient toujours 2 Pods ayant le label {foo:bar}, et zoneB contient 1 Pod cayant le label {foo:bar}. Si ce n'est pas ce que vous attendez, nous recommandons que <code>topologySpreadConstraints[*].labelSelector</code> du workload corresponde à ses propres labels.</p></li><li><p>Si le Pod entrant a défini <code>spec.nodeSelector</code> ou <code>spec.affinity.nodeAffinity</code>, les noeuds non correspondants seront ignorés.</p><p>Supposons que vous ayez un cluster de 5 noeuds allant de zoneA à zoneC :</p><pre tabindex=0><code>+---------------+---------------+-------+
|     zoneA     |     zoneB     | zoneC |
+-------+-------+-------+-------+-------+
| node1 | node2 | node3 | node4 | node5 |
+-------+-------+-------+-------+-------+
|   P   |   P   |   P   |       |       |
+-------+-------+-------+-------+-------+
</code></pre><p>et vous savez que "zoneC" doit être exclue. Dans ce cas, vous pouvez écrire le yaml ci-dessous, pour que "mypod" soit placé dans "zoneB" plutôt que dans "zoneC". <code>spec.nodeSelector</code> est pris en compte de la même manière.</p><div class=highlight><div class=copy-code-icon style=text-align:right><a href=https://raw.githubusercontent.com/kubernetes/website/main/content/fr/examples/pods/topology-spread-constraints/one-constraint-with-nodeaffinity.yaml download=pods/topology-spread-constraints/one-constraint-with-nodeaffinity.yaml><code>pods/topology-spread-constraints/one-constraint-with-nodeaffinity.yaml</code></a>
<img src=/images/copycode.svg style=max-height:24px;cursor:pointer onclick='copyCode("pods-topology-spread-constraints-one-constraint-with-nodeaffinity-yaml")' title="Copy pods/topology-spread-constraints/one-constraint-with-nodeaffinity.yaml to clipboard"></img></div><div class=includecode id=pods-topology-spread-constraints-one-constraint-with-nodeaffinity-yaml><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Pod<span style=color:#bbb>
    </span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
    </span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
    </span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>mypod<span style=color:#bbb>
    </span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>labels</span>:<span style=color:#bbb>
    </span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>foo</span>:<span style=color:#bbb> </span>bar<span style=color:#bbb>
    </span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
    </span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>topologySpreadConstraints</span>:<span style=color:#bbb>
    </span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>maxSkew</span>:<span style=color:#bbb> </span><span style=color:#666>1</span><span style=color:#bbb>
    </span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>topologyKey</span>:<span style=color:#bbb> </span>zone<span style=color:#bbb>
    </span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>whenUnsatisfiable</span>:<span style=color:#bbb> </span>DoNotSchedule<span style=color:#bbb>
    </span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>labelSelector</span>:<span style=color:#bbb>
    </span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>matchLabels</span>:<span style=color:#bbb>
    </span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>foo</span>:<span style=color:#bbb> </span>bar<span style=color:#bbb>
    </span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>affinity</span>:<span style=color:#bbb>
    </span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>nodeAffinity</span>:<span style=color:#bbb>
    </span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>requiredDuringSchedulingIgnoredDuringExecution</span>:<span style=color:#bbb>
    </span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>nodeSelectorTerms</span>:<span style=color:#bbb>
    </span></span></span><span style=display:flex><span><span style=color:#bbb>        </span>- <span style=color:green;font-weight:700>matchExpressions</span>:<span style=color:#bbb>
    </span></span></span><span style=display:flex><span><span style=color:#bbb>          </span>- <span style=color:green;font-weight:700>key</span>:<span style=color:#bbb> </span>zone<span style=color:#bbb>
    </span></span></span><span style=display:flex><span><span style=color:#bbb>            </span><span style=color:green;font-weight:700>operator</span>:<span style=color:#bbb> </span>NotIn<span style=color:#bbb>
    </span></span></span><span style=display:flex><span><span style=color:#bbb>            </span><span style=color:green;font-weight:700>values</span>:<span style=color:#bbb>
    </span></span></span><span style=display:flex><span><span style=color:#bbb>            </span>- zoneC<span style=color:#bbb>
    </span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
    </span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>pause<span style=color:#bbb>
    </span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>k8s.gcr.io/pause:3.1<span style=color:#bbb>
    </span></span></span></code></pre></div></div></div></li></ul><h3 id=contraintes-par-défaut-au-niveau-du-cluster>Contraintes par défaut au niveau du cluster</h3><div style=margin-top:10px;margin-bottom:10px><b>FEATURE STATE:</b> <code>Kubernetes v1.18 [alpha]</code></div><p>Il est possible de définir des contraintes de propagation de topologie par défaut pour un cluster. Les contraintes de propagation de topologie sont appliquées à un Pod si et seulement si :</p><ul><li>Il ne définit aucune contrainte dans son <code>.spec.topologySpreadConstraints</code>.</li><li>Il appartient à un service, replication controller, replica set ou stateful set.</li></ul><p>Les contraintes par défaut peuvent être définies comme arguments du plugin <code>PodTopologySpread</code>
dans un <a href=/docs/reference/scheduling/profiles>profil de scheduling</a>.
Les contraintes sont spécifiées avec la même <a href=#api>API ci-dessus</a>, à l'exception que
<code>labelSelector</code> doit être vide. Les sélecteurs sont calculés à partir des services,
replication controllers, replica sets ou stateful sets auxquels le Pod appartient.</p><p>Un exemple de configuration pourrait ressembler à :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>kubescheduler.config.k8s.io/v1alpha2<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>KubeSchedulerConfiguration<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>profiles</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>schedulerName</span>:<span style=color:#bbb> </span>default-scheduler<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>pluginConfig</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>PodTopologySpread<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>args</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>defaultConstraints</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>            </span>- <span style=color:green;font-weight:700>maxSkew</span>:<span style=color:#bbb> </span><span style=color:#666>1</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>              </span><span style=color:green;font-weight:700>topologyKey</span>:<span style=color:#bbb> </span>topology.kubernetes.io/zone<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>              </span><span style=color:green;font-weight:700>whenUnsatisfiable</span>:<span style=color:#bbb> </span>ScheduleAnyway<span style=color:#bbb>
</span></span></span></code></pre></div><div class="alert alert-info note callout" role=alert><strong>Note:</strong> Le score produit par les contraintes de scheduling par défaut peuvent rentrer en conflit avec le score
produit par le <a href=/docs/reference/scheduling/profiles/#scheduling-plugins>plugin <code>DefaultPodTopologySpread</code></a>.
Il est recommandé de désactiver ce plugin dans le profil de scheduling lorsque vous utilisez des contraintes
par défaut pour <code>PodTopologySpread</code>.</div><h2 id=comparaison-avec-podaffinity-podantiaffinity>Comparaison avec PodAffinity/PodAntiAffinity</h2><p>Dans Kubernetes, les directives relatives aux "Affinités" contrôlent comment les Pods sont
programmés - plus regroupés ou plus dispersés.</p><ul><li>Pour <code>PodAffinity</code>, vous pouvez essayer de regrouper un certain nombre de Pods dans des domaines de topologie qualifiés,</li><li>Pour <code>PodAntiAffinity</code>, seulement un Pod peut être programmé dans un domaine de topologie unique.</li></ul><p>La fonctionnalité "EvenPodsSpread" fournit des options flexibles pour distribuer des Pods uniformément sur différents domaines de topologie - pour mettre en place de la haute disponibilité ou réduire les coûts. Cela peut aussi aider
au rolling update des charges de travail et à la mise à l'échelle de réplicas. Voir <a href=https://github.com/kubernetes/enhancements/tree/master/keps/sig-scheduling/895-pod-topology-spread#motivation>Motivations</a> pour plus de détails.</p><h2 id=limitations-connues>Limitations connues</h2><p>En version 1.18, pour laquelle cette fonctionnalité est en Beta, il y a quelques limitations connues :</p><ul><li>Réduire un Déploiement peut résulter en une distrubution désiquilibrée des Pods.</li><li>Les Pods correspondants sur des noeuds taintés sont respectés. Voir <a href=https://github.com/kubernetes/kubernetes/issues/80921>Issue 80921</a></li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-1ccbd4eeded6ab138d98b59175bd557e>5 - Init Containers</h1><p>Cette page fournit une vue d'ensemble des <em>conteneurs d'initialisation</em> (init containers) : des conteneurs spécialisés qui s'exécutent avant les conteneurs d'application dans un <a class=glossary-tooltip title='Le plus petit et le plus simple des objets Kubernetes. Un Pod est un ensemble de conteneurs fonctionnant sur votre cluster.' data-toggle=tooltip data-placement=top href=/fr/docs/concepts/workloads/pods/pod-overview/ target=_blank aria-label=Pod>Pod</a>.
Les init containers peuvent contenir des utilitaires ou des scripts d'installation qui ne sont pas présents dans une image d'application.</p><p>Vous pouvez spécifier des init containers dans la spécification du Pod à côté du tableau <code>containers</code> (qui décrit les conteneurs d'application)</p><h2 id=comprendre-les-init-containers>Comprendre les init containers</h2><p>Un <a class=glossary-tooltip title='Le plus petit et le plus simple des objets Kubernetes. Un Pod est un ensemble de conteneurs fonctionnant sur votre cluster.' data-toggle=tooltip data-placement=top href=/fr/docs/concepts/workloads/pods/pod-overview/ target=_blank aria-label=Pod>Pod</a> peut avoir plusieurs conteneurs exécutant des applications mais peut aussi avoir un ou plusieurs init containers, qui sont exécutés avant que les conteneurs d'application ne démarrent.</p><p>Les init containers se comportent comme les conteneurs réguliers, avec quelques différences :</p><ul><li>Les init containers s'exécutent toujours jusqu'à la complétion.</li><li>Chaque init container doit se terminer avec succès avant que le prochain ne démarre.</li></ul><p>Si le init container d'un Pod échoue, Kubernetes redémarre le Pod à répétition jusqu'à ce que le init container se termine avec succès.
Cependant, si le Pod a une <code>restartPolicy</code> à "Never", Kubernetes ne redémarre pas le Pod.</p><p>Afin de spécifier un init container pour un Pod, il faut ajouter le champ <code>initContainers</code> dans la spécification du Pod, comme un
tableau d'objets de type <a href=/docs/reference/generated/kubernetes-api/v1.25/#container-v1-core>Container</a>, au même niveau que le tableau d'applications <code>containers</code>.
Le statut des init containers est retourné dans le champ <code>.status.initContainerStatuses</code>
comme un tableau des statuts du conteneur (comparable au champ <code>.status.containerStatuses</code>).</p><h3 id=différences-avec-les-conteneurs-réguliers>Différences avec les conteneurs réguliers</h3><p>Les init containers supportent tous les champs et fonctionnalités des conteneurs d'application
incluant les limites de ressources, les volumes et les paramètres de sécurité.
Cependant, les demandes de ressources pour un init container sont gérées différemment des
limites de ressources, tel que documenté dans <a href=#ressources>Ressources</a>.</p><p>De plus, les init containers ne supportent pas les readiness probes parce que ces conteneurs
s'exécutent jusqu'au bout avant que le Pod soit prêt.</p><p>Si l'on spécifie plusieurs init containers pour un Pod, Kubelet exécute chaque
init container de manière séquentielle.
Chaque init container doit se terminer avec succès avant que le prochain ne puisse s'exécuter.
Lorsque tous les init containers se sont exécutés jusqu'au bout, Kubelet initialise
les conteneurs d'application pour le Pod et les exécute comme d'habitude.</p><h2 id=utiliser-les-init-containers>Utiliser les init containers</h2><p>Puisque les init containers ont des images séparées des conteneurs d'application,
ils apportent certains avantages pour du code de mise en route :</p><ul><li>Les init containers peuvent contenir des utilitaires ou du code de configuration personnalisé
qui ne sont pas présents dans une image d'application.
Par exemple, il n'y a pas besoin de faire hériter une image d'une autre (<code>FROM</code>) seulement pour utiliser
un outil comme <code>sed</code>, <code>awk</code>, <code>python</code>, ou <code>dig</code> pendant l'installation.</li><li>Les init containers peuvent exécuter en toute sécurité des utilitaires qui rendraient moins sécurisée une image de conteneur d'application.</li><li>Les rôles "builder" et "deployer" d'une image d'application peuvent travailler indépendamment sans qu'il n'y ait besoin
de créer conjointement une seule image d'application.</li><li>Les init containers peuvent s'exécuter avec une vue du système de fichiers différente de celle des conteneurs d'application dans le même Pod. Par conséquent, on peut leur donner accès aux <a class=glossary-tooltip title='Stores sensitive information, such as passwords, OAuth tokens, and ssh keys.' data-toggle=tooltip data-placement=top href=/docs/concepts/configuration/secret/ target=_blank aria-label=Secrets>Secrets</a>, auxquels les conteneurs d'application n'ont pas accès.</li><li>Puisque les init containers s'exécutent jusqu'à la complétion avant qu'un conteneur d'application ne démarre, les init containers
offrent un mécanisme pour bloquer ou retarder le démarrage d'un conteneur d'application tant qu'un ensemble de préconditions n'est pas respecté. Une fois que les préconditions sont respectées, tous les conteneurs d'application dans un Pod peuvent démarrer en parallèle.</li></ul><h3 id=exemples>Exemples</h3><p>Voici plusieurs idées pour utiliser les init containers :</p><ul><li><p>Attendre qu'un <a class=glossary-tooltip title="Un moyen d'exposer une application s'exécutant sur un ensemble de pods en tant que service réseau." data-toggle=tooltip data-placement=top href=/fr/docs/concepts/services-networking/service/ target=_blank aria-label=Service>Service</a> soit créé,
en utilisant une commande shell d'une ligne telle que :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span><span style=color:#a2f;font-weight:700>for</span> i in <span style=color:#666>{</span>1..100<span style=color:#666>}</span>; <span style=color:#a2f;font-weight:700>do</span> sleep 1; <span style=color:#a2f;font-weight:700>if</span> dig myservice; <span style=color:#a2f;font-weight:700>then</span> <span style=color:#a2f>exit</span> 0; <span style=color:#a2f;font-weight:700>fi</span>; <span style=color:#a2f;font-weight:700>done</span>; <span style=color:#a2f>exit</span> <span style=color:#666>1</span>
</span></span></code></pre></div></li><li><p>Enregistrer ce Pod à un serveur distant depuis l'API downward avec une commande telle que :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>curl -X POST http://<span style=color:#b8860b>$MANAGEMENT_SERVICE_HOST</span>:<span style=color:#b8860b>$MANAGEMENT_SERVICE_PORT</span>/register -d <span style=color:#b44>&#39;instance=$(&lt;POD_NAME&gt;)&amp;ip=$(&lt;POD_IP&gt;)&#39;</span>
</span></span></code></pre></div></li><li><p>Attendre un certain temps avant de démarrer le conteneur d'application avec une commande telle que :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>sleep <span style=color:#666>60</span>
</span></span></code></pre></div></li><li><p>Cloner un dépôt Git dans un <a class=glossary-tooltip title="Un répertoire contenant des données, accessible aux conteneurs d'un pod." data-toggle=tooltip data-placement=top href=/fr/docs/concepts/storage/volumes/ target=_blank aria-label=Volume>Volume</a></p></li><li><p>Placer des valeurs dans un fichier de configuration et exécuter un outil de templating pour générer
dynamiquement un fichier de configuration pour le conteneur d'application principal.
Par exemple, placer la valeur <code>POD_IP</code> dans une configuration et générer le fichier de configuration de l'application principale
en utilisant Jinja.</p></li></ul><h4 id=les-init-containers-en-utilisation>Les init containers en utilisation</h4><p>Cet exemple définit un simple Pod possédant deux init containers.
Le premier attend <code>myservice</code> et le second attend <code>mydb</code>. Une fois que les deux
init containers terminent leur exécution, le Pod exécute le conteneur d'application décrit dans sa section <code>spec</code>.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>myapp-pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>labels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>app.kubernetes.io/name</span>:<span style=color:#bbb> </span>MyApp<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>myapp-container<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>busybox:1.28<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>command</span>:<span style=color:#bbb> </span>[<span style=color:#b44>&#39;sh&#39;</span>,<span style=color:#bbb> </span><span style=color:#b44>&#39;-c&#39;</span>,<span style=color:#bbb> </span><span style=color:#b44>&#39;echo &#34;L&#39;&#39;app s&#39;&#39;exécute!&#34; &amp;&amp; sleep 3600&#39;</span>]<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>initContainers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>init-myservice<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>busybox:1.28<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>command</span>:<span style=color:#bbb> </span>[<span style=color:#b44>&#39;sh&#39;</span>,<span style=color:#bbb> </span><span style=color:#b44>&#39;-c&#39;</span>,<span style=color:#bbb> </span><span style=color:#b44>&#34;until nslookup myservice.$(cat /var/run/secrets/kubernetes.io/serviceaccount/namespace).svc.cluster.local; do echo en attente de myservice; sleep 2; done&#34;</span>]<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>init-mydb<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>busybox:1.28<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>command</span>:<span style=color:#bbb> </span>[<span style=color:#b44>&#39;sh&#39;</span>,<span style=color:#bbb> </span><span style=color:#b44>&#39;-c&#39;</span>,<span style=color:#bbb> </span><span style=color:#b44>&#34;until nslookup mydb.$(cat /var/run/secrets/kubernetes.io/serviceaccount/namespace).svc.cluster.local; do echo en attente de mydb; sleep 2; done&#34;</span>]<span style=color:#bbb>
</span></span></span></code></pre></div><p>Les fichiers YAML suivants résument les services <code>mydb</code> et <code>myservice</code> :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Service<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>myservice<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>ports</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>protocol</span>:<span style=color:#bbb> </span>TCP<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>port</span>:<span style=color:#bbb> </span><span style=color:#666>80</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>targetPort</span>:<span style=color:#bbb> </span><span style=color:#666>9376</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:#00f;font-weight:700>---</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Service<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>mydb<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>ports</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>protocol</span>:<span style=color:#bbb> </span>TCP<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>port</span>:<span style=color:#bbb> </span><span style=color:#666>80</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>targetPort</span>:<span style=color:#bbb> </span><span style=color:#666>9377</span><span style=color:#bbb>
</span></span></span></code></pre></div><p>Vous pouvez démarrer ce Pod en exécutant :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl apply -f myapp.yaml
</span></span></code></pre></div><pre tabindex=0><code>pod/myapp-pod created
</code></pre><p>Et vérifier son statut avec :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get -f myapp.yaml
</span></span></code></pre></div><pre tabindex=0><code>NAME        READY     STATUS     RESTARTS   AGE
myapp-pod   0/1       Init:0/2   0          6m
</code></pre><p>ou pour plus de détails :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl describe -f myapp.yaml
</span></span></code></pre></div><pre tabindex=0><code>Name:          myapp-pod
Namespace:     default
[...]
Labels:        app.kubernetes.io/name=MyApp
Status:        Pending
[...]
Init Containers:
  init-myservice:
[...]
    State:         Running
[...]
  init-mydb:
[...]
    State:         Waiting
      Reason:      PodInitializing
    Ready:         False
[...]
Containers:
  myapp-container:
[...]
    State:         Waiting
      Reason:      PodInitializing
    Ready:         False
[...]
Events:
  FirstSeen    LastSeen    Count    From                      SubObjectPath                           Type          Reason        Message
  ---------    --------    -----    ----                      -------------                           --------      ------        -------
  16s          16s         1        {default-scheduler }                                              Normal        Scheduled     Successfully assigned myapp-pod to 172.17.4.201
  16s          16s         1        {kubelet 172.17.4.201}    spec.initContainers{init-myservice}     Normal        Pulling       pulling image &#34;busybox&#34;
  13s          13s         1        {kubelet 172.17.4.201}    spec.initContainers{init-myservice}     Normal        Pulled        Successfully pulled image &#34;busybox&#34;
  13s          13s         1        {kubelet 172.17.4.201}    spec.initContainers{init-myservice}     Normal        Created       Created container with docker id 5ced34a04634; Security:[seccomp=unconfined]
  13s          13s         1        {kubelet 172.17.4.201}    spec.initContainers{init-myservice}     Normal        Started       Started container with docker id 5ced34a04634
</code></pre><p>Pour voir les logs des init containers dans ce Pod, exécuter :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl logs myapp-pod -c init-myservice <span style=color:#080;font-style:italic># Inspecter le premier init container</span>
</span></span><span style=display:flex><span>kubectl logs myapp-pod -c init-mydb      <span style=color:#080;font-style:italic># Inspecter le second init container</span>
</span></span></code></pre></div><p>À ce stade, ces init containers attendent de découvrir les services nommés
<code>mydb</code> et <code>myservice</code>.</p><p>Voici une configuration que vous pouvez utiliser pour faire apparaître ces Services :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#00f;font-weight:700>---</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Service<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>myservice<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>ports</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>protocol</span>:<span style=color:#bbb> </span>TCP<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>port</span>:<span style=color:#bbb> </span><span style=color:#666>80</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>targetPort</span>:<span style=color:#bbb> </span><span style=color:#666>9376</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:#00f;font-weight:700>---</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Service<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>mydb<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>ports</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>protocol</span>:<span style=color:#bbb> </span>TCP<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>port</span>:<span style=color:#bbb> </span><span style=color:#666>80</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>targetPort</span>:<span style=color:#bbb> </span><span style=color:#666>9377</span><span style=color:#bbb>
</span></span></span></code></pre></div><p>Pour créer les services <code>mydb</code> et <code>myservice</code> :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl apply -f services.yaml
</span></span></code></pre></div><pre tabindex=0><code>service/myservice created
service/mydb created
</code></pre><p>Vous verrez ensuite que ces init containers se terminent et que le Pod <code>myapp-pod</code> évolue vers l'état "Running" (en exécution) :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get -f myapp.yaml
</span></span></code></pre></div><pre tabindex=0><code>NAME        READY     STATUS    RESTARTS   AGE
myapp-pod   1/1       Running   0          9m
</code></pre><p>Cet exemple simple devrait suffire à vous inspirer pour créer vos propres init containers.
<a href=#a-suivre>A suivre</a> contient un lien vers un exemple plus détaillé.</p><h2 id=comportement-détaillé>Comportement détaillé</h2><p>Pendant le démarrage d'un Pod, chaque init container démarre en ordre, après que le réseau
et les volumes ont été initialisés. Chaque conteneur doit se terminer avec succès avant que le prochain
ne démarre. Si un conteneur n'arrive pas à démarrer à cause d'un problème d'exécution ou
se termine avec un échec, il est redémarré selon la <code>restartPolicy</code> du Pod.
Toutefois, si la <code>restartPolicy</code> du Pod est configurée à "Always", les init containers utilisent la <code>restartPolicy</code> "OnFailure".</p><p>Un Pod ne peut pas être <code>Ready</code> tant que tous les init containers ne se sont pas exécutés avec succès.
Les ports d'un init container ne sont pas agrégés sous un Service. Un Pod qui s'initialise
est dans l'état <code>Pending</code> mais devrait avoir une condition <code>Initialized</code> configurée à "true".</p><p>Si le Pod <a href=#raisons-du-red%C3%A9marrage-d-un-pod>redémarre</a> ou est redémarré, tous les init containers
doivent s'exécuter à nouveau.</p><p>Les changements aux spec d'un init containers sont limités au champ image du conteneur.
Changer le champ image d'un init container équivaut à redémarrer le Pod.</p><p>Puisque les init containers peuvent être redémarrés, réessayés ou ré-exécutés,
leur code doit être idempotent. En particulier, le code qui écrit dans des fichiers sur <code>EmptyDirs</code>
devrait être préparé à la possibilité qu'un fichier de sortie existe déjà.</p><p>Les init containers ont tous les champs d'un conteneur d'application.
Cependant, Kubernetes interdit l'utilisation de <code>readinessProbe</code> parce que les init containers
ne peuvent pas définir une "readiness" distincte de la complétion. Ceci est appliqué lors de la validation.</p><p>L'utilisation de <code>activeDeadlineSeconds</code> sur le Pod et <code>livenessProbe</code> sur le conteneur
permet d'empêcher les init containers d'échouer tout le temps.
La deadline active inclut les init containers.</p><p>Le nom de chaque application et init container dans un Pod doit être unique; une erreur de validation
est générée pour tout conteneur partageant un nom avec un autre.</p><h3 id=ressources>Ressources</h3><p>Étant donné l'ordonnancement et l'exécution des init containers, les règles suivantes s'appliquent pour l'utilisation des ressources :</p><ul><li>La plus haute requête ou limite particulière de ressource définie pour tous les init containers
est la <em>limite/requête d'initialisation effective</em></li><li>La <em>limite/requête effective</em> d'un Pod pour une ressource est la plus haute parmis :<ul><li>la somme de toutes les requêtes/limites des conteneurs d'application pour une ressource</li><li>la limite/requête d'initialisation effective pour une ressource</li></ul></li><li>Le Scheduling est effectué sur la base des requêtes/limites effectives, ce qui signifie
que les init containers peuvent réserver des ressources pour l'initialisation qui ne sont pas utilisées durant le
cycle de vie du Pod.</li><li>La QoS (qualité de service) tierce de la <em>QoS tierce effective</em> d'un Pod est la QoS tierce aussi bien pour les init containers
que pour les conteneurs d'application.</li></ul><p>Les quotas et limites sont appliqués sur la base de la requête/limite effective d'un Pod.</p><p>Les groupes de contrôle au niveau du Pod (<a class=glossary-tooltip title="Un groupe de processus Linux avec des options d'isolation, de suivi, et de limites des ressources." data-toggle=tooltip data-placement=top href='/fr/docs/reference/glossary/?all=true#term-cgroup' target=_blank aria-label=cgroups>cgroups</a>) sont basés sur la requête/limite effective de Pod, la même que
celle du scheduler.</p><h3 id=raisons-du-redémarrage-d-un-pod>Raisons du redémarrage d'un Pod</h3><p>Un Pod peut redémarrer, ce qui cause la ré-exécution des init containers, pour les raisons suivantes :</p><ul><li>Un utilisateur met à jour les spécifications du Pod, ce qui cause le changement de l'image de l'init container.
Tout changement à l'image du init container redémarre le Pod. Les changements au conteneur d'application entraînent seulement le
redémarrage du conteneur d'application.</li><li>Le conteneur d'infrastructure Pod est redémarré. Ceci est peu commun et serait effectué par une personne ayant un accès root aux nœuds.</li><li>Tous les conteneurs dans un Pod sont terminés tandis que <code>restartPolicy</code> est configurée à "Always", ce qui force le redémarrage, et l'enregistrement de complétion du init container a été perdu à cause d'une opération de garbage collection (récupération de mémoire).</li></ul><h2 id=a-suivre>A suivre</h2><ul><li>Lire à propos de la <a href=/docs/tasks/configure-pod-container/configure-pod-initialization/#creating-a-pod-that-has-an-init-container>création d'un Pod ayant un init container</a></li><li>Apprendre à <a href=/docs/tasks/debug/debug-application/debug-init-containers/>debugger les init containers</a></li></ul></div></main></div></div><footer class=d-print-none><div class=footer__links><nav><a class=text-white href=/fr/docs/home/>Accueil</a>
<a class=text-white href=/fr/blog/>Blog</a>
<a class=text-white href=/fr/partners/>Partenaires</a>
<a class=text-white href=/fr/community/>Communauté</a>
<a class=text-white href=/fr/case-studies/>Études de cas</a></nav></div><div class=container-fluid><div class=row><div class="col-6 col-sm-2 text-xs-center order-sm-2"><ul class="list-inline mb-0"><li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title="User mailing list" aria-label="User mailing list"><a class=text-white target=_blank href=https://discuss.kubernetes.io><i class="fa fa-envelope"></i></a></li><li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title=Twitter aria-label=Twitter><a class=text-white target=_blank href=https://twitter.com/kubernetesio><i class="fab fa-twitter"></i></a></li><li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title=Calendar aria-label=Calendar><a class=text-white target=_blank href="https://calendar.google.com/calendar/embed?src=calendar%40kubernetes.io"><i class="fas fa-calendar-alt"></i></a></li><li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title=Youtube aria-label=Youtube><a class=text-white target=_blank href=https://youtube.com/kubernetescommunity><i class="fab fa-youtube"></i></a></li></ul></div><div class="col-6 col-sm-2 text-right text-xs-center order-sm-3"><ul class="list-inline mb-0"><li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title=GitHub aria-label=GitHub><a class=text-white target=_blank href=https://github.com/kubernetes/kubernetes><i class="fab fa-github"></i></a></li><li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title=Slack aria-label=Slack><a class=text-white target=_blank href=https://slack.k8s.io><i class="fab fa-slack"></i></a></li><li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title=Contribute aria-label=Contribute><a class=text-white target=_blank href=https://git.k8s.io/community/contributors/guide><i class="fas fa-edit"></i></a></li><li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title="Stack Overflow" aria-label="Stack Overflow"><a class=text-white target=_blank href=https://stackoverflow.com/questions/tagged/kubernetes><i class="fab fa-stack-overflow"></i></a></li></ul></div><div class="col-12 col-sm-8 text-center order-sm-2"><small class=text-white>&copy; 2023 The Kubernetes Authors | Documentation Distributed under <a href=https://git.k8s.io/website/LICENSE class=light-text>CC BY 4.0</a></small><br><small class=text-white>Copyright &copy; 2023 The Linux Foundation &reg;. All rights reserved. The Linux Foundation has registered trademarks and uses trademarks. For a list of trademarks of The Linux Foundation, please see our <a href=https://www.linuxfoundation.org/trademark-usage class=light-text>Trademark Usage page</a></small><br><small class=text-white>ICP license: 京ICP备17074266号-3</small></div></div></div></footer></div><script src=/js/jquery-3.6.0.min.js integrity=sha384-vtXRMe3mGCbOeY7l30aIg8H9p3GdeSe4IFlP6G8JMa7o7lXvnz3GFKzPxzJdPfGK crossorigin=anonymous></script>
<script src=/js/popper-1.16.1.min.js intregrity=sha384-9/reFTGAW83EW2RDu2S0VKaIzap3H66lZH81PoYlFhbGU+6BZp6G7niu735Sk7lN crossorigin=anonymous></script>
<script src=/js/bootstrap-4.6.1.min.js integrity=sha384-VHvPCCyXqtD5DqJeNxl2dtTyhF78xXNXdkwX1CZeRusQfRKp+tA7hAShOK/B/fQ2 crossorigin=anonymous></script>
<script src=/js/script.js></script>
<script async src=/js/mermaid-8.13.4.min.js integrity=sha384-5hHNvPeMrNH14oM3IcQofDoBhiclNK3g2+hnEinKzQ07C4AliMeVpnvxuiwEGpaO crossorigin=anonymous></script>
<script src=/js/main.min.5c0bf7f21dc4f66485f74efbbeeff28a7e4f8cddaac1bae47043159c922ff3a3.js integrity="sha256-XAv38h3E9mSF9077vu/yin5PjN2qwbrkcEMVnJIv86M=" crossorigin=anonymous></script></body></html>