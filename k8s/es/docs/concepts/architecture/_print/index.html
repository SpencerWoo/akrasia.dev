<!doctype html><html lang=es class=no-js><head><meta name=robots content="noindex, nofollow"><link rel=alternate hreflang=en href=https://kubernetes.io/docs/concepts/architecture/><link rel=alternate hreflang=zh-cn href=https://kubernetes.io/zh-cn/docs/concepts/architecture/><link rel=alternate hreflang=ko href=https://kubernetes.io/ko/docs/concepts/architecture/><link rel=alternate hreflang=ja href=https://kubernetes.io/ja/docs/concepts/architecture/><link rel=alternate hreflang=fr href=https://kubernetes.io/fr/docs/concepts/architecture/><link rel=alternate hreflang=it href=https://kubernetes.io/it/docs/concepts/architecture/><link rel=alternate hreflang=de href=https://kubernetes.io/de/docs/concepts/architecture/><link rel=alternate hreflang=pt-br href=https://kubernetes.io/pt-br/docs/concepts/architecture/><link rel=alternate hreflang=id href=https://kubernetes.io/id/docs/concepts/architecture/><link rel=alternate hreflang=vi href=https://kubernetes.io/vi/docs/concepts/architecture/><link rel=alternate hreflang=ru href=https://kubernetes.io/ru/docs/concepts/architecture/><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=generator content="Hugo 0.110.0"><link rel=canonical type=text/html href=https://kubernetes.io/es/docs/concepts/architecture/><link rel="shortcut icon" type=image/png href=/images/favicon.png><link rel=apple-touch-icon href=/favicons/apple-touch-icon-180x180.png sizes=180x180><link rel=manifest href=/manifest.webmanifest><link rel=apple-touch-icon href=/images/kubernetes-192x192.png><title>Arquitectura de Kubernetes | Kubernetes</title><meta property="og:title" content="Arquitectura de Kubernetes"><meta property="og:description" content="Orquestación de contenedores para producción"><meta property="og:type" content="website"><meta property="og:url" content="https://kubernetes.io/es/docs/concepts/architecture/"><meta property="og:site_name" content="Kubernetes"><meta itemprop=name content="Arquitectura de Kubernetes"><meta itemprop=description content="Orquestación de contenedores para producción"><meta name=twitter:card content="summary"><meta name=twitter:title content="Arquitectura de Kubernetes"><meta name=twitter:description content="Orquestación de contenedores para producción"><link href=/scss/main.css rel=stylesheet><script type=application/ld+json>{"@context":"https://schema.org","@type":"Organization","url":"https://kubernetes.io","logo":"https://kubernetes.io/images/favicon.png","potentialAction":{"@type":"SearchAction","target":"https://kubernetes.io/search/?q={search_term_string}","query-input":"required name=search_term_string"}}</script><meta name=theme-color content="#326ce5"><link rel=stylesheet href=/css/feature-states.css><meta name=description content><meta property="og:description" content><meta name=twitter:description content><meta property="og:url" content="https://kubernetes.io/es/docs/concepts/architecture/"><meta property="og:title" content="Arquitectura de Kubernetes"><meta name=twitter:title content="Arquitectura de Kubernetes"><meta name=twitter:image content="https://kubernetes.io/images/favicon.png"><meta name=twitter:image:alt content="Kubernetes"><meta property="og:image" content="/images/kubernetes-horizontal-color.png"><meta property="og:type" content="article"><script src=/js/jquery-3.6.0.min.js intregrity=sha384-vtXRMe3mGCbOeY7l30aIg8H9p3GdeSe4IFlP6G8JMa7o7lXvnz3GFKzPxzJdPfGK crossorigin=anonymous></script></head><body class=td-section><header><nav class="js-navbar-scroll navbar navbar-expand navbar-dark flex-column flex-md-row td-navbar" data-auto-burger=primary><a class=navbar-brand href=/es/></a><div class="td-navbar-nav-scroll ml-md-auto" id=main_navbar><ul class="navbar-nav mt-2 mt-lg-0"><li class="nav-item mr-2 mb-lg-0"><a class="nav-link active" href=/es/docs/>Documentación</a></li><li class="nav-item mr-2 mb-lg-0"><a class=nav-link href=/es/blog/>Kubernetes Blog</a></li><li class="nav-item mr-2 mb-lg-0"><a class=nav-link href=/es/partners/>Partners</a></li><li class="nav-item mr-2 mb-lg-0"><a class=nav-link href=/es/community/>Comunidad</a></li><li class="nav-item mr-2 mb-lg-0"><a class=nav-link href=/es/case-studies/>Casos de éxito</a></li><li class="nav-item dropdown"><a class="nav-link dropdown-toggle" href=# id=navbarDropdown role=button data-toggle=dropdown aria-haspopup=true aria-expanded=false>Versions</a><div class="dropdown-menu dropdown-menu-right" aria-labelledby=navbarDropdownMenuLink><a class=dropdown-item href=/es/releases>Release Information</a>
<a class=dropdown-item href=https://kubernetes.io/es/docs/concepts/architecture/>v1.25</a>
<a class=dropdown-item href=https://v1-24.docs.kubernetes.io/es/docs/concepts/architecture/>v1.24</a>
<a class=dropdown-item href=https://v1-23.docs.kubernetes.io/es/docs/concepts/architecture/>v1.23</a>
<a class=dropdown-item href=https://v1-22.docs.kubernetes.io/es/docs/concepts/architecture/>v1.22</a>
<a class=dropdown-item href=https://v1-21.docs.kubernetes.io/es/docs/concepts/architecture/>v1.21</a></div></li><li class="nav-item dropdown"><a class="nav-link dropdown-toggle" href=# id=navbarDropdownMenuLink role=button data-toggle=dropdown aria-haspopup=true aria-expanded=false>Español (Spanish)</a><div class="dropdown-menu dropdown-menu-right" aria-labelledby=navbarDropdownMenuLink><a class=dropdown-item href=/docs/concepts/architecture/>English</a>
<a class=dropdown-item href=/zh-cn/docs/concepts/architecture/>中文 (Chinese)</a>
<a class=dropdown-item href=/ko/docs/concepts/architecture/>한국어 (Korean)</a>
<a class=dropdown-item href=/ja/docs/concepts/architecture/>日本語 (Japanese)</a>
<a class=dropdown-item href=/fr/docs/concepts/architecture/>Français (French)</a>
<a class=dropdown-item href=/it/docs/concepts/architecture/>Italiano (Italian)</a>
<a class=dropdown-item href=/de/docs/concepts/architecture/>Deutsch (German)</a>
<a class=dropdown-item href=/pt-br/docs/concepts/architecture/>Português (Portuguese)</a>
<a class=dropdown-item href=/id/docs/concepts/architecture/>Bahasa Indonesia</a>
<a class=dropdown-item href=/vi/docs/concepts/architecture/>Tiếng Việt (Vietnamese)</a>
<a class=dropdown-item href=/ru/docs/concepts/architecture/>Русский (Russian)</a></div></li></ul></div><button id=hamburger onclick=kub.toggleMenu() data-auto-burger-exclude><div></div></button></nav></header><div class="container-fluid td-outer"><div class=td-main><div class="row flex-xl-nowrap"><main class="col-12 col-md-9 col-xl-8 pl-md-5" role=main><div class=td-content><div class="pageinfo pageinfo-primary d-print-none"><p>Versión imprimible multipagina.
<a href=# onclick="return print(),!1">Haga click aquí para imprimir</a>.</p><p><a href=/es/docs/concepts/architecture/>Volver a la vista normal de esta página</a>.</p></div><h1 class=title>Arquitectura de Kubernetes</h1><ul><li>1: <a href=#pg-9ef2890698e773b6c0d24fd2c20146f5>Nodos</a></li><li>2: <a href=#pg-63e7fdf87ba61eb2586bb8c625c23506>Comunicación Nodo-Maestro</a></li><li>3: <a href=#pg-bc804b02614d67025b4c788f1ca87fbc>Conceptos subyacentes del Cloud Controller Manager</a></li></ul><div class=content></div></div><div class=td-content><h1 id=pg-9ef2890698e773b6c0d24fd2c20146f5>1 - Nodos</h1><p>Un nodo es una máquina de trabajo en Kubernetes, previamente conocida como <code>minion</code>. Un nodo puede ser una máquina virtual o física, dependiendo del tipo de clúster. Cada nodo está gestionado por el componente máster y contiene los servicios necesarios para ejecutar <a href=/docs/concepts/workloads/pods/pod>pods</a>. Los servicios en un nodo incluyen el <a href=/docs/concepts/overview/components/#node-components>container runtime</a>, kubelet y el kube-proxy. Accede a la sección <a href=https://git.k8s.io/design-proposals-archive/architecture/architecture.md#the-kubernetes-node>The Kubernetes Node</a> en el documento de diseño de arquitectura para más detalle.</p><h2 id=estado-del-nodo>Estado del Nodo</h2><p>El estado de un nodo comprende la siguiente información:</p><ul><li><a href=#direcciones>Direcciones</a></li><li><a href=#estados>Estados</a></li><li><a href=#capacidad>Capacidad</a></li><li><a href=#informaci%C3%B3n>Información</a></li></ul><h3 id=direcciones>Direcciones</h3><p>El uso de estos campos varía dependiendo del proveedor de servicios en la nube y/o de la configuración en máquinas locales.</p><ul><li><code>HostName</code>: El nombre de la máquina huésped como aparece en el kernel del nodo. Puede ser reconfigurado a través del kubelet usando el parámetro <code>--hostname-override</code>.</li><li><code>ExternalIP</code>: La dirección IP del nodo que es accesible externamente (que está disponible desde fuera del clúster).</li><li><code>InternalIP</code>: La dirección IP del nodo que es accesible únicamente desde dentro del clúster.</li></ul><h3 id=estados>Estados</h3><p>El campo <code>conditions</code> describe el estado de todos los nodos en modo <code>Running</code>.</p><table><thead><tr><th>Estado</th><th>Descripción</th></tr></thead><tbody><tr><td><code>OutOfDisk</code></td><td><code>True</code> si no hay espacio suficiente en el nodo para añadir nuevos pods; sino <code>False</code></td></tr><tr><td><code>Ready</code></td><td><code>True</code> si el nodo está en buen estado y preparado para aceptar nuevos pods, <code>Falso</code> si no puede aceptar nuevos pods, y <code>Unknown</code> si el controlador aún no tiene constancia del nodo después del último <code>node-monitor-grace-period</code> (por defecto cada 40 segundos)</td></tr><tr><td><code>MemoryPressure</code></td><td><code>True</code> si hay presión en la memoria del nodo -- es decir, si el consumo de memoria en el nodo es elevado; sino <code>False</code></td></tr><tr><td><code>PIDPressure</code></td><td><code>True</code> si el número de PIDs consumidos en el nodo es alto -- es decir, si hay demasiados procesos en el nodo; sino <code>False</code></td></tr><tr><td><code>DiskPressure</code></td><td><code>True</code> si hay presión en el tamaño del disco -- esto es, si la capacidad del disco es baja; sino <code>False</code></td></tr><tr><td><code>NetworkUnavailable</code></td><td><code>True</code> si la configuración de red del nodo no es correcta; sino <code>False</code></td></tr></tbody></table><p>El estado del nodo se representa como un objeto JSON. Por ejemplo, la siguiente respuesta describe un nodo en buen estado:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-json data-lang=json><span style=display:flex><span><span style=color:#b44>&#34;conditions&#34;</span><span>:</span> [
</span></span><span style=display:flex><span>  {
</span></span><span style=display:flex><span>    <span style=color:green;font-weight:700>&#34;type&#34;</span>: <span style=color:#b44>&#34;Ready&#34;</span>,
</span></span><span style=display:flex><span>    <span style=color:green;font-weight:700>&#34;status&#34;</span>: <span style=color:#b44>&#34;True&#34;</span>
</span></span><span style=display:flex><span>  }
</span></span><span style=display:flex><span>]
</span></span></code></pre></div><p>Si el <code>status</code> de la condición <code>Ready</code> se mantiene como <code>Unknown</code> o <code>False</code> por más tiempo de lo que dura un <code>pod-eviction-timeout</code>, se pasa un argumento al <a href=/docs/admin/kube-controller-manager/>kube-controller-manager</a> y todos los pods en el nodo se marcan para borrado por el controlador de nodos. El tiempo de desalojo por defecto es de <strong>cinco minutos</strong>. En algunos casos, cuando el nodo se encuentra inaccesible, el API Server no puede comunicar con el kubelet del nodo. La decisión de borrar pods no se le puede hacer llegar al kubelet hasta que la comunicación con el API Server se ha restablecido. Mientras tanto, los pods marcados para borrado pueden continuar ejecutándose en el nodo aislado.</p><p>En versiones de Kubernetes anteriores a 1.5, el controlador de nodos <a href=/docs/concepts/workloads/pods/pod/#force-deletion-of-pods>forzaba el borrado</a> de dichos pods inaccesibles desde el API Server. Sin embargo, desde la versión 1.5, el nodo controlador no fuerza el borrado de pods hasta que se confirma que dichos pods han dejado de ejecutarse en el clúster. Pods que podrían estar ejecutándose en un nodo inalcanzable se muestran como <code>Terminating</code> o <code>Unknown</code>. En aquellos casos en los que Kubernetes no puede deducir si un nodo ha abandonado el clúster de forma permanente, puede que sea el administrador el que tenga que borrar el nodo de forma manual. Borrar un objeto <code>Node</code> en un clúster de Kubernetes provoca que los objetos Pod que se ejecutaban en el nodo sean eliminados en el API Server y libera sus nombres.</p><p>En la versión 1.12, la funcionalidad <code>TaintNodesByCondition</code> se eleva a beta, de forma que el controlador del ciclo de vida de nodos crea <a href=/docs/concepts/configuration/taint-and-toleration/>taints</a> de forma automática, que representan estados de nodos.
De forma similar, el planificador de tareas ignora estados cuando evalúa un nodo; en su lugar mira los taints del nodo y las tolerancias de los pods.</p><p>En la actualidad, los usuarios pueden elegir entre la versión de planificación antigua y el nuevo, más flexible, modelo de planificación.
Un pod que no tiene definida ninguna tolerancia es planificado utilizando el modelo antiguo, pero si un nodo tiene definidas ciertas tolerancias, sólo puede ser asignado a un nodo que lo permita.</p><div class="alert alert-warning caution callout" role=alert><strong>Precaución:</strong> Habilitar esta funcionalidad crea una pequeña demora entre que una condición es evaluada y un taint creado. Esta demora suele ser inferior a un segundo, pero puede incrementar el número de pods que se planifican con éxito pero que luego son rechazados por el kubelet.</div><h3 id=capacidad>Capacidad</h3><p>Describe los recursos disponibles en el nodo: CPU, memoria, y el número máximo de pods que pueden ser planificados dentro del nodo.</p><h3 id=información>Información</h3><p>Información general sobre el nodo: versión del kernel, versión de Kubernetes (versiones del kubelet y del kube-proxy), versión de Docker (si se utiliza), nombre del sistema operativo. Toda esta información es recogida por el kubelet en el nodo.</p><h2 id=gestión>Gestión</h2><p>A diferencia de <a href=/docs/concepts/workloads/pods/pod/>pods</a> y <a href=/docs/concepts/services-networking/service/>services</a>, los nodos no son creados por Kubernetes de forma inherente; o son creados de manera externa por los proveedores de servicios en la nube como Google Compute Engine, o existen en la colección de máquinas virtuales o físicas. De manera que cuando Kubernetes crea un nodo, crea un objeto que representa el nodo. Después de ser creado, Kubernetes comprueba si el nodo es válido o no. Por ejemplo, si intentas crear un nodo con el siguiente detalle:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-json data-lang=json><span style=display:flex><span>{
</span></span><span style=display:flex><span>  <span style=color:green;font-weight:700>&#34;kind&#34;</span>: <span style=color:#b44>&#34;Node&#34;</span>,
</span></span><span style=display:flex><span>  <span style=color:green;font-weight:700>&#34;apiVersion&#34;</span>: <span style=color:#b44>&#34;v1&#34;</span>,
</span></span><span style=display:flex><span>  <span style=color:green;font-weight:700>&#34;metadata&#34;</span>: {
</span></span><span style=display:flex><span>    <span style=color:green;font-weight:700>&#34;name&#34;</span>: <span style=color:#b44>&#34;10.240.79.157&#34;</span>,
</span></span><span style=display:flex><span>    <span style=color:green;font-weight:700>&#34;labels&#34;</span>: {
</span></span><span style=display:flex><span>      <span style=color:green;font-weight:700>&#34;name&#34;</span>: <span style=color:#b44>&#34;my-first-k8s-node&#34;</span>
</span></span><span style=display:flex><span>    }
</span></span><span style=display:flex><span>  }
</span></span><span style=display:flex><span>}
</span></span></code></pre></div><p>Kubernetes crea un objeto <code>Node</code> internamente (la representación), y valida el nodo comprobando su salud en el campo <code>metadata.name</code>. Si el nodo es válido -- es decir, si todos los servicios necesarios están ejecutándose -- el nodo es elegible para correr un pod. Sino, es ignorado para cualquier actividad del clúster hasta que se convierte en un nodo válido.</p><div class="alert alert-info note callout" role=alert><strong>Nota:</strong> Kubernetes conserva el objeto de un nodo inválido y continúa probando por si el nodo, en algún momento, entrase en servicio.
Para romper este ciclo deberás borrar el objeto <code>Node</code> explícitamente.</div><p>Actualmente, hay tres componentes que interactúan con la interfaz de nodos de Kubernetes: controlador de nodos, kubelet y kubectl.</p><h3 id=controlador-de-nodos>Controlador de Nodos</h3><p>El controlador de nodos es un componente maestro en Kubernetes que gestiona diferentes aspectos de los nodos.</p><p>El controlador juega múltiples papeles en la vida de un nodo. El primero es asignar un bloque CIDR (Class Inter-Domain Routing) al nodo cuando este se registra (si la asignación CIDR está activada) que contendrá las IPs disponibles para asignar a los objetos que se ejecutarán en ese nodo.</p><p>El segundo es mantener actualizada la lista interna del controlador con la lista de máquinas disponibles a través del proveedor de servicios en la nube. Cuando Kubernetes se ejecuta en la nube, si un nodo deja de responder, el controlador del nodo preguntará al proveedor si la máquina virtual de dicho nodo continúa estando disponible. Si no lo está, el controlador borrará dicho nodo de su lista interna.</p><p>El tercero es el de monitorizar la salud de los nodos. El controlador de nodos es el responsable de actualizar la condición <code>NodeReady</code> del campo <code>NodeStatus</code> a <code>ConditionUnknown</code> cuando un nodo deja de estar accesible (por ejemplo, si deja de recibir señales de vida del nodo indicando que está disponible, conocidas como latidos o <code>hearbeats</code> en inglés) y, también es responsable de posteriormente desalojar todos los pods del nodo si este continúa estando inalcanzable. Por defecto, cuando un nodo deja de responder, el controlador sigue reintentando contactar con el nodo durante 40 segundos antes de marcar el nodo con <code>ConditionUnknown</code> y, si el nodo no se recupera de ese estado pasados 5 minutos, empezará a drenar los pods del nodo para desplegarlos en otro nodo que esté disponible. El controlador comprueba el estado de cada nodo cada <code>--node-monitor-period</code> segundos.</p><p>En versiones de Kubernetes previas a 1.13, <code>NodeStatus</code> es el <code>heartbeat</code> del nodo. Empezando con 1.13 la funcionalidad de <code>node lease</code> se introduce como alfa (<code>NodeLease</code>,
<a href=https://github.com/kubernetes/enhancements/blob/master/keps/sig-node/0009-node-heartbeat.md>KEP-0009</a>). Cuando la funcionalidad está habilitada, cada nodo tiene un objeto <code>Lease</code> asociado en el namespace <code>kube-node-lease</code> que se renueva periódicamente y ambos, el <code>NodeStatus</code> y el <code>Lease</code> son considerados como <code>hearbeats</code> del nodo. <code>Node leases</code> se renuevan con frecuencia, mientras que <code>NodeStatus</code> se transmite desde el nodo al máster únicamente si hay cambios o si ha pasado cierto tiempo (por defecto, 1 minuto, que es más que la cuenta atrás por defecto de 40 segundos que marca un nodo como inalcanzable). Al ser los <code>node lease</code> más ligeros que <code>NodeStatus</code>, los <code>hearbeats</code> resultan más económicos desde las perspectivas de escalabilidad y de rendimiento.</p><p>En Kubernetes 1.4, se actualizó la lógica del controlador de nodos para gestionar mejor los casos en los que un gran número de nodos tiene problemas alcanzando el nodo máster (Por ejemplo, cuando el nodo máster es el que tiene un problema de red). Desde 1.4, el controlador de nodos observa el estado de todos los nodos en el clúster cuando toma decisiones sobre desalojo de pods.</p><p>En la mayoría de los casos, el controlador de nodos limita el ritmo de desalojo <code>--node-eviction-rate</code> (0.1 por defecto) por segundo, lo que significa que no desalojará pods de más de un nodo cada diez segundos.</p><p>El comportamiento de desalojo de nodos cambia cuando un nodo en una zona de disponibilidad tiene problemas. El controlador de nodos comprobará qué porcentaje de nodos en la zona no se encuentran en buen estado (es decir, que su condición <code>NodeReady</code> tiene un valor <code>ConditionUnknown</code> o <code>ConditionFalse</code>) al mismo tiempo. Si la fracción de nodos con problemas es de al menos <code>--unhealthy-zone-threshold</code> (0.55 por defecto) entonces se reduce el ratio de desalojos: si el clúster es pequeño (por ejemplo, tiene menos o los mismos nodos que <code>--large-cluster-size-threshold</code> - 50 por defecto) entonces los desalojos se paran. Sino, el ratio se reduce a <code>--secondary-node-eviction-rate</code> (0.01 por defecto) por segundo. La razón por la que estas políticas se implementan por zonas de disponibilidad es debido a que una zona puede quedarse aislada del nodo máster mientras que las demás continúan conectadas. Si un clúster no comprende más de una zona, todo el clúster se considera una única zona.</p><p>La razón principal por la que se distribuyen nodos entre varias zonas de disponibilidad es para que el volumen de trabajo se transfiera a aquellas zonas que se encuentren en buen estado cuando una de las zonas se caiga.
Por consiguiente, si todos los nodos de una zona se encuentran en mal estado, el nodo controlador desaloja al ritmo normal <code>--node-eviction-rate</code>. En el caso extremo de que todas las zonas se encuentran en mal estado (es decir, no responda ningún nodo del clúster), el controlador de nodos asume que hay algún tipo de problema con la conectividad del nodo máster y paraliza todos los desalojos hasta que se restablezca la conectividad.</p><p>Desde la versión 1.6 de Kubernetes el controlador de nodos también es el responsable de desalojar pods que están ejecutándose en nodos con <code>NoExecute</code> taints, cuando los pods no permiten dichos taints. De forma adicional, como una funcionalidad alfa que permanece deshabilitada por defecto, el <code>NodeController</code> es responsable de añadir taints que se corresponden con problemas en los nodos del tipo nodo inalcanzable o nodo no preparado. En <a href=/docs/concepts/configuration/taint-and-toleration/>esta sección de la documentación</a> hay más detalles acerca de los taints <code>NoExecute</code> y de la funcionalidad alfa.</p><p>Desde la versión 1.8, el controlador de nodos puede ser responsable de la creación de taints que representan condiciones de nodos. Esta es una funcionalidad alfa en 1.8.</p><h3 id=auto-registro-de-nodos>Auto-Registro de Nodos</h3><p>Cuando el atributo del kubelet <code>--register-node</code> está habilitado (el valor por defecto), el kubelet intentará auto-registrarse con el API Server. Este es el patrón de diseño preferido, y utilizado por la mayoría de distribuciones.</p><p>Para auto-registro, el kubelet se inicia con las siguientes opciones:</p><ul><li><code>--kubeconfig</code> - La ruta a las credenciales para autentificarse con el API Server.</li><li><code>--cloud-provider</code> - Cómo comunicarse con un proveedor de servicios para leer meta-datos sobre si mismo.</li><li><code>--register-node</code> - Registro automático con el API Server.</li><li><code>--register-with-taints</code> - Registro del nodo con la lista de taints proporcionada (separada por comas <code>&lt;key>=&lt;value>:&lt;effect></code>). Esta opción se ignora si el atributo<code>--register-node</code> no está habilitado.</li><li><code>--node-ip</code> - La dirección IP del nodo.</li><li><code>--node-labels</code> - Etiquetas para añadir al nodo durante el registro en el clúster (ver las restricciones que impone el <a href=/docs/reference/access-authn-authz/admission-controllers/#noderestriction>NodeRestriction admission plugin</a> en 1.13+).</li><li><code>--node-status-update-frequency</code> - Especifica la frecuencia con la que el nodo envía información de estado al máster.</li></ul><p>Cuando el <a href=/docs/reference/access-authn-authz/node/>Node authorization mode</a> y el <a href=/docs/reference/access-authn-authz/admission-controllers/#noderestriction>NodeRestriction admission plugin</a> están habilitados, los kubelets sólo tienen permisos para crear/modificar su propio objeto <code>Node</code>.</p><h3 id=administración-manual-de-nodos>Administración Manual de Nodos</h3><p>Los administradores del clúster pueden crear y modificar objetos <code>Node</code>.</p><p>Si un administrador desea crear objetos <code>Node</code> de forma manual, debe levantar kubelet con el atributo <code>--register-node=false</code>.</p><p>Los administradores del clúster pueden modificar recursos <code>Node</code> (independientemente del valor de <code>--register-node</code>). Dichas modificaciones incluyen crear etiquetas en el nodo y/o marcarlo como no-planificable (de forma que pods no pueden ser planificados para instalación en el nodo).</p><p>Etiquetas y selectores de nodos pueden utilizarse de forma conjunta para controlar las tareas de planificación, por ejemplo, para determinar un subconjunto de nodos elegibles para ejecutar un pod.</p><p>Marcar un nodo como no-planificable impide que nuevos pods sean planificados en dicho nodo, pero no afecta a ninguno de los pods que existían previamente en el nodo. Esto resulta de utilidad como paso preparatorio antes de reiniciar un nodo, etc. Por ejemplo, para marcar un nodo como no-planificable, se ejecuta el siguiente comando:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl cordon <span style=color:#b8860b>$NODENAME</span>
</span></span></code></pre></div><div class="alert alert-info note callout" role=alert><strong>Nota:</strong> Los pods creados por un controlador DaemonSet ignoran el planificador de Kubernetes y no respetan el atributo no-planificable de un nodo. Se asume que los daemons pertenecen a la máquina huésped y que se ejecutan incluso cuando esta está siendo drenada de aplicaciones en preparación de un reinicio.</div><h3 id=capacidad-del-nodo>Capacidad del Nodo</h3><p>La capacidad del nodo (número de CPUs y cantidad de memoria) es parte del objeto <code>Node</code>.
Normalmente, nodos se registran a sí mismos y declaran sus capacidades cuando el objeto <code>Node</code> es creado. Si se está haciendo <a href=#administraci%C3%B3n-manual-de-nodos>administración manual</a>, las capacidades deben configurarse en el momento de añadir el nodo.</p><p>El planificador de Kubernetes asegura la existencia de recursos suficientes para todos los pods que se ejecutan en un nodo. Comprueba que la suma recursos solicitados por los pods no exceda la capacidad del nodo. Incluye todos los pods iniciados por el kubelet, pero no tiene control sobre contenedores iniciados directamente por el <a href=/docs/concepts/overview/components/#node-components>runtime de contenedores</a> ni sobre otros procesos que corren fuera de contenedores.</p><p>Para reservar explícitamente recursos en la máquina huésped para procesos no relacionados con pods, sigue este tutorial <a href=/docs/tasks/administer-cluster/reserve-compute-resources/#system-reserved>reserva de recursos para daemons de sistema</a>.</p><h2 id=objeto-api>Objeto API</h2><p>Un nodo es un recurso principal dentro de la REST API de Kubernetes. Más detalles sobre el objeto en la API se puede encontrar en: <a href=/docs/reference/generated/kubernetes-api/v1.25/#node-v1-core>Object Node API</a>.</p></div><div class=td-content style=page-break-before:always><h1 id=pg-63e7fdf87ba61eb2586bb8c625c23506>2 - Comunicación Nodo-Maestro</h1><p>Este documento cataloga las diferentes vías de comunicación entre el nodo máster (en realidad el apiserver) y el clúster de Kubernetes. La intención es permitir a los usuarios personalizar sus instalaciones para proteger sus configuraciones de red de forma que el clúster pueda ejecutarse en una red insegura. (o en un proveedor de servicios en la nube con direcciones IP públicas)</p><h3 id=clúster-a-máster>Clúster a Máster</h3><p>Todos los canales de comunicación desde el clúster hacia el máster terminan en el apiserver (ningún otro componente del máster está diseñado para exponer servicios remotos). En un despliegue típico, el apiserver está configurado para escuchar conexiones remotas en un canal seguro cómo HTTPS en el puerto (443) con una o más formas de <a href=/docs/reference/access-authn-authz/authentication/>autenticación de clientes</a> habilitada. Una o más formas de <a href=/docs/reference/access-authn-authz/authorization/>autorización</a> deberían ser habilitadas, especialmente si se permiten <a href=/docs/reference/access-authn-authz/authentication/#anonymous-requests>peticiones anónimas</a>
o <a href=/docs/reference/access-authn-authz/authentication/#service-account-tokens>tokens de cuenta de servicio</a>.</p><p>Los nodos deben ser aprovisionados con el certificado raíz público del clúster de forma que puedan conectar de forma segura con el apiserver en conjunción con credenciales de cliente válidas. Por ejemplo, en un despliegue por defecto en GKE, las credenciales de cliente proporcionadas al kubelet están en la forma de certificados de cliente. Accede <a href=/docs/reference/command-line-tools-reference/kubelet-tls-bootstrapping/>kubelet TLS bootstrapping</a> para ver cómo aprovisionar certificados de cliente de forma automática.</p><p>Aquellos Pods que deseen conectar con el apiserver pueden hacerlo de forma segura a través de una cuenta de servicio, de esta forma Kubernetes inserta de forma automática el certificado raíz público y un bearer token válido en el pod cuando este es instanciado. El servicio <code>kubernetes</code> (en todos los namespaces) se configura con una dirección IP virtual que es redireccionada (via kube-proxy) al punto de acceso HTTPS en el apiserver.</p><p>Los componentes máster también se comunican con el apiserver del clúster a través de un puerto seguro.</p><p>Como resultado, el modo de operación por defecto para conexiones desde el clúster (nodos y pods ejecutándose en nodos) al máster es seguro por defecto y puede correr en redes públicas y/o inseguras.</p><h2 id=máster-a-clúster>Máster a Clúster</h2><p>Hay dos vías de comunicación primaria desde el máster (apiserver) al clúster. La primera es desde el apiserver al proceso kubelet que se ejecuta en cada nodo del clúster. La segunda es desde el apiserver a cualquier nodo, pod, o servicio a través de la funcionalidad proxy del apiserver.</p><h3 id=apiserver-al-kubelet>apiserver al kubelet</h3><p>Las conexiones del apiserver al kubelet se utilizan para:</p><ul><li>Recoger entradas de registro de pods.</li><li>Conectar (a través de <code>kubectl</code>) con pods en ejecución.</li><li>Facilitar la funcionalidad <code>port-forwarding</code> del kubelet.</li></ul><p>Estas conexiones terminan en el endpoint HTTPS del kubelet. Por defecto, el apiserver no verifica el certificado del kubelet, por lo que la conexión es vulnerable a ataques del tipo <code>man-in-the-middle</code>, e <strong>insegura</strong> para conectar a través de redes públicas o de no confianza.</p><p>Para verificar esta conexión, se utiliza el atributo <code>--kubeket-certificate-authority</code> que provee el apiserver con un certificado raíz con el que verificar el certificado del kubelet.
Si esto no es posible, se utiliza un <a href=/docs/concepts/architecture/master-node-communication/#ssh-tunnels>túnel SSH</a> entre el apiserver y el kubelet para conectar a través de redes públicas o de no confianza.</p><p>Finalmente, <a href=/docs/admin/kubelet-authentication-authorization/>autenticación y/o autorización al kubelet</a> debe ser habilitada para proteger su API.</p><h3 id=apiserver-a-nodos-pods-y-servicios>apiserver a nodos, pods y servicios</h3><p>Las conexiones desde el apiserver a un nodo, pod o servicio se realizan por defecto con HTTP y, por consiguiente, no son autentificadas o encriptadas. Pueden ser ejecutadas en una conexión HTTPS segura añadiendo el prefijo <code>https:</code> al nodo, pod o nombre de servicio en la API URL, pero los receptores no validan el certificado provisto por el endpoint HTTPS ni facilitan credenciales de cliente asi que, aunque la conexión esté encriptada, esta no ofrece garantía de integridad. Estas conexiones <strong>no son seguras</strong> para conectar a través de redes públicas o inseguras.</p><h3 id=túneles-ssh>Túneles SSH</h3><p>Kubernetes ofrece soporte para túneles SSH que protegen la comunicación Máster -> Clúster. En este modo de configuración, el apiserver inicia un túnel SSH a cada nodo en el clúster (conectando al servidor SSH en el puerto 22) y transfiere todo el tráfico destinado a un kubelet, nodo, pod o servicio a través del túnel. El túnel garantiza que dicho tráfico no es expuesto fuera de la red en la que se ejecutan los nodos.</p><p>Los túneles SSH se consideran obsoletos, y no deberían utilizarse a menos que se sepa lo que se está haciendo. Se está diseñando un reemplazo para este canal de comunicación.</p></div><div class=td-content style=page-break-before:always><h1 id=pg-bc804b02614d67025b4c788f1ca87fbc>3 - Conceptos subyacentes del Cloud Controller Manager</h1><p>El concepto del Cloud Controller Manager (CCM) (no confundir con el ejecutable) fue creado originalmente para permitir que Kubernetes y el código específico de proveedores de servicios en la nube evolucionen de forma independiente. El Cloud Controller Manager se ejecuta a la par con otros componentes maestros como el Kubernetes Controller Manager, el API Server y el planificador. También puede ejecutarse como un extra, en cuyo caso se ejecuta por encima de Kubernetes.</p><p>El diseño del Cloud Controller Manager está basado en un sistema de plugins, lo que permite a nuevos proveedores de servicios integrarse de forma fácil con Kubernetes. Se está trabajando en implementar nuevos proveedores de servicios y para migrar los existentes del antiguo modelo al nuevo CCM.</p><p>Este documento describe los conceptos tras el Cloud Controller Manager y detalla sus funciones asociadas.</p><p>En la siguiente imagen, se puede visualizar la arquitectura de un cluster de Kubernetes que no utiliza el Cloud Controller Manager:</p><p><img src=/images/docs/pre-ccm-arch.png alt="Arquitectura previa a CCM"></p><h2 id=diseño>Diseño</h2><p>En el diagrama anterior, Kubernetes y el proveedor de servicios en la nube están integrados a través de diferentes componentes:</p><ul><li>Kubelet</li><li>Kubernetes controller manager</li><li>Kubernetes API server</li></ul><p>El CCM consolida toda la lógica dependiente de la nube de estos tres componentes para crear un punto de integración único. La nueva arquitectura con CCM se muestra a continuación:</p><p><img src=/images/docs/post-ccm-arch.png alt="Arquitectura CCM"></p><h2 id=componentes-del-ccm>Componentes del CCM</h2><p>El CCM secciona parte de la funcionalidad del Kubernetes Controller Manager (KCM) y la ejecuta como procesos independientes. Específicamente, aquellos controladores en el KCM que son dependientes de la nube:</p><ul><li>Controlador de Nodos</li><li>Controlador de Volúmenes</li><li>Controlador de Rutas</li><li>Controlador de Servicios</li></ul><p>En la versión 1.9, el CCM se encarga de la ejecución de los siguientes controladores:</p><ul><li>Controlador de Nodos</li><li>Controlador de Rutas</li><li>Controlador de Servicios</li></ul><div class="alert alert-info note callout" role=alert><strong>Nota:</strong> El controlador de volúmenes se dejó fuera del CCM de forma explícita. Debido a la complejidad que ello requería y a los esfuerzos existentes para abstraer lógica de volúmenes específica a proveedores de servicios, se decidió que el controlador de volúmenes no fuese movido al CCM.</div><p>El plan original para habilitar volúmenes en CCM era utilizar volúmenes Flex con soporte para volúmenes intercambiables. Sin embargo, otro programa conocido como CSI (Container Storage Interface) se está planeando para reemplazar Flex.</p><p>Considerando todo lo anterior, se ha decidido esperar hasta que CSI esté listo.</p><h2 id=funciones-del-ccm>Funciones del CCM</h2><p>El CCM hereda sus funciones de componentes que son dependientes de un proveedor de servicios en la nube. Esta sección se ha estructurado basado en dichos componentes:</p><h3 id=1-kubernetes-controller-manager>1. Kubernetes Controller Manager</h3><p>La mayoría de las funciones del CCM derivan del KCM. Como se ha mencionado en la sección anterior, el CCM es responsable de los siguientes circuitos de control:</p><ul><li>Controlador de Nodos</li><li>Controlador de Rutas</li><li>Controlador de Servicios</li></ul><h4 id=controlador-de-nodos>Controlador de Nodos</h4><p>El controlador de nodos es responsable de inicializar un nodo obteniendo información del proveedor de servicios sobre los nodos ejecutándose en el clúster. El controlador de nodos lleva a cabo las siguientes funciones:</p><ol><li>Inicializa un nodo con etiquetas de región y zona específicas del proveedor.</li><li>Inicializa un nodo con detalles de la instancia específicos del proveedor, como por ejemplo, el tipo o el tamaño.</li><li>Obtiene las direcciones de red del nodo y su hostname.</li><li>En caso de que el nodo deje de responder, comprueba la nube para ver si el nodo ha sido borrado. Si lo ha sido, borra el objeto nodo en Kubernetes.</li></ol><h4 id=controlador-de-rutas>Controlador de Rutas</h4><p>El controlador de Rutas es responsable de configurar rutas en la nube para que contenedores en diferentes nodos dentro de un clúster kubernetes se puedan comunicar entre sí.</p><h4 id=controlador-de-servicios>Controlador de Servicios</h4><p>El controlador de servicios es responsable de monitorizar eventos de creación, actualización y borrado de servicios. Basándose en el estado actual de los servicios en el clúster Kubernetes, configura balanceadores de carga del proveedor (como Amazon ELB, Google LB, or Oracle Cloud Infrastructure Lb) de forma que estos reflejen los servicios definidos en Kubernetes. Adicionalmente, se asegura de que los sistemas de apoyo de servicios para balanceadores de carga en la nube se encuentren actualizados.</p><h3 id=2-kubelet>2. Kubelet</h3><p>El controlador de nodos incluye la funcionalidad del kubelet que es dependiente de la nube. Previa a la introducción de CCM, el kubelet era responsable de inicializar un nodo con detalles específicos al proveedor como direcciones IP, etiquetas de región/zona y tipo de instancia. La introduccion de CCM transfiere esta inicialización del kubelet al CCM.</p><p>En este nuevo modelo, el kubelet inicializa un nodo sin información especifica del proveedor de servicios. Sin embargo, añade un <code>taint</code> al nodo recién creado de forma que este no esté disponible para el planificador hasta que el CCM completa el nodo con la información específica del proveedor. Sólo entonces elimina el <code>taint</code> y el nodo se vuelve accesible.</p><h2 id=mecanismo-de-plugins-extensiones>Mecanismo de Plugins (extensiones)</h2><p>El Cloud Controller Manager utiliza interfaces Go(lang), lo que permite que implementaciones de cualquier proveedor de servicios sean conectadas. Específicamente, utiliza el CloudProvider Interface definido <a href=https://github.com/kubernetes/cloud-provider/blob/9b77dc1c384685cb732b3025ed5689dd597a5971/cloud.go#L42-L62>aquí</a>.</p><p>La implementación de los cuatro controladores referenciados en este documento, algunas estructuras de inicialización junto con el interface CloudProvider, permanecerán como parte del núcleo de Kubernetes.</p><p>Para más información sobre el desarrollo de extensiones/plugins, consultar <a href=https://kubernetes.io/docs/tasks/administer-cluster/developing-cloud-controller-manager/>Desarrollo del CCM</a>.</p><h2 id=autorización>Autorización</h2><p>Esta sección divide el nivel de acceso requerido por varios objetos API para que el CCM pueda llevar acabo sus operaciones.</p><h3 id=controlador-de-nodos-1>Controlador de Nodos</h3><p>El controlador de nodos sólo opera con objetos Nodo. Necesita de acceso total para obtener, listar, crear, actualizar, arreglar, monitorizar y borrar objetos Nodo.</p><p>v1/Node:</p><ul><li>Get</li><li>List</li><li>Create</li><li>Update</li><li>Patch</li><li>Watch</li><li>Delete</li></ul><h3 id=controlador-de-rutas-1>Controlador de Rutas</h3><p>El controlador de rutas permanece a la escucha de eventos de creación de nodos y configura sus rutas. Necesita acceso a los objetos Nodo.</p><p>v1/Node:</p><ul><li>Get</li></ul><h3 id=controlador-de-servicios-1>Controlador de Servicios</h3><p>El controlador de servicios permanece a la escucha de eventos de creación, actualización y borrado de objetos Servicio, y se encarga de configurar los endpoints para dichos servicios.</p><p>Para acceder a los objetos Servicio, necesita permisos para listar y monitorizar. Para el mantenimiento de servicios necesita permisos para parchear y actualizar.</p><p>Para configurar endpoints para los servicios necesita permisos para crear, listar, obtener, monitorizar y actualizar.</p><p>v1/Service:</p><ul><li>List</li><li>Get</li><li>Watch</li><li>Patch</li><li>Update</li></ul><h3 id=otros>Otros</h3><p>La implementación del núcleo de CCM requiere acceso para crear eventos, y para asegurar la seguridad de operaciones; necesita acceso para crear ServiceAccounts.</p><p>v1/Event:</p><ul><li>Create</li><li>Patch</li><li>Update</li></ul><p>v1/ServiceAccount:</p><ul><li>Create</li></ul><p>El RBAC ClusterRole para CCM se muestra a continuación:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>rbac.authorization.k8s.io/v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>ClusterRole<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>cloud-controller-manager<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>rules</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span>- <span style=color:green;font-weight:700>apiGroups</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:#b44>&#34;&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>resources</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- events<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>verbs</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- create<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- patch<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- update<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span>- <span style=color:green;font-weight:700>apiGroups</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:#b44>&#34;&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>resources</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- nodes<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>verbs</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:#b44>&#39;*&#39;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span>- <span style=color:green;font-weight:700>apiGroups</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:#b44>&#34;&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>resources</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- nodes/status<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>verbs</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- patch<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span>- <span style=color:green;font-weight:700>apiGroups</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:#b44>&#34;&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>resources</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- services<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>verbs</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- list<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- patch<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- update<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- watch<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span>- <span style=color:green;font-weight:700>apiGroups</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:#b44>&#34;&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>resources</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- serviceaccounts<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>verbs</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- create<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span>- <span style=color:green;font-weight:700>apiGroups</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:#b44>&#34;&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>resources</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- persistentvolumes<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>verbs</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- get<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- list<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- update<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- watch<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span>- <span style=color:green;font-weight:700>apiGroups</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:#b44>&#34;&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>resources</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- endpoints<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>verbs</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- create<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- get<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- list<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- watch<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- update<span style=color:#bbb>
</span></span></span></code></pre></div><h2 id=implementaciones-de-proveedores>Implementaciones de Proveedores</h2><p>Los siguientes proveedores de servicios en la nube han implementado CCMs:</p><ul><li><a href=https://github.com/digitalocean/digitalocean-cloud-controller-manager>Digital Ocean</a></li><li><a href=https://github.com/oracle/oci-cloud-controller-manager>Oracle</a></li><li><a href=https://github.com/kubernetes/cloud-provider-azure>Azure</a></li><li><a href=https://github.com/kubernetes/cloud-provider-gcp>GCP</a></li><li><a href=https://github.com/kubernetes/cloud-provider-aws>AWS</a></li><li><a href=https://github.com/baidu/cloud-provider-baiducloud>BaiduCloud</a></li><li><a href=https://github.com/linode/linode-cloud-controller-manager>Linode</a></li></ul><h2 id=administración-del-clúster>Administración del Clúster</h2><p>Instrucciones para configurar y ejecutar el CCM pueden encontrarse <a href=/docs/tasks/administer-cluster/running-cloud-controller/#cloud-controller-manager>aquí</a>.</p></div></main></div></div><footer class=d-print-none><div class=footer__links><nav><a class=text-white href=/es/docs/home/>Home</a>
<a class=text-white href=/es/blog/>Blog</a>
<a class=text-white href=/es/partners/>Partners</a>
<a class=text-white href=/es/community/>Comunidad</a>
<a class=text-white href=/es/case-studies/>Casos de éxito</a></nav></div><div class=container-fluid><div class=row><div class="col-6 col-sm-2 text-xs-center order-sm-2"><ul class="list-inline mb-0"><li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title="User mailing list" aria-label="User mailing list"><a class=text-white target=_blank href=https://discuss.kubernetes.io><i class="fa fa-envelope"></i></a></li><li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title=Twitter aria-label=Twitter><a class=text-white target=_blank href=https://twitter.com/kubernetesio><i class="fab fa-twitter"></i></a></li><li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title=Calendar aria-label=Calendar><a class=text-white target=_blank href="https://calendar.google.com/calendar/embed?src=calendar%40kubernetes.io"><i class="fas fa-calendar-alt"></i></a></li><li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title=Youtube aria-label=Youtube><a class=text-white target=_blank href=https://youtube.com/kubernetescommunity><i class="fab fa-youtube"></i></a></li></ul></div><div class="col-6 col-sm-2 text-right text-xs-center order-sm-3"><ul class="list-inline mb-0"><li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title=GitHub aria-label=GitHub><a class=text-white target=_blank href=https://github.com/kubernetes/kubernetes><i class="fab fa-github"></i></a></li><li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title=Slack aria-label=Slack><a class=text-white target=_blank href=https://slack.k8s.io><i class="fab fa-slack"></i></a></li><li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title=Contribute aria-label=Contribute><a class=text-white target=_blank href=https://git.k8s.io/community/contributors/guide><i class="fas fa-edit"></i></a></li><li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title="Stack Overflow" aria-label="Stack Overflow"><a class=text-white target=_blank href=https://stackoverflow.com/questions/tagged/kubernetes><i class="fab fa-stack-overflow"></i></a></li></ul></div><div class="col-12 col-sm-8 text-center order-sm-2"><small class=text-white>&copy; 2023 Los autores de Kubernetes | Documentación distribuida bajo <a href=https://git.k8s.io/website/LICENSE class=light-text>CC BY 4.0</a></small><br><small class=text-white>Copyright &copy; 2023 The Linux Foundation &reg;. Todos los derechos reservados. The Linux Foundation tiene marcas registradas y utiliza marcas registradas. Para obtener una lista de marcas registradas por The Linux Foundation, visita <a href=https://www.linuxfoundation.org/trademark-usage class=light-text>Trademark Usage page</a></small><br><small class=text-white>ICP license: 京ICP备17074266号-3</small></div></div></div></footer></div><script src=/js/jquery-3.6.0.min.js integrity=sha384-vtXRMe3mGCbOeY7l30aIg8H9p3GdeSe4IFlP6G8JMa7o7lXvnz3GFKzPxzJdPfGK crossorigin=anonymous></script>
<script src=/js/popper-1.16.1.min.js intregrity=sha384-9/reFTGAW83EW2RDu2S0VKaIzap3H66lZH81PoYlFhbGU+6BZp6G7niu735Sk7lN crossorigin=anonymous></script>
<script src=/js/bootstrap-4.6.1.min.js integrity=sha384-VHvPCCyXqtD5DqJeNxl2dtTyhF78xXNXdkwX1CZeRusQfRKp+tA7hAShOK/B/fQ2 crossorigin=anonymous></script>
<script src=/js/script.js></script>
<script async src=/js/mermaid-8.13.4.min.js integrity=sha384-5hHNvPeMrNH14oM3IcQofDoBhiclNK3g2+hnEinKzQ07C4AliMeVpnvxuiwEGpaO crossorigin=anonymous></script>
<script src=/js/main.min.5c0bf7f21dc4f66485f74efbbeeff28a7e4f8cddaac1bae47043159c922ff3a3.js integrity="sha256-XAv38h3E9mSF9077vu/yin5PjN2qwbrkcEMVnJIv86M=" crossorigin=anonymous></script></body></html>