<!doctype html><html lang=de class=no-js><head><meta name=robots content="noindex, nofollow"><link rel=alternate hreflang=en href=https://kubernetes.io/docs/><link rel=alternate hreflang=zh-cn href=https://kubernetes.io/zh-cn/docs/><link rel=alternate hreflang=ko href=https://kubernetes.io/ko/docs/><link rel=alternate hreflang=ja href=https://kubernetes.io/ja/docs/><link rel=alternate hreflang=fr href=https://kubernetes.io/fr/docs/><link rel=alternate hreflang=it href=https://kubernetes.io/it/docs/><link rel=alternate hreflang=es href=https://kubernetes.io/es/docs/><link rel=alternate hreflang=pt-br href=https://kubernetes.io/pt-br/docs/><link rel=alternate hreflang=id href=https://kubernetes.io/id/docs/><link rel=alternate hreflang=hi href=https://kubernetes.io/hi/docs/><link rel=alternate hreflang=vi href=https://kubernetes.io/vi/docs/><link rel=alternate hreflang=ru href=https://kubernetes.io/ru/docs/><link rel=alternate hreflang=pl href=https://kubernetes.io/pl/docs/><link rel=alternate hreflang=uk href=https://kubernetes.io/uk/docs/><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=generator content="Hugo 0.110.0"><link rel=canonical type=text/html href=https://kubernetes.io/de/docs/><link rel="shortcut icon" type=image/png href=/images/favicon.png><link rel=apple-touch-icon href=/favicons/apple-touch-icon-180x180.png sizes=180x180><link rel=manifest href=/manifest.webmanifest><link rel=apple-touch-icon href=/images/kubernetes-192x192.png><title>Dokumentation | Kubernetes</title><meta property="og:title" content="Dokumentation"><meta property="og:description" content="Produktionsreife Container-Orchestrierung"><meta property="og:type" content="website"><meta property="og:url" content="https://kubernetes.io/de/docs/"><meta property="og:site_name" content="Kubernetes"><meta itemprop=name content="Dokumentation"><meta itemprop=description content="Produktionsreife Container-Orchestrierung"><meta name=twitter:card content="summary"><meta name=twitter:title content="Dokumentation"><meta name=twitter:description content="Produktionsreife Container-Orchestrierung"><link href=/scss/main.css rel=stylesheet><script type=application/ld+json>{"@context":"https://schema.org","@type":"Organization","url":"https://kubernetes.io","logo":"https://kubernetes.io/images/favicon.png","potentialAction":{"@type":"SearchAction","target":"https://kubernetes.io/search/?q={search_term_string}","query-input":"required name=search_term_string"}}</script><meta name=theme-color content="#326ce5"><link rel=stylesheet href=/css/feature-states.css><meta name=description content><meta property="og:description" content><meta name=twitter:description content><meta property="og:url" content="https://kubernetes.io/de/docs/"><meta property="og:title" content="Dokumentation"><meta name=twitter:title content="Dokumentation"><meta name=twitter:image content="https://kubernetes.io/images/favicon.png"><meta name=twitter:image:alt content="Kubernetes"><meta property="og:image" content="/images/kubernetes-horizontal-color.png"><meta property="og:type" content="article"><script src=/js/jquery-3.6.0.min.js intregrity=sha384-vtXRMe3mGCbOeY7l30aIg8H9p3GdeSe4IFlP6G8JMa7o7lXvnz3GFKzPxzJdPfGK crossorigin=anonymous></script></head><body class=td-section><header><nav class="js-navbar-scroll navbar navbar-expand navbar-dark flex-column flex-md-row td-navbar" data-auto-burger=primary><a class=navbar-brand href=/de/></a><div class="td-navbar-nav-scroll ml-md-auto" id=main_navbar><ul class="navbar-nav mt-2 mt-lg-0"><li class="nav-item mr-2 mb-lg-0"><a class="nav-link active" href=/de/docs/>Dokumentation</a></li><li class="nav-item mr-2 mb-lg-0"><a class=nav-link href=/de/blog/>Kubernetes Blog</a></li><li class="nav-item mr-2 mb-lg-0"><a class=nav-link href=/de/training/>Schulungen</a></li><li class="nav-item mr-2 mb-lg-0"><a class=nav-link href=/de/partners/>Partner</a></li><li class="nav-item mr-2 mb-lg-0"><a class=nav-link href=/de/community/>Community</a></li><li class="nav-item mr-2 mb-lg-0"><a class=nav-link href=/de/case-studies/>Fallstudien</a></li><li class="nav-item dropdown"><a class="nav-link dropdown-toggle" href=# id=navbarDropdown role=button data-toggle=dropdown aria-haspopup=true aria-expanded=false>Versions</a><div class="dropdown-menu dropdown-menu-right" aria-labelledby=navbarDropdownMenuLink><a class=dropdown-item href=/de/releases>Release Information</a>
<a class=dropdown-item href=https://kubernetes.io/de/docs/>v1.25</a>
<a class=dropdown-item href=https://v1-24.docs.kubernetes.io/de/docs/>v1.24</a>
<a class=dropdown-item href=https://v1-23.docs.kubernetes.io/de/docs/>v1.23</a>
<a class=dropdown-item href=https://v1-22.docs.kubernetes.io/de/docs/>v1.22</a>
<a class=dropdown-item href=https://v1-21.docs.kubernetes.io/de/docs/>v1.21</a></div></li><li class="nav-item dropdown"><a class="nav-link dropdown-toggle" href=# id=navbarDropdownMenuLink role=button data-toggle=dropdown aria-haspopup=true aria-expanded=false>Deutsch (German)</a><div class="dropdown-menu dropdown-menu-right" aria-labelledby=navbarDropdownMenuLink><a class=dropdown-item href=/docs/>English</a>
<a class=dropdown-item href=/zh-cn/docs/>中文 (Chinese)</a>
<a class=dropdown-item href=/ko/docs/>한국어 (Korean)</a>
<a class=dropdown-item href=/ja/docs/>日本語 (Japanese)</a>
<a class=dropdown-item href=/fr/docs/>Français (French)</a>
<a class=dropdown-item href=/it/docs/>Italiano (Italian)</a>
<a class=dropdown-item href=/es/docs/>Español (Spanish)</a>
<a class=dropdown-item href=/pt-br/docs/>Português (Portuguese)</a>
<a class=dropdown-item href=/id/docs/>Bahasa Indonesia</a>
<a class=dropdown-item href=/hi/docs/>हिन्दी (Hindi)</a>
<a class=dropdown-item href=/vi/docs/>Tiếng Việt (Vietnamese)</a>
<a class=dropdown-item href=/ru/docs/>Русский (Russian)</a>
<a class=dropdown-item href=/pl/docs/>Polski (Polish)</a>
<a class=dropdown-item href=/uk/docs/>Українська (Ukrainian)</a></div></li></ul></div><button id=hamburger onclick=kub.toggleMenu() data-auto-burger-exclude><div></div></button></nav></header><div class="container-fluid td-outer"><div class=td-main><div class="row flex-xl-nowrap"><main class="col-12 col-md-9 col-xl-8 pl-md-5" role=main><div class=td-content><div class="pageinfo pageinfo-primary d-print-none"><p>Das ist eine für den Ausdruck optimierte Ansicht des gesamten Kapitels inkl. Unterseiten.
<a href=# onclick="return print(),!1">Druckvorgang starten</a>.</p><p><a href=/de/docs/>Zur Standardansicht zurückkehren</a>.</p></div><h1 class=title>Dokumentation</h1><ul><li>1: <a href=#pg-e735cee7e913aa88bc0aa10594d12966>Kubernetes Dokumentation</a></li><ul><li>1.1: <a href=#pg-92dfff0ca612d0bff40171aa9df6c4ae>Unterstützte Versionen der Kubernetes-Dokumentation</a></li></ul><li>2: <a href=#pg-66b565805ca1061be35ff2c0165f13c1>Setup</a></li><ul><li>2.1: <a href=#pg-d33663ac044e1981b406949f9124cc04>Kubernetes herunterladen</a></li><ul><li>2.1.1: <a href=#pg-10b7970741f3e4925d298f965641410e>Release erstellen</a></li></ul><li>2.2: <a href=#pg-5b371d44337790d2ed5453caf048692b>Kubernetes lokal über Minikube betreiben</a></li></ul><li>3: <a href=#pg-dd948255948d6b59b32c471abcb62997>Konzepte</a></li><ul><li>3.1: <a href=#pg-0554ac387412eaf4e6e89b2f847dacde>Überblick</a></li><ul><li>3.1.1: <a href=#pg-45bdca6129cf540121623e903c18ba46>Was ist Kubernetes?</a></li><li>3.1.2: <a href=#pg-13b0f1dbe89228e3d76d2ac231e245f1>Kubernetes Komponenten</a></li></ul><li>3.2: <a href=#pg-2bf36ccd6b3dbeafecf87c39761b07c7>Kubernetes Architekur</a></li><ul><li>3.2.1: <a href=#pg-9ef2890698e773b6c0d24fd2c20146f5>Nodes</a></li><li>3.2.2: <a href=#pg-63e7fdf87ba61eb2586bb8c625c23506>Master-Node Kommunikation</a></li><li>3.2.3: <a href=#pg-bc804b02614d67025b4c788f1ca87fbc>Zugrunde liegende Konzepte des Cloud Controller Manager</a></li></ul><li>3.3: <a href=#pg-a5f7383c83ab9eb9cd0e3c4c020b3ae6>Container</a></li><ul><li>3.3.1: <a href=#pg-16042b4652ad19e565c7263824029a43>Images</a></li></ul><li>3.4: <a href=#pg-d52aadda80edd9f8c514cfe2321363c2>Workloads</a></li><ul><li>3.4.1: <a href=#pg-4d68b0ccf9c683e6368ffdcc40c838d4>Pods</a></li><ul></ul></ul><li>3.5: <a href=#pg-0a0a7eca3e302a3c08f8c85e15d337fd>Dienste, Lastverteilung und Netzwerkfunktionen</a></li><ul></ul><li>3.6: <a href=#pg-f018f568c6723865753f150c3c59bdda>Speicher</a></li><ul></ul><li>3.7: <a href=#pg-275bea454e1cf4c5adeca4058b5af988>Konfiguration</a></li><ul></ul><li>3.8: <a href=#pg-ac9161c6d952925b083ad9602b4e8e7f>Richtlinien</a></li><ul></ul><li>3.9: <a href=#pg-285a3785fd3d20f437c28d87ca4dadca>Cluster Administration</a></li><ul><li>3.9.1: <a href=#pg-08e94e6a480e0d6b2de72d84a1b97617>Proxies in Kubernetes</a></li><li>3.9.2: <a href=#pg-d5cc46b61677b53f61a407d20bdd0830>Controller Manager Metriken</a></li><li>3.9.3: <a href=#pg-85d633ae590aa20ec024f1b7af1d74fc>Addons Installieren</a></li></ul><li>3.10: <a href=#pg-7e0d97616b15e2c383c6a0a96ec442cb>Kubernetes erweitern</a></li><ul></ul><li>3.11: <a href=#pg-4c31edff4063c7b31c556b3eb1405c65>Konzept Dokumentations-Vorlage</a></li></ul><li>4: <a href=#pg-f8918f697450c2009b75913f9e9317a5>Aufgaben</a></li><ul><li>4.1: <a href=#pg-57bf66f59d9a642b82eebeabbc66470b>Werkzeuge installieren</a></li><ul><li>4.1.1: <a href=#pg-bbdc530b292ab4074d1dfe69feafb3e7>Installieren und konfigurieren von kubectl</a></li><li>4.1.2: <a href=#pg-2142bfe0834f1bf8f47887f85adba495>Installation von Minikube</a></li></ul><li>4.2: <a href=#pg-34a810f1516ad9d99b2697e36e9b0d0f>Einen Cluster verwalten</a></li><ul><li>4.2.1: <a href=#pg-8e16d69617b175d61e2e7a6e1642c9d6>Verwaltung mit kubeadm</a></li><ul></ul></ul><li>4.3: <a href=#pg-f5da33b976758a9183018c421eb83f58>Pods und Container konfigurieren</a></li><ul></ul><li>4.4: <a href=#pg-866924fa095f897ede8dfdcab9e97942>Daten in Anwendungen injizieren</a></li><ul></ul><li>4.5: <a href=#pg-a78a5e7e765fd8c49c8f7c0d72499f72>Anwendungen ausführen</a></li><ul><li>4.5.1: <a href=#pg-0c0bb1bd76d2a9069e50e2cec6d20c2a>Horizontal Pod Autoscaler</a></li></ul><li>4.6: <a href=#pg-ca3bc4e31dfe46d5044a3b93eb804ee9>Jobs ausführen</a></li><ul></ul><li>4.7: <a href=#pg-b74b959f5a531003dd0653dfbfc2e88b>Auf Anwendungen in einem Cluster zugreifen</a></li><ul></ul><li>4.8: <a href=#pg-f6a755efe831d24956501e4bcd49ff96>Überwachung, Protokollierung und Fehlerbehebung</a></li><ul></ul><li>4.9: <a href=#pg-fd78dc15c135dedc24438431769d4d5b>Kubernetes erweitern</a></li><ul></ul><li>4.10: <a href=#pg-d3c88a8663f58e9ec0bed73faff5b670>TLS</a></li><ul></ul><li>4.11: <a href=#pg-40e9293a348cfa50147082afc09ff77f>Föderation</a></li><ul></ul><li>4.12: <a href=#pg-ba58efa15c6d46f10e34d799be220965>Cluster-Daemons verwalten</a></li><ul></ul><li>4.13: <a href=#pg-5266308e17490aeee8b018316bf47e03>Service Catalog installieren</a></li><ul></ul></ul><li>5: <a href=#pg-68ec2370d0409cc27325be36693f9368>Tutorials</a></li><ul><li>5.1: <a href=#pg-5e3051fff9e84735871d9fb5e7b93f33>Hallo Minikube</a></li><li>5.2: <a href=#pg-3c83f53a74233ace9b289ac5e24c3e62>Kubernetes Grundlagen lernen</a></li><ul><li>5.2.1: <a href=#pg-7df66040311338d6098ebeab43ba9afb>Einen Cluster erstellen</a></li><ul><li>5.2.1.1: <a href=#pg-de49316920e97a82e36763cb66781ada>Minikube zum Erstellen eines Clusters verwenden</a></li><li>5.2.1.2: <a href=#pg-323b75976001e8dfe35d67d61bc74f1a>Interaktives Lernprogramm - Erstellen eines Clusters</a></li></ul><li>5.2.2: <a href=#pg-76d78b3fba507f7ed33cef14a35b631d>Eine App bereitstellen</a></li><ul><li>5.2.2.1: <a href=#pg-2b1bba431989008c7493109a0f049ece>Verwenden von kubectl zum Erstellen eines Deployments</a></li><li>5.2.2.2: <a href=#pg-f8997ec143b382fa6c9621941ea62ca3>Interaktives Lernprogramm - Bereitstellen einer App</a></li></ul><li>5.2.3: <a href=#pg-250d620a73ec8be7e1f7d835574c4596>Entdecken Sie Ihre App</a></li><ul><li>5.2.3.1: <a href=#pg-2771f4e8c45321b17cb0114a2d266453>Anzeigen von Pods und Nodes</a></li><li>5.2.3.2: <a href=#pg-4b01eab98a9844ad91131079654199dd>Interaktives Lernprogramm - Entdecken Sie Ihre App</a></li></ul><li>5.2.4: <a href=#pg-4b0e31c9e0eae68bbb0a358b4042ada9>Machen Sie Ihre App öffentlich zugänglich</a></li><ul><li>5.2.4.1: <a href=#pg-8ef4dad8f743b191a9e8c6f891cb191a>Verwendung eines Services zum Veröffentlichen Ihrer App</a></li><li>5.2.4.2: <a href=#pg-352241d22effe0714772d21c7d1b512d>Interaktives Lernprogramm - Ihre App öffentlich zugänglich machen</a></li></ul><li>5.2.5: <a href=#pg-be4996c93fb39c459a30b6669569d423>Skalieren Sie Ihre App</a></li><ul><li>5.2.5.1: <a href=#pg-d1c15c9bd4f625adbc13149b1475287c>Mehrere Instanzen Ihrer App ausführen</a></li><li>5.2.5.2: <a href=#pg-7bdb3fbaa1177ff5dfa3fe86bd35ef59>Interaktives Lernprogramm - Skalieren Ihrer App</a></li></ul><li>5.2.6: <a href=#pg-62b8b17dadfb55f1801cf8439e944e58>Aktualisieren Sie Ihre App</a></li><ul><li>5.2.6.1: <a href=#pg-12e04355145afad615ca3c38335ba019>Durchführen eines Rolling-Updates</a></li><li>5.2.6.2: <a href=#pg-dddc0cb356c280e0339bcf42776987dc>Interaktives Lernprogramm - Aktualisieren Ihrer App</a></li></ul></ul></ul><li>6: <a href=#pg-b00a88a07ceb21b1a83e5822e0c86c1d>Referenzen</a></li><ul><li>6.1: <a href=#pg-2b03679960950df772fb4fe7d78427b9>Standardisiertes Glossar</a></li><li>6.2: <a href=#pg-af7c1f9168ec67f957edc504f43faf9a>Kubernetes Probleme und Sicherheit</a></li><ul></ul><li>6.3: <a href=#pg-882c82a32bfb4d7946585a93a966b442>Verwendung der Kubernetes-API</a></li><ul></ul><li>6.4: <a href=#pg-99b26586d8a33ec06996dcf7892a9683>API Zugriff</a></li><ul></ul><li>6.5: <a href=#pg-60a16da3955f1de774f1f8dd756f2251>API Referenzinformationen</a></li><ul></ul><li>6.6: <a href=#pg-a92541c7b5589e722b0b250b8ee3172d>Föderation API</a></li><ul></ul><li>6.7: <a href=#pg-5bbbc5163b35431b3bff029ab9ec57d3>Setup-Tools Referenzinformationen</a></li><ul></ul><li>6.8: <a href=#pg-54e562dd1441d0195970a6526b0055cc>Befehlszeilen-Werkzeug Referenzinformationen</a></li><ul></ul><li>6.9: <a href=#pg-03460a7254c6c73eb2a1bb3dd7d25910>kubectl CLI</a></li><ul><li>6.9.1: <a href=#pg-8aba901ac13f124e5782b90ddb166ee2>kubectl Spickzettel</a></li></ul><li>6.10: <a href=#pg-4f002b9458521ca7afd32176fd590646>Tools</a></li></ul><li>7: <a href=#pg-4985cb55ddfb184639d767ec54b9f0f7>Zur Kubernetes-Dokumentation beitragen</a></li><ul><li>7.1: <a href=#pg-849a2fdb87779db1c212fe5a9f88ff0d>Lokalisierung der Kubernetes Dokumentation</a></li><li>7.2: <a href=#pg-8b9b22280711800788333c1a4d129735>Bei SIG Docs mitmachen</a></li><ul><li>7.2.1: <a href=#pg-76656ea25ba7e6404601838389262482>Rollen und Verantwortlichkeiten</a></li><li>7.2.2: <a href=#pg-48abd3bcfba9976d000a96a0734b90f6>PR Wranglers</a></li></ul></ul><li>8: <a href=#pg-91737b3265a3e3f407fbeeb86a8973ab></a></li><li>9: <a href=#pg-a0415b49c9410c15a8694fed28aa36ae>Suchergebnisse</a></li></ul><div class=content></div></div><div class=td-content><h1 id=pg-e735cee7e913aa88bc0aa10594d12966>1 - Kubernetes Dokumentation</h1></div><div class=td-content><h1 id=pg-92dfff0ca612d0bff40171aa9df6c4ae>1.1 - Unterstützte Versionen der Kubernetes-Dokumentation</h1><p>Diese Website enthält Dokumentation für die aktuelle Version von Kubernetes
und die vier vorherigen Versionen von Kubernetes.</p><h2 id=aktuelle-version>Aktuelle Version</h2><p>Die aktuelle Version ist
<a href=/>v1.25</a>.</p><h2 id=vorherige-versionen>Vorherige Versionen</h2><ul><li><a href=https://v1-24.docs.kubernetes.io>v1.24</a></li><li><a href=https://v1-23.docs.kubernetes.io>v1.23</a></li><li><a href=https://v1-22.docs.kubernetes.io>v1.22</a></li><li><a href=https://v1-21.docs.kubernetes.io>v1.21</a></li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-66b565805ca1061be35ff2c0165f13c1>2 - Setup</h1><p>Diese Sektion umfasst verschiedene Optionen zum Einrichten und Betrieb von Kubernetes.</p><p>Verschiedene Kubernetes Lösungen haben verschiedene Anforderungen: Einfache Wartung, Sicherheit, Kontrolle, verfügbare Resourcen und erforderliches Fachwissen zum Betrieb und zur Verwaltung. Das folgende Diagramm zeigt die möglichen Abstraktionen eines Kubernetes-Clusters und ob eine Abstraktion selbst verwaltet oder von einem Anbieter verwaltet wird.</p><p>Sie können einen Kubernetes-Cluster auf einer lokalen Maschine, Cloud, On-Prem Datacenter bereitstellen; oder wählen Sie einen verwalteten Kubernetes-Cluster. Sie können auch eine individuelle Lösung über eine grosse Auswahl an Cloud Anbietern oder Bare-Metal-Umgebungen nutzen.</p><p>Noch einfacher können Sie einen Kubernetes-Cluster in einer Lern- und Produktionsumgebung erstellen.</p><h2 id=lernumgebung>Lernumgebung</h2><p>Benutzen Sie eine Docker-basierende Lösung, wenn Sie Kubernetes erlernen wollen: Von der Kubernetes-Community unterstützte Werkzeuge oder Werkzeuge in einem Ökosystem zum Einrichten eines Kubernetes-Clusters auf einer lokalen Maschine.</p><table><caption style=display:none>Tabelle mit Lösungen für lokale Maschinen, in der die Tools aufgeführt sind, die von der Community und dem Ökosystem für die Bereitstellung von Kubernetes unterstützt werden.</caption><thead><tr><th>Community</th><th>Ökosystem</th></tr></thead><tbody><tr><td><a href=/docs/setup/learning-environment/minikube/>Minikube</a></td><td><a href=https://www.ubuntu.com/kubernetes/docs/install-local>CDK on LXD</a></td></tr><tr><td><a href=https://github.com/kubernetes-sigs/kind>kind (Kubernetes IN Docker)</a></td><td><a href=https://www.docker.com/products/docker-desktop>Docker Desktop</a></td></tr><tr><td></td><td><a href=https://docs.okd.io/latest/minishift/>Minishift</a></td></tr><tr><td></td><td><a href=https://microk8s.io/>MicroK8s</a></td></tr><tr><td></td><td><a href=https://github.com/IBM/deploy-ibm-cloud-private>IBM Cloud Private-CE (Community Edition)</a></td></tr><tr><td></td><td><a href=https://github.com/HSBawa/icp-ce-on-linux-containers>IBM Cloud Private-CE (Community Edition) on Linux Containers</a></td></tr><tr><td></td><td><a href=https://k3s.io>k3s</a></td></tr></tbody></table><h2 id=produktionsumgebung>Produktionsumgebung</h2><p>Überlegen Sie sich bei der Bewertung einer Lösung für eine Produktionsumgebung, welche Aspekte des Betriebs eines Kubernetes-Clusters (oder von <em>abstractions</em>) Sie selbst verwalten oder an einen Anbieter auslagern möchten.</p><p>Einige mögliche Abstraktionen von Kubernetes-Clustern sind <a class=glossary-tooltip title='The layer where various containerized applications run.' data-toggle=tooltip data-placement=top href='/de/docs/reference/glossary/?all=true#term-applications' target=_blank aria-label=applications>applications</a>, <a class=glossary-tooltip title='The layer that provides capacity such as CPU, memory, network, and storage so that the containers can run and connect to a network.' data-toggle=tooltip data-placement=top href='/de/docs/reference/glossary/?all=true#term-data-plane' target=_blank aria-label='data plane'>data plane</a>, <a class=glossary-tooltip title='The container orchestration layer that exposes the API and interfaces to define, deploy, and manage the lifecycle of containers.' data-toggle=tooltip data-placement=top href='/de/docs/reference/glossary/?all=true#term-control-plane' target=_blank aria-label='control plane'>control plane</a>, <a class=glossary-tooltip title='The infrastructure layer provides and maintains VMs, networking, security groups and others.' data-toggle=tooltip data-placement=top href='/de/docs/reference/glossary/?all=true#term-cluster-infrastructure' target=_blank aria-label='cluster infrastructure'>cluster infrastructure</a> und <a class=glossary-tooltip title='The work involved in managing a Kubernetes cluster.' data-toggle=tooltip data-placement=top href='/de/docs/reference/glossary/?all=true#term-cluster-operations' target=_blank aria-label='cluster operations'>cluster operations</a>.</p><p>Das folgende Diagramm zeigt die möglichen Abstraktionen eines Kubernetes-Clusters und ob eine Abstraktion selbst verwaltet oder von einem Anbieter verwaltet wird.</p><p>Lösungen für Produktionsumgebungen<img src=/images/docs/KubernetesSolutions.svg alt="Lösungen für Produktionsumgebungen"></p><p>Die folgende Tabelle für Produktionsumgebungs-Lösungen listet Anbieter und deren Lösungen auf.</p><table><caption style=display:none>Tabelle mit Lösungen für lokale Maschinen, in der die Tools aufgeführt sind, die von der Community und dem Ökosystem für die Bereitstellung von Kubernetes unterstützt werden.</caption><caption style=display:none>Tabelle für Produktionsumgebungs-Lösungen listet Anbieter und deren Lösungen auf.</caption><thead><tr><th>Providers</th><th>Managed</th><th>Turnkey cloud</th><th>On-Prem Datacenter</th><th>Custom (cloud)</th><th>Custom (On-premises VMs)</th><th>Custom (Bare Metal)</th></tr></thead><tbody><tr><td><a href=https://www.agilestacks.com/products/kubernetes>Agile Stacks</a></td><td></td><td>✔</td><td>✔</td><td></td><td></td><td></td></tr><tr><td><a href=https://www.alibabacloud.com/product/kubernetes>Alibaba Cloud</a></td><td></td><td>✔</td><td></td><td></td><td></td><td></td></tr><tr><td><a href=https://aws.amazon.com>Amazon</a></td><td><a href=https://aws.amazon.com/eks/>Amazon EKS</a></td><td><a href=https://aws.amazon.com/ec2/>Amazon EC2</a></td><td></td><td></td><td></td><td></td></tr><tr><td><a href=https://appscode.com/products/pharmer/>AppsCode</a></td><td>✔</td><td></td><td></td><td></td><td></td><td></td></tr><tr><td><a href=https://appuio.ch/>APPUiO</a> </td><td>✔</td><td>✔</td><td>✔</td><td></td><td></td><td></td></tr><tr><td><a href=https://banzaicloud.com/products/pke/>Banzai Cloud Pipeline Kubernetes Engine (PKE)</a></td><td></td><td>✔</td><td></td><td>✔</td><td>✔</td><td>✔</td></tr><tr><td><a href=https://www.ctl.io/>CenturyLink Cloud</a></td><td></td><td>✔</td><td></td><td></td><td></td><td></td></tr><tr><td><a href=https://cisco.com/go/containers>Cisco Container Platform</a></td><td></td><td></td><td>✔</td><td></td><td></td><td></td></tr><tr><td><a href=https://docs-cfcr.cfapps.io/>Cloud Foundry Container Runtime (CFCR)</a></td><td></td><td></td><td></td><td>✔</td><td>✔</td><td></td></tr><tr><td><a href=https://cloudstack.apache.org/>CloudStack</a></td><td></td><td></td><td></td><td></td><td>✔</td><td></td></tr><tr><td><a href=https://ubuntu.com/kubernetes>Canonical</a></td><td>✔</td><td>✔</td><td>✔</td><td>✔</td><td>✔</td><td>✔</td></tr><tr><td><a href=https://containership.io>Containership</a></td><td>✔</td><td>✔</td><td></td><td></td><td></td><td></td></tr><tr><td><a href=https://d2iq.com/>D2iQ</a></td><td></td><td><a href=https://d2iq.com/solutions/ksphere>Kommander</a></td><td><a href=https://d2iq.com/solutions/ksphere/konvoy>Konvoy</a></td><td><a href=https://d2iq.com/solutions/ksphere/konvoy>Konvoy</a></td><td><a href=https://d2iq.com/solutions/ksphere/konvoy>Konvoy</a></td><td><a href=https://d2iq.com/solutions/ksphere/konvoy>Konvoy</a></td></tr><tr><td><a href=https://provision.readthedocs.io/en/tip/README.html>Digital Rebar</a></td><td></td><td></td><td></td><td></td><td></td><td>✔</td></tr><tr><td><a href=https://www.digitalocean.com/products/kubernetes/>DigitalOcean</a></td><td>✔</td><td></td><td></td><td></td><td></td><td></td></tr><tr><td><a href=https://www.docker.com/products/docker-enterprise>Docker Enterprise</a></td><td></td><td>✔</td><td>✔</td><td></td><td></td><td>✔</td></tr><tr><td><a href=https://gardener.cloud/>Gardener</a></td><td>✔</td><td>✔</td><td>✔</td><td>✔</td><td>✔</td><td><a href=https://github.com/gardener/gardener/blob/master/docs/extensions/overview.md>Custom Extensions</a></td></tr><tr><td><a href=https://www.giantswarm.io/>Giant Swarm</a></td><td>✔</td><td>✔</td><td>✔</td><td></td><td></td><td></td></tr><tr><td><a href=https://cloud.google.com/>Google</a></td><td><a href=https://cloud.google.com/kubernetes-engine/>Google Kubernetes Engine (GKE)</a></td><td><a href=https://cloud.google.com/compute/>Google Compute Engine (GCE)</a></td><td><a href=https://cloud.google.com/gke-on-prem/>GKE On-Prem</a></td><td></td><td></td><td></td></tr><tr><td><a href=https://www.ibm.com/in-en/cloud>IBM</a></td><td><a href=https://cloud.ibm.com/kubernetes/catalog/cluster>IBM Cloud Kubernetes Service</a></td><td></td><td><a href=https://www.ibm.com/in-en/cloud/private>IBM Cloud Private</a></td><td></td><td></td><td></td></tr><tr><td><a href=https://www.ionos.com/enterprise-cloud>Ionos</a></td><td><a href=https://www.ionos.com/enterprise-cloud/managed-kubernetes>Ionos Managed Kubernetes</a></td><td><a href=https://www.ionos.com/enterprise-cloud>Ionos Enterprise Cloud</a></td><td></td><td></td><td></td><td></td></tr><tr><td><a href=https://www.kontena.io/pharos/>Kontena Pharos</a></td><td></td><td>✔</td><td>✔</td><td></td><td></td><td></td></tr><tr><td><a href=https://kubeone.io/>KubeOne</a></td><td></td><td>✔</td><td>✔</td><td>✔</td><td>✔</td><td>✔</td></tr><tr><td><a href=https://kubermatic.io/>Kubermatic</a></td><td>✔</td><td>✔</td><td>✔</td><td>✔</td><td>✔</td><td></td></tr><tr><td><a href=https://kubesail.com/>KubeSail</a></td><td>✔</td><td></td><td></td><td></td><td></td><td></td></tr><tr><td><a href=https://kubespray.io/#/>Kubespray</a></td><td></td><td></td><td></td><td>✔</td><td>✔</td><td>✔</td></tr><tr><td><a href=https://kublr.com/>Kublr</a></td><td>✔</td><td>✔</td><td>✔</td><td>✔</td><td>✔</td><td>✔</td></tr><tr><td><a href=https://azure.microsoft.com>Microsoft Azure</a></td><td><a href=https://azure.microsoft.com/en-us/services/kubernetes-service/>Azure Kubernetes Service (AKS)</a></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td><a href=https://www.mirantis.com/software/kubernetes/>Mirantis Cloud Platform</a></td><td></td><td></td><td>✔</td><td></td><td></td><td></td></tr><tr><td><a href=https://www.nirmata.com/>Nirmata</a></td><td></td><td>✔</td><td>✔</td><td></td><td></td><td></td></tr><tr><td><a href=https://www.nutanix.com/en>Nutanix</a></td><td><a href=https://www.nutanix.com/products/karbon>Nutanix Karbon</a></td><td><a href=https://www.nutanix.com/products/karbon>Nutanix Karbon</a></td><td></td><td></td><td><a href=https://www.nutanix.com/products/acropolis/virtualization>Nutanix AHV</a></td><td></td></tr><tr><td><a href=https://www.opennebula.org>OpenNebula</a></td><td><a href=https://marketplace.opennebula.systems/docs/service/kubernetes.html>OpenNebula Kubernetes</a></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td><a href=https://www.openshift.com>OpenShift</a></td><td><a href=https://www.openshift.com/products/dedicated/>OpenShift Dedicated</a> and <a href=https://www.openshift.com/products/online/>OpenShift Online</a></td><td></td><td><a href=https://www.openshift.com/products/container-platform/>OpenShift Container Platform</a></td><td></td><td><a href=https://www.openshift.com/products/container-platform/>OpenShift Container Platform</a></td><td><a href=https://www.openshift.com/products/container-platform/>OpenShift Container Platform</a></td></tr><tr><td><a href=https://docs.cloud.oracle.com/iaas/Content/ContEng/Concepts/contengoverview.htm>Oracle Cloud Infrastructure Container Engine for Kubernetes (OKE)</a></td><td>✔</td><td>✔</td><td></td><td></td><td></td><td></td></tr><tr><td><a href=https://www.ovirt.org/>oVirt</a></td><td></td><td></td><td></td><td></td><td>✔</td><td></td></tr><tr><td><a href=https://pivotal.io/>Pivotal</a></td><td></td><td><a href=https://pivotal.io/platform/pivotal-container-service>Enterprise Pivotal Container Service (PKS)</a></td><td><a href=https://pivotal.io/platform/pivotal-container-service>Enterprise Pivotal Container Service (PKS)</a></td><td></td><td></td><td></td></tr><tr><td><a href=https://platform9.com/>Platform9</a></td><td><a href=https://platform9.com/managed-kubernetes/>Platform9 Managed Kubernetes</a></td><td></td><td><a href=https://platform9.com/managed-kubernetes/>Platform9 Managed Kubernetes</a></td><td>✔</td><td>✔</td><td>✔</td></tr><tr><td><a href=https://rancher.com/>Rancher</a></td><td></td><td><a href=https://rancher.com/docs/rancher/v2.x/en/>Rancher 2.x</a></td><td></td><td><a href=https://rancher.com/docs/rke/latest/en/>Rancher Kubernetes Engine (RKE)</a></td><td></td><td><a href=https://k3s.io/>k3s</a></td></tr><tr><td><a href=https://stackpoint.io/>StackPoint</a> </td><td>✔</td><td>✔</td><td></td><td></td><td></td><td></td></tr><tr><td><a href=https://supergiant.io/>Supergiant</a></td><td></td><td>✔</td><td></td><td></td><td></td><td></td></tr><tr><td><a href=https://www.suse.com/>SUSE</a></td><td></td><td>✔</td><td></td><td></td><td></td><td></td></tr><tr><td><a href=https://www.syseleven.io/>SysEleven</a></td><td>✔</td><td></td><td></td><td></td><td></td><td></td></tr><tr><td><a href=https://intl.cloud.tencent.com/>Tencent Cloud</a></td><td><a href=https://intl.cloud.tencent.com/product/tke>Tencent Kubernetes Engine</a></td><td>✔</td><td>✔</td><td></td><td></td><td>✔</td></tr><tr><td><a href=https://vexxhost.com/>VEXXHOST</a></td><td>✔</td><td>✔</td><td></td><td></td><td></td><td></td></tr><tr><td><a href=https://cloud.vmware.com/>VMware</a></td><td><a href=https://cloud.vmware.com/vmware-cloud-pks>VMware Cloud PKS</a></td><td><a href=https://cloud.vmware.com/vmware-enterprise-pks>VMware Enterprise PKS</a></td><td><a href=https://cloud.vmware.com/vmware-enterprise-pks>VMware Enterprise PKS</a></td><td><a href=https://cloud.vmware.com/vmware-essential-pks>VMware Essential PKS</a></td><td></td><td><a href=https://cloud.vmware.com/vmware-essential-pks>VMware Essential PKS</a></td></tr><tr><td><a href=https://zarvis.ai/>Z.A.R.V.I.S.</a></td><td>✔</td><td></td><td></td><td></td><td></td><td></td></tr></tbody></table></div><div class=td-content style=page-break-before:always><h1 id=pg-d33663ac044e1981b406949f9124cc04>2.1 - Kubernetes herunterladen</h1></div><div class=td-content><h1 id=pg-10b7970741f3e4925d298f965641410e>2.1.1 - Release erstellen</h1><p>Sie können entweder eine Version aus dem Quellcode erstellen oder eine bereits kompilierte Version herunterladen.
Wenn Sie nicht vorhaben, Kubernetes selbst zu entwickeln, empfehlen wir die Verwendung eines vorkompilierten Builds der aktuellen Version, die Sie in den <a href=/docs/setup/release/notes/>Versionshinweisen</a> finden.</p><p>Der Kubernetes-Quellcode kann aus dem <a href=https://github.com/kubernetes/kubernetes>kubernetes/kubernetes</a> repo der heruntergeladen werden.</p><h2 id=aus-dem-quellcode-kompilieren>Aus dem Quellcode kompilieren</h2><p>Wenn Sie einfach ein Release aus dem Quellcode erstellen, müssen Sie keine vollständige Golang-Umgebung einrichten, da alle Aktionen in einem Docker-Container stattfinden.</p><p>Das Kompilieren einer Version ist einfach:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>git clone https://github.com/kubernetes/kubernetes.git
</span></span><span style=display:flex><span><span style=color:#a2f>cd</span> kubernetes
</span></span><span style=display:flex><span>make release
</span></span></code></pre></div><p>Mehr Informationen zum Release-Prozess finden Sie im kubernetes/kubernetes <a href=http://releases.k8s.io/master/build/><code>build</code></a> Verzeichnis.</p></div><div class=td-content style=page-break-before:always><h1 id=pg-5b371d44337790d2ed5453caf048692b>2.2 - Kubernetes lokal über Minikube betreiben</h1><p>Minikube ist ein Tool, mit dem Kubernetes lokal einfach ausgeführt werden kann. Minikube führt einen Kubernetes-Cluster mit einem einzigen Node in einer VM auf Ihrem Laptop aus, damit Anwender Kubernetes ausprobieren oder täglich damit entwickeln können.</p><h2 id=minikube-funktionen>Minikube-Funktionen</h2><ul><li>Minikube unterstützt Kubernetes-Funktionen wie:<ul><li>DNS</li><li>NodePorts</li><li>ConfigMaps and Secrets</li><li>Dashboards</li><li>Container Laufzeiumgebungen: Docker, <a href=https://github.com/rkt/rkt>rkt</a>, <a href=https://cri-o.io/>CRI-O</a> und <a href=https://github.com/containerd/containerd>containerd</a></li><li>Unterstützung von CNI (Container Network Interface)</li><li>Ingress</li></ul></li></ul><h2 id=installation>Installation</h2><p>Lesen Sie <a href=/docs/tasks/tools/install-minikube/>Minikube installieren</a> für Informationen zur Installation von Minikubes.</p><h2 id=schnellstart>Schnellstart</h2><p>Folgend finden Sie eine kurze Demo zur Verwendung von Minikube.
Wenn Sie den VM-Treiber ändern möchten, fügen Sie das entsprechende <code>--vm-driver=xxx</code>-Flag zu <code>minikube start</code> hinzu.
Minikube unterstützt die folgenden Treiber:</p><ul><li>virtualbox</li><li>vmwarefusion</li><li>kvm2 (<a href=https://minikube.sigs.k8s.io/docs/drivers/#kvm2-driver>Treiber installation</a>)</li><li>kvm (<a href=https://minikube.sigs.k8s.io/docs/drivers/#kvm-driver>Treiber installation</a>)</li><li>hyperkit (<a href=https://minikube.sigs.k8s.io/docs/drivers/#hyperkit-driver>Treiber installation</a>)</li><li>xhyve (<a href=https://minikube.sigs.k8s.io/docs/drivers/#xhyve-driver>Treiber installation</a>) (deprecated)</li><li>hyperv (<a href=https://minikube.sigs.k8s.io/docs/drivers/#hyperv-driver>Treiber installation</a>)
Beachten Sie, dass die unten angegebene IP-Adresse dynamisch ist und sich ändern kann. Sie kann mit <code>minikube ip</code> abgerufen werden.</li><li>none (Führt die Kubernetes-Komponenten auf dem Host und nicht in einer VM aus. Die Verwendung dieses Treibers erfordert Docker (<a href=https://docs.docker.com/install/linux/docker-ce/ubuntu/>Docker installieren</a>) und eine Linux-Umgebung)</li></ul><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>minikube start
</span></span></code></pre></div><pre tabindex=0><code>Starting local Kubernetes cluster...
Running pre-create checks...
Creating machine...
Starting local Kubernetes cluster...
</code></pre><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl create deployment hello-minikube --image<span style=color:#666>=</span>k8s.gcr.io/echoserver:1.10
</span></span></code></pre></div><pre tabindex=0><code>deployment.apps/hello-minikube created
</code></pre><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl expose deployment hello-minikube --type<span style=color:#666>=</span>NodePort --port<span style=color:#666>=</span><span style=color:#666>8080</span>
</span></span></code></pre></div><pre tabindex=0><code>service/hello-minikube exposed
</code></pre><pre tabindex=0><code># Wir haben jetzt einen echoserver Pod gestartet, aber wir müssen warten,
# bis der Pod betriebsbereit ist, bevor wir über den exponierten Dienst auf ihn zugreifen können.
# Um zu überprüfen, ob der Pod läuft, können wir Folgendes verwenden:
kubectl get pod
</code></pre><pre tabindex=0><code>NAME                              READY     STATUS              RESTARTS   AGE
hello-minikube-3383150820-vctvh   0/1       ContainerCreating   0          3s
</code></pre><pre tabindex=0><code># Wir können anhand des ContainerCreating-Status sehen, dass der Pod immer noch erstellt wird.
kubectl get pod
</code></pre><pre tabindex=0><code>NAME                              READY     STATUS    RESTARTS   AGE
hello-minikube-3383150820-vctvh   1/1       Running   0          13s
</code></pre><pre tabindex=0><code># Wir können sehen, dass der Pod jetzt läuft und wir können ihn jetzt mit curl kontaktieren:
curl $(minikube service hello-minikube --url)
</code></pre><pre tabindex=0><code>
Hostname: hello-minikube-7c77b68cff-8wdzq

Pod Information:
	-no pod information available-

Server values:
	server_version=nginx: 1.13.3 - lua: 10008

Request Information:
	client_address=172.17.0.1
	method=GET
	real path=/
	query=
	request_version=1.1
	request_scheme=http
	request_uri=http://192.168.99.100:8080/

Request Headers:
	accept=*/*
	host=192.168.99.100:30674
	user-agent=curl/7.47.0

Request Body:
	-no body in request-
</code></pre><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl delete services hello-minikube
</span></span></code></pre></div><pre tabindex=0><code>service &#34;hello-minikube&#34; deleted
</code></pre><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl delete deployment hello-minikube
</span></span></code></pre></div><pre tabindex=0><code>deployment.extensions &#34;hello-minikube&#34; deleted
</code></pre><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>minikube stop
</span></span></code></pre></div><pre tabindex=0><code>Stopping local Kubernetes cluster...
Stopping &#34;minikube&#34;...
</code></pre><h3 id=alternative-containerlaufzeitumgebungen>Alternative Containerlaufzeitumgebungen</h3><h4 id=containerd>containerd</h4><p>Um <a href=https://github.com/containerd/containerd>containerd</a> als Containerlaufzeitumgebung zu verwenden, führen Sie den folgenden Befehl aus:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>minikube start <span style=color:#b62;font-weight:700>\
</span></span></span><span style=display:flex><span><span style=color:#b62;font-weight:700></span>    --network-plugin<span style=color:#666>=</span>cni <span style=color:#b62;font-weight:700>\
</span></span></span><span style=display:flex><span><span style=color:#b62;font-weight:700></span>    --enable-default-cni <span style=color:#b62;font-weight:700>\
</span></span></span><span style=display:flex><span><span style=color:#b62;font-weight:700></span>    --container-runtime<span style=color:#666>=</span>containerd <span style=color:#b62;font-weight:700>\
</span></span></span><span style=display:flex><span><span style=color:#b62;font-weight:700></span>    --bootstrapper<span style=color:#666>=</span>kubeadm
</span></span></code></pre></div><p>Oder verwenden Sie die erweiterte Version:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>minikube start <span style=color:#b62;font-weight:700>\
</span></span></span><span style=display:flex><span><span style=color:#b62;font-weight:700></span>    --network-plugin<span style=color:#666>=</span>cni <span style=color:#b62;font-weight:700>\
</span></span></span><span style=display:flex><span><span style=color:#b62;font-weight:700></span>    --enable-default-cni <span style=color:#b62;font-weight:700>\
</span></span></span><span style=display:flex><span><span style=color:#b62;font-weight:700></span>    --extra-config<span style=color:#666>=</span>kubelet.container-runtime<span style=color:#666>=</span>remote <span style=color:#b62;font-weight:700>\
</span></span></span><span style=display:flex><span><span style=color:#b62;font-weight:700></span>    --extra-config<span style=color:#666>=</span>kubelet.container-runtime-endpoint<span style=color:#666>=</span>unix:///run/containerd/containerd.sock <span style=color:#b62;font-weight:700>\
</span></span></span><span style=display:flex><span><span style=color:#b62;font-weight:700></span>    --extra-config<span style=color:#666>=</span>kubelet.image-service-endpoint<span style=color:#666>=</span>unix:///run/containerd/containerd.sock <span style=color:#b62;font-weight:700>\
</span></span></span><span style=display:flex><span><span style=color:#b62;font-weight:700></span>    --bootstrapper<span style=color:#666>=</span>kubeadm
</span></span></code></pre></div><h4 id=cri-o>CRI-O</h4><p>Um <a href=https://cri-o.io/>CRI-O</a> als Containerlaufzeitumgebung zu verwenden, führen Sie den folgenden Befehl aus:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>minikube start <span style=color:#b62;font-weight:700>\
</span></span></span><span style=display:flex><span><span style=color:#b62;font-weight:700></span>    --network-plugin<span style=color:#666>=</span>cni <span style=color:#b62;font-weight:700>\
</span></span></span><span style=display:flex><span><span style=color:#b62;font-weight:700></span>    --enable-default-cni <span style=color:#b62;font-weight:700>\
</span></span></span><span style=display:flex><span><span style=color:#b62;font-weight:700></span>    --container-runtime<span style=color:#666>=</span>cri-o <span style=color:#b62;font-weight:700>\
</span></span></span><span style=display:flex><span><span style=color:#b62;font-weight:700></span>    --bootstrapper<span style=color:#666>=</span>kubeadm
</span></span></code></pre></div><p>Oder verwenden Sie die erweiterte Version:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>minikube start <span style=color:#b62;font-weight:700>\
</span></span></span><span style=display:flex><span><span style=color:#b62;font-weight:700></span>    --network-plugin<span style=color:#666>=</span>cni <span style=color:#b62;font-weight:700>\
</span></span></span><span style=display:flex><span><span style=color:#b62;font-weight:700></span>    --enable-default-cni <span style=color:#b62;font-weight:700>\
</span></span></span><span style=display:flex><span><span style=color:#b62;font-weight:700></span>    --extra-config<span style=color:#666>=</span>kubelet.container-runtime<span style=color:#666>=</span>remote <span style=color:#b62;font-weight:700>\
</span></span></span><span style=display:flex><span><span style=color:#b62;font-weight:700></span>    --extra-config<span style=color:#666>=</span>kubelet.container-runtime-endpoint<span style=color:#666>=</span>/var/run/crio.sock <span style=color:#b62;font-weight:700>\
</span></span></span><span style=display:flex><span><span style=color:#b62;font-weight:700></span>    --extra-config<span style=color:#666>=</span>kubelet.image-service-endpoint<span style=color:#666>=</span>/var/run/crio.sock <span style=color:#b62;font-weight:700>\
</span></span></span><span style=display:flex><span><span style=color:#b62;font-weight:700></span>    --bootstrapper<span style=color:#666>=</span>kubeadm
</span></span></code></pre></div><h4 id=rkt-container-engine>rkt container engine</h4><p>Um <a href=https://github.com/rkt/rkt>rkt</a> als Containerlaufzeitumgebung zu verwenden, führen Sie den folgenden Befehl aus:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>minikube start <span style=color:#b62;font-weight:700>\
</span></span></span><span style=display:flex><span><span style=color:#b62;font-weight:700></span>    --network-plugin<span style=color:#666>=</span>cni <span style=color:#b62;font-weight:700>\
</span></span></span><span style=display:flex><span><span style=color:#b62;font-weight:700></span>    --enable-default-cni <span style=color:#b62;font-weight:700>\
</span></span></span><span style=display:flex><span><span style=color:#b62;font-weight:700></span>    --container-runtime<span style=color:#666>=</span>rkt
</span></span></code></pre></div><p>Hierbei wird ein alternatives Minikube-ISO-Image verwendet, das sowohl rkt als auch Docker enthält, und CNI-Netzwerke ermöglichen.</p><h3 id=treiber-plugins>Treiber Plugins</h3><p>Weitere Informationen zu unterstützten Treibern und zur Installation von Plugins finden Sie bei Bedarf unter <a href=https://minikube.sigs.k8s.io/docs/drivers/>TREIBER</a>.</p><h3 id=lokale-images-durch-erneute-verwendung-des-docker-daemon-ausführen>Lokale Images durch erneute Verwendung des Docker-Daemon ausführen</h3><p>Wenn Sie eine einzige Kubernetes VM verwenden, ist es sehr praktisch, den integrierten Docker-Daemon von Minikube wiederzuverwenden; Dies bedeutet, dass Sie auf Ihrem lokalen Computer keine Docker-Registy erstellen und das Image in die Registry importieren müssen - Sie können einfach innerhalb desselben Docker-Daemons wie Minikube arbeiten, was lokale Experimente beschleunigt. Stellen Sie einfach sicher, dass Sie Ihr Docker-Image mit einem anderen Element als 'latest' versehen, und verwenden Sie dieses Tag, wenn Sie das Image laden. Andernfalls, wenn Sie keine Version Ihres Images angeben, wird es als <code>:latest</code> angenommen, mit der Pull-Image-Richtlinie von <code>Always</code> entsprechend, was schließlich zu <code>ErrImagePull</code> führen kann, da Sie möglicherweise noch keine Versionen Ihres Docker-Images in der Standard-Docker-Registry (normalerweise DockerHub) haben.</p><p>Um mit dem Docker-Daemon auf Ihrem Mac/Linux-Computer arbeiten zu können, verwenden Sie den <code>docker-env</code>-Befehl in Ihrer Shell:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span><span style=color:#a2f>eval</span> <span style=color:#a2f;font-weight:700>$(</span>minikube docker-env<span style=color:#a2f;font-weight:700>)</span>
</span></span></code></pre></div><p>Sie sollten nun Docker in der Befehlszeile Ihres Mac/Linux-Computers verwenden können, um mit dem Docker-Daemon in der Minikube-VM zu sprechen:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>docker ps
</span></span></code></pre></div><p>In Centos 7 meldets Docker möglicherweise den folgenden Fehler:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>Could not <span style=color:#a2f>read</span> CA certificate <span style=color:#b44>&#34;/etc/docker/ca.pem&#34;</span>: open /etc/docker/ca.pem: no such file or directory
</span></span></code></pre></div><p>Das Update besteht darin, <code>/etc/sysconfig/docker</code> zu aktualisieren, um sicherzustellen, dass die Umgebungsänderungen von Minikube beachtet werden:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>&lt; <span style=color:#b8860b>DOCKER_CERT_PATH</span><span style=color:#666>=</span>/etc/docker
</span></span><span style=display:flex><span>---
</span></span><span style=display:flex><span>&gt; <span style=color:#a2f;font-weight:700>if</span> <span style=color:#666>[</span> -z <span style=color:#b44>&#34;</span><span style=color:#b68;font-weight:700>${</span><span style=color:#b8860b>DOCKER_CERT_PATH</span><span style=color:#b68;font-weight:700>}</span><span style=color:#b44>&#34;</span> <span style=color:#666>]</span>; <span style=color:#a2f;font-weight:700>then</span>
</span></span><span style=display:flex><span>&gt;   <span style=color:#b8860b>DOCKER_CERT_PATH</span><span style=color:#666>=</span>/etc/docker
</span></span><span style=display:flex><span>&gt; <span style=color:#a2f;font-weight:700>fi</span>
</span></span></code></pre></div><p>Denken Sie daran, <code>imagePullPolicy: Always</code> auszuschalten. Andernfalls verwendet Kubernetes keine lokal erstellten Images.</p><h2 id=cluster-verwalten>Cluster verwalten</h2><h3 id=cluster-starten>Cluster starten</h3><p>Mit dem Befehl <code>minikube start</code> können Sie Ihr Cluster starten.
Dieser Befehl erstellt und konfiguriert eine virtuelle Maschine, auf der ein Kubernetes-Cluster mit einem Knoten ausgeführt wird.
Ebenfalls konfiguriert dieser Befehl auch Ihre <a href=/docs/user-guide/kubectl-overview/>kubectl</a> Installation zur Kommunikation mit diesem Cluster.</p><p>Wenn Sie sich hinter einem Web-Proxy befinden, müssen Sie diese Informationen mit dem Befehl <code>minikube start</code> übergeben:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span><span style=color:#b8860b>https_proxy</span><span style=color:#666>=</span>&lt;mein_proxy&gt; minikube start --docker-env <span style=color:#b8860b>http_proxy</span><span style=color:#666>=</span>&lt;mein_proxy&gt; --docker-env <span style=color:#b8860b>https_proxy</span><span style=color:#666>=</span>&lt;mein_proxy&gt; --docker-env <span style=color:#b8860b>no_proxy</span><span style=color:#666>=</span>192.168.99.0/24
</span></span></code></pre></div><p>Leider wird nur das Setzen der Umgebungsvariablen nicht funktionieren.</p><p>Minikube erstellt auch einen "Minikube"-Kontext und setzt ihn in kubectl auf den Standardwert.
Um später wieder zu diesem Kontext zurückzukehren, führen Sie den folgenden Befehl aus: <code>kubectl config use-context minikube</code>.</p><h4 id=angabe-der-kubernetes-version>Angabe der Kubernetes-Version</h4><p>Sie können die bestimmte Version von Kubernetes für Minikube angeben, indem Sie die Zeichenfolge <code>--kubernetes-version</code> an den Befehl<code> minikube start</code> anhängen.
Zum Verwenden der Version <code>v1.7.3</code> führen Sie beispielsweise Folgendes aus:</p><pre tabindex=0><code>minikube start --kubernetes-version v1.7.3
</code></pre><h3 id=kubernetes-konfigurieren>Kubernetes konfigurieren</h3><p>Minikube verfügt über eine "Konfigurator"-Funktion, mit der Anwender die Kubernetes-Komponenten mit beliebigen Werten konfigurieren können.
Um diese Funktion zu verwenden, setzen Sie das <code>--extra-config</code>-Flag an den <code>minikube start</code> Befehl.</p><p>Dieses Flag wird wiederholt, sodass Sie es mehrere Male mit verschiedenen Werten übergeben können, um mehrere Optionen festzulegen.</p><p>Dieses Flag nimmt eine Zeichenkette der Form <code>component.key=value</code> an, wobei <code>component</code> eine der Zeichenketten aus der unteren Liste ist, <code>key</code> ein Wert in der Konfigurationsstruktur ist und <code>value</code> der einzustellende Wert ist.</p><p>Gültige Schlüssel finden Sie in der Dokumentation der Kubernetes <code>componentconfigs</code> für jede Komponente.
Nachstehend die Dokumentation für jede unterstützte Konfiguration:</p><ul><li><a href=https://godoc.org/k8s.io/kubernetes/pkg/kubelet/apis/config#KubeletConfiguration>kubelet</a></li><li><a href=https://godoc.org/k8s.io/kubernetes/cmd/kube-apiserver/app/options#ServerRunOptions>apiserver</a></li><li><a href=https://godoc.org/k8s.io/kubernetes/pkg/proxy/apis/config#KubeProxyConfiguration>proxy</a></li><li><a href=https://godoc.org/k8s.io/kubernetes/pkg/controller/apis/config#KubeControllerManagerConfiguration>controller-manager</a></li><li><a href=https://godoc.org/github.com/coreos/etcd/etcdserver#ServerConfig>etcd</a></li><li><a href=https://godoc.org/k8s.io/kubernetes/pkg/scheduler/apis/config#KubeSchedulerConfiguration>scheduler</a></li></ul><h4 id=beispiele>Beispiele</h4><p>Um die <code>MaxPods</code>-Einstellung im Kubelet auf 5 zu ändern, übergeben Sie dieses Flag: <code>--extra-config=kubelet.MaxPods=5</code>.</p><p>Diese Funktion unterstützt auch verschachtelte Strukturen. Um die <code>LeaderElection.LeaderElect</code> Einstellung zu <code>true</code> zu ändern, übergeben Sie im Scheduler dieses Flag: <code>--extra-config=scheduler.LeaderElection.LeaderElect=true</code>.</p><p>Um den <code>AuthorizationMode</code> auf dem <code>apiserver</code> zu <code>RBAC</code> zu ändern, verwenden Sie: <code>--extra-config=apiserver.authorization-mode=RBAC</code>.</p><h3 id=einen-cluster-stoppen>Einen Cluster stoppen</h3><p>Mit dem Befehl <code>minikube stop</code> können Sie Ihr Cluster anhalten.
Mit diesem Befehl wird die Minikube Virtual Machine heruntergefahren, der Clusterstatus und die Clusterdaten bleiben jedoch erhalten.
Durch erneutes Starten des Clusters wird der vorherige Status wiederhergestellt.</p><h3 id=cluster-löschen>Cluster löschen</h3><p>Der Befehl <code>minikube delete</code> kann zum Löschen Ihres Clusters verwendet werden.
Mit diesem Befehl wird die Minikube Virtual Machine heruntergefahren und gelöscht. Keine Daten oder Zustände bleiben erhalten.</p><h2 id=mit-einem-cluster-interagieren>Mit einem Cluster interagieren</h2><h3 id=kubectl>Kubectl</h3><p>Der <code>minikube start</code> Befehl erstellt einen <a href=/docs/reference/generated/kubectl/kubectl-commands#-em-set-context-em->kubectl Kontext</a> genannt "minikube".
Dieser Kontext enthält die Konfiguration für die Kommunikation mit Ihrem Minikube-Cluster.</p><p>Minikube setzt diesen Kontext automatisch auf den Standardwert, aber wenn Sie in Zukunft wieder darauf zurückgreifen müssen, führen Sie den folgenden Befehl aus:</p><p><code>kubectl config use-context minikube</code>,</p><p>Oder übergeben Sie den Kontext bei jedem Befehl wie folgt: <code>kubectl get pods --context=minikube</code>.</p><h3 id=dashboard>Dashboard</h3><p>Um Zugriff auf das <a href=/docs/tasks/access-application-cluster/web-ui-dashboard/>Kubernetes Dashboard</a> zu erhalten, führen Sie diesen Befehl in einer Shell aus, nachdem Sie Minikube gestartet haben, um die Adresse abzurufen:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>minikube dashboard
</span></span></code></pre></div><h3 id=services>Services</h3><p>Um auf einen Service zuzugreifen, der über einen NodePort verfügbar gemacht wird, führen Sie diesen Befehl in einer Shell aus, nachdem Sie Minikube gestartet haben, um die Adresse abzurufen:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>minikube service <span style=color:#666>[</span>-n NAMESPACE<span style=color:#666>]</span> <span style=color:#666>[</span>--url<span style=color:#666>]</span> NAME
</span></span></code></pre></div><h2 id=netzwerk>Netzwerk</h2><p>Die Minikube-VM wird über eine Host-Only-IP-Adresse, die mit dem Befehl <code>minikube ip</code> abgerufen werden kann, für das Hostsystem verfügbar gemacht.
Auf alle Dienste des Typs <code>NodePort</code> kann über diese IP-Adresse und den NodePort zugegriffen werden.</p><p>Um den NodePort für Ihren Dienst zu ermitteln, können Sie einen <code>kubectl</code>-Befehl wie folgt verwenden:</p><p><code>kubectl get service $SERVICE --output='jsonpath="{.spec.ports[0].nodePort}"'</code></p><h2 id=dauerhafte-volumen>Dauerhafte Volumen</h2><p>Minikube unterstützt <a href=/docs/concepts/storage/persistent-volumes/>PersistentVolumes</a> des Typs <code>hostPath</code>.
Diese dauerhaften Volumen werden einem Verzeichnis in der Minikube-VM zugeordnet.</p><p>Die Minikube-VM wird in ein temporäres Dateisystem hochgefahren, sodass die meisten Verzeichnisse nicht nach Neustarts beibehalten werden (<code>minikube stop</code>).
Minikube ist jedoch so konfiguriert, dass Dateien beibehalten werden, die in den folgenden Host-Verzeichnissen gespeichert sind:</p><ul><li><code>/data</code></li><li><code>/var/lib/minikube</code></li><li><code>/var/lib/docker</code></li></ul><p>Hier ist ein Beispiel einer PersistentVolume-Konfiguration, um Daten im Verzeichnis <code>/ data</code> beizubehalten:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>PersistentVolume<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>pv0001<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>accessModes</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- ReadWriteOnce<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>capacity</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>storage</span>:<span style=color:#bbb> </span>5Gi<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>hostPath</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>path</span>:<span style=color:#bbb> </span>/data/pv0001/<span style=color:#bbb>
</span></span></span></code></pre></div><h2 id=hostordnerfreigabe>Hostordnerfreigabe</h2><p>Einige Treiber werden einen Hostordner in der VM bereitstellen, sodass Sie Dateien problemlos zwischen VM und Host freigeben können. Diese sind momentan nicht konfigurierbar und unterscheiden sich für den Treiber und das Betriebssystem, das Sie verwenden.</p><div class="alert alert-info note callout" role=alert><strong>Hinweis:</strong> Die Hostordnerfreigabe ist noch nicht im KVM-Treiber implementiert.</div><table><thead><tr><th>Treiber</th><th>Betriebssystem</th><th>Hostordner</th><th>VM</th></tr></thead><tbody><tr><td>VirtualBox</td><td>Linux</td><td>/home</td><td>/hosthome</td></tr><tr><td>VirtualBox</td><td>macOS</td><td>/Users</td><td>/Users</td></tr><tr><td>VirtualBox</td><td>Windows</td><td>C://Users</td><td>/c/Users</td></tr><tr><td>VMware Fusion</td><td>macOS</td><td>/Users</td><td>/Users</td></tr><tr><td>Xhyve</td><td>macOS</td><td>/Users</td><td>/Users</td></tr></tbody></table><h2 id=private-containerregistries>Private Containerregistries</h2><p>Um auf eine private Container Registry zuzugreifen, führen Sie die Schritte <a href=/docs/concepts/containers/images/>auf dieser Seite aus</a>.</p><p>Wir empfehlen die Verwendung von <code>ImagePullSecrets</code>, wenn Sie jedoch den Zugriff auf die Minikube-VM konfigurieren möchten, können Sie die Datei <code>.dockercfg</code> im Verzeichnis<code>/home/docker</code> oder die Datei <code>config.json</code> im Verzeichnis<code>/home/docker/.docker</code> ablegen.</p><h2 id=add-ons>Add-ons</h2><p>Damit Minikube benutzerdefinierte Addons ordnungsgemäß starten oder neu starten kann, platzieren Sie die Addons, die mit Minikube gestartet werden sollen, im Verzeichnis <code>~ /.minikube/addons</code>.
Addons in diesem Ordner werden in die Minikube-VM verschoben und jedes Mal gestartet, wenn Minikube gestartet oder neu gestartet wird.</p><h2 id=minikube-mit-einem-http-proxy-verwenden>Minikube mit einem HTTP-Proxy verwenden</h2><p>Minikube erstellt eine virtuelle Maschine, die Kubernetes und einen Docker-Dämon enthält.
Wenn Kubernetes versucht, Container mithilfe von Docker zu planen, erfordert der Docker-Daemon möglicherweise einen externen Netzwerkzugriff, um Container abzurufen.</p><p>Wenn Sie sich hinter einem HTTP-Proxy befinden, müssen Sie möglicherweise die Proxy-Einstellungen für Docker angeben.
Übergeben Sie dazu die erforderlichen Umgebungsvariablen während des <code>minikube start</code> als Flags.</p><p>Zum Beispiel:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>minikube start --docker-env <span style=color:#b8860b>http_proxy</span><span style=color:#666>=</span>http://<span style=color:#b8860b>$IHRPROXY</span>:PORT <span style=color:#b62;font-weight:700>\
</span></span></span><span style=display:flex><span><span style=color:#b62;font-weight:700></span>                 --docker-env <span style=color:#b8860b>https_proxy</span><span style=color:#666>=</span>https://<span style=color:#b8860b>$IHRPROXY</span>:PORT
</span></span></code></pre></div><p>Wenn die Adresse Ihrer virtuellen Maschine 192.168.99.100 lautet, besteht die Möglichkeit, dass Ihre Proxy-Einstellungen verhindern, dass <code>kubectl</code> sie direkt erreicht.
Um die Proxy-Konfiguration für diese IP-Adresse zu umgehen, sollten Sie Ihre no_proxy-Einstellungen ändern. Sie können dies mit dem folgenden Befehl tun:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span><span style=color:#a2f>export</span> <span style=color:#b8860b>no_proxy</span><span style=color:#666>=</span><span style=color:#b8860b>$no_proxy</span>,<span style=color:#a2f;font-weight:700>$(</span>minikube ip<span style=color:#a2f;font-weight:700>)</span>
</span></span></code></pre></div><h2 id=bekannte-probleme>Bekannte Probleme</h2><ul><li>Funktionen, die einen Cloud-Provider erfordern, funktionieren in Minikube nicht. Diese schließen ein:<ul><li>LoadBalancer</li></ul></li><li>Features, die mehrere Knoten erfordern. Diese schließen ein:<ul><li>Erweiterte Planungsrichtlinien</li></ul></li></ul><h2 id=design>Design</h2><p>Minikube verwendet <a href=https://github.com/docker/machine/tree/master/libmachine>libmachine</a> zur Bereitstellung von VMs, und <a href=https://github.com/kubernetes/kubeadm>kubeadm</a> um einen Kubernetes-Cluster in Betrieb zu nehmen.</p><p>Weitere Informationen zu Minikube finden Sie im <a href=https://git.k8s.io/design-proposals-archive/cluster-lifecycle/local-cluster-ux.md>Vorschlag</a>.</p><h2 id=zusätzliche-links>Zusätzliche Links</h2><ul><li><strong>Ziele und Nichtziele</strong>: Die Ziele und Nichtziele des Minikube-Projekts finden Sie in unserer <a href=https://minikube.sigs.k8s.io/docs/contrib/roadmap/>Roadmap</a>.</li><li><strong>Entwicklungshandbuch</strong>: Lesen Sie <a href=https://git.k8s.io/minikube/CONTRIBUTING.md>CONTRIBUTING.md</a> für einen Überblick über das Senden von Pull-Requests.</li><li><strong>Minikube bauen</strong>: Anweisungen zum Erstellen/Testen von Minikube aus dem Quellcode finden Sie im <a href=https://minikube.sigs.k8s.io/docs/contrib/building/>build Handbuch</a>.</li><li><strong>Neue Abhängigkeit hinzufügen</strong>: Anweisungen zum Hinzufügen einer neuen Abhängigkeit zu Minikube finden Sie in der <a href=https://minikube.sigs.k8s.io/docs/drivers/>Anleitung zum Hinzufügen von Abhängigkeiten</a>.</li><li><strong>Neues Addon hinzufügen</strong>: Anweisungen zum Hinzufügen eines neuen Addons für Minikube finden Sie im <a href=https://minikube.sigs.k8s.io/docs/handbook/addons/>Anleitung zum Hinzufügen eines Addons</a>.</li><li><strong>MicroK8s</strong>: Linux-Benutzer, die die Ausführung einer virtuellen Maschine vermeiden möchten, sollten <a href=https://microk8s.io/>MicroK8s</a> als Alternative in Betracht ziehen.</li></ul><h2 id=community>Community</h2><p>Beiträge, Fragen und Kommentare werden begrüßt und ermutigt! Minikube-Entwickler finden Sie in <a href=https://kubernetes.slack.com>Slack</a> im #minikube Kanal (Erhalten Sie <a href=http://slack.kubernetes.io/>hier</a> eine Einladung). Wir haben ausserdem die <a href=https://groups.google.com/forum/#!forum/kubernetes-dev>kubernetes-dev Google Groups-Mailingliste</a>. Wenn Sie in der Liste posten, fügen Sie Ihrem Betreff bitte "minikube:" voran.</p></div><div class=td-content style=page-break-before:always><h1 id=pg-dd948255948d6b59b32c471abcb62997>3 - Konzepte</h1><p>Im Abschnitt Konzepte erfahren Sie mehr über die Bestandteile des Kubernetes-Systems und die Abstraktionen, die Kubernetes zur Verwaltung Ihres Clusters zur Verfügung stellt. Sie erhalten zudem ein tieferes Verständnis der Funktionsweise von Kubernetes.</p><h2 id=überblick>Überblick</h2><p>Um mit Kubernetes zu arbeiten, verwenden Sie <em>Kubernetes-API-Objekte</em>, um den <em>gewünschten Status Ihres Clusters</em> zu beschreiben:
welche Anwendungen oder anderen Workloads Sie ausführen möchten, welche Containerimages sie verwenden, die Anzahl der Replikate, welche Netzwerk- und Festplattenressourcen Sie zur Verfügung stellen möchten, und vieles mehr. Sie legen den gewünschten Status fest, indem Sie Objekte mithilfe der Kubernetes-API erstellen. Dies geschieht normalerweise über die Befehlszeilenschnittstelle <code>kubectl</code>. Sie können die Kubernetes-API auch direkt verwenden, um mit dem Cluster zu interagieren und den gewünschten Status festzulegen oder zu ändern.</p><p>Sobald Sie den gewünschten Status eingestellt haben, wird das <em>Kubernetes Control Plane</em> dafür sorgen, dass der aktuelle Status des Clusters mit dem gewünschten Status übereinstimmt. Zu diesem Zweck führt Kubernetes verschiedene Aufgaben automatisch aus, z. B. das Starten oder Neustarten von Containern, Skalieren der Anzahl der Repliken einer bestimmten Anwendung und vieles mehr. Das Kubernetes Control Plane besteht aus einer Reihe von Prozessen, die in Ihrem Cluster ausgeführt werden:</p><ul><li>Der <strong>Kubernetes Master</strong> besteht aus drei Prozessen, die auf einem einzelnen Node in Ihrem Cluster ausgeführt werden, der als Master-Node bezeichnet wird. Diese Prozesse sind: <a href=/docs/admin/kube-apiserver/>kube-apiserver</a>, <a href=/docs/admin/kube-controller-manager/>kube-controller-manager</a> und <a href=/docs/admin/kube-scheduler/>kube-scheduler</a>.</li><li>Jeder einzelne Node in Ihrem Cluster, welcher nicht der Master ist, führt zwei Prozesse aus:<ul><li><strong><a href=/docs/admin/kubelet/>kubelet</a></strong>, das mit dem Kubernetes Master kommuniziert.</li><li><strong><a href=/docs/admin/kube-proxy/>kube-proxy</a></strong>, ein Netzwerk-Proxy, der die Netzwerkdienste von Kubernetes auf jedem Node darstellt.</li></ul></li></ul><h2 id=kubernetes-objects>Kubernetes Objects</h2><p>Kubernetes enthält eine Reihe von Abstraktionen, die den Status Ihres Systems darstellen: im Container eingesetzte Anwendungen und Workloads, die zugehörigen Netzwerk- und Festplattenressourcen sowie weitere Informationen zu den Aufgaben Ihres Clusters. Diese Abstraktionen werden durch Objekte in der Kubernetes-API dargestellt. Lesen Sie <a href=/docs/concepts/abstractions/overview/>Kubernetes Objects Überblick</a> für weitere Details.</p><p>Die Basisobjekte von Kubernetes umfassen:</p><ul><li><a href=/docs/concepts/workloads/pods/pod-overview/>Pod</a></li><li><a href=/docs/concepts/services-networking/service/>Service</a></li><li><a href=/docs/concepts/storage/volumes/>Volume</a></li><li><a href=/docs/concepts/overview/working-with-objects/namespaces/>Namespace</a></li></ul><p>Darüber hinaus enthält Kubernetes Abstraktionen auf höherer Ebene, die als Controller bezeichnet werden. Controller bauen auf den Basisobjekten auf und bieten zusätzliche Funktionen und Komfortfunktionen. Sie beinhalten:</p><ul><li><a href=/docs/concepts/workloads/controllers/replicaset/>ReplicaSet</a></li><li><a href=/docs/concepts/workloads/controllers/deployment/>Deployment</a></li><li><a href=/docs/concepts/workloads/controllers/statefulset/>StatefulSet</a></li><li><a href=/docs/concepts/workloads/controllers/daemonset/>DaemonSet</a></li><li><a href=/docs/concepts/workloads/controllers/jobs-run-to-completion/>Job</a></li></ul><h2 id=kubernetes-control-plane>Kubernetes Control Plane</h2><p>Die verschiedenen Teile der Kubernetes-Steuerungsebene (Control Plane), wie der Kubernetes Master- und der Kubelet-Prozess, bestimmen, wie Kubernetes mit Ihrem Cluster kommuniziert. Das Control Plane verwaltet ein Inventar aller Kubernetes-Objekte im System und führt kontinuierlich Kontrollschleifen aus, um den Status dieser Objekte zu verwalten. Zu jeder Zeit reagieren die Kontrollschleifen des Control Plane auf Änderungen im Cluster und arbeiten daran, dass der tatsächliche Status aller Objekte im System mit dem von Ihnen definierten Status übereinstimmt.</p><p>Wenn Sie beispielsweise mit der Kubernetes-API ein Deployment-Objekt erstellen, geben Sie einen neuen gewünschten Status für das System an. Das Kubernetes Control Plane zeichnet die Objekterstellung auf und führt Ihre Anweisungen aus, indem es die erforderlichen Anwendungen startet und Sie für auf den Cluster-Nodes plant - Dadurch wird der tatsächliche Status des Clusters an den gewünschten Status angepasst.</p><h3 id=kubernetes-master>Kubernetes Master</h3><p>Der Kubernetes-Master ist für Erhalt des gewünschten Status Ihres Clusters verantwortlich. Wenn Sie mit Kubernetes interagieren, beispielsweise mit dem Kommandozeilen-Tool <code>kubectl</code>, kommunizieren Sie mit dem Kubernetes-Master Ihres Clusters.</p><blockquote><p>Der Begriff "Master" bezeichnet dabei eine Reihe von Prozessen, die den Clusterstatus verwalten. Normalerweise werden diese Prozesse alle auf einem einzigen Node im Cluster ausgeführt. Dieser Node wird auch als Master bezeichnet. Der Master kann repliziert werden, um die Verfügbarkeit und Redundanz zu erhöhen.</p></blockquote><h3 id=kubernetes-nodes>Kubernetes Nodes</h3><p>Die Nodes in einem Cluster sind die Maschinen (VMs, physische Server usw.), auf denen Ihre Anwendungen und Cloud-Workflows ausgeführt werden. Der Kubernetes-Master steuert jeden Node; Sie werden selten direkt mit Nodes interagieren.</p><h4 id=objekt-metadata>Objekt Metadata</h4><ul><li><a href=/docs/concepts/overview/working-with-objects/annotations/>Anmerkungen</a></li></ul><h2 id=nächste-schritte>Nächste Schritte</h2><p>Wenn Sie eine Konzeptseite schreiben möchten, lesen Sie <a href=/docs/home/contribute/page-templates/>Seitenvorlagen verwenden</a>
für Informationen zum Konzeptseitentyp und zur Dokumentations Vorlage.</p></div><div class=td-content style=page-break-before:always><h1 id=pg-0554ac387412eaf4e6e89b2f847dacde>3.1 - Überblick</h1></div><div class=td-content><h1 id=pg-45bdca6129cf540121623e903c18ba46>3.1.1 - Was ist Kubernetes?</h1><p>Diese Seite ist eine Übersicht über Kubernetes.</p><p>Kubernetes ist eine portable, erweiterbare Open-Source-Plattform zur Verwaltung von
containerisierten Arbeitslasten und Services, die sowohl die deklarative Konfiguration als auch die Automatisierung erleichtert.
Es hat ein großes, schnell wachsendes Ökosystem. Kubernetes Dienstleistungen, Support und Tools sind weit verbreitet.</p><p>Google hat das Kubernetes-Projekt 2014 als Open-Source-Projekt zur Verfügung gestellt. Kubernetes baut auf anderthalb Jahrzehnten
Erfahrung auf, die Google mit der Ausführung von Produktions-Workloads in großem Maßstab hat, kombiniert mit den besten Ideen und Praktiken der Community.</p><h2 id=warum-brauche-ich-kubernetes-und-was-kann-ich-damit-tun>Warum brauche ich Kubernetes und was kann ich damit tun?</h2><p>Kubernetes hat eine Reihe von Funktionen. Es kann gesehen werden als:</p><ul><li>eine Containerplattform</li><li>eine Microservices-Plattform</li><li>eine portable Cloud-Plattform
und vieles mehr.</li></ul><p>Kubernetes bietet eine <strong>containerzentrierte</strong> Managementumgebung. Es koordiniert die Computer-, Netzwerk- und Speicherinfrastruktur
im Namen der Benutzer-Workloads. Dies bietet einen Großteil der Einfachheit von Platform as a Service (PaaS) mit der Flexibilität
von Infrastructure as a Service (IaaS) und ermöglicht die Portabilität zwischen Infrastrukturanbietern.</p><h2 id=wie-ist-kubernetes-eine-plattform>Wie ist Kubernetes eine Plattform?</h2><p>Auch wenn Kubernetes eine Menge Funktionalität bietet, gibt es immer wieder neue Szenarien,
die von neuen Funktionen profitieren würden. Anwendungsspezifische Workflows können optimiert werden,
um die Entwicklungsgeschwindigkeit zu beschleunigen.
Eine zunächst akzeptable Ad-hoc-Orchestrierung erfordert oft eine robuste Automatisierung in großem Maßstab.
Aus diesem Grund wurde Kubernetes auch als Plattform für den Aufbau eines Ökosystems von Komponenten und Tools
konzipiert, um die Bereitstellung, Skalierung und Verwaltung von Anwendungen zu erleichtern.</p><p><a href=/docs/concepts/overview/working-with-objects/labels/>Labels</a> ermöglichen es den Benutzern, ihre Ressourcen
nach Belieben zu organisieren. <a href=/docs/concepts/overview/working-with-objects/annotations/>Anmerkungen</a> ermöglichen es Benutzern,
Ressourcen mit benutzerdefinierten Informationen zu versehen, um ihre Arbeitsabläufe zu vereinfachen und eine einfache Möglichkeit
für Managementtools zu bieten, den Status von Kontrollpunkten zu ermitteln.</p><p>Darüber hinaus basiert die <a href=/docs/concepts/overview/components/>Kubernetes-Steuerungsebene</a> auf den gleichen APIs,
die Entwicklern und Anwendern zur Verfügung stehen. Benutzer können ihre eigenen Controller, wie z.B.
<a href=https://github.com/kubernetes/community/blob/master/contributors/devel/scheduler.md>Scheduler</a>, mit
ihren <a href=/docs/concepts/api-extension/custom-resources/>eigenen APIs</a> schreiben, die von einem
universellen <a href=/docs/user-guide/kubectl-overview/>Kommandozeilen-Tool</a> angesprochen werden können.</p><p>Dieses <a href=https://git.k8s.io/design-proposals-archive/architecture/architecture.md>Design</a> hat es einer Reihe anderer Systeme ermöglicht, auf Kubernetes aufzubauen.</p><h2 id=was-kubernetes-nicht-ist>Was Kubernetes nicht ist</h2><p>Kubernetes ist kein traditionelles, allumfassendes PaaS (Plattform als ein Service) System. Da Kubernetes nicht auf Hardware-,
sondern auf Containerebene arbeitet, bietet es einige allgemein anwendbare Funktionen, die PaaS-Angeboten gemeinsam sind,
wie Bereitstellung, Skalierung, Lastausgleich, Protokollierung und Überwachung.
Kubernetes ist jedoch nicht monolithisch, und diese Standardlösungen sind optional und modular erweiterbar.
Kubernetes liefert die Bausteine für den Aufbau von Entwicklerplattformen, bewahrt aber die
Wahlmöglichkeiten und Flexibilität der Benutzer, wo es wichtig ist.</p><p>Kubernetes:</p><ul><li>Schränkt nicht die Art der unterstützten Anwendungen ein. Kubernetes zielt darauf ab,
eine extrem große Vielfalt von Workloads zu unterstützen, einschließlich stateless,
stateful und datenverarbeitender Workloads. Wenn eine Anwendung in einem Container ausgeführt
werden kann, sollte sie auf Kubernetes hervorragend laufen.</li><li>Verteilt keinen Quellcode und entwickelt Ihre Anwendung nicht.
Kontinuierliche Integrations-, Liefer- und Bereitstellungs-Workflows (CI/CD) werden durch
Unternehmenskulturen und -präferenzen sowie technische Anforderungen bestimmt.</li><li>Bietet keine Dienste auf Anwendungsebene, wie Middleware (z.B. Nachrichtenbusse),
Datenverarbeitungs-Frameworks (z.B. Spark), Datenbanken (z.B. mysql), Caches oder
Cluster-Speichersysteme (z.B. Ceph) als eingebaute Dienste. Solche Komponenten können
auf Kubernetes laufen und/oder von Anwendungen, die auf Kubernetes laufen, über
portable Mechanismen wie den Open Service Broker angesprochen werden.</li><li>Bietet keine Konfigurationssprache bzw. kein Konfigurationssystem (z.B. <a href=https://github.com/google/jsonnet>jsonnet</a>).
Es bietet eine deklarative API, die von beliebigen Formen deklarativer Spezifikationen angesprochen werden kann.</li><li>Bietet keine umfassenden Systeme zur Maschinenkonfiguration, Wartung, Verwaltung oder Selbstheilung.</li></ul><p>Außerdem ist Kubernetes nicht nur ein <em>Orchestrierungssystem</em>. Fakt ist, dass es die Notwendigkeit einer Orchestrierung
überflüssig macht. Die technische Definition von <em>Orchestrierung</em> ist die Ausführung eines
definierten Workflows: zuerst A, dann B, dann C. Im Gegensatz dazu besteht Kubernetes aus einer Reihe von unabhängigen,
komponierbaren Steuerungsprozessen, die den aktuellen Zustand kontinuierlich in Richtung des bereitgestellten Soll-Zustandes vorantreiben.
Es sollte keine Rolle spielen, wie Sie von A nach C kommen. Eine zentrale Steuerung ist ebenfalls nicht erforderlich.
Das Ergebnis ist ein System, das einfacher zu bedienen und leistungsfähiger, robuster, widerstandsfähiger und erweiterbar ist.</p><h2 id=warum-container>Warum Container?</h2><p>Sie suchen nach Gründen, warum Sie Container verwenden sollten?</p><p><img src=/images/docs/why_containers.svg alt="Why Containers?"></p><p>Der <em>Altbekannte</em> Weg zur Bereitstellung von Anwendungen war die Installation
der Anwendungen auf einem Host mit dem Betriebssystempaketmanager.
Dies hatte den Nachteil, dass die ausführbaren Dateien, Konfigurationen,
Bibliotheken und Lebenszyklen der Anwendungen untereinander und mit dem
Host-Betriebssystem verwoben waren. Man könnte unveränderliche
Virtual-Machine-Images erzeugen, um vorhersehbare Rollouts
und Rollbacks zu erreichen, aber VMs sind schwergewichtig und nicht portierbar.</p><p>Der <em>Neue Weg</em> besteht darin, Container auf Betriebssystemebene und nicht auf
Hardware-Virtualisierung bereitzustellen. Diese Container sind voneinander
und vom Host isoliert: Sie haben ihre eigenen Dateisysteme, sie können die
Prozesse des anderen nicht sehen, und ihr Ressourcenverbrauch kann begrenzt
werden. Sie sind einfacher zu erstellen als VMs, und da sie von der zugrunde
liegenden Infrastruktur und dem Host-Dateisystem entkoppelt sind,
sind sie über Clouds und Betriebssystem-Distributionen hinweg portabel.</p><p>Da Container klein und schnell sind, kann in jedes Containerimage eine Anwendung gepackt werden.
Diese 1:1-Beziehung zwischen Anwendung und Image ermöglicht es, die Vorteile von Containern
voll auszuschöpfen. Mit Containern können unveränderliche Container-Images eher zur Build-/Release-Zeit
als zur Deployment-Zeit erstellt werden, da jede Anwendung nicht mit dem Rest des Anwendungsstacks komponiert
werden muss und auch nicht mit der Produktionsinfrastrukturumgebung verbunden ist. Die Generierung von
Container-Images zum Zeitpunkt der Erstellung bzw. Freigabe ermöglicht es, eine konsistente Umgebung
von der Entwicklung bis zur Produktion zu gewährleisten.
Ebenso sind Container wesentlich transparenter als VMs, was die Überwachung und Verwaltung erleichtert.
Dies gilt insbesondere dann, wenn die Prozesslebenszyklen der Container von der Infrastruktur verwaltet
werden und nicht von einem Prozess-Supervisor im Container versteckt werden.
Schließlich, mit einer einzigen Anwendung pro Container, wird die Verwaltung
der Container gleichbedeutend mit dem Management des Deployments der Anwendung.</p><p>Zusammenfassung der Container-Vorteile:</p><ul><li><strong>Agile Anwendungserstellung und -bereitstellung</strong>:
Einfachere und effizientere Erstellung von Container-Images im Vergleich zur Verwendung von VM-Images.</li><li><strong>Kontinuierliche Entwicklung, Integration und Bereitstellung</strong>:
Bietet eine zuverlässige und häufige Erstellung und Bereitstellung von Container-Images
mit schnellen und einfachen Rollbacks (aufgrund der Unveränderlichkeit des Images).</li><li><strong>Dev und Ops Trennung der Bedenken</strong>:
Erstellen Sie Anwendungscontainer-Images nicht zum Deployment-, sondern zum Build-Releasezeitpunkt
und entkoppeln Sie so Anwendungen von der Infrastruktur.</li><li><strong>Überwachbarkeit</strong>:
Nicht nur Informationen und Metriken auf Betriebssystemebene werden angezeigt,
sondern auch der Zustand der Anwendung und andere Signale.</li><li><strong>Umgebungskontinuität in Entwicklung, Test und Produktion</strong>:
Läuft auf einem Laptop genauso wie in der Cloud.</li><li><strong>Cloud- und OS-Distribution-Portabilität</strong>:
Läuft auf Ubuntu, RHEL, CoreOS, On-Prem, Google Kubernetes Engine und überall sonst.</li><li><strong>Anwendungsorientiertes Management</strong>:
Erhöht den Abstraktionsgrad vom Ausführen eines Betriebssystems auf virtueller Hardware
bis zum Ausführen einer Anwendung auf einem Betriebssystem unter Verwendung logischer Ressourcen.</li><li><strong>Locker gekoppelte, verteilte, elastische, freie <a href=https://martinfowler.com/articles/microservices.html>Microservices</a></strong>:
Anwendungen werden in kleinere, unabhängige Teile zerlegt und können dynamisch bereitgestellt
und verwaltet werden -- nicht ein monolithischer Stack, der auf einer großen Single-Purpose-Maschine läuft.</li><li><strong>Ressourcenisolierung</strong>:
Vorhersehbare Anwendungsleistung.</li><li><strong>Ressourcennutzung</strong>:
Hohe Effizienz und Dichte.</li></ul><h2 id=was-bedeutet-kubernetes-k8s>Was bedeutet Kubernetes? K8s?</h2><p>Der Name <strong>Kubernetes</strong> stammt aus dem Griechischen, bedeutet <em>Steuermann</em> oder
<em>Pilot</em>, und ist der Ursprung von <em>Gouverneur</em> und
<a href="http://www.etymonline.com/index.php?term=cybernetics">cybernetic</a>. <em>K8s</em>
ist eine Abkürzung, die durch Ersetzen der 8 Buchstaben "ubernete" mit "8" abgeleitet wird.</p><h2 id=nächste-schritte>Nächste Schritte</h2><ul><li><a href=/docs/setup/>Bereit loszulegen</a>?</li><li>Weitere Einzelheiten finden Sie in der <a href=/docs/home/>Kubernetes Dokumentation</a>.</li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-13b0f1dbe89228e3d76d2ac231e245f1>3.1.2 - Kubernetes Komponenten</h1><p>In diesem Dokument werden die verschiedenen binären Komponenten beschrieben, die zur Bereitstellung eines funktionsfähigen Kubernetes-Clusters erforderlich sind.</p><h2 id=master-komponenten>Master-Komponenten</h2><p>Master-Komponenten stellen die Steuerungsebene des Clusters bereit. Master-Komponenten treffen globale Entscheidungen über den Cluster (z. B. Zeitplanung) und das Erkennen und Reagieren auf Clusterereignisse (Starten eines neuen Pods, wenn das <code>replicas</code>-Feld eines Replikationscontrollers nicht zufriedenstellend ist).</p><p>Master-Komponenten können auf jedem Computer im Cluster ausgeführt werden.
Der Einfachheit halber starten Setup-Skripts normalerweise alle Master-Komponenten auf demselben Computer, und es werden keine Benutzercontainer auf diesem Computer ausgeführt.
Lesen Sie <a href=/docs/admin/high-availability/>Cluster mit hoher Verfügbarkeit erstellen</a> für ein Beispiel für ein Multi-Master-VM-Setup.</p><h3 id=kube-apiserver>kube-apiserver</h3><p>Komponente auf dem Master, der die Kubernetes-API verfügbar macht. Es ist das Frontend für die Kubernetes-Steuerebene.</p><p>Es ist für die horizontale Skalierung konzipiert, d. H. Es skaliert durch die Bereitstellung von mehr Instanzen. Mehr informationen finden Sie unter <a href=/docs/admin/high-availability/>Cluster mit hoher Verfügbarkeit erstellen</a>.</p><h3 id=etcd>etcd</h3><p>Konsistenter und hochverfügbarer Key-Value Speicher, der als Backupspeicher von Kubernetes für alle Clusterdaten verwendet wird.</p><p>Halten Sie immer einen Sicherungsplan für etcds Daten für Ihren Kubernetes-Cluster bereit. Ausführliche Informationen zu etcd finden Sie in der <a href=https://etcd.io/docs>etcd Dokumentation</a>.</p><h3 id=kube-scheduler>kube-scheduler</h3><p>Komponente auf dem Master, die neu erstellte Pods überwacht, denen kein Node zugewiesen ist. Sie wählt den Node aus, auf dem sie ausgeführt werden sollen.</p><p>Zu den Faktoren, die bei Planungsentscheidungen berücksichtigt werden, zählen individuelle und kollektive Ressourcenanforderungen, Hardware- / Software- / Richtlinieneinschränkungen, Affinitäts- und Anti-Affinitätsspezifikationen, Datenlokalität, Interworkload-Interferenz und Deadlines.</p><h3 id=kube-controller-manager>kube-controller-manager</h3><p>Komponente auf dem Master, auf dem <a class=glossary-tooltip title='A control loop that watches the shared state of the cluster through the apiserver and makes changes attempting to move the current state towards the desired state.' data-toggle=tooltip data-placement=top href=/docs/concepts/architecture/controller/ target=_blank aria-label=controllers>controllers</a> ausgeführt werden.</p><p>Logisch gesehen ist jeder <a class=glossary-tooltip title='A control loop that watches the shared state of the cluster through the apiserver and makes changes attempting to move the current state towards the desired state.' data-toggle=tooltip data-placement=top href=/docs/concepts/architecture/controller/ target=_blank aria-label=controller>controller</a> ein separater Prozess, aber zur Vereinfachung der Komplexität werden sie alle zu einer einzigen Binärdatei zusammengefasst und in einem einzigen Prozess ausgeführt.</p><p>Diese Controller umfassen:</p><ul><li>Node Controller: Verantwortlich für das Erkennen und Reagieren, wenn Nodes ausfallen.</li><li>Replication Controller: Verantwortlich für die Aufrechterhaltung der korrekten Anzahl von Pods für jedes Replikationscontrollerobjekt im System.</li><li>Endpoints Controller: Füllt das Endpoints-Objekt aus (d.h. verbindet Services & Pods).</li><li>Service Account & Token Controllers: Erstellt Standardkonten und API-Zugriffstoken für neue Namespaces.</li></ul><h3 id=cloud-controller-manager>cloud-controller-manager</h3><p><a href=/docs/tasks/administer-cluster/running-cloud-controller/>cloud-controller-manager</a> führt Controller aus, die mit den entsprechenden Cloud-Anbietern interagieren.
Der cloud-controller-manager ist eine Alpha-Funktion, die in Kubernetes Version 1.6 eingeführt wurde.</p><p>cloud-controller-manager führt nur Cloud-Provider-spezifische Controller-Schleifen aus. Sie müssen diese Controller-Schleifen im Cube-Controller-Manager deaktivieren. Sie können die Controller-Schleifen deaktivieren, indem Sie beim Starten des kube-controller-manager das Flag <code>--cloud-provider</code> auf <code>external</code> setzen.</p><p>cloud-controller-manager erlaubt es dem Cloud-Anbieter Code und dem Kubernetes-Code, sich unabhängig voneinander zu entwickeln.
In früheren Versionen war der Kerncode von Kubernetes für die Funktionalität von Cloud-Provider-spezifischem Code abhängig.
In zukünftigen Versionen sollte der für Cloud-Anbieter spezifische Code vom Cloud-Anbieter selbst verwaltet und mit dem Cloud-Controller-Manager verknüpft werden, während Kubernetes ausgeführt wird.</p><p>Die folgenden Controller haben Abhängigkeiten von Cloud-Anbietern:</p><ul><li>Node Controller: Zum Überprüfen, ob ein Node in der Cloud beim Cloud-Anbieter gelöscht wurde, nachdem er nicht mehr reagiert</li><li>Route Controller: Zum Einrichten von Routen in der zugrunde liegenden Cloud-Infrastruktur</li><li>Service Controller: Zum Erstellen, Aktualisieren und Löschen von Lastverteilern von Cloud-Anbietern</li><li>Volume Controller: Zum Erstellen, Verbinden und Bereitstellen von Volumes und zur Interaktion mit dem Cloud-Provider zum Orchestrieren von Volumes</li></ul><h2 id=node-komponenten>Node-Komponenten</h2><p>Node Komponenten werden auf jedem Knoten ausgeführt, halten laufende Pods aufrecht und stellen die Kubernetes-Laufzeitumgebung bereit.</p><h3 id=kubelet>kubelet</h3><p>Ein Agent, der auf jedem Node im Cluster ausgeführt wird. Er stellt sicher, dass Container in einem Pod ausgeführt werden.</p><p>Das Kubelet verwendet eine Reihe von PodSpecs, die über verschiedene Mechanismen bereitgestellt werden, und stellt sicher, dass die in diesen PodSpecs beschriebenen Container ordnungsgemäß ausgeführt werden. Das kubelet verwaltet keine Container, die nicht von Kubernetes erstellt wurden.</p><h3 id=kube-proxy>kube-proxy</h3><p><a href=/docs/admin/kube-proxy/>kube-proxy</a> ermöglicht die Kubernetes Service-Abstraktion, indem die Netzwerkregeln auf dem Host beibehalten und die Verbindungsweiterleitung durchgeführt wird.</p><h3 id=container-runtime>Container Runtime</h3><p>Die Containerlaufzeit ist die Software, die für das Ausführen von Containern verantwortlich ist.
Kubernetes unterstützt mehrere Laufzeiten: <a href=http://www.docker.com>Docker</a>, <a href=https://containerd.io>containerd</a>, <a href=https://cri-o.io/>cri-o</a>, <a href=https://github.com/kubernetes-incubator/rktlet>rktlet</a> und jede Implementierung des <a href=https://github.com/kubernetes/community/blob/master/contributors/devel/sig-node/container-runtime-interface.md>Kubernetes CRI (Container Runtime Interface)</a>.</p><h2 id=addons>Addons</h2><p>Addons sind Pods und Dienste, die Clusterfunktionen implementieren. Die Pods können verwaltet werden
durch Deployments, ReplicationControllers, und so wieter.
Namespace-Addon-Objekte werden im Namespace <code>kube-system</code> erstellt.</p><p>Ausgewählte Addons werden unten beschrieben. Eine erweiterte Liste verfügbarer Addons finden Sie unter <a href=/docs/concepts/cluster-administration/addons/>Addons</a>.</p><h3 id=dns>DNS</h3><p>Während die anderen Addons nicht unbedingt erforderlich sind, sollte <a href=/docs/concepts/services-networking/dns-pod-service/>cluster DNS</a> in allen Kubernetes-Cluster vorhanden sein, da viele Beispiele davon abhängen.</p><p>Cluster-DNS ist neben anderen DNS-Servern in Ihrer Umgebung ein DNS-Server, der DNS-Einträge für Kubernetes-Dienste bereitstellt.</p><p>Von Kubernetes gestartete Container schließen diesen DNS-Server automatisch in ihre DNS-Suchen ein.</p><h3 id=web-ui-dashboard>Web UI (Dashboard)</h3><p><a href=/docs/tasks/access-application-cluster/web-ui-dashboard/>Dashboard</a> ist eine allgemeine, webbasierte Benutzeroberfläche für Kubernetes-Cluster. Benutzer können damit Anwendungen, die im Cluster ausgeführt werden, sowie den Cluster selbst verwalten und Fehler beheben.</p><h3 id=container-resource-monitoring>Container Resource Monitoring</h3><p><a href=/docs/tasks/debug-application-cluster/resource-usage-monitoring/>Container Resource Monitoring</a> zeichnet generische Zeitreihenmessdaten zu Containern in einer zentralen Datenbank auf und stellt eine Benutzeroberfläche zum Durchsuchen dieser Daten bereit.</p><h3 id=cluster-level-logging>Cluster-level Logging</h3><p>Ein <a href=/docs/concepts/cluster-administration/logging/>Cluster-level logging</a> Mechanismus ist für das Speichern von Containerprotokollen in einem zentralen Protokollspeicher mit Such- / Browsing-Schnittstelle verantwortlich.</p></div><div class=td-content style=page-break-before:always><h1 id=pg-2bf36ccd6b3dbeafecf87c39761b07c7>3.2 - Kubernetes Architekur</h1></div><div class=td-content><h1 id=pg-9ef2890698e773b6c0d24fd2c20146f5>3.2.1 - Nodes</h1><p>Ein Knoten (Node in Englisch) ist eine Arbeitsmaschine in Kubernetes. Ein Node
kann je nach Cluster eine VM oder eine physische Maschine sein. Jeder Node enthält
die für den Betrieb von <a href=/docs/concepts/workloads/pods/pod/>Pods</a> notwendigen Dienste
und wird von den Master-Komponenten verwaltet.
Die Dienste auf einem Node umfassen die <a href=/docs/concepts/overview/components/#node-components>Container Runtime</a>, das Kubelet und den Kube-Proxy.
Weitere Informationen finden Sie im Abschnitt Kubernetes Node in der Architekturdesign-Dokumentation.</p><h2 id=node-status>Node Status</h2><p>Der Status eines Nodes enthält folgende Informationen:</p><ul><li><a href=#adressen>Adressen</a></li><li><a href=#zustand>Zustand</a></li><li><a href=#kapazit%C3%A4t>Kapazität</a></li><li><a href=#info>Info</a></li></ul><p>Jeder Abschnitt wird folgend detailliert beschrieben.</p><h3 id=adressen>Adressen</h3><p>Die Verwendung dieser Felder hängt von Ihrem Cloud-Anbieter oder der Bare-Metal-Konfiguration ab.</p><ul><li>HostName: Der vom Kernel des Nodes gemeldete Hostname. Kann mit dem kubelet-Parameter <code>--hostname-override</code> überschrieben werden.</li><li>ExternalIP: In der Regel die IP-Adresse des Nodes, die extern geroutet werden kann (von außerhalb des Clusters verfügbar).</li><li>InternalIP: In der Regel die IP-Adresse des Nodes, die nur innerhalb des Clusters routbar ist.</li></ul><h3 id=zustand>Zustand</h3><p>Das <code>conditions</code> Feld beschreibt den Zustand, aller <code>Running</code> Nodes.</p><table><thead><tr><th>Node Condition</th><th>Beschreibung</th></tr></thead><tbody><tr><td><code>OutOfDisk</code></td><td><code>True</code> wenn auf dem Node nicht genügend freier Speicherplatz zum Hinzufügen neuer Pods vorhanden ist, andernfalls <code>False</code></td></tr><tr><td><code>Ready</code></td><td><code>True</code> wenn der Node in einem guten Zustand und bereit ist Pods aufzunehmen, <code>False</code> wenn der Node nicht in einem guten Zustand ist und nicht bereit ist Pods aufzunehmeb, und <code>Unknown</code> wenn der Node-Controller seit der letzten <code>node-monitor-grace-period</code> nichts von dem Node gehört hat (Die Standardeinstellung beträgt 40 Sekunden)</td></tr><tr><td><code>MemoryPressure</code></td><td><code>True</code> wenn der verfügbare Speicher des Nodes niedrig ist; Andernfalls<code>False</code></td></tr><tr><td><code>PIDPressure</code></td><td><code>True</code> wenn zu viele Prozesse auf dem Node vorhanden sind; Andernfalls<code>False</code></td></tr><tr><td><code>DiskPressure</code></td><td><code>True</code> wenn die Festplattenkapazität niedrig ist. Andernfalls <code>False</code></td></tr><tr><td><code>NetworkUnavailable</code></td><td><code>True</code> wenn das Netzwerk für den Node nicht korrekt konfiguriert ist, andernfalls <code>False</code></td></tr></tbody></table><p>Der Zustand eines Nodes wird als JSON-Objekt dargestellt. Die folgende Antwort beschreibt beispielsweise einen fehlerfreien Node.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-json data-lang=json><span style=display:flex><span><span style=color:#b44>&#34;conditions&#34;</span><span>:</span> [
</span></span><span style=display:flex><span>  {
</span></span><span style=display:flex><span>    <span style=color:green;font-weight:700>&#34;type&#34;</span>: <span style=color:#b44>&#34;Ready&#34;</span>,
</span></span><span style=display:flex><span>    <span style=color:green;font-weight:700>&#34;status&#34;</span>: <span style=color:#b44>&#34;True&#34;</span>
</span></span><span style=display:flex><span>  }
</span></span><span style=display:flex><span>]
</span></span></code></pre></div><p>Wenn der Status der <code>Ready</code>-Bedingung <code>Unknown</code> oder <code>False</code> länger als der <code>pod-eviction-timeout</code> bleibt, wird ein Parameter an den <a href=/docs/admin/kube-controller-manager/>kube-controller-manager</a> übergeben und alle Pods auf dem Node werden vom Node Controller gelöscht.</p><p>Die voreingestellte Zeit vor der Entfernung beträgt <strong>fünf Minuten</strong>.
In einigen Fällen, in denen der Node nicht erreichbar ist, kann der Apiserver nicht mit dem Kubelet auf dem Node kommunizieren.
Die Entscheidung, die Pods zu löschen, kann dem Kublet erst mitgeteilt werden, wenn die Kommunikation mit dem Apiserver wiederhergestellt ist.
In der Zwischenzeit können Pods, deren Löschen geplant ist, weiterhin auf dem unzugänglichen Node laufen.</p><p>In Versionen von Kubernetes vor 1.5 würde der Node Controller das Löschen dieser unerreichbaren Pods vom Apiserver <a href=/docs/concepts/workloads/pods/pod/#force-deletion-of-pods>erzwingen</a>. In Version 1.5 und höher erzwingt der Node Controller jedoch keine Pod Löschung, bis bestätigt wird, dass sie nicht mehr im Cluster ausgeführt werden. Pods die auf einem unzugänglichen Node laufen sind eventuell in einem einem <code>Terminating</code> oder <code>Unkown</code> Status. In Fällen, in denen Kubernetes nicht aus der zugrunde liegenden Infrastruktur schließen kann, ob ein Node einen Cluster dauerhaft verlassen hat, muss der Clusteradministrator den Node möglicherweise manuell löschen.
Das Löschen des Kubernetes-Nodeobjekts bewirkt, dass alle auf dem Node ausgeführten Pod-Objekte gelöscht und deren Namen freigegeben werden.</p><p>In Version 1.12 wurde die Funktion <code>TaintNodesByCondition</code> als Beta-Version eingeführt, die es dem Node-Lebenszyklus-Controller ermöglicht, automatisch <a href=/docs/concepts/configuration/taint-and-toleration/>Markierungen</a> (<em>taints</em> in Englisch) zu erstellen, die Bedingungen darstellen.</p><p>Ebenso ignoriert der Scheduler die Bedingungen, wenn er einen Node berücksichtigt; stattdessen betrachtet er die Markierungen (taints) des Nodes und die Toleranzen eines Pod.</p><p>Anwender können jetzt zwischen dem alten Scheduling-Modell und einem neuen, flexibleren Scheduling-Modell wählen.</p><p>Ein Pod, der keine Toleranzen aufweist, wird gemäß dem alten Modell geplant.
Aber ein Pod, die die Taints eines bestimmten Node toleriert, kann auf diesem Node geplant werden.</p><div class="alert alert-warning caution callout" role=alert><strong>Achtung:</strong> Wenn Sie diese Funktion aktivieren, entsteht eine kleine Verzögerung zwischen der Zeit,
in der eine Bedingung beobachtet wird, und der Zeit, in der ein Taint entsteht.
Diese Verzögerung ist in der Regel kürzer als eine Sekunde, aber sie kann die Anzahl
der Pods erhöhen, die erfolgreich geplant, aber vom Kubelet abgelehnt werden.</div><h3 id=kapazität>Kapazität</h3><p>Beschreibt die auf dem Node verfügbaren Ressourcen: CPU, Speicher und die maximale
Anzahl der Pods, die auf dem Node ausgeführt werden können.</p><h3 id=info>Info</h3><p>Allgemeine Informationen zum Node, z. B. Kernelversion, Kubernetes-Version
(kubelet- und kube-Proxy-Version), Docker-Version (falls verwendet), Betriebssystemname.
Die Informationen werden von Kubelet vom Node gesammelt.</p><h2 id=management>Management</h2><p>Im Gegensatz zu <a href=/docs/concepts/workloads/pods/pod/>Pods</a> und <a href=/docs/concepts/services-networking/service/>Services</a>,
ein Node wird nicht von Kubernetes erstellt: Er wird extern von Cloud-Anbietern wie Google Compute Engine erstellt oder ist in Ihrem Pool physischer oder virtueller Maschinen vorhanden.
Wenn Kubernetes also einen Node erstellt, wird ein Objekt erstellt, das den Node darstellt.
Nach der Erstellung überprüft Kubernetes, ob der Node gültig ist oder nicht.</p><p>Wenn Sie beispielsweise versuchen, einen Node aus folgendem Inhalt zu erstellen:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-json data-lang=json><span style=display:flex><span>{
</span></span><span style=display:flex><span>  <span style=color:green;font-weight:700>&#34;kind&#34;</span>: <span style=color:#b44>&#34;Node&#34;</span>,
</span></span><span style=display:flex><span>  <span style=color:green;font-weight:700>&#34;apiVersion&#34;</span>: <span style=color:#b44>&#34;v1&#34;</span>,
</span></span><span style=display:flex><span>  <span style=color:green;font-weight:700>&#34;metadata&#34;</span>: {
</span></span><span style=display:flex><span>    <span style=color:green;font-weight:700>&#34;name&#34;</span>: <span style=color:#b44>&#34;10.240.79.157&#34;</span>,
</span></span><span style=display:flex><span>    <span style=color:green;font-weight:700>&#34;labels&#34;</span>: {
</span></span><span style=display:flex><span>      <span style=color:green;font-weight:700>&#34;name&#34;</span>: <span style=color:#b44>&#34;my-first-k8s-node&#34;</span>
</span></span><span style=display:flex><span>    }
</span></span><span style=display:flex><span>  }
</span></span><span style=display:flex><span>}
</span></span></code></pre></div><p>Kubernetes erstellt intern ein Node-Objekt (die Darstellung) und validiert den Node durch Zustandsprüfung basierend auf dem Feld <code>metadata.name</code>.
Wenn der Node gültig ist, d.h. wenn alle notwendigen Dienste ausgeführt werden, ist er berechtigt, einen Pod auszuführen.
Andernfalls wird er für alle Clusteraktivitäten ignoriert, bis er gültig wird.</p><div class="alert alert-info note callout" role=alert><strong>Hinweis:</strong> Kubernetes behält das Objekt für den ungültigen Node und prüft ständig seine Gültigkeit.
Sie müssen das Node-Objekt explizit löschen, um diesen Prozess zu stoppen.</div><p>Aktuell gibt es drei Komponenten, die mit dem Kubernetes Node-Interface interagieren: Node Controller, Kubelet und Kubectl.</p><h3 id=node-controller>Node Controller</h3><p>Der Node Controller ist eine Kubernetes-Master-Komponente, die verschiedene Aspekte von Nodes verwaltet.</p><p>Der Node Controller hat mehrere Rollen im Leben eines Nodes.
Der erste ist die Zuordnung eines CIDR-Blocks zu dem Node, wenn er registriert ist (sofern die CIDR-Zuweisung aktiviert ist).</p><p>Die zweite ist, die interne Node-Liste des Node Controllers mit der Liste der verfügbaren Computer des Cloud-Anbieters auf dem neuesten Stand zu halten.
Wenn ein Node in einer Cloud-Umgebung ausgeführt wird und sich in einem schlechten Zustand befindet, fragt der Node Controller den Cloud-Anbieter, ob die virtuelle Maschine für diesen Node noch verfügbar ist. Wenn nicht, löscht der Node Controller den Node aus seiner Node-Liste.</p><p>Der dritte ist die Überwachung des Zustands der Nodes. Der Node Controller ist dafür verantwortlich,
die NodeReady-Bedingung von NodeStatus auf ConditionUnknown zu aktualisieren, wenn ein Node unerreichbar wird (der Node Controller empfängt aus irgendeinem Grund keine Herzschläge mehr, z.B. weil der Node heruntergefahren ist) und später alle Pods aus dem Node zu entfernen (und diese ordnungsgemäss zu beenden), wenn der Node weiterhin unzugänglich ist. (Die Standard-Timeouts sind 40s, um ConditionUnknown zu melden und 5 Minuten, um mit der Evakuierung der Pods zu beginnen).</p><p>Der Node Controller überprüft den Zustand jedes Nodes alle <code>--node-monitor-period</code> Sekunden.</p><p>In Versionen von Kubernetes vor 1.13 ist NodeStatus der Herzschlag des Nodes.
Ab Kubernetes 1.13 wird das Node-Lease-Feature als Alpha-Feature eingeführt (Feature-Gate <code>NodeLease</code>, <a href=https://github.com/kubernetes/enhancements/blob/master/keps/sig-node/0009-node-heartbeat.md>KEP-0009</a>).</p><p>Wenn die Node Lease Funktion aktiviert ist, hat jeder Node ein zugeordnetes <code>Lease</code>-Objekt im <code>kube-node-lease</code>-Namespace, das vom Node regelmäßig erneuert wird.
Sowohl NodeStatus als auch Node Lease werden als Herzschläge vom Node aus behandelt.
Node Leases werden häufig erneuert, während NodeStatus nur dann vom Node zu Master gemeldet wird, wenn sich etwas ändert oder genügend Zeit vergangen ist (Standard ist 1 Minute, was länger ist als der Standard-Timeout von 40 Sekunden für unerreichbare Nodes).
Da Node Leases viel lastärmer sind als NodeStatus, macht diese Funktion den Node Herzschlag sowohl in Bezug auf Skalierbarkeit als auch auf die Leistung deutlich effizienter.</p><p>In Kubernetes 1.4 haben wir die Logik der Node-Steuerung aktualisiert, um Fälle besser zu handhaben, in denen eine große Anzahl von Nodes Probleme hat, den Master zu erreichen (z.B. weil der Master Netzwerkprobleme hat).
Ab 1.4 betrachtet der Node-Controller den Zustand aller Nodes im Cluster, wenn er eine Entscheidung über die Enterfung eines Pods trifft.</p><p>In den meisten Fällen begrenzt der Node-Controller die Entfernungsrate auf <code>--node-eviction-rate</code> (Standard 0,1) pro Sekunde, was bedeutet, dass er die Pods nicht von mehr als einem Node pro 10 Sekunden entfernt.</p><p>Das Entfernungsverhalten von Nodes ändert sich, wenn ein Node in einer bestimmten Verfügbarkeitszone ungesund wird.
Der Node-Controller überprüft gleichzeitig, wie viel Prozent der Nodes in der Zone ungesund sind (NodeReady-Bedingung ist ConditionUnknown oder ConditionFalse).
Wenn der Anteil der ungesunden Nodes mindestens <code>--unhealthy-zone-threshold</code> (Standard 0,55) beträgt, wird die Entfernungsrate reduziert:</p><p>Wenn der Cluster klein ist (d.h. weniger als oder gleich <code>--large-cluster-size-threshold</code> Node - Standard 50), werden die Entfernungen gestoppt. Andernfalls wird die Entfernungsrate auf <code>--secondary-node-eviction-rate</code> (Standard 0,01) pro Sekunde reduziert.</p><p>Der Grund, warum diese Richtlinien pro Verfügbarkeitszone implementiert werden, liegt darin, dass eine Verfügbarkeitszone vom Master unerreichbar werden könnte, während die anderen verbunden bleiben. Wenn Ihr Cluster nicht mehrere Verfügbarkeitszonen von Cloud-Anbietern umfasst, gibt es nur eine Verfügbarkeitszone (den gesamten Cluster).</p><p>Ein wichtiger Grund für die Verteilung Ihrer Nodes auf Verfügbarkeitszonen ist, dass die Arbeitsbelastung auf gesunde Zonen verlagert werden kann, wenn eine ganze Zone ausfällt.
Wenn also alle Nodes in einer Zone ungesund sind, entfernt Node Controller mit der normalen <code>--node-eviction-rate</code> Geschwindigkeit.
Der Ausnahmefall ist, wenn alle Zonen völlig ungesund sind (d.h. es gibt keine gesunden Node im Cluster).
In diesem Fall geht der Node-Controller davon aus, dass es ein Problem mit der Master-Konnektivität gibt und stoppt alle Entfernungen, bis die Verbindung wiederhergestellt ist.</p><p>Ab Kubernetes 1.6 ist der Node-Controller auch für die Entfernung von Pods zuständig, die auf Nodes mit <code>NoExecute</code>-Taints laufen, wenn die Pods die Markierungen nicht tolerieren.
Zusätzlich ist der NodeController als Alpha-Funktion, die standardmäßig deaktiviert ist, dafür verantwortlich, Taints hinzuzufügen, die Node Probleme, wie <code>Node unreachable</code> oder <code>not ready</code> entsprechen.
Siehe <a href=/docs/concepts/configuration/taint-and-toleration/>diese Dokumentation</a> für Details über <code>NoExecute</code> Taints und die Alpha-Funktion.</p><p>Ab Version 1.8 kann der Node-Controller für die Erzeugung von Taints, die Node Bedingungen darstellen, verantwortlich gemacht werden. Dies ist eine Alpha-Funktion der Version 1.8.</p><h3 id=selbstregistrierung-von-nodes>Selbstregistrierung von Nodes</h3><p>Wenn das Kubelet-Flag <code>--register-node</code> aktiv ist (Standard), versucht das Kubelet, sich beim API-Server zu registrieren. Dies ist das bevorzugte Muster, das von den meisten Distributionen verwendet wird.</p><p>Zur Selbstregistrierung wird das kubelet mit den folgenden Optionen gestartet:</p><ul><li><code>--kubeconfig</code> - Pfad zu Anmeldeinformationen, um sich beim Apiserver zu authentifizieren.</li><li><code>--cloud-provider</code> - Wie man sich mit einem Cloud-Anbieter unterhält, um Metadaten über sich selbst zu lesen.</li><li><code>--register-node</code> - Automatisch beim API-Server registrieren.</li><li><code>--register-with-taints</code> - Registrieren Sie den Node mit der angegebenen Taints-Liste (Kommagetrennt <code>&lt;key>=&lt;value>:&lt;effect></code>). No-op wenn <code>register-node</code> false ist.</li><li><code>--node-ip</code> - IP-Adresse des Nodes.</li><li><code>--node-labels</code> - Labels, die bei der Registrierung des Nodes im Cluster hinzugefügt werden sollen (Beachten Sie die Richlinien des <a href=/docs/reference/access-authn-authz/admission-controllers/#noderestriction>NodeRestriction admission plugin</a> in 1.13+).</li><li><code>--node-status-update-frequency</code> - Gibt an, wie oft kubelet den Nodestatus an den Master übermittelt.</li></ul><p>Wenn der <a href=/docs/reference/access-authn-authz/node/>Node authorization mode</a> und
<a href=/docs/reference/access-authn-authz/admission-controllers/#noderestriction>NodeRestriction admission plugin</a> aktiviert sind,
dürfen kubelets nur ihre eigene Node-Ressource erstellen / ändern.</p><h4 id=manuelle-nodeverwaltung>Manuelle Nodeverwaltung</h4><p>Ein Cluster-Administrator kann Nodeobjekte erstellen und ändern.</p><p>Wenn der Administrator Nodeobjekte manuell erstellen möchte, setzen Sie das kubelet Flag <code>--register-node=false</code>.</p><p>Der Administrator kann Node-Ressourcen ändern (unabhängig von der Einstellung von <code>--register-node</code>).
Zu den Änderungen gehören das Setzen von Labels und das Markieren des Nodes.</p><p>Labels auf Nodes können in Verbindung mit node selectors auf Pods verwendet werden, um die Planung zu steuern, z.B. um einen Pod so zu beschränken, dass er nur auf einer Teilmenge der Nodes ausgeführt werden darf.</p><p>Das Markieren eines Nodes als nicht geplant, verhindert, dass neue Pods für diesen Node geplant werden. Dies hat jedoch keine Auswirkungen auf vorhandene Pods auf dem Node.
Dies ist nützlich als vorbereitender Schritt vor einem Neustart eines Nodes usw.
Um beispielsweise einen Node als nicht geplant zu markieren, führen Sie den folgenden Befehl aus:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl cordon <span style=color:#b8860b>$NODENAME</span>
</span></span></code></pre></div><div class="alert alert-info note callout" role=alert><strong>Hinweis:</strong> Pods, die von einem DaemonSet-Controller erstellt wurden, umgehen den Kubernetes-Scheduler und respektieren nicht das <em>unschedulable</em> Attribut auf einem Node.
Dies setzt voraus, dass Daemons auf dem Computer verbleiben, auch wenn während der Vorbereitung eines Neustarts keine Anwendungen mehr vorhanden sind.</div><h3 id=node-kapazität>Node Kapazität</h3><p>Die Kapazität des Nodes (Anzahl der CPU und Speichermenge) ist Teil des Nodeobjekts.
Normalerweise registrieren sich Nodes selbst und melden ihre Kapazität beim Erstellen des Nodeobjekts.
Sofern Sie <a href=#Manuelle-Nodeverwaltung>Manuelle Nodeverwaltung</a> betreiben, müssen Sie die Node Kapazität setzen, wenn Sie einen Node hinzufügen.</p><p>Der Kubernetes-Scheduler stellt sicher, dass für alle Pods auf einem Nodes genügend Ressourcen vorhanden sind.
Er prüft, dass die Summe der Requests von Containern auf dem Node nicht größer ist als die Kapazität des Nodes.
Er beinhaltet alle Container die vom kubelet gestarted worden, aber keine Container die direkt von der <a href=/docs/concepts/overview/components/#node-components>container runtime</a> gestartet wurden, noch jegleiche Prozesse die ausserhalb von Containern laufen.</p><p>Wenn Sie Ressourcen explizit für Nicht-Pod-Prozesse reservieren möchten, folgen Sie diesem Lernprogramm um <a href=/docs/tasks/administer-cluster/reserve-compute-resources/#system-reserved>Ressourcen für Systemdaemons zu reservieren</a>.</p><h2 id=api-objekt>API-Objekt</h2><p>Node ist eine Top-Level-Ressource in der Kubernetes-REST-API. Weitere Details zum API-Objekt finden Sie unter:
<a href=/docs/reference/generated/kubernetes-api/v1.25/#node-v1-core>Node API object</a>.</p></div><div class=td-content style=page-break-before:always><h1 id=pg-63e7fdf87ba61eb2586bb8c625c23506>3.2.2 - Master-Node Kommunikation</h1><p>Dieses Dokument katalogisiert die Kommunikationspfade zwischen dem Master (eigentlich dem Apiserver) und des Kubernetes-Clusters.
Die Absicht besteht darin, Benutzern die Möglichkeit zu geben, ihre Installation so anzupassen, dass die Netzwerkkonfiguration so abgesichert wird, dass der Cluster in einem nicht vertrauenswürdigen Netzwerk (oder mit vollständig öffentlichen IP-Adressen eines Cloud-Providers) ausgeführt werden kann.</p><h2 id=cluster-zum-master>Cluster zum Master</h2><p>Alle Kommunikationspfade vom Cluster zum Master enden beim Apiserver (keine der anderen Master-Komponenten ist dafür ausgelegt, Remote-Services verfügbar zu machen).
In einem typischen Setup ist der Apiserver so konfiguriert, dass er Remote-Verbindungen an einem sicheren HTTPS-Port (443) mit einer oder mehreren Formen der <a href=/docs/reference/access-authn-authz/authentication/>Clientauthentifizierung</a> überwacht.
Eine oder mehrere Formene von <a href=/docs/reference/access-authn-authz/authorization/>Autorisierung</a> sollte aktiviert sein, insbesondere wenn <a href=/docs/reference/access-authn-authz/authentication/#anonymous-requests>anonyme Anfragen</a> oder <a href=/docs/reference/access-authn-authz/authentication/#service-account-tokens>Service Account Tokens</a> aktiviert sind.</p><p>Nodes sollten mit dem öffentlichen Stammzertifikat für den Cluster konfiguriert werden, sodass sie eine sichere Verbindung zum Apiserver mit gültigen Client-Anmeldeinformationen herstellen können.
Beispielsweise bei einer gewöhnlichen GKE-Konfiguration enstprechen die dem kubelet zur Verfügung gestellten Client-Anmeldeinformationen eines Client-Zertifikats.
Lesen Sie über <a href=/docs/reference/command-line-tools-reference/kubelet-tls-bootstrapping/>kubelet TLS bootstrapping</a> zur automatisierten Bereitstellung von kubelet-Client-Zertifikaten.</p><p>Pods, die eine Verbindung zum Apiserver herstellen möchten, können dies auf sichere Weise tun, indem sie ein Dienstkonto verwenden, sodass Kubernetes das öffentliche Stammzertifikat und ein gültiges Trägertoken automatisch in den Pod einfügt, wenn er instanziiert wird.
Der <code>kubernetes</code>-Dienst (in allen Namespaces) ist mit einer virtuellen IP-Adresse konfiguriert, die (über den Kube-Proxy) an den HTTPS-Endpunkt auf dem Apiserver umgeleitet wird.</p><p>Die Master-Komponenten kommunizieren auch über den sicheren Port mit dem Cluster-Apiserver.</p><p>Der Standardbetriebsmodus für Verbindungen vom Cluster (Knoten und Pods, die auf den Knoten ausgeführt werden) zum Master ist daher standardmäßig gesichert und kann über nicht vertrauenswürdige und/oder öffentliche Netzwerke laufen.</p><h2 id=master-zum-cluster>Master zum Cluster</h2><p>Es gibt zwei primäre Kommunikationspfade vom Master (Apiserver) zum Cluster.
Der Erste ist vom Apiserver hin zum Kubelet-Prozess, der auf jedem Node im Cluster ausgeführt wird.
Der Zweite ist vom Apiserver zu einem beliebigen Node, Pod oder Dienst über die Proxy-Funktionalität des Apiservers.</p><h3 id=apiserver-zum-kubelet>Apiserver zum kubelet</h3><p>Die Verbindungen vom Apiserver zum Kubelet werden verwendet für:</p><ul><li>Das Abrufen von Protokollen für Pods.</li><li>Das Verbinden (durch kubectl) mit laufenden Pods.</li><li>Die Bereitstellung der Portweiterleitungsfunktion des kubelet.</li></ul><p>Diese Verbindungen enden am HTTPS-Endpunkt des kubelet.
Standardmäßig überprüft der Apiserver das Serverzertifikat des Kubelets nicht, was die Verbindung angreifbar für Man-in-the-Middle-Angriffe macht. Die Kommunikation ist daher <strong>unsicher</strong>, wenn die Verbindungen über nicht vertrauenswürdige und/oder öffentliche Netzwerke laufen.</p><p>Um diese Verbindung zu überprüfen, verwenden Sie das Flag <code>--kubelet-certificate-authority</code>, um dem Apiserver ein Stammzertifikatbündel bereitzustellen, das zur Überprüfung des Server-Zertifikats des kubelets verwendet wird.</p><p>Wenn dies nicht möglich ist, verwenden Sie <a href=/docs/concepts/architecture/master-node-communication/#ssh-tunnels>SSH tunneling</a>
zwischen dem Apiserver und dem kubelet, falls es erforderlich ist eine Verbindung über ein nicht vertrauenswürdiges oder öffentliches Netz zu vermeiden.</p><p>Außerdem sollte <a href=/docs/admin/kubelet-authentication-authorization/>Kubelet Authentifizierung und/oder Autorisierung</a> aktiviert sein, um die kubelet-API abzusichern.</p><h3 id=apiserver-zu-nodes-pods-und-services>Apiserver zu Nodes, Pods und Services</h3><p>Die Verbindungen vom Apiserver zu einem Node, Pod oder Dienst verwenden standardmäßig einfache HTTP-Verbindungen und werden daher weder authentifiziert noch verschlüsselt.
Sie können über eine sichere HTTPS-Verbindung ausgeführt werden, indem dem Node, dem Pod oder dem Servicenamen in der API-URL "https:" vorangestellt wird. Das vom HTTPS-Endpunkt bereitgestellte Zertifikat wird jedoch nicht überprüft, und es werden keine Clientanmeldeinformationen bereitgestellt. Die Verbindung wird zwar verschlüsselt, garantiert jedoch keine Integrität.
Diese Verbindungen <strong>sind derzeit nicht sicher</strong> innerhalb von nicht vertrauenswürdigen und/oder öffentlichen Netzen.</p><h3 id=ssh-tunnels>SSH Tunnels</h3><p>Kubernetes unterstützt SSH-Tunnel zum Schutz der Master -> Cluster Kommunikationspfade.
In dieser Konfiguration initiiert der Apiserver einen SSH-Tunnel zu jedem Node im Cluster (Verbindung mit dem SSH-Server, der mit Port 22 läuft), und leitet den gesamten Datenverkehr für ein kubelet, einen Node, einen Pod oder einen Dienst durch den Tunnel.
Dieser Tunnel stellt sicher, dass der Datenverkehr nicht außerhalb des Netzwerks sichtbar ist, in dem die Knoten ausgeführt werden.</p><p>SSH-Tunnel werden zur Zeit nicht unterstützt. Sie sollten also nicht verwendet werden, sei denn, man weiß, was man tut. Ein Ersatz für diesen Kommunikationskanal wird entwickelt.</p></div><div class=td-content style=page-break-before:always><h1 id=pg-bc804b02614d67025b4c788f1ca87fbc>3.2.3 - Zugrunde liegende Konzepte des Cloud Controller Manager</h1><p>Das Konzept des Cloud Controller Managers (CCM) (nicht zu verwechseln mit der Binärdatei) wurde ursprünglich entwickelt, um Cloud-spezifischen Anbieter Code und den Kubernetes Kern unabhängig voneinander entwickeln zu können. Der Cloud Controller Manager läuft zusammen mit anderen Master Komponenten wie dem Kubernetes Controller Manager, dem API-Server und dem Scheduler auf dem Host. Es kann auch als Kubernetes Addon gestartet werden, in diesem Fall läuft er auf Kubernetes.</p><p>Das Design des Cloud Controller Managers basiert auf einem Plugin Mechanismus, der es neuen Cloud Anbietern ermöglicht, sich mit Kubernetes einfach über Plugins zu integrieren. Es gibt Pläne für die Einbindung neuer Cloud Anbieter auf Kubernetes und für die Migration von Cloud Anbietern vom alten Modell auf das neue CCM-Modell.</p><p>Dieses Dokument beschreibt die Konzepte hinter dem Cloud Controller Manager und gibt Details zu den damit verbundenen Funktionen.</p><p>Die Architektur eines Kubernetes Clusters ohne den Cloud Controller Manager sieht wie folgt aus:</p><p><img src=/images/docs/pre-ccm-arch.png alt="Pre CCM Kube Arch"></p><h2 id=design>Design</h2><p>Im vorhergehenden Diagramm sind Kubernetes und der Cloud-Provider über mehrere verschiedene Komponenten integriert:</p><ul><li>Kubelet</li><li>Kubernetes Controller Manager</li><li>Kubernetes API Server</li></ul><p>CCM konsolidiert die gesamte Abhängigkeit der Cloud Logik von den drei vorhergehenden Komponenten zu einem einzigen Integrationspunkt mit der Cloud. So sieht die neue Architektur mit dem CCM aus:</p><p><img src=/images/docs/post-ccm-arch.png alt="CCM Kube Arch"></p><h2 id=komponenten-des-ccm>Komponenten des CCM</h2><p>Der CCM löst einen Teil der Funktionalität des Kubernetes Controller Managers (KCM) ab und führt ihn als separaten Prozess aus. Konkret trennt es die Cloud abhängigen Controller im KCM. Der KCM verfügt über die folgenden Cloud abhängigen Steuerungsschleifen:</p><ul><li>Node Controller</li><li>Volume Controller</li><li>Route Controller</li><li>Service Controller</li></ul><p>In der Version 1.9 führt der CCM die folgenden Controller aus der vorhergehenden Liste aus:</p><ul><li>Node Controller</li><li>Route Controller</li><li>Service Controller</li></ul><div class="alert alert-info note callout" role=alert><strong>Hinweis:</strong> Der Volume Controller wurde bewusst nicht als Teil des CCM gewählt. Aufgrund der Komplexität und der bestehenden Bemühungen, herstellerspezifische Volume Logik zu abstrahieren, wurde entschieden, dass der Volume Controller nicht zum CCM verschoben wird.</div><p>Der ursprüngliche Plan, Volumes mit CCM zu integrieren, sah die Verwendung von Flex-Volumes vor welche austauschbare Volumes unterstützt. Allerdings ist eine konkurrierende Initiative namens CSI geplant, um Flex zu ersetzen.</p><p>In Anbetracht dieser Dynamik haben wir uns entschieden, eine Zwischenstopp durchzuführen um die Unterschiede zu beobachten , bis das CSI bereit ist.</p><h2 id=funktionen-des-ccm>Funktionen des CCM</h2><p>Der CCM erbt seine Funktionen von Komponenten des Kubernetes, die von einem Cloud Provider abhängig sind. Dieser Abschnitt ist auf der Grundlage dieser Komponenten strukturiert.</p><h3 id=1-kubernetes-controller-manager>1. Kubernetes Controller Manager</h3><p>Die meisten Funktionen des CCM stammen aus dem KCM. Wie im vorherigen Abschnitt erwähnt, führt das CCM die folgenden Steuerschleifen durch:</p><ul><li>Node Controller</li><li>Route Controller</li><li>Service Controller</li></ul><h4 id=node-controller>Node Controller</h4><p>Der Node Controller ist für die Initialisierung eines Knotens verantwortlich, indem er Informationen über die im Cluster laufenden Knoten vom Cloud Provider erhält. Der Node Controller führt die folgenden Funktionen aus:</p><ol><li>Initialisierung eines Knoten mit Cloud-spezifischen Zonen-/Regionen Labels.</li><li>Initialisieren von Knoten mit Cloud-spezifischen Instanzdetails, z.B. Typ und Größe.</li><li>Ermitteln der Netzwerkadressen und des Hostnamen des Knotens.</li><li>Falls ein Knoten nicht mehr reagiert, überprüft der Controller die Cloud, um festzustellen, ob der Knoten aus der Cloud gelöscht wurde.
Wenn der Knoten aus der Cloud gelöscht wurde, löscht der Controller das Kubernetes Node Objekt.</li></ol><h4 id=route-controller>Route Controller</h4><p>Der Route Controller ist dafür verantwortlich, Routen in der Cloud so zu konfigurieren, dass Container auf verschiedenen Knoten im Kubernetes Cluster miteinander kommunizieren können. Der Route Controller ist nur auf einem Google Compute Engine Cluster anwendbar.</p><h4 id=service-controller>Service Controller</h4><p>Der Service Controller ist verantwortlich für das Abhören von Ereignissen zum Erstellen, Aktualisieren und Löschen von Diensten. Basierend auf dem aktuellen Stand der Services in Kubernetes konfiguriert es Cloud Load Balancer (wie ELB, Google LB oder Oracle Cloud Infrastructure LB), um den Zustand der Services in Kubernetes abzubilden. Darüber hinaus wird sichergestellt, dass die Service Backends für Cloud Loadbalancer auf dem neuesten Stand sind.</p><h3 id=2-kubelet>2. Kubelet</h3><p>Der Node Controller enthält die Cloud-abhängige Funktionalität des Kubelets. Vor der Einführung des CCM war das Kubelet für die Initialisierung eines Knotens mit cloudspezifischen Details wie IP-Adressen, Regions-/Zonenbezeichnungen und Instanztypinformationen verantwortlich. Mit der Einführung des CCM wurde diese Initialisierungsoperation aus dem Kubelet in das CCM verschoben.</p><p>In diesem neuen Modell initialisiert das Kubelet einen Knoten ohne cloudspezifische Informationen. Es fügt jedoch dem neu angelegten Knoten einen Taint hinzu, der den Knoten nicht verplanbar macht, bis der CCM den Knoten mit cloudspezifischen Informationen initialisiert. Dann wird der Taint entfernt.</p><h2 id=plugin-mechanismus>Plugin Mechanismus</h2><p>Der Cloud Controller Manager verwendet die Go Schnittstellen, um Implementierungen aus jeder Cloud einzubinden. Konkret verwendet dieser das CloudProvider Interface, das <a href=https://github.com/kubernetes/cloud-provider/blob/9b77dc1c384685cb732b3025ed5689dd597a5971/cloud.go#L42-L62>hier</a> definiert ist.</p><p>Die Implementierung der vier oben genannten geteiltent Controllern und einigen Scaffolding sowie die gemeinsame CloudProvider Schnittstelle bleiben im Kubernetes Kern. Cloud Provider spezifische Implementierungen werden außerhalb des Kerns aufgebaut und implementieren im Kern definierte Schnittstellen.</p><p>Weitere Informationen zur Entwicklung von Plugins findest du im Bereich <a href=/docs/tasks/administer-cluster/developing-cloud-controller-manager/>Entwickeln von Cloud Controller Manager</a>.</p><h2 id=autorisierung>Autorisierung</h2><p>Dieser Abschnitt beschreibt den Zugriff, den der CCM für die Ausführung seiner Operationen auf verschiedene API Objekte benötigt.</p><h3 id=node-controller-1>Node Controller</h3><p>Der Node Controller funktioniert nur mit Node Objekten. Es benötigt vollen Zugang zu get, list, create, update, patch, watch, und delete Node Objekten.</p><p>v1/Node:</p><ul><li>Get</li><li>List</li><li>Create</li><li>Update</li><li>Patch</li><li>Watch</li><li>Delete</li></ul><h3 id=route-controller-1>Route Controller</h3><p>Der Route Controller horcht auf die Erstellung von Node Objekten und konfiguriert die Routen entsprechend. Es erfordert get Zugriff auf die Node Objekte.</p><p>v1/Node:</p><ul><li>Get</li></ul><h3 id=service-controller-1>Service Controller</h3><p>Der Service Controller hört auf die Service Objekt Events create, update und delete und konfiguriert dann die Endpunkte für diese Services entsprechend.</p><p>Um auf Services zuzugreifen, benötigt man list und watch Berechtigung. Um die Services zu aktualisieren, sind patch und update Zugriffsrechte erforderlich.</p><p>Um die Endpunkte für die Dienste einzurichten, benötigt der Controller Zugriff auf create, list, get, watch und update.</p><p>v1/Service:</p><ul><li>List</li><li>Get</li><li>Watch</li><li>Patch</li><li>Update</li></ul><h3 id=sonstiges>Sonstiges</h3><p>Die Implementierung des Kerns des CCM erfordert den Zugriff auf die Erstellung von Ereignissen und zur Gewährleistung eines sicheren Betriebs den Zugriff auf die Erstellung von ServiceAccounts.</p><p>v1/Event:</p><ul><li>Create</li><li>Patch</li><li>Update</li></ul><p>v1/ServiceAccount:</p><ul><li>Create</li></ul><p>Die RBAC ClusterRole für CCM sieht wie folgt aus:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>rbac.authorization.k8s.io/v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>ClusterRole<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>cloud-controller-manager<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>rules</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span>- <span style=color:green;font-weight:700>apiGroups</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:#b44>&#34;&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>resources</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- events<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>verbs</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- create<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- patch<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- update<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span>- <span style=color:green;font-weight:700>apiGroups</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:#b44>&#34;&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>resources</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- nodes<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>verbs</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:#b44>&#39;*&#39;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span>- <span style=color:green;font-weight:700>apiGroups</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:#b44>&#34;&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>resources</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- nodes/status<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>verbs</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- patch<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span>- <span style=color:green;font-weight:700>apiGroups</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:#b44>&#34;&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>resources</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- services<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>verbs</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- list<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- patch<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- update<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- watch<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span>- <span style=color:green;font-weight:700>apiGroups</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:#b44>&#34;&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>resources</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- serviceaccounts<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>verbs</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- create<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span>- <span style=color:green;font-weight:700>apiGroups</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:#b44>&#34;&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>resources</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- persistentvolumes<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>verbs</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- get<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- list<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- update<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- watch<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span>- <span style=color:green;font-weight:700>apiGroups</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:#b44>&#34;&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>resources</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- endpoints<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>verbs</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- create<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- get<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- list<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- watch<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- update<span style=color:#bbb>
</span></span></span></code></pre></div><h2 id=anbieter-implementierung>Anbieter Implementierung</h2><p>Die folgenden Cloud Anbieter haben CCMs implementiert:</p><ul><li><a href=https://github.com/digitalocean/digitalocean-cloud-controller-manager>Digital Ocean</a></li><li><a href=https://github.com/oracle/oci-cloud-controller-manager>Oracle</a></li><li><a href=https://github.com/kubernetes/cloud-provider-azure>Azure</a></li><li><a href=https://github.com/kubernetes/cloud-provider-gcp>GCP</a></li><li><a href=https://github.com/kubernetes/cloud-provider-aws>AWS</a></li><li><a href=https://github.com/baidu/cloud-provider-baiducloud>BaiduCloud</a></li><li><a href=https://github.com/linode/linode-cloud-controller-manager>Linode</a></li></ul><h2 id=cluster-administration>Cluster Administration</h2><p>Eine vollständige Anleitung zur Konfiguration und zum Betrieb des CCM findest du <a href=/docs/tasks/administer-cluster/running-cloud-controller/#cloud-controller-manager>hier</a>.</p></div><div class=td-content style=page-break-before:always><h1 id=pg-a5f7383c83ab9eb9cd0e3c4c020b3ae6>3.3 - Container</h1></div><div class=td-content><h1 id=pg-16042b4652ad19e565c7263824029a43>3.3.1 - Images</h1><p>Sie erstellen Ihr Docker Image und laden es in eine Registry hoch, bevor es in einem Kubernetes Pod referenziert werden kann.</p><p>Die <code>image</code> Eigenschaft eines Containers unterstüzt die gleiche Syntax wie die des <code>docker</code> Kommandos, inklusive privater Registries und Tags.</p><h2 id=aktualisieren-von-images>Aktualisieren von Images</h2><p>Die Standardregel für das Herunterladen von Images ist <code>IfNotPresent</code>, dies führt dazu, dass das Image wird nur heruntergeladen wenn es noch nicht lokal verfügbar ist.
Wenn sie stattdessen möchten, dass ein Image immer forciert heruntergeladen wird, können sie folgendes tun:</p><ul><li>Die <code>imagePullPolicy</code> des Containers auf <code>Always</code> setzen.</li><li>Die <code>imagePullPolicy</code> auslassen und <code>:latest</code> als Image Tag nutzen.</li><li>Die <code>imagePullPolicy</code> und den Tag des Images auslassen.</li><li>Den <a href=/docs/reference/access-authn-authz/admission-controllers/#alwayspullimages>AlwaysPullImages</a> Admission Controller aktivieren.</li></ul><p>Beachten Sie, dass Sie die Nutzung des <code>:latest</code> Tags vermeiden sollten. Für weitere Informationen siehe: <a href=/docs/concepts/configuration/overview/#container-images>Best Practices for Configuration</a>.</p><h2 id=multi-architektur-images-mit-manifesten-bauen>Multi-Architektur Images mit Manifesten bauen</h2><p>Das Docker Kommandozeilenwerkzeug unterstützt jetzt das Kommando <code>docker manifest</code> mit den Subkommandos <code>create</code>, <code>annotate</code> and <code>push</code>.
Diese Kommandos können dazu genutzt werden Manifeste zu bauen und diese hochzuladen.</p><p>Weitere Informationen finden sie in der Docker Dokumentation:
<a href=https://docs.docker.com/edge/engine/reference/commandline/manifest/>https://docs.docker.com/edge/engine/reference/commandline/manifest/</a></p><p>Hier einige Beispiele wie wir dies in unserem Build - Prozess nutzen:
<a href="https://cs.k8s.io/?q=docker%20manifest%20(create%7Cpush%7Cannotate)&i=nope&files=&repos=">https://cs.k8s.io/?q=docker%20manifest%20(create%7Cpush%7Cannotate)&i=nope&files=&repos=</a></p><p>Diese Kommandos basieren rein auf dem Docker Kommandozeileninterface und werden auch damit ausgeführt. Sie sollten entweder die Datei <code>$HOME/.docker/config.json</code> bearbeiten und den <code>experimental</code> Schlüssel auf <code>enabled</code> setzen, oder einfach die Umgebungsvariable <code>DOCKER_CLI_EXPERIMENTAL</code> auf <code>enabled</code> setzen, wenn Sie das Docker Kommandozeileninterface aufrufen.</p><div class="alert alert-info note callout" role=alert><strong>Hinweis:</strong> Nutzen die bitte Docker <em>18.06 oder neuer</em>, ältere Versionen haben entweder Bugs oder unterstützen die experimentelle Kommandozeilenoption nicht. Beispiel: <a href=https://github.com/docker/cli/issues/1135>https://github.com/docker/cli/issues/1135</a> verursacht Probleme unter containerd.</div><p>Wenn mit alten Manifesten Probleme auftreten, können sie die alten Manifeste in <code>$HOME/.docker/manifests</code> entfernen, um von vorne zu beginnen.</p><p>Für Kubernetes selbst nutzen wir typischerweise Images mit dem Suffix <code>-$(ARCH)</code>. Um die Abwärtskompatibilität zu erhalten, bitten wir Sie, die älteren Images mit diesen Suffixen zu generieren. Die Idee dahinter ist z.B., das <code>pause</code> image zu generieren, welches das Manifest für alle Architekturen hat, <code>pause-amd64</code> wäre dann abwärtskompatibel zu älteren Konfigurationen, oder YAML - Dateien, die ein Image mit Suffixen hart kodiert enthalten.</p><h2 id=nutzung-einer-privaten-registry>Nutzung einer privaten Registry</h2><p>Private Registries könnten Schlüssel erfordern um Images von ihnen herunterzuladen.
Authentifizierungsdaten können auf verschiedene Weisen hinterlegt werden:</p><ul><li>Bei der Google Container Registry<ul><li>Je Cluster</li><li>Automatisch in der Google Compute Engine oder Google Kubernetes Engine</li><li>Allen Pods erlauben von der privaten Registry des Projektes lesen zu können</li></ul></li><li>Bei der Amazon Elastic Container Registry (ECR)<ul><li>IAM Rollen und Richtlinien nutzen um den Zugriff auf ECR Repositories zu kontrollieren</li><li>Automatisch ECR Authentifizierungsdaten aktualisieren</li></ul></li><li>Bei der Oracle Cloud Infrastructure Registry (OCIR)<ul><li>IAM Rollen und Richtlinien nutzen um den Zugriff auf OCIR Repositories zu kontrollieren</li></ul></li><li>Bei der Azure Container Registry (ACR)</li><li>Bei der IBM Cloud Container Registry</li><li>Nodes konfigurieren sich bei einer privaten Registry authentifizieren zu können
- Allen Pods erlauben von jeder konfigurierten privaten Registry lesen zu können
- Setzt die Konfiguration der Nodes durch einen Cluster - Aministrator voraus</li><li>Im Voraus heruntergeladene Images<ul><li>Alle Pods können jedes gecachte Image auf einem Node nutzen</li><li>Setzt root - Zugriff auf allen Nodes zum Einrichten voraus</li></ul></li><li>Spezifizieren eines ImagePullSecrets auf einem Pod<ul><li>Nur Pods, die eigene Secrets tragen, haben Zugriff auf eine private Registry</li></ul></li></ul><p>Jede Option wird im Folgenden im Detail beschrieben</p><h3 id=bei-nutzung-der-google-container-registry>Bei Nutzung der Google Container Registry</h3><p>Kubernetes hat eine native Unterstützung für die <a href=https://cloud.google.com/tools/container-registry/>Google Container
Registry (GCR)</a> wenn es auf der Google Compute
Engine (GCE) läuft. Wenn Sie ihren Cluster auf GCE oder der Google Kubernetes Engine betreiben, genügt es, einfach den vollen Image Namen zu nutzen (z.B. gcr.io/my_project/image:tag ).</p><p>Alle Pods in einem Cluster haben dann Lesezugriff auf Images in dieser Registry.</p><p>Das Kubelet authentifiziert sich bei GCR mit Nutzung des Google service Kontos der jeweiligen Instanz.
Das Google Servicekonto der Instanz hat einen <code>https://www.googleapis.com/auth/devstorage.read_only</code>, so kann es vom GCR des Projektes herunter, aber nicht hochladen.</p><h3 id=bei-nutzung-der-amazon-elastic-container-registry>Bei Nutzung der Amazon Elastic Container Registry</h3><p>Kubernetes bietet native Unterstützung für die <a href=https://aws.amazon.com/ecr/>Amazon Elastic Container Registry</a>, wenn Knoten AWS EC2 Instanzen sind.</p><p>Es muss einfach nur der komplette Image Name (z.B. <code>ACCOUNT.dkr.ecr.REGION.amazonaws.com/imagename:tag</code>) in der Pod - Definition genutzt werden.</p><p>Alle Benutzer eines Clusters, die Pods erstellen dürfen, können dann jedes der Images in der ECR Registry zum Ausführen von Pods nutzen.</p><p>Das Kubelet wird periodisch ECR Zugriffsdaten herunterladen und auffrischen, es benötigt hierfür die folgenden Berechtigungen:</p><ul><li><code>ecr:GetAuthorizationToken</code></li><li><code>ecr:BatchCheckLayerAvailability</code></li><li><code>ecr:GetDownloadUrlForLayer</code></li><li><code>ecr:GetRepositoryPolicy</code></li><li><code>ecr:DescribeRepositories</code></li><li><code>ecr:ListImages</code></li><li><code>ecr:BatchGetImage</code></li></ul><p>Voraussetzungen:</p><ul><li>Sie müssen Kubelet in der Version <code>v1.2.0</code> nutzen. (Führen sie z.B. (e.g. run <code>/usr/bin/kubelet --version=true</code> aus um die Version zu prüfen)</li><li>Sie benötigen Version <code>v1.3.0</code> oder neuer wenn ihre Knoten in einer A - Region sind und sich ihre Registry in einer anderen B - Region befindet.</li><li>ECR muss in ihrer Region angeboten werden</li></ul><p>Fehlerbehebung:</p><ul><li>Die oben genannten Voraussetzungen müssen erfüllt sein</li><li>Laden sie die $REGION (z.B. <code>us-west-2</code>) Zugriffsdaten auf ihren Arbeitsrechner. Verbinden sie sich per SSH auf den Host und nutzen die Docker mit diesen Daten. Funktioniert es?</li><li>Prüfen sie ob das Kubelet it dem Parameter <code>--cloud-provider=aws</code> läuft.</li><li>Prüfen sie die Logs des Kubelets (z.B. mit <code>journalctl -u kubelet</code>) auf Zeilen wie:<ul><li><code>plugins.go:56] Registering credential provider: aws-ecr-key</code></li><li><code>provider.go:91] Refreshing cache for provider: *aws_credentials.ecrProvider</code></li></ul></li></ul><h3 id=bei-nutzung-der-azure-container-registry-acr>Bei Nutzung der Azure Container Registry (ACR)</h3><p>Bei Nutzung der <a href=https://azure.microsoft.com/en-us/services/container-registry/>Azure Container Registry</a> können sie sich entweder als ein administrativer Nutzer, oder als ein Service Principal authentifizieren.
In jedem Fall wird die Authentifizierung über die Standard - Docker Authentifizierung ausgeführt. Diese Anleitung bezieht sich auf das <a href=https://github.com/azure/azure-cli>azure-cli</a> Kommandozeilenwerkzeug.</p><p>Sie müssen zunächst eine Registry und Authentifizierungsdaten erstellen, eine komplette Dokumentation dazu finden sie hier: <a href=https://docs.microsoft.com/en-us/azure/container-registry/container-registry-get-started-azure-cli>Azure container registry documentation</a>.</p><p>Sobald sie ihre Container Registry erstellt haben, nutzen sie die folgenden Authentifizierungsdaten:</p><ul><li><code>DOCKER_USER</code> : Service Principal oder Administratorbenutzername</li><li><code>DOCKER_PASSWORD</code>: Service Principal Password oder Administratorpasswort</li><li><code>DOCKER_REGISTRY_SERVER</code>: <code>${some-registry-name}.azurecr.io</code></li><li><code>DOCKER_EMAIL</code>: <code>${some-email-address}</code></li></ul><p>Wenn sie diese Variablen befüllt haben, können sie:
<a href=/docs/concepts/containers/images/#specifying-imagepullsecrets-on-a-pod>Kubernetes konfigurieren und damit einen Pod deployen</a>.</p><h3 id=bei-nutzung-der-ibm-cloud-container-registry>Bei Nutzung der IBM Cloud Container Registry</h3><p>Die IBM Cloud Container Registry bietet eine mandantenfähige Private Image Registry, die Sie nutzen können, um ihre Docker Images sicher zu speichern und zu teilen.
Standardmäßig werden Images in ihrer Private Registry vom integrierten Schwachstellenscaner durchsucht, um Sicherheitsprobleme und potentielle Schwachstellen zu finden. Benutzer können ihren IBM Cloud Account nutzen, um Zugang zu ihren Images zu erhalten, oder um einen Token zu generieren, der Zugriff auf die Registry Namespaces erlaubt.</p><p>Um das IBM Cloud Container Registry Kommandozeilenwerkzeug zu installieren und einen Namespace für ihre Images zu erstellen, folgen sie dieser Dokumentation <a href="https://cloud.ibm.com/docs/services/Registry?topic=registry-getting-started">Getting started with IBM Cloud Container Registry</a>.</p><p>Sie können die IBM Cloud Container Registry nutzen, um Container aus <a href="https://cloud.ibm.com/docs/services/Registry?topic=registry-public_images">IBM Cloud public images</a> und ihren eigenen Images in den <code>default</code> Namespace ihres IBM Cloud Kubernetes Service Clusters zu deployen.
Um einen Container in einen anderen Namespace, oder um ein Image aus einer anderen IBM Cloud Container Registry Region oder einem IBM Cloud account zu deployen, erstellen sie ein Kubernetes <code>imagePullSecret</code>.
Weitere Informationen finden sie unter: <a href="https://cloud.ibm.com/docs/containers?topic=containers-images">Building containers from images</a>.</p><h3 id=knoten-für-die-nutzung-einer-private-registry-konfigurieren>Knoten für die Nutzung einer Private Registry konfigurieren</h3><div class="alert alert-info note callout" role=alert><strong>Hinweis:</strong> Wenn sie Google Kubernetes Engine verwenden, gibt es schon eine <code>.dockercfg</code> auf jedem Knoten, die Zugriffsdaten für ihre Google Container Registry beinhaltet. Dann kann die folgende Vorgehensweise nicht angewendet werden.</div><div class="alert alert-info note callout" role=alert><strong>Hinweis:</strong> Wenn sie AWS EC2 verwenden und die EC2 Container Registry (ECR) nutzen, wird das Kubelet auf jedem Knoten die ECR Zugriffsdaten verwalten und aktualisieren. Dann kann die folgende Vorgehensweise nicht angewendet werden.</div><div class="alert alert-info note callout" role=alert><strong>Hinweis:</strong> Diese Vorgehensweise ist anwendbar, wenn sie ihre Knoten-Konfiguration ändern können; Sie wird nicht zuverlässig auf GCE oder einem anderen Cloud - Provider funktionieren, der automatisch Knoten ersetzt.</div><div class="alert alert-info note callout" role=alert><strong>Hinweis:</strong> Kubernetes unterstützt zurzeit nur die <code>auths</code> und <code>HttpHeaders</code> Abschnitte der Dockerkonfiguration. Das bedeutet, dass die Hilfswerkzeuge (<code>credHelpers</code> ooderr <code>credsStore</code>) nicht unterstützt werden.</div><p>Docker speichert Schlüssel für eigene Registries entweder unter <code>$HOME/.dockercfg</code> oder <code>$HOME/.docker/config.json</code>. Wenn sie die gleiche Datei in einen der unten aufgeführten Suchpfade speichern, wird Kubelet sie als Hilfswerkzeug für Zugriffsdaten beim Beziehen von Images nutzen.</p><ul><li><code>{--root-dir:-/var/lib/kubelet}/config.json</code></li><li><code>{cwd of kubelet}/config.json</code></li><li><code>${HOME}/.docker/config.json</code></li><li><code>/.docker/config.json</code></li><li><code>{--root-dir:-/var/lib/kubelet}/.dockercfg</code></li><li><code>{cwd of kubelet}/.dockercfg</code></li><li><code>${HOME}/.dockercfg</code></li><li><code>/.dockercfg</code></li></ul><div class="alert alert-info note callout" role=alert><strong>Hinweis:</strong> Eventuell müssen sie <code>HOME=/root</code> in ihrer Umgebungsvariablendatei setzen.</div><p>Dies sind die empfohlenen Schritte, um ihre Knoten für eine Nutzung einer eigenen Registry zu konfigurieren.
In diesem Beispiel führen sie folgende Schritte auf ihrem Desktop/Laptop aus:</p><ol><li>Führen sie <code>docker login [server]</code> für jeden Satz ihrer Zugriffsdaten aus. Dies aktualisiert <code>$HOME/.docker/config.json</code>.</li><li>Prüfen Sie <code>$HOME/.docker/config.json</code> in einem Editor darauf, ob dort nur Zugriffsdaten enthalten sind, die Sie nutzen möchten.</li><li>Erhalten sie eine Liste ihrer Knoten:<ul><li>Wenn sie die Namen benötigen: <code>nodes=$(kubectl get nodes -o jsonpath='{range.items[*].metadata}{.name} {end}')</code></li><li>Wenn sie die IP - Adressen benötigen: <code>nodes=$(kubectl get nodes -o jsonpath='{range .items[*].status.addresses[?(@.type=="ExternalIP")]}{.address} {end}')</code></li></ul></li><li>Kopieren sie ihre lokale <code>.docker/config.json</code> in einen der oben genannten Suchpfade.<ul><li>Zum Beispiel: <code>for n in $nodes; do scp ~/.docker/config.json root@$n:/var/lib/kubelet/config.json; done</code></li></ul></li></ol><p>Prüfen durch das Erstellen eines Pods, der ein eigenes Image nutzt, z.B.:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span>kubectl apply -f - &lt;&lt;EOF<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>private-image-test-1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>uses-private-image<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>$PRIVATE_IMAGE_NAME<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>imagePullPolicy</span>:<span style=color:#bbb> </span>Always<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>command</span>:<span style=color:#bbb> </span>[<span style=color:#bbb> </span><span style=color:#b44>&#34;echo&#34;</span>,<span style=color:#bbb> </span><span style=color:#b44>&#34;SUCCESS&#34;</span><span style=color:#bbb> </span>]<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span>EOF<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span>pod/private-image-test-1 created<span style=color:#bbb>
</span></span></span></code></pre></div><p>Wenn alles funktioniert, sollten sie nach einigen Momenten folgendes sehen:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl logs private-image-test-1
</span></span><span style=display:flex><span>SUCCESS
</span></span></code></pre></div><p>Wenn es nicht funktioniert, sehen Sie:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl describe pods/private-image-test-1 | grep <span style=color:#b44>&#34;Failed&#34;</span>
</span></span><span style=display:flex><span>  Fri, <span style=color:#666>26</span> Jun <span style=color:#666>2015</span> 15:36:13 -0700    Fri, <span style=color:#666>26</span> Jun <span style=color:#666>2015</span> 15:39:13 -0700    <span style=color:#666>19</span>    <span style=color:#666>{</span>kubelet node-i2hq<span style=color:#666>}</span>    spec.containers<span style=color:#666>{</span>uses-private-image<span style=color:#666>}</span>    failed        Failed to pull image <span style=color:#b44>&#34;user/privaterepo:v1&#34;</span>: Error: image user/privaterepo:v1 not found
</span></span></code></pre></div><p>Sie müssen sich darum kümmern, dass alle Knoten im Cluster die gleiche <code>.docker/config.json</code> haben, andernfalls werden Pods auf einigen Knoten starten, auf anderen jedoch nicht.
Wenn sie zum Beispiel Knoten automatisch skalieren lassen, sollte dann jedes Instanztemplate die <code>.docker/config.json</code> beinhalten, oder ein Laufwerk einhängen, das diese beinhaltet.</p><p>Alle Pods haben Lesezugriff auf jedes Image in ihrer eigenen Registry, sobald die Registry - Schlüssel zur <code>.docker/config.json</code> hinzugefügt wurden.</p><h3 id=im-voraus-heruntergeladene-images>Im Voraus heruntergeladene Images</h3><div class="alert alert-info note callout" role=alert><strong>Hinweis:</strong> Wenn sie Google Kubernetes Engine verwenden, gibt es schon eine <code>.dockercfg</code> auf jedem Knoten die Zugriffsdaten für ihre Google Container Registry beinhaltet. Dann kann die folgende Vorgehensweise nicht angewendet werden.</div><div class="alert alert-info note callout" role=alert><strong>Hinweis:</strong> Diese Vorgehensweise ist anwendbar, wenn sie ihre Knoten-Konfiguration ändern können; Sie wird nicht zuverlässig auf GCE oder einem anderen Cloud - Provider funktionieren, der automatisch Knoten ersetzt.</div><p>Standardmäßig wird das Kubelet versuchen, jedes Image von der spezifizierten Registry herunterzuladen.
Falls jedoch die <code>imagePullPolicy</code> Eigenschaft der Containers auf <code>IfNotPresent</code> oder <code>Never</code> gesetzt wurde, wird ein lokales Image genutzt (präferiert oder exklusiv, jenachdem).</p><p>Wenn Sie sich auf im Voraus heruntergeladene Images als Ersatz für eine Registry - Authentifizierung verlassen möchten, müssen sie sicherstellen, dass alle Knoten die gleichen, im Voraus heruntergeladenen Images aufweisen.</p><p>Diese Methode kann dazu genutzt werden, bestimmte Images aus Geschwindigkeitsgründen im Voraus zu laden, oder als Alternative zur Authentifizierung an einer eigenen Registry zu nutzen.</p><p>Alle Pods haben Leserechte auf alle im Voraus geladenen Images.</p><h3 id=spezifizieren-eines-imagepullsecrets-für-einen-pod>Spezifizieren eines ImagePullSecrets für einen Pod</h3><div class="alert alert-info note callout" role=alert><strong>Hinweis:</strong> Diese Vorgehensweise ist aktuell die empfohlene Vorgehensweise für Google Kubernetes Engine, GCE, und jeden Cloud - Provider bei dem die Knotenerstelltung automatisiert ist.</div><p>Kubernetes unterstützt die Spezifikation von Registrierungsschlüsseln für einen Pod.</p><h4 id=erstellung-eines-secrets-mit-einer-docker-konfiguration>Erstellung eines Secrets mit einer Docker Konfiguration</h4><p>Führen sie folgenden Befehl mit Ersetzung der groß geschriebenen Werte aus:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl create secret docker-registry &lt;name&gt; --docker-server<span style=color:#666>=</span>DOCKER_REGISTRY_SERVER --docker-username<span style=color:#666>=</span>DOCKER_USER --docker-password<span style=color:#666>=</span>DOCKER_PASSWORD --docker-email<span style=color:#666>=</span>DOCKER_EMAIL
</span></span></code></pre></div><p>Wenn Sie bereits eine Datei mit Docker-Zugriffsdaten haben, können Sie die Zugriffsdaten als ein Kubernetes Secret importieren:
<a href=/docs/tasks/configure-pod-container/pull-image-private-registry/#registry-secret-existing-credentials>Create a Secret based on existing Docker credentials</a> beschreibt die Erstellung.
Dies ist insbesondere dann sinnvoll, wenn sie mehrere eigene Container Registries nutzen, da <code>kubectl create secret docker-registry</code> ein Secret erstellt, das nur mit einer einzelnen eigenen Registry funktioniert.</p><div class="alert alert-info note callout" role=alert><strong>Hinweis:</strong> Pods können nur eigene Image Pull Secret in ihrem eigenen Namespace referenzieren, somit muss dieser Prozess jedes mal einzeln für jeden Namespace angewendet werden.</div><h4 id=referenzierung-eines-imagepullsecrets-bei-einem-pod>Referenzierung eines imagePullSecrets bei einem Pod</h4><p>Nun können Sie Pods erstellen, die dieses Secret referenzieren, indem Sie einen Aschnitt <code>imagePullSecrets</code> zu ihrer Pod - Definition hinzufügen.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>cat <span style=color:#b44>&lt;&lt;EOF &gt; pod.yaml
</span></span></span><span style=display:flex><span><span style=color:#b44>apiVersion: v1
</span></span></span><span style=display:flex><span><span style=color:#b44>kind: Pod
</span></span></span><span style=display:flex><span><span style=color:#b44>metadata:
</span></span></span><span style=display:flex><span><span style=color:#b44>  name: foo
</span></span></span><span style=display:flex><span><span style=color:#b44>  namespace: awesomeapps
</span></span></span><span style=display:flex><span><span style=color:#b44>spec:
</span></span></span><span style=display:flex><span><span style=color:#b44>  containers:
</span></span></span><span style=display:flex><span><span style=color:#b44>    - name: foo
</span></span></span><span style=display:flex><span><span style=color:#b44>      image: janedoe/awesomeapp:v1
</span></span></span><span style=display:flex><span><span style=color:#b44>  imagePullSecrets:
</span></span></span><span style=display:flex><span><span style=color:#b44>    - name: myregistrykey
</span></span></span><span style=display:flex><span><span style=color:#b44>EOF</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>cat <span style=color:#b44>&lt;&lt;EOF &gt;&gt; ./kustomization.yaml
</span></span></span><span style=display:flex><span><span style=color:#b44>resources:
</span></span></span><span style=display:flex><span><span style=color:#b44>- pod.yaml
</span></span></span><span style=display:flex><span><span style=color:#b44>EOF</span>
</span></span></code></pre></div><p>Dies muss für jeden Pod getan werden, der eine eigene Registry nutzt.</p><p>Die Erstellung dieser Sektion kann jedoch automatisiert werden, indem man imagePullSecrets einer <a href=/docs/user-guide/service-accounts>serviceAccount</a> Ressource hinzufügt.
<a href=/docs/tasks/configure-pod-container/configure-service-account/#add-imagepullsecrets-to-a-service-account>Add ImagePullSecrets to a Service Account</a> bietet detaillierte Anweisungen hierzu.</p><p>Sie können dies in Verbindung mit einer auf jedem Knoten genutzten <code>.docker/config.json</code> benutzen, die Zugriffsdaten werden dann zusammengeführt. Dieser Vorgehensweise wird in der Google Kubernetes Engine funktionieren.</p><h3 id=anwendungsfälle>Anwendungsfälle</h3><p>Es gibt eine Anzahl an Lösungen um eigene Registries zu konfigurieren, hier sind einige Anwendungsfälle und empfohlene Lösungen.</p><ol><li>Cluster die nur nicht-proprietäre Images (z.B. open-source) ausführen. Images müssen nicht versteckt werden.<ul><li>Nutzung von öffentlichen Images auf Docker Hub.<ul><li>Keine Konfiguration notwendig.</li><li>Auf GCE/Google Kubernetes Engine, wird automatisch ein lokaler Spiegel für eine verbesserte Geschwindigkeit und Verfügbarkeit genutzt.</li></ul></li></ul></li><li>Cluster die einige proprietäre Images ausführen die für Außenstehende nicht sichtbar sein dürfen, aber für alle Cluster - Benutzer sichtbar sein sollen.<ul><li>Nutzung einer gehosteten privaten Registry <a href=https://docs.docker.com/registry/>Docker registry</a>.<ul><li>Kann auf <a href=https://hub.docker.com/signup>Docker Hub</a>, oder woanders gehostet werden.</li><li>Manuelle Konfiguration der .docker/config.json auf jedem Knoten, wie oben beschrieben.</li></ul></li><li>Der Betrieb einer internen privaten Registry hinter ihrer Firewall mit offenen Leseberechtigungen.<ul><li>Keine Kubernetes - Konfiguration notwendig</li></ul></li><li>Wenn GCE/Google Kubernetes Engine genutzt wird, nutzen sie die Google Container Registry des Projektes.<ul><li>Funktioniert besser mit Cluster - Autoskalierung als mit manueller Knotenkonfiguration.</li></ul></li><li>Auf einem Cluster bei dem die Knotenkonfiguration ungünstig ist können <code>imagePullSecrets</code> genutzt werden.</li></ul></li><li>Cluster mit proprieritären Images, mit einigen Images die eine erweiterte Zugriffskontrolle erfordern.<ul><li>Stellen sie sicher das <a href=/docs/reference/access-authn-authz/admission-controllers/#alwayspullimages>AlwaysPullImages admission controller</a> aktiv ist, anderenfalls können alle Pods potenziell Zugriff auf alle Images haben.</li><li>Verschieben sie sensitive Daten in eine "Secret" Ressource statt sie im Image abzulegen.</li></ul></li><li>Ein mandantenfähiger Cluster in dem jeder Mandant eine eigene private Registry benötigt.<ul><li>Stellen sie dicher das <a href=/docs/reference/access-authn-authz/admission-controllers/#alwayspullimages>AlwaysPullImages admission controller</a> aktiv ist, anderenfalls können alle Pods potenziell Zugriff auf alle Images haben.</li><li>Nutzen sie eine private Registry die eine Authorisierung erfordert.</li><li>Generieren die Registry - Zugriffsdaten für jeden Mandanten, abgelegt in einem Secret das in jedem Mandanten - Namespace vorhanden ist.</li><li>Der Mandant fügt dieses Sercret zu den imagePullSecrets in jedem seiner Namespace hinzu.</li></ul></li></ol><p>Falls die Zugriff auf mehrere Registries benötigen, können sie ein Secret für jede Registry erstellen, Kubelet wird jedwede <code>imagePullSecrets</code> in einer einzelnen <code>.docker/config.json</code> zusammenfassen.</p></div><div class=td-content style=page-break-before:always><h1 id=pg-d52aadda80edd9f8c514cfe2321363c2>3.4 - Workloads</h1></div><div class=td-content><h1 id=pg-4d68b0ccf9c683e6368ffdcc40c838d4>3.4.1 - Pods</h1><p><em>Pods</em> sind die kleinsten einsetzbaren Einheiten, die in Kubernetes
erstellt und verwaltet werden können.</p><p>Ein <em>Pod</em> (übersetzt Gruppe/Schote, wie z. B. eine Gruppe von Walen oder eine
Erbsenschote) ist eine Gruppe von einem oder mehreren
<a class=glossary-tooltip title='A lightweight and portable executable image that contains software and all of its dependencies.' data-toggle=tooltip data-placement=top href=/docs/concepts/containers/ target=_blank aria-label=Containern>Containern</a> mit gemeinsam
genutzten Speicher- und Netzwerkressourcen und einer Spezifikation für die
Ausführung der Container. Die Ressourcen eines Pods befinden sich immer auf dem
gleichen (virtuellen) Server, werden gemeinsam geplant und in einem
gemeinsamen Kontext ausgeführt. Ein Pod modelliert einen anwendungsspezifischen
"logischen Server": Er enthält eine oder mehrere containerisierte Anwendungen,
die relativ stark voneinander abhängen.
In Nicht-Cloud-Kontexten sind Anwendungen, die auf
demselben physischen oder virtuellen Server ausgeführt werden, vergleichbar zu
Cloud-Anwendungen, die auf demselben logischen Server ausgeführt werden.</p><p>Ein Pod kann neben Anwendungs-Containern auch sogenannte
<a href=/docs/concepts/workloads/pods/init-containers/>Initialisierungs-Container</a>
enthalten, die beim Starten des Pods ausgeführt werden.
Es können auch
kurzlebige/<a href=/docs/concepts/workloads/pods/ephemeral-containers/>ephemere Container</a>
zum Debuggen gestartet werden, wenn dies der Cluster anbietet.</p><h2 id=was-ist-ein-pod>Was ist ein Pod?</h2><div class="alert alert-info note callout" role=alert><strong>Hinweis:</strong> Obwohl Kubernetes abgesehen von <a href=https://www.docker.com/>Docker</a> auch andere
<a class=glossary-tooltip title='The container runtime is the software that is responsible for running containers.' data-toggle=tooltip data-placement=top href=/docs/setup/production-environment/container-runtimes target=_blank aria-label=Container-Laufzeitumgebungen>Container-Laufzeitumgebungen</a> unterstützt, ist Docker am bekanntesten und
es ist hilfreich, Pods mit der Terminologie von Docker zu beschreiben.</div><p>Der gemeinsame Kontext eines Pods besteht aus einer Reihe von Linux-Namespaces,
Cgroups und möglicherweise anderen Aspekten der Isolation, also die gleichen
Dinge, die einen Dockercontainer isolieren. Innerhalb des Kontexts eines Pods
können die einzelnen Anwendungen weitere Unterisolierungen haben.</p><p>Im Sinne von Docker-Konzepten ähnelt ein Pod einer Gruppe von Docker-Containern,
die gemeinsame Namespaces und Dateisystem-Volumes nutzen.</p><h2 id=pods-verwenden>Pods verwenden</h2><p>Normalerweise müssen keine Pods erzeugt werden, auch keine Singleton-Pods.
Stattdessen werden sie mit Workload-Ressourcen wie <a class=glossary-tooltip title='Manages a replicated application on your cluster.' data-toggle=tooltip data-placement=top href=/docs/concepts/workloads/controllers/deployment/ target=_blank aria-label=Deployment>Deployment</a> oder <a class=glossary-tooltip title='A finite or batch task that runs to completion.' data-toggle=tooltip data-placement=top href=/docs/concepts/workloads/controllers/job/ target=_blank aria-label=Job>Job</a> erzeugt. Für Pods, die von einem Systemzustand
abhängen, ist die Nutzung von <a class=glossary-tooltip title='Manages deployment and scaling of a set of Pods, with durable storage and persistent identifiers for each Pod.' data-toggle=tooltip data-placement=top href=/docs/concepts/workloads/controllers/statefulset/ target=_blank aria-label=StatefulSet>StatefulSet</a>-Ressourcen zu erwägen.</p><p>Pods in einem Kubernetes-Cluster werden hauptsächlich auf zwei Arten verwendet:</p><ul><li><strong>Pods, die einen einzelnen Container ausführen</strong>. Das
"Ein-Container-per-Pod"-Modell ist der häufigste Kubernetes-Anwendungsfall. In
diesem Fall kannst du dir einen einen Pod als einen Behälter vorstellen, der einen
einzelnen Container enthält; Kubernetes verwaltet die Pods anstatt die
Container direkt zu verwalten.</li><li><strong>Pods, in denen mehrere Container ausgeführt werden, die zusammenarbeiten
müssen</strong>. Wenn eine Softwareanwendung aus co-lokaliserten Containern besteht,
die sich gemeinsame Ressourcen teilen und stark voneinander abhängen, kann ein
Pod die Container verkapseln.
Diese Container bilden eine einzelne zusammenhängende
Serviceeinheit, z. B. ein Container, der Daten in einem gemeinsam genutzten
Volume öffentlich verfügbar macht, während ein separater <em>Sidecar</em>-Container
die Daten aktualisiert. Der Pod fasst die Container, die Speicherressourcen
und eine kurzlebiges Netzwerk-Identität als eine Einheit zusammen.</li></ul><div class="alert alert-info note callout" role=alert><strong>Hinweis:</strong> Das Gruppieren mehrerer gemeinsam lokalisierter und gemeinsam verwalteter
Container in einem einzigen Pod ist ein relativ fortgeschrittener
Anwendungsfall. Du solltest diese Architektur nur in bestimmten Fällen
verwenden, wenn deine Container stark voneinander abhängen.</div><p>Jeder Pod sollte eine einzelne Instanz einer gegebenen Anwendung ausführen. Wenn
du deine Anwendung horizontal skalieren willst (um mehr Instanzen auszuführen
und dadurch mehr Gesamtressourcen bereitstellen), solltest du mehrere Pods
verwenden, einen für jede Instanz.
In Kubernetes wird dies typischerweise als Replikation bezeichnet.
Replizierte Pods werden normalerweise als eine Gruppe durch eine
Workload-Ressource und deren
<a class=glossary-tooltip title='A control loop that watches the shared state of the cluster through the apiserver and makes changes attempting to move the current state towards the desired state.' data-toggle=tooltip data-placement=top href=/docs/concepts/architecture/controller/ target=_blank aria-label=Controller>Controller</a> erstellt
und verwaltet.</p><p>Der Abschnitt <a href=#pods-und-controller>Pods und Controller</a> beschreibt, wie
Kubernetes Workload-Ressourcen und deren Controller verwendet, um Anwendungen
zu skalieren und zu heilen.</p><h3 id=wie-pods-mehrere-container-verwalten>Wie Pods mehrere Container verwalten</h3><p>Pods unterstützen mehrere kooperierende Prozesse (als Container), die eine
zusammenhängende Serviceeinheit bilden. Kubernetes plant und stellt automatisch
sicher, dass sich die Container in einem Pod auf demselben physischen oder
virtuellen Server im Cluster befinden. Die Container können Ressourcen und
Abhängigkeiten gemeinsam nutzen, miteinander kommunizieren und
ferner koordinieren wann und wie sie beendet werden.</p><p>Zum Beispiel könntest du einen Container haben, der als Webserver für Dateien in
einem gemeinsamen Volume arbeitet. Und ein separater "Sidecar" -Container
aktualisiert die Daten von einer externen Datenquelle, siehe folgenden
Abbildung:</p><figure><img src=/images/docs/pod.svg alt=Pod-Beispieldiagramm width=50%></figure><p>Einige Pods haben sowohl <a class=glossary-tooltip title='One or more initialization containers that must run to completion before any app containers run.' data-toggle=tooltip data-placement=top href='/de/docs/reference/glossary/?all=true#term-init-container' target=_blank aria-label=Initialisierungs-Container>Initialisierungs-Container</a> als auch <a class=glossary-tooltip title='A container used to run part of a workload. Compare with init container.' data-toggle=tooltip data-placement=top href='/de/docs/reference/glossary/?all=true#term-app-container' target=_blank aria-label=Anwendungs-Container>Anwendungs-Container</a>.
Initialisierungs-Container werden gestartet und beendet bevor die
Anwendungs-Container gestartet werden.</p><p>Pods stellen standardmäßig zwei Arten von gemeinsam Ressourcen für die
enthaltenen Container bereit:
<a href=#pod-netzwerk>Netzwerk</a> und <a href=#datenspeicherung-in-pods>Speicher</a>.</p><h2 id=mit-pods-arbeiten>Mit Pods arbeiten</h2><p>Du wirst selten einzelne Pods direkt in Kubernetes erstellen, selbst
Singleton-Pods. Das liegt daran, dass Pods als relativ kurzlebige
Einweg-Einheiten konzipiert sind. Wenn ein Pod erstellt wird (entweder direkt
von Ihnen oder indirekt von einem
<a class=glossary-tooltip title='A control loop that watches the shared state of the cluster through the apiserver and makes changes attempting to move the current state towards the desired state.' data-toggle=tooltip data-placement=top href=/docs/concepts/architecture/controller/ target=_blank aria-label=Controller>Controller</a>), wird die
Ausführung auf einem <a class=glossary-tooltip title='A node is a worker machine in Kubernetes.' data-toggle=tooltip data-placement=top href=/docs/concepts/architecture/nodes/ target=_blank aria-label=Node>Node</a> in Ihrem Cluster
geplant. Der Pod bleibt auf diesem (virtuellen) Server, bis entweder der Pod die
Ausführung beendet hat, das Pod-Objekt gelöscht wird, der Pod aufgrund
mangelnder Ressourcen <em>evakuiert</em> wird oder der Node ausfällt.</p><div class="alert alert-info note callout" role=alert><strong>Hinweis:</strong> Das Neustarten eines Containers in einem Pod sollte nicht mit dem Neustarten
eines Pods verwechselt werden. Ein Pod ist kein Prozess, sondern eine Umgebung
zur Ausführung von Containern. Ein Pod bleibt bestehen bis er gelöscht wird.</div><p>Stelle beim Erstellen des Manifests für ein Pod-Objekt sicher, dass der
angegebene Name ein gültiger
<a href=/docs/concepts/overview/working-with-objects/names#dns-subdomain-names>DNS-Subdomain-Name</a>
ist.</p><h3 id=pods-und-controller>Pods und Controller</h3><p>Mit Workload-Ressourcen kannst du mehrere Pods erstellen und verwalten. Ein
Controller für die Ressource kümmert sich um Replikation, Roll-Out sowie
automatische Wiederherstellung im Fall von versagenden Pods. Wenn beispielsweise ein Node
ausfällt, bemerkt ein Controller, dass die Pods auf dem Node nicht mehr laufen
und plant die Ausführung eines Ersatzpods auf einem funktionierenden Node.
Hier sind einige Beispiele für Workload-Ressourcen, die einen oder mehrere Pods
verwalten:</p><ul><li><a class=glossary-tooltip title='Manages a replicated application on your cluster.' data-toggle=tooltip data-placement=top href=/docs/concepts/workloads/controllers/deployment/ target=_blank aria-label=Deployment>Deployment</a></li><li><a class=glossary-tooltip title='Manages deployment and scaling of a set of Pods, with durable storage and persistent identifiers for each Pod.' data-toggle=tooltip data-placement=top href=/docs/concepts/workloads/controllers/statefulset/ target=_blank aria-label=StatefulSet>StatefulSet</a></li><li><a class=glossary-tooltip title='Ensures a copy of a Pod is running across a set of nodes in a cluster.' data-toggle=tooltip data-placement=top href=/docs/concepts/workloads/controllers/daemonset target=_blank aria-label=DaemonSet>DaemonSet</a></li></ul><h3 id=pod-vorlagen>Pod-Vorlagen</h3><p>Controller für
<a class=glossary-tooltip title='A workload is an application running on Kubernetes.' data-toggle=tooltip data-placement=top href=/docs/concepts/workloads/ target=_blank aria-label=Workload>Workload</a>-Ressourcen
erstellen Pods von einer <em>Pod-Vorlage</em> und verwalten diese Pods für dich.</p><p>Pod-Vorlagen sind Spezifikationen zum Erstellen von Pods und sind in
Workload-Ressourcen enthalten wie z. B.
<a href=/docs/concepts/workloads/controllers/deployment/>Deployments</a>,
<a href=/docs/concepts/workloads/controllers/job/>Jobs</a>, and
<a href=/docs/concepts/workloads/controllers/daemonset/>DaemonSets</a>.</p><p>Jeder Controller für eine Workload-Ressource verwendet die Pod-Vorlage innerhalb
des Workload-Objektes, um Pods zu erzeugen. Die Pod-Vorlage ist Teil des
gewünschten Zustands der Workload-Ressource, mit der du deine Anwendung
ausgeführt hast.</p><p>Das folgende Beispiel ist ein Manifest für einen einfachen Job mit einer
<code>Vorlage</code>, die einen Container startet. Der Container in diesem Pod druckt
eine Nachricht und pausiert dann.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>batch/v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Job<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb> </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>hello<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb> </span><span style=color:green;font-weight:700>template</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb> </span><span style=color:#080;font-style:italic># Dies is the Pod-Vorlage</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb> </span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb> </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb> </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>hello<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb> </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>busybox<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb> </span><span style=color:green;font-weight:700>command</span>:<span style=color:#bbb> </span>[<span style=color:#b44>&#39;sh&#39;</span>,<span style=color:#bbb> </span><span style=color:#b44>&#39;-c&#39;</span>,<span style=color:#bbb> </span><span style=color:#b44>&#39;echo &#34;Hello, Kubernetes!&#34; &amp;&amp; sleep 3600&#39;</span>]<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb> </span><span style=color:green;font-weight:700>restartPolicy</span>:<span style=color:#bbb> </span>OnFailure<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb> </span><span style=color:#080;font-style:italic># Die Pod-Vorlage endet hier</span><span style=color:#bbb>
</span></span></span></code></pre></div><p>Das Ändern der Pod-Vorlage oder der Wechsel zu einer neuen Pod-Vorlage hat keine
direkten Auswirkungen auf bereits existierende Pods. Wenn du die Pod-Vorlage für
eine Workload-Ressource änderst, dann muss diese Ressource die Ersatz-Pods
erstellen, welche die aktualisierte Vorlage verwenden.</p><p>Beispielsweise stellt der StatefulSet-Controller sicher, dass für jedes
StatefulSet-Objekt die ausgeführten Pods mit der aktueller Pod-Vorlage
übereinstimmen. Wenn du das StatefulSet bearbeitest und die Vorlage änderst,
beginnt das StatefulSet mit der Erstellung neuer Pods basierend auf der
aktualisierten Vorlage. Schließlich werden alle alten Pods durch neue Pods
ersetzt, und das Update ist abgeschlossen.</p><p>Jede Workload-Ressource implementiert eigenen Regeln für die Umsetzung von
Änderungen der Pod-Vorlage. Wenn du mehr über StatefulSet erfahren möchtest,
dann lese die Seite
<a href=/docs/tutorials/stateful-application/basic-stateful-set/#updating-statefulsets>Update-Strategien</a>
im Tutorial StatefulSet Basics.</p><p>Auf Nodes beobachtet oder verwaltet das
<a class=glossary-tooltip title='Ein Agent, der auf jedem Node im Cluster ausgeführt wird. Er stellt sicher, dass Container in einem Pod ausgeführt werden.' data-toggle=tooltip data-placement=top href=/docs/reference/generated/kubelet target=_blank aria-label=Kubelet>Kubelet</a>
nicht direkt die Details zu Pod-Vorlagen und Updates. Diese Details sind
abstrahiert. Die Abstraktion und Trennung von Aufgaben vereinfacht die
Systemsemantik und ermöglicht so das Verhalten des Clusters zu ändern ohne
vorhandenen Code zu ändern.</p><h2 id=pod-update-und-austausch>Pod Update und Austausch</h2><p>Wie im vorherigen Abschnitt erwähnt, erstellt der Controller neue Pods basierend
auf der aktualisierten Vorlage, wenn die Pod-Vorlage für eine Workload-Ressource
geändert wird anstatt die vorhandenen Pods zu aktualisieren oder zu patchen.</p><p>Kubernetes hindert dich nicht daran, Pods direkt zu verwalten. Es ist möglich,
einige Felder eines laufenden Pods zu aktualisieren. Allerdings haben
Pod-Aktualisierungsvorgänge wie zum Beispiel
<a href=/docs/reference/generated/kubernetes-api/v1.25/#patch-pod-v1-core><code>patch</code></a>,
und
<a href=/docs/reference/generated/kubernetes-api/v1.25/#replace-pod-v1-core><code>replace</code></a>
einige Einschränkungen:</p><ul><li><p>Die meisten Metadaten zu einem Pod können nicht verändert werden. Zum Beispiel kannst
du nicht die Felder <code>namespace</code>, <code>name</code>, <code>uid</code>, oder <code>creationTimestamp</code>
ändern. Das <code>generation</code>-Feld muss eindeutig sein. Es werden nur Aktualisierungen
akzeptiert, die den Wert des Feldes inkrementieren.</p></li><li><p>Wenn das Feld <code>metadata.deletionTimestamp</code> gesetzt ist, kann kein neuer
Eintrag zur Liste <code>metadata.finalizers</code> hinzugefügt werden.</p></li><li><p>Pod-Updates dürfen keine Felder ändern, die Ausnahmen sind
<code>spec.containers[*].image</code>,
<code>spec.initContainers[*].image</code>, <code>spec.activeDeadlineSeconds</code> oder
<code>spec.tolerations</code>. Für <code>spec.tolerations</code> kannnst du nur neue Einträge
hinzufügen.</p></li><li><p>Für <code>spec.activeDeadlineSeconds</code> sind nur zwei Änderungen erlaubt:</p><ol><li>ungesetztes Feld in eine positive Zahl</li><li>positive Zahl in eine kleinere positive Zahl, die nicht negativ ist</li></ol></li></ul><h2 id=gemeinsame-nutzung-von-ressourcen-und-kommunikation>Gemeinsame Nutzung von Ressourcen und Kommunikation</h2><p>Pods ermöglichen den Datenaustausch und die Kommunikation zwischen den
Containern, die im Pod enthalten sind.</p><h3 id=datenspeicherung-in-pods>Datenspeicherung in Pods</h3><p>Ein Pod kann eine Reihe von gemeinsam genutzten Speicher-
<a class=glossary-tooltip title='A directory containing data, accessible to the containers in a pod.' data-toggle=tooltip data-placement=top href=/docs/concepts/storage/volumes/ target=_blank aria-label=Volumes>Volumes</a> spezifizieren. Alle
Container im Pod können auf die gemeinsamen Volumes zugreifen und dadurch Daten
austauschen. Volumes ermöglichen auch, dass Daten ohne Verlust gespeichert
werden, falls einer der Container neu gestartet werden muss.
Im Kapitel <a href=/docs/concepts/storage/>Datenspeicherung</a> findest du weitere
Informationen, wie Kubernetes gemeinsam genutzten Speicher implementiert und
Pods zur Verfügung stellt.</p><h3 id=pod-netzwerk>Pod-Netzwerk</h3><p>Jedem Pod wird für jede Adressenfamilie eine eindeutige IP-Adresse zugewiesen.
Jeder Container in einem Pod nutzt den gemeinsamen Netzwerk-Namespace,
einschließlich der IP-Adresse und der Ports. In einem Pod (und <strong>nur</strong> dann)
können die Container, die zum Pod gehören, über <code>localhost</code> miteinander
kommunizieren. Wenn Container in einem Pod mit Entitäten <em>außerhalb des Pods</em>
kommunizieren, müssen sie koordinieren, wie die gemeinsam genutzten
Netzwerkressourcen (z. B. Ports) verwenden werden. Innerhalb eines Pods teilen
sich Container eine IP-Adresse und eine Reihe von Ports und können sich
gegenseitig über <code>localhost</code> finden. Die Container in einem Pod können auch die
üblichen Kommunikationsverfahren zwischen Prozessen nutzen, wie z. B.
SystemV-Semaphoren oder "POSIX Shared Memory". Container in verschiedenen Pods
haben unterschiedliche IP-Adressen und können nicht per IPC ohne
<a href=/docs/concepts/policy/pod-security-policy/>spezielle Konfiguration</a>
kommunizieren. Container, die mit einem Container in einem anderen Pod
interagieren möchten, müssen IP Netzwerke verwenden.</p><p>Für die Container innerhalb eines Pods stimmt der "hostname" mit dem
konfigurierten <code>Namen</code> des Pods überein. Mehr dazu im Kapitel
<a href=/docs/concepts/cluster-administration/networking/>Netzwerke</a>.</p><h2 id=privilegierter-modus-für-container>Privilegierter Modus für Container</h2><p>Jeder Container in einem Pod kann den privilegierten Modus aktivieren, indem
das Flag <code>privileged</code> im
<a href=/docs/tasks/configure-pod-container/security-context/>Sicherheitskontext</a>
der Container-Spezifikation verwendet wird.
Dies ist nützlich für Container, die Verwaltungsfunktionen des Betriebssystems
verwenden möchten, z. B. das Manipulieren des Netzwerk-Stacks oder den Zugriff
auf Hardware. Prozesse innerhalb eines privilegierten Containers erhalten fast
die gleichen Rechte wie sie Prozessen außerhalb eines Containers zur Verfügung
stehen.</p><div class="alert alert-info note callout" role=alert><strong>Hinweis:</strong> Ihre
<a class=glossary-tooltip title='The container runtime is the software that is responsible for running containers.' data-toggle=tooltip data-placement=top href=/docs/setup/production-environment/container-runtimes target=_blank aria-label=Container-Umgebung>Container-Umgebung</a>
muss das Konzept eines privilegierten Containers unterstützen, damit diese
Einstellung relevant ist.</div><h2 id=statische-pods>Statische Pods</h2><p><em>Statische Pods</em> werden direkt vom Kubelet-Daemon auf einem bestimmten Node
verwaltet ohne dass sie vom
<a class=glossary-tooltip title='Komponente auf dem Master, der die Kubernetes-API verfügbar macht. Es ist das Frontend für die Kubernetes-Steuerebene.' data-toggle=tooltip data-placement=top href=/docs/reference/generated/kube-apiserver/ target=_blank aria-label='API Server'>API Server</a> überwacht
werden.</p><p>Die meisten Pods werden von der Kontrollebene verwaltet (z. B.
<a class=glossary-tooltip title='Manages a replicated application on your cluster.' data-toggle=tooltip data-placement=top href=/docs/concepts/workloads/controllers/deployment/ target=_blank aria-label=Deployment>Deployment</a>). Aber für
statische Pods überwacht das Kubelet jeden statischen Pod direkt (und startet
ihn neu, wenn er ausfällt).</p><p>Statische Pods sind immer an ein <a class=glossary-tooltip title='Ein Agent, der auf jedem Node im Cluster ausgeführt wird. Er stellt sicher, dass Container in einem Pod ausgeführt werden.' data-toggle=tooltip data-placement=top href=/docs/reference/generated/kubelet target=_blank aria-label=Kubelet>Kubelet</a> auf
einem bestimmten Node gebunden. Der Hauptanwendungsfall für statische Pods
besteht darin, eine selbst gehostete Steuerebene auszuführen. Mit anderen
Worten: Das Kubelet dient zur Überwachung der einzelnen
<a href=/docs/concepts/overview/components/#control-plane-components>Komponenten der Kontrollebene</a>.</p><p>Das Kubelet versucht automatisch auf dem Kubernetes API-Server für jeden
statischen Pod einen spiegelbildlichen Pod
(im Englischen: <a class=glossary-tooltip title='An object in the API server that tracks a static pod on a kubelet.' data-toggle=tooltip data-placement=top href='/de/docs/reference/glossary/?all=true#term-mirror-pod' target=_blank aria-label='mirror pod'>mirror pod</a>)
zu erstellen.
Das bedeutet, dass die auf einem Node ausgeführten Pods auf dem API-Server
sichtbar sind jedoch von dort nicht gesteuert werden können.</p><h2 id=nächste-schritte>Nächste Schritte</h2><ul><li>Verstehe den
<a href=/docs/concepts/workloads/pods/pod-lifecycle/>Lebenszyklus eines Pods</a>.</li><li>Erfahre mehr über <a href=/docs/concepts/containers/runtime-class/>RuntimeClass</a>
und wie du damit verschiedene Pods mit unterschiedlichen
Container-Laufzeitumgebungen konfigurieren kannst.</li><li>Mehr zum Thema
<a href=/docs/concepts/workloads/pods/pod-topology-spread-constraints/>Restriktionen für die Verteilung von Pods</a>.</li><li>Lese
<a href=/docs/concepts/workloads/pods/disruptions/>Pod-Disruption-Budget</a>
und wie du es verwenden kannst, um die Verfügbarkeit von Anwendungen bei
Störungen zu verwalten. Die
<a href=/docs/reference/generated/kubernetes-api/v1.25/#pod-v1-core>Pod</a>
-Objektdefinition beschreibt das Objekt im Detail.</li><li><a href=https://kubernetes.io/blog/2015/06/the-distributed-system-toolkit-patterns>The Distributed System Toolkit: Patterns for Composite Containers</a>
erläutert allgemeine Layouts für Pods mit mehr als einem Container.</li></ul><p>Um den Hintergrund zu verstehen, warum Kubernetes eine gemeinsame Pod-API in
andere Ressourcen, wie z. B.
<a class=glossary-tooltip title='Manages deployment and scaling of a set of Pods, with durable storage and persistent identifiers for each Pod.' data-toggle=tooltip data-placement=top href=/docs/concepts/workloads/controllers/statefulset/ target=_blank aria-label=StatefulSets>StatefulSets</a>
oder <a class=glossary-tooltip title='Manages a replicated application on your cluster.' data-toggle=tooltip data-placement=top href=/docs/concepts/workloads/controllers/deployment/ target=_blank aria-label=Deployments>Deployments</a> einbindet,
kannst du Artikel zu früheren Technologien lesen, unter anderem:</p><ul><li><a href=https://aurora.apache.org/documentation/latest/reference/configuration/#job-schema>Aurora</a></li><li><a href=https://research.google.com/pubs/pub43438.html>Borg</a></li><li><a href=https://mesosphere.github.io/marathon/docs/rest-api.html>Marathon</a></li><li><a href=https://research.google/pubs/pub41684/>Omega</a></li><li><a href=https://engineering.fb.com/data-center-engineering/tupperware/>Tupperware</a>.</li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-0a0a7eca3e302a3c08f8c85e15d337fd>3.5 - Dienste, Lastverteilung und Netzwerkfunktionen</h1></div><div class=td-content style=page-break-before:always><h1 id=pg-f018f568c6723865753f150c3c59bdda>3.6 - Speicher</h1></div><div class=td-content style=page-break-before:always><h1 id=pg-275bea454e1cf4c5adeca4058b5af988>3.7 - Konfiguration</h1></div><div class=td-content style=page-break-before:always><h1 id=pg-ac9161c6d952925b083ad9602b4e8e7f>3.8 - Richtlinien</h1></div><div class=td-content style=page-break-before:always><h1 id=pg-285a3785fd3d20f437c28d87ca4dadca>3.9 - Cluster Administration</h1></div><div class=td-content><h1 id=pg-08e94e6a480e0d6b2de72d84a1b97617>3.9.1 - Proxies in Kubernetes</h1><p>Auf dieser Seite werden die im Kubernetes verwendeten Proxies erläutert.</p><h2 id=proxies>Proxies</h2><p>Es gibt mehrere verschiedene Proxies, die die bei der Verwendung von Kubernetes begegnen können:</p><ol><li><p>Der <a href=/docs/tasks/access-application-cluster/access-cluster/#directly-accessing-the-rest-api>kubectl Proxy</a>:</p><ul><li>läuft auf dem Desktop eines Benutzers oder in einem Pod</li><li>Proxy von einer lokalen Host-Adresse zum Kubernetes API Server</li><li>Client zu Proxy verwendet HTTP</li><li>Proxy zu API Server verwendet HTTPS</li><li>lokalisiert den API Server</li><li>fügt Authentifizierungs-Header hinzu</li></ul></li><li><p>Der <a href=/docs/tasks/access-application-cluster/access-cluster-services/#discovering-builtin-services>API Server Proxy</a>:</p><ul><li>ist eine Bastion, die in den API Server eingebaut ist</li><li>verbindet einen Benutzer außerhalb des Clusters mit Cluster IPs, die sonst möglicherweise nicht erreichbar wären</li><li>läuft im API Server Prozess</li><li>Client zu Proxy verwendet HTTPS (oder http, wenn API Server so konfiguriert ist)</li><li>Proxy zum Ziel kann HTTP oder HTTPS verwenden, der Proxy wählt dies unter Verwendung der verfügbaren Informationen aus</li><li>kann verwendet werden, um einen Knoten, Pod oder Service zu erreichen</li><li>führt einen Lastausgleich durch um einen Service zu erreichen, wenn dieser verwendet wird</li></ul></li><li><p>Der <a href=/docs/concepts/services-networking/service/#ips-and-vips>kube Proxy</a>:</p><ul><li>läuft auf jedem Knoten</li><li>Proxy unterstüzt UDP, TCP und SCTP</li><li>versteht kein HTTP</li><li>stellt Lastausgleich zur Verfügung</li><li>wird nur zum erreichen von Services verwendet</li></ul></li><li><p>Ein Proxy/Load-balancer vor dem API Server:</p><ul><li>Existenz und Implementierung variieren von Cluster zu Cluster (z.B. nginx)</li><li>sitzt zwischen allen Clients und einem oder mehreren API Servern</li><li>fungiert als Load Balancer, wenn es mehrere API Server gibt</li></ul></li><li><p>Cloud Load Balancer für externe Services:</p><ul><li>wird von einigen Cloud Anbietern angeboten (z.B. AWS ELB, Google Cloud Load Balancer)</li><li>werden automatisch erstellt, wenn der Kubernetes Service den Typ <code>LoadBalancer</code> hat</li><li>unterstützt normalerweiße nur UDP/TCP</li><li>Die SCTP-Unterstützung hängt von der Load Balancer Implementierung des Cloud Providers ab</li><li>die Implementierung variiert je nach Cloud Anbieter</li></ul></li></ol><p>Kubernetes Benutzer müssen sich in der Regel um nichts anderes als die ersten beiden Typen kümmern. Der Cluster Administrator stellt in der Regel sicher, dass die letztgenannten Typen korrekt eingerichtet sind.</p><h2 id=anforderung-an-umleitungen>Anforderung an Umleitungen</h2><p>Proxies haben die Möglichkeit der Umleitung (redirect) ersetzt. Umleitungen sind veraltet.</p></div><div class=td-content style=page-break-before:always><h1 id=pg-d5cc46b61677b53f61a407d20bdd0830>3.9.2 - Controller Manager Metriken</h1><p>Controller Manager Metriken liefern wichtige Erkenntnisse über die Leistung und den Zustand von den Controller Managern.</p><h2 id=was-sind-controller-manager-metriken>Was sind Controller Manager Metriken</h2><p>Die Kennzahlen des Controller Managers liefert wichtige Erkenntnisse über die Leistung und den Zustand des Controller Managers.
Diese Metriken beinhalten gängige Go Language Laufzeitmetriken wie go_routine count und controller-spezifische Metriken wie z.B.
etcd Request Latenzen oder Cloud Provider (AWS, GCE, OpenStack) API Latenzen, die verwendet werden können um den Zustand eines Clusters zu messen.</p><p>Ab Kubernetes 1.7 stehen detaillierte Cloud Provider Metriken für den Speicherbetrieb für GCE, AWS, Vsphere und OpenStack zur Verfügung.
Diese Metriken können verwendet werden, um den Zustand persistenter Datenträgeroperationen zu überwachen.</p><p>Für GCE werden diese Metriken beispielsweise wie folgt aufgerufen:</p><pre tabindex=0><code>cloudprovider_gce_api_request_duration_seconds { request = &#34;instance_list&#34;}
cloudprovider_gce_api_request_duration_seconds { request = &#34;disk_insert&#34;}
cloudprovider_gce_api_request_duration_seconds { request = &#34;disk_delete&#34;}
cloudprovider_gce_api_request_duration_seconds { request = &#34;attach_disk&#34;}
cloudprovider_gce_api_request_duration_seconds { request = &#34;detach_disk&#34;}
cloudprovider_gce_api_request_duration_seconds { request = &#34;list_disk&#34;}
</code></pre><h2 id=konfiguration>Konfiguration</h2><p>In einem Cluster sind die Controller Manager Metriken unter <code>http://localhost:10252/metrics</code> auf dem Host verfügbar, auf dem der Controller Manager läuft.</p><p>Die Metriken werden im <a href=https://prometheus.io/docs/instrumenting/exposition_formats/>Prometheus Format</a> ausgegeben.</p><p>In einer Produktionsumgebung können Sie Prometheus oder einen anderen Metrik Scraper konfigurieren, um diese Metriken regelmäßig zu sammeln und in einer Art Zeitreihen Datenbank verfügbar zu machen.</p></div><div class=td-content style=page-break-before:always><h1 id=pg-85d633ae590aa20ec024f1b7af1d74fc>3.9.3 - Addons Installieren</h1><p>Add-Ons erweitern die Funktionalität von Kubernetes.</p><p>Diese Seite gibt eine Übersicht über einige verfügbare Add-Ons und verweist auf die entsprechenden Installationsanleitungen.</p><p>Die Add-Ons in den einzelnen Kategorien sind alphabetisch sortiert - Die Reihenfolge impliziert keine bevorzugung einzelner Projekte.</p><h2 id=networking-und-network-policy>Networking und Network Policy</h2><ul><li><a href=https://www.github.com/noironetworks/aci-containers>ACI</a> bietet Container-Networking und Network-Security mit Cisco ACI.</li><li><a href=https://docs.projectcalico.org/latest/introduction/>Calico</a> ist ein Networking- und Network-Policy-Provider. Calico unterstützt eine Reihe von Networking-Optionen, damit Du die richtige für deinen Use-Case wählen kannst. Dies beinhaltet Non-Overlaying and Overlaying-Networks mit oder ohne BGP. Calico nutzt die gleiche Engine um Network-Policies für Hosts, Pods und (falls Du Istio & Envoy benutzt) Anwendungen auf Service-Mesh-Ebene durchzusetzen.</li><li><a href=https://projectcalico.docs.tigera.io/getting-started/kubernetes/flannel/flannel>Canal</a> vereint Flannel und Calico um Networking- und Network-Policies bereitzustellen.</li><li><a href=https://github.com/cilium/cilium>Cilium</a> ist ein L3 Network- and Network-Policy-Plugin welches das transparent HTTP/API/L7-Policies durchsetzen kann. Sowohl Routing- als auch Overlay/Encapsulation-Modes werden uterstützt. Außerdem kann Cilium auf andere CNI-Plugins aufsetzen.</li><li><a href=https://github.com/cni-genie/CNI-Genie>CNI-Genie</a> ermöglicht das nahtlose Verbinden von Kubernetes mit einer Reihe an CNI-Plugins wie z.B. Calico, Canal, Flannel, Romana, oder Weave.</li><li><a href=https://contivpp.io/>Contiv</a> bietet konfigurierbares Networking (Native L3 auf BGP, Overlay mit vxlan, Klassisches L2, Cisco-SDN/ACI) für verschiedene Anwendungszwecke und auch umfangreiches Policy-Framework. Das Contiv-Projekt ist vollständig <a href=http://github.com/contiv>Open Source</a>. Der <a href=http://github.com/contiv/install>installer</a> bietet sowohl kubeadm als auch nicht-kubeadm basierte Installationen.</li><li><a href=http://www.juniper.net/us/en/products-services/sdn/contrail/contrail-networking/>Contrail</a>, basierend auf <a href=https://tungsten.io>Tungsten Fabric</a>, ist eine Open Source, multi-Cloud Netzwerkvirtualisierungs- und Policy-Management Plattform. Contrail und Tungsten Fabric sind mit Orechstratoren wie z.B. Kubernetes, OpenShift, OpenStack und Mesos integriert und bieten Isolationsmodi für Virtuelle Maschinen, Container (bzw. Pods) und Bare Metal workloads.</li><li><a href=https://github.com/flannel-io/flannel#deploying-flannel-manually>Flannel</a> ist ein Overlay-Network-Provider der mit Kubernetes genutzt werden kann.</li><li><a href=https://github.com/ZTE/Knitter/>Knitter</a> ist eine Network-Lösung die Mehrfach-Network in Kubernetes ermöglicht.</li><li><a href=https://github.com/k8snetworkplumbingwg/multus-cni>Multus</a> ist ein Multi-Plugin für Mehrfachnetzwerk-Unterstützung um alle CNI-Plugins (z.B. Calico, Cilium, Contiv, Flannel), zusätzlich zu SRIOV-, DPDK-, OVS-DPDK- und VPP-Basierten Workloads in Kubernetes zu unterstützen.</li><li><a href=https://docs.vmware.com/en/VMware-NSX-T-Data-Center/index.html>NSX-T</a> Container Plug-in (NCP) bietet eine Integration zwischen VMware NSX-T und einem Orchestator wie z.B. Kubernetes. Außerdem bietet es eine Integration zwischen NSX-T und Containerbasierten CaaS/PaaS-Plattformen wie z.B. Pivotal Container Service (PKS) und OpenShift.</li><li><a href=https://github.com/nuagenetworks/nuage-kubernetes/blob/v5.1.1-1/docs/kubernetes-1-installation.rst>Nuage</a> ist eine SDN-Plattform die Policy-Basiertes Networking zwischen Kubernetes Pods und nicht-Kubernetes Umgebungen inklusive Sichtbarkeit und Security-Monitoring bereitstellt.</li><li><a href=https://github.com/romana/romana>Romana</a> ist eine Layer 3 Network-Lösung für Pod-Netzwerke welche auch die <a href=/docs/concepts/services-networking/network-policies/>NetworkPolicy API</a> unterstützt. Details zur Installation als kubeadm Add-On sind <a href=https://github.com/romana/romana/tree/master/containerize>hier</a> verfügbar.</li><li><a href=https://www.weave.works/docs/net/latest/kube-addon/>Weave Net</a> bietet Networking and Network-Policies und arbeitet auf beiden Seiten der Network-Partition ohne auf eine externe Datenbank angwiesen zu sein.</li></ul><h2 id=service-discovery>Service-Discovery</h2><ul><li><a href=https://coredns.io>CoreDNS</a> ist ein flexibler, erweiterbarer DNS-Server der in einem Cluster <a href=https://github.com/coredns/deployment/tree/master/kubernetes>installiert</a> werden kann und das Cluster-interne DNS für Pods bereitzustellen.</li></ul><h2 id=visualisierung-amp-überwachung>Visualisierung & Überwachung</h2><ul><li><a href=https://github.com/kubernetes/dashboard#kubernetes-dashboard>Dashboard</a> ist ein Dashboard Web Interface für Kubernetes.</li><li><a href=https://www.weave.works/documentation/scope-latest-installing/#k8s>Weave Scope</a> ist ein Tool um Container, Pods, Services usw. Grafisch zu visualieren. Kann in Verbindung mit einem <a href=https://cloud.weave.works/>Weave Cloud Account</a> genutzt oder selbst gehosted werden.</li></ul><h2 id=infrastruktur>Infrastruktur</h2><ul><li><a href=https://kubevirt.io/user-guide/docs/latest/administration/intro.html#cluster-side-add-on-deployment>KubeVirt</a> ist ein Add-On um Virtuelle Maschinen in Kubernetes auszuführen. Wird typischer auf Bare-Metal Clustern eingesetzt.</li></ul><h2 id=legacy-add-ons>Legacy Add-Ons</h2><p>Es gibt einige weitere Add-Ons die in dem abgekündigten <a href=https://git.k8s.io/kubernetes/cluster/addons>cluster/addons</a>-Verzeichnis dokumentiert sind.</p><p>Add-Ons die ordentlich gewartet werden dürfen gerne hier aufgezählt werden. Wir freuen uns auf PRs!</p></div><div class=td-content style=page-break-before:always><h1 id=pg-7e0d97616b15e2c383c6a0a96ec442cb>3.10 - Kubernetes erweitern</h1></div><div class=td-content style=page-break-before:always><h1 id=pg-4c31edff4063c7b31c556b3eb1405c65>3.11 - Konzept Dokumentations-Vorlage</h1><div class="alert alert-info note callout" role=alert><strong>Hinweis:</strong> Stellen Sie auch sicher <a href=/docs/home/contribute/write-new-topic/#creating-an-entry-in-the-table-of-contents>einen Eintrag im Inhaltsverzeichnis</a> für Ihr neues Dokument zu erstellen.</div><p>Diese Seite erklärt ...</p><h2 id=verstehen>Verstehen ...</h2><p>Kubernetes bietet ...</p><h2 id=verwenden>Verwenden ...</h2><p>Benutzen Sie ...</p><h2 id=nächste-schritte>Nächste Schritte</h2><p><strong>[Optionaler Bereich]</strong></p><ul><li>Lernen Sie mehr über <a href=/docs/home/contribute/write-new-topic/>ein neues Thema schreiben</a>.</li><li>Besuchen Sie <a href=/docs/home/contribute/page-templates/#concept_template>Seitenvorlagen verwenden - Konzeptvorlage</a> wie Sie diese Vorlage verwenden.</li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-f8918f697450c2009b75913f9e9317a5>4 - Aufgaben</h1><nav id=TableOfContents><ul><li><a href=#webbenutzeroberfläche-dashboard>Webbenutzeroberfläche (Dashboard)</a></li><li><a href=#die-kubectl-befehlszeile-verwenden>Die kubectl-Befehlszeile verwenden</a></li><li><a href=#pods-und-container-konfigurieren>Pods und Container konfigurieren</a></li><li><a href=#anwendungen-ausführen>Anwendungen ausführen</a></li><li><a href=#jobs-ausführen>Jobs ausführen</a></li><li><a href=#auf-anwendungen-in-einem-cluster-zugreifen>Auf Anwendungen in einem Cluster zugreifen</a></li><li><a href=#überwachung-protokollierung-und-fehlerbehebung>Überwachung, Protokollierung und Fehlerbehebung</a></li><li><a href=#zugriff-auf-die-kubernetes-api>Zugriff auf die Kubernetes-API</a></li><li><a href=#tls-verwenden>TLS verwenden</a></li><li><a href=#cluster-verwalten>Cluster verwalten</a></li><li><a href=#föderation-verwalten>Föderation verwalten</a></li><li><a href=#managing-stateful-applications>Managing Stateful Applications</a></li><li><a href=#cluster-dämonen>Cluster-Dämonen</a></li><li><a href=#gpus-verwalten>GPUs verwalten</a></li><li><a href=#verwalten-von-hugepages>Verwalten von HugePages</a></li><li><a href=#nächste-schritte>Nächste Schritte</a></li></ul></nav><p>Dieser Abschnitt der Kubernetes-Dokumentation enthält Seiten, die zeigen, wie man einzelne Aufgaben erledigt.
Eine Aufgabenseite zeigt, wie man eine einzelne Aufgabe ausführt, typischerweise durch eine kurze Abfolge von Schritten.</p><h2 id=webbenutzeroberfläche-dashboard>Webbenutzeroberfläche (Dashboard)</h2><p>Stellen Sie die Dashboard-Webbenutzeroberfläche bereit, und greifen Sie auf sie zu, um Sie bei der Verwaltung und Überwachung von Containeranwendungen in einem Kubernetes-Cluster zu unterstützen.</p><h2 id=die-kubectl-befehlszeile-verwenden>Die kubectl-Befehlszeile verwenden</h2><p>Installieren und konfigurieren Sie das <code>kubectl</code>-Befehlszeilentool, mit dem Kubernetes-Cluster direkt verwaltet werden.</p><h2 id=pods-und-container-konfigurieren>Pods und Container konfigurieren</h2><p>Ausführen allgemeiner Konfigurationsaufgaben für Pods und Container.</p><h2 id=anwendungen-ausführen>Anwendungen ausführen</h2><p>Ausführen allgemeiner Aufgaben zur Anwendungsverwaltung, z. B. Aktualisierungen, Einfügen von Informationen in Pods und automatisches horizontales Skalieren der Pods.</p><h2 id=jobs-ausführen>Jobs ausführen</h2><p>Jobs mit Parallelverarbeitung ausführen.</p><h2 id=auf-anwendungen-in-einem-cluster-zugreifen>Auf Anwendungen in einem Cluster zugreifen</h2><p>Konfigurieren Sie den Lastausgleich, die Portweiterleitung oder die Einrichtung von Firewall- oder DNS-Konfigurationen für den Zugriff auf Anwendungen in einem Cluster.</p><h2 id=überwachung-protokollierung-und-fehlerbehebung>Überwachung, Protokollierung und Fehlerbehebung</h2><p>Richten Sie die Überwachung und Protokollierung ein, um einen Cluster zu behandeln oder eine Container-Anwendung zu debuggen.</p><h2 id=zugriff-auf-die-kubernetes-api>Zugriff auf die Kubernetes-API</h2><p>Lernen Sie verschiedene Methoden kennen, um direkt auf die Kubernetes-API zuzugreifen.</p><h2 id=tls-verwenden>TLS verwenden</h2><p>Konfigurieren Sie Ihre Anwendung so, dass sie der Cluster-Stammzertifizierungsstelle (Certificate Authority, CA) vertraut und diese verwendet.</p><h2 id=cluster-verwalten>Cluster verwalten</h2><p>Erfahren Sie allgemeine Aufgaben zum Verwalten eines Clusters.</p><h2 id=föderation-verwalten>Föderation verwalten</h2><p>Konfigurieren Sie Komponenten in einer Clusterföderation.</p><h2 id=managing-stateful-applications>Managing Stateful Applications</h2><p>Ausführen allgemeiner Aufgaben zum Verwalten von Stateful-Anwendungen, einschließlich Skalieren, Löschen und Debuggen von StatefulSets.</p><h2 id=cluster-dämonen>Cluster-Dämonen</h2><p>Ausführen allgemeiner Aufgaben zum Verwalten eines DaemonSet, z. B. Durchführen eines fortlaufenden Updates.</p><h2 id=gpus-verwalten>GPUs verwalten</h2><p>Konfigurieren und planen Sie NVIDIA-GPUs für die Verwendung durch Nodes in einem Cluster als Ressource.</p><h2 id=verwalten-von-hugepages>Verwalten von HugePages</h2><p>Konfigurieren und verwalten Sie <code>HugePages</code> als planbare Ressource in einem Cluster.</p><h2 id=nächste-schritte>Nächste Schritte</h2><p>Wenn Sie eine Aufgabenseite schreiben möchten, finden Sie weitere Informationen unter <a href=/docs/home/contribute/create-pull-request/>Erstellen einer Pull-Anfrage für Dokumentation</a>.</p></div><div class=td-content style=page-break-before:always><h1 id=pg-57bf66f59d9a642b82eebeabbc66470b>4.1 - Werkzeuge installieren</h1></div><div class=td-content><h1 id=pg-bbdc530b292ab4074d1dfe69feafb3e7>4.1.1 - Installieren und konfigurieren von kubectl</h1><p>Verwenden Sie das Kubernetes Befehlszeilenprogramm, <a href=/docs/user-guide/kubectl/>kubectl</a>, um Anwendungen auf Kubernetes bereitzustellen und zu verwalten.
Mit kubectl können Sie Clusterressourcen überprüfen, Komponenten erstellen, löschen und aktualisieren; Ihren neuen Cluster betrachten; und Beispielanwendungen aufrufen.</p><h2 id=bevor-sie-beginnen>Bevor Sie beginnen</h2><p>Sie müssen eine kubectl-Version verwenden, die innerhalb eines geringfügigen Versionsunterschieds zur Version Ihres Clusters liegt. Ein v1.2-Client sollte beispielsweise mit einem v1.1, v1.2 und v1.3-Master arbeiten. Die Verwendung der neuesten Version von kubectl verhindert unvorhergesehene Probleme.</p><h2 id=kubectl-installieren>Kubectl installieren</h2><p>Nachfolgend finden Sie einige Methoden zur Installation von kubectl.</p><h2 id=installieren-der-kubectl-anwendung-mithilfe-der-systemeigenen-paketverwaltung>Installieren der kubectl Anwendung mithilfe der systemeigenen Paketverwaltung</h2><ul class="nav nav-tabs" id=kubectl-install role=tablist><li class=nav-item><a data-toggle=tab class="nav-link active" href=#kubectl-install-0 role=tab aria-controls=kubectl-install-0 aria-selected=true>Ubuntu, Debian oder HypriotOS</a></li><li class=nav-item><a data-toggle=tab class=nav-link href=#kubectl-install-1 role=tab aria-controls=kubectl-install-1>CentOS, RHEL oder Fedora</a></li></ul><div class=tab-content id=kubectl-install><div id=kubectl-install-0 class="tab-pane show active" role=tabpanel aria-labelledby=kubectl-install-0><p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>
</span></span><span style=display:flex><span>sudo apt-get update <span style=color:#666>&amp;&amp;</span> sudo apt-get install -y apt-transport-https
</span></span><span style=display:flex><span>curl -s https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key add -
</span></span><span style=display:flex><span><span style=color:#a2f>echo</span> <span style=color:#b44>&#34;deb https://apt.kubernetes.io/ kubernetes-xenial main&#34;</span> | sudo tee -a /etc/apt/sources.list.d/kubernetes.list
</span></span><span style=display:flex><span>sudo apt-get update
</span></span><span style=display:flex><span>sudo apt-get install -y kubectl
</span></span></code></pre></div></div><div id=kubectl-install-1 class=tab-pane role=tabpanel aria-labelledby=kubectl-install-1><p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>cat <span style=color:#b44>&lt;&lt;EOF &gt; /etc/yum.repos.d/kubernetes.repo
</span></span></span><span style=display:flex><span><span style=color:#b44>[kubernetes]
</span></span></span><span style=display:flex><span><span style=color:#b44>name=Kubernetes
</span></span></span><span style=display:flex><span><span style=color:#b44>baseurl=https://packages.cloud.google.com/yum/repos/kubernetes-el7-x86_64
</span></span></span><span style=display:flex><span><span style=color:#b44>enabled=1
</span></span></span><span style=display:flex><span><span style=color:#b44>gpgcheck=1
</span></span></span><span style=display:flex><span><span style=color:#b44>repo_gpgcheck=1
</span></span></span><span style=display:flex><span><span style=color:#b44>gpgkey=https://packages.cloud.google.com/yum/doc/rpm-package-key.gpg
</span></span></span><span style=display:flex><span><span style=color:#b44>EOF</span>
</span></span><span style=display:flex><span>yum install -y kubectl
</span></span></code></pre></div></div></div><h2 id=installation-mit-snap-auf-ubuntu>Installation mit snap auf Ubuntu</h2><p>Wenn Sie Ubuntu oder eine der anderen Linux-Distributionen verwenden, die den <a href=https://snapcraft.io/docs/core/install>snap</a> Paketmanager unterstützen, können Sie kubectl als <a href=https://snapcraft.io/>snap</a>-Anwendung installieren.</p><ol><li><p>Wechseln Sie zum Snap-Benutzer und führen Sie den Installationsbefehl aus:</p><pre tabindex=0><code>sudo snap install kubectl --classic
</code></pre></li><li><p>Testen Sie, ob die installierte Version ausreichend aktuell ist:</p><pre tabindex=0><code>kubectl version
</code></pre></li></ol><h2 id=installation-mit-homebrew-auf-macos>Installation mit Homebrew auf macOS</h2><p>Wenn Sie mit macOS arbeiten und den <a href=https://brew.sh/>Homebrew</a> Paketmanager verwenden, können Sie kubectl mit Homebrew installieren.</p><ol><li><p>Führen Sie den Installationsbefehl aus:</p><pre tabindex=0><code>brew install kubernetes-cli
</code></pre></li><li><p>Testen Sie, ob die installierte Version ausreichend aktuell ist:</p><pre tabindex=0><code>kubectl version
</code></pre></li></ol><h2 id=installation-mit-macports-auf-macos>Installation mit Macports auf macOS</h2><p>Wenn Sie mit macOS arbeiten und den <a href=https://macports.org/>Macports</a> Paketmanager verwenden, können Sie kubectl mit Macports installieren.</p><ol><li><p>Führen Sie den Installationsbefehl aus:</p><pre tabindex=0><code>sudo port selfupdate
sudo port install kubectl
</code></pre></li><li><p>Testen Sie, ob die installierte Version ausreichend aktuell ist:</p><pre tabindex=0><code>kubectl version
</code></pre></li></ol><h2 id=installation-mit-powershell-von-psgallery>Installation mit PowerShell von PSGallery</h2><p>Wenn Sie mit Windows arbeiten und den <a href=https://www.powershellgallery.com/>Powershell Gallery</a> Paketmanager verwenden, können Sie kubectl mit Powershell installieren und aktualisieren.</p><ol><li><p>Führen Sie die Installationsbefehle aus (stellen Sie sicher, dass eine <code>DownloadLocation</code> angegeben wird):</p><pre tabindex=0><code>Install-Script -Name install-kubectl -Scope CurrentUser -Force
install-kubectl.ps1 [-DownloadLocation &lt;path&gt;]
</code></pre><div class="alert alert-info note callout" role=alert><strong>Hinweis:</strong> Wenn Sie keine <code>DownloadLocation</code> angeben, wird <code>kubectl</code> im temporären Verzeichnis des Benutzers installiert.</div><p>Das Installationsprogramm erstellt <code>$HOME/.kube</code> und weist es an, eine Konfigurationsdatei zu erstellen</p></li><li><p>Testen Sie, ob die installierte Version ausreichend aktuell ist:</p><pre tabindex=0><code>kubectl version
</code></pre><div class="alert alert-info note callout" role=alert><strong>Hinweis:</strong> Die Aktualisierung der Installation erfolgt durch erneutes Ausführen der beiden in Schritt 1 aufgelisteten Befehle.</div></li></ol><h2 id=installation-auf-windows-mit-chocolatey-oder-scoop>Installation auf Windows mit Chocolatey oder scoop</h2><p>Um kubectl unter Windows zu installieren, können Sie entweder den Paketmanager <a href=https://chocolatey.org>Chocolatey</a> oder das Befehlszeilen-Installationsprogramm <a href=https://scoop.sh>scoop</a> verwenden.</p><p><ul class="nav nav-tabs" id=kubectl-win-install role=tablist><li class=nav-item><a data-toggle=tab class="nav-link active" href=#kubectl-win-install-0 role=tab aria-controls=kubectl-win-install-0 aria-selected=true>choco</a></li><li class=nav-item><a data-toggle=tab class=nav-link href=#kubectl-win-install-1 role=tab aria-controls=kubectl-win-install-1>scoop</a></li></ul><div class=tab-content id=kubectl-win-install><div id=kubectl-win-install-0 class="tab-pane show active" role=tabpanel aria-labelledby=kubectl-win-install-0><p><pre><code>choco install kubernetes-cli
</code></pre></div><div id=kubectl-win-install-1 class=tab-pane role=tabpanel aria-labelledby=kubectl-win-install-1><p><pre><code>scoop install kubectl
</code></pre></div></div>2. Testen Sie, ob die installierte Version ausreichend aktuell ist:</p><pre><code>```
kubectl version
```
</code></pre><ol start=3><li><p>Navigieren Sie zu Ihrem Heimatverzeichnis:</p><pre tabindex=0><code>cd %USERPROFILE%
</code></pre></li><li><p>Erstellen Sie das <code>.kube</code>-Verzeichnis:</p><pre tabindex=0><code>mkdir .kube
</code></pre></li><li><p>Wechseln Sie in das soeben erstellte <code>.kube</code>-Verzeichnis:</p><pre tabindex=0><code>cd .kube
</code></pre></li><li><p>Konfigurieren Sie kubectl für die Verwendung eines Remote-Kubernetes-Clusters:</p><pre tabindex=0><code>New-Item config -type file
</code></pre><div class="alert alert-info note callout" role=alert><strong>Hinweis:</strong> Bearbeiten Sie die Konfigurationsdatei mit einem Texteditor Ihrer Wahl, z.B. Notepad.</div></li></ol><h2 id=download-als-teil-des-google-cloud-sdk-herunter>Download als Teil des Google Cloud SDK herunter</h2><p>Sie können kubectl als Teil des Google Cloud SDK installieren.</p><ol><li><p>Installieren Sie das <a href=https://cloud.google.com/sdk/>Google Cloud SDK</a>.</p></li><li><p>Führen Sie den <code>kubectl</code>-Installationsbefehl aus:</p><pre tabindex=0><code>gcloud components install kubectl
</code></pre></li><li><p>Testen Sie, ob die installierte Version ausreichend aktuell ist:</p><pre tabindex=0><code>kubectl version
</code></pre></li></ol><h2 id=installation-der-kubectl-anwendung-mit-curl>Installation der kubectl Anwendung mit curl</h2><ul class="nav nav-tabs" id=kubectl-install-curl role=tablist><li class=nav-item><a data-toggle=tab class="nav-link active" href=#kubectl-install-curl-0 role=tab aria-controls=kubectl-install-curl-0 aria-selected=true>macOS</a></li><li class=nav-item><a data-toggle=tab class=nav-link href=#kubectl-install-curl-1 role=tab aria-controls=kubectl-install-curl-1>Linux</a></li><li class=nav-item><a data-toggle=tab class=nav-link href=#kubectl-install-curl-2 role=tab aria-controls=kubectl-install-curl-2>Windows</a></li></ul><div class=tab-content id=kubectl-install-curl><div id=kubectl-install-curl-0 class="tab-pane show active" role=tabpanel aria-labelledby=kubectl-install-curl-0><p><ol><li><p>Laden Sie die neueste Version herunter:</p><pre tabindex=0><code>curl -LO https://storage.googleapis.com/kubernetes-release/release/$(curl -s https://storage.googleapis.com/kubernetes-release/release/stable.txt)/bin/darwin/amd64/kubectl
</code></pre><p>Um eine bestimmte Version herunterzuladen, ersetzen Sie den Befehlsteil <code>$(curl -s https://storage.googleapis.com/kubernetes-release/release/stable.txt)</code> mit der jeweiligen Version.</p><p>Um beispielsweise die Version v1.25.0 auf macOS herunterzuladen, verwenden Sie den folgenden Befehl:</p><pre tabindex=0><code>curl -LO https://storage.googleapis.com/kubernetes-release/release/v1.25.0/bin/darwin/amd64/kubectl
</code></pre></li><li><p>Machen Sie die kubectl-Binärdatei ausführbar.</p><pre tabindex=0><code>chmod +x ./kubectl
</code></pre></li><li><p>Verschieben Sie die Binärdatei in Ihren PATH.</p><pre tabindex=0><code>sudo mv ./kubectl /usr/local/bin/kubectl
</code></pre></li></ol></div><div id=kubectl-install-curl-1 class=tab-pane role=tabpanel aria-labelledby=kubectl-install-curl-1><p><ol><li><p>Laden Sie die neueste Version mit dem Befehl herunter:</p><pre tabindex=0><code>curl -LO https://storage.googleapis.com/kubernetes-release/release/$(curl -s https://storage.googleapis.com/kubernetes-release/release/stable.txt)/bin/linux/amd64/kubectl
</code></pre><p>Um eine bestimmte Version herunterzuladen, ersetzen Sie den Befehlsteil <code>$(curl -s https://storage.googleapis.com/kubernetes-release/release/stable.txt)</code> mit der jeweiligen Version.</p><p>Um beispielsweise die Version v1.25.0 auf Linux herunterzuladen, verwenden Sie den folgenden Befehl:</p><pre tabindex=0><code>curl -LO https://storage.googleapis.com/kubernetes-release/release/v1.25.0/bin/linux/amd64/kubectl
</code></pre></li><li><p>Machen Sie die kubectl-Binärdatei ausführbar.</p><pre tabindex=0><code>chmod +x ./kubectl
</code></pre></li><li><p>Verschieben Sie die Binärdatei in Ihren PATH.</p><pre tabindex=0><code>sudo mv ./kubectl /usr/local/bin/kubectl
</code></pre></li></ol></div><div id=kubectl-install-curl-2 class=tab-pane role=tabpanel aria-labelledby=kubectl-install-curl-2><p><ol><li><p>Laden Sie das aktuellste Release v1.25.0 von <a href=https://storage.googleapis.com/kubernetes-release/release/v1.25.0/bin/windows/amd64/kubectl.exe>diesem link</a> herunter.</p><p>Oder, sofern Sie <code>curl</code> installiert haven, verwenden Sie den folgenden Befehl:</p><pre tabindex=0><code>curl -LO https://storage.googleapis.com/kubernetes-release/release/v1.25.0/bin/windows/amd64/kubectl.exe
</code></pre><p>Informationen zur aktuellen stabilen Version (z. B. für scripting) finden Sie unter <a href=https://storage.googleapis.com/kubernetes-release/release/stable.txt>https://storage.googleapis.com/kubernetes-release/release/stable.txt</a>.</p></li><li><p>Verschieben Sie die Binärdatei in Ihren PATH.</p></li></ol></div></div><h2 id=kubectl-konfigurieren>kubectl konfigurieren</h2><p>Damit kubectl einen Kubernetes-Cluster finden und darauf zugreifen kann, benötigt es eine <a href=/docs/tasks/access-application-cluster/configure-access-multiple-clusters/>kubeconfig Datei</a>. Diese wird automatisch erstellt, wenn Sie einen Cluster mit <a href=https://github.com/kubernetes/kubernetes/blob/master/cluster/kube-up.sh>kube-up.sh</a> erstellen oder einen Minikube-Cluster erfolgreich implementieren. Weitere Informationen zum Erstellen von Clustern finden Sie in den <a href=/docs/setup/>Anleitungen für die ersten Schritte</a>. Wenn Sie Zugriff auf einen Cluster benötigen, den Sie nicht erstellt haben, lesen Sie die <a href=/docs/tasks/access-application-cluster/configure-access-multiple-clusters/>Cluster-Zugriff freigeben Dokumentation</a>.
Die kubectl-Konfiguration befindet sich standardmäßig unter <code>~/.kube/config</code>.</p><h2 id=überprüfen-der-kubectl-konfiguration>Überprüfen der kubectl-Konfiguration</h2><p>Überprüfen Sie, ob kubectl ordnungsgemäß konfiguriert ist, indem Sie den Clusterstatus abrufen:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl cluster-info
</span></span></code></pre></div><p>Wenn Sie eine URL-Antwort sehen, ist kubectl korrekt für den Zugriff auf Ihren Cluster konfiguriert.</p><p>Wenn eine Meldung ähnlich der folgenden angezeigt wird, ist kubectl nicht richtig konfiguriert oder kann keine Verbindung zu einem Kubernetes-Cluster herstellen.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>The connection to the server &lt;server-name:port&gt; was refused - did you specify the right host or port?
</span></span></code></pre></div><p>Wenn Sie beispielsweise vorhaben, einen Kubernetes-Cluster auf Ihrem Laptop (lokal) auszuführen, müssen Sie zunächst ein Tool wie minikube installieren und anschließend die oben genannten Befehle erneut ausführen.</p><p>Wenn kubectl cluster-info die URL-Antwort zurückgibt, Sie jedoch nicht auf Ihren Cluster zugreifen können, verwenden Sie Folgendes, um zu überprüfen, ob er ordnungsgemäß konfiguriert ist:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl cluster-info dump
</span></span></code></pre></div><h2 id=aktivieren-der-automatischen-autovervollständigung-der-shell>Aktivieren der automatischen Autovervollständigung der Shell</h2><p>kubectl bietet Autocompletion-Unterstützung für Bash und Zsh, was Ihnen viel Tipparbeit erspart!</p><p>Im Folgenden werden die Verfahren zum Einrichten der automatischen Vervollständigung für Bash (einschließlich der Unterschiede zwischen Linux und macOS) und Zsh beschrieben.</p><ul class="nav nav-tabs" id=kubectl-autocompletion role=tablist><li class=nav-item><a data-toggle=tab class="nav-link active" href=#kubectl-autocompletion-0 role=tab aria-controls=kubectl-autocompletion-0 aria-selected=true>Bash on Linux</a></li><li class=nav-item><a data-toggle=tab class=nav-link href=#kubectl-autocompletion-1 role=tab aria-controls=kubectl-autocompletion-1>Bash auf macOS</a></li><li class=nav-item><a data-toggle=tab class=nav-link href=#kubectl-autocompletion-2 role=tab aria-controls=kubectl-autocompletion-2>Zsh</a></li></ul><div class=tab-content id=kubectl-autocompletion><div id=kubectl-autocompletion-0 class="tab-pane show active" role=tabpanel aria-labelledby=kubectl-autocompletion-0><p><h3 id=einführung>Einführung</h3><p>Das kubectl-Vervollständigungsskript für Bash kann mit dem Befehl <code>kubectl completion bash</code> generiert werden. Durch das Sourcing des Vervollständigungsskripts in Ihrer Shell wird die automatische Vervollständigung von kubectl ermöglicht.</p><p>Das Fertigstellungsskript benötigt jedoch <a href=https://github.com/scop/bash-completion><strong>bash-completion</strong></a>. Dies bedeutet, dass Sie diese Software zuerst installieren müssen (Sie können testen, ob Sie bereits bash-completion installiert haben, indem Sie <code>type _init_completion</code> ausführen).</p><h3 id=installation-von-bash-completion>Installation von bash-completion</h3><p>bash-completion wird von vielen Paketmanagern bereitgestellt (siehe <a href=https://github.com/scop/bash-completion#installation>hier</a>). Sie können es mittels <code>apt-get install bash-completion</code> oder <code>yum install bash-completion</code>, usw.</p><p>Die obigen Befehle erstellen <code>/usr/share/bash-completion/bash_completion</code>,Dies ist das Hauptskript für die Bash-Vollendung. Abhängig von Ihrem Paketmanager müssen Sie diese Datei manuell in Ihre <code>~ / .bashrc</code>-Datei eingeben.</p><p>Um dies herauszufinden, laden Sie Ihre Shell erneut und führen Sie <code>type _init_completion</code> aus. Wenn der Befehl erfolgreich ist, ist bereits alles vorbereitet. Andernfalls fügen Sie der <code>~/.bashrc</code>-Datei Folgendes hinzu:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span><span style=color:#a2f>source</span> /usr/share/bash-completion/bash_completion
</span></span></code></pre></div><p>Laden Sie Ihre Shell erneut und vergewissern Sie sich, dass bash-completion korrekt installiert ist, indem Sie folgendes eingeben: <code>type _init_completion</code>.</p><h3 id=aktivieren-der-automatische-vervollständigung-von-kubectl>Aktivieren der automatische Vervollständigung von kubectl</h3><p>Sie müssen nun sicherstellen, dass das kubectl-Abschlussskript in allen Ihren Shell-Sitzungen verwendet wird. Es gibt zwei Möglichkeiten, dies zu tun:</p><ul><li><p>Fügen Sie das Vervollständigungsskript Ihrer <code>~ /.bashrc</code>-Datei hinzu:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span><span style=color:#a2f>echo</span> <span style=color:#b44>&#39;source &lt;(kubectl completion bash)&#39;</span> &gt;&gt;~/.bashrc
</span></span></code></pre></div></li><li><p>Fügen Sie das Vervollständigungsskript zum Verzeichnis <code>/etc/bash_completion.d</code> hinzu:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl completion bash &gt;/etc/bash_completion.d/kubectl
</span></span></code></pre></div></li></ul><div class="alert alert-info note callout" role=alert><strong>Hinweis:</strong> bash-completion bezieht alle Vervollständigungsskripte aus <code>/etc/bash_completion.d</code>.</div><p>Beide Ansätze sind gleichwertig. Nach dem erneuten Laden der Shell sollte kubectl autocompletion funktionieren.</p></div><div id=kubectl-autocompletion-1 class=tab-pane role=tabpanel aria-labelledby=kubectl-autocompletion-1><p><div class="alert alert-danger warning callout" role=alert><strong>Warnung:</strong> macOS beinhaltet standardmäßig Bash 3.2. Das kubectl-Vervollständigunsskript erfordert Bash 4.1+ und funktioniert nicht mit Bash 3.2. Um dies zu umgehen, können Sie eine neuere Version von Bash unter macOS installieren (folgen Sie den Anweisungen <a href=https://itnext.io/upgrading-bash-on-macos-7138bd1066ba>hier</a>). Die folgenden Anweisungen funktionieren nur, wenn Sie Bash 4.1 oder höher verwenden.</div><h3 id=einführung>Einführung</h3><p>Das kubectl-Vervollständigungsskript für Bash kann mit dem Befehl <code>kubectl completion bash</code> generiert werden. Durch das Sourcing des Vervollständigungsskripts in Ihrer Shell wird die automatische Vervollständigung von kubectl ermöglicht.</p><p>Das Fertigstellungsskript benötigt jedoch <a href=https://github.com/scop/bash-completion><strong>bash-completion</strong></a>. Dies bedeutet, dass Sie diese Software zuerst installieren müssen (Sie können testen, ob Sie bereits bash-completion installiert haben, indem Sie <code>type _init_completion</code> ausführen).</p><h3 id=installation-von-bash-completion>Installation von bash-completion</h3><p>Sie können bash-completion mit Homebrew installieren:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>brew install bash-completion@2
</span></span></code></pre></div><div class="alert alert-info note callout" role=alert><strong>Hinweis:</strong> <code>@2</code> steht für bash-completion 2, was vom kubectl Vervollständigungsskript benötigt wird (es funktioniert nicht mit bash-completion 1). Für bash-completion 2 ist wiederum Bash 4.1 oder höher erforderlich. Deshalb mussten Sie Bash aktualisieren.</div><p>Wie in der Ausgabe von <code>brew install</code> (Abschnitt "Vorsichtsmaßnahmen") angegeben, fügen Sie Ihrer <code>~/.bashrc</code> oder <code>~/.bash_profile</code>-Datei die folgenden Zeilen hinzu:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span><span style=color:#a2f>export</span> <span style=color:#b8860b>BASH_COMPLETION_COMPAT_DIR</span><span style=color:#666>=</span>/usr/local/etc/bash_completion.d
</span></span><span style=display:flex><span><span style=color:#666>[[</span> -r /usr/local/etc/profile.d/bash_completion.sh <span style=color:#666>]]</span> <span style=color:#666>&amp;&amp;</span> . /usr/local/etc/profile.d/bash_completion.sh
</span></span></code></pre></div><p>Laden Sie Ihre Shell erneut und vergewissern Sie sich, dass bash-completion korrekt installiert ist, indem Sie <code>type _init_completion</code> eingeben.</p><h3 id=aktivieren-der-automatischen-vervollständigung-von-kubectl>Aktivieren der automatischen Vervollständigung von kubectl</h3><p>Sie müssen nun sicherstellen, dass das kubectl-Abschlussskript in allen Ihren Shell-Sitzungen verwendet wird. Es gibt mehrere Möglichkeiten, dies zu tun:</p><ul><li><p>Fügen Sie das Vervollständigungsskript Ihrer <code>~ /.bashrc</code>-Datei hinzu:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span><span style=color:#a2f>echo</span> <span style=color:#b44>&#39;source &lt;(kubectl completion bash)&#39;</span> &gt;&gt;~/.bashrc
</span></span></code></pre></div></li><li><p>Fügen Sie das Vervollständigungsskript zum Verzeichnis <code>/etc/bash_completion.d</code> hinzu:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl completion bash &gt;/usr/local/etc/bash_completion.d/kubectl
</span></span></code></pre></div></li><li><p>Wenn Sie kubectl mit Homebrew installiert haben (wie <a href=#install-with-homebrew-on-macos>hier</a> beschrieben), dann wurde das Vervollständigungsskript automatisch in <code>/usr/local/etc/bash_completion.d/kubectl</code> installiert. In diesem Fall müssen Sie nichts tun.</p></li></ul><div class="alert alert-info note callout" role=alert><strong>Hinweis:</strong> bash-completion (falls mit Homebrew installiert) bezieht alle Vervollständigungsskripte aus dem Verzeichnis, das in der Umgebungsvariablen <code>BASH_COMPLETION_COMPAT_DIR</code>festgelegt ist.</div><p>Alle Ansätze sind gleichwertig. Nach dem erneuten Laden der Shell sollte kubectl Autovervollständigung funktionieren.</p></div><div id=kubectl-autocompletion-2 class=tab-pane role=tabpanel aria-labelledby=kubectl-autocompletion-2><p><p>Das kubectl Vervollständigungsskript für Zsh kann mit dem folgenden Befehl generiert werden: <code>kubectl completion zsh</code>. Durch das Sourcing des Completion-Skripts in Ihrer Shell wird die automatische Vervollständigung von kubectl ermöglicht.</p><p>Fügen Sie Ihrer <code>~/.zshrc</code>-Datei dazu Folgendes hinzu:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span><span style=color:#a2f>source</span> &lt;<span style=color:#666>(</span>kubectl completion zsh<span style=color:#666>)</span>
</span></span></code></pre></div><p>Nach dem erneuten Laden der Shell sollte kubectl Autovervollständigung funktionieren.</p><p>Wenn eine Fehlermeldung wie <code>complete: 13: command not found: compdef</code> angezeigt wird, fügen Sie am Anfang der Datei `~/.zshrc" folgendes hinzu:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>autoload -Uz compinit
</span></span><span style=display:flex><span>compinit
</span></span></code></pre></div></div></div><h2 id=nächste-schritte>Nächste Schritte</h2><p><a href=/docs/tasks/access-application-cluster/service-access-application-cluster/>Erfahren Sie, wie Sie Ihre Anwendung starten und verfügbar machen.</a></p></div><div class=td-content style=page-break-before:always><h1 id=pg-2142bfe0834f1bf8f47887f85adba495>4.1.2 - Installation von Minikube</h1><p>Diese Seite zeigt Ihnen, wie Sie <a href=/docs/tutorials/hello-minikube>Minikube</a> installieren, ein Programm, das einen Kubernetes-Cluster mit einem einzigen Node in einer virtuellen Maschine auf Ihrem Laptop ausführt.</p><h2 id=bevor-sie-beginnen>Bevor Sie beginnen</h2><p>Die VT-x- oder AMD-v-Virtualisierung muss im BIOS Ihres Computers aktiviert sein. Um dies unter Linux zu überprüfen, führen Sie Folgendes aus und vergewissern Sie sich, dass die Ausgabe nicht leer ist:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>egrep --color <span style=color:#b44>&#39;vmx|svm&#39;</span> /proc/cpuinfo
</span></span></code></pre></div><h2 id=einen-hypervisor-installieren>Einen Hypervisor installieren</h2><p>Wenn noch kein Hypervisor installiert ist, installieren Sie jetzt einen für Ihr Betriebssystem:</p><table><thead><tr><th style=text-align:left>Betriebssystem</th><th style=text-align:left>Unterstützte Hypervisoren</th></tr></thead><tbody><tr><td style=text-align:left>macOS</td><td style=text-align:left><a href=https://www.virtualbox.org/wiki/Downloads>VirtualBox</a>, <a href=https://www.vmware.com/products/fusion>VMware Fusion</a>, <a href=https://github.com/moby/hyperkit>HyperKit</a></td></tr><tr><td style=text-align:left>Linux</td><td style=text-align:left><a href=https://www.virtualbox.org/wiki/Downloads>VirtualBox</a>, <a href=http://www.linux-kvm.org/>KVM</a></td></tr><tr><td style=text-align:left>Windows</td><td style=text-align:left><a href=https://www.virtualbox.org/wiki/Downloads>VirtualBox</a>, <a href=https://msdn.microsoft.com/en-us/virtualization/hyperv_on_windows/quick_start/walkthrough_install>Hyper-V</a></td></tr></tbody></table><div class="alert alert-info note callout" role=alert><strong>Hinweis:</strong> Minikube unterstützt auch die Option <code>--vm-driver=none</code>, mit der die Kubernetes-Komponenten auf dem Host und nicht in einer VM ausgeführt werden. Die Verwendung dieses Treibers erfordert Docker und eine Linux-Umgebung, jedoch keinen Hypervisor.</div><h2 id=kubectl-installieren>Kubectl installieren</h2><ul><li>Installieren Sie kubectl gemäß den Anweisungen in <a href=/docs/tasks/tools/install-kubectl/>kubectl installieren und einrichten</a>.</li></ul><h2 id=minikube-installieren>Minikube installieren</h2><h3 id=macos>macOS</h3><p>Die einfachste Möglichkeit, Minikube unter macOS zu installieren, ist die Verwendung von <a href=https://brew.sh>Homebrew</a>:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>brew install minikube
</span></span></code></pre></div><p>Sie können es auch auf macOS installieren, indem Sie eine statische Binärdatei herunterladen:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>curl -Lo minikube https://storage.googleapis.com/minikube/releases/latest/minikube-darwin-amd64 <span style=color:#b62;font-weight:700>\
</span></span></span><span style=display:flex><span><span style=color:#b62;font-weight:700></span>  <span style=color:#666>&amp;&amp;</span> chmod +x minikube
</span></span></code></pre></div><p>So fügen Sie die Minikube-Programmdatei auf einfache Weise Ihrem Pfad hinzu:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>sudo mv minikube /usr/local/bin
</span></span></code></pre></div><h3 id=linux>Linux</h3><div class="alert alert-info note callout" role=alert><strong>Hinweis:</strong> Dieses Dokument zeigt Ihnen, wie Sie Minikube mit einer statischen Binärdatei unter Linux installieren. Für alternative Linux-Installationsmethoden siehe <a href=https://minikube.sigs.k8s.io/docs/start/>Andere Installationsmethoden</a> im offiziellen Minikube-GitHub-Repository.</div><p>Sie können Minikube unter Linux installieren, indem Sie eine statische Binärdatei herunterladen:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>curl -Lo minikube https://storage.googleapis.com/minikube/releases/latest/minikube-linux-amd64 <span style=color:#b62;font-weight:700>\
</span></span></span><span style=display:flex><span><span style=color:#b62;font-weight:700></span>  <span style=color:#666>&amp;&amp;</span> chmod +x minikube
</span></span></code></pre></div><p>So fügen Sie die Minikube-Programmdatei auf einfache Weise Ihrem Pfad hinzu:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>sudo cp minikube /usr/local/bin <span style=color:#666>&amp;&amp;</span> rm minikube
</span></span></code></pre></div><h3 id=windows>Windows</h3><div class="alert alert-info note callout" role=alert><strong>Hinweis:</strong> Um Minikube unter Windows auszuführen, müssen Sie zuerst <a href=https://www.virtualbox.org/>VirtualBox</a> oder <a href=https://docs.microsoft.com/en-us/virtualization/hyper-v-on-windows/quick-start/enable-hyper-v>Hyper-V</a> installieren. Hyper-V kann auf drei Versionen von Windows 10 ausgeführt werden: Windows 10 Enterprise, Windows 10 Professional und Windows 10 Education. Weitere Informationen zur Installation finden Sie im offiziellen <a href=https://github.com/kubernetes/minikube/#installation>Minikube GitHub-Repository</a>.</div><p>Die einfachste Möglichkeit, Minikube unter Windows zu installieren, ist die Verwendung von <a href=https://chocolatey.org/>Chocolatey</a> (als Administrator ausführen):</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>choco install minikube kubernetes-cli
</span></span></code></pre></div><p>Schließen Sie nach der Installation von Minikube die aktuelle CLI-Sitzung und starten Sie sie neu. Minikube sollte automatisch zu Ihrem Pfad hinzugefügt werden.</p><h4 id=manuelle-installation-unter-windows>Manuelle installation unter Windows</h4><p>Um Minikube manuell unter Windows zu installieren, laden Sie die Datei <a href=https://github.com/kubernetes/minikube/releases/latest><code>minikube-windows-amd64</code></a> herunter, umbenennen Sie sie in <code>minikube.exe</code> und fügen Sie sie Ihrem Pfad zu.</p><h4 id=windows-installer>Windows Installer</h4><p>So installieren Sie Minikube manuell unter Windows mit <a href=https://docs.microsoft.com/en-us/windows/desktop/msi/windows-installer-portal>Windows Installer</a>, laden Sie die Datei <a href=https://github.com/kubernetes/minikube/releases/latest><code>minikube-installer.exe</code></a> und führen Sie den Installer aus.</p><h2 id=eine-bestehende-installation-bereinigen>Eine bestehende Installation bereinigen</h2><p>Wenn Sie minikube bereits installiert haben, starten Sie die Anwendung:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>minikube start
</span></span></code></pre></div><p>Und der Befehl gibt einen Fehler zurück:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>machine does not exist
</span></span></code></pre></div><p>Müssen Sie die Konfigurationsdateien löschen:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>rm -rf ~/.minikube
</span></span></code></pre></div><h2 id=nächste-schritte>Nächste Schritte</h2><ul><li><a href=/docs/setup/minikube/>Kubernetes lokal über Minikube ausführen</a></li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-34a810f1516ad9d99b2697e36e9b0d0f>4.2 - Einen Cluster verwalten</h1><div class=lead>Lerne allgemeine Aufgaben zur Verwaltung eines Clusters kennen.</div></div><div class=td-content><h1 id=pg-8e16d69617b175d61e2e7a6e1642c9d6>4.2.1 - Verwaltung mit kubeadm</h1></div><div class=td-content style=page-break-before:always><h1 id=pg-f5da33b976758a9183018c421eb83f58>4.3 - Pods und Container konfigurieren</h1></div><div class=td-content style=page-break-before:always><h1 id=pg-866924fa095f897ede8dfdcab9e97942>4.4 - Daten in Anwendungen injizieren</h1></div><div class=td-content style=page-break-before:always><h1 id=pg-a78a5e7e765fd8c49c8f7c0d72499f72>4.5 - Anwendungen ausführen</h1></div><div class=td-content><h1 id=pg-0c0bb1bd76d2a9069e50e2cec6d20c2a>4.5.1 - Horizontal Pod Autoscaler</h1><p>Der Horizontal Pod Autoscaler skaliert automatisch die Anzahl der Pods eines Replication Controller, Deployment oder Replikat Set basierend auf der beobachteten CPU-Auslastung (oder, mit Unterstützung von <a href=https://git.k8s.io/design-proposals-archive/instrumentation/custom-metrics-api.md>benutzerdefinierter Metriken</a>, von der Anwendung bereitgestellten Metriken). Beachte, dass die horizontale Pod Autoskalierung nicht für Objekte gilt, die nicht skaliert werden können, z. B. DaemonSets.</p><p>Der Horizontal Pod Autoscaler ist als Kubernetes API-Ressource und einem Controller implementiert.
Die Ressource bestimmt das Verhalten des Controllers.
Der Controller passt die Anzahl der Replikate eines Replication Controller oder Deployments regelmäßig an, um die beobachtete durchschnittliche CPU-Auslastung an das vom Benutzer angegebene Ziel anzupassen.</p><h2 id=wie-funktioniert-der-horizontal-pod-autoscaler>Wie funktioniert der Horizontal Pod Autoscaler?</h2><p><img src=/images/docs/horizontal-pod-autoscaler.svg alt="Horizontal Pod Autoscaler Diagramm"></p><p>Der Horizontal Pod Autoscaler ist als Kontrollschleife mit einer Laufzeit implementiert, die durch das Flag <code>--horizontal-pod-autoscaler-sync-period</code> am Controller Manager gesteuert wird (mit einem Standardwert von 15 Sekunden).</p><p>Während jedem Durchlauf fragt der Controller Manager die Ressourcennutzung anhand der in jeder HorizontalPodAutoscaler Definition angegebenen Metriken ab. Der Controller Manager bezieht die Metriken entweder aus der Resource Metrics API (für Ressourcenmetriken pro Pod) oder aus der Custom Metrics API (für alle anderen Metriken).</p><ul><li>Für jede pro Pod Ressourcenmetriken (wie CPU) ruft der Controller die Metriken über die Ressourcenmetriken API für jeden Pod ab, der vom HorizontalPodAutoscaler angesprochen wird. Sofern ein Zielnutzungswert eingestellt ist, berechnet der Controller den Nutzungswert als Prozentsatz der äquivalenten Ressourcenanforderung der Containern in jedem Pod. Wenn ein Ziel-Rohwert eingestellt ist, werden die Rohmetrikenwerte direkt verwendet. Der Controller nimmt dann den Mittelwert der Auslastung oder den Rohwert (je nach Art des angegebenen Ziels) über alle Zielpods und erzeugt ein Quotienten, mit dem die Anzahl der gewünschten Replikate skaliert wird.</li></ul><p>Beachte, dass, wenn einige der Container des Pods nicht über den entsprechenden Ressourcenanforderung verfügen, die CPU-Auslastung für den Pod nicht definiert wird und der Autoscaler keine Maßnahmen bezüglich dieser Metrik ergreift. Weitere Informationen zur Funktionsweise des Autoskalierungsalgorithmus finden Sie im folgenden Abschnitt über den <a href=#details-zum-algorithmus>Algorithmus</a>.</p><ul><li><p>Bei benutzerdefinierten Metriken pro Pod funktioniert die Steuerung ähnlich wie bei Ressourcenmetriken pro Pod, nur dass diese mit Rohwerten und nicht mit Nutzungswerten arbeitet.</p></li><li><p>Für Objektmetriken und externe Metriken wird eine einzelne Metrik abgerufen, die das jeweilige Objekt beschreibt. Diese Kennzahl wird mit dem Sollwert verglichen, um ein Verhältnis wie oben beschrieben zu erhalten. In der API-Version von <code>autoscaling/v2beta2</code> kann dieser Wert optional durch die Anzahl der Pods geteilt werden, bevor der Vergleich durchgeführt wird.</p></li></ul><p>Der HorizontalPodAutoscaler holt Metriken normalerweise aus einer Reihe von aggregierten APIs (<code>metrics.k8s.io</code>, <code>custom.metrics.k8s.io</code> und <code>external.metrics.k8s.io</code>). Die API <code>metrics.k8s.io</code> wird normalerweise vom Metrics Server bereitgestellt, der separat gestartet werden muss. Siehe <a href=/docs/tasks/debug-application-cluster/resource-metrics-pipeline/#metrics-server>Metrics Server</a> für weitere Anweisungen. Der HorizontalPodAutoscaler kann auch Metriken direkt aus dem Heapster beziehen.</p><div class="alert alert-info note callout" role=alert><strong>Hinweis:</strong><div style=margin-top:10px;margin-bottom:10px><b>FEATURE STATE:</b> <code>Kubernetes 1.11 [deprecated]</code></div><p>Das Verwenden von Metriken aus Heapster ist seit der Kubernetes Version 1.11 veraltet.</div><p>Siehe <a href=#unterst%C3%BCtzung-der-metrik-apis>Unterstützung der Metrik APIs</a> für weitere Details.</p><p>Der Autoscaler greift über die Scale Sub-Ressource auf die entsprechenden skalierbaren Controller (z.B. Replication Controller, Deployments und Replika Sets) zu. Scale ist eine Schnittstelle, mit der Sie die Anzahl der Replikate dynamisch einstellen und jeden ihrer aktuellen Zustände untersuchen können. Weitere Details zu der Scale Sub-Ressource findest du <a href=https://git.k8s.io/design-proposals-archive/autoscaling/horizontal-pod-autoscaler.md#scale-subresource>hier</a>.</p><h3 id=details-zum-algorithmus>Details zum Algorithmus</h3><p>Vereinfacht gesagt arbeitet der Horizontal Pod Autoscaler Controller mit dem Verhältnis zwischen dem gewünschten metrischen Wert und dem aktuellen metrischen Wert:</p><pre tabindex=0><code>desiredReplicas = ceil[currentReplicas * ( currentMetricValue / desiredMetricValue )]
</code></pre><p>Wenn beispielsweise der aktuelle metrische Wert <code>200m</code> und der gewünschte Wert <code>100m</code> ist, wird die Anzahl der Replikate verdoppelt, da <code>200.0 / 100.0 == 2.0</code> ist. Wenn der aktuelle Wert jedoch <code>50m</code> ist, halbieren sich die Anzahl der Replikate <code>50.0 / 100.0 == 0.5</code>. Es wird auf die Skalierung verzichtet, wenn das Verhältnis ausreichend nahe bei 1,0 liegt (innerhalb einer global konfigurierbaren Toleranz, vom Flag <code>--horizontal-pod-autoscaler-tolerance</code>, das standardmäßig auf 0,1 gesetzt ist).</p><p>Wenn ein <code>targetAverageValue</code> oder <code>targetAverageUtilization</code> angegeben wird, wird der <code>currentMetricValue</code> berechnet, indem der Mittelwert der gegebenen Metrik über alle Pods im Skalierungsziel des HorizontalPodAutoscaler berechnet wird. Vor der Überprüfung der Toleranz und der Entscheidung über die finalen Werte berücksichtigen wir jedoch die Pod Readiness und fehlende Metriken.</p><p>Alle Pods mit einem gesetzten Zeitstempel zur Löschung (d.h. Pods, die gerade heruntergefahren werden) und alle ausgefallenen Pods werden verworfen.</p><p>Wenn einem bestimmten Pod Metriken fehlen, wird es für später zurückgestellt; Pods mit fehlenden Metriken werden verwendet, um den endgültigen Skalierungsmenge anzupassen.</p><p>Wenn bei der Skalierung anhand der CPU ein Pod noch nicht bereit ist (d.h. er wird noch initialisiert) <em>oder</em> der letzte metrische Punkt für den Pod vor dessen Einsatzbereitschaft liegt, wird auch dieser Pod zurückgestellt.</p><p>Aufgrund technischer Einschränkungen kann der HorizontalPodAutoscaler Controller nicht genau bestimmen, wann ein Pod zum ersten Mal bereit ist, wenn es darum geht, bestimmte CPU Metriken festzulegen. Stattdessen betrachtet er eine Pod als "not yet ready", wenn dieser noch nicht bereit ist und geht in "unready" über, innerhalb eines kurzen, konfigurierbaren Zeitfensters seit dem Start.
Dieser Wert wird mit dem Flag <code>--horizontal-pod-autoscaler-initial-readiness-delay</code> konfiguriert und ist standardmäßig auf 30 Sekunden eingestellt. Sobald ein Pod bereit ist, betrachtet er jeden Übergang zu Bereit als den ersten, wenn dies innerhalb einer längeren, konfigurierbaren Zeit seit seinem Start erfolgt ist. Dieser Wert wird mit dem Flag <code>--horizontal-pod-autoscaler-cpu-initialization-period</code> gesetzt und dessen Standardwert beträgt 5 Minuten.</p><p>Das Basisskalenverhältnis <code>currentMetricValue / desiredMetricValue</code> wird dann mit den restlichen Pods berechnet, die nicht zurückgestellt oder von den oben genannten Kriterien entsorgt wurden.</p><p>Wenn es irgendwelche fehlenden Metriken gab, berechnen wir den Durchschnitt konservativer, vorausgesetzt, dass die Pods 100% des gewünschten Wertes bei der Verringerung und 0% bei einer Vergrößerung verbrauchten. Dadurch wird die Dimension einer beliebigen potenziellen Skalierung verringert.</p><p>Wenn außerdem noch nicht bereite Pods vorhanden sind und es ohne Berücksichtigung fehlender Metriken oder noch nicht bereiter Pods skaliert wurde, wird konservativ davon ausgegangen, dass die noch nicht bereiten Pods 0% der gewünschten Metrik verbrauchen, was die Dimension einer Skalierung weiter dämpft.</p><p>Nach Berücksichtigung der noch nicht bereiten Pods und fehlender Metriken wird der Nutzungsgrad neu berechnet. Wenn das neue Verhältnis die Skalierungsrichtung umkehrt oder innerhalb der Toleranz liegt, wird das weitere Skalieren übersprungen. Andernfalls wird das neue Verhältnis zur Skalierung verwendet.</p><p>Beachte, dass der <em>ursprüngliche</em> Wert für die durchschnittliche Auslastung über den HorizontalPodAutoscaler Status zurückgemeldet wird, ohne die noch nicht bereiten Pods oder fehlende Metriken zu berücksichtigen, selbst wenn das neue Nutzungsverhältnis verwendet wird.</p><p>Wenn mehrere Metriken in einem HorizontalPodAutoscaler angegeben sind, wird die Berechnung für jede Metrik durchgeführt, und dann wird die größte der gewünschten Replikanzahl ausgewählt. Wenn eine dieser Metriken nicht in eine gewünschte Replikanzahl umgewandelt werden kann (z.B. aufgrund eines Fehlers beim Abrufen der Metriken aus den Metrik APIs), wird diese Skalierung übersprungen.</p><p>Schließlich, kurz bevor HPA das Ziel skaliert, wird die Skalierungsempfehlung aufgezeichnet. Der Controller berücksichtigt alle Empfehlungen innerhalb eines konfigurierbaren Fensters und wählt aus diesem Fenster die höchste Empfehlung aus. Dieser Wert kann mit dem Flag <code>--horizontal-pod-autoscaler-downscale-stabilization</code> konfiguriert werden, das standardmäßig auf 5 Minuten eingestellt ist. Dies bedeutet, dass die Skalierung schrittweise erfolgt, wodurch die Auswirkungen schnell schwankender metrischer Werte ausgeglichen werden.</p><h2 id=api-objekt>API Objekt</h2><p>Der Horizontal Pod Autoscaler ist eine API Ressource in der Kubernetes <code>autoscaling</code> API Gruppe.
Die aktuelle stabile Version, die nur die Unterstützung für die automatische Skalierung der CPU beinhaltet, befindet sich in der <code>autoscaling/v1</code> API Version.</p><p>Die Beta-Version, welche die Skalierung des Speichers und benutzerdefinierte Metriken unterstützt, befindet sich unter <code>autoscaling/v2beta2</code>. Die in <code>autoscaling/v2beta2</code> neu eingeführten Felder bleiben bei der Arbeit mit <code>autoscaling/v1</code> als Anmerkungen erhalten.</p><p>Weitere Details über das API Objekt kann unter dem <a href=https://git.k8s.io/design-proposals-archive/autoscaling/horizontal-pod-autoscaler.md#horizontalpodautoscaler-object>HorizontalPodAutoscaler Objekt</a> gefunden werden.</p><h2 id=unterstützung-des-horizontal-pod-autoscaler-in-kubectl>Unterstützung des Horizontal Pod Autoscaler in kubectl</h2><p>Der Horizontal Pod Autoscaler wird, wie jede API-Ressource, standardmäßig von <code>kubectl</code> unterstützt.
Ein neuer Autoskalierer kann mit dem Befehl <code>kubectl create</code> erstellt werden.
Das auflisten der Autoskalierer geschieht über <code>kubectl get hpa</code> und eine detaillierte Beschreibung erhält man mit <code>kubectl describe hpa</code>.
Letzendlich können wir einen Autoskalierer mit <code>kubectl delete hpa</code> löschen.</p><p>Zusätzlich gibt es einen speziellen Befehl <code>kubectl autoscale</code> zur einfachen Erstellung eines Horizontal Pod Autoscalers.
Wenn du beispielsweise <code>kubectl autoscale rs foo --min=2 --max=5 --cpu-percent=80</code> ausführst, wird ein Autoskalierer für den ReplicaSet <em>foo</em> erstellt, wobei die Ziel-CPU-Auslastung auf <code>80%</code> und die Anzahl der Replikate zwischen 2 und 5 gesetzt wird.
Die Detaildokumentation von <code>kubectl autoscale</code> kann <a href=/docs/reference/generated/kubectl/kubectl-commands/#autoscale>hier</a> gefunden werden.</p><h2 id=autoskalieren-während-rollierender-updates>Autoskalieren während rollierender Updates</h2><p>Derzeit ist es in Kubernetes möglich, ein <a href=/docs/tasks/run-application/rolling-update-replication-controller/>rollierendes Update</a> durchzuführen, indem du den Replikationscontroller direkt verwaltest oder das Deployment Objekt verwendest, das die zugrunde liegenden Replica Sets für dich verwaltet.
Der Horizontal Pod Autoscaler unterstützt nur den letztgenannten Ansatz: Der Horizontal Pod Autoscaler ist an das Deployment Objekt gebunden, er legt die Größe für das Deployment Objekt fest, und das Deployment ist für die Festlegung der Größen der zugrunde liegenden Replica Sets verantwortlich.</p><p>Der Horizontal Pod Autoscaler funktioniert nicht mit rollierendem Update durch direkte Manipulation vom Replikationscontrollern, d.h. du kannst einen Horizontal Pod Autoscaler nicht an einen Replikationscontroller binden und rollierend aktualisieren (z.B. mit <code>kubectl rolling-update</code>).
Der Grund dafür ist, dass beim Erstellen eines neuen Replikationscontrollers durch ein rollierendes Update der Horizontal Pod Autoscaler nicht an den neue Replikationscontroller gebunden wird.</p><h2 id=unterstützung-von-abklingzeiten-verzögerungen>Unterstützung von Abklingzeiten/Verzögerungen</h2><p>Bei der Verwaltung der Größe einer Gruppe von Replikaten mit dem Horizontal Pod Autoscaler ist es möglich, dass die Anzahl der Replikate aufgrund der Dynamik der ausgewerteten Metriken häufig schwankt. Dies wird manchmal als <em>thrashing</em>, zu deutsch <em>Flattern</em>, bezeichnet.</p><p>Ab v1.6 kann ein Cluster Operator dieses Problem mitigieren, indem er die globalen HPA Einstellungen anpasst, die als Flags für die Komponente <code>kube-controller-manager</code> dargelegt werden:</p><p>Ab v1.12 erübrigt ein neues Update des Algorithmus die Notwendigkeit der Verzögerung beim hochskalieren.</p><ul><li><code>--horizontal-pod-autoscaler-downscale-stabilization</code>: Der Wert für diese Option ist eine Dauer, die angibt, wie lange der Autoscaler warten muss, bis nach Abschluss des aktuellen Skalierungsvorgangs ein weiterer Downscale durchgeführt werden kann.
Der Standardwert ist 5 Minuten (<code>5m0s</code>).</li></ul><div class="alert alert-info note callout" role=alert><strong>Hinweis:</strong> Beim Abstimmen dieser Parameterwerte sollte sich ein Clusterbetreiber der möglichen Konsequenzen bewusst sein. Wenn der Wert für die Verzögerung (Abklingzeit) zu groß eingestellt ist, kann es zu Beschwerden kommen, dass der Horizontal Pod Autoscaler nicht auf Änderungen der Arbeitslast reagiert. Wenn der Verzögerungswert jedoch zu kurz eingestellt ist, kann es vorkommen, dass die Skalierung der eingestellten Replikate wie gewohnt weiter flattert.</div><h2 id=unterstützung-von-mehrere-metriken>Unterstützung von mehrere Metriken</h2><p>Kubernetes 1.6 bietet Unterstützung für die Skalierung basierend auf mehreren Metriken. Du kannst die API Version <code>autoscaling/v2beta2</code> verwenden, um mehrere Metriken für den Horizontal Pod Autoscaler zum Skalieren festzulegen. Anschließend wertet der Horizontal Pod Autoscaler Controller jede Metrik aus und schlägt eine neue Skalierung basierend auf diesen Metrik vor. Die größte der vorgeschlagenen Skalierung wird als neue Skalierung verwendet.</p><h2 id=unterstützung-von-benutzerdefinierte-metriken>Unterstützung von benutzerdefinierte Metriken</h2><div class="alert alert-info note callout" role=alert><strong>Hinweis:</strong> Kubernetes 1.2 bietet Alpha Unterstützung für die Skalierung basierend auf anwendungsspezifischen Metriken über speziellen Annotations. Die Unterstützung für diese Annotations wurde in Kubernetes 1.6 zugunsten der neuen autoskalierenden API entfernt. Während die alte Methode zum Sammeln von benutzerdefinierten Metriken weiterhin verfügbar ist, stehen diese Metriken dem Horizontal Pod Autoscaler nicht mehr zur Verfügung, ebenso wenig wie die früheren Annotations zur Angabe, welche benutzerdefinierten Metriken zur Skalierung vom Horizontal Pod Autoscaler Controller berücksichtigt werden sollen.</div><p>Kubernetes 1.6 bietet Unterstützung für die Verwendung benutzerdefinierter Metriken im Horizontal Pod Autoscaler.
Du kannst benutzerdefinierte Metriken für den Horizontal Pod Autoscaler hinzufügen, die in der <code>autoscaling/v2beta2</code> API verwendet werden.
Kubernetes fragt dann die neue API für die benutzerdefinierte Metriken ab, um die Werte der entsprechenden benutzerdefinierten Metriken zu erhalten.</p><p>Die Voraussetzungen hierfür werden im nachfolgenden Kapitel <a href=#unterst%C3%BCtzung-der-metrik-apis>Unterstützung für die Metrik APIs</a> geklärt.</p><h2 id=unterstützung-der-metrik-apis>Unterstützung der Metrik APIs</h2><p>Standardmäßig ruft der HorizontalPodAutoscaler Controller Metriken aus einer Reihe von APIs ab. Damit dieser auf die APIs zugreifen kann, muss der Cluster Administratoren sicherstellen, dass:</p><ul><li><p>Der <a href=/docs/tasks/access-kubernetes-api/configure-aggregation-layer/>API Aggregations Layer</a> aktiviert ist.</p></li><li><p>Die entsprechenden APIs registriert sind:</p><ul><li><p>Für Ressourcenmetriken ist dies die API <code>metrics.k8s.io</code>, die im Allgemeinen von <a href=https://github.com/kubernetes-incubator/metrics-server>metrics-server</a> bereitgestellt wird.
Es kann als Cluster-Addon gestartet werden.</p></li><li><p>Für benutzerdefinierte Metriken ist dies die API <code>custom.metrics.k8s.io</code>. Diese wird vom "Adapter" API Servern bereitgestellt, welches von Anbietern von Metrik Lösungen beliefert wird.
Überprüfe dies mit deiner Metrik Pipeline oder der <a href=https://github.com/kubernetes/metrics/blob/master/IMPLEMENTATIONS.md#custom-metrics-api>Liste bekannter Lösungen</a>.
Falls du deinen eigenen schreiben möchtest hilft dir folgender <a href=https://github.com/kubernetes-incubator/custom-metrics-apiserver>boilerplate</a> um zu starten.</p></li><li><p>Für externe Metriken ist dies die <code>external.metrics.k8s.io</code> API. Es kann sein, dass dies durch den benutzerdefinierten Metrik Adapter bereitgestellt wird.</p></li></ul></li><li><p>Das Flag <code>--horizontal-pod-autoscaler-use-rest-clients</code> ist auf <code>true</code> oder ungesetzt. Wird dies auf <code>false</code> gesetzt wird die Heapster basierte Autoskalierung aktiviert, welche veraltet ist.</p></li></ul><h2 id=nächste-schritte>Nächste Schritte</h2><ul><li>Design Dokument <a href=https://git.k8s.io/design-proposals-archive/autoscaling/horizontal-pod-autoscaler.md>Horizontal Pod Autoscaling</a>.</li><li>kubectl autoscale Befehl: <a href=/docs/reference/generated/kubectl/kubectl-commands/#autoscale>kubectl autoscale</a>.</li><li>Verwenden des <a href=/docs/tasks/run-application/horizontal-pod-autoscale-walkthrough/>Horizontal Pod Autoscaler</a>.</li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-ca3bc4e31dfe46d5044a3b93eb804ee9>4.6 - Jobs ausführen</h1><div class=lead>Führen Sie Jobs mit paralleler Verarbeitung aus.</div></div><div class=td-content style=page-break-before:always><h1 id=pg-b74b959f5a531003dd0653dfbfc2e88b>4.7 - Auf Anwendungen in einem Cluster zugreifen</h1></div><div class=td-content style=page-break-before:always><h1 id=pg-f6a755efe831d24956501e4bcd49ff96>4.8 - Überwachung, Protokollierung und Fehlerbehebung</h1></div><div class=td-content style=page-break-before:always><h1 id=pg-fd78dc15c135dedc24438431769d4d5b>4.9 - Kubernetes erweitern</h1></div><div class=td-content style=page-break-before:always><h1 id=pg-d3c88a8663f58e9ec0bed73faff5b670>4.10 - TLS</h1></div><div class=td-content style=page-break-before:always><h1 id=pg-40e9293a348cfa50147082afc09ff77f>4.11 - Föderation</h1></div><div class=td-content style=page-break-before:always><h1 id=pg-ba58efa15c6d46f10e34d799be220965>4.12 - Cluster-Daemons verwalten</h1></div><div class=td-content style=page-break-before:always><h1 id=pg-5266308e17490aeee8b018316bf47e03>4.13 - Service Catalog installieren</h1></div><div class=td-content style=page-break-before:always><h1 id=pg-68ec2370d0409cc27325be36693f9368>5 - Tutorials</h1><p>Dieser Abschnitt der Kubernetes-Dokumentation enthält Tutorials.
Ein Tutorial zeigt, wie Sie ein Ziel erreichen, das größer ist als eine einzelne <a href=/docs/tasks/>Aufgabe</a>.
Ein Tutorial besteht normalerweise aus mehreren Abschnitten, die jeweils eine Abfolge von Schritten haben.
Bevor Sie die einzelnen Lernprogramme durchgehen, möchten Sie möglicherweise ein Lesezeichen zur Seite mit dem <a href=/docs/reference/glossary/>Standardisierten Glossar</a> setzen um später Informationen nachzuschlagen.</p><h2 id=grundlagen>Grundlagen</h2><ul><li><p><a href=/docs/tutorials/kubernetes-basics/>Kubernetes Basics</a> ist ein ausführliches interaktives Lernprogramm, das Ihnen hilft, das Kubernetes-System zu verstehen und einige grundlegende Kubernetes-Funktionen auszuprobieren.</p></li><li><p><a href=https://www.udacity.com/course/scalable-microservices-with-kubernetes--ud615>Scalable Microservices mit Kubernetes (Udacity)</a> (Englisch)</p></li><li><p><a href=https://www.edx.org/course/introduction-kubernetes-linuxfoundationx-lfs158x#>Einführung in Kubernetes (edX)</a> (Englisch)</p></li><li><p><a href=/docs/tutorials/hello-minikube/>Hello Minikube</a></p></li></ul><h2 id=konfiguration>Konfiguration</h2><ul><li><a href=/docs/tutorials/configuration/configure-redis-using-configmap/>Redis mit einer ConfigMap konfigurieren</a></li></ul><h2 id=stateless-anwendungen>Stateless Anwendungen</h2><ul><li><p><a href=/docs/tutorials/stateless-application/expose-external-ip-address/>Freigeben einer externen IP-Adresse für den Zugriff auf eine Anwendung in einem Cluster</a></p></li><li><p><a href=/docs/tutorials/stateless-application/guestbook/>Beispiel: Bereitstellung der PHP-Gästebuchanwendung mit Redis</a></p></li></ul><h2 id=stateful-anwendungen>Stateful Anwendungen</h2><ul><li><p><a href=/docs/tutorials/stateful-application/basic-stateful-set/>StatefulSet Grundlagen</a></p></li><li><p><a href=/docs/tutorials/stateful-application/mysql-wordpress-persistent-volume/>Beispiel: WordPress und MySQL mit persistenten Volumes</a></p></li><li><p><a href=/docs/tutorials/stateful-application/cassandra/>Beispiel: Bereitstellen von Cassandra mit Stateful-Sets</a></p></li><li><p><a href=/docs/tutorials/stateful-application/zookeeper/>ZooKeeper, ein verteiltes CP-System</a></p></li></ul><h2 id=clusters>Clusters</h2><ul><li><p><a href=/docs/tutorials/clusters/apparmor/>AppArmor</a></p></li><li><p><a href=/docs/tutorials/clusters/seccomp/>seccomp</a></p></li></ul><h2 id=services>Services</h2><ul><li><a href=/docs/tutorials/services/source-ip/>Source IP verwenden</a></li></ul><h2 id=nächste-schritte>Nächste Schritte</h2><p>Wenn Sie ein Tutorial schreiben möchten, lesen Sie
<a href=/docs/home/contribute/page-templates/>Seitenvorlagen verwenden</a>
für weitere Informationen zum Typ der Tutorial-Seite und zur Tutorial-Vorlage.</p></div><div class=td-content style=page-break-before:always><h1 id=pg-5e3051fff9e84735871d9fb5e7b93f33>5.1 - Hallo Minikube</h1><p>Dieses Tutorial zeigt Ihnen, wie Sie eine einfache "Hallo Welt" Node.js-Anwendung auf Kubernetes mit <a href=/docs/getting-started-guides/minikube>Minikube</a> und Katacoda ausführen.
Katacoda bietet eine kostenlose Kubernetes-Umgebung im Browser.</p><div class="alert alert-info note callout" role=alert><strong>Hinweis:</strong> Sie können dieses Tutorial auch verwenden, wenn Sie <a href=/docs/tasks/tools/install-minikube/>Minikube lokal</a> installiert haben.</div><h2 id=ziele>Ziele</h2><ul><li>Stellen Sie eine Hallo-Welt-Anwendung für Minikube bereit.</li><li>Führen Sie die App aus.</li><li>Betrachten Sie die Log Dateien.</li></ul><h2 id=bevor-sie-beginnen>Bevor Sie beginnen</h2><p>Dieses Lernprogramm enthält ein aus den folgenden Dateien erstelltes Container-Image:</p><div class=highlight><div class=copy-code-icon style=text-align:right><a href=https://raw.githubusercontent.com/kubernetes/website/main/content/de/examples/minikube/server.js download=minikube/server.js><code>minikube/server.js</code></a>
<img src=/images/copycode.svg style=max-height:24px;cursor:pointer onclick='copyCode("minikube-server-js")' title="Copy minikube/server.js to clipboard"></img></div><div class=includecode id=minikube-server-js><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-js data-lang=js><span style=display:flex><span><span style=color:#a2f;font-weight:700>var</span> http <span style=color:#666>=</span> require(<span style=color:#b44>&#39;http&#39;</span>);
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#a2f;font-weight:700>var</span> handleRequest <span style=color:#666>=</span> <span style=color:#a2f;font-weight:700>function</span>(request, response) {
</span></span><span style=display:flex><span>  console.log(<span style=color:#b44>&#39;Received request for URL: &#39;</span> <span style=color:#666>+</span> request.url);
</span></span><span style=display:flex><span>  response.writeHead(<span style=color:#666>200</span>);
</span></span><span style=display:flex><span>  response.end(<span style=color:#b44>&#39;Hello World!&#39;</span>);
</span></span><span style=display:flex><span>};
</span></span><span style=display:flex><span><span style=color:#a2f;font-weight:700>var</span> www <span style=color:#666>=</span> http.createServer(handleRequest);
</span></span><span style=display:flex><span>www.listen(<span style=color:#666>8080</span>);
</span></span></code></pre></div></div></div><div class=highlight><div class=copy-code-icon style=text-align:right><a href=https://raw.githubusercontent.com/kubernetes/website/main/content/de/examples/minikube/Dockerfile download=minikube/Dockerfile><code>minikube/Dockerfile</code></a>
<img src=/images/copycode.svg style=max-height:24px;cursor:pointer onclick='copyCode("minikube-dockerfile")' title="Copy minikube/Dockerfile to clipboard"></img></div><div class=includecode id=minikube-dockerfile><pre tabindex=0><code class=language-conf data-lang=conf>FROM node:6.14.2
EXPOSE 8080
COPY server.js .
CMD node server.js
</code></pre></div></div><p>Weitere Informationen zum <code>docker build</code> Befehl, lesen Sie die <a href=https://docs.docker.com/engine/reference/commandline/build/>Docker Dokumentation</a>.</p><h2 id=erstellen-sie-einen-minikube-cluster>Erstellen Sie einen Minikube-Cluster</h2><ol><li><p>Klicken Sie auf <strong>Launch Terminal</strong>.</p><script defer src=https://katacoda.com/embed.js></script>
<button class=button onclick=window.katacoda.init()>Launch Terminal</button><div class="alert alert-info note callout" role=alert><strong>Hinweis:</strong> Wenn Sie Minikube lokal installiert haben, führen Sie <code>minikube start</code> aus.</div></li><li><p>Öffnen Sie das Kubernetes-Dashboard in einem Browser:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>minikube dashboard
</span></span></code></pre></div></li><li><p>In einer Katacoda-Umgebung: Klicken Sie oben im Terminalbereich auf das Pluszeichen und anschließend auf <strong>Select port to view on Host 1</strong>.</p></li><li><p>In einer Katacoda-Umgebung: Geben Sie <code>30000</code> ein und klicken Sie dann auf <strong>Display Port</strong>.</p></li></ol><h2 id=erstellen-eines-deployments>Erstellen eines Deployments</h2><p>Ein Kubernetes <a href=/docs/concepts/workloads/pods/pod/><em>Pod</em></a> ist eine Gruppe von einem oder mehreren Containern, die zu Verwaltungs- und Netzwerkzwecken miteinander verbunden sind.
Der Pod in diesem Tutorial hat nur einen Container.
Ein Kubernetes <a href=/docs/concepts/workloads/controllers/deployment/><em>Deployment</em></a> überprüft den Zustand Ihres Pods und startet den Container des Pods erneut, wenn er beendet wird.
Deployments sind die empfohlene Methode zum Verwalten der Erstellung und Skalierung von Pods.</p><ol><li><p>Verwenden Sie den Befehl <code>kubectl create</code>, um ein Deployment zu erstellen, die einen Pod verwaltet.
Der Pod führt einen Container basierend auf dem bereitgestellten Docker-Image aus.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl create deployment hello-node --image<span style=color:#666>=</span>k8s.gcr.io/echoserver:1.4
</span></span></code></pre></div></li><li><p>Anzeigen des Deployments:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get deployments
</span></span></code></pre></div><p>Ausgabe:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>NAME         DESIRED   CURRENT   UP-TO-DATE   AVAILABLE   AGE
</span></span><span style=display:flex><span>hello-node   <span style=color:#666>1</span>         <span style=color:#666>1</span>         <span style=color:#666>1</span>            <span style=color:#666>1</span>           1m
</span></span></code></pre></div></li><li><p>Den Pod anzeigen:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get pods
</span></span></code></pre></div><p>Ausgabe:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>NAME                          READY     STATUS    RESTARTS   AGE
</span></span><span style=display:flex><span>hello-node-5f76cf6ccf-br9b5   1/1       Running   <span style=color:#666>0</span>          1m
</span></span></code></pre></div></li><li><p>Cluster Events anzeigen:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get events
</span></span></code></pre></div></li><li><p>Die Konfiguration von <code>kubectl</code> anzeigen:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl config view
</span></span></code></pre></div><div class="alert alert-info note callout" role=alert><strong>Hinweis:</strong> Weitere Informationen zu <code>kubectl</code>-Befehlen finden Sie im <a href=/docs/user-guide/kubectl-overview/>kubectl Überblick</a>.</div></li></ol><h2 id=erstellen-sie-einen-service>Erstellen Sie einen Service</h2><p>Standardmäßig ist der Pod nur über seine interne IP-Adresse im Kubernetes-Cluster erreichbar.
Um den "Hallo-Welt"-Container außerhalb des virtuellen Netzwerks von Kubernetes zugänglich zu machen, müssen Sie den Pod als Kubernetes <a href=/docs/concepts/services-networking/service/><em>Service</em></a> verfügbar machen.</p><ol><li><p>Stellen Sie den Pod mit dem Befehl <code>kubectl expose</code> im öffentlichen Internet bereit:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl expose deployment hello-node --type<span style=color:#666>=</span>LoadBalancer --port<span style=color:#666>=</span><span style=color:#666>8080</span>
</span></span></code></pre></div><p>Das Flag <code>--type = LoadBalancer</code> zeigt an, dass Sie Ihren Service außerhalb des Clusters verfügbar machen möchten.</p></li><li><p>Zeigen Sie den gerade erstellten Service an:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get services
</span></span></code></pre></div><p>Ausgabe:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>NAME         TYPE           CLUSTER-IP      EXTERNAL-IP   PORT<span style=color:#666>(</span>S<span style=color:#666>)</span>          AGE
</span></span><span style=display:flex><span>hello-node   LoadBalancer   10.108.144.78   &lt;pending&gt;     8080:30369/TCP   21s
</span></span><span style=display:flex><span>kubernetes   ClusterIP      10.96.0.1       &lt;none&gt;        443/TCP          23m
</span></span></code></pre></div><p>Bei Cloud-Anbietern, die Load-Balancer unterstützen, wird eine externe IP-Adresse für den Zugriff auf den Dienst bereitgestellt.
Bei Minikube ermöglicht der Typ <code>LoadBalancer</code> den Dienst über den Befehl <code>minikube service</code> verfügbar zu machen.</p></li><li><p>Führen Sie den folgenden Befehl aus:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>minikube service hello-node
</span></span></code></pre></div></li><li><p>In einer Katacoda-Umgebung: Klicken Sie auf das Pluszeichen und dann auf <strong>Select port to view on Host 1</strong>.</p></li><li><p>In einer Katacoda-Umgebung: Geben Sie "30369" ein (siehe Port gegenüber "8080" in der service ausgabe), und klicken Sie dann auf</p><p>Daraufhin wird ein Browserfenster geöffnet, in dem Ihre App ausgeführt wird und die Meldung "Hello World" (Hallo Welt) angezeigt wird.</p></li></ol><h2 id=addons-aktivieren>Addons aktivieren</h2><p>Minikube verfügt über eine Reihe von integrierten Add-Ons, die in der lokalen Kubernetes-Umgebung aktiviert, deaktiviert und geöffnet werden können.</p><ol><li><p>Listen Sie die aktuell unterstützten Addons auf:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>minikube addons list
</span></span></code></pre></div><p>Ausgabe:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>addon-manager: enabled
</span></span><span style=display:flex><span>coredns: disabled
</span></span><span style=display:flex><span>dashboard: enabled
</span></span><span style=display:flex><span>default-storageclass: enabled
</span></span><span style=display:flex><span>efk: disabled
</span></span><span style=display:flex><span>freshpod: disabled
</span></span><span style=display:flex><span>heapster: disabled
</span></span><span style=display:flex><span>ingress: disabled
</span></span><span style=display:flex><span>kube-dns: enabled
</span></span><span style=display:flex><span>metrics-server: disabled
</span></span><span style=display:flex><span>nvidia-driver-installer: disabled
</span></span><span style=display:flex><span>nvidia-gpu-device-plugin: disabled
</span></span><span style=display:flex><span>registry: disabled
</span></span><span style=display:flex><span>registry-creds: disabled
</span></span><span style=display:flex><span>storage-provisioner: enabled
</span></span></code></pre></div></li><li><p>Aktivieren Sie ein Addon, zum Beispiel <code>heapster</code>:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>minikube addons <span style=color:#a2f>enable</span> heapster
</span></span></code></pre></div><p>Ausgabe:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>heapster was successfully enabled
</span></span></code></pre></div></li><li><p>Sehen Sie sich den Pod und den Service an, den Sie gerade erstellt haben:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get pod,svc -n kube-system
</span></span></code></pre></div><p>Ausgabe:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>NAME                                        READY     STATUS    RESTARTS   AGE
</span></span><span style=display:flex><span>pod/heapster-9jttx                          1/1       Running   <span style=color:#666>0</span>          26s
</span></span><span style=display:flex><span>pod/influxdb-grafana-b29w8                  2/2       Running   <span style=color:#666>0</span>          26s
</span></span><span style=display:flex><span>pod/kube-addon-manager-minikube             1/1       Running   <span style=color:#666>0</span>          34m
</span></span><span style=display:flex><span>pod/kube-dns-6dcb57bcc8-gv7mw               3/3       Running   <span style=color:#666>0</span>          34m
</span></span><span style=display:flex><span>pod/kubernetes-dashboard-5498ccf677-cgspw   1/1       Running   <span style=color:#666>0</span>          34m
</span></span><span style=display:flex><span>pod/storage-provisioner                     1/1       Running   <span style=color:#666>0</span>          34m
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>NAME                           TYPE        CLUSTER-IP      EXTERNAL-IP   PORT<span style=color:#666>(</span>S<span style=color:#666>)</span>             AGE
</span></span><span style=display:flex><span>service/heapster               ClusterIP   10.96.241.45    &lt;none&gt;        80/TCP              26s
</span></span><span style=display:flex><span>service/kube-dns               ClusterIP   10.96.0.10      &lt;none&gt;        53/UDP,53/TCP       34m
</span></span><span style=display:flex><span>service/kubernetes-dashboard   NodePort    10.109.29.1     &lt;none&gt;        80:30000/TCP        34m
</span></span><span style=display:flex><span>service/monitoring-grafana     NodePort    10.99.24.54     &lt;none&gt;        80:30002/TCP        26s
</span></span><span style=display:flex><span>service/monitoring-influxdb    ClusterIP   10.111.169.94   &lt;none&gt;        8083/TCP,8086/TCP   26s
</span></span></code></pre></div></li><li><p>Deaktivieren Sie <code>heapster</code>:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>minikube addons disable heapster
</span></span></code></pre></div><p>Ausgabe:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>heapster was successfully disabled
</span></span></code></pre></div></li></ol><h2 id=aufräumen>Aufräumen</h2><p>Jetzt können Sie die in Ihrem Cluster erstellten Ressourcen bereinigen:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl delete service hello-node
</span></span><span style=display:flex><span>kubectl delete deployment hello-node
</span></span></code></pre></div><p>Stoppen Sie optional die virtuelle Minikube-Maschine (VM):</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>minikube stop
</span></span></code></pre></div><p>Löschen Sie optional die Minikube-VM:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>minikube delete
</span></span></code></pre></div><h2 id=nächste-schritte>Nächste Schritte</h2><ul><li>Lernen Sie mehr über <a href=/docs/concepts/workloads/controllers/deployment/>Bereitstellungsobjekte</a>.</li><li>Lernen Sie mehr über <a href=/docs/user-guide/deploying-applications/>Anwendungen bereitstellen</a>.</li><li>Lernen Sie mehr über <a href=/docs/concepts/services-networking/service/>Serviceobjekte</a>.</li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-3c83f53a74233ace9b289ac5e24c3e62>5.2 - Kubernetes Grundlagen lernen</h1><!doctype html><html lang=de><body><link href=/docs/tutorials/kubernetes-basics/public/css/styles.css rel=stylesheet><div class=layout id=top><main class=content><div class=row><div class=col-md-9><h2>Kubernetes Grundlagen</h2><p>Dieses Tutorial bietet einen Überblick über die Grundlagen des Kubernetes-Cluster-Orchestrierungssystems. Jedes Modul enthält einige Hintergrundinformationen zu den wichtigsten Funktionen und Konzepten von Kubernetes sowie ein interaktives Online-Lernprogramm. Mit diesen interaktiven Lernprogrammen können Sie einen einfachen Cluster und seine containerisierten Anwendungen selbst verwalten.</p><p>Mithilfe der interaktiven Tutorials können Sie Folgendes lernen:</p><ul><li>Eine containerisierte Anwendung in einem Cluster bereitstellen</li><li>Skalieren des Deployments</li><li>Aktualisieren der containerisierten Anwendung mit einer neuen Softwareversion</li><li>Debuggen der containerisierten Anwendung</li></ul><p>In den Lernprogrammen wird mit Katacoda ein virtuelles Terminal in Ihrem Webbrowser ausgeführt, in dem Minikube ausgeführt wird. Dies ist eine kleine lokale Bereitstellung von Kubernetes, die überall ausgeführt werden kann. Es muss keine Software installiert oder konfiguriert werden. Jedes interaktive Lernprogramm wird direkt von Ihrem Webbrowser aus ausgeführt.</p></div></div><br><div class=row><div class=col-md-9><h2>Was kann Kubernetes für Sie tun?</h2><p>Bei modernen Webservices erwarten Benutzer, dass Anwendungen rund um die Uhr verfügbar sind, und Entwickler erwarten, mehrmals täglich neue Versionen dieser Anwendungen bereitzustellen (deployen).
Containerisierung hilft bei der Paketierung von Software, um diese Ziele zu erreichen, sodass Anwendungen einfach und schnell ohne Ausfallzeiten veröffentlicht und aktualisiert werden können. Kubernetes hilft Ihnen dabei, sicherzustellen, dass diese Containeranwendungen immer dort laufen, wo und wann Sie möchten, und hilft Ihnen, die Ressourcen und Tools zu finden, die Sie zum Arbeiten benötigen. Kubernetes ist eine produktionsbereite Open-Source-Plattform, die auf der gesammelten Erfahrung von Google in der Container-Orchestrierung basiert und mit den besten Ideen der Community kombiniert wird.</p></div></div><div id=basics-modules class=content__modules><h2>Kubernetes Grundlagen Module</h2><div class=row><div class=col-md-12><div class=row><div class=col-md-4><div class=thumbnail><a href=/docs/tutorials/kubernetes-basics/create-cluster/cluster-intro/><img src="/docs/tutorials/kubernetes-basics/public/images/module_01.svg?v=1469803628347" alt></a><div class=caption><a href=/docs/tutorials/kubernetes-basics/create-cluster/cluster-intro/><h5>1. Erstellen Sie einen Kubernetes-Cluster</h5></a></div></div></div><div class=col-md-4><div class=thumbnail><a href=/docs/tutorials/kubernetes-basics/deploy-app/deploy-intro/><img src="/docs/tutorials/kubernetes-basics/public/images/module_02.svg?v=1469803628347" alt></a><div class=caption><a href=/docs/tutorials/kubernetes-basics/deploy-app/deploy-intro/><h5>2. Stellen Sie eine App bereit</h5></a></div></div></div><div class=col-md-4><div class=thumbnail><a href=/docs/tutorials/kubernetes-basics/explore/explore-intro/><img src="/docs/tutorials/kubernetes-basics/public/images/module_03.svg?v=1469803628347" alt></a><div class=caption><a href=/docs/tutorials/kubernetes-basics/explore/explore-intro/><h5>3. Erkunden Sie Ihre App</h5></a></div></div></div></div></div><div class=col-md-12><div class=row><div class=col-md-4><div class=thumbnail><a href=/docs/tutorials/kubernetes-basics/expose/expose-intro/><img src="/docs/tutorials/kubernetes-basics/public/images/module_04.svg?v=1469803628347" alt></a><div class=caption><a href=/docs/tutorials/kubernetes-basics/expose/expose-intro/><h5>4. Machen Sie Ihre App öffentlich zugänglich</h5></a></div></div></div><div class=col-md-4><div class=thumbnail><a href=/docs/tutorials/kubernetes-basics/scale/scale-intro/><img src="/docs/tutorials/kubernetes-basics/public/images/module_05.svg?v=1469803628347" alt></a><div class=caption><a href=/docs/tutorials/kubernetes-basics/scale/scale-intro/><h5>5. Skalieren Sie Ihre App</h5></a></div></div></div><div class=col-md-4><div class=thumbnail><a href=/docs/tutorials/kubernetes-basics/update/update-intro/><img src="/docs/tutorials/kubernetes-basics/public/images/module_06.svg?v=1469803628347" alt></a><div class=caption><a href=/docs/tutorials/kubernetes-basics/update/update-intro/><h5>6. Aktualisieren Sie Ihre App</h5></a></div></div></div></div></div></div></div><div class=row><div class=col-md-12><a class="btn btn-lg btn-success" href=/docs/tutorials/kubernetes-basics/create-cluster/cluster-intro/ role=button>Starten Sie das Tutorial<span class=btn__next>›</span></a></div></div></main></div></body></html></div><div class=td-content style=page-break-before:always><h1 id=pg-7df66040311338d6098ebeab43ba9afb>5.2.1 - Einen Cluster erstellen</h1></div><div class=td-content><h1 id=pg-de49316920e97a82e36763cb66781ada>5.2.1.1 - Minikube zum Erstellen eines Clusters verwenden</h1><!doctype html><html lang=de><body><link href=/docs/tutorials/kubernetes-basics/public/css/styles.css rel=stylesheet><div class=layout id=top><main class=content><div class=row><div class=col-md-8><h3>Ziele</h3><ul><li>Erfahren Sie, was ein Kubernetes-Cluster ist.</li><li>Erfahren Sie, was Minikube ist.</li><li>Starten Sie einen Kubernetes-Cluster mit einem Online-Terminal.</li></ul></div><div class=col-md-8><h3>Kubernetes Clusters</h3><p><b>Kubernetes koordiniert hochverfügbare Cluster von Computern, die miteinander verbunden sind, um als eine Einheit zu arbeiten.</b> Die Abstraktionen in Kubernetes ermöglichen es Ihnen, containerisierte Anwendungen in einem Cluster bereitzustellen, ohne sie spezifisch an einzelne Maschinen zu binden. Um dieses neue Bereitstellungsmodell nutzen zu können, müssen Anwendungen so gebündelt werden, dass sie von einzelnen Hosts entkoppelt werden: Sie müssen in Container verpackt werden. Containerisierte Anwendungen sind flexibler und verfügbarer als in früheren Bereitstellungsmodellen, bei denen Anwendungen direkt auf bestimmten Computern als tief in den Host integrierte Pakete installiert wurden. <b>Kubernetes automatisiert die Verteilung und Planung von Anwendungscontainern über einen Cluster hinweg auf effizientere Weise.</b> Kubernetes ist eine Open-Source-Plattform und produktionsreif.</p><p>Ein Kubernetes-Cluster besteht aus zwei Arten von Ressourcen:<ul><li>Der <b>Master</b> koordiniert den Cluster</li><li><b>Nodes sind die Arbeiter, die Anwendungen ausführen</li></ul></p></div><div class=col-md-4><div class="content__box content__box_lined"><h3>Zusammenfassung:</h3><ul><li>Kubernetes-Cluster</li><li>Minikube</li></ul></div><div class="content__box content__box_fill"><p><i>Kubernetes ist eine produktionsreife Open-Source-Plattform, die die Bereitstellung (scheduling) und Ausführung von Anwendungscontainern innerhalb und zwischen Computerclustern koordiniert.</i></p></div></div></div><br><div class=row><div class=col-md-8><h2 style=color:#3771e3>Cluster-Diagramm</h2></div></div><div class=row><div class=col-md-8><p><img src=/docs/tutorials/kubernetes-basics/public/images/module_01_cluster.svg></p></div></div><br><div class=row><div class=col-md-8><p><b>Der Master ist für die Verwaltung des Clusters verantwortlich.</b> Der Master koordiniert alle Aktivitäten in Ihrem Cluster, z. B. das Planen von Anwendungen, das Verwalten des gewünschten Status der Anwendungen, das Skalieren von Anwendungen und das Rollout neuer Updates.</p><p><b>Ein Node ist eine VM oder ein physischer Computer, der als Arbeitsmaschine in einem Kubernetes-Cluster dient.</b> Jeder Node verfügt über ein Kubelet, einen Agenten zur Verwaltung des Node und zur Kommunikation mit dem Kubernetes-Master. Der Node sollte auch über Werkzeuge zur Abwicklung von Containeroperationen verfügen, z. B. Docker oder rkt. Ein Kubernetes-Cluster, das den Produktionsverkehr abwickelt, sollte aus mindestens drei Nodes bestehen.</p></div><div class=col-md-4><div class="content__box content__box_fill"><p><i>Master verwalten den Cluster und die Nodes werden zum Hosten der laufenden Anwendungen verwendet.</i></p></div></div></div><div class=row><div class=col-md-8><p>Wenn Sie Anwendungen auf Kubernetes bereitstellen, weisen Sie den Master an, die Anwendungscontainer zu starten. Der Master plant die Ausführung der Container auf den Nodes des Clusters. <b>Die Nodes kommunizieren über die Kubernetes-API mit dem Master</b>, die der Master bereitstellt. Endbenutzer können die Kubernetes-API auch direkt verwenden, um mit dem Cluster zu interagieren.</p><p>Ein Kubernetes-Cluster kann auf physischen oder virtuellen Maschinen bereitgestellt werden. Um mit der Entwicklung von Kubernetes zu beginnen, können Sie Minikube verwenden. Minikube ist eine einfache Kubernetes-Implementierung, die eine VM auf Ihrem lokalen Computer erstellt und einen einfachen Cluster mit nur einem Knoten bereitstellt. Minikube ist für Linux-, MacOS- und Windows-Systeme verfügbar. Die Minikube-CLI bietet grundlegende Bootstrapping-Vorgänge für die Arbeit mit Ihrem Cluster, einschließlich Start, Stopp, Status und Löschen. Für dieses Lernprogramm verwenden Sie jedoch ein bereitgestelltes Online-Terminal mit vorinstalliertem Minikube.</p><p>Nun, da Sie wissen, was Kubernetes ist, schreiten wir zum Online-Tutorial und starten unseren ersten Cluster!</p></div></div><br><div class=row><div class=col-md-12><a class="btn btn-lg btn-success" href=/de/docs/tutorials/kubernetes-basics/create-cluster/cluster-interactive/ role=button>Interaktives Lernprogramm starten <span class=btn__next>›</span></a></div></div></main></div></body></html></div><div class=td-content style=page-break-before:always><h1 id=pg-323b75976001e8dfe35d67d61bc74f1a>5.2.1.2 - Interaktives Lernprogramm - Erstellen eines Clusters</h1><!doctype html><html lang=de><body><link href=/docs/tutorials/kubernetes-basics/public/css/styles.css rel=stylesheet><link href=/docs/tutorials/kubernetes-basics/public/css/overrides.css rel=stylesheet><script src=https://katacoda.com/embed.js></script><div class=layout id=top><main class="content katacoda-content"><div class=katacoda><div class=katacoda__alert>Um mit dem Terminal zu interagieren, verwenden Sie bitte die Desktop- / Tablet-Version</div><div class=katacoda__box id=inline-terminal-1 data-katacoda-id=kubernetes-bootcamp/1 data-katacoda-color=326de6 data-katacoda-secondary=273d6d data-katacoda-hideintro=false data-katacoda-prompt="Kubernetes Bootcamp Terminal" style=height:600px></div></div><div class=row><div class=col-md-12><a class="btn btn-lg btn-success" href=/docs/tutorials/kubernetes-basics/deploy-app/deploy-intro/ role=button>Weiter mit Modul 2<span class=btn__next>›</span></a></div></div></main></div></body></html></div><div class=td-content style=page-break-before:always><h1 id=pg-76d78b3fba507f7ed33cef14a35b631d>5.2.2 - Eine App bereitstellen</h1></div><div class=td-content><h1 id=pg-2b1bba431989008c7493109a0f049ece>5.2.2.1 - Verwenden von kubectl zum Erstellen eines Deployments</h1><!doctype html><html lang=de><body><link href=/docs/tutorials/kubernetes-basics/public/css/styles.css rel=stylesheet><div class=layout id=top><main class=content><div class=row><div class=col-md-8><h3>Ziele</h3><ul><li>Erfahren Sie mehr über Anwendungsbereitstellungen.</li><li>Stellen Sie Ihre erste App auf Kubernetes mit kubectl bereit.</li></ul></div><div class=col-md-8><h3>Kubernetes-Bereitstellungen (Deployments)</h3><p>Sobald Sie einen Kubernetes-Cluster ausgeführt haben, können Sie Ihre containerisierten Anwendungen darüber bereitstellen.
                Dazu erstellen Sie eine Kubernetes <b>Deployment</b>-Konfiguration. Das Deployment weist Kubernetes an, wie Instanzen Ihrer
Anwendung erstellt und aktualisiert werden. Nachdem Sie ein Deployment erstellt haben, plant der Kubernetes-Master die genannten
Anwendungsinstanzen für einzelne Nodes im Cluster.</p><p>Sobald die Anwendungsinstanzen erstellt wurden, überwacht ein Kubernetes Deployment Controller diese Instanzen kontinuierlich. Wenn der Node, der eine Instanz hostet, ausfällt oder gelöscht wird, ersetzt der Deployment Controller die Instanz durch eine Instanz auf einem anderen Node im Cluster. <b>Dies bietet einen Selbstheilungsmechanismus, um Maschinenausfälle oder -wartungen zu vermeiden.</b></p><p>In einer Welt vor der Orchestrierung wurden häufig Installationsskripts zum Starten von Anwendungen verwendet, sie erlaubten jedoch keine Wiederherstellung nach einem Maschinenausfall.
Kubernetes Deployments erstellen Ihre Anwendungsinstanzen und sorgen dafür, dass sie über mehrere Nodes hinweg ausgeführt werden. Dadurch bieten Kubernetes Deployments einen grundlegend anderen Ansatz für die Anwendungsverwaltung.</p></div><div class=col-md-4><div class="content__box content__box_lined"><h3>Zusammenfassung:</h3><ul><li>Deployments</li><li>Kubectl</li></ul></div><div class="content__box content__box_fill"><p><i>Eine Bereitstellung (Deployment) ist für das Erstellen und Aktualisieren von Instanzen Ihrer Anwendung verantwortlich</i></p></div></div></div><br><div class=row><div class=col-md-8><h2 style=color:#3771e3>Erste App auf Kubernetes bereitstellen</h2></div></div><div class=row><div class=col-md-8><p><img src=/docs/tutorials/kubernetes-basics/public/images/module_02_first_app.svg></p></div></div><br><div class=row><div class=col-md-8><p>Sie können eine Bereitstellung mithilfe der Kubernetes-Befehlszeilenschnittstelle <b>Kubectl</b> erstellen und verwalten.
Kubectl verwendet die Kubernetes-API, um mit dem Cluster zu interagieren.
                    In diesem Modul lernen Sie die gebräuchlichsten Kubectl-Befehle kennen, die zum Erstellen von Deployments zum Ausführen Ihrer Anwendungen in einem Kubernetes-Cluster erforderlich sind.</p><p>Wenn Sie ein Deployment erstellen, müssen Sie das Container-Image für Ihre Anwendung und die Anzahl der Replikate angeben, die Sie ausführen möchten. Sie können diese Informationen später ändern, indem Sie Ihr Deployment aktualisieren; In den Modulen <a href=/docs/tutorials/kubernetes-basics/scale-intro/>5</a> und <a href=/docs/tutorials/kubernetes-basics/update-intro/>6</a> des Bootcamps wird diskutiert, wie Sie Ihre Deployments skalieren und aktualisieren können.</p></div><div class=col-md-4><div class="content__box content__box_fill"><p><i>Anwendungen müssen in eines der unterstützten Containerformate gepackt werden, um auf Kubernetes bereitgestellt zu werden</i></p></div></div></div><div class=row><div class=col-md-8><p>Für unser erstes Deployment verwenden wir eine Node.js-Anwendung, die in einem Docker-Container verpackt ist.
Um die Node.js-Anwendung zu erstellen und den Docker-Container bereitzustellen, folgen Sie den Anweisungen im
<a href=/docs/tutorials/hello-minikube/>Hello Minikube tutorial</a>.</p><p>Nun, da Sie wissen, was Deployments sind, gehen wir zum Online-Tutorial und stellen unsere erste App bereit!</p></div></div><br><div class=row><div class=col-md-12><a class="btn btn-lg btn-success" href=/docs/tutorials/kubernetes-basics/deploy-app/deploy-interactive/ role=button>Interaktives Lernprogramm starten <span class=btn__next>›</span></a></div></div></main></div></body></html></div><div class=td-content style=page-break-before:always><h1 id=pg-f8997ec143b382fa6c9621941ea62ca3>5.2.2.2 - Interaktives Lernprogramm - Bereitstellen einer App</h1><!doctype html><html lang=de><body><link href=/docs/tutorials/kubernetes-basics/public/css/styles.css rel=stylesheet><link href=/docs/tutorials/kubernetes-basics/public/css/overrides.css rel=stylesheet><script src=https://katacoda.com/embed.js></script><div class=layout id=top><main class="content katacoda-content"><br><div class=katacoda><div class=katacoda__alert>Um mit dem Terminal zu interagieren, verwenden Sie bitte die Desktop- / Tablet-Version</div><div class=katacoda__box id=inline-terminal-1 data-katacoda-id=kubernetes-bootcamp/7 data-katacoda-color=326de6 data-katacoda-secondary=273d6d data-katacoda-hideintro=false data-katacoda-prompt="Kubernetes Bootcamp Terminal" style=height:600px></div></div><div class=row><div class=col-md-12><a class="btn btn-lg btn-success" href=/docs/tutorials/kubernetes-basics/explore/explore-intro/ role=button>Weiter mit Modul 3<span class=btn__next>›</span></a></div></div></main></div></body></html></div><div class=td-content style=page-break-before:always><h1 id=pg-250d620a73ec8be7e1f7d835574c4596>5.2.3 - Entdecken Sie Ihre App</h1></div><div class=td-content><h1 id=pg-2771f4e8c45321b17cb0114a2d266453>5.2.3.1 - Anzeigen von Pods und Nodes</h1><!doctype html><html lang=de><body><link href=/docs/tutorials/kubernetes-basics/public/css/styles.css rel=stylesheet><div class=layout id=top><main class=content><div class=row><div class=col-md-8><h3>Ziele:</h3><ul><li>Erfahren Sie mehr über Kubernetes Pods.</li><li>Erfahren Sie mehr über Kubernetes-Nodes.</li><li>Beheben Sie Fehler in bereitgestellten Anwendungen.</li></ul></div><div class=col-md-8><h2>Kubernetes Pods</h2><p>Als Sie ein Deployment in Modul <a href=/docs/tutorials/kubernetes-basics/deploy-intro/>2</a>, hat Kubernetes einen <b>Pod</b> erstellt, der Ihre Anwendungsinstanz hostet. Ein Pod ist eine Kubernetes-Abstraktion, die eine Gruppe von einem oder mehreren Anwendungscontainern (z. B. Docker oder rkt) und einigen gemeinsam genutzten Ressourcen für diese Container darstellt. Diese Ressourcen umfassen:</p><ul><li>Gemeinsamer Speicher, als Volumes</li><li>Networking, als eindeutige Cluster-IP-Adresse</li><li>Informationen zur Ausführung der einzelnen Container, wie z.B. die Container-Image-Version oder bestimmte Ports, die verwendet werden sollen.</li></ul><p>Ein Pod stellt einen anwendungsspezifischen "logischen Host" dar und kann verschiedene Anwendungscontainer enthalten, die relativ eng gekoppelt sind. Ein Pod kann beispielsweise sowohl den Container mit Ihrer Node.js-Applikation als auch einen anderen Container beinhalten, der die vom Webserver Node.js zu veröffentlichenden Daten einspeist. Die Container in einem Pod teilen sich eine IP-Adresse und einen Portbereich, sind immer kolokalisiert und gemeinsam geplant und laufen in einem gemeinsamen Kontext auf demselben Node.</p></div><div class=col-md-4><div class="content__box content__box_lined"><h3>Zusammenfassung:</h3><ul><li>Pods</li><li>Nodes</li><li>Kubectl-Hauptbefehle</li></ul></div><div class="content__box content__box_fill"><p><i>Ein Pod ist eine Gruppe von einem oder mehreren Anwendungscontainern (z. B. Docker oder rkt) und enthält gemeinsam genutzten Speicher (Volumes), IP-Adresse und Informationen zur Ausführung.</i></p></div></div></div><br><div class=row><div class=col-md-8><h2 style=color:#3771e3>Pods-Übersicht</h2></div></div><div class=row><div class=col-md-8><p><img src=/docs/tutorials/kubernetes-basics/public/images/module_03_pods.svg></p></div></div><br><div class=row><div class=col-md-8><h2>Nodes</h2><p>Ein Pod läuft immer auf einem <b>Node</b>. Ein Node ist eine Arbeitsmaschine in Kubernetes und kann je nach Cluster entweder eine virtuelle oder eine physische Maschine sein. Jeder Node wird vom Master verwaltet. Ein Node kann über mehrere Pods verfügen, und der Kubernetes-Master übernimmt automatisch die Planung der Pods für die Nodes im Cluster. Die automatische Zeitplanung des Masters berücksichtigt die verfügbaren Ressourcen auf jedem Node.</p><p>Auf jedem Kubernetes Node läuft mindestens:</p><ul><li>Kubelet, ein Prozess, der für die Kommunikation zwischen dem Kubernetes Master und dem Node verantwortlich ist; Er verwaltet die Pods und die auf einer Maschine laufenden Container.</li><li>Eine Containerlaufzeit (wie Docker, rkt), die für das Abrufen des Containerabbilds aus einer Registry, das Entpacken des Containers und das Ausführen der Anwendung verantwortlich ist.</li></ul></div><div class=col-md-4><div class="content__box content__box_fill"><p><i>Container sollten nur dann gemeinsam in einem Pod geplant werden, wenn sie eng miteinander verbunden sind und Ressourcen wie Festplatten gemeinsam nutzen müssen.</i></p></div></div></div><br><div class=row><div class=col-md-8><h2 style=color:#3771e3>Node Überblick</h2></div></div><div class=row><div class=col-md-8><p><img src=/docs/tutorials/kubernetes-basics/public/images/module_03_nodes.svg></p></div></div><br><div class=row><div class=col-md-8><h2>Troubleshooting mit kubectl</h2><p>In Modul <a href=/docs/tutorials/kubernetes-basics/deploy/deploy-intro/>2</a> erstellt haben, haben Sie die Befehlszeilenschnittstelle von Kubectl verwendet. Sie verwenden sie weiterhin in Modul 3, um Informationen zu den bereitgestellten Anwendungen und ihren Umgebungen zu erhalten. Die häufigsten Operationen können mit den folgenden kubectl-Befehlen ausgeführt werden:</p><ul><li><b>kubectl get</b> - Ressourcen auflisten</li><li><b>kubectl describe</b> - Detaillierte Informationen zu einer Ressource anzeigen</li><li><b>kubectl logs</b> - Die Logdateien von einem Container in einem Pod anzigen</li><li><b>kubectl exec</b> - Einen Befehl für einen Container in einem Pod ausführen</li></ul><p>Mit diesen Befehlen können Sie sehen, wann Anwendungen bereitgestellt wurden, ihren aktuellen Status anzeigen, sehen wo sie ausgeführt werden und wie sie konfiguriert sind.</p><p>Nun, da wir mehr über unsere Clusterkomponenten und die Befehlszeile wissen, wollen wir unsere Anwendung untersuchen.</p></div><div class=col-md-4><div class="content__box content__box_fill"><p><i>Ein Node ist eine Arbeitsmaschine in Kubernetes und kann je nach Cluster eine VM oder eine physische Maschine sein. Auf einem Node können mehrere Pods laufen.</i></p></div></div></div><br><div class=row><div class=col-md-12><a class="btn btn-lg btn-success" href=/docs/tutorials/kubernetes-basics/explore/explore-interactive/ role=button>Interaktives Lernprogramm starten <span class=btn__next>›</span></a></div></div></main></div></body></html></div><div class=td-content style=page-break-before:always><h1 id=pg-4b01eab98a9844ad91131079654199dd>5.2.3.2 - Interaktives Lernprogramm - Entdecken Sie Ihre App</h1><!doctype html><html lang=de><body><link href=/docs/tutorials/kubernetes-basics/public/css/styles.css rel=stylesheet><link href=/docs/tutorials/kubernetes-basics/public/css/overrides.css rel=stylesheet><script src=https://katacoda.com/embed.js></script><div class=layout id=top><main class="content katacoda-content"><br><div class=katacoda><div class=katacoda__alert>Um mit dem Terminal zu interagieren, verwenden Sie bitte die Desktop- / Tablet-Version</div><div class=katacoda__box id=inline-terminal-1 data-katacoda-id=kubernetes-bootcamp/4 data-katacoda-color=326de6 data-katacoda-secondary=273d6d data-katacoda-hideintro=false data-katacoda-prompt="Kubernetes Bootcamp Terminal" style=height:600px></div></div><div class=row><div class=col-md-12><a class="btn btn-lg btn-success" href=/docs/tutorials/kubernetes-basics/expose/expose-intro/ role=button>Weiter mit Modul 4<span class=btn__next>›</span></a></div></div></main></div></body></html></div><div class=td-content style=page-break-before:always><h1 id=pg-4b0e31c9e0eae68bbb0a358b4042ada9>5.2.4 - Machen Sie Ihre App öffentlich zugänglich</h1></div><div class=td-content><h1 id=pg-8ef4dad8f743b191a9e8c6f891cb191a>5.2.4.1 - Verwendung eines Services zum Veröffentlichen Ihrer App</h1><!doctype html><html lang=de><body><link href=/docs/tutorials/kubernetes-basics/public/css/styles.css rel=stylesheet><div class=layout id=top><main class=content><div class=row><div class=col-md-8><h3>Ziele:</h3><ul><li>Erfahren Sie mehr über einen Service in Kubernetes</li><li>Verstehen, wie Labels und LabelSelector-Objekte sich auf einen Dienst beziehen</li><li>Stellen Sie eine Anwendung außerhalb eines Kubernetes-Clusters mithilfe eines Services bereit</li></ul></div><div class=col-md-8><h3>Überblick über Kubernetes Services</h3><p>Kubernetes <a href=/docs/concepts/workloads/pods/pod-overview/>Pods</a> sind sterblich. Pods haben tatsächlich einen <a href=/docs/concepts/workloads/pods/pod-lifecycle/>Lebenszyklus</a>. Wenn ein Worker-Node stirbt, gehen auch die auf dem Knoten laufenden Pods verloren. Ein <a href=/docs/concepts/workloads/controllers/replicaset/>ReplicaSet</a> kann dann durch Erstellen neuer Pods dynamisch den Cluster in den gewünschten Status zurückversetzen, damit die Anwendung weiterhin ausgeführt werden kann. Als ein anderes Beispiel betrachten wir ein Bildverarbeitungs-Backend mit 3 Reproduktionen. Diese Repliken sind austauschbar; Das Front-End-System sollte sich nicht für Backend-Replikate interessieren, selbst wenn ein Pod verloren geht und neu erstellt wird. Allerdings hat jeder Pod in einem Kubernetes-Cluster eine eindeutige IP-Adresse, sogar Pods auf demselben Knoten. Daher müssen Änderungen automatisch zwischen den Pods abgeglichen werden, damit Ihre Anwendungen weiterhin funktionieren.</p><p>Ein Dienst in Kubernetes ist eine Abstraktion, die einen logischen Satz von Pods und eine Richtlinie für den Zugriff auf diese definiert. Services ermöglichen eine lose Kopplung zwischen abhängigen Pods. Ein Service ist in YAML <a href=/docs/concepts/configuration/overview/#general-configuration-tips>(bevorzugt)</a> oder JSON spezifiziert, wie alle Kubernetes-Objekte. Die Gruppe von Pods, auf die ein Service abzielt, wird normalerweise von einem <i>LabelSelector</i> bestimmt (Siehe unten, warum Sie möglicherweise wünschen, einen Service ohne <code>selector</code> in die Spezifikation aufzunehmen).</p><p>Obwohl jeder Pod über eine eindeutige IP-Adresse verfügt, werden diese IP-Adressen nicht außerhalb des Clusters ohne einen Service verfügbar gemacht. Services ermöglichen es Ihren Anwendungen, Datenverkehr zu empfangen. Services können auf unterschiedliche Weise verfügbar gemacht werden, indem Sie einen <code>type</code> in der ServiceSpec angeben:</p><ul><li><i>ClusterIP</i> (Standardeinstellung) - Macht den Service auf einer internen IP im Cluster verfügbar. Durch diesen Typ ist der Service nur innerhalb des Clusters erreichbar.</li><li><i>NodePort</i> - Macht den Dienst auf demselben Port jedes ausgewählten Knotens im Cluster mithilfe von NAT verfügbar. Macht einen Dienst von außerhalb des Clusters mit <code>&lt;NodeIP>:&lt;NodePort></code> zugänglich. Oberhalb von ClusterIP positioniert.</li><li><i>LoadBalancer</i> - Erstellt einen externen Load-Balancer in der aktuellen Cloud (sofern unterstützt) und weist dem Service eine feste externe IP zu. Oberhalb von NodePort positioniert.</li><li><i>ExternalName</i> - Macht den Dienst mit einem beliebigen Namen verfügbar (Spezifiziert durch <code>externalName</code> in der Konfiguration) indem Sie einen CNAME-Datensatz mit dem Namen zurückgeben. Kein Proxy wird verwendet. Für diesen Typ ist v1.7 von <code>kube-dns</code> oder höher erforderlich.</li></ul><p>Weitere Informationen zu den verschiedenen Arten von Services finden Sie im <a href=/docs/tutorials/services/source-ip/>Verwendung von Source IP</a> Tutorial. Siehe auch <a href=/docs/concepts/services-networking/connect-applications-service>Anwendungen mit Services verbinden</a>.</p><p>Beachten Sie außerdem, dass es einige Anwendungsfälle mit Services gibt, bei denen keine <code>selector</code> Spezifikation in der Konfiguration nötig ist. Ein Service ohne <code>selector</code> erstellt auch nicht das entsprechende Endpunktobjekt. Auf diese Weise können Benutzer einen Service manuell bestimmten Endpunkten zuordnen. Eine andere Möglichkeit, warum es keinen Selektor gibt, ist die strikte Verwendung <code>type: ExternalName</code>.</p></div><div class=col-md-4><div class="content__box content__box_lined"><h3>Zusammenfassung:</h3><ul><li>Pods externen Verkehr aussetzen</li><li>Lastverteilung über mehrere Pods</li><li>Labels verwenden</li></ul></div><div class="content__box content__box_fill"><p><i>Ein Kubernetes Service ist eine Abstraktionsschicht, die einen logischen Satz von Pods definiert und den externen Datenverkehr, Lastverteilung und Service Discovery für diese Pods ermöglicht.</i></p></div></div></div><br><div class=row><div class=col-md-8><h3>Services und Labels</h3></div></div><div class=row><div class=col-md-8><p><img src=/docs/tutorials/kubernetes-basics/public/images/module_04_services.svg width=150% height=150%></p></div></div><div class=row><div class=col-md-8><p>Ein Service leitet den Traffic über eine Reihe von Pods. Services sind die Abstraktion, die es Pods ermöglichen, in Kubernetes zu sterben und sich zu replizieren, ohne die Anwendung zu beeinträchtigen. Die Erkennung und das Routing zwischen abhängigen Pods (z. B. Frontend- und Backend-Komponenten in einer Anwendung) werden von Kubernetes Services ausgeführt.</p><p>Services passen zu einem Satz von Pods mit <a href=/docs/concepts/overview/working-with-objects/labels>Labels und Selektoren</a>, eine einfache Gruppierung, die logische Operationen an Objekten in Kubernetes ermöglicht. Labels sind Schlüssel/Wert-Paare, die an Objekte angehängt werden, und können auf verschiedene Arten verwendet werden:</p><ul><li>Festlegen von Objekten für Entwicklung, Test und Produktion</li><li>Versions-Tags einbetten</li><li>Klassifizieren von Objekten mithilfe von Tags</li></ul></div><div class=col-md-4><div class="content__box content__box_fill"><p><i>Sie können einen Service gleichzeitig mit dem Erstellen eines Deployments erstellen, indem Sie<br><code>--expose</code> in kubectl verwenden.</i></p></div></div></div><br><div class=row><div class=col-md-8><p><img src=/docs/tutorials/kubernetes-basics/public/images/module_04_labels.svg></p></div></div><br><div class=row><div class=col-md-8><p>Labels können zum Zeitpunkt der Erstellung oder zu einem späteren Zeitpunkt an Objekte angehängt werden. Sie können jederzeit geändert werden. Lassen Sie uns jetzt unsere Anwendung mit einem Service verfügbar machen und einige Labels anbringen.</p></div></div><br><div class=row><div class=col-md-12><a class="btn btn-lg btn-success" href=/docs/tutorials/kubernetes-basics/expose/expose-interactive/ role=button>Interaktives Lernprogramm starten<span class=btn__next>›</span></a></div></div></main></div></body></html></div><div class=td-content style=page-break-before:always><h1 id=pg-352241d22effe0714772d21c7d1b512d>5.2.4.2 - Interaktives Lernprogramm - Ihre App öffentlich zugänglich machen</h1><!doctype html><html lang=de><body><link href=/docs/tutorials/kubernetes-basics/public/css/styles.css rel=stylesheet><link href=/docs/tutorials/kubernetes-basics/public/css/overrides.css rel=stylesheet><script src=https://katacoda.com/embed.js></script><div class=layout id=top><main class="content katacoda-content"><div class=katacoda><div class=katacoda__alert>Um mit dem Terminal zu interagieren, verwenden Sie bitte die Desktop- / Tablet-Version</div><div class=katacoda__box id=inline-terminal-1 data-katacoda-id=kubernetes-bootcamp/8 data-katacoda-color=326de6 data-katacoda-secondary=273d6d data-katacoda-hideintro=false data-katacoda-prompt="Kubernetes Bootcamp Terminal" style=height:600px></div></div><div class=row><div class=col-md-12><a class="btn btn-lg btn-success" href=/docs/tutorials/kubernetes-basics/scale/scale-intro/ role=button>Weiter mit Modul 5<span class=btn__next>›</span></a></div></div></main></div></body></html></div><div class=td-content style=page-break-before:always><h1 id=pg-be4996c93fb39c459a30b6669569d423>5.2.5 - Skalieren Sie Ihre App</h1></div><div class=td-content><h1 id=pg-d1c15c9bd4f625adbc13149b1475287c>5.2.5.1 - Mehrere Instanzen Ihrer App ausführen</h1><!doctype html><html lang=de><body><link href=/docs/tutorials/kubernetes-basics/public/css/styles.css rel=stylesheet><div class=layout id=top><main class=content><div class=row><div class=col-md-8><h3>Ziele:</h3><ul><li>Skalieren einer App mit kubectl.</li></ul></div><div class=col-md-8><h3>Eine Anwendung skalieren</h3><p>In den vorherigen Modulen haben wir ein <a href=/docs/concepts/workloads/controllers/deployment/>Deployment</a> erstellt, und es dann öffentlich mittels einem <a href=/docs/concepts/services-networking/service/>Service</a> bereitgestellt. Das Deployment hat nur einen Pod für die Ausführung unserer Anwendung erstellt. Wenn der Anfragen zunehmen, müssen wir die Anwendung skalieren, um den Anforderungen der Benutzer gerecht zu werden.</p><p><b>Skalieren</b> wird durch Ändern der Anzahl der Repliken in einer Bereitstellung erreichtt</p></div><div class=col-md-4><div class="content__box content__box_lined"><h3>Zusammenfassung:</h3><ul><li>Skalieren eines Deployments</li></ul></div><div class="content__box content__box_fill"><p><i>Sie können von Anfang an eine Bereitstellung mit mehreren Instanzen erstellen, indem Sie den Parameter --replicas mit dem Befehl `kubectl run` verwenden</i></p></div></div></div><br><div class=row><div class=col-md-8><h2 style=color:#3771e3>Skalierung - Übersicht</h2></div></div><div class=row><div class=col-md-1></div><div class=col-md-8><div id=myCarousel class=carousel data-ride=carousel data-interval=3000><ol class=carousel-indicators><li data-target=#myCarousel data-slide-to=0 class=active></li><li data-target=#myCarousel data-slide-to=1></li></ol><div class=carousel-inner role=listbox><div class="item carousel-item active"><img src=/docs/tutorials/kubernetes-basics/public/images/module_05_scaling1.svg></div><div class="item carousel-item"><img src=/docs/tutorials/kubernetes-basics/public/images/module_05_scaling2.svg></div></div><a class="left carousel-control" href=#myCarousel role=button data-slide=prev><span class=sr-only>Vorherige</span></a>
<a class="right carousel-control" href=#myCarousel role=button data-slide=next><span class=sr-only>Nächste</span></a></div></div></div><br><div class=row><div class=col-md-8><p>Durch das Skalieren eines Deployments wird sichergestellt, dass neue Pods erstellt und auf Nodes mit verfügbaren Ressourcen geplant werden. Durch die Skalierung wird die Anzahl der Pods auf den neuen gewünschten Status erhöht. Kubernetes unterstützt auch die <a href=/docs/user-guide/horizontal-pod-autoscaling/>automatische Skalierung</a> von Pods, dies ist jedoch außerhalb des Anwendungsbereichs dieses Lernprogramms. Die Skalierung auf Null ist ebenfalls möglich und beendet alle Pods der angegebenen Bereitstellung.</p><p>Das Ausführen mehrerer Instanzen einer Anwendung erfordert eine Möglichkeit, den Datenverkehr auf alle Anwendungen zu verteilen. Services verfügen über eine integrierte Lastverteilung, der den Netzwerkverkehr auf alle Pods eines bereitgestellten Deployments verteilt. Die Services überwachen kontinuierlich die laufenden Pods mithilfe von Endpunkten, um sicherzustellen, dass der Datenverkehr nur an die verfügbaren Pods gesendet wird.</p></div><div class=col-md-4><div class="content__box content__box_fill"><p><i>Die Skalierung wird durch Ändern der Anzahl der Repliken in einer Bereitstellung erreicht.</i></p></div></div></div><br><div class=row><div class=col-md-8><p>Wenn Sie mehrere Instanzen einer Anwendung ausgeführt haben, können Sie Rolling-Updates ohne Ausfallzeiten durchführen. Wir werden das im nächsten Modul behandeln. Nun gehen wir zum Online-Terminal und skalieren unsere Anwendung.</p></div></div><br><div class=row><div class=col-md-12><a class="btn btn-lg btn-success" href=/docs/tutorials/kubernetes-basics/scale/scale-interactive/ role=button>Interaktives Lernprogramm starten <span class=btn__next>›</span></a></div></div></main></div></body></html></div><div class=td-content style=page-break-before:always><h1 id=pg-7bdb3fbaa1177ff5dfa3fe86bd35ef59>5.2.5.2 - Interaktives Lernprogramm - Skalieren Ihrer App</h1><!doctype html><html lang=de><body><link href=/docs/tutorials/kubernetes-basics/public/css/styles.css rel=stylesheet><link href=/docs/tutorials/kubernetes-basics/public/css/overrides.css rel=stylesheet><script src=https://katacoda.com/embed.js></script><div class=layout id=top><main class="content katacoda-content"><div class=katacoda><div class=katacoda__alert>Um mit dem Terminal zu interagieren, verwenden Sie bitte die Desktop- / Tablet-Version</div><div class=katacoda__box id=inline-terminal-1 data-katacoda-id=kubernetes-bootcamp/5 data-katacoda-color=326de6 data-katacoda-secondary=273d6d data-katacoda-hideintro=false data-katacoda-prompt="Kubernetes Bootcamp Terminal" style=height:600px></div></div><div class=row><div class=col-md-12><a class="btn btn-lg btn-success" href=/docs/tutorials/kubernetes-basics/update/update-intro/ role=button>Weiter mit Modul 6<span class=btn__next>›</span></a></div></div></main><a class=scrolltop href=#top></a></div></body></html></div><div class=td-content style=page-break-before:always><h1 id=pg-62b8b17dadfb55f1801cf8439e944e58>5.2.6 - Aktualisieren Sie Ihre App</h1></div><div class=td-content><h1 id=pg-12e04355145afad615ca3c38335ba019>5.2.6.1 - Durchführen eines Rolling-Updates</h1><!doctype html><html lang=de><body><link href=/docs/tutorials/kubernetes-basics/public/css/styles.css rel=stylesheet><link href="https://fonts.googleapis.com/css?family=Roboto+Slab:300,400,700" rel=stylesheet><div class=layout id=top><main class=content><div class=row><div class=col-md-8><h3>Objectives</h3><ul><li>Führen Sie ein Rolling-Update mit kubectl durch.</li></ul></div><div class=col-md-8><h3>Anwendung aktualisieren</h3><p>Anwender erwarten, dass Anwendungen jederzeit verfügbar sind, und Entwickler haben das Bedürfnis mehrmals täglich neue Versionen davon bereitstellen. In Kubernetes geschieht dies mit laufenden Aktualisierungen. <b>Rolling Updates</b> ermöglichen die Aktualisierung von Deployments ohne Ausfallzeit, indem Pod-Instanzen inkrementell mit neuen aktualisiert werden. Die neuen Pods werden auf Nodes mit verfügbaren Ressourcen geplant.</p><p>Im vorherigen Modul haben wir unsere Anwendung so skaliert, dass mehrere Instanzen ausgeführt werden können. Dies ist eine Voraussetzung, um Aktualisierungen durchzuführen, ohne die Anwendungsverfügbarkeit zu beeinträchtigen. Standardmäßig ist die maximale Anzahl von Pods, die während der Aktualisierung nicht verfügbar sein kann, und die maximale Anzahl neuer Pods, die erstellt werden können, 1. Beide Optionen können entweder nach Zahlen oder Prozentsätzen (von Pods) konfiguriert werden.
In Kubernetes werden Updates versioniert und jedes Deployment-Update kann auf die vorherige (stabile) Version zurückgesetzt werden.</p></div><div class=col-md-4><div class="content__box content__box_lined"><h3>Zusammenfassung:</h3><ul><li>App aktualisieren</li></ul></div><div class="content__box content__box_fill"><p><i>Rolling Updates ermöglichen die Aktualisierung der Deployments ohne Ausfallzeit, indem Pod-Instanzen inkrementell mit neuen aktualisiert werden.</i></p></div></div></div><br><div class=row><div class=col-md-8><h2 style=color:#3771e3>Rolling Updates - Übersicht</h2></div></div><div class=row><div class=col-md-1></div><div class=col-md-8><div id=myCarousel class=carousel data-ride=carousel data-interval=3000><ol class=carousel-indicators><li data-target=#myCarousel data-slide-to=0 class=active></li><li data-target=#myCarousel data-slide-to=1></li><li data-target=#myCarousel data-slide-to=2></li><li data-target=#myCarousel data-slide-to=3></li></ol><div class=carousel-inner role=listbox><div class="item carousel-item active"><img src=/docs/tutorials/kubernetes-basics/public/images/module_06_rollingupdates1.svg></div><div class="item carousel-item"><img src=/docs/tutorials/kubernetes-basics/public/images/module_06_rollingupdates2.svg></div><div class="item carousel-item"><img src=/docs/tutorials/kubernetes-basics/public/images/module_06_rollingupdates3.svg></div><div class="item carousel-item"><img src=/docs/tutorials/kubernetes-basics/public/images/module_06_rollingupdates4.svg></div></div><a class="left carousel-control" href=#myCarousel role=button data-slide=prev><span class=sr-only>Vorherige</span></a>
<a class="right carousel-control" href=#myCarousel role=button data-slide=next><span class=sr-only>Nächste</span></a></div></div></div><br><div class=row><div class=col-md-8><p>Ähnlich wie bei der Anwendungsskalierung wird der Datenverkehr, wenn ein Deployment öffentlich verfügbar gemacht wird, während der Aktualisierung auf die verfügbaren Pods lastverteilt. Ein verfügbarer Pod ist eine Instanz, die den Benutzern der Anwendung zur Verfügung steht.</p><p>Rolling Updates ermöglichen die folgenden Aktionen:</p><ul><li>Heraufstufen einer Anwendung von einer Umgebung in eine andere (über Aktualisierungen der Container-Images)</li><li>Rollback auf frühere Versionen</li><li>Kontinuierliche Integration und kontinuierliche Bereitstellung von Anwendungen ohne Ausfallzeiten</li></ul></div><div class=col-md-4><div class="content__box content__box_fill"><p><i>Wenn ein Deployment öffentlich verfügbar gemacht wird, wird der Verkehr während des Updates nur auf verfügbare Pods verteilt.</i></p></div></div></div><br><div class=row><div class=col-md-8><p>Im folgenden interaktiven Tutorial werden wir unsere Anwendung auf eine neue Version aktualisieren und auch einen Rollback durchführen.</p></div></div><br><div class=row><div class=col-md-12><a class="btn btn-lg btn-success" href=/docs/tutorials/kubernetes-basics/update/update-interactive/ role=button>Interaktives Lernprogramm starten <span class=btn__next>›</span></a></div></div></main></div></body></html></div><div class=td-content style=page-break-before:always><h1 id=pg-dddc0cb356c280e0339bcf42776987dc>5.2.6.2 - Interaktives Lernprogramm - Aktualisieren Ihrer App</h1><!doctype html><html lang=de><body><link href=/docs/tutorials/kubernetes-basics/public/css/styles.css rel=stylesheet><link href=/docs/tutorials/kubernetes-basics/public/css/overrides.css rel=stylesheet><script src=https://katacoda.com/embed.js></script><div class=layout id=top><main class="content katacoda-content"><div class=katacoda><div class=katacoda__alert>Um mit dem Terminal zu interagieren, verwenden Sie bitte die Desktop- / Tablet-Version</div><div class=katacoda__box id=inline-terminal-1 data-katacoda-id=kubernetes-bootcamp/6 data-katacoda-color=326de6 data-katacoda-secondary=273d6d data-katacoda-hideintro=false data-katacoda-prompt="Kubernetes Bootcamp Terminal" style=height:600px></div></div><div class=row><div class=col-md-12><a class="btn btn-lg btn-success" href=/docs/tutorials/kubernetes-basics/ role=button>Zurück zu Kubernetes Grundlagen<span class=btn__next>›</span></a></div></div></main></div></body></html></div><div class=td-content style=page-break-before:always><h1 id=pg-b00a88a07ceb21b1a83e5822e0c86c1d>6 - Referenzen</h1><p>Dieser Abschnitt der Kubernetes-Dokumentation enthält Referenzinformationen.</p><h2 id=api-referenz>API-Referenz</h2><ul><li><a href=/docs/reference/using-api/api-overview/>Kubernetes API Überblick</a> - Übersicht über die API für Kubernetes.</li><li>Kubernetes API Versionen<ul><li><a href=/docs/reference/generated/kubernetes-api/v1.17/>1.17</a></li><li><a href=/docs/reference/generated/kubernetes-api/v1.16/>1.16</a></li><li><a href=/docs/reference/generated/kubernetes-api/v1.15/>1.15</a></li><li><a href=/docs/reference/generated/kubernetes-api/v1.14/>1.14</a></li><li><a href=/docs/reference/generated/kubernetes-api/v1.13/>1.13</a></li></ul></li></ul><h2 id=api-clientbibliotheken>API-Clientbibliotheken</h2><p>Um die Kubernetes-API aus einer Programmiersprache aufzurufen, können Sie
<a href=/docs/reference/using-api/client-libraries/>Clientbibliotheken</a> verwenden.
Offiziell unterstützte Clientbibliotheken:</p><ul><li><a href=https://github.com/kubernetes/client-go/>Kubernetes Go Clientbibliothek</a></li><li><a href=https://github.com/kubernetes-client/python>Kubernetes Python Clientbibliothek</a></li><li><a href=https://github.com/kubernetes-client/java>Kubernetes Java Clientbibliothek</a></li><li><a href=https://github.com/kubernetes-client/javascript>Kubernetes JavaScript Clientbibliothek</a></li></ul><h2 id=cli-referenz>CLI-Referenz</h2><ul><li><a href=/docs/user-guide/kubectl-overview>kubectl</a> - Haupt-CLI-Tool zum Ausführen von Befehlen und zum Verwalten von Kubernetes-Clustern.<ul><li><a href=/docs/user-guide/jsonpath/>JSONPath</a> - Syntax-Anleitung zur Verwendung von <a href=http://goessner.net/articles/JsonPath/>JSONPath expressionen</a> mit kubectl.</li></ul></li><li><a href=/docs/admin/kubeadm/>kubeadm</a> - CLI-Tool zur einfachen Bereitstellung eines sicheren Kubernetes-Clusters.</li><li><a href=/docs/admin/kubefed/>kubefed</a> - CLI-Tool zur Verwaltung Ihres Clusterverbunds.</li></ul><h2 id=konfigurationsreferenz>Konfigurationsreferenz</h2><ul><li><a href=/docs/admin/kubelet/>kubelet</a> - Der primäre <em>Node-Agent</em>, der auf jedem Node ausgeführt wird. Das Kubelet betrachtet eine Reihe von PodSpecs und stellt sicher, dass die beschriebenen Container ordnungsgemäß ausgeführt werden.</li><li><a href=/docs/admin/kube-apiserver/>kube-apiserver</a> - REST-API zur Überprüfung und Konfiguration von Daten für API-Objekte wie Pods, Services und Replikationscontroller.</li><li><a href=/docs/admin/kube-controller-manager/>kube-controller-manager</a> - Daemon, der die mit Kubernetes gelieferten zentralen Regelkreise einbettet.</li><li><a href=/docs/admin/kube-proxy/>kube-proxy</a> - Kann einfache TCP/UDP-Stream-Weiterleitung oder Round-Robin-TCP/UDP-Weiterleitung über eine Reihe von Back-Ends durchführen.</li><li><a href=/docs/admin/kube-scheduler/>kube-scheduler</a> - Scheduler, der Verfügbarkeit, Leistung und Kapazität verwaltet.</li><li><a href=/docs/admin/federation-apiserver/>federation-apiserver</a> - API-Server für Cluster Föderationen.</li><li><a href=/docs/admin/federation-controller-manager/>federation-controller-manager</a> - Daemon, der die zentralen Regelkreise einbindet, die mit der Kubernetes-Föderation ausgeliefert werden.</li></ul><h2 id=design-dokumentation>Design Dokumentation</h2><p>Ein Archiv der Designdokumente für Kubernetes-Funktionalität. Gute Ansatzpunkte sind <a href=https://git.k8s.io/design-proposals-archive/architecture/architecture.md>Kubernetes Architektur</a> und <a href=https://git.k8s.io/community/contributors/design-proposals>Kubernetes Design Übersicht</a>.</p></div><div class=td-content style=page-break-before:always><h1 id=pg-2b03679960950df772fb4fe7d78427b9>6.1 - Standardisiertes Glossar</h1></div><div class=td-content style=page-break-before:always><h1 id=pg-af7c1f9168ec67f957edc504f43faf9a>6.2 - Kubernetes Probleme und Sicherheit</h1></div><div class=td-content style=page-break-before:always><h1 id=pg-882c82a32bfb4d7946585a93a966b442>6.3 - Verwendung der Kubernetes-API</h1></div><div class=td-content style=page-break-before:always><h1 id=pg-99b26586d8a33ec06996dcf7892a9683>6.4 - API Zugriff</h1></div><div class=td-content style=page-break-before:always><h1 id=pg-60a16da3955f1de774f1f8dd756f2251>6.5 - API Referenzinformationen</h1></div><div class=td-content style=page-break-before:always><h1 id=pg-a92541c7b5589e722b0b250b8ee3172d>6.6 - Föderation API</h1></div><div class=td-content style=page-break-before:always><h1 id=pg-5bbbc5163b35431b3bff029ab9ec57d3>6.7 - Setup-Tools Referenzinformationen</h1></div><div class=td-content style=page-break-before:always><h1 id=pg-54e562dd1441d0195970a6526b0055cc>6.8 - Befehlszeilen-Werkzeug Referenzinformationen</h1></div><div class=td-content style=page-break-before:always><h1 id=pg-03460a7254c6c73eb2a1bb3dd7d25910>6.9 - kubectl CLI</h1></div><div class=td-content><h1 id=pg-8aba901ac13f124e5782b90ddb166ee2>6.9.1 - kubectl Spickzettel</h1><p>Siehe auch: <a href=/docs/reference/kubectl/overview/>Kubectl Überblick</a> und <a href=/docs/reference/kubectl/jsonpath>JsonPath Dokumentation</a>.</p><p>Diese Seite ist eine Übersicht über den Befehl <code>kubectl</code>.</p><h1 id=kubectl-spickzettel>kubectl - Spickzettel</h1><h2 id=kubectl-autovervollständigung>Kubectl Autovervollständigung</h2><h3 id=bash>BASH</h3><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#a2f>source</span> &lt;<span style=color:#666>(</span>kubectl completion bash<span style=color:#666>)</span> <span style=color:#080;font-style:italic># Wenn Sie autocomplete in bash in der aktuellen Shell einrichten, sollte zuerst das bash-completion-Paket installiert werden.</span>
</span></span><span style=display:flex><span><span style=color:#a2f>echo</span> <span style=color:#b44>&#34;source &lt;(kubectl completion bash)&#34;</span> &gt;&gt; ~/.bashrc <span style=color:#080;font-style:italic># Fügen Sie der Bash-Shell dauerhaft Autocomplete hinzu.</span>
</span></span></code></pre></div><p>Sie können auch ein Abkürzungsalias für <code>kubectl</code> verwenden, welches auch mit Vervollständigung funktioniert:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#a2f>alias</span> <span style=color:#b8860b>k</span><span style=color:#666>=</span>kubectl
</span></span><span style=display:flex><span><span style=color:#a2f>complete</span> -F __start_kubectl k
</span></span></code></pre></div><h3 id=zsh>ZSH</h3><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#a2f>source</span> &lt;<span style=color:#666>(</span>kubectl completion zsh<span style=color:#666>)</span>  <span style=color:#080;font-style:italic># Richten Sie Autocomplete in zsh in der aktuellen Shell ein</span>
</span></span><span style=display:flex><span><span style=color:#a2f>echo</span> <span style=color:#b44>&#34;if [ </span><span style=color:#b8860b>$commands</span><span style=color:#b44>[kubectl] ]; then source &lt;(kubectl completion zsh); fi&#34;</span> &gt;&gt; ~/.zshrc <span style=color:#080;font-style:italic># Fügen Sie der Zsh-Shell dauerhaft Autocomplete hinzu</span>
</span></span></code></pre></div><h2 id=kubectl-kontext-und-konfiguration>Kubectl Kontext und Konfiguration</h2><p>Legen Sie fest, welcher Kubernetes-Cluster mit <code>kubectl</code> kommuniziert und dessen Konfiguration ändert. Lesen Sie die Dokumentation <a href=/docs/tasks/access-application-cluster/configure-access-multiple-clusters/>Authentifizierung mit kubeconfig über mehrere Cluster hinweg</a> für ausführliche Informationen zur Konfigurationsdatei.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>kubectl config view <span style=color:#080;font-style:italic># Zusammengeführte kubeconfig-Einstellungen anzeigen.</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#080;font-style:italic># Verwenden Sie mehrere kubeconfig-Dateien gleichzeitig und zeigen Sie die zusammengeführte Konfiguration an</span>
</span></span><span style=display:flex><span><span style=color:#b8860b>KUBECONFIG</span><span style=color:#666>=</span>~/.kube/config:~/.kube/kubconfig2 kubectl config view
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#080;font-style:italic># Zeigen Sie das Passwort für den e2e-Benutzer an</span>
</span></span><span style=display:flex><span>kubectl config view -o <span style=color:#b8860b>jsonpath</span><span style=color:#666>=</span><span style=color:#b44>&#39;{.users[?(@.name == &#34;e2e&#34;)].user.password}&#39;</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>kubectl config view -o <span style=color:#b8860b>jsonpath</span><span style=color:#666>=</span><span style=color:#b44>&#39;{.users[].name}&#39;</span>    <span style=color:#080;font-style:italic># den ersten Benutzer anzeigen</span>
</span></span><span style=display:flex><span>kubectl config view -o <span style=color:#b8860b>jsonpath</span><span style=color:#666>=</span><span style=color:#b44>&#39;{.users[*].name}&#39;</span>    <span style=color:#080;font-style:italic># eine Liste der Benutzer erhalten</span>
</span></span><span style=display:flex><span>kubectl config current-context                       <span style=color:#080;font-style:italic># den aktuellen Kontext anzeigen</span>
</span></span><span style=display:flex><span>kubectl config use-context my-cluster-name           <span style=color:#080;font-style:italic># Setzen Sie den Standardkontext auf my-cluster-name</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#080;font-style:italic># Fügen Sie Ihrer kubeconf einen neuen Cluster hinzu, der basic auth unterstützt</span>
</span></span><span style=display:flex><span>kubectl config set-credentials kubeuser/foo.kubernetes.com --username<span style=color:#666>=</span>kubeuser --password<span style=color:#666>=</span>kubepassword
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#080;font-style:italic># Legen Sie einen Kontext fest, indem Sie einen bestimmten Benutzernamen und einen bestimmten Namespace verwenden.</span>
</span></span><span style=display:flex><span>kubectl config set-context gce --user<span style=color:#666>=</span>cluster-admin --namespace<span style=color:#666>=</span>foo <span style=color:#b62;font-weight:700>\
</span></span></span><span style=display:flex><span><span style=color:#b62;font-weight:700></span>  <span style=color:#666>&amp;&amp;</span> kubectl config use-context gce
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>kubectl config <span style=color:#a2f>unset</span> users.foo                       <span style=color:#080;font-style:italic># delete user foo</span>
</span></span></code></pre></div><h2 id=apply>Apply</h2><p><code>apply</code> verwaltet Anwendungen durch Dateien, die Kubernetes-Ressourcen definieren. Es erstellt und aktualisiert Ressourcen in einem Cluster durch Ausführen von <code>kubectl apply</code>. Dies ist die empfohlene Methode zur Verwaltung von Kubernetes-Anwendungen in der Produktion. Lesen Sie die ausführliche <a href=https://kubectl.docs.kubernetes.io>Kubectl Dokumentation</a> für weitere Informationen.</p><h2 id=objekte-erstellen>Objekte erstellen</h2><p>Kubernetes Manifeste können in Json oder Yaml definiert werden. Die Dateierweiterungen <code>.yaml</code>,
<code>.yml</code>, und <code>.json</code> können verwendet werden.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>kubectl apply -f ./my-manifest.yaml            <span style=color:#080;font-style:italic># Ressource(n) erstellen</span>
</span></span><span style=display:flex><span>kubectl apply -f ./my1.yaml -f ./my2.yaml      <span style=color:#080;font-style:italic># aus mehreren Dateien erstellen</span>
</span></span><span style=display:flex><span>kubectl apply -f ./dir                         <span style=color:#080;font-style:italic># Erstellen Sie Ressourcen in allen Manifestdateien in Verzeichnis</span>
</span></span><span style=display:flex><span>kubectl apply -f https://git.io/vPieo          <span style=color:#080;font-style:italic># Ressource(n) aus URL erstellen</span>
</span></span><span style=display:flex><span>kubectl create deployment nginx --image<span style=color:#666>=</span>nginx  <span style=color:#080;font-style:italic># Starten Sie eine einzelne Instanz von Nginx</span>
</span></span><span style=display:flex><span>kubectl explain pods,svc                       <span style=color:#080;font-style:italic># Zeigen Sie die Dokumentation für Pod und SVC Manifeste an</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#080;font-style:italic># Erstellen Sie mehrere YAML-Objekte aus stdin</span>
</span></span><span style=display:flex><span>cat <span style=color:#b44>&lt;&lt;EOF | kubectl apply -f -
</span></span></span><span style=display:flex><span><span style=color:#b44>apiVersion: v1
</span></span></span><span style=display:flex><span><span style=color:#b44>kind: Pod
</span></span></span><span style=display:flex><span><span style=color:#b44>metadata:
</span></span></span><span style=display:flex><span><span style=color:#b44>  name: busybox-sleep
</span></span></span><span style=display:flex><span><span style=color:#b44>spec:
</span></span></span><span style=display:flex><span><span style=color:#b44>  containers:
</span></span></span><span style=display:flex><span><span style=color:#b44>  - name: busybox
</span></span></span><span style=display:flex><span><span style=color:#b44>    image: busybox
</span></span></span><span style=display:flex><span><span style=color:#b44>    args:
</span></span></span><span style=display:flex><span><span style=color:#b44>    - sleep
</span></span></span><span style=display:flex><span><span style=color:#b44>    - &#34;1000000&#34;
</span></span></span><span style=display:flex><span><span style=color:#b44>---
</span></span></span><span style=display:flex><span><span style=color:#b44>apiVersion: v1
</span></span></span><span style=display:flex><span><span style=color:#b44>kind: Pod
</span></span></span><span style=display:flex><span><span style=color:#b44>metadata:
</span></span></span><span style=display:flex><span><span style=color:#b44>  name: busybox-sleep-less
</span></span></span><span style=display:flex><span><span style=color:#b44>spec:
</span></span></span><span style=display:flex><span><span style=color:#b44>  containers:
</span></span></span><span style=display:flex><span><span style=color:#b44>  - name: busybox
</span></span></span><span style=display:flex><span><span style=color:#b44>    image: busybox
</span></span></span><span style=display:flex><span><span style=color:#b44>    args:
</span></span></span><span style=display:flex><span><span style=color:#b44>    - sleep
</span></span></span><span style=display:flex><span><span style=color:#b44>    - &#34;1000&#34;
</span></span></span><span style=display:flex><span><span style=color:#b44>EOF</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#080;font-style:italic># Erstellen Sie ein &#34;Secret&#34; mit mehreren Schlüsseln</span>
</span></span><span style=display:flex><span>cat <span style=color:#b44>&lt;&lt;EOF | kubectl apply -f -
</span></span></span><span style=display:flex><span><span style=color:#b44>apiVersion: v1
</span></span></span><span style=display:flex><span><span style=color:#b44>kind: Secret
</span></span></span><span style=display:flex><span><span style=color:#b44>metadata:
</span></span></span><span style=display:flex><span><span style=color:#b44>  name: mysecret
</span></span></span><span style=display:flex><span><span style=color:#b44>type: Opaque
</span></span></span><span style=display:flex><span><span style=color:#b44>data:
</span></span></span><span style=display:flex><span><span style=color:#b44>  password: $(echo -n &#34;s33msi4&#34; | base64 -w0)
</span></span></span><span style=display:flex><span><span style=color:#b44>  username: $(echo -n &#34;jane&#34; | base64 -w0)
</span></span></span><span style=display:flex><span><span style=color:#b44>EOF</span>
</span></span></code></pre></div><h2 id=suchen-und-anzeigen-von-ressourcen>Suchen und Anzeigen von Ressourcen</h2><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#080;font-style:italic># Get Befehle mit grundlegenden Ausgaben</span>
</span></span><span style=display:flex><span>kubectl get services                          <span style=color:#080;font-style:italic># Listen Sie alle Dienste im Namespace auf</span>
</span></span><span style=display:flex><span>kubectl get pods --all-namespaces             <span style=color:#080;font-style:italic># Listen Sie alle Pods in allen Namespaces auf</span>
</span></span><span style=display:flex><span>kubectl get pods -o wide                      <span style=color:#080;font-style:italic># Listen Sie alle Pods im Namespace mit weiteren Details auf</span>
</span></span><span style=display:flex><span>kubectl get deployment my-dep                 <span style=color:#080;font-style:italic># Listen Sie eine bestimmte Bereitstellung auf</span>
</span></span><span style=display:flex><span>kubectl get pods                              <span style=color:#080;font-style:italic># Listen Sie alle Pods im Namespace auf</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#080;font-style:italic># Describe Befehle mit ausführlicher Ausgabe</span>
</span></span><span style=display:flex><span>kubectl describe nodes my-node
</span></span><span style=display:flex><span>kubectl describe pods my-pod
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>kubectl get services --sort-by<span style=color:#666>=</span>.metadata.name <span style=color:#080;font-style:italic># Listen Sie Dienste nach Namen sortiert auf</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#080;font-style:italic># Listen Sie Pods Sortiert nach Restart Count auf</span>
</span></span><span style=display:flex><span>kubectl get pods --sort-by<span style=color:#666>=</span><span style=color:#b44>&#39;.status.containerStatuses[0].restartCount&#39;</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#080;font-style:italic># Erhalten Sie die Versionsbezeichnung aller Pods mit der Bezeichnung app=cassandra</span>
</span></span><span style=display:flex><span>kubectl get pods --selector<span style=color:#666>=</span><span style=color:#b8860b>app</span><span style=color:#666>=</span>cassandra -o <span style=color:#b62;font-weight:700>\
</span></span></span><span style=display:flex><span><span style=color:#b62;font-weight:700></span>  <span style=color:#b8860b>jsonpath</span><span style=color:#666>=</span><span style=color:#b44>&#39;{.items[*].metadata.labels.version}&#39;</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#080;font-style:italic># Alle Worker-Knoten abrufen (verwenden Sie einen Selektor, um Ergebnisse auszuschließen,</span>
</span></span><span style=display:flex><span><span style=color:#080;font-style:italic># die ein Label mit dem Namen &#39;node-role.kubernetes.io/master&#39; tragen).</span>
</span></span><span style=display:flex><span>kubectl get node --selector<span style=color:#666>=</span><span style=color:#b44>&#39;!node-role.kubernetes.io/master&#39;</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#080;font-style:italic># Zeigen Sie alle laufenden Pods im Namespace an</span>
</span></span><span style=display:flex><span>kubectl get pods --field-selector<span style=color:#666>=</span>status.phase<span style=color:#666>=</span>Running
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#080;font-style:italic># Rufen Sie die externe IP aller Nodes ab</span>
</span></span><span style=display:flex><span>kubectl get nodes -o <span style=color:#b8860b>jsonpath</span><span style=color:#666>=</span><span style=color:#b44>&#39;{.items[*].status.addresses[?(@.type==&#34;ExternalIP&#34;)].address}&#39;</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#080;font-style:italic># Listet die Namen der Pods auf, die zu einem bestimmten RC gehören</span>
</span></span><span style=display:flex><span><span style=color:#080;font-style:italic># Der Befehl &#34;jq&#34; ist nützlich für Transformationen, die für jsonpath zu komplex sind. Sie finden ihn unter https://stedolan.github.io/jq/</span>
</span></span><span style=display:flex><span><span style=color:#b8860b>sel</span><span style=color:#666>=</span><span style=color:#b68;font-weight:700>${</span><span style=color:#a2f;font-weight:700>$(</span>kubectl get rc my-rc --output<span style=color:#666>=</span>json | jq -j <span style=color:#b44>&#39;.spec.selector | to_entries | .[] | &#34;\(.key)=\(.value),&#34;&#39;</span><span style=color:#a2f;font-weight:700>)</span>%?<span style=color:#b68;font-weight:700>}</span>
</span></span><span style=display:flex><span><span style=color:#a2f>echo</span> <span style=color:#a2f;font-weight:700>$(</span>kubectl get pods --selector<span style=color:#666>=</span><span style=color:#b8860b>$sel</span> --output<span style=color:#666>=</span><span style=color:#b8860b>jsonpath</span><span style=color:#666>={</span>.items..metadata.name<span style=color:#666>}</span><span style=color:#a2f;font-weight:700>)</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#080;font-style:italic># Labels für alle Pods anzeigen (oder jedes andere Kubernetes-Objekt, das labelling unterstützt)</span>
</span></span><span style=display:flex><span><span style=color:#080;font-style:italic># Verwendet auch &#34;jq&#34;</span>
</span></span><span style=display:flex><span><span style=color:#a2f;font-weight:700>for</span> item in <span style=color:#a2f;font-weight:700>$(</span> kubectl get pod --output<span style=color:#666>=</span>name<span style=color:#a2f;font-weight:700>)</span>; <span style=color:#a2f;font-weight:700>do</span> <span style=color:#a2f>printf</span> <span style=color:#b44>&#34;Labels for %s\n&#34;</span> <span style=color:#b44>&#34;</span><span style=color:#b8860b>$item</span><span style=color:#b44>&#34;</span> | grep --color -E <span style=color:#b44>&#39;[^/]+$&#39;</span> <span style=color:#666>&amp;&amp;</span> kubectl get <span style=color:#b44>&#34;</span><span style=color:#b8860b>$item</span><span style=color:#b44>&#34;</span> --output<span style=color:#666>=</span>json | jq -r -S <span style=color:#b44>&#39;.metadata.labels | to_entries | .[] | &#34; \(.key)=\(.value)&#34;&#39;</span> 2&gt;/dev/null; <span style=color:#a2f>printf</span> <span style=color:#b44>&#34;\n&#34;</span>; <span style=color:#a2f;font-weight:700>done</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#080;font-style:italic># Prüfen Sie, welche Nodes bereit sind</span>
</span></span><span style=display:flex><span><span style=color:#b8860b>JSONPATH</span><span style=color:#666>=</span><span style=color:#b44>&#39;{range .items[*]}{@.metadata.name}:{range @.status.conditions[*]}{@.type}={@.status};{end}{end}&#39;</span> <span style=color:#b62;font-weight:700>\
</span></span></span><span style=display:flex><span><span style=color:#b62;font-weight:700></span> <span style=color:#666>&amp;&amp;</span> kubectl get nodes -o <span style=color:#b8860b>jsonpath</span><span style=color:#666>=</span><span style=color:#b44>&#34;</span><span style=color:#b8860b>$JSONPATH</span><span style=color:#b44>&#34;</span> | grep <span style=color:#b44>&#34;Ready=True&#34;</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#080;font-style:italic># Listen Sie alle Secrets auf, die derzeit von einem Pod verwendet werden</span>
</span></span><span style=display:flex><span>kubectl get pods -o json | jq <span style=color:#b44>&#39;.items[].spec.containers[].env[]?.valueFrom.secretKeyRef.name&#39;</span> | grep -v null | sort | uniq
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#080;font-style:italic># Ereignisse nach Zeitstempel sortiert auflisten</span>
</span></span><span style=display:flex><span>kubectl get events --sort-by<span style=color:#666>=</span>.metadata.creationTimestamp
</span></span></code></pre></div><h2 id=ressourcen-aktualisieren>Ressourcen aktualisieren</h2><p>Ab Version 1.11 ist das <code>rolling-update</code> veraltet (Lesen Sie <a href=https://github.com/kubernetes/kubernetes/blob/master/CHANGELOG/CHANGELOG-1.11.md>CHANGELOG-1.11.md</a> für weitere Informationen), verwenden Sie stattdessen <code>rollout</code>.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>kubectl <span style=color:#a2f>set</span> image deployment/frontend <span style=color:#b8860b>www</span><span style=color:#666>=</span>image:v2               <span style=color:#080;font-style:italic># Fortlaufende Aktualisierung der &#34;www&#34; Container der &#34;Frontend&#34;-Bereitstellung, Aktualisierung des Images</span>
</span></span><span style=display:flex><span>kubectl rollout undo deployment/frontend                         <span style=color:#080;font-style:italic># Rollback zur vorherigen Bereitstellung</span>
</span></span><span style=display:flex><span>kubectl rollout status -w deployment/frontend                    <span style=color:#080;font-style:italic># Beobachten Sie den fortlaufenden Aktualisierungsstatus der &#34;Frontend&#34;-Bereitstellung bis zum Abschluss.</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#080;font-style:italic># veraltet ab Version 1.11</span>
</span></span><span style=display:flex><span>kubectl rolling-update frontend-v1 -f frontend-v2.json           <span style=color:#080;font-style:italic># (veraltet) Fortlaufendes Update der Pods von Frontend-v1</span>
</span></span><span style=display:flex><span>kubectl rolling-update frontend-v1 frontend-v2 --image<span style=color:#666>=</span>image:v2  <span style=color:#080;font-style:italic># (veraltet) Ändern Sie den Namen der Ressource und aktualisieren Sie das Image</span>
</span></span><span style=display:flex><span>kubectl rolling-update frontend --image<span style=color:#666>=</span>image:v2                 <span style=color:#080;font-style:italic># (veraltet) Aktualisieren Sie das Pod-Image des Frontends</span>
</span></span><span style=display:flex><span>kubectl rolling-update frontend-v1 frontend-v2 --rollback        <span style=color:#080;font-style:italic># (veraltet) Bricht das laufende Rollout ab</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>cat pod.json | kubectl replace -f -                              <span style=color:#080;font-style:italic># Ersetzen Sie einen Pod basierend auf der in std übergebenen JSON</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#080;font-style:italic># Ersetzen, löschen und Ressource neu erstellen. Dies führt zu einer temprären Unerreichbarkeit des Dienstes.</span>
</span></span><span style=display:flex><span>kubectl replace --force -f ./pod.json
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#080;font-style:italic># Erstellen Sie einen Dienst für eien replizierten nginx Webserver, der an Port 80 und in den Containern an Port 8000 lauscht</span>
</span></span><span style=display:flex><span>kubectl expose rc nginx --port<span style=color:#666>=</span><span style=color:#666>80</span> --target-port<span style=color:#666>=</span><span style=color:#666>8000</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#080;font-style:italic># Aktualisieren Sie die Image-Version (Tag) eines Einzelcontainer-Pods auf Version 4</span>
</span></span><span style=display:flex><span>kubectl get pod mypod -o yaml | sed <span style=color:#b44>&#39;s/\(image: myimage\):.*$/\1:v4/&#39;</span> | kubectl replace -f -
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>kubectl label pods my-pod new-label<span style=color:#666>=</span>awesome                      <span style=color:#080;font-style:italic># Label hinzufügen</span>
</span></span><span style=display:flex><span>kubectl annotate pods my-pod icon-url<span style=color:#666>=</span>http://goo.gl/XXBTWq       <span style=color:#080;font-style:italic># Eine Anmerkung hinzufügen</span>
</span></span><span style=display:flex><span>kubectl autoscale deployment foo --min<span style=color:#666>=</span><span style=color:#666>2</span> --max<span style=color:#666>=</span><span style=color:#666>10</span>                <span style=color:#080;font-style:italic># Automatische Skalierung einer Bereitstellung &#34;Foo&#34;</span>
</span></span></code></pre></div><h2 id=ressourcen-patchen>Ressourcen patchen</h2><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>kubectl patch node k8s-node-1 -p <span style=color:#b44>&#39;{&#34;spec&#34;:{&#34;unschedulable&#34;:true}}&#39;</span> <span style=color:#080;font-style:italic># Aktualisieren Sie einen Node teilweise</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#080;font-style:italic># Aktualisieren Sie das Image eines Containers; spec.containers[*].name ist erforderlich, da es sich um einen Merge-Schlüssel handelt</span>
</span></span><span style=display:flex><span>kubectl patch pod valid-pod -p <span style=color:#b44>&#39;{&#34;spec&#34;:{&#34;containers&#34;:[{&#34;name&#34;:&#34;kubernetes-serve-hostname&#34;,&#34;image&#34;:&#34;new image&#34;}]}}&#39;</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#080;font-style:italic># Aktualisieren Sie das Image eines Containers mithilfe eines Json-Patches mit Positionsarrays</span>
</span></span><span style=display:flex><span>kubectl patch pod valid-pod --type<span style=color:#666>=</span><span style=color:#b44>&#39;json&#39;</span> -p<span style=color:#666>=</span><span style=color:#b44>&#39;[{&#34;op&#34;: &#34;replace&#34;, &#34;path&#34;: &#34;/spec/containers/0/image&#34;, &#34;value&#34;:&#34;new image&#34;}]&#39;</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#080;font-style:italic># Deaktivieren Sie eine Bereitstellung von livenessProbe durch verwenden eines Json-Patches mit Positionsarrays</span>
</span></span><span style=display:flex><span>kubectl patch deployment valid-deployment  --type json   -p<span style=color:#666>=</span><span style=color:#b44>&#39;[{&#34;op&#34;: &#34;remove&#34;, &#34;path&#34;: &#34;/spec/template/spec/containers/0/livenessProbe&#34;}]&#39;</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#080;font-style:italic># Fügen Sie einem Positionsarray ein neues Element hinzu</span>
</span></span><span style=display:flex><span>kubectl patch sa default --type<span style=color:#666>=</span><span style=color:#b44>&#39;json&#39;</span> -p<span style=color:#666>=</span><span style=color:#b44>&#39;[{&#34;op&#34;: &#34;add&#34;, &#34;path&#34;: &#34;/secrets/1&#34;, &#34;value&#34;: {&#34;name&#34;: &#34;whatever&#34; } }]&#39;</span>
</span></span></code></pre></div><h2 id=ressourcen-bearbeiten>Ressourcen bearbeiten</h2><p>Bearbeiten Sie eine beliebige API-Ressource in einem Editor.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>kubectl edit svc/docker-registry                      <span style=color:#080;font-style:italic># Bearbeiten Sie den Dienst docker-registry</span>
</span></span><span style=display:flex><span><span style=color:#b8860b>KUBE_EDITOR</span><span style=color:#666>=</span><span style=color:#b44>&#34;nano&#34;</span> kubectl edit svc/docker-registry   <span style=color:#080;font-style:italic># Verwenden Sie einen alternativen Texteditor</span>
</span></span></code></pre></div><h2 id=ressourcen-skalieren>Ressourcen skalieren</h2><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>kubectl scale --replicas<span style=color:#666>=</span><span style=color:#666>3</span> rs/foo                                 <span style=color:#080;font-style:italic># Skaliert ein Replikat mit dem Namen &#39;foo&#39; auf 3</span>
</span></span><span style=display:flex><span>kubectl scale --replicas<span style=color:#666>=</span><span style=color:#666>3</span> -f foo.yaml                            <span style=color:#080;font-style:italic># Skaliert eine in &#34;foo.yaml&#34; angegebene Ressource auf 3</span>
</span></span><span style=display:flex><span>kubectl scale --current-replicas<span style=color:#666>=</span><span style=color:#666>2</span> --replicas<span style=color:#666>=</span><span style=color:#666>3</span> deployment/mysql  <span style=color:#080;font-style:italic># Wenn die aktuelle Konfiguration der Replikation von mysql 2 ist, skaliert mysql auf 3</span>
</span></span><span style=display:flex><span>kubectl scale --replicas<span style=color:#666>=</span><span style=color:#666>5</span> rc/foo rc/bar rc/baz                   <span style=color:#080;font-style:italic># Skaliert mehrere Replikationscontroller</span>
</span></span></code></pre></div><h2 id=ressourcen-löschen>Ressourcen löschen</h2><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>kubectl delete -f ./pod.json                                              <span style=color:#080;font-style:italic># Löscht einen Pod mit dem in pod.json angegebenen Typ und Namen</span>
</span></span><span style=display:flex><span>kubectl delete pod,service baz foo                                        <span style=color:#080;font-style:italic># Löscht Pods und Services mit den gleichen Namen &#34;baz&#34; und &#34;foo&#34;</span>
</span></span><span style=display:flex><span>kubectl delete pods,services -l <span style=color:#b8860b>name</span><span style=color:#666>=</span>myLabel                              <span style=color:#080;font-style:italic># Löscht Pods und Services mit dem Label name=myLabel</span>
</span></span><span style=display:flex><span>kubectl -n my-ns delete po,svc --all                                      <span style=color:#080;font-style:italic># Löscht alle Pods und Dienste, im Namespace my-ns</span>
</span></span></code></pre></div><h2 id=interaktion-mit-laufenden-pods>Interaktion mit laufenden Pods</h2><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>kubectl logs my-pod                                 <span style=color:#080;font-style:italic># Pod-Logdatei ausgeben (stdout)</span>
</span></span><span style=display:flex><span>kubectl logs my-pod --previous                      <span style=color:#080;font-style:italic># Pod-Logdatei für eine vorherige Instantiierung eines Containers ausgeben (stdout)</span>
</span></span><span style=display:flex><span>kubectl logs my-pod -c my-container                 <span style=color:#080;font-style:italic># Pod Container-Logdatei ausgeben (stdout, multi-container case)</span>
</span></span><span style=display:flex><span>kubectl logs my-pod -c my-container --previous      <span style=color:#080;font-style:italic># Pod Container-Logdatei für eine vorherige Instantiierung eines Containers ausgeben (stdout, multi-container case)</span>
</span></span><span style=display:flex><span>kubectl logs -f my-pod                              <span style=color:#080;font-style:italic># Pod-Logdatei streamen (stdout)</span>
</span></span><span style=display:flex><span>kubectl logs -f my-pod -c my-container              <span style=color:#080;font-style:italic># Pod Container-Logdatei streamen (stdout, multi-container case)</span>
</span></span><span style=display:flex><span>kubectl run -i --tty busybox --image<span style=color:#666>=</span>busybox -- sh  <span style=color:#080;font-style:italic># Pod als interaktive Shell ausführen</span>
</span></span><span style=display:flex><span>kubectl attach my-pod -i                            <span style=color:#080;font-style:italic># An laufenden Container anhängen</span>
</span></span><span style=display:flex><span>kubectl port-forward my-pod 5000:6000               <span style=color:#080;font-style:italic># Lauscht auf Port 5000 auf dem lokalen Computer und leitet den Port 6000 auf my-pod weiter</span>
</span></span><span style=display:flex><span>kubectl <span style=color:#a2f>exec</span> my-pod -- ls /                         <span style=color:#080;font-style:italic># Befehl in vorhandenem Pod ausführen (1 Container)</span>
</span></span><span style=display:flex><span>kubectl <span style=color:#a2f>exec</span> my-pod -c my-container -- ls /         <span style=color:#080;font-style:italic># Befehl in vorhandenem Pod ausführen (Mehrere Container)</span>
</span></span><span style=display:flex><span>kubectl top pod POD_NAME --containers               <span style=color:#080;font-style:italic># Zeigt Metriken für einen bestimmten Pod und seine Container an</span>
</span></span></code></pre></div><h2 id=mit-nodes-und-clustern-interagieren>Mit Nodes und Clustern interagieren</h2><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>kubectl cordon my-node                                                <span style=color:#080;font-style:italic># Markiert &#34;my-node&#34; als unplanbar</span>
</span></span><span style=display:flex><span>kubectl drain my-node                                                 <span style=color:#080;font-style:italic># Entleert &#34;my-node&#34; zur Vorbereitung der Wartung</span>
</span></span><span style=display:flex><span>kubectl uncordon my-node                                              <span style=color:#080;font-style:italic># Markiert &#34;my-node&#34; als planbar</span>
</span></span><span style=display:flex><span>kubectl top node my-node                                              <span style=color:#080;font-style:italic># Metriken für einen bestimmten Node anzeigen</span>
</span></span><span style=display:flex><span>kubectl cluster-info                                                  <span style=color:#080;font-style:italic># Adressen des Masters und der Services anzeigen</span>
</span></span><span style=display:flex><span>kubectl cluster-info dump                                             <span style=color:#080;font-style:italic># Ausgabe des aktuellen Clusterstatus in stdout</span>
</span></span><span style=display:flex><span>kubectl cluster-info dump --output-directory<span style=color:#666>=</span>/pfad/zum/cluster-status <span style=color:#080;font-style:italic># Aktuellen Cluster-Status in /pfad/zum/cluster-status ausgeben</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#080;font-style:italic># Wenn bereits ein Taint mit diesem Key und Effekt vorhanden ist, wird sein Wert wie angegeben ersetzt.</span>
</span></span><span style=display:flex><span>kubectl taint nodes foo <span style=color:#b8860b>dedicated</span><span style=color:#666>=</span>special-user:NoSchedule
</span></span></code></pre></div><h3 id=ressourcentypen>Ressourcentypen</h3><p>Liste aller unterstützten Ressourcentypen mit ihren Kurzbezeichnungen, der <a href=/docs/concepts/overview/kubernetes-api/#api-groups>API-Gruppe</a>, unabhängig davon ob sie im Namespace liegen, und der <a href=/docs/concepts/overview/working-with-objects/kubernetes-objects>Art</a>:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>kubectl api-resources
</span></span></code></pre></div><p>Andere Operationen zum Erkunden von API-Ressourcen:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>kubectl api-resources --namespaced<span style=color:#666>=</span><span style=color:#a2f>true</span>      <span style=color:#080;font-style:italic># Alle Ressourcen im Namespace</span>
</span></span><span style=display:flex><span>kubectl api-resources --namespaced<span style=color:#666>=</span><span style=color:#a2f>false</span>     <span style=color:#080;font-style:italic># Alle nicht im Namespace befindlichen Ressourcen</span>
</span></span><span style=display:flex><span>kubectl api-resources -o name                <span style=color:#080;font-style:italic># Alle Ressourcen mit einfacher Ausgabe (nur der Ressourcenname)</span>
</span></span><span style=display:flex><span>kubectl api-resources -o wide                <span style=color:#080;font-style:italic># Alle Ressourcen mit erweiterter Ausgabe (aka &#34;Wide&#34;)</span>
</span></span><span style=display:flex><span>kubectl api-resources --verbs<span style=color:#666>=</span>list,get       <span style=color:#080;font-style:italic># Alle Ressourcen, die &#34;list&#34; und &#34;get&#34; Verben unterstützen anfordern</span>
</span></span><span style=display:flex><span>kubectl api-resources --api-group<span style=color:#666>=</span>extensions <span style=color:#080;font-style:italic># Alle Ressourcen in der API-Gruppe &#34;extensions&#34;</span>
</span></span></code></pre></div><h3 id=ausgabe-formatieren>Ausgabe formatieren</h3><p>Um Details in einem bestimmten Format an Ihr Terminalfenster auszugeben, können Sie entweder das <code>-o</code> oder <code>--output</code> Flag zu einem unterstützten <code>kubectl</code> Befehl anhängens.</p><table><thead><tr><th>Ausgabeformat</th><th>Beschreibung</th></tr></thead><tbody><tr><td><code>-o=custom-columns=&lt;spec></code></td><td>Ausgabe einer Tabelle mit einer durch Kommas getrennten Liste benutzerdefinierter Spalten</td></tr><tr><td><code>-o=custom-columns-file=&lt;dateiname></code></td><td>Drucken Sie eine Tabelle mit der benutzerdefinierten Spaltenvorlage in der <code>&lt;dateiname></code> Datei</td></tr><tr><td><code>-o=json</code></td><td>Ausgabe eines JSON-formatierten API-Objekts</td></tr><tr><td><code>-o=jsonpath=&lt;template></code></td><td>Ausgabe der in einem <a href=/docs/reference/kubectl/jsonpath>jsonpath</a>-Ausdruck definierten Felder</td></tr><tr><td><code>-o=jsonpath-file=&lt;dateiname></code></td><td>Ausgabe der in einem <a href=/docs/reference/kubectl/jsonpath>jsonpath</a>-Ausdruck definierten Felder in der <code>&lt;dateiname></code> Datei</td></tr><tr><td><code>-o=name</code></td><td>Ausgabe von nur dem Ressourcennamen und nichts anderes</td></tr><tr><td><code>-o=wide</code></td><td>Ausgabe im Klartextformat mit zusätzlichen Informationen. Bei Pods ist der Node-Name enthalten</td></tr><tr><td><code>-o=yaml</code></td><td>Gibt ein YAML-formatiertes API-Objekt aus</td></tr></tbody></table><h3 id=kubectl-ausgabe-ausführlichkeit-und-debugging>Kubectl Ausgabe Ausführlichkeit und Debugging</h3><p>Die Ausführlichkeit von Kubectl wird mit den Flags <code>-v</code> oder <code>--v</code> gesteuert, gefolgt von einer Ganzzahl, die die Protokollebene darstellt. Allgemeine Protokollierungskonventionen für Kubernetes und die zugehörigen Protokollebenen werden <a href=https://github.com/kubernetes/community/blob/master/contributors/devel/sig-instrumentation/logging.md>hier</a> beschrieben.</p><table><thead><tr><th>Ausführlichkeit</th><th>Beschreibung</th></tr></thead><tbody><tr><td><code>--v=0</code></td><td>Allgemein nützlich, damit dies für den Bediener IMMER sichtbar ist.</td></tr><tr><td><code>--v=1</code></td><td>Eine vernünftige Standardprotokollebene, wenn Sie keine Ausführlichkeit wünschen.</td></tr><tr><td><code>--v=2</code></td><td>Nützliche Informationen zum stabilen Status des Dienstes und wichtige Protokollnachrichten, die möglicherweise zu erheblichen Änderungen im System führen. Dies ist die empfohlene Standardprotokollebene für die meisten Systeme.</td></tr><tr><td><code>--v=3</code></td><td>Erweiterte Informationen zu Änderungen.</td></tr><tr><td><code>--v=4</code></td><td>Debug-Level-Ausführlichkeit.</td></tr><tr><td><code>--v=6</code></td><td>Angeforderte Ressourcen anzeigen</td></tr><tr><td><code>--v=7</code></td><td>HTTP-Anforderungsheader anzeigen</td></tr><tr><td><code>--v=8</code></td><td>HTTP-Anforderungsinhalt anzeigen</td></tr><tr><td><code>--v=9</code></td><td>HTTP-Anforderungsinhalt anzeigen, ohne den Inhalt zu kürzen.</td></tr></tbody></table><h2 id=nächste-schritte>Nächste Schritte</h2><ul><li><p>Lernen Sie mehr im <a href=/docs/reference/kubectl/overview/>Überblick auf kubectl</a>.</p></li><li><p>Erkunden Sie <a href=/docs/reference/kubectl/kubectl/>kubectl</a> Optionen.</p></li><li><p>Und ebenfalls die <a href=/docs/reference/kubectl/conventions/>kubectl Nutzungskonventionen</a> um zu verstehen, wie man es in wiederverwendbaren Skripten verwendet.</p></li><li><p>Entdecken Sie mehr Community <a href=https://github.com/dennyzhang/cheatsheet-kubernetes-A4>kubectl Spickzettel</a>.</p></li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-4f002b9458521ca7afd32176fd590646>6.10 - Tools</h1><p>Kubernetes enthält mehrere integrierte Tools, die Ihnen bei der Arbeit mit dem Kubernetes System helfen.</p><h2 id=kubectl>Kubectl</h2><p><a href=/docs/tasks/tools/install-kubectl/><code>kubectl</code></a> ist ein Kommandozeilenprogramm für Kubernetes. Es steuert den Kubernetes Clustermanager.</p><h2 id=kubeadm>Kubeadm</h2><p><a href=/docs/setup/independent/install-kubeadm/><code>kubeadm</code></a> ist ein Kommandozeilenprogramm zur einfachen Bereitstellung eines sicheren Kubernetes-Clusters auf physischen oder Cloud-Servern oder virtuellen Maschinen (derzeit in alpha).</p><h2 id=kubefed>Kubefed</h2><p><a href=/docs/tasks/federation/set-up-cluster-federation-kubefed/><code>kubefed</code></a> ist ein Kommandozeilenprogramm um Ihnen bei der Verwaltung Ihrer Verbundcluster zu helfen.</p><h2 id=minikube>Minikube</h2><p><a href=/docs/tasks/tools/install-minikube/><code>minikube</code></a> ist ein Tool, das es Ihnen einfach macht, einen Kubernetes-Cluster mit einem einzigen Knoten lokal auf Ihrer Workstation für Entwicklungs- und Testzwecke auszuführen.</p><h2 id=dashboard>Dashboard</h2><p><a href=/docs/tasks/access-application-cluster/web-ui-dashboard/><code>Dashboard</code></a>, die webbasierte Benutzeroberfläche von Kubernetes ermöglicht es Ihnen containerisierte Anwendungen in einem Kubernetes-Cluster bereitzustellen Fehler zu beheben und den Cluster und seine Ressourcen selbst zu verwalten.</p><h2 id=helm>Helm</h2><p><a href=https://github.com/kubernetes/helm><code>Kubernetes Helm</code></a> ist ein Tool zur Verwaltung von Paketen mit vorkonfigurierten Kubernetes-Ressourcen, auch bekannt als Kubernetes charts.</p><p>Verwenden Sie Helm um:</p><ul><li>Beliebte Software verpackt als Kubernetes charts zu finden und zu verwenden</li><li>Ihre eigenen Applikationen als Kubernetes charts zu teilen</li><li>Reproduzierbare Builds Ihrer Kubernetes Anwendungen zu erstellen</li><li>Intelligenten Verwaltung von Ihren Kubernetes manifest files</li><li>Verwalten von Versionen von Helm Paketen</li></ul><h2 id=kompose>Kompose</h2><p><a href=https://github.com/kubernetes-incubator/kompose><code>Kompose</code></a> ist ein Tool, das Docker Compose Benutzern hilft, nach Kubernetes zu wechseln.</p><p>Verwenden Sie Kompose um:</p><ul><li>Ein Docker Compose Datei in Kubernetes Objekte zu übersetzen</li><li>Von Ihrer lokalen Docker Entwicklung auf eine Kubernetes verwaltete Entwicklung zu wechseln</li><li>v1 oder v2 Docker Compose <code>yaml</code> Dateien oder <a href=https://docs.docker.com/compose/bundles/>Distributed Application Bundles</a> zu konvertieren</li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-4985cb55ddfb184639d767ec54b9f0f7>7 - Zur Kubernetes-Dokumentation beitragen</h1><p>Wenn Sie an der Dokumentation oder der Website von Kubernetes mitwirken möchten, freuen wir uns über Ihre Hilfe!
Jeder kann seinen Beitrag leisten, unabhängig davon ob Sie neu im Projekt sind oder schon lange dabei sind, und ob Sie sich als
Entwickler, Endbenutzer oder einfach jemanden, der es einfach nicht aushält, Tippfehler zu sehen sehen.</p><p>Weitere Möglichkeiten, sich in der Kubernetes-Community zu engagieren oder mehr über uns zu erfahren, finden Sie auf der <a href=/community/>Kubernetes-Community-Seite</a>.
Informationen zum Handbuch zur Dokumentation von Kubernetes finden Sie im <a href=/docs/contribute/style/style-guide/>Gestaltungshandbuch</a>.</p><h2 id=arten-von-mitwirkenden>Arten von Mitwirkenden</h2><ul><li>Ein <em>Member</em> der Kubernetes Organisation, hat die <a href=/docs/contribute/start#sign-the-cla>CLA unterzeichnet</a>
und etwas Zeit und Energie zum Projekt beigetragen.
Siehe <a href=https://github.com/kubernetes/community/blob/master/community-membership.md>Community-Mitgliedschaft</a> für spezifische Kriterien bezüglich der Mitgliedschaft.</li><li>Ein SIG Docs <em>Reviewer</em> ist ein Mitglied der Kubernetes-Organisation, das Interesse an der Überprüfung von
Dokumentationsanfragen geäußert hat und von einem SIG Docs Approver zu der entsprechenden Github-Gruppe
und den <code>OWNERS</code>-Dateien im Github-Repository hinzugefügt wurde.</li><li>Ein SIG Docs <em>approver</em> ist ein Mitglied mit gutem Ansehen, das sich kontinuierlich für das Projekt engagiert hat.
Ein Approver kann Pull-Anfragen zusammenführen und Inhalte im Namen der Kubernetes-Organisation veröffentlichen.
Approver können SIG Docs auch in der größeren Kubernetes-Community vertreten. Einige der Aufgaben eines SIG Docs Approvers, wie z.B. die Koordination einer Freigabe, erfordern einen erheblichen Zeitaufwand.</li></ul><h2 id=möglichkeiten-einen-beitrag-zu-leisten>Möglichkeiten, einen Beitrag zu leisten</h2><p>Diese Liste ist in Funktionen unterteilt, die jeder tun kann, die von Mitgliedern der Kubernetes-Organisation durchgeführt werden können, und Dinge, die ein höheres Maß an Zugriff und eine bessere Kenntnis der SIG Docs-Prozesse erfordern. Wenn Sie im Laufe der Zeit einen konstanten Beitrag leisten, können Sie einige der bereits getroffenen Tools und organisatorischen Entscheidungen nachvollziehen.</p><p>Dies ist keine vollständige Liste von Möglichkeiten, wie Sie zur Kubernetes-Dokumentation beitragen können, aber sie sollte Ihnen den Einstieg erleichtern.</p><ul><li><a href=/docs/contribute/start/>Jeder</a><ul><li>Umsetzbare issues eröffnen</li></ul></li><li><a href=/docs/contribute/start/>Member</a><ul><li>Vorhandene Dokumente verbessern</li><li>Ideen zur Verbesserung in <a href=http://slack.k8s.io/>Slack</a> oder der <a href=https://groups.google.com/forum/#!forum/kubernetes-sig-docs>SIG docs Mailingliste</a> einbringen</li><li>Den Zugriff auf Dokumente verbessern</li><li>Unverbindliches Feedback zu PRs verfassen</li><li>Enen Blogbeitrag oder eine Fallstudie schreiben</li></ul></li><li><a href=/docs/contribute/intermediate/>Reviewer</a><ul><li>Neue Funktionen dokumentieren</li><li>Auswerten und Kategorisieren von Problemen</li><li>PRs überprüfen</li><li>Diagramme, Grafiken und einbettbare Screencasts / Videos erstellen</li><li>Lokalisierung</li><li>Als Vertreter von docs zu anderen Repos beitragen</li><li>An Benutzer gerichtete Zeichenfolgen im Code bearbeiten</li><li>Code-Kommentare verbessern, Godoc</li></ul></li><li><a href=/docs/contribute/advanced/>Approver</a><ul><li>Veröffentlichen Sie den Inhalt von Members, indem Sie PRs genehmigen und zusammenführen</li><li>Nehmen Sie als Docs-Vertreter an einem Kubernetes-Release-Team teil</li><li>Verbesserungsvorschläge für den Style Guide</li><li>Verbesserungsvorschläge für Dokumentprüfungen vorschlagen</li><li>Vorschläge für Verbesserungen der Kubernetes-Website oder anderer Tools</li></ul></li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-849a2fdb87779db1c212fe5a9f88ff0d>7.1 - Lokalisierung der Kubernetes Dokumentation</h1><p>Diese Seite zeigt dir wie die Dokumentation für verschiedene Sprachen <a href=https://blog.mozilla.org/l10n/2011/12/14/i18n-vs-l10n-whats-the-diff/>lokalisiert</a> wird.</p><h2 id=erste-schritte>Erste Schritte</h2><p>Da Mitwirkende nicht ihren eigenen Pull Request freigeben können, brauchst du mindestens zwei Mitwirkende um mit der Lokalisierung anfangen zu können.</p><p>Alle Lokalisierungsteams müssen sich mit ihren eigenen Ressourcen selbst tragen. Die Kubernetes-Website ist gerne bereit, deine Arbeit zu beherbergen, aber es liegt an dir, sie zu übersetzen.</p><h3 id=ermittlung-deines-zwei-buchstaben-sprachcodes>Ermittlung deines Zwei-Buchstaben-Sprachcodes</h3><p>Rufe den <a href=https://www.loc.gov/standards/iso639-2/php/code_list.php>ISO 639-1 Standard</a> auf und finde deinen Zwei-Buchstaben-Ländercode zur Lokalisierung. Zum Beispiel ist der Zwei-Buchstaben-Code für Korea <code>ko</code>.</p><h3 id=duplizieren-und-klonen-des-repositories>Duplizieren und Klonen des Repositories</h3><p>Als erstes <a href=/docs/contribute/new-content/new-content/#fork-the-repo>erstellst du dir deine eigenes Duplikat</a> vom [kubernetes/website] Repository.</p><p>Dann klonst du das Duplikat und wechselst in das neu erstellte Verzeichnis:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>git clone https://github.com/&lt;username&gt;/website
</span></span><span style=display:flex><span><span style=color:#a2f>cd</span> website
</span></span></code></pre></div><h3 id=eröffnen-eines-pull-requests>Eröffnen eines Pull Requests</h3><p>Als nächstes <a href=/docs/contribute/new-content/open-a-pr/#open-a-pr>eröffnest du einen Pull Request</a> (PR) um eine Lokalisierung zum <code>kubernetes/website</code> Repository hinzuzufügen.</p><p>Der PR muss die <a href=#mindestanforderungen>minimalen Inhaltsanforderungen</a> erfüllen, bevor dieser genehmigt werden kann.</p><p>Wie der PR für eine neue Lokalisierung aussieht, kannst du dir an dem PR für die <a href=https://github.com/kubernetes/website/pull/12548>Französische Dokumentation</a> ansehen.</p><h3 id=tritt-der-kubernetes-github-organisation-bei>Tritt der Kubernetes GitHub Organisation bei</h3><p>Sobald du eine Lokalisierungs-PR eröffnet hast, kannst du Mitglied der Kubernetes GitHub Organisation werden. Jede Person im Team muss einen eigenen <a href=https://github.com/kubernetes/org/issues/new/choose>Antrag auf Mitgliedschaft in der Organisation</a> im <code>kubernetes/org</code>-Repository erstellen.</p><h3 id=lokalisierungs-team-in-github-hinzufügen>Lokalisierungs-Team in GitHub hinzufügen</h3><p>Im nächsten Schritt musst du dein Kubernetes Lokalisierungs-Team in die <a href=https://github.com/kubernetes/org/blob/master/config/kubernetes/sig-docs/teams.yaml><code>sig-docs/teams.yaml</code></a> eintragen.</p><p>Der PR des <a href=https://github.com/kubernetes/org/pull/685>Spanischen Lokalisierungs-Teams</a> kann dir hierbei eine Hilfestellung sein.</p><p>Mitglieder der <code>@kubernetes/sig-docs-**-owners</code> können nur PRs freigeben die innerhalb deines Lokalisierungs-Ordners Änderungen vorgenommen haben: <code>/content/**/</code>.</p><p>Für jede Lokalisierung automatisiert das Team <code>@kubernetes/sig-docs-**-reviews</code> die Review-Zuweisung für neue PRs.</p><p>Mitglieder von <code>@kubernetes/website-maintainers</code> können neue Entwicklungszweige schaffen, um die Übersetzungsarbeiten zu koordinieren.</p><p>Mitglieder von <code>@kubernetes/website-milestone-maintainers</code> können den Befehl <code>/milestone</code> <a href=https://prow.k8s.io/command-help>Prow Kommando</a> verwenden, um Themen oder PRs einen Meilenstein zuzuweisen.</p><h3 id=workflow-konfigurieren>Workflow konfigurieren</h3><p>Als nächstes fügst du ein GitHub-Label für deine Lokalisierung im <code>kubernetes/test-infra</code>-Repository hinzu. Mit einem Label kannst du Aufgaben filtern und Anfragen für deine spezifische Sprache abrufen.</p><p>Schau dir den PR zum Hinzufügen der Labels für die [Italienischen Sprachen-Labels](<a href=https://github.com/kubernetes/test-infra/pull/11316>https://github.com/kubernetes/test-infra/pull/11316</a> an.</p><h3 id=finde-eine-gemeinschaft>Finde eine Gemeinschaft</h3><p>Lasse die Kubernetes SIG Docs wissen, dass du an der Erstellung einer Lokalisierung interessiert bist! Trete dem <a href=https://kubernetes.slack.com/messages/C1J0BPD2M/>SIG Docs Slack-Kanal</a> bei. Andere Lokalisierungsteams helfen dir gerne beim Einstieg und beantworten deine Fragen.</p><p>Du kannst auch einen Slack-Kanal für deine Lokalisierung im <code>kubernetes/community</code>-Repository erstellen. Ein Beispiel für das Hinzufügen eines Slack-Kanals findest du im PR für <a href=https://github.com/kubernetes/community/pull/3605>Kanäle für Indonesisch und Portugiesisch hinzufügen</a>.</p><h2 id=mindestanforderungen>Mindestanforderungen</h2><h3 id=ändere-die-website-konfiguration>Ändere die Website-Konfiguration</h3><p>Die Kubernetes-Website verwendet Hugo als Web-Framework. Die Hugo-Konfiguration der Website befindet sich in der Datei <a href=https://github.com/kubernetes/website/tree/master/config.toml><code>config.toml</code></a>. Um eine neue Lokalisierung zu unterstützen, musst du die Datei <code>config.toml</code> modifizieren.</p><p>Dazu fügst du einen neuen Block für die neue Sprache unter den bereits existierenden <code>[languages]</code> Block in das <code>config.toml</code> ein, wie folgendes Beispiel zeigt:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-toml data-lang=toml><span style=display:flex><span>[languages.de]
</span></span><span style=display:flex><span>title = <span style=color:#b44>&#34;Kubernetes&#34;</span>
</span></span><span style=display:flex><span>description = <span style=color:#b44>&#34;Produktionsreife Container-Verwaltung&#34;</span>
</span></span><span style=display:flex><span>languageName = <span style=color:#b44>&#34;Deutsch&#34;</span>
</span></span><span style=display:flex><span>contentDir = <span style=color:#b44>&#34;content/de&#34;</span>
</span></span><span style=display:flex><span>weight = <span style=color:#666>3</span>
</span></span></code></pre></div><p>Wenn du deinem Block einen Parameter <code>weight</code> zuweist, suche den Sprachblock mit dem höchsten Gewicht und addiere 1 zu diesem Wert.</p><p>Weitere Informationen zu Hugos multilingualem Support findest du unter "<a href=https://gohugo.io/content-management/multilingual/>Multilingual Mode</a>" auf in der Hugo Dokumentation.</p><h3 id=neuen-lokalisierungsordner-erstellen>Neuen Lokalisierungsordner erstellen</h3><p>Füge eine sprachspezifisches Unterverzeichnis zum Ordner <a href=https://github.com/kubernetes/website/tree/master/content><code>content</code></a> im Repository hinzu. Der Zwei-Buchstaben-Code für Deutsch ist zum Beispiel <code>de</code>:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>mkdir content/de
</span></span></code></pre></div><h3 id=lokalisiere-den-verhaltenscodex>Lokalisiere den Verhaltenscodex</h3><p>Öffne einen PR gegen das <a href=https://github.com/cncf/foundation/tree/master/code-of-conduct-languages><code>cncf/foundation</code></a> Repository, um den Verhaltenskodex in deiner Sprache hinzuzufügen.</p><h3 id=lokalisierungs-readme-datei-hinzufügen>Lokalisierungs README Datei hinzufügen</h3><p>Um andere Lokalisierungsmitwirkende anzuleiten, füge eine neue <a href=https://help.github.com/articles/about-readmes/><code>README-**.md</code></a> auf der obersten Ebene von k/website hinzu, wobei <code>**</code> der aus zwei Buchstaben bestehende Sprachcode ist. Eine deutsche README-Datei wäre zum Beispiel <code>README-de.md</code>.</p><p>Gebe den Lokalisierungsmitwirkende in der lokalisierten <code>README-**.md</code>-Datei Anleitung zum Mitwirken. Füge dieselben Informationen ein, die auch in <code>README.md</code> enthalten sind, sowie:</p><ul><li>Eine Anlaufstelle für das Lokalisierungsprojekt</li><li>Alle für die Lokalisierung spezifischen Informationen</li></ul><p>Nachdem du das lokalisierte README erstellt hast, füge der Datei einen Link aus der englischen Hauptdatei <code>README.md</code> hinzu und gebe die Kontaktinformationen auf Englisch an. Du kannst eine GitHub-ID, eine E-Mail-Adresse, <a href=https://slack.com/>Slack-Kanal</a> oder eine andere Kontaktmethode angeben. Du musst auch einen Link zu deinem lokalisierten Verhaltenskodex der Gemeinschaft angeben.</p><h3 id=richte-eine-owners-datei-ein>Richte eine OWNERS Datei ein</h3><p>Um die Rollen der einzelnen an der Lokalisierung beteiligten Benutzer festzulegen, erstelle eine <code>OWNERS</code>-Datei innerhalb des sprachspezifischen Unterverzeichnisses mit:</p><ul><li><strong>reviewers</strong>: Eine Liste von kubernetes-Teams mit Gutachter-Rollen, in diesem Fall das <code>sig-docs-**-reviews</code> Team, das in <a href=#lokalisierungs-team-in-github-hinzuf%C3%BCgen>Lokalisierungsteam in GitHub hinzufügen</a> erstellt wurde.</li><li><strong>approvers</strong>: Eine Liste der Kubernetes-Teams mit der Rolle des Genehmigers, in diesem Fall das <code>sig-docs-**-owners</code> Team, das in <a href=#lokalisierungs-team-in-github-hinzuf%C3%BCgen>Lokalisierungsteam in GitHub hinzufügen</a> erstellt wurde.</li><li><strong>labels</strong>: Eine Liste von GitHub-Labels, die automatisch auf einen PR angewendet werden sollen, in diesem Fall das Sprachlabel, das unter <a href=#workflow-konfigurieren>Workflow konfigurieren</a> erstellt wurde.</li></ul><p>Weitere Informationen über die Datei <code>OWNERS</code> findest du unter <a href=https://go.k8s.io/owners>go.k8s.io/owners</a>.</p><p>Die Datei <a href=https://git.k8s.io/website/content/es/OWNERS>Spanish OWNERS file</a>, mit dem Sprachcode <code>es</code>, sieht wie folgt aus:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#080;font-style:italic># See the OWNERS docs at https://go.k8s.io/owners</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:#080;font-style:italic># This is the localization project for Spanish.</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:#080;font-style:italic># Teams and members are visible at https://github.com/orgs/kubernetes/teams.</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>reviewers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span>- sig-docs-es-reviews<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>approvers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span>- sig-docs-es-owners<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>labels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span>- language/es<span style=color:#bbb>
</span></span></span></code></pre></div><p>Nachdem du die sprachspezifische Datei <code>OWNERS</code> hinzugefügt hast, aktualisiere die root Datei <a href=https://git.k8s.io/website/OWNERS_ALIASES><code>OWNERS_ALIASES</code></a> mit den neuen Kubernetes-Teams für die Lokalisierung, <code>sig-docs-**-owners</code> und <code>sig-docs-**-reviews</code>.</p><p>Füge für jedes Team die Liste der unter <a href=#lokalisierungs-team-in-github-hinzuf%C3%BCgen>Ihr Lokalisierungsteam in GitHub hinzufügen</a> angeforderten GitHub-Benutzer in alphabetischer Reihenfolge hinzu.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-diff data-lang=diff><span style=display:flex><span><span style=color:#a00000>--- a/OWNERS_ALIASES
</span></span></span><span style=display:flex><span><span style=color:#a00000></span><span style=color:#00a000>+++ b/OWNERS_ALIASES
</span></span></span><span style=display:flex><span><span style=color:#00a000></span><span style=color:purple;font-weight:700>@@ -48,6 +48,14 @@ aliases:
</span></span></span><span style=display:flex><span><span style=color:purple;font-weight:700></span>     - stewart-yu
</span></span><span style=display:flex><span>     - xiangpengzhao
</span></span><span style=display:flex><span>     - zhangxiaoyu-zidif
</span></span><span style=display:flex><span><span style=color:#00a000>+  sig-docs-es-owners: # Admins for Spanish content
</span></span></span><span style=display:flex><span><span style=color:#00a000>+    - alexbrand
</span></span></span><span style=display:flex><span><span style=color:#00a000>+    - raelga
</span></span></span><span style=display:flex><span><span style=color:#00a000>+  sig-docs-es-reviews: # PR reviews for Spanish content
</span></span></span><span style=display:flex><span><span style=color:#00a000>+    - alexbrand
</span></span></span><span style=display:flex><span><span style=color:#00a000>+    - electrocucaracha
</span></span></span><span style=display:flex><span><span style=color:#00a000>+    - glo-pena
</span></span></span><span style=display:flex><span><span style=color:#00a000>+    - raelga
</span></span></span><span style=display:flex><span><span style=color:#00a000></span>   sig-docs-fr-owners: # Admins for French content
</span></span><span style=display:flex><span>     - perriea
</span></span><span style=display:flex><span>     - remyleone
</span></span></code></pre></div><h2 id=inhalte-übersetzen>Inhalte übersetzen</h2><p>Die Lokalisierung <em>aller</em> Dokumentationen des Kubernetes ist eine enorme Aufgabe. Es ist in Ordnung, klein anzufangen und mit der Zeit zu erweitern.</p><p>Alle Lokalisierungen müssen folgende Inhalte enthalten:</p><table><thead><tr><th>Beschreibung</th><th>URLs</th></tr></thead><tbody><tr><td>Startseite</td><td><a href=/docs/home/>Alle Überschriften und Untertitel URLs</a></td></tr><tr><td>Einrichtung</td><td><a href=/docs/setup/>Alle Überschriften und Untertitel URLs</a></td></tr><tr><td>Tutorials</td><td><a href=/docs/tutorials/kubernetes-basics/>Kubernetes Grundlagen</a>, <a href=/docs/tutorials/stateless-application/hello-minikube/>Hello Minikube</a></td></tr><tr><td>Site strings</td><td><a href=https://github.com/kubernetes/website/tree/master/i18n>Alle Website-Zeichenfolgen in einer neuen lokalisierten TOML-Datei</a></td></tr></tbody></table><p>Übersetzte Dokumente müssen sich in ihrem eigenen Unterverzeichnis <code>content/**/</code> befinden, aber ansonsten dem gleichen URL-Pfad wie die englische Quelle folgen. Um z.B. das Tutorial <a href=/docs/tutorials/kubernetes-basics/>Kubernetes Grundlagen</a> für die Übersetzung ins Deutsche vorzubereiten, erstelle einen Unterordner unter dem Ordner <code>content/de/</code> und kopiere die englische Quelle:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>mkdir -p content/de/docs/tutorials
</span></span><span style=display:flex><span>cp content/en/docs/tutorials/kubernetes-basics.md content/de/docs/tutorials/kubernetes-basics.md
</span></span></code></pre></div><p>Übersetzungswerkzeuge können den Übersetzungsprozess beschleunigen. Einige Redakteure bieten beispielsweise Plugins zur schnellen Übersetzung von Text an.</p><div class="alert alert-warning caution callout" role=alert><strong>Achtung:</strong> Maschinelle Übersetzung allein reicht nicht aus. Die Lokalisierung erfordert eine umfassende menschliche Überprüfung, um Mindestqualitätsstandards zu erfüllen.</div><p>Um die Genauigkeit in Grammatik und Bedeutung zu gewährleisten, sollten die Mitglieder deines Lokalisierungsteams alle maschinell erstellten Übersetzungen vor der Veröffentlichung sorgfältig überprüfen.</p><h3 id=quelldaten>Quelldaten</h3><p>Lokalisierungen müssen auf den englischen Dateien der neuesten Version basieren, v1.25.</p><p>Um die Quelldatei für das neueste Release führe folgende Schritte durch:</p><ol><li>Navigiere zum Repository der Website Kubernetes unter <a href=https://github.com/kubernetes/website>https://github.com/kubernetes/website</a>.</li><li>Wähle den <code>release-1.X</code>-Zweig für die aktuellste Version.</li></ol><p>Die neueste Version ist v1.25, so dass der neueste Versionszweig <a href=https://github.com/kubernetes/website/tree/release-1.25><code>release-1.25</code></a> ist.</p><h3 id=seitenverlinkung-in-der-internationalisierung>Seitenverlinkung in der Internationalisierung</h3><p>Lokalisierungen müssen den Inhalt von <a href=https://github.com/kubernetes/website/blob/main/i18n/en.toml><code>i18n/de.toml</code></a> in einer neuen sprachspezifischen Datei enthalten. Als Beispiel: <code>i18n/de.toml</code>.</p><p>Füge eine neue Lokalisierungsdatei zu <code>i18n/</code> hinzu. Zum Beispiel mit Deutsch (<code>de</code>):</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>cp i18n/en.toml i18n/de.toml
</span></span></code></pre></div><p>Übersetze dann den Wert jeder Zeichenfolge:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-TOML data-lang=TOML><span style=display:flex><span>[docs_label_i_am]
</span></span><span style=display:flex><span>other = <span style=color:#b44>&#34;ICH BIN...&#34;</span>
</span></span></code></pre></div><p>Durch die Lokalisierung von Website-Zeichenfolgen kannst du Website-weiten Text und Funktionen anpassen: z. B. den gesetzlichen Copyright-Text in der Fußzeile auf jeder Seite.</p><h2 id=sprachspezifischer-styleguide>Sprachspezifischer Styleguide</h2><p>Einige Sprachteams haben ihren eigenen sprachspezifischen Styleguide und ihr eigenes Glossar. Siehe zum Beispiel den <a href=/ko/docs/contribute/localization_ko/>Leitfaden zur koreanischen Lokalisierung</a>.</p><h3 id=informale-schreibweise>Informale Schreibweise</h3><p>Für die deutsche Übersetzungen verwenden wir eine informelle Schreibweise und der Ansprache per <code>Du</code>. Allerdings werden keine Jargon, Slang, Wortspiele, Redewendungen oder kulturspezifische Bezüge eingebracht.</p><h3 id=datums-und-maßeinheiten>Datums und Maßeinheiten</h3><p>Wenn notwendig sollten Datumsangaben in das in Deutschland übliche dd.mm.yyyy überführt werden. Alternativ können diese auch in den Textfluss eingebunden werden: "... am 24. April ....".</p><h3 id=abkürzungen>Abkürzungen</h3><p>Abkürzungen sollten nach Möglichkeit nicht verwendet werden und entweder ausgeschrieben oder anderweitig umgangen werden.</p><h3 id=zusammengesetzte-wörter>Zusammengesetzte Wörter</h3><p>Durch die Übersetzung werden oft Nomen aneinandergereiht, diese Wortketten müssen durch Bindestriche verbunden werden. Dies ist auch möglich wenn ein Teil ins Deutsche übersetzt wird ein weiterer jedoch im Englischen bestehen bleibt. Als Richtlinie gilt hier der <a href=https://www.duden.de/sprachwissen/rechtschreibregeln/bindestrich>Duden</a>.</p><h3 id=anglizismen>Anglizismen</h3><p>Die Verwendung von Anglizismen ist dann wünschenswert, wenn die Verwendung eines deutschen Wortes, vor allem für technische Begriffe, nicht eindeutig ist oder zu Unklarheiten führt.</p><h2 id=branching-strategie>Branching Strategie</h2><p>Da Lokalisierungsprojekte in hohem Maße gemeinschaftliche Bemühungen sind, ermutigen wir Teams, in gemeinsamen Entwicklungszweigen zu arbeiten.</p><p>In einem Entwicklungszweig zusammenzuarbeiten:</p><ol><li><p>Ein Teammitglied von <a href=https://github.com/orgs/kubernetes/teams/website-maintainers>@kubernetes/website-maintainers</a> eröffnet einen Entwicklungszweig aus einem Quellzweig auf <a href=https://github.com/kubernetes/website>https://github.com/kubernetes/website</a>.</p><p>Deine Genehmiger sind dem <code>@kubernetes/website-maintainers</code>-Team beigetreten, als du <a href=#lokalisierungs-team-in-github-hinzuf%C3%BCgen>dein Lokalisierungsteam</a> zum Repository <a href=https://github.com/kubernetes/org><code>kubernetes/org</code></a> hinzugefügt hast.</p><p>Wir empfehlen das folgende Zweigbenennungsschema:</p><p><code>dev-&lt;Quellversion>-&lt;Sprachcode>.&lt;Team-Meilenstein></code></p><p>Beispielsweise öffnet ein Genehmigender in einem deutschen Lokalisierungsteam den Entwicklungszweig <code>dev-1.12-de.1</code> direkt gegen das k/website-Repository, basierend auf dem Quellzweig für Kubernetes v1.12.</p></li><li><p>Einzelne Mitwirkende öffnen Feature-Zweige, die auf dem Entwicklungszweig basieren.</p><p>Zum Beispiel öffnet ein deutscher Mitwirkende eine Pull-Anfrage mit Änderungen an <code>kubernetes:dev-1.12-de.1</code> von <code>Benutzername:lokaler-Zweig-Name</code>.</p></li><li><p>Genehmiger Überprüfen und führen die Feature-Zweigen in den Entwicklungszweig zusammen.</p></li><li><p>In regelmäßigen Abständen führt ein Genehmiger den Entwicklungszweig mit seinem Ursprungszweig zusammen, indem er eine neue Pull-Anfrage eröffnet und genehmigt. Achtet darauf, die Commits zusammenzuführen (squash), bevor die Pull-Anfrage genehmigt wird.</p></li></ol><p>Wiederhole die Schritte 1-4 nach Bedarf, bis die Lokalisierung abgeschlossen ist. Zum Beispiel würden nachfolgende deutsche Entwicklungszweige sein: <code>dev-1.12-de.2</code>, <code>dev-1.12-de.3</code>, usw.</p><p>Die Teams müssen den lokalisierten Inhalt in demselben Versionszweig zusammenführen, aus dem der Inhalt stammt. Beispielsweise muss ein Entwicklungszweig, der von release-1.25 ausgeht, auf {{release-1.25} basieren.</p><p>Ein Genehmiger muss einen Entwicklungszweig aufrechterhalten, indem er seinen Quellzweig auf dem aktuellen Stand hält und Merge-Konflikte auflöst. Je länger ein Entwicklungszweig geöffnet bleibt, desto mehr Wartung erfordert er in der Regel. Ziehe in Betracht, regelmäßig Entwicklungszweige zusammenzuführen und neue zu eröffnen, anstatt einen extrem lang laufenden Entwicklungszweig zu unterhalten.</p><p>Zu Beginn jedes Team-Meilensteins ist es hilfreich, ein Problem <a href=https://github.com/kubernetes/website/blob/main/scripts/upstream_changes.py>Vergleich der Upstream-Änderungen</a> zwischen dem vorherigen Entwicklungszweig und dem aktuellen Entwicklungszweig zu öffnen.</p><p>Während nur Genehmiger einen neuen Entwicklungszweig eröffnen und Pull-Anfragen zusammenführen können, kann jeder eine Pull-Anfrage für einen neuen Entwicklungszweig eröffnen. Es sind keine besonderen Genehmigungen erforderlich.</p><p>Weitere Informationen über das Arbeiten von Forks oder direkt vom Repository aus findest du unter <a href=#duplizieren-und-klonen-des-repositories>"fork and clone the repo"</a>.</p><h2 id=am-upstream-mitwirken>Am Upstream Mitwirken</h2><p>SIG Docs begrüßt Upstream Beiträge, also auf das englische Original, und Korrekturen an der englischen Quelle.</p><h2 id=unterstütze-bereits-bestehende-lokalisierungen>Unterstütze bereits bestehende Lokalisierungen</h2><p>Du kannst auch dazu beitragen, Inhalte zu einer bestehenden Lokalisierung hinzuzufügen oder zu verbessern. Trete dem <a href=https://kubernetes.slack.com/messages/C1J0BPD2M/>Slack-Kanal</a> für die Lokalisierung bei und beginne mit der Eröffnung von PRs, um zu helfen. Bitte beschränke deine Pull-Anfragen auf eine einzige Lokalisierung, da Pull-Anfragen, die Inhalte in mehreren Lokalisierungen ändern, schwer zu überprüfen sein könnten.</p><h2 id=nächste-schritte>Nächste Schritte</h2><p>Sobald eine Lokalisierung die Anforderungen an den Arbeitsablauf und die Mindestausgabe erfüllt, wird SIG docs:</p><ul><li>Die Sprachauswahl auf der Website aktivieren</li><li>Die Verfügbarkeit der Lokalisierung über die Kanäle der <a href=https://www.cncf.io/about/>Cloud Native Computing Foundation</a> (CNCF), einschließlich des <a href=https://kubernetes.io/blog/>Kubernetes Blogs</a> veröffentlichen.</li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-8b9b22280711800788333c1a4d129735>7.2 - Bei SIG Docs mitmachen</h1><p>Die SIG Docs ist eine der <a href=https://github.com/kubernetes/community/blob/master/sig-list.md>Special Interest Groups</a> (Fachspezifischen Interessengruppen) innerhalb des Kubernetes-Projekts, die sich auf das Schreiben, Aktualisieren und Pflegen der Dokumentation für Kubernetes als Ganzes konzentriert. Weitere Informationen über die SIG findest du unter SIG Docs im <a href=https://github.com/kubernetes/community/tree/master/sig-docs>GitHub Repository der Community</a>.</p><p>SIG Docs begrüßt Inhalte und Bewertungen von allen Mitwirkenden. Jeder kann einen
Pull Request (PR) eröffnen, und jeder ist willkommen, Fragen zum Inhalt zu stellen oder Kommentare
zu laufenden Pull Requests abzugeben.</p><p>Du kannst dich ausserdem als <a href=/de/docs/contribute/participate/roles-and-responsibilities/#member>Member</a>,
<a href=/de/docs/contribute/participate/roles-and-responsibilities/#reviewer>Reviewer</a>, oder
<a href=/de/docs/contribute/participate/roles-and-responsibilities/#approver>Approver</a> beteiligen.
Diese Rollen erfordern einen erweiterten Zugriff und bringen bestimmte Verantwortlichkeiten zur Genehmigung und Bestätigung von Änderungen mit sich.
Unter <a href=https://github.com/kubernetes/community/blob/master/community-membership.md>community-membership</a> findest du weitere Informationen darüber, wie die Mitgliedschaft in der Kubernetes-Community funktioniert.</p><p>Der Rest dieses Dokuments umreißt einige spezielle Vorgehensweisen dieser Rollen innerhalb von SIG Docs, die für die Pflege eines der öffentlichsten Aushängeschilder von Kubernetes verantwortlich ist - die Kubernetes-Website und die Dokumentation.</p><h2 id=sig-docs-vorstand>SIG Docs Vorstand</h2><p>Jede SIG, auch die SIG Docs, wählt ein oder mehrere SIG-Mitglieder, die als
Vorstand fungieren. Sie sind die Kontaktstellen zwischen der SIG Docs und anderen Teilen der
der Kubernetes-Organisation. Sie benötigen umfassende Kenntnisse über die Struktur
des Kubernetes-Projekts als Ganzes und wie SIG Docs darin arbeitet. Hier findest alle weiteren Informationen zu den aktuellen Vorsitzenden und der <a href=https://github.com/kubernetes/community/tree/master/sig-docs#leadership>Leitung</a>.</p><h2 id=sig-docs-teams-und-automatisierung>SIG Docs-Teams und Automatisierung</h2><p>Die Automatisierung in SIG Docs stützt sich auf zwei verschiedene Mechanismen:
GitHub-Teams und OWNERS-Dateien.</p><h3 id=github-teams>GitHub Teams</h3><p>Es gibt zwei Kategorien von SIG Docs <a href="https://github.com/orgs/kubernetes/teams?query=sig-docs">Teams</a> auf GitHub:</p><ul><li><code>@sig-docs-{language}-owners</code> sind Genehmiger und Verantwortliche</li><li><code>@sig-docs-{language}-reviews</code> sind Reviewer</li></ul><p>Jede Gruppe kann in GitHub-Kommentaren mit ihrem <code>@name</code> referenziert werden, um mit allen Mitgliedern dieser Gruppe zu kommunizieren.</p><p>Manchmal überschneiden sich Prow- und GitHub-Teams, ohne eine genaue Übereinstimmung. Für die Zuordnung von Issues, Pull-Requests und zur Unterstützung von PR-Genehmigungen verwendet die
Automatisierung die Informationen aus den <code>OWNERS</code>-Dateien.</p><h3 id=owners-dateien-und-front-matter>OWNERS Dateien und Front-Matter</h3><p>Das Kubernetes-Projekt verwendet ein Automatisierungstool namens prow für die Automatisierung im Zusammenhang mit GitHub-Issues und Pull-Requests.
Das <a href=https://github.com/kubernetes/website>Kubernetes-Website-Repository</a> verwendet zwei <a href=https://github.com/kubernetes/test-infra/tree/master/prow/plugins>prow-Plugins</a>:</p><ul><li>blunderbuss</li><li>approve</li></ul><p>Diese beiden Plugins nutzen die
<a href=https://github.com/kubernetes/website/blob/main/OWNERS>OWNERS</a> und
<a href=https://github.com/kubernetes/website/blob/main/OWNERS_ALIASES>OWNERS_ALIASES</a>
Dateien auf der obersten Ebene des GitHub-Repositorys <code>kubernetes/website</code>, um zu steuern
wie prow innerhalb des Repositorys arbeitet.</p><p>Eine OWNERS-Datei enthält eine Liste von Personen, die SIG Docs-Reviewer und
Genehmiger sind. OWNERS-Dateien können auch in Unterverzeichnissen existieren und bestimmen, wer
Dateien in diesem Unterverzeichnis und seinen Unterverzeichnissen als Gutachter oder
Genehmiger bestätigen darf. Weitere Informationen über OWNERS-Dateien im Allgemeinen findest du unter
<a href=https://github.com/kubernetes/community/blob/master/contributors/guide/owners.md>OWNERS</a>.</p><p>Außerdem kann eine einzelne Markdown-Datei in ihrem Front-Matter (Vorspann) Reviewer und Genehmiger auflisten.
Entweder durch Auflistung einzelner GitHub-Benutzernamen oder GitHub-Gruppen.</p><p>Die Kombination aus OWNERS-Dateien und Front-Matter in Markdown-Dateien bestimmt, welche Empfehlungen PR-Eigentümer von automatisierten Systemen erhalten, und wen sie um eine technische und redaktionelle Überprüfung ihres PRs bitten sollen.</p><h2 id=so-funktioniert-das-zusammenführen>So funktioniert das Zusammenführen</h2><p>Wenn ein Pull Request mit der Branch (Ast) zusammengeführt wird, in dem der Inhalt bereitgestellt werden soll, wird dieser Inhalt auf <a href=http://kubernetes.io>http://kubernetes.io</a> veröffentlicht. Um sicherzustellen, dass die Qualität der veröffentlichten Inhalte hoch ist, beschränken wir das Zusammenführen von Pull Requests auf
SIG Docs Freigabeberechtigte. So funktioniert es:</p><ul><li>Wenn eine Pull-Anfrage sowohl das <code>lgtm</code>- als auch das <code>approve</code>-Label hat, kein <code>hold</code>-Label hat,
und alle Tests bestanden sind, wird der Pull Request automatisch zusammengeführt.</li><li>Jedes Kubernetes-Mitglied kann das <code>lgtm</code>-Label hinzufügen, indem es einen <code>/lgtm</code>-Kommentar hinzufügt.</li><li>Mitglieder der Kubernetes-Organisation und SIG Docs-Genehmiger können kommentieren, um das automatische Zusammenführen eines Pull Requests zu verhindern (durch Hinzufügen eines <code>/hold</code>-Kommentars
kann ein vorheriger <code>/lgtm</code>-Kommentar zurückgehalten werden).</li><li>Nur SIG Docs-Genehmiger können einen Pull Request zusammenführen indem sie einen <code>/approve</code> Kommentar hinzufügen.
Einige Genehmiger übernehmen auch weitere spezielle Rollen, wie zum Beispiel <a href=/docs/contribute/participate/pr-wranglers/>PR Wrangler</a> oder <a href=#sig-docs-chairperson>SIG Docs Vorsitzende</a>.</li></ul><h2 id=nächste-schritte>Nächste Schritte</h2><p>Weitere Informationen über die Mitarbeit an der Kubernetes-Dokumentation findest du unter:</p><ul><li><a href=/docs/contribute/new-content/overview/>Neue Inhalte beisteuern</a></li><li><a href=/docs/contribute/review/reviewing-prs>Inhalte überprüfen</a></li><li><a href=/docs/contribute/style/>Styleguide für die Dokumentation</a></li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-76656ea25ba7e6404601838389262482>7.2.1 - Rollen und Verantwortlichkeiten</h1><p>Jeder kann zu Kubernetes beitragen. Wenn deine Beiträge zu SIG Docs wachsen, kannst du dich für verschiedene Stufen der Mitgliedschaft in der Community bewerben.
Diese Rollen ermöglichen es dir, mehr Verantwortung innerhalb der Gemeinschaft zu übernehmen.
Jede Rolle erfordert mehr Zeit und Engagement. Die Rollen sind:</p><ul><li>Jeder: kann regelmäßig zur Kubernetes-Dokumentation beitragen</li><li>Member: können Issues zuweisen und einstufen und Pull Requests unverbindlich prüfen</li><li>Reviewer: können die Überprüfung von Dokumentations-Pull-Requests leiten und für die Qualität einer Änderung bürgen</li><li>Approver: können die Überprüfung von Dokumentations- und Merge-Änderungen leiten</li></ul><h2 id=jeder>Jeder</h2><p>Jeder mit einem GitHub-Konto kann zu Kubernetes beitragen. SIG Docs heißt alle neuen Mitwirkenden willkommen!</p><p>Jeder kann:</p><ul><li>Ein Problem in einem beliebigen <a href=https://github.com/kubernetes/>Kubernetes</a>
Repository, einschließlich
<a href=https://github.com/kubernetes/website><code>kubernetes/website</code></a> melden</li><li>Unverbindliches Feedback zu einem Pull Request geben</li><li>Zu einer Lokalisierung beitragen</li><li>Verbesserungen auf <a href=https://slack.k8s.io/>Slack</a> oder der
<a href=https://groups.google.com/forum/#!forum/kubernetes-sig-docs>SIG docs mailing list</a> vorschlagen.</li></ul><p>Nach dem <a href=/docs/contribute/new-content/overview/#sign-the-cla>Signieren des CLA</a> kann jeder auch:</p><ul><li>eine Pull-Anfrage öffnen, um bestehende Inhalte zu verbessern, neue Inhalte hinzuzufügen oder einen Blogbeitrag oder eine Fallstudie zu schreiben</li><li>Diagramme, Grafiken und einbettbare Screencasts und Videos erstellen</li></ul><p>Weitere Informationen findest du unter <a href=/docs/contribute/new-content/>neue Inhalte beisteuern</a>.</p><h2 id=member>Member</h2><p>Ein Member (Mitglied) ist jemand, der bereits mehrere Pull Requests an
<code>kubernetes/website</code> eingereicht hat. Mitglieder sind ein Teil der
<a href=https://github.com/kubernetes>Kubernetes GitHub Organisation</a>.</p><p>Member können:</p><ul><li><p>Alles tun, was unter <a href=#jeder>Jeder</a> aufgeführt ist</p></li><li><p>Den Kommentar <code>/lgtm</code> verwenden, um einem Pull Request das Label LGTM (looks good to me) hinzuzufügen</p><div class="alert alert-info note callout" role=alert><strong>Hinweis:</strong> Die Verwendung von <code>/lgtm</code> löst eine Automatisierung aus. Wenn du eine unverbindliche
Zustimmung geben willst, funktioniert der Kommentar "LGTM" auch!</div></li><li><p>Verwende den Kommentar <code>/hold</code>, um das Zusammenführen eines Pull Requests zu blockieren.</p></li><li><p>Benutze den Kommentar <code>/assign</code>, um einem Pull Request einen Reviewer zuzuweisen.</p></li><li><p>Unverbindliche Überprüfung von Pull Requests</p></li><li><p>Nutze die Automatisierung, um Issues zu sortieren und zu kategorisieren</p></li><li><p>Neue Funktionen dokumentieren</p></li></ul><h3 id=mitglied-werden>Mitglied werden</h3><p>Du kannst ein Mitglied werden, nachdem du mindestens 5 substantielle Pull Requests eingereicht hast und die anderen
<a href=https://github.com/kubernetes/community/blob/master/community-membership.md#member>Anforderungen</a> erforderst:</p><ol><li><p>Finde zwei <a href=#reviewers>Reviewer</a> oder <a href=#approvers>Approver</a>, die deine Mitgliedschaft <a href=/docs/contribute/advanced#sponsor-a-new-contributor>sponsern</a>.</p><p>Bitte um Sponsoring im <a href=https://kubernetes.slack.com>#sig-docs channel on Slack</a> oder auf der
<a href=https://groups.google.com/forum/#!forum/kubernetes-sig-docs>SIG Docs Mailingliste</a>.</p><div class="alert alert-info note callout" role=alert><strong>Hinweis:</strong> Schicke keine direkte E-Mail oder Slack-Direktnachricht an ein einzelnes
SIG Docs-Mitglied. Du musst das Sponsoring beantragen, bevor du deine Bewerbung einreichst.</div></li><li><p>Eröffne ein GitHub-Issue im
<a href=https://github.com/kubernetes/org/><code>kubernetes/org</code></a> Repository. Verwende dabei das
<strong>Organization Membership Request</strong> issue template.</p></li><li><p>Informiere deine Sponsoren über das GitHub-Issue. Du kannst entweder:</p><ul><li><p>Ihren GitHub-Benutzernamen in deinem Issue (<code>@&lt;GitHub-Benutzername></code>) erwähnen</p></li><li><p>Ihnen den Issue-Link über Slack oder per E-Mail senden.</p><p>Die Sponsoren werden deine Anfrage mit einer "+1"-Stimme genehmigen. Sobald deine Sponsoren
genehmigen, fügt dich ein Kubernetes-GitHub-Admin als Mitglied hinzu.
Herzlichen Glückwunsch!</p><p>Wenn dein Antrag auf Mitgliedschaft nicht angenommen wird, erhältst du eine Rückmeldung.
Nachdem du dich mit dem Feedback auseinandergesetzt hast, kannst du dich erneut bewerben.</p></li></ul></li><li><p>Nimm die Einladung zur Kubernetes GitHub Organisation in deinem E-Mail-Konto an.</p><div class="alert alert-info note callout" role=alert><strong>Hinweis:</strong> GitHub sendet die Einladung an die Standard-E-Mail-Adresse in deinem Konto.</div></li></ol><h2 id=reviewer>Reviewer</h2><p>Reviewer (Gutachteren) sind dafür verantwortlich, offene Pull Requests zu überprüfen. Anders als bei den Mitgliedern
musst du auf das Feedback der Prüfer eingehen. Reviewer sind Mitglieder des
<a href="https://github.com/orgs/kubernetes/teams?query=sig-docs">@kubernetes/sig-docs-{language}-reviews</a>
GitHub-Teams.</p><p>Gutachteren können:</p><ul><li><p>Alles tun, was unter <a href=#jeder>Jeder</a> und <a href=#member>Member</a> aufgeführt ist</p></li><li><p>Pull Requests überprüfen und verbindliches Feedback geben</p><div class="alert alert-info note callout" role=alert><strong>Hinweis:</strong> Um unverbindliches Feedback zu geben, stellst du deinen Kommentaren eine Formulierung wie "Optional:" voran.</div></li><li><p>Bearbeite benutzerseitige Zeichenfolgen im Code</p></li><li><p>Verbessere Code-Kommentare</p></li></ul><h3 id=zuweisung-von-reviewern-zu-pull-requests>Zuweisung von Reviewern zu Pull Requests</h3><p>Die Automatisierung weist allen Pull Requests Reviewer zu. Du kannst eine
Review von einer bestimmten Person anfordern, indem du einen Kommentar schreibst: <code>/assign [@_github_handle]</code>.</p><p>Wenn der zugewiesene Prüfer den PR nicht kommentiert hat, kann ein anderer Prüfer
einspringen. Du kannst bei Bedarf auch technische Prüfer zuweisen.</p><h3 id=verwendung-von-lgtm>Verwendung von <code>/lgtm</code></h3><p>LGTM steht für "Looks good to me" und zeigt an, dass ein Pull Request
technisch korrekt und bereit zum Zusammenführen ist. Alle PRs brauchen einen <code>/lgtm</code> Kommentar von einem
Reviewer und einen <code>/approve</code> Kommentar von einem Approver, um zusammengeführt zu werden.</p><p>Ein <code>/lgtm</code>-Kommentar vom Reviewer ist verbindlich und löst eine Automatisierung aus, die das <code>lgtm</code>-Label hinzufügt.</p><h3 id=reviewer-werden>Reviewer werden</h3><p>Wenn du die
<a href=https://github.com/kubernetes/community/blob/master/community-membership.md#reviewer>Anforderungen</a> erfüllst,
kannst du ein SIG Docs-Reviewer werden. Reviewer in anderen SIGs müssen sich gesondert für den Reviewer-Status in SIG Docs bewerben.</p><p>So bewirbst du dich:</p><ol><li><p>Eröffne einen Pull Request, in dem du deinen GitHub-Benutzernamen in einen Abschnitt der
<a href=https://github.com/kubernetes/website/blob/main/OWNERS>OWNERS_ALIASES</a> Datei
im <code>kubernetes/website</code> Repository hinzufügt.</p><div class="alert alert-info note callout" role=alert><strong>Hinweis:</strong> Wenn du dir nicht sicher bist, wo du dich hinzufügen sollst, füge dich zu <code>sig-docs-de-reviews</code> hinzu.</div></li><li><p>Weise den PR einem oder mehreren SIG-Docs-Genehmigern zu (Benutzernamen, die unter
<code>sig-docs-{language}-owners</code> aufgelisted sind).
Wenn der PR genehmigt wurde, fügt dich ein SIG Docs-Lead dem entsprechenden GitHub-Team hinzu. Sobald du hinzugefügt bist,
wird <a href=https://github.com/kubernetes/test-infra/tree/master/prow#bots-home>@k8s-ci-robot</a>
dich als Reviewer für neue Pull Requests vorschlagen und zuweisen.</p></li></ol><h2 id=approver>Approver</h2><p>Approver (Genehmiger) prüfen und genehmigen Pull Requests zum Zusammenführen. Genehmigende sind Mitglieder des
<a href="https://github.com/orgs/kubernetes/teams/?query=sig-docs">@kubernetes/sig-docs-{language}-owners</a>
GitHub-Teams.</p><p>Genehmigende können Folgendes tun:</p><ul><li>Alles, was unter <a href=#jeder>Jeder</a>, <a href=#member>Member</a> und <a href=#reviewes>Reviewer</a> aufgeführt ist</li><li>Inhalte von Mitwirkenden veröffentlichen, indem sie Pull Requests mit dem Kommentar <code>/approve</code> genehmigen und zusammenführen</li><li>Verbesserungen für den Style Guide vorschlagen</li><li>Verbesserungsvorschläge für Docs-Tests einbringen</li><li>Verbesserungsvorschläge für die Kubernetes-Website oder andere Tools machen</li></ul><p>Wenn der PR bereits einen <code>/lgtm</code> hat, oder wenn der Genehmigende ebenfalls mit
<code>/lgtm</code> kommentiert, wird der PR automatisch zusammengeführt. Ein SIG Docs-Genehmiger sollte nur ein
<code>/lgtm</code> für eine Änderung hinterlassen, die keine weitere technische Überprüfung erfordert.</p><h3 id=pull-requests-genehmigen>Pull Requests genehmigen</h3><p>Genehmiger und SIG Docs-Leads sind die Einzigen, die Pull Requests
in das Website-Repository aufnehmen. Damit sind bestimmte Verantwortlichkeiten verbunden.</p><ul><li><p>Genehmigende können den Befehl <code>/approve</code> verwenden, der PRs in das Repository einfügt.</p><div class="alert alert-danger warning callout" role=alert><strong>Warnung:</strong> Ein unvorsichtiges Zusammenführen kann die Website lahmlegen, also sei dir sicher, dass du es auch so meinst, wenn du etwas zusammenführst.</div></li><li><p>Vergewissere dich, dass die vorgeschlagenen Änderungen den
<a href=/docs/contribute/style/content-guide/#contributing-content>Beitragsrichtlinien</a> entsprechen.</p><p>Wenn du jemals eine Frage hast oder dir bei etwas nicht sicher bist, fordere einfach Hilfe an, um eine zusätzliche Überprüfung zu erhalten.</p></li><li><p>Vergewissere dich, dass die Netlify-Tests erfolgreich sind, bevor du einen PR mittels <code>/approve</code> genehmigst.</p><img src=/images/docs/contribute/netlify-pass.png width=75% alt="Netlify-Tests müssen vor der Freigabe bestanden werden"></li><li><p>Besuche die Netlify-Seitenvorschau für den PR, um sicherzustellen, dass alles gut aussieht, bevor du es genehmigst.</p></li><li><p>Nimm am <a href=https://github.com/kubernetes/website/wiki/PR-Wranglers>PR Wrangler Rotationsplan</a>
für wöchentliche Rotationen teil. SIG Docs erwartet von allen Genehmigern, dass sie an dieser
Rotation teilnehmen. Siehe <a href=/docs/contribute/participate/pr-wranglers/>PR-Wranglers</a>.
für weitere Details.</p></li></ul><h3 id=approver-werden>Approver werden</h3><p>Wenn du die <a href=https://github.com/kubernetes/community/blob/master/community-membership.md#approver>Anforderungen</a> erfüllst,
kannst du ein SIG Docs Approver werden. Genehmigende in anderen SIGs müssen sich separat für den Approver-Status in SIG Docs bewerben.</p><p>So bewirbst du dich:</p><ol><li><p>Eröffne eine Pull-Anfrage, in der du dich in einem Abschnitt der
<a href=https://github.com/kubernetes/website/blob/main/OWNERS>OWNERS_ALIASES</a>
Datei im <code>kubernetes/website</code> Repository hinzuzufügen.</p><div class="alert alert-info note callout" role=alert><strong>Hinweis:</strong> Wenn du dir nicht sicher bist, wo du dich hinzufügen sollst, füge dich zu <code>sig-docs-de-owners</code> hinzu.</div></li><li><p>Weise den PR einem oder mehreren aktuellen SIG Docs Genehmigern zu.</p></li></ol><p>Wenn der PR genehmigt wurde, fügt dich ein SIG Docs-Lead dem entsprechenden GitHub-Team hinzu. Sobald du hinzugefügt bist,
wird <a href=https://github.com/kubernetes/test-infra/tree/master/prow#bots-home>@k8s-ci-robot</a>
dich als Reviewer für neue Pull Requests vorschlagen und zuweisen.</p><h2 id=nächste-schritte>Nächste Schritte</h2><ul><li>Erfahre mehr über <a href=/de/docs/contribute/participate/pr-wranglers/>PR-Wrangling</a>, eine Rolle, die alle Genehmiger im Wechsel übernehmen.</li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-48abd3bcfba9976d000a96a0734b90f6>7.2.2 - PR Wranglers</h1><p>SIG Docs <a href=/docs/contribute/participate/roles-and-responsibilities/#approvers>approvers</a> übernehmen einwöchige Schichten um die <a href=https://github.com/kubernetes/website/wiki/PR-Wranglers>Pull Requests</a> des Repositories zu verwalten.</p><p>Dieser Abschnitt behandelt die Aufgaben eines PR-Wranglers. Weitere Informationen über gute Reviews findest du unter <a href=/docs/contribute/review/>Überprüfen von Änderungen</a>.</p><h2 id=aufgaben>Aufgaben</h2><p>Tägliche Aufgaben in einer einwöchigen Schicht als PR Wrangler:</p><ul><li>Sortiere und kennzeichne täglich eingehende Probleme. Siehe <a href=/docs/contribute/review/for-approvers/#triage-and-categorize-issues>Einstufung und Kategorisierung von Problemen</a> für Richtlinien, wie SIG Docs Metadaten verwendet.</li><li>Überprüfe <a href=https://github.com/kubernetes/website/pulls>offene Pull Requests</a> auf Qualität und Einhaltung der <a href=/docs/contribute/style/style-guide/>Style</a> und <a href=/docs/contribute/style/content-guide/>Content</a> Leitfäden.<ul><li>Beginne mit den kleinsten PRs (<code>size/XS</code>) und ende mit den größten (<code>size/XXL</code>). Überprüfe so viele PRs, wie du kannst.</li></ul></li><li>Achte darauf, dass die PR-Autoren den <a href=https://github.com/kubernetes/community/blob/master/CLA.md>CLA</a> unterschreiben.<ul><li>Verwende <a href=https://github.com/zparnold/k8s-docs-pr-botherer>dieses</a> Skript, um diejenigen, die den CLA noch nicht unterschrieben haben, daran zu erinnern, dies zu tun.</li></ul></li><li>Gib Feedback zu den Änderungen und bitte die Mitglieder anderer SIGs um technische Überprüfung.<ul><li>Gib inline Vorschläge für die vorgeschlagenen inhaltlichen Änderungen in den PR ein.</li><li>Wenn du den Inhalt überprüfen musst, kommentiere den PR und bitte um weitere Details.</li><li>Vergebe das/die entsprechende(n) <code>sig/</code>-Label.</li><li>Falls nötig, weise die Reviever aus dem Block <code>revievers:</code> im Vorspann der Datei zu.</li></ul></li><li>Benutze den Kommentar <code>/approve</code>, um einen PR zum Zusammenführen zu genehmigen. Führe den PR zusammen, wenn er inhaltlich und technisch einwandfrei ist.<ul><li>PRs sollten einen <code>/lgtm</code>-Kommentar von einem anderen Mitglied haben, bevor sie zusammengeführt werden.</li><li>Erwäge, technisch korrekte Inhalte zu akzeptieren, die nicht den <a href=/docs/contribute/style/style-guide/>Stilrichtlinien</a> entsprechen. Eröffne ein neues Thema mit dem Label <code>good first issue</code>, um Stilprobleme anzusprechen.</li></ul></li></ul><h3 id=hilfreiche-github-anfragen-für-wranglers>Hilfreiche GitHub-Anfragen für Wranglers</h3><p>Die folgenden Anfragen sind beim Wrangling hilfreich.
Wenn du diese Anfragen abgearbeitet hast, ist die verbleibende Liste der zu prüfenden PRs meist klein.
Diese Anfragen schließen Lokalisierungs-PRs aus. Alle Anfragen beziehen sich auf den <code>main</code>-Branch, außer der letzten.</p><ul><li><a href="https://github.com/kubernetes/website/pulls?q=is%3Aopen+ist%3Apr+label%3A%22cncf-cla%3A+no%22+-label%3A%22do-not-merge%2Fwork-in-progress%22+-label%3A%22do-not-merge%2Fhold%22+label%3Alanguage%2Fen">Kein CLA, nicht zusammenfürbar</a>:
Erinnere den Beitragenden daran, den CLA zu unterschreiben. Wenn sowohl der Bot als auch ein Mensch sie daran erinnert haben, schließe
den PR und erinnere die Autoren daran, dass sie ihn erneut öffnen können, nachdem sie den CLA unterschrieben haben.
<strong>Überprüfe keine PRs, deren Autoren den CLA nicht unterschrieben haben!</strong></li><li><a href="https://github.com/kubernetes/website/pulls?q=is%3Aopen+ist%3Apr+-label%3A%22cncf-cla%3A+kein%22+-label%3Ado-not-merge%2Fwork-in-progress+-label%3Ado-not-merge%2Fhold+label%3Alanguage%2Fen+-label%3Algtm">Benötigt LGTM</a>:
Listet PRs auf, die ein LGTM von einem Mitglied benötigen. Wenn der PR eine technische Überprüfung benötigt, schalte einen der vom Bot vorgeschlagenen Reviewer ein. Wenn der Inhalt überarbeitet werden muss, füge Vorschläge und Feedback in-line hinzu.</li><li><a href="https://github.com/kubernetes/website/pulls?q=is%3Aopen+is%3Apr+-label%3Ado-not-merge%2Fwork-in-progress+-label%3Ado-not-merge%2Fhold+label%3Alanguage%2Fen+label%3Algtm+">Hat LGTM, braucht die Zustimmung von Docs</a>:
Listet PRs auf, die einen <code>/approve</code>-Kommentar benötigen, um zusammengeführt zu werden.</li><li><a href="https://github.com/kubernetes/website/pulls?utf8=%E2%9C%93&q=is%3Apr+is%3Aopen+base%3Amain+-label%3A%22do-not-merge%2Fwork-in-progress%22+-label%3A%22do-not-merge%2Fhold%22+label%3A%22cncf-cla%3A+yes%22+label%3A%22size%2FXS%22+label%3A%22language%2Fen%22">Quick Wins</a>: Listet PRs gegen den Hauptzweig auf, die nicht eindeutig blockiert sind. (ändere "XS" in der Größenbezeichnung, wenn du dich durch die PRs arbeitest [XS, S, M, L, XL, XXL]).</li><li><a href="https://github.com/kubernetes/website/pulls?q=is%3Aopen+ist%3Apr+label%3Alanguage%2Fen+-base%3Amain">Nicht gegen den <code>main</code>-Branch</a>: Wenn der PR gegen einen <code>dev-</code>Ast gerichtet ist, ist er für eine kommende Veröffentlichung. Weise diesen dem <a href=https://github.com/kubernetes/sig-release/tree/master/release-team#kubernetes-release-team-roles>Docs Release Manager</a> zu: <code>/assign @&lt;manager's_github-username></code>. Wenn der PR gegen einen alten Ast gerichtet ist, hilf dem Autor herauszufinden, ob er auf den richtigen Ast gerichtet ist.</li></ul><h3 id=hilfreiche-prow-befehle-für-wranglers>Hilfreiche Prow-Befehle für Wranglers</h3><pre tabindex=0><code># Englisches Label hinzufügen
/language en

# füge dem PR ein Squash-Label hinzu, wenn es mehr als einen Commit gibt
/label tide/merge-method-squash

# einen PR ueber Prow neu betiteln (z.B. als Work-in-Progress [WIP])
/retitle [WIP] &lt;TITLE&gt;
</code></pre><h3 id=wann-sind-pull-requests-zu-schließen>Wann sind Pull Requests zu schließen</h3><p>Reviews und Genehmigungen sind ein Mittel, um unsere PR-Warteschlange kurz und aktuell zu halten. Ein weiteres Mittel ist das Schließen.</p><p>PRs werden geschlossen, wenn:</p><ul><li><p>Der Autor den CLA seit zwei Wochen nicht unterschrieben hat.</p><p>Die Autoren können den PR wieder öffnen, nachdem sie den CLA unterschrieben haben. Dies ist ein risikoarmer Weg, um sicherzustellen, dass nichts zusammengeführt wird, ohne dass ein CLA unterzeichnet wurde.</p></li><li><p>Der Autor hat seit Zwei oder mehr Wochen nicht auf Kommentare oder Feedback geantwortet.</p></li></ul><p>Hab keine Angst, Pull Requests zu schließen. Mitwirkende können sie leicht wieder öffnen und die laufenden Arbeiten fortsetzen. Oft ist es die Nachricht über die Schließung, die einen Autor dazu anspornt, seinen Beitrag wieder aufzunehmen und zu beenden.</p><p>Um eine Pull-Anfrage zu schließen, hinterlasse einen <code>/close</code>-Kommentar zu dem PR.</p><div class="alert alert-info note callout" role=alert><strong>Hinweis:</strong> Der <a href=https://github.com/k8s-ci-robot><code>k8s-ci-robot</code></a> Bot markiert Themen nach 90 Tagen Inaktivität als veraltet. Nach weiteren 30 Tagen markiert er Issues als faul und schließt sie. PR-Beauftragte sollten Themen nach 14-30 Tagen Inaktivität schließen.</div></div><div class=td-content style=page-break-before:always><h1 id=pg-91737b3265a3e3f407fbeeb86a8973ab>8 -</h1><script language=javascript>var dropDownsPopulated=!1;$(document).ready(function(){$.get("/metadata.txt",function(e){metadata=$.parseJSON(e),metadata.pages.sort(dynamicSort("t")),mainLogic(),$(window).bind("hashchange",function(){mainLogic()})})});function mainLogic(){dropDownsPopulated||populateDropdowns();var e=window.location.hash.replace("#","");if(e){e=$.trim(e);for(i=0;i<tagName.length;i++)querystringTag=tagName[i]+"=",e.indexOf(querystringTag)>-1&&(console.log("in mainLog: querystringTag of "+querystringTag+" matches tag of "+e),e=e.replace(querystringTag,""),selectDropDown(tagName[i],e),topicsFilter(tagName[i],e,"output"))}else currentTopics=metadata.pages;renderTable(currentTopics,"output")}function populateDropdowns(){for(i=0;i<metadata.pages.length;i++){var e,t=[metadata.pages[i].cr,metadata.pages[i].or,metadata.pages[i].mr];for(j=0;j<t.length;j++)if(t[j])for(k=0;k<t[j].length;k++)typeof storedTagsArrays[j]=="undefined"&&(storedTagsArrays[j]=new Array),storedTagsArrays[j][t[j][k][tagName[j]]]=!0}e=new Array;for(i=0;i<tagName.length;i++)e=[],e.push("<select id='"+tagName[i]+"' onchange='dropFilter(this)'>"),e.push("<option>---</option>"),Object.keys(storedTagsArrays[i]).sort().forEach(function(t){e.push("<option>"+t+"</option>")}),e.push("</select>"),$(dropDowns[i]).html(e.join(""));dropDownsPopulated=!0}function dropFilter(e){console.log("dropFilter:"+$(e).attr("id")+":"+$(e).find(":selected").text()),topicsFilter($(e).attr("id").replace("#",""),$(e).find(":selected").text(),"output");for(i=0;i<tagName.length;i++)$(e).attr("id")!=tagName[i]&&selectDropDown(tagName[i],"---")}function selectDropDown(e,t){$("#"+e).val(t)}</script><style>#filters select{font-size:14px;border:1px #000 solid}#filters{padding-top:20px}</style><p>Klicken Sie auf Tags oder verwenden Sie die Dropdown-Liste zum Filtern. Klicken Sie auf Tabellenköpfe, um die Ergebnisse zu sortieren oder umzukehren.</p><p id=filters>Nach Konzept filtern: <span id=conceptFilter><br>Nach Objekt filtern: <span id=objectFilter><br>Nach Befehl filtern: <span id=commandFilter></p><div id=output></div><div class=td-content style=page-break-before:always><h1 id=pg-a0415b49c9410c15a8694fed28aa36ae>9 - Suchergebnisse</h1></div></main></div></div><footer class=d-print-none><div class=footer__links><nav><a class=text-white href=/de/docs/home/>Home</a>
<a class=text-white href=/de/blog/>Blog</a>
<a class=text-white href=/de/training/>Schulungen</a>
<a class=text-white href=/de/partners/>Partner</a>
<a class=text-white href=/de/community/>Community</a>
<a class=text-white href=/de/case-studies/>Fallstudien</a></nav></div><div class=container-fluid><div class=row><div class="col-6 col-sm-2 text-xs-center order-sm-2"><ul class="list-inline mb-0"><li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title="User mailing list" aria-label="User mailing list"><a class=text-white target=_blank href=https://discuss.kubernetes.io><i class="fa fa-envelope"></i></a></li><li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title=Twitter aria-label=Twitter><a class=text-white target=_blank href=https://twitter.com/kubernetesio><i class="fab fa-twitter"></i></a></li><li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title=Calendar aria-label=Calendar><a class=text-white target=_blank href="https://calendar.google.com/calendar/embed?src=calendar%40kubernetes.io"><i class="fas fa-calendar-alt"></i></a></li><li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title=Youtube aria-label=Youtube><a class=text-white target=_blank href=https://youtube.com/kubernetescommunity><i class="fab fa-youtube"></i></a></li></ul></div><div class="col-6 col-sm-2 text-right text-xs-center order-sm-3"><ul class="list-inline mb-0"><li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title=GitHub aria-label=GitHub><a class=text-white target=_blank href=https://github.com/kubernetes/kubernetes><i class="fab fa-github"></i></a></li><li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title=Slack aria-label=Slack><a class=text-white target=_blank href=https://slack.k8s.io><i class="fab fa-slack"></i></a></li><li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title=Contribute aria-label=Contribute><a class=text-white target=_blank href=https://git.k8s.io/community/contributors/guide><i class="fas fa-edit"></i></a></li><li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title="Stack Overflow" aria-label="Stack Overflow"><a class=text-white target=_blank href=https://stackoverflow.com/questions/tagged/kubernetes><i class="fab fa-stack-overflow"></i></a></li></ul></div><div class="col-12 col-sm-8 text-center order-sm-2"><small class=text-white>&copy; 2023 The Kubernetes Authors | Documentation Distributed under <a href=https://git.k8s.io/website/LICENSE class=light-text>CC BY 4.0</a></small><br><small class=text-white>Copyright &copy; 2023 The Linux Foundation &reg;. All rights reserved. The Linux Foundation has registered trademarks and uses trademarks. For a list of trademarks of The Linux Foundation, please see our <a href=https://www.linuxfoundation.org/trademark-usage class=light-text>Trademark Usage page</a></small><br><small class=text-white>ICP license: 京ICP备17074266号-3</small></div></div></div></footer></div><script src=/js/jquery-3.6.0.min.js integrity=sha384-vtXRMe3mGCbOeY7l30aIg8H9p3GdeSe4IFlP6G8JMa7o7lXvnz3GFKzPxzJdPfGK crossorigin=anonymous></script>
<script src=/js/popper-1.16.1.min.js intregrity=sha384-9/reFTGAW83EW2RDu2S0VKaIzap3H66lZH81PoYlFhbGU+6BZp6G7niu735Sk7lN crossorigin=anonymous></script>
<script src=/js/bootstrap-4.6.1.min.js integrity=sha384-VHvPCCyXqtD5DqJeNxl2dtTyhF78xXNXdkwX1CZeRusQfRKp+tA7hAShOK/B/fQ2 crossorigin=anonymous></script>
<script src=/js/script.js></script>
<script async src=/js/mermaid-8.13.4.min.js integrity=sha384-5hHNvPeMrNH14oM3IcQofDoBhiclNK3g2+hnEinKzQ07C4AliMeVpnvxuiwEGpaO crossorigin=anonymous></script>
<script src=/js/main.min.5c0bf7f21dc4f66485f74efbbeeff28a7e4f8cddaac1bae47043159c922ff3a3.js integrity="sha256-XAv38h3E9mSF9077vu/yin5PjN2qwbrkcEMVnJIv86M=" crossorigin=anonymous></script></body></html>