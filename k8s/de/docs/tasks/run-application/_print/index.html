<!doctype html><html lang=de class=no-js><head><meta name=robots content="noindex, nofollow"><link rel=alternate hreflang=en href=https://kubernetes.io/docs/tasks/run-application/><link rel=alternate hreflang=zh-cn href=https://kubernetes.io/zh-cn/docs/tasks/run-application/><link rel=alternate hreflang=ko href=https://kubernetes.io/ko/docs/tasks/run-application/><link rel=alternate hreflang=ja href=https://kubernetes.io/ja/docs/tasks/run-application/><link rel=alternate hreflang=fr href=https://kubernetes.io/fr/docs/tasks/run-application/><link rel=alternate hreflang=es href=https://kubernetes.io/es/docs/tasks/run-application/><link rel=alternate hreflang=id href=https://kubernetes.io/id/docs/tasks/run-application/><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=generator content="Hugo 0.110.0"><link rel=canonical type=text/html href=https://kubernetes.io/de/docs/tasks/run-application/><link rel="shortcut icon" type=image/png href=/images/favicon.png><link rel=apple-touch-icon href=/favicons/apple-touch-icon-180x180.png sizes=180x180><link rel=manifest href=/manifest.webmanifest><link rel=apple-touch-icon href=/images/kubernetes-192x192.png><title>Anwendungen ausführen | Kubernetes</title><meta property="og:title" content="Anwendungen ausführen"><meta property="og:description" content="Produktionsreife Container-Orchestrierung"><meta property="og:type" content="website"><meta property="og:url" content="https://kubernetes.io/de/docs/tasks/run-application/"><meta property="og:site_name" content="Kubernetes"><meta itemprop=name content="Anwendungen ausführen"><meta itemprop=description content="Produktionsreife Container-Orchestrierung"><meta name=twitter:card content="summary"><meta name=twitter:title content="Anwendungen ausführen"><meta name=twitter:description content="Produktionsreife Container-Orchestrierung"><link href=/scss/main.css rel=stylesheet><script type=application/ld+json>{"@context":"https://schema.org","@type":"Organization","url":"https://kubernetes.io","logo":"https://kubernetes.io/images/favicon.png","potentialAction":{"@type":"SearchAction","target":"https://kubernetes.io/search/?q={search_term_string}","query-input":"required name=search_term_string"}}</script><meta name=theme-color content="#326ce5"><link rel=stylesheet href=/css/feature-states.css><meta name=description content><meta property="og:description" content><meta name=twitter:description content><meta property="og:url" content="https://kubernetes.io/de/docs/tasks/run-application/"><meta property="og:title" content="Anwendungen ausführen"><meta name=twitter:title content="Anwendungen ausführen"><meta name=twitter:image content="https://kubernetes.io/images/favicon.png"><meta name=twitter:image:alt content="Kubernetes"><meta property="og:image" content="/images/kubernetes-horizontal-color.png"><meta property="og:type" content="article"><script src=/js/jquery-3.6.0.min.js intregrity=sha384-vtXRMe3mGCbOeY7l30aIg8H9p3GdeSe4IFlP6G8JMa7o7lXvnz3GFKzPxzJdPfGK crossorigin=anonymous></script></head><body class=td-section><header><nav class="js-navbar-scroll navbar navbar-expand navbar-dark flex-column flex-md-row td-navbar" data-auto-burger=primary><a class=navbar-brand href=/de/></a><div class="td-navbar-nav-scroll ml-md-auto" id=main_navbar><ul class="navbar-nav mt-2 mt-lg-0"><li class="nav-item mr-2 mb-lg-0"><a class="nav-link active" href=/de/docs/>Dokumentation</a></li><li class="nav-item mr-2 mb-lg-0"><a class=nav-link href=/de/blog/>Kubernetes Blog</a></li><li class="nav-item mr-2 mb-lg-0"><a class=nav-link href=/de/training/>Schulungen</a></li><li class="nav-item mr-2 mb-lg-0"><a class=nav-link href=/de/partners/>Partner</a></li><li class="nav-item mr-2 mb-lg-0"><a class=nav-link href=/de/community/>Community</a></li><li class="nav-item mr-2 mb-lg-0"><a class=nav-link href=/de/case-studies/>Fallstudien</a></li><li class="nav-item dropdown"><a class="nav-link dropdown-toggle" href=# id=navbarDropdown role=button data-toggle=dropdown aria-haspopup=true aria-expanded=false>Versions</a><div class="dropdown-menu dropdown-menu-right" aria-labelledby=navbarDropdownMenuLink><a class=dropdown-item href=/de/releases>Release Information</a>
<a class=dropdown-item href=https://kubernetes.io/de/docs/tasks/run-application/>v1.25</a>
<a class=dropdown-item href=https://v1-24.docs.kubernetes.io/de/docs/tasks/run-application/>v1.24</a>
<a class=dropdown-item href=https://v1-23.docs.kubernetes.io/de/docs/tasks/run-application/>v1.23</a>
<a class=dropdown-item href=https://v1-22.docs.kubernetes.io/de/docs/tasks/run-application/>v1.22</a>
<a class=dropdown-item href=https://v1-21.docs.kubernetes.io/de/docs/tasks/run-application/>v1.21</a></div></li><li class="nav-item dropdown"><a class="nav-link dropdown-toggle" href=# id=navbarDropdownMenuLink role=button data-toggle=dropdown aria-haspopup=true aria-expanded=false>Deutsch (German)</a><div class="dropdown-menu dropdown-menu-right" aria-labelledby=navbarDropdownMenuLink><a class=dropdown-item href=/docs/tasks/run-application/>English</a>
<a class=dropdown-item href=/zh-cn/docs/tasks/run-application/>中文 (Chinese)</a>
<a class=dropdown-item href=/ko/docs/tasks/run-application/>한국어 (Korean)</a>
<a class=dropdown-item href=/ja/docs/tasks/run-application/>日本語 (Japanese)</a>
<a class=dropdown-item href=/fr/docs/tasks/run-application/>Français (French)</a>
<a class=dropdown-item href=/es/docs/tasks/run-application/>Español (Spanish)</a>
<a class=dropdown-item href=/id/docs/tasks/run-application/>Bahasa Indonesia</a></div></li></ul></div><button id=hamburger onclick=kub.toggleMenu() data-auto-burger-exclude><div></div></button></nav></header><div class="container-fluid td-outer"><div class=td-main><div class="row flex-xl-nowrap"><main class="col-12 col-md-9 col-xl-8 pl-md-5" role=main><div class=td-content><div class="pageinfo pageinfo-primary d-print-none"><p>Das ist eine für den Ausdruck optimierte Ansicht des gesamten Kapitels inkl. Unterseiten.
<a href=# onclick="return print(),!1">Druckvorgang starten</a>.</p><p><a href=/de/docs/tasks/run-application/>Zur Standardansicht zurückkehren</a>.</p></div><h1 class=title>Anwendungen ausführen</h1><ul><li>1: <a href=#pg-0c0bb1bd76d2a9069e50e2cec6d20c2a>Horizontal Pod Autoscaler</a></li></ul><div class=content></div></div><div class=td-content><h1 id=pg-0c0bb1bd76d2a9069e50e2cec6d20c2a>1 - Horizontal Pod Autoscaler</h1><p>Der Horizontal Pod Autoscaler skaliert automatisch die Anzahl der Pods eines Replication Controller, Deployment oder Replikat Set basierend auf der beobachteten CPU-Auslastung (oder, mit Unterstützung von <a href=https://git.k8s.io/design-proposals-archive/instrumentation/custom-metrics-api.md>benutzerdefinierter Metriken</a>, von der Anwendung bereitgestellten Metriken). Beachte, dass die horizontale Pod Autoskalierung nicht für Objekte gilt, die nicht skaliert werden können, z. B. DaemonSets.</p><p>Der Horizontal Pod Autoscaler ist als Kubernetes API-Ressource und einem Controller implementiert.
Die Ressource bestimmt das Verhalten des Controllers.
Der Controller passt die Anzahl der Replikate eines Replication Controller oder Deployments regelmäßig an, um die beobachtete durchschnittliche CPU-Auslastung an das vom Benutzer angegebene Ziel anzupassen.</p><h2 id=wie-funktioniert-der-horizontal-pod-autoscaler>Wie funktioniert der Horizontal Pod Autoscaler?</h2><p><img src=/images/docs/horizontal-pod-autoscaler.svg alt="Horizontal Pod Autoscaler Diagramm"></p><p>Der Horizontal Pod Autoscaler ist als Kontrollschleife mit einer Laufzeit implementiert, die durch das Flag <code>--horizontal-pod-autoscaler-sync-period</code> am Controller Manager gesteuert wird (mit einem Standardwert von 15 Sekunden).</p><p>Während jedem Durchlauf fragt der Controller Manager die Ressourcennutzung anhand der in jeder HorizontalPodAutoscaler Definition angegebenen Metriken ab. Der Controller Manager bezieht die Metriken entweder aus der Resource Metrics API (für Ressourcenmetriken pro Pod) oder aus der Custom Metrics API (für alle anderen Metriken).</p><ul><li>Für jede pro Pod Ressourcenmetriken (wie CPU) ruft der Controller die Metriken über die Ressourcenmetriken API für jeden Pod ab, der vom HorizontalPodAutoscaler angesprochen wird. Sofern ein Zielnutzungswert eingestellt ist, berechnet der Controller den Nutzungswert als Prozentsatz der äquivalenten Ressourcenanforderung der Containern in jedem Pod. Wenn ein Ziel-Rohwert eingestellt ist, werden die Rohmetrikenwerte direkt verwendet. Der Controller nimmt dann den Mittelwert der Auslastung oder den Rohwert (je nach Art des angegebenen Ziels) über alle Zielpods und erzeugt ein Quotienten, mit dem die Anzahl der gewünschten Replikate skaliert wird.</li></ul><p>Beachte, dass, wenn einige der Container des Pods nicht über den entsprechenden Ressourcenanforderung verfügen, die CPU-Auslastung für den Pod nicht definiert wird und der Autoscaler keine Maßnahmen bezüglich dieser Metrik ergreift. Weitere Informationen zur Funktionsweise des Autoskalierungsalgorithmus finden Sie im folgenden Abschnitt über den <a href=#details-zum-algorithmus>Algorithmus</a>.</p><ul><li><p>Bei benutzerdefinierten Metriken pro Pod funktioniert die Steuerung ähnlich wie bei Ressourcenmetriken pro Pod, nur dass diese mit Rohwerten und nicht mit Nutzungswerten arbeitet.</p></li><li><p>Für Objektmetriken und externe Metriken wird eine einzelne Metrik abgerufen, die das jeweilige Objekt beschreibt. Diese Kennzahl wird mit dem Sollwert verglichen, um ein Verhältnis wie oben beschrieben zu erhalten. In der API-Version von <code>autoscaling/v2beta2</code> kann dieser Wert optional durch die Anzahl der Pods geteilt werden, bevor der Vergleich durchgeführt wird.</p></li></ul><p>Der HorizontalPodAutoscaler holt Metriken normalerweise aus einer Reihe von aggregierten APIs (<code>metrics.k8s.io</code>, <code>custom.metrics.k8s.io</code> und <code>external.metrics.k8s.io</code>). Die API <code>metrics.k8s.io</code> wird normalerweise vom Metrics Server bereitgestellt, der separat gestartet werden muss. Siehe <a href=/docs/tasks/debug-application-cluster/resource-metrics-pipeline/#metrics-server>Metrics Server</a> für weitere Anweisungen. Der HorizontalPodAutoscaler kann auch Metriken direkt aus dem Heapster beziehen.</p><div class="alert alert-info note callout" role=alert><strong>Hinweis:</strong><div style=margin-top:10px;margin-bottom:10px><b>FEATURE STATE:</b> <code>Kubernetes 1.11 [deprecated]</code></div><p>Das Verwenden von Metriken aus Heapster ist seit der Kubernetes Version 1.11 veraltet.</div><p>Siehe <a href=#unterst%C3%BCtzung-der-metrik-apis>Unterstützung der Metrik APIs</a> für weitere Details.</p><p>Der Autoscaler greift über die Scale Sub-Ressource auf die entsprechenden skalierbaren Controller (z.B. Replication Controller, Deployments und Replika Sets) zu. Scale ist eine Schnittstelle, mit der Sie die Anzahl der Replikate dynamisch einstellen und jeden ihrer aktuellen Zustände untersuchen können. Weitere Details zu der Scale Sub-Ressource findest du <a href=https://git.k8s.io/design-proposals-archive/autoscaling/horizontal-pod-autoscaler.md#scale-subresource>hier</a>.</p><h3 id=details-zum-algorithmus>Details zum Algorithmus</h3><p>Vereinfacht gesagt arbeitet der Horizontal Pod Autoscaler Controller mit dem Verhältnis zwischen dem gewünschten metrischen Wert und dem aktuellen metrischen Wert:</p><pre tabindex=0><code>desiredReplicas = ceil[currentReplicas * ( currentMetricValue / desiredMetricValue )]
</code></pre><p>Wenn beispielsweise der aktuelle metrische Wert <code>200m</code> und der gewünschte Wert <code>100m</code> ist, wird die Anzahl der Replikate verdoppelt, da <code>200.0 / 100.0 == 2.0</code> ist. Wenn der aktuelle Wert jedoch <code>50m</code> ist, halbieren sich die Anzahl der Replikate <code>50.0 / 100.0 == 0.5</code>. Es wird auf die Skalierung verzichtet, wenn das Verhältnis ausreichend nahe bei 1,0 liegt (innerhalb einer global konfigurierbaren Toleranz, vom Flag <code>--horizontal-pod-autoscaler-tolerance</code>, das standardmäßig auf 0,1 gesetzt ist).</p><p>Wenn ein <code>targetAverageValue</code> oder <code>targetAverageUtilization</code> angegeben wird, wird der <code>currentMetricValue</code> berechnet, indem der Mittelwert der gegebenen Metrik über alle Pods im Skalierungsziel des HorizontalPodAutoscaler berechnet wird. Vor der Überprüfung der Toleranz und der Entscheidung über die finalen Werte berücksichtigen wir jedoch die Pod Readiness und fehlende Metriken.</p><p>Alle Pods mit einem gesetzten Zeitstempel zur Löschung (d.h. Pods, die gerade heruntergefahren werden) und alle ausgefallenen Pods werden verworfen.</p><p>Wenn einem bestimmten Pod Metriken fehlen, wird es für später zurückgestellt; Pods mit fehlenden Metriken werden verwendet, um den endgültigen Skalierungsmenge anzupassen.</p><p>Wenn bei der Skalierung anhand der CPU ein Pod noch nicht bereit ist (d.h. er wird noch initialisiert) <em>oder</em> der letzte metrische Punkt für den Pod vor dessen Einsatzbereitschaft liegt, wird auch dieser Pod zurückgestellt.</p><p>Aufgrund technischer Einschränkungen kann der HorizontalPodAutoscaler Controller nicht genau bestimmen, wann ein Pod zum ersten Mal bereit ist, wenn es darum geht, bestimmte CPU Metriken festzulegen. Stattdessen betrachtet er eine Pod als "not yet ready", wenn dieser noch nicht bereit ist und geht in "unready" über, innerhalb eines kurzen, konfigurierbaren Zeitfensters seit dem Start.
Dieser Wert wird mit dem Flag <code>--horizontal-pod-autoscaler-initial-readiness-delay</code> konfiguriert und ist standardmäßig auf 30 Sekunden eingestellt. Sobald ein Pod bereit ist, betrachtet er jeden Übergang zu Bereit als den ersten, wenn dies innerhalb einer längeren, konfigurierbaren Zeit seit seinem Start erfolgt ist. Dieser Wert wird mit dem Flag <code>--horizontal-pod-autoscaler-cpu-initialization-period</code> gesetzt und dessen Standardwert beträgt 5 Minuten.</p><p>Das Basisskalenverhältnis <code>currentMetricValue / desiredMetricValue</code> wird dann mit den restlichen Pods berechnet, die nicht zurückgestellt oder von den oben genannten Kriterien entsorgt wurden.</p><p>Wenn es irgendwelche fehlenden Metriken gab, berechnen wir den Durchschnitt konservativer, vorausgesetzt, dass die Pods 100% des gewünschten Wertes bei der Verringerung und 0% bei einer Vergrößerung verbrauchten. Dadurch wird die Dimension einer beliebigen potenziellen Skalierung verringert.</p><p>Wenn außerdem noch nicht bereite Pods vorhanden sind und es ohne Berücksichtigung fehlender Metriken oder noch nicht bereiter Pods skaliert wurde, wird konservativ davon ausgegangen, dass die noch nicht bereiten Pods 0% der gewünschten Metrik verbrauchen, was die Dimension einer Skalierung weiter dämpft.</p><p>Nach Berücksichtigung der noch nicht bereiten Pods und fehlender Metriken wird der Nutzungsgrad neu berechnet. Wenn das neue Verhältnis die Skalierungsrichtung umkehrt oder innerhalb der Toleranz liegt, wird das weitere Skalieren übersprungen. Andernfalls wird das neue Verhältnis zur Skalierung verwendet.</p><p>Beachte, dass der <em>ursprüngliche</em> Wert für die durchschnittliche Auslastung über den HorizontalPodAutoscaler Status zurückgemeldet wird, ohne die noch nicht bereiten Pods oder fehlende Metriken zu berücksichtigen, selbst wenn das neue Nutzungsverhältnis verwendet wird.</p><p>Wenn mehrere Metriken in einem HorizontalPodAutoscaler angegeben sind, wird die Berechnung für jede Metrik durchgeführt, und dann wird die größte der gewünschten Replikanzahl ausgewählt. Wenn eine dieser Metriken nicht in eine gewünschte Replikanzahl umgewandelt werden kann (z.B. aufgrund eines Fehlers beim Abrufen der Metriken aus den Metrik APIs), wird diese Skalierung übersprungen.</p><p>Schließlich, kurz bevor HPA das Ziel skaliert, wird die Skalierungsempfehlung aufgezeichnet. Der Controller berücksichtigt alle Empfehlungen innerhalb eines konfigurierbaren Fensters und wählt aus diesem Fenster die höchste Empfehlung aus. Dieser Wert kann mit dem Flag <code>--horizontal-pod-autoscaler-downscale-stabilization</code> konfiguriert werden, das standardmäßig auf 5 Minuten eingestellt ist. Dies bedeutet, dass die Skalierung schrittweise erfolgt, wodurch die Auswirkungen schnell schwankender metrischer Werte ausgeglichen werden.</p><h2 id=api-objekt>API Objekt</h2><p>Der Horizontal Pod Autoscaler ist eine API Ressource in der Kubernetes <code>autoscaling</code> API Gruppe.
Die aktuelle stabile Version, die nur die Unterstützung für die automatische Skalierung der CPU beinhaltet, befindet sich in der <code>autoscaling/v1</code> API Version.</p><p>Die Beta-Version, welche die Skalierung des Speichers und benutzerdefinierte Metriken unterstützt, befindet sich unter <code>autoscaling/v2beta2</code>. Die in <code>autoscaling/v2beta2</code> neu eingeführten Felder bleiben bei der Arbeit mit <code>autoscaling/v1</code> als Anmerkungen erhalten.</p><p>Weitere Details über das API Objekt kann unter dem <a href=https://git.k8s.io/design-proposals-archive/autoscaling/horizontal-pod-autoscaler.md#horizontalpodautoscaler-object>HorizontalPodAutoscaler Objekt</a> gefunden werden.</p><h2 id=unterstützung-des-horizontal-pod-autoscaler-in-kubectl>Unterstützung des Horizontal Pod Autoscaler in kubectl</h2><p>Der Horizontal Pod Autoscaler wird, wie jede API-Ressource, standardmäßig von <code>kubectl</code> unterstützt.
Ein neuer Autoskalierer kann mit dem Befehl <code>kubectl create</code> erstellt werden.
Das auflisten der Autoskalierer geschieht über <code>kubectl get hpa</code> und eine detaillierte Beschreibung erhält man mit <code>kubectl describe hpa</code>.
Letzendlich können wir einen Autoskalierer mit <code>kubectl delete hpa</code> löschen.</p><p>Zusätzlich gibt es einen speziellen Befehl <code>kubectl autoscale</code> zur einfachen Erstellung eines Horizontal Pod Autoscalers.
Wenn du beispielsweise <code>kubectl autoscale rs foo --min=2 --max=5 --cpu-percent=80</code> ausführst, wird ein Autoskalierer für den ReplicaSet <em>foo</em> erstellt, wobei die Ziel-CPU-Auslastung auf <code>80%</code> und die Anzahl der Replikate zwischen 2 und 5 gesetzt wird.
Die Detaildokumentation von <code>kubectl autoscale</code> kann <a href=/docs/reference/generated/kubectl/kubectl-commands/#autoscale>hier</a> gefunden werden.</p><h2 id=autoskalieren-während-rollierender-updates>Autoskalieren während rollierender Updates</h2><p>Derzeit ist es in Kubernetes möglich, ein <a href=/docs/tasks/run-application/rolling-update-replication-controller/>rollierendes Update</a> durchzuführen, indem du den Replikationscontroller direkt verwaltest oder das Deployment Objekt verwendest, das die zugrunde liegenden Replica Sets für dich verwaltet.
Der Horizontal Pod Autoscaler unterstützt nur den letztgenannten Ansatz: Der Horizontal Pod Autoscaler ist an das Deployment Objekt gebunden, er legt die Größe für das Deployment Objekt fest, und das Deployment ist für die Festlegung der Größen der zugrunde liegenden Replica Sets verantwortlich.</p><p>Der Horizontal Pod Autoscaler funktioniert nicht mit rollierendem Update durch direkte Manipulation vom Replikationscontrollern, d.h. du kannst einen Horizontal Pod Autoscaler nicht an einen Replikationscontroller binden und rollierend aktualisieren (z.B. mit <code>kubectl rolling-update</code>).
Der Grund dafür ist, dass beim Erstellen eines neuen Replikationscontrollers durch ein rollierendes Update der Horizontal Pod Autoscaler nicht an den neue Replikationscontroller gebunden wird.</p><h2 id=unterstützung-von-abklingzeiten-verzögerungen>Unterstützung von Abklingzeiten/Verzögerungen</h2><p>Bei der Verwaltung der Größe einer Gruppe von Replikaten mit dem Horizontal Pod Autoscaler ist es möglich, dass die Anzahl der Replikate aufgrund der Dynamik der ausgewerteten Metriken häufig schwankt. Dies wird manchmal als <em>thrashing</em>, zu deutsch <em>Flattern</em>, bezeichnet.</p><p>Ab v1.6 kann ein Cluster Operator dieses Problem mitigieren, indem er die globalen HPA Einstellungen anpasst, die als Flags für die Komponente <code>kube-controller-manager</code> dargelegt werden:</p><p>Ab v1.12 erübrigt ein neues Update des Algorithmus die Notwendigkeit der Verzögerung beim hochskalieren.</p><ul><li><code>--horizontal-pod-autoscaler-downscale-stabilization</code>: Der Wert für diese Option ist eine Dauer, die angibt, wie lange der Autoscaler warten muss, bis nach Abschluss des aktuellen Skalierungsvorgangs ein weiterer Downscale durchgeführt werden kann.
Der Standardwert ist 5 Minuten (<code>5m0s</code>).</li></ul><div class="alert alert-info note callout" role=alert><strong>Hinweis:</strong> Beim Abstimmen dieser Parameterwerte sollte sich ein Clusterbetreiber der möglichen Konsequenzen bewusst sein. Wenn der Wert für die Verzögerung (Abklingzeit) zu groß eingestellt ist, kann es zu Beschwerden kommen, dass der Horizontal Pod Autoscaler nicht auf Änderungen der Arbeitslast reagiert. Wenn der Verzögerungswert jedoch zu kurz eingestellt ist, kann es vorkommen, dass die Skalierung der eingestellten Replikate wie gewohnt weiter flattert.</div><h2 id=unterstützung-von-mehrere-metriken>Unterstützung von mehrere Metriken</h2><p>Kubernetes 1.6 bietet Unterstützung für die Skalierung basierend auf mehreren Metriken. Du kannst die API Version <code>autoscaling/v2beta2</code> verwenden, um mehrere Metriken für den Horizontal Pod Autoscaler zum Skalieren festzulegen. Anschließend wertet der Horizontal Pod Autoscaler Controller jede Metrik aus und schlägt eine neue Skalierung basierend auf diesen Metrik vor. Die größte der vorgeschlagenen Skalierung wird als neue Skalierung verwendet.</p><h2 id=unterstützung-von-benutzerdefinierte-metriken>Unterstützung von benutzerdefinierte Metriken</h2><div class="alert alert-info note callout" role=alert><strong>Hinweis:</strong> Kubernetes 1.2 bietet Alpha Unterstützung für die Skalierung basierend auf anwendungsspezifischen Metriken über speziellen Annotations. Die Unterstützung für diese Annotations wurde in Kubernetes 1.6 zugunsten der neuen autoskalierenden API entfernt. Während die alte Methode zum Sammeln von benutzerdefinierten Metriken weiterhin verfügbar ist, stehen diese Metriken dem Horizontal Pod Autoscaler nicht mehr zur Verfügung, ebenso wenig wie die früheren Annotations zur Angabe, welche benutzerdefinierten Metriken zur Skalierung vom Horizontal Pod Autoscaler Controller berücksichtigt werden sollen.</div><p>Kubernetes 1.6 bietet Unterstützung für die Verwendung benutzerdefinierter Metriken im Horizontal Pod Autoscaler.
Du kannst benutzerdefinierte Metriken für den Horizontal Pod Autoscaler hinzufügen, die in der <code>autoscaling/v2beta2</code> API verwendet werden.
Kubernetes fragt dann die neue API für die benutzerdefinierte Metriken ab, um die Werte der entsprechenden benutzerdefinierten Metriken zu erhalten.</p><p>Die Voraussetzungen hierfür werden im nachfolgenden Kapitel <a href=#unterst%C3%BCtzung-der-metrik-apis>Unterstützung für die Metrik APIs</a> geklärt.</p><h2 id=unterstützung-der-metrik-apis>Unterstützung der Metrik APIs</h2><p>Standardmäßig ruft der HorizontalPodAutoscaler Controller Metriken aus einer Reihe von APIs ab. Damit dieser auf die APIs zugreifen kann, muss der Cluster Administratoren sicherstellen, dass:</p><ul><li><p>Der <a href=/docs/tasks/access-kubernetes-api/configure-aggregation-layer/>API Aggregations Layer</a> aktiviert ist.</p></li><li><p>Die entsprechenden APIs registriert sind:</p><ul><li><p>Für Ressourcenmetriken ist dies die API <code>metrics.k8s.io</code>, die im Allgemeinen von <a href=https://github.com/kubernetes-incubator/metrics-server>metrics-server</a> bereitgestellt wird.
Es kann als Cluster-Addon gestartet werden.</p></li><li><p>Für benutzerdefinierte Metriken ist dies die API <code>custom.metrics.k8s.io</code>. Diese wird vom "Adapter" API Servern bereitgestellt, welches von Anbietern von Metrik Lösungen beliefert wird.
Überprüfe dies mit deiner Metrik Pipeline oder der <a href=https://github.com/kubernetes/metrics/blob/master/IMPLEMENTATIONS.md#custom-metrics-api>Liste bekannter Lösungen</a>.
Falls du deinen eigenen schreiben möchtest hilft dir folgender <a href=https://github.com/kubernetes-incubator/custom-metrics-apiserver>boilerplate</a> um zu starten.</p></li><li><p>Für externe Metriken ist dies die <code>external.metrics.k8s.io</code> API. Es kann sein, dass dies durch den benutzerdefinierten Metrik Adapter bereitgestellt wird.</p></li></ul></li><li><p>Das Flag <code>--horizontal-pod-autoscaler-use-rest-clients</code> ist auf <code>true</code> oder ungesetzt. Wird dies auf <code>false</code> gesetzt wird die Heapster basierte Autoskalierung aktiviert, welche veraltet ist.</p></li></ul><h2 id=nächste-schritte>Nächste Schritte</h2><ul><li>Design Dokument <a href=https://git.k8s.io/design-proposals-archive/autoscaling/horizontal-pod-autoscaler.md>Horizontal Pod Autoscaling</a>.</li><li>kubectl autoscale Befehl: <a href=/docs/reference/generated/kubectl/kubectl-commands/#autoscale>kubectl autoscale</a>.</li><li>Verwenden des <a href=/docs/tasks/run-application/horizontal-pod-autoscale-walkthrough/>Horizontal Pod Autoscaler</a>.</li></ul></div></main></div></div><footer class=d-print-none><div class=footer__links><nav><a class=text-white href=/de/docs/home/>Home</a>
<a class=text-white href=/de/blog/>Blog</a>
<a class=text-white href=/de/training/>Schulungen</a>
<a class=text-white href=/de/partners/>Partner</a>
<a class=text-white href=/de/community/>Community</a>
<a class=text-white href=/de/case-studies/>Fallstudien</a></nav></div><div class=container-fluid><div class=row><div class="col-6 col-sm-2 text-xs-center order-sm-2"><ul class="list-inline mb-0"><li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title="User mailing list" aria-label="User mailing list"><a class=text-white target=_blank href=https://discuss.kubernetes.io><i class="fa fa-envelope"></i></a></li><li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title=Twitter aria-label=Twitter><a class=text-white target=_blank href=https://twitter.com/kubernetesio><i class="fab fa-twitter"></i></a></li><li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title=Calendar aria-label=Calendar><a class=text-white target=_blank href="https://calendar.google.com/calendar/embed?src=calendar%40kubernetes.io"><i class="fas fa-calendar-alt"></i></a></li><li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title=Youtube aria-label=Youtube><a class=text-white target=_blank href=https://youtube.com/kubernetescommunity><i class="fab fa-youtube"></i></a></li></ul></div><div class="col-6 col-sm-2 text-right text-xs-center order-sm-3"><ul class="list-inline mb-0"><li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title=GitHub aria-label=GitHub><a class=text-white target=_blank href=https://github.com/kubernetes/kubernetes><i class="fab fa-github"></i></a></li><li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title=Slack aria-label=Slack><a class=text-white target=_blank href=https://slack.k8s.io><i class="fab fa-slack"></i></a></li><li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title=Contribute aria-label=Contribute><a class=text-white target=_blank href=https://git.k8s.io/community/contributors/guide><i class="fas fa-edit"></i></a></li><li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title="Stack Overflow" aria-label="Stack Overflow"><a class=text-white target=_blank href=https://stackoverflow.com/questions/tagged/kubernetes><i class="fab fa-stack-overflow"></i></a></li></ul></div><div class="col-12 col-sm-8 text-center order-sm-2"><small class=text-white>&copy; 2023 The Kubernetes Authors | Documentation Distributed under <a href=https://git.k8s.io/website/LICENSE class=light-text>CC BY 4.0</a></small><br><small class=text-white>Copyright &copy; 2023 The Linux Foundation &reg;. All rights reserved. The Linux Foundation has registered trademarks and uses trademarks. For a list of trademarks of The Linux Foundation, please see our <a href=https://www.linuxfoundation.org/trademark-usage class=light-text>Trademark Usage page</a></small><br><small class=text-white>ICP license: 京ICP备17074266号-3</small></div></div></div></footer></div><script src=/js/jquery-3.6.0.min.js integrity=sha384-vtXRMe3mGCbOeY7l30aIg8H9p3GdeSe4IFlP6G8JMa7o7lXvnz3GFKzPxzJdPfGK crossorigin=anonymous></script>
<script src=/js/popper-1.16.1.min.js intregrity=sha384-9/reFTGAW83EW2RDu2S0VKaIzap3H66lZH81PoYlFhbGU+6BZp6G7niu735Sk7lN crossorigin=anonymous></script>
<script src=/js/bootstrap-4.6.1.min.js integrity=sha384-VHvPCCyXqtD5DqJeNxl2dtTyhF78xXNXdkwX1CZeRusQfRKp+tA7hAShOK/B/fQ2 crossorigin=anonymous></script>
<script src=/js/script.js></script>
<script async src=/js/mermaid-8.13.4.min.js integrity=sha384-5hHNvPeMrNH14oM3IcQofDoBhiclNK3g2+hnEinKzQ07C4AliMeVpnvxuiwEGpaO crossorigin=anonymous></script>
<script src=/js/main.min.5c0bf7f21dc4f66485f74efbbeeff28a7e4f8cddaac1bae47043159c922ff3a3.js integrity="sha256-XAv38h3E9mSF9077vu/yin5PjN2qwbrkcEMVnJIv86M=" crossorigin=anonymous></script></body></html>