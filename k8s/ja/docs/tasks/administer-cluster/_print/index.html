<!doctype html><html lang=ja class=no-js><head><meta name=robots content="noindex, nofollow"><link rel=alternate hreflang=en href=https://kubernetes.io/docs/tasks/administer-cluster/><link rel=alternate hreflang=zh-cn href=https://kubernetes.io/zh-cn/docs/tasks/administer-cluster/><link rel=alternate hreflang=ko href=https://kubernetes.io/ko/docs/tasks/administer-cluster/><link rel=alternate hreflang=fr href=https://kubernetes.io/fr/docs/tasks/administer-cluster/><link rel=alternate hreflang=de href=https://kubernetes.io/de/docs/tasks/administer-cluster/><link rel=alternate hreflang=es href=https://kubernetes.io/es/docs/tasks/administer-cluster/><link rel=alternate hreflang=id href=https://kubernetes.io/id/docs/tasks/administer-cluster/><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=generator content="Hugo 0.110.0"><link rel=canonical type=text/html href=https://kubernetes.io/ja/docs/tasks/administer-cluster/><link rel="shortcut icon" type=image/png href=/images/favicon.png><link rel=apple-touch-icon href=/favicons/apple-touch-icon-180x180.png sizes=180x180><link rel=manifest href=/manifest.webmanifest><link rel=apple-touch-icon href=/images/kubernetes-192x192.png><title>クラスターの管理 | Kubernetes</title><meta property="og:title" content="クラスターの管理"><meta property="og:description" content="クラスターの管理のための一般的なタスクについて学びます。"><meta property="og:type" content="website"><meta property="og:url" content="https://kubernetes.io/ja/docs/tasks/administer-cluster/"><meta property="og:site_name" content="Kubernetes"><meta itemprop=name content="クラスターの管理"><meta itemprop=description content="クラスターの管理のための一般的なタスクについて学びます。"><meta name=twitter:card content="summary"><meta name=twitter:title content="クラスターの管理"><meta name=twitter:description content="クラスターの管理のための一般的なタスクについて学びます。"><link href=/scss/main.css rel=stylesheet><script type=application/ld+json>{"@context":"https://schema.org","@type":"Organization","url":"https://kubernetes.io","logo":"https://kubernetes.io/images/favicon.png","potentialAction":{"@type":"SearchAction","target":"https://kubernetes.io/search/?q={search_term_string}","query-input":"required name=search_term_string"}}</script><meta name=theme-color content="#326ce5"><link rel=stylesheet href=/css/feature-states.css><meta name=description content="クラスターの管理のための一般的なタスクについて学びます。"><meta property="og:description" content="クラスターの管理のための一般的なタスクについて学びます。"><meta name=twitter:description content="クラスターの管理のための一般的なタスクについて学びます。"><meta property="og:url" content="https://kubernetes.io/ja/docs/tasks/administer-cluster/"><meta property="og:title" content="クラスターの管理"><meta name=twitter:title content="クラスターの管理"><meta name=twitter:image content="https://kubernetes.io/images/favicon.png"><meta name=twitter:image:alt content="Kubernetes"><meta property="og:image" content="/images/kubernetes-horizontal-color.png"><meta property="og:type" content="article"><script src=/js/jquery-3.6.0.min.js intregrity=sha384-vtXRMe3mGCbOeY7l30aIg8H9p3GdeSe4IFlP6G8JMa7o7lXvnz3GFKzPxzJdPfGK crossorigin=anonymous></script></head><body class=td-section><header><nav class="js-navbar-scroll navbar navbar-expand navbar-dark flex-column flex-md-row td-navbar" data-auto-burger=primary><a class=navbar-brand href=/ja/></a><div class="td-navbar-nav-scroll ml-md-auto" id=main_navbar><ul class="navbar-nav mt-2 mt-lg-0"><li class="nav-item mr-2 mb-lg-0"><a class="nav-link active" href=/ja/docs/>ドキュメント</a></li><li class="nav-item mr-2 mb-lg-0"><a class=nav-link href=/ja/blog/>Blogs</a></li><li class="nav-item mr-2 mb-lg-0"><a class=nav-link href=/ja/training/>トレーニング</a></li><li class="nav-item mr-2 mb-lg-0"><a class=nav-link href=/ja/partners/>パートナー</a></li><li class="nav-item mr-2 mb-lg-0"><a class=nav-link href=/ja/community/>コミュニティ</a></li><li class="nav-item mr-2 mb-lg-0"><a class=nav-link href=/ja/case-studies/>ケーススタディ</a></li><li class="nav-item dropdown"><a class="nav-link dropdown-toggle" href=# id=navbarDropdown role=button data-toggle=dropdown aria-haspopup=true aria-expanded=false>バージョン</a><div class="dropdown-menu dropdown-menu-right" aria-labelledby=navbarDropdownMenuLink><a class=dropdown-item href=/ja/releases>Release Information</a>
<a class=dropdown-item href=https://kubernetes.io/ja/docs/tasks/administer-cluster/>v1.25</a>
<a class=dropdown-item href=https://v1-24.docs.kubernetes.io/ja/docs/tasks/administer-cluster/>v1.24</a>
<a class=dropdown-item href=https://v1-23.docs.kubernetes.io/ja/docs/tasks/administer-cluster/>v1.23</a>
<a class=dropdown-item href=https://v1-22.docs.kubernetes.io/ja/docs/tasks/administer-cluster/>v1.22</a>
<a class=dropdown-item href=https://v1-21.docs.kubernetes.io/ja/docs/tasks/administer-cluster/>v1.21</a></div></li><li class="nav-item dropdown"><a class="nav-link dropdown-toggle" href=# id=navbarDropdownMenuLink role=button data-toggle=dropdown aria-haspopup=true aria-expanded=false>日本語 (Japanese)</a><div class="dropdown-menu dropdown-menu-right" aria-labelledby=navbarDropdownMenuLink><a class=dropdown-item href=/docs/tasks/administer-cluster/>English</a>
<a class=dropdown-item href=/zh-cn/docs/tasks/administer-cluster/>中文 (Chinese)</a>
<a class=dropdown-item href=/ko/docs/tasks/administer-cluster/>한국어 (Korean)</a>
<a class=dropdown-item href=/fr/docs/tasks/administer-cluster/>Français (French)</a>
<a class=dropdown-item href=/de/docs/tasks/administer-cluster/>Deutsch (German)</a>
<a class=dropdown-item href=/es/docs/tasks/administer-cluster/>Español (Spanish)</a>
<a class=dropdown-item href=/id/docs/tasks/administer-cluster/>Bahasa Indonesia</a></div></li></ul></div><button id=hamburger onclick=kub.toggleMenu() data-auto-burger-exclude><div></div></button></nav></header><div class="container-fluid td-outer"><div class=td-main><div class="row flex-xl-nowrap"><main class="col-12 col-md-9 col-xl-8 pl-md-5" role=main><div class=td-content><div class="pageinfo pageinfo-primary d-print-none"><p>これは、このセクションの複数ページの印刷可能なビューです。
<a href=# onclick="return print(),!1">印刷するには、ここをクリックしてください</a>.</p><p><a href=/ja/docs/tasks/administer-cluster/>このページの通常のビューに戻る</a>.</p></div><h1 class=title>クラスターの管理</h1><div class=lead>クラスターの管理のための一般的なタスクについて学びます。</div><ul><li>1: <a href=#pg-adb6c52e773f4d890595e14a9251f59b>dockershimからの移行</a></li><ul><li>1.1: <a href=#pg-d79db9ed1698f75ec5f2228987290e49>ノードで使用されているコンテナランタイムの確認</a></li><li>1.2: <a href=#pg-58702e4818c09c9b3d574349c1a71cb3>Dockershim非推奨の影響範囲を確認する</a></li><li>1.3: <a href=#pg-eb3e279a6c5e1224e744080a52ee3f28>dockershimからテレメトリーやセキュリティエージェントを移行する</a></li></ul><li>2: <a href=#pg-8e16d69617b175d61e2e7a6e1642c9d6>kubeadmによる管理</a></li><ul><li>2.1: <a href=#pg-6134c5061298affa145ddb801b5c29da>cgroupドライバーの設定</a></li><li>2.2: <a href=#pg-f62fba1de4084f3be070785757c8079c>kubeadmによる証明書管理</a></li><li>2.3: <a href=#pg-9133578f1e75663bb031e5a377ca896d>Windowsノードの追加</a></li><li>2.4: <a href=#pg-e805c7d8d4ad6195cb82dbbc843bfc29>Windowsノードのアップグレード</a></li></ul><li>3: <a href=#pg-47be5dd51f686017f1766e6ec7aa6f41>メモリー、CPU、APIリソースの管理</a></li><ul><li>3.1: <a href=#pg-337620c76587e4aeb32009cb23be46de>ネームスペースのデフォルトのメモリー要求と制限を設定する</a></li><li>3.2: <a href=#pg-adb489b1ab985c9215657b0d4c6ae92b>Namespaceに対する最小および最大メモリー制約の構成</a></li></ul><li>4: <a href=#pg-7743f043c43f7b12e8654e2227dbc658>証明書</a></li><li>5: <a href=#pg-77351865caa548b0a06694b904dd881c>EndpointSliceの有効化</a></li><li>6: <a href=#pg-9ceed97f912df7289ed8872e290cfbad>KubernetesクラスターでNodeLocal DNSキャッシュを使用する</a></li><li>7: <a href=#pg-00733cc3747eb3f5fe1c9e0439262967>Serviceトポロジーを有効にする</a></li><li>8: <a href=#pg-e1afcdac8d5e8458274b3c481c5ebcda>サービスディスカバリーにCoreDNSを使用する</a></li><li>9: <a href=#pg-8060aed5bf1172fa62199a4c306a4cd1>ノードのトポロジー管理ポリシーを制御する</a></li><li>10: <a href=#pg-ce4cd28c8feb9faa783e79b48af37961>クラウドコントローラーマネージャーの運用管理</a></li><li>11: <a href=#pg-9585dc0efb0450fd68728e7511754717>クラウドコントローラーマネージャーの開発</a></li><li>12: <a href=#pg-12001be83d15fcd7f3242313a55777df>クラスターのセキュリティ</a></li><li>13: <a href=#pg-a3790dfb57271d13517e549dffa805b9>ネットワークポリシーを宣言する</a></li><li>14: <a href=#pg-a8f6511197efcd7d0db80ade49620f9d>拡張リソースをNodeにアドバタイズする</a></li></ul><div class=content></div></div><div class=td-content><h1 id=pg-adb6c52e773f4d890595e14a9251f59b>1 - dockershimからの移行</h1><p>dockershimから他のコンテナランタイムに移行する際に知っておくべき情報を紹介します。</p><p>Kubernetes 1.20で<a href=blog/2020/12/08/kubernetes-1-20-release-announcement/#dockershim-deprecation>dockershim deprecation</a>が発表されてから、様々なワークロードやKubernetesインストールにどう影響するのかという質問が寄せられています。</p><p>この問題をよりよく理解するために、<a href=/blog/2020/12/02/dockershim-faq/>Dockershim Deprecation FAQ</a>ブログが役に立つでしょう。</p><p>dockershimから代替のコンテナランタイムに移行することが推奨されます。
<a href=/ja/docs/setup/production-environment/container-runtimes/>コンテナランタイム</a>のセクションをチェックして、どのような選択肢があるかを確認してください。
問題が発生した場合は、必ず<a href=https://github.com/kubernetes/kubernetes/issues>問題の報告</a>をしてください。
そうすれば、問題が適時に修正され、クラスターがdockershimの削除に対応できるようになります。</p></div><div class=td-content style=page-break-before:always><h1 id=pg-d79db9ed1698f75ec5f2228987290e49>1.1 - ノードで使用されているコンテナランタイムの確認</h1><p>このページでは、クラスター内のノードが使用している<a href=/docs/setup/production-environment/container-runtimes/>コンテナランタイム</a>を確認する手順を概説しています。</p><p>クラスターの実行方法によっては、ノード用のコンテナランタイムが事前に設定されている場合と、設定する必要がある場合があります。
マネージドKubernetesサービスを使用している場合、ノードに設定されているコンテナランタイムを確認するためのベンダー固有の方法があるかもしれません。
このページで説明する方法は、<code>kubectl</code>の実行が許可されていればいつでも動作するはずです。</p><h2 id=始める前に>始める前に</h2><p><code>kubectl</code>をインストールし、設定します。詳細は<a href=/ja/docs/tasks/tools/#kubectl>ツールのインストール</a>の項を参照してください。</p><h2 id=ノードで使用されているコンテナランタイムの確認>ノードで使用されているコンテナランタイムの確認</h2><p>ノードの情報を取得して表示するには<code>kubectl</code>を使用します:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get nodes -o wide
</span></span></code></pre></div><p>出力は以下のようなものです。列<code>CONTAINER-RUNTIME</code>には、ランタイムとそのバージョンが出力されます。</p><pre tabindex=0><code class=language-none data-lang=none># For dockershim
NAME         STATUS   VERSION    CONTAINER-RUNTIME
node-1       Ready    v1.16.15   docker://19.3.1
node-2       Ready    v1.16.15   docker://19.3.1
node-3       Ready    v1.16.15   docker://19.3.1
</code></pre><pre tabindex=0><code class=language-none data-lang=none># For containerd
NAME         STATUS   VERSION   CONTAINER-RUNTIME
node-1       Ready    v1.19.6   containerd://1.4.1
node-2       Ready    v1.19.6   containerd://1.4.1
node-3       Ready    v1.19.6   containerd://1.4.1
</code></pre><p>コンテナランタイムについては、<a href=/docs/setup/production-environment/container-runtimes/>コンテナランタイム</a>のページで詳細を確認することができます。</p></div><div class=td-content style=page-break-before:always><h1 id=pg-58702e4818c09c9b3d574349c1a71cb3>1.2 - Dockershim非推奨の影響範囲を確認する</h1><p>Kubernetesの<code>dockershim</code>コンポーネントは、DockerをKubernetesの<a class=glossary-tooltip title=コンテナランタイムは、コンテナの実行を担当するソフトウェアです。 data-toggle=tooltip data-placement=top href=/ja/docs/setup/production-environment/container-runtimes target=_blank aria-label=コンテナランタイム>コンテナランタイム</a>として使用することを可能にします。</p><p>Kubernetesの組み込みコンポーネントである<code>dockershim</code>はリリースv1.20で非推奨となりました。</p><p>このページでは、あなたのクラスターがどのようにDockerをコンテナランタイムとして使用しているか、使用中の<code>dockershim</code>が果たす役割について詳しく説明し、<code>dockershim</code>の廃止によって影響を受けるワークロードがあるかどうかをチェックするためのステップを示します。</p><h2 id=find-docker-dependencies>自分のアプリがDockerに依存しているかどうかの確認</h2><p>アプリケーションコンテナの構築にDockerを使用している場合でも、これらのコンテナを任意のコンテナランタイム上で実行することができます。このようなDockerの使用は、コンテナランタイムとしてのDockerへの依存とはみなされません。</p><p>代替のコンテナランタイムが使用されている場合、Dockerコマンドを実行しても動作しないか、予期せぬ出力が得られる可能性があります。</p><p>このように、Dockerへの依存があるかどうかを調べることができます:</p><ol><li>特権を持つPodがDockerコマンド(<code>docker ps</code>など)を実行したり、Dockerサービスを再起動したり(<code>systemctl restart docker.service</code>などのコマンド)、Docker固有のファイル(<code>/etc/docker/daemon.json</code>など)を変更しないことを確認すること。</li><li>Dockerの設定ファイル(<code>/etc/docker/daemon.json</code> など)にプライベートレジストリやイメージミラーの設定がないか確認します。これらは通常、別のコンテナランタイムのために再設定する必要があります。</li><li>Kubernetesインフラストラクチャーの外側のノードで実行される以下のようなスクリプトやアプリがDockerコマンドを実行しないことを確認します。<ul><li>トラブルシューティングのために人間がノードにSSHで接続</li><li>ノードのスタートアップスクリプト</li><li>ノードに直接インストールされた監視エージェントやセキュリティエージェント</li></ul></li><li>上記のような特権的な操作を行うサードパーティツール。詳しくは<a href=/docs/tasks/administer-cluster/migrating-from-dockershim/migrating-telemetry-and-security-agents>Migrating telemetry and security agents from dockershim</a> を参照してください。</li><li>dockershimの動作に間接的な依存性がないことを確認します。
これはエッジケースであり、あなたのアプリケーションに影響を与える可能性は低いです。ツールによっては、Docker固有の動作に反応するように設定されている場合があります。例えば、特定のメトリクスでアラートを上げたり、トラブルシューティングの指示の一部として特定のログメッセージを検索したりします。そのようなツールを設定している場合、移行前にテストクラスターで動作をテストしてください。</li></ol><h2 id=role-of-dockershim>Dockerへの依存について解説</h2><p><a href=/ja/docs/concepts/containers/#container-runtimes>コンテナランタイム</a>とは、Kubernetes Podを構成するコンテナを実行できるソフトウェアです。</p><p>KubernetesはPodのオーケストレーションとスケジューリングを担当し、各ノードでは<a class=glossary-tooltip title=クラスター内の各ノードで実行されるエージェントです。各コンテナがPodで実行されていることを保証します。 data-toggle=tooltip data-placement=top href=/docs/reference/generated/kubelet target=_blank aria-label=kubelet>kubelet</a>がコンテナランタイムインターフェイスを抽象化して使用するので、互換性があればどのコンテナランタイムでも使用することができます。
初期のリリースでは、Kubernetesは1つのコンテナランタイムと互換性を提供していました: Dockerです。
その後、Kubernetesプロジェクトの歴史の中で、クラスター運用者は追加のコンテナランタイムを採用することを希望しました。
CRIはこのような柔軟性を可能にするために設計され、kubeletはCRIのサポートを開始しました。
しかし、DockerはCRI仕様が考案される前から存在していたため、Kubernetesプロジェクトはアダプタコンポーネント「dockershim」を作成しました。</p><p>dockershimアダプターは、DockerがCRI互換ランタイムであるかのように、kubeletがDockerと対話することを可能にします。
<a href=/blog/2018/05/24/kubernetes-containerd-integration-goes-ga/>Kubernetes Containerd integration goes GA</a>ブログ記事で紹介されています。</p><p><img src=/images/blog/2018-05-24-kubernetes-containerd-integration-goes-ga/cri-containerd.png alt="Dockershim vs. CRI with Containerd"></p><p>コンテナランタイムとしてContainerdに切り替えることで、中間マージンを排除することができます。
これまでと同じように、Containerdのようなコンテナランタイムですべてのコンテナを実行できます。
しかし今は、コンテナはコンテナランタイムで直接スケジュールするので、Dockerからは見えません。
そのため、これらのコンテナをチェックするために以前使っていたかもしれないDockerツールや派手なUIは、もはや利用できません。
<code>docker ps</code>や<code>docker inspect</code>を使用してコンテナ情報を取得することはできません。
コンテナを一覧表示できないので、ログを取得したり、コンテナを停止したり、<code>docker exec</code>を使用してコンテナ内で何かを実行したりすることもできません。</p><div class="alert alert-info note callout" role=alert><strong>備考:</strong> Kubernetes経由でワークロードを実行している場合、コンテナを停止する最善の方法は、コンテナランタイムを直接経由するよりもKubernetes APIを経由することです(このアドバイスはDockerだけでなく、すべてのコンテナランタイムに適用されます)。</div><p>この場合でも、イメージを取得したり、<code>docker build</code>コマンドを使用してビルドすることは可能です。
しかし、Dockerによってビルドまたはプルされたイメージは、コンテナランタイムとKubernetesからは見えません。
Kubernetesで使用できるようにするには、何らかのレジストリにプッシュする必要がありました。</p></div><div class=td-content style=page-break-before:always><h1 id=pg-eb3e279a6c5e1224e744080a52ee3f28>1.3 - dockershimからテレメトリーやセキュリティエージェントを移行する</h1><p>Kubernetes 1.20でdockershimは非推奨になりました。</p><p><a href=/blog/2020/12/02/dockershim-faq/>Dockershim Deprecation FAQ</a>から、ほとんどのアプリがコンテナをホストするランタイムに直接依存しないことは既にご存知かもしれません。
しかし、コンテナのメタデータやログ、メトリクスを収集するためにDockerに依存しているテレメトリーやセキュリティエージェントはまだ多く存在します。
この文書では、これらの依存関係を検出する方法と、これらのエージェントを汎用ツールまたは代替ランタイムに移行する方法に関するリンクを集約しています。</p><h2 id=テレメトリーとセキュリティエージェント>テレメトリーとセキュリティエージェント</h2><p>Kubernetesクラスター上でエージェントを実行するには、いくつかの方法があります。エージェントはノード上で直接、またはDaemonSetとして実行することができます。</p><h3 id=テレメトリーエージェントがdockerに依存する理由とは>テレメトリーエージェントがDockerに依存する理由とは？</h3><p>歴史的には、KubernetesはDockerの上に構築されていました。
Kubernetesはネットワークとスケジューリングを管理し、Dockerはコンテナをノードに配置して操作していました。
そのため、KubernetesからはPod名などのスケジューリング関連のメタデータを、Dockerからはコンテナの状態情報を取得することができます。
時が経つにつれ、コンテナを管理するためのランタイムも増えてきました。
また、多くのランタイムにまたがるコンテナ状態情報の抽出を一般化するプロジェクトやKubernetesの機能もあります。</p><p>いくつかのエージェントはDockerツールに関連しています。
エージェントは<a href=https://docs.docker.com/engine/reference/commandline/ps/><code>docker ps</code></a>や<a href=https://docs.docker.com/engine/reference/commandline/top/><code>docker top</code></a>といったコマンドを実行し、コンテナやプロセスの一覧を表示します。
または<a href=https://docs.docker.com/engine/reference/commandline/logs/>docker logs</a>を使えば、dockerログを購読することができます。</p><p>Dockerがコンテナランタイムとして非推奨になったため、これらのコマンドはもう使えません。</p><h3 id=identify-docker-dependency>Dockerに依存するDaemonSetの特定</h3><p>Podがノード上で動作している<code>dockerd</code>を呼び出したい場合、Podは以下のいずれかを行う必要があります。</p><ul><li><p>Dockerデーモンの特権ソケットがあるファイルシステムを<a class=glossary-tooltip title=データを格納するディレクトリで、Pod内のコンテナからアクセス可能です。 data-toggle=tooltip data-placement=top href=/docs/concepts/storage/volumes/ target=_blank aria-label=volume>volume</a>のようにマウントする。</p></li><li><p>Dockerデーモンの特権ソケットの特定のパスを直接ボリュームとしてマウントします。</p></li></ul><p>例: COSイメージでは、DockerはそのUnixドメインソケットを<code>/var/run/docker.sock</code>に公開します。
つまり、Pod仕様には<code>/var/run/docker.sock</code>の<code>hostPath</code>ボリュームマウントが含まれることになります。</p><p>以下は、Dockerソケットを直接マッピングしたマウントを持つPodを探すためのシェルスクリプトのサンプルです。</p><p>このスクリプトは、Podの名前空間と名前を出力します。</p><p><code>grep '/var/run/docker.sock'</code>を削除して、他のマウントを確認することもできます。</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>kubectl get pods --all-namespaces <span style=color:#b62;font-weight:700>\
</span></span></span><span style=display:flex><span><span style=color:#b62;font-weight:700></span>-o<span style=color:#666>=</span><span style=color:#b8860b>jsonpath</span><span style=color:#666>=</span><span style=color:#b44>&#39;{range .items[*]}{&#34;\n&#34;}{.metadata.namespace}{&#34;:\t&#34;}{.metadata.name}{&#34;:\t&#34;}{range .spec.volumes[*]}{.hostPath.path}{&#34;, &#34;}{end}{end}&#39;</span> <span style=color:#b62;font-weight:700>\
</span></span></span><span style=display:flex><span><span style=color:#b62;font-weight:700></span>| sort <span style=color:#b62;font-weight:700>\
</span></span></span><span style=display:flex><span><span style=color:#b62;font-weight:700></span>| grep <span style=color:#b44>&#39;/var/run/docker.sock&#39;</span>
</span></span></code></pre></div><div class="alert alert-info note callout" role=alert><strong>備考:</strong> Podがホスト上のDockerにアクセスするための代替方法があります。
例えば、フルパスの代わりに親ディレクトリ<code>/var/run</code>をマウントすることができます(<a href=https://gist.github.com/itaysk/7bc3e56d69c4d72a549286d98fd557dd>この例</a> のように)。
上記のスクリプトは、最も一般的な使用方法のみを検出します。</div><h3 id=ノードエージェントからdockerの依存性を検出する>ノードエージェントからDockerの依存性を検出する</h3><p>クラスターノードをカスタマイズし、セキュリティやテレメトリーのエージェントをノードに追加インストールする場合、エージェントのベンダーにDockerへの依存性があるかどうかを必ず確認してください。</p><h3 id=テレメトリーとセキュリティエージェントのベンダー>テレメトリーとセキュリティエージェントのベンダー</h3><p>様々なテレメトリーおよびセキュリティエージェントベンダーのための移行指示の作業中バージョンを<a href=https://docs.google.com/document/d/1ZFi4uKit63ga5sxEiZblfb-c23lFhvy6RXVPikS8wf0/edit#>Google doc</a>に保管しています。
dockershimからの移行に関する最新の手順については、各ベンダーにお問い合わせください。</p></div><div class=td-content style=page-break-before:always><h1 id=pg-8e16d69617b175d61e2e7a6e1642c9d6>2 - kubeadmによる管理</h1></div><div class=td-content><h1 id=pg-6134c5061298affa145ddb801b5c29da>2.1 - cgroupドライバーの設定</h1><p>このページでは、kubeadmクラスターのコンテナランタイムcgroupドライバーに合わせて、kubelet cgroupドライバーを設定する方法について説明します。</p><h2 id=始める前に>始める前に</h2><p>Kubernetesの<a href=/docs/setup/production-environment/container-runtimes>コンテナランタイムの要件</a>を熟知している必要があります。</p><h2 id=コンテナランタイムのcgroupドライバーの設定>コンテナランタイムのcgroupドライバーの設定</h2><p><a href=/docs/setup/production-environment/container-runtimes>Container runtimes</a>ページでは、kubeadmベースのセットアップでは<code>cgroupfs</code>ドライバーではなく、<code>systemd</code>ドライバーが推奨されると説明されています。</p><p>このページでは、デフォルトの<code>systemd</code>ドライバーを使用して多くの異なるコンテナランタイムをセットアップする方法についての詳細も説明されています。</p><h2 id=kubelet-cgroupドライバーの設定>kubelet cgroupドライバーの設定</h2><p>kubeadmでは、<code>kubeadm init</code>の際に<code>KubeletConfiguration</code>構造体を渡すことができます。</p><p>この<code>KubeletConfiguration</code>には、kubeletのcgroupドライバーを制御する<code>cgroupDriver</code>フィールドを含めることができます。</p><div class="alert alert-info note callout" role=alert><strong>備考:</strong> v1.22では、ユーザーが<code>KubeletConfiguration</code>の<code>cgroupDriver</code>フィールドを設定していない場合、<code>kubeadm</code>はデフォルトで<code>systemd</code>を設定するようになりました。</div><p>フィールドを明示的に設定する最小限の例です:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#080;font-style:italic># kubeadm-config.yaml</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>ClusterConfiguration<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>kubeadm.k8s.io/v1beta3<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kubernetesVersion</span>:<span style=color:#bbb> </span>v1.21.0<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:#00f;font-weight:700>---</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>KubeletConfiguration<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>kubelet.config.k8s.io/v1beta1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>cgroupDriver</span>:<span style=color:#bbb> </span>systemd<span style=color:#bbb>
</span></span></span></code></pre></div><p>このような設定ファイルは、kubeadmコマンドに渡すことができます:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubeadm init --config kubeadm-config.yaml
</span></span></code></pre></div><div class="alert alert-info note callout" role=alert><strong>備考:</strong><p>Kubeadmはクラスター内の全ノードで同じ<code>KubeletConfiguration</code>を使用します。</p><p><code>KubeletConfiguration</code>は<code>kube-system</code>名前空間下の<a href=/docs/concepts/configuration/configmap>ConfigMap</a>オブジェクトに格納されます。</p><p>サブコマンド<code>init</code>、<code>join</code>、<code>upgrade</code>を実行すると、kubeadmが<code>KubeletConfiguration</code>を<code>/var/lib/kubelet/config.yaml</code>以下にファイルとして書き込み、ローカルノードのkubeletに渡します。</p></div><h2 id=cgroupfsドライバーの使用>cgroupfsドライバーの使用</h2><p>このガイドで説明するように、<code>cgroupfs</code>ドライバーをkubeadmと一緒に使用することは推奨されません。
<code>cgroupfs</code>を使い続け、<code>kubeadm upgrade</code>が既存のセットアップで<code>KubeletConfiguration</code> cgroupドライバーを変更しないようにするには、その値を明示的に指定する必要があります。
これは、将来のバージョンのkubeadmに<code>systemd</code>ドライバーをデフォルトで適用させたくない場合に適用されます。
値を明示する方法については、後述の「kubelet ConfigMapの修正」の項を参照してください。
<code>cgroupfs</code>ドライバーを使用するようにコンテナランタイムを設定したい場合は、選択したコンテナランタイムのドキュメントを参照する必要があります。</p><h2 id=systemd-ドライバーへの移行><code>systemd</code>ドライバーへの移行</h2><p>既存のkubeadmクラスターのcgroupドライバーを<code>systemd</code>にインプレースで変更する場合は、kubeletのアップグレードと同様の手順が必要です。
これには、以下に示す両方の手順を含める必要があります。</p><div class="alert alert-info note callout" role=alert><strong>備考:</strong> あるいは、クラスター内の古いノードを<code>systemd</code>ドライバーを使用する新しいノードに置き換えることも可能です。
この場合、新しいノードに参加する前に以下の最初のステップのみを実行し、古いノードを削除する前にワークロードが新しいノードに安全に移動できることを確認する必要があります。</div><h3 id=kubelet-configmapの修正>kubelet ConfigMapの修正</h3><ul><li><code>kubectl get cm -n kube-system | grep kubelet-config</code>で、kubelet ConfigMapの名前を探します。</li><li><code>kubectl edit cm kubelet-config-x.yy -n kube-system</code>を呼び出します(<code>x.yy</code>はKubernetesのバージョンに置き換えてください)。</li><li>既存の<code>cgroupDriver</code>の値を修正するか、以下のような新しいフィールドを追加します。</li></ul><p>``yaml
cgroupDriver: systemd</p><pre tabindex=0><code>
このフィールドは、ConfigMapの`kubelet:`セクションの下に存在する必要があります。

### 全ノードでcgroupドライバーを更新

クラスター内の各ノードについて:

- [Drain the node](/docs/tasks/administer-cluster/safely-drain-node)を`kubectl drain &lt;node-name&gt; --ignore-daemonsets`を使ってドレーンします。
- `systemctl stop kubelet`を使用して、kubeletを停止します。
- コンテナランタイムの停止。
- コンテナランタイムのcgroupドライバーを`systemd`に変更します。
- `var/lib/kubelet/config.yaml`に`cgroupDriver: systemd`を設定します。
- コンテナランタイムの開始。
- `systemctl start kubelet`でkubeletを起動します。
- [Drain the node](/docs/tasks/administer-cluster/safely-drain-node)を`kubectl uncordon &lt;node-name&gt;`を使って行います。

ワークロードが異なるノードでスケジュールするための十分な時間を確保するために、これらのステップを1つずつノード上で実行します。
プロセスが完了したら、すべてのノードとワークロードが健全であることを確認します。
</code></pre></div><div class=td-content style=page-break-before:always><h1 id=pg-f62fba1de4084f3be070785757c8079c>2.2 - kubeadmによる証明書管理</h1><div style=margin-top:10px;margin-bottom:10px><b>FEATURE STATE:</b> <code>Kubernetes v1.15 [stable]</code></div><p><a href=/docs/reference/setup-tools/kubeadm/>kubeadm</a>で生成されたクライアント証明書は1年で失効します。
このページでは、kubeadmで証明書の更新を管理する方法について説明します。</p><h2 id=始める前に>始める前に</h2><p><a href=/docs/setup/best-practices/certificates/>KubernetesにおけるPKI証明書と要件</a>を熟知している必要があります。</p><h2 id=custom-certificates>カスタム証明書の使用</h2><p>デフォルトでは、kubeadmはクラスターの実行に必要なすべての証明書を生成します。
独自の証明書を提供することで、この動作をオーバーライドできます。</p><p>そのためには、<code>--cert-dir</code>フラグまたはkubeadmの<code>ClusterConfiguration</code>の<code>certificatesDir</code>フィールドで指定された任意のディレクトリに配置する必要があります。
デフォルトは<code>/etc/kubernetes/pki</code>です。</p><p><code>kubeadm init</code> を実行する前に与えられた証明書と秘密鍵のペアが存在する場合、kubeadmはそれらを上書きしません。
つまり、例えば既存のCAを<code>/etc/kubernetes/pki/ca.crt</code>と<code>/etc/kubernetes/pki/ca.key</code>にコピーすれば、kubeadmは残りの証明書に署名する際、このCAを使用できます。</p><h2 id=external-ca-mode>外部CAモード</h2><p>また、<code>ca.crt</code>ファイルのみを提供し、<code>ca.key</code>ファイルを提供しないことも可能です(これはルートCAファイルのみに有効で、他の証明書ペアには有効ではありません)。
他の証明書とkubeconfigファイルがすべて揃っている場合、kubeadmはこの状態を認識し、外部CAモードを有効にします。
kubeadmはディスク上のCAキーがなくても処理を進めます。</p><p>代わりに、Controller-managerをスタンドアロンで、<code>--controllers=csrsigner</code>と実行し、CA証明書と鍵を指し示します。</p><p><a href=/docs/setup/best-practices/certificates/>PKI certificates and requirements</a>には、外部CAを使用するためのクラスターのセットアップに関するガイダンスが含まれています。</p><h2 id=証明書の有効期限の確認>証明書の有効期限の確認</h2><p><code>check-expiration</code>サブコマンドを使うと、証明書の有効期限を確認することができます。</p><pre tabindex=0><code>kubeadm certs check-expiration
</code></pre><p>このような出力になります:</p><pre tabindex=0><code>CERTIFICATE                EXPIRES                  RESIDUAL TIME   CERTIFICATE AUTHORITY   EXTERNALLY MANAGED
admin.conf                 Dec 30, 2020 23:36 UTC   364d                                    no
apiserver                  Dec 30, 2020 23:36 UTC   364d            ca                      no
apiserver-etcd-client      Dec 30, 2020 23:36 UTC   364d            etcd-ca                 no
apiserver-kubelet-client   Dec 30, 2020 23:36 UTC   364d            ca                      no
controller-manager.conf    Dec 30, 2020 23:36 UTC   364d                                    no
etcd-healthcheck-client    Dec 30, 2020 23:36 UTC   364d            etcd-ca                 no
etcd-peer                  Dec 30, 2020 23:36 UTC   364d            etcd-ca                 no
etcd-server                Dec 30, 2020 23:36 UTC   364d            etcd-ca                 no
front-proxy-client         Dec 30, 2020 23:36 UTC   364d            front-proxy-ca          no
scheduler.conf             Dec 30, 2020 23:36 UTC   364d                                    no

CERTIFICATE AUTHORITY   EXPIRES                  RESIDUAL TIME   EXTERNALLY MANAGED
ca                      Dec 28, 2029 23:36 UTC   9y              no
etcd-ca                 Dec 28, 2029 23:36 UTC   9y              no
front-proxy-ca          Dec 28, 2029 23:36 UTC   9y              no
</code></pre><p>このコマンドは、<code>/etc/kubernetes/pki</code>フォルダ内のクライアント証明書と、kubeadmが使用するKUBECONFIGファイル(<code>admin.conf</code>,<code>controller-manager.conf</code>,<code>scheduler.conf</code>)に埋め込まれたクライアント証明書の有効期限/残余時間を表示します。</p><p>また、証明書が外部管理されている場合、kubeadmはユーザーに通知します。この場合、ユーザーは証明書の更新を手動または他のツールを使用して管理する必要があります。</p><div class="alert alert-danger warning callout" role=alert><strong>警告:</strong> <code>kubeadm</code>は外部CAによって署名された証明書を管理することができません。</div><div class="alert alert-info note callout" role=alert><strong>備考:</strong><p>kubeadmは<code>/var/lib/kubelet/pki</code>以下にあるローテート可能な証明書でkubeletの<a href=/docs/task/tls/certificate-rotation/>証明書の自動更新</a>を構成するので<code>kubelet.conf</code>は上記のリストに含まれません。</p><p>期限切れのkubeletクライアント証明書を修復するには、<a href=/docs/setup/production-environment/tools/kubeadm/troubleshooting-kubeadm/#kubelet-client-cert>Kubelet クライアント証明書のローテーションに失敗しました</a>を参照ください。</p></div><div class="alert alert-danger warning callout" role=alert><strong>警告:</strong><p>kubeadm version 1.17より前の<code>kubeadm init</code>で作成したノードでは、<code>kubelet.conf</code>の内容を手動で変更しなければならないという<a href=https://github.com/kubernetes/kubeadm/issues/1753>bug</a>が存在します。</p><p><code>kubeadm init</code>が終了したら、<code>client-certificate-data</code>と<code>client-key-data</code>を置き換えて、ローテーションされたkubeletクライアント証明書を指すように<code>kubelet.conf</code>を更新してください。</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>client-certificate</span>:<span style=color:#bbb> </span>/var/lib/kubelet/pki/kubelet-client-current.pem<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>client-key</span>:<span style=color:#bbb> </span>/var/lib/kubelet/pki/kubelet-client-current.pem<span style=color:#bbb>
</span></span></span></code></pre></div></div><h2 id=証明書の自動更新>証明書の自動更新</h2><p>kubeadmはコントロールプレーンの<a href=/docs/tasks/administer-cluster/kubeadm/kubeadm-upgrade/>アップグレード</a>時にすべての証明書を更新します。</p><p>この機能は、最もシンプルなユースケースに対応するために設計されています。
証明書の更新に特別な要件がなく、Kubernetesのバージョンアップを定期的に行う場合(各アップグレードの間隔が1年未満)、kubeadmがクラスターを最新かつ適度に安全に保つための処理を行います。</p><div class="alert alert-info note callout" role=alert><strong>備考:</strong> 安全性を維持するために、クラスターを頻繁にアップグレードすることがベストプラクティスです。</div><p>証明書の更新に関してより複雑な要求がある場合は、<code>--certificate-renewal=false</code>を<code>kubeadm upgrade apply</code>や<code>kubeadm upgrade node</code>に渡して、デフォルトの動作から外れるようにすることができます。</p><div class="alert alert-danger warning callout" role=alert><strong>警告:</strong> kubeadmバージョン1.17より前のバージョンでは、<code>kubeadm upgrade node</code>コマンドの<code>--certificate-renewal</code>のデフォルト値が<code>false</code>になっているという[bug(https://github.com/kubernetes/kubeadm/issues/1818)]問題があります。
この場合、明示的に<code>--certificate-renewal=true</code>を設定する必要があります。</div><h2 id=手動による証明書更新>手動による証明書更新</h2><p><code>kubeadm certs renew</code> コマンドを使えば、いつでも証明書を手動で更新することができます。</p><p>このコマンドは<code>/etc/kubernetes/pki</code>に格納されているCA(またはfront-proxy-CA)の証明書と鍵を使って更新を行います。</p><p>コマンド実行後、コントロールプレーンのPodを再起動する必要があります。
これは、現在すべてのコンポーネントと証明書について動的な証明書のリロードがサポートされていないため、必要な作業です。
<a href=/docs/tasks/configure-pod-container/static-pod/>スタティックPod</a>はローカルkubeletによって管理され、API Serverによって管理されないため、kubectlで削除および再起動することはできません。</p><p>スタティックPodを再起動するには、一時的に<code>/etc/kubernetes/manifests/</code>からマニフェストファイルを削除して20秒間待ちます(<a href=/docs/reference/config-api/kubelet-config.v1beta1/>KubeletConfiguration struct</a>の<code>fileCheckFrequency</code>値を参照してください)。
マニフェストディレクトリにPodが無くなると、kubeletはPodを終了します。
その後ファイルを戻して、さらに<code>fileCheckFrequency</code>期間後に、kubeletはPodを再作成し、コンポーネントの証明書更新を完了することができます。</p><div class="alert alert-danger warning callout" role=alert><strong>警告:</strong> HAクラスターを実行している場合、このコマンドはすべての制御プレーンノードで実行する必要があります。</div><div class="alert alert-info note callout" role=alert><strong>備考:</strong> <code>certs renew</code>は、属性(Common Name、Organization、SANなど)の信頼できるソースとして、kubeadm-config ConfigMapではなく、既存の証明書を使用します。両者を同期させておくことが強く推奨されます。</div><p><code>kubeadm certs renew</code> は以下のオプションを提供します:</p><p>Kubernetesの証明書は通常1年後に有効期限を迎えます。</p><ul><li><p><code>--csr-only</code>を使用すると、証明書署名要求を生成して外部CAとの証明書を更新することができます(実際にはその場で証明書を更新しません)。詳しくは次の段落を参照してください。</p></li><li><p>また、すべての証明書を更新するのではなく、1つの証明書を更新することも可能です。</p></li></ul><h2 id=kubernetes-certificates-apiによる証明書の更新>Kubernetes certificates APIによる証明書の更新</h2><p>ここでは、Kubernetes certificates APIを使用して手動で証明書更新を実行する方法について詳しく説明します。</p><div class="alert alert-warning caution callout" role=alert><strong>注意:</strong> これらは、組織の証明書インフラをkubeadmで構築されたクラスターに統合する必要があるユーザー向けの上級者向けのトピックです。
kubeadmのデフォルトの設定で満足できる場合は、代わりにkubeadmに証明書を管理させる必要があります。</div><h3 id=署名者の設定>署名者の設定</h3><p>Kubernetesの認証局は、そのままでは機能しません。
<a href=https://cert-manager.io/docs/configuration/ca/>cert-manager</a>などの外部署名者を設定するか、組み込みの署名者を使用することができます。</p><p>ビルトインサイナーは<a href=/docs/reference/command-line-tools-reference/kube-controller-manager/><code>kube-controller-manager</code></a>に含まれるものです。</p><p>ビルトインサイナーを有効にするには、<code>--cluster-signing-cert-file</code>と<code>--cluster-signing-key-file</code>フラグを渡す必要があります。</p><p>新しいクラスターを作成する場合は、kubeadm<a href=https://pkg.go.dev/k8s.io/kubernetes/cmd/kubeadm/app/apis/kubeadm/v1beta3>設定ファイル</a>を使用します。</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>kubeadm.k8s.io/v1beta3<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>ClusterConfiguration<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>controllerManager</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>extraArgs</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>cluster-signing-cert-file</span>:<span style=color:#bbb> </span>/etc/kubernetes/pki/ca.crt<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>cluster-signing-key-file</span>:<span style=color:#bbb> </span>/etc/kubernetes/pki/ca.key<span style=color:#bbb>
</span></span></span></code></pre></div><h3 id=証明書署名要求の作成-csr>証明書署名要求の作成 (CSR)</h3><p>Kubernetes APIでのCSR作成については、<a href=/docs/reference/access-authn-authz/certificate-signing-requests/#create-certificatesigningrequest>Create CertificateSigningRequest</a>を参照ください。</p><h2 id=外部caによる証明書の更新>外部CAによる証明書の更新</h2><p>ここでは、外部認証局を利用して手動で証明書更新を行う方法について詳しく説明します。</p><p>外部CAとの連携を強化するために、kubeadmは証明書署名要求(CSR)を生成することもできます。
CSRとは、クライアント用の署名付き証明書をCAに要求することを表します。
kubeadmの用語では、通常ディスク上のCAによって署名される証明書をCSRとして生成することができます。しかし、CAはCSRとして生成することはできません。</p><h3 id=証明書署名要求の作成-csr-1>証明書署名要求の作成 (CSR)</h3><p><code>kubeadm certs renew --csr-only</code>で証明書署名要求を作成することができます。</p><p>CSRとそれに付随する秘密鍵の両方が出力されます。
ディレクトリを<code>--csr-dir</code>で渡すと、指定した場所にCSRを出力することができます。
<code>csr-dir</code>を指定しない場合は、デフォルトの証明書ディレクトリ(<code>/etc/kubernetes/pki</code>)が使用されます。</p><p>証明書は<code>kubeadm certs renew --csr-only</code>で更新することができます。
<code>kubeadm init</code>と同様に、<code>--csr-dir</code>フラグで出力先ディレクトリを指定することができます。</p><p>CSRには、証明書の名前、ドメイン、IPが含まれますが、用途は指定されません。
証明書を発行する際に、<a href=/docs/setup/best-practices/certificates/#all-certificates>正しい証明書の使用法</a>を指定するのはCAの責任です。</p><ul><li><p><code>openssl</code>では、<a href=https://superuser.com/questions/738612/openssl-ca-keyusage-extension><code>openssl ca</code>コマンド</a>を使って行います。</p></li><li><p><code>cfssl</code>では、<a href=https://github.com/cloudflare/cfssl/blob/master/doc/cmd/cfssl.txt#L170>configファイルのusages</a>で指定します。</p></li></ul><p>お好みの方法で証明書に署名した後、証明書と秘密鍵をPKIディレクトリ(デフォルトでは<code>/etc/kubernetes/pki</code>)にコピーする必要があります。</p><h2 id=certificate-authority-rotation>認証局(CA)のローテーション</h2><p>Kubeadmは、CA証明書のローテーションや交換を最初からサポートしているわけではありません。</p><p>CAの手動ローテーションや交換についての詳細は、<a href=/docs/tasks/tls/manual-rotation-of-ca-certificates/>manual rotation of CA certificates</a>を参照してください。</p><h2 id=kubelet-serving-certs>署名付きkubeletサービング証明書の有効化</h2><p>デフォルトでは、kubeadmによって展開されるkubeletサービング証明書は自己署名されています。
これは、<a href=https://github.com/kubernetes-sigs/metrics-server>metrics-server</a>のような外部サービスからキューブレットへの接続がTLSで保護されないことを意味します。
新しいkubeadmクラスター内のkubeletが適切に署名されたサービング証明書を取得するように設定するには、<code>kubeadm init</code>に以下の最小限の設定を渡す必要があります。</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>kubeadm.k8s.io/v1beta3<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>ClusterConfiguration<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:#00f;font-weight:700>---</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>kubelet.config.k8s.io/v1beta1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>KubeletConfiguration<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>serverTLSBootstrap</span>:<span style=color:#bbb> </span><span style=color:#a2f;font-weight:700>true</span><span style=color:#bbb>
</span></span></span></code></pre></div><p>すでにクラスターを作成している場合は、以下の手順で適応させる必要があります。</p><ul><li>kube-system<code>ネームスペースにある</code>kubelet-config-1.25` ConfigMapを見つけて編集します。</li></ul><p>そのConfigMapの<code>kubelet</code>キーの値として<a href=/docs/reference/config-api/kubelet-config.v1beta1/#kubelet-config-k8s-io-v1beta1-KubeletConfiguration>KubeletConfiguration</a>ドキュメントを指定します。KubeletConfigurationドキュメントを編集し、<code>serverTLSBootstrap: true</code>を設定します。</p><ul><li>各ノードで、<code>/var/lib/kubelet/config.yaml</code>に<code>serverTLSBootstrap: true</code>フィールドを追加し、<code>systemctl restart kubelet</code>でkubeletを再起動します。</li></ul><p><code>serverTLSBootstrap: true</code>フィールドは、kubeleサービングのブートストラップを有効にします。
証明書を<code>certificates.k8s.io</code>APIにリクエストすることで、証明書を発行することができます。</p><p>既知の制限事項として、これらの証明書のCSR(Certificate Signing Requests)はkube-controller-managerのデフォルトサイナーによって自動的に承認されないことがあります。
<a href=/docs/reference/access-authn-authz/certificate-signing-requests/#kubernetes-signers><code>kubernetes.io/kubelet-serving</code></a> を参照してください。</p><p>これには、ユーザーまたはサードパーティーのコントローラーからのアクションが必要です。</p><p>これらのCSRは、以下を使用して表示できます:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get csr
</span></span><span style=display:flex><span>NAME        AGE     SIGNERNAME                        REQUESTOR                      CONDITION
</span></span><span style=display:flex><span>csr-9wvgt   112s    kubernetes.io/kubelet-serving     system:node:worker-1           Pending
</span></span><span style=display:flex><span>csr-lz97v   1m58s   kubernetes.io/kubelet-serving     system:node:control-plane-1    Pending
</span></span></code></pre></div><p>承認するためには、次のようにします:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl certificate approve &lt;CSR-name&gt;
</span></span></code></pre></div><p>デフォルトでは、これらのサービング証明書は1年後に失効します。</p><p>Kubeadmは<code>KubeletConfiguration</code>フィールド<code>rotateCertificates</code>を<code>true</code>に設定します。これは有効期限が切れる間際に、サービング証明書のための新しいCSRセットを作成し、ローテーションを完了するために承認する必要があることを意味します。</p><p>詳しくは<a href=/docs/reference/command-line-tools-reference/kubelet-tls-bootstrapping/#certificate-rotation>Certificate Rotation</a>をご覧ください。</p><p>これらのCSRを自動的に承認するためのソリューションをお探しの場合は、以下をお勧めします。
クラウドプロバイダーに連絡し、ノードの識別をアウトオブバンドのメカニズムで行うCSRの署名者がいるかどうか尋ねてください。</p><div class="alert alert-secondary callout third-party-content" role=alert><strong>備考:</strong>
このセクションでは、Kubernetesが必要とする機能を提供するサードパーティープロジェクトにリンクしています。これらのプロジェクトはアルファベット順に記載されていて、Kubernetesプロジェクトの作者は責任を持ちません。このリストにプロジェクトを追加するには、変更を提出する前に<a href=/docs/contribute/style/content-guide/#third-party-content>content guide</a>をお読みください。<a href=#third-party-content-disclaimer>詳細はこちら。</a></div><p>サードパーティーのカスタムコントローラーを使用することができます。</p><ul><li><a href=https://github.com/postfinance/kubelet-csr-approver>kubelet-csr-approver</a></li></ul><p>このようなコントローラーは、CSRのCommonNameを検証するだけでなく、要求されたIPやドメイン名も検証しなければ、安全なメカニズムとは言えません。これにより、kubeletクライアント証明書にアクセスできる悪意のあるアクターが、任意のIPやドメイン名に対してサービング証明書を要求するCSRを作成することを防ぐことができます。</p></div><div class=td-content style=page-break-before:always><h1 id=pg-9133578f1e75663bb031e5a377ca896d>2.3 - Windowsノードの追加</h1><div style=margin-top:10px;margin-bottom:10px><b>FEATURE STATE:</b> <code>Kubernetes v1.18 [beta]</code></div><p>Kubernetesを使用してLinuxノードとWindowsノードを混在させて実行できるため、Linuxで実行するPodとWindowsで実行するPodを混在させることができます。このページでは、Windowsノードをクラスターに登録する方法を示します。</p><h2 id=始める前に>始める前に</h2>作業するKubernetesサーバーは次のバージョン以降のものである必要があります: 1.17.
バージョンを確認するには次のコマンドを実行してください: <code>kubectl version</code>.<ul><li><p>WindowsコンテナをホストするWindowsノードを構成するには、<a href=https://www.microsoft.com/en-us/cloud-platform/windows-server-pricing>Windows Server 2019ライセンス</a>(またはそれ以上)を取得します。
VXLAN/オーバーレイネットワークを使用している場合は、<a href=https://support.microsoft.com/help/4489899>KB4489899</a>もインストールされている必要があります。</p></li><li><p>コントロールプレーンにアクセスできるLinuxベースのKubernetes kubeadmクラスター(<a href=/ja/docs/setup/production-environment/tools/kubeadm/create-cluster-kubeadm/>kubeadmを使用したシングルコントロールプレーンクラスターの作成</a>を参照)</p></li></ul><h2 id=目標>目標</h2><ul><li>Windowsノードをクラスターに登録する</li><li>LinuxとWindowsのPodとServiceが相互に通信できるようにネットワークを構成する</li></ul><h2 id=はじめに-クラスターへのwindowsノードの追加>はじめに: クラスターへのWindowsノードの追加</h2><h3 id=ネットワーク構成>ネットワーク構成</h3><p>LinuxベースのKubernetesコントロールプレーンノードを取得したら、ネットワーキングソリューションを選択できます。このガイドでは、簡単にするためにVXLANモードでのFlannelの使用について説明します。</p><h4 id=flannel構成>Flannel構成</h4><ol><li><p>FlannelのためにKubernetesコントロールプレーンを準備する</p><p>クラスター内のKubernetesコントロールプレーンでは、多少の準備が推奨されます。Flannelを使用する場合は、iptablesチェーンへのブリッジIPv4トラフィックを有効にすることをお勧めします。すべてのLinuxノードで次のコマンドを実行する必要があります:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>sudo sysctl net.bridge.bridge-nf-call-iptables<span style=color:#666>=</span><span style=color:#666>1</span>
</span></span></code></pre></div></li><li><p>Linux用のFlannelをダウンロードして構成する</p><p>最新のFlannelマニフェストをダウンロード:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>wget https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml
</span></span></code></pre></div><p>VNIを4096、ポートを4789に設定するために、flannelマニフェストの<code>net-conf.json</code>セクションを変更します。次のようになります:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-json data-lang=json><span style=display:flex><span><span>net-conf.json:</span> <span>|</span>
</span></span><span style=display:flex><span>    {
</span></span><span style=display:flex><span>      <span style=color:green;font-weight:700>&#34;Network&#34;</span>: <span style=color:#b44>&#34;10.244.0.0/16&#34;</span>,
</span></span><span style=display:flex><span>      <span style=color:green;font-weight:700>&#34;Backend&#34;</span>: {
</span></span><span style=display:flex><span>        <span style=color:green;font-weight:700>&#34;Type&#34;</span>: <span style=color:#b44>&#34;vxlan&#34;</span>,
</span></span><span style=display:flex><span>        <span style=color:green;font-weight:700>&#34;VNI&#34;</span> : <span style=color:#666>4096</span>,
</span></span><span style=display:flex><span>        <span style=color:green;font-weight:700>&#34;Port&#34;</span>: <span style=color:#666>4789</span>
</span></span><span style=display:flex><span>      }
</span></span><span style=display:flex><span>    }
</span></span></code></pre></div><div class="alert alert-info note callout" role=alert><strong>備考:</strong> Linux上のFlannelがWindows上のFlannelと相互運用するには、VNIを4096およびポート4789に設定する必要があります。これらのフィールドの説明については、<a href=https://github.com/coreos/flannel/blob/master/Documentation/backends.md#vxlan>VXLANドキュメント</a>を参照してください。</div><div class="alert alert-info note callout" role=alert><strong>備考:</strong> L2Bridge/Host-gatewayモードを使用するには、代わりに<code>Type</code>の値を<code>"host-gw"</code>に変更し、<code>VNI</code>と<code>Port</code>を省略します。</div></li><li><p>Flannelマニフェストを適用して検証する</p><p>Flannelの構成を適用しましょう:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>kubectl apply -f kube-flannel.yml
</span></span></code></pre></div><p>数分後、Flannel Podネットワークがデプロイされていれば、すべてのPodが実行されていることがわかります。</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>kubectl get pods -n kube-system
</span></span></code></pre></div><p>出力結果には、実行中のLinux flannel DaemonSetが含まれているはずです:</p><pre tabindex=0><code>NAMESPACE     NAME                                      READY        STATUS    RESTARTS   AGE
...
kube-system   kube-flannel-ds-54954                     1/1          Running   0          1m
</code></pre></li><li><p>Windows Flannelとkube-proxy DaemonSetを追加する</p><p>これで、Windows互換バージョンのFlannelおよびkube-proxyを追加できます。
互換性のあるバージョンのkube-proxyを確実に入手するには、イメージのタグを置換する必要があります。
次の例は、Kubernetesv1.25.0の使用方法を示していますが、
独自のデプロイに合わせてバージョンを調整する必要があります。</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>curl -L https://github.com/kubernetes-sigs/sig-windows-tools/releases/latest/download/kube-proxy.yml | sed <span style=color:#b44>&#39;s/VERSION/v1.25.0/g&#39;</span> | kubectl apply -f -
</span></span><span style=display:flex><span>kubectl apply -f https://github.com/kubernetes-sigs/sig-windows-tools/releases/latest/download/flannel-overlay.yml
</span></span></code></pre></div><div class="alert alert-info note callout" role=alert><strong>備考:</strong> ホストゲートウェイを使用している場合は、代わりに <a href=https://github.com/kubernetes-sigs/sig-windows-tools/releases/latest/download/flannel-host-gw.yml>https://github.com/kubernetes-sigs/sig-windows-tools/releases/latest/download/flannel-host-gw.yml</a> を使用してください。</div><div class="alert alert-info note callout" role=alert><strong>備考:</strong><p>Windowsノードでイーサネット(「Ethernet0 2」など)ではなく別のインターフェースを使用している場合は、次の行を変更する必要があります:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-powershell data-lang=powershell><span style=display:flex><span>wins <span style=color:#a2f>cli </span><span style=color:#a2f;font-weight:700>process</span> run --path /k/flannel/setup.exe --args <span style=color:#b44>&#34;--mode=overlay --interface=Ethernet&#34;</span>
</span></span></code></pre></div><p><code>flannel-host-gw.yml</code>または<code>flannel-overlay.yml</code>ファイルで、それに応じてインターフェースを指定します。</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#080;font-style:italic># 例</span>
</span></span><span style=display:flex><span>curl -L https://github.com/kubernetes-sigs/sig-windows-tools/releases/latest/download/flannel-overlay.yml | sed <span style=color:#b44>&#39;s/Ethernet/Ethernet0 2/g&#39;</span> | kubectl apply -f -
</span></span></code></pre></div></div></li></ol><h3 id=windowsワーカーノードの参加>Windowsワーカーノードの参加</h3><div class="alert alert-info note callout" role=alert><strong>備考:</strong> <code>Containers</code>機能をインストールし、Dockerをインストールする必要があります。
行うための指示としては、<a href=https://docs.mirantis.com/docker-enterprise/v3.1/dockeree-products/docker-engine-enterprise/dee-windows.html>Dockerエンジンのインストール - Windowsサーバー上のエンタープライズ</a>を利用できます。</div><div class="alert alert-info note callout" role=alert><strong>備考:</strong> Windowsセクションのすべてのコードスニペットは、
Windowsワーカーノードの(管理者)権限を持つPowerShell環境で実行されます。</div><ol><li><p>wins、kubelet、kubeadmをインストールします。</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-PowerShell data-lang=PowerShell><span style=display:flex><span>curl.exe -LO https<span>:</span>//raw.githubusercontent.com/<span style=color:#a2f>kubernetes-sigs</span>/<span style=color:#a2f>sig-windows</span>-tools/master/kubeadm/scripts/PrepareNode.ps1
</span></span><span style=display:flex><span>.\PrepareNode.ps1 -KubernetesVersion <span style=color:#a2f>
</span></span></code></pre></div></li><li><p><code>kubeadm</code>を実行してノードに参加します</p><p>コントロールプレーンホストで<code>kubeadm init</code>を実行したときに提供されたコマンドを使用します。
このコマンドがなくなった場合、またはトークンの有効期限が切れている場合は、<code>kubeadm token create --print-join-command</code>
(コントロールプレーンホスト上で)を実行して新しいトークンを生成します。</p></li></ol><h4 id=インストールの確認>インストールの確認</h4><p>次のコマンドを実行して、クラスター内のWindowsノードを表示できるようになります:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>kubectl get nodes -o wide
</span></span></code></pre></div><p>新しいノードが<code>NotReady</code>状態の場合は、flannelイメージがまだダウンロード中の可能性があります。
<code>kube-system</code>名前空間のflannel Podを確認することで、以前と同様に進行状況を確認できます:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl -n kube-system get pods -l <span style=color:#b8860b>app</span><span style=color:#666>=</span>flannel
</span></span></code></pre></div><p>flannel Podが実行されると、ノードは<code>Ready</code>状態になり、ワークロードを処理できるようになります。</p><h2 id=次の項目>次の項目</h2><ul><li><a href=/ja/docs/tasks/administer-cluster/kubeadm/upgrading-windows-nodes>Windows kubeadmノードのアップグレード</a></li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-e805c7d8d4ad6195cb82dbbc843bfc29>2.4 - Windowsノードのアップグレード</h1><div style=margin-top:10px;margin-bottom:10px><b>FEATURE STATE:</b> <code>Kubernetes v1.18 [beta]</code></div><p>このページでは、<a href=/ja/docs/tasks/administer-cluster/kubeadm/adding-windows-nodes>kubeadmで作られた</a>Windowsノードをアップグレードする方法について説明します。</p><h2 id=始める前に>始める前に</h2><p><p>Kubernetesクラスターが必要、かつそのクラスターと通信するためにkubectlコマンドラインツールが設定されている必要があります。
このチュートリアルは、コントロールプレーンのホストとして動作していない少なくとも2つのノードを持つクラスターで実行することをおすすめします。
まだクラスターがない場合、<a href=https://minikube.sigs.k8s.io/docs/tutorials/multi_node/>minikube</a>を使って作成するか、
以下のいずれかのKubernetesプレイグラウンドも使用できます:</p><ul><li><a href=https://killercoda.com/playgrounds/scenario/kubernetes>Killercoda</a></li><li><a href=http://labs.play-with-k8s.com/>Play with Kubernetes</a></li></ul>作業するKubernetesサーバーは次のバージョン以降のものである必要があります: 1.17.
バージョンを確認するには次のコマンドを実行してください: <code>kubectl version</code>.</p><ul><li><a href=/docs/tasks/administer-cluster/kubeadm/kubeadm-upgrade>残りのkubeadmクラスターをアップグレードするプロセス</a>を理解します。
Windowsノードをアップグレードする前にコントロールプレーンノードをアップグレードしたいと思うかもしれません。</li></ul><h2 id=ワーカーノードをアップグレード>ワーカーノードをアップグレード</h2><h3 id=kubeadmをアップグレード>kubeadmをアップグレード</h3><ol><li><p>Windowsノードから、kubeadmをアップグレードします。:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-powershell data-lang=powershell><span style=display:flex><span><span style=color:#080;font-style:italic># v1.25.0を目的のバージョンに置き換えます</span>
</span></span><span style=display:flex><span>curl.exe -Lo C:\k\kubeadm.exe https<span>:</span>//dl.k8s.io/<span style=color:#a2f>/bin/windows/amd64/kubeadm.exe
</span></span></code></pre></div></li></ol><h3 id=ノードをドレインする>ノードをドレインする</h3><ol><li><p>Kubernetes APIにアクセスできるマシンから、
ノードをスケジュール不可としてマークして、ワークロードを削除することでノードのメンテナンスを準備します:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span><span style=color:#080;font-style:italic># &lt;node-to-drain&gt;をドレインするノードの名前に置き換えます</span>
</span></span><span style=display:flex><span>kubectl drain &lt;node-to-drain&gt; --ignore-daemonsets
</span></span></code></pre></div><p>このような出力結果が表示されるはずです:</p><pre tabindex=0><code>node/ip-172-31-85-18 cordoned
node/ip-172-31-85-18 drained
</code></pre></li></ol><h3 id=kubeletの構成をアップグレード>kubeletの構成をアップグレード</h3><ol><li><p>Windowsノードから、次のコマンドを呼び出して新しいkubelet構成を同期します:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-powershell data-lang=powershell><span style=display:flex><span>kubeadm upgrade node
</span></span></code></pre></div></li></ol><h3 id=kubeletをアップグレード>kubeletをアップグレード</h3><ol><li><p>Windowsノードから、kubeletをアップグレードして再起動します:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-powershell data-lang=powershell><span style=display:flex><span><span style=color:#a2f>stop-service</span> kubelet
</span></span><span style=display:flex><span>curl.exe -Lo C:\k\kubelet.exe https<span>:</span>//dl.k8s.io/<span style=color:#a2f>/bin/windows/amd64/kubelet.exe
</span></span><span style=display:flex><span><span style=color:#a2f>restart-service</span> kubelet
</span></span></code></pre></div></li></ol><h3 id=ノードをオンライン状態に>ノードをオンライン状態に</h3><ol><li><p>Kubernetes APIにアクセスできるマシンから、
スケジュール可能としてマークして、ノードをオンラインに戻します:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span><span style=color:#080;font-style:italic># &lt;node-to-drain&gt;をノードの名前に置き換えます</span>
</span></span><span style=display:flex><span>kubectl uncordon &lt;node-to-drain&gt;
</span></span></code></pre></div></li></ol><h3 id=kube-proxyをアップグレード>kube-proxyをアップグレード</h3><ol><li><p>Kubernetes APIにアクセスできるマシンから、次を実行します、
もう一度v1.25.0を目的のバージョンに置き換えます:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>curl -L https://github.com/kubernetes-sigs/sig-windows-tools/releases/latest/download/kube-proxy.yml | sed <span style=color:#b44>&#39;s/VERSION/v1.25.0/g&#39;</span> | kubectl apply -f -
</span></span></code></pre></div></li></ol></div><div class=td-content style=page-break-before:always><h1 id=pg-47be5dd51f686017f1766e6ec7aa6f41>3 - メモリー、CPU、APIリソースの管理</h1></div><div class=td-content><h1 id=pg-337620c76587e4aeb32009cb23be46de>3.1 - ネームスペースのデフォルトのメモリー要求と制限を設定する</h1><div class=lead>ネームスペースのデフォルトのメモリーリソース制限を定義して、そのネームスペース内のすべての新しいPodにメモリーリソース制限が設定されるようにします。</div><p>このページでは、<a class=glossary-tooltip title=同一の物理クラスター上で複数の仮想クラスターをサポートするために使われる抽象概念です。 data-toggle=tooltip data-placement=top href=/ja/docs/concepts/overview/working-with-objects/namespaces target=_blank aria-label=ネームスペース>ネームスペース</a>のデフォルトのメモリー要求と制限を設定する方法を説明します。</p><p>Kubernetesクラスターはネームスペースに分割することができます。デフォルトのメモリー<a href=/ja/docs/concepts/configuration/manage-resources-containers/#requests-and-limits>制限</a>を持つネームスペースがあり、独自のメモリー制限を指定しないコンテナでPodを作成しようとすると、<a class=glossary-tooltip title=コンテナのライフサイクルを定義、展開、管理するためのAPIとインターフェイスを公開するコンテナオーケストレーションレイヤーです。 data-toggle=tooltip data-placement=top href='/ja/docs/reference/glossary/?all=true#term-control-plane' target=_blank aria-label=コントロールプレーン>コントロールプレーン</a>はそのコンテナにデフォルトのメモリー制限を割り当てます。</p><p>Kubernetesは、このトピックで後ほど説明する特定の条件下で、デフォルトのメモリー要求を割り当てます。</p><h2 id=始める前に>始める前に</h2><p>Kubernetesクラスターが必要、かつそのクラスターと通信するためにkubectlコマンドラインツールが設定されている必要があります。
このチュートリアルは、コントロールプレーンのホストとして動作していない少なくとも2つのノードを持つクラスターで実行することをおすすめします。
まだクラスターがない場合、<a href=https://minikube.sigs.k8s.io/docs/tutorials/multi_node/>minikube</a>を使って作成するか、
以下のいずれかのKubernetesプレイグラウンドも使用できます:</p><ul><li><a href=https://killercoda.com/playgrounds/scenario/kubernetes>Killercoda</a></li><li><a href=http://labs.play-with-k8s.com/>Play with Kubernetes</a></li></ul><p>クラスターにネームスペースを作成するには、アクセス権が必要です。</p><p>クラスターの各ノードには、最低でも2GiBのメモリーが必要です。</p><h2 id=ネームスペースの作成>ネームスペースの作成</h2><p>この演習で作成したリソースがクラスターの他の部分から分離されるように、ネームスペースを作成します。</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl create namespace default-mem-example
</span></span></code></pre></div><h2 id=limitrangeとpodの作成>LimitRangeとPodの作成</h2><p>以下は、<a class=glossary-tooltip title='Provides constraints to limit resource consumption per Containers or Pods in a namespace.' data-toggle=tooltip data-placement=top href=/docs/concepts/policy/limit-range/ target=_blank aria-label=LimitRange>LimitRange</a>のマニフェストの例です。このマニフェストでは、デフォルトのメモリー要求とデフォルトのメモリー制限を指定しています。</p><div class=highlight><div class=copy-code-icon style=text-align:right><a href=https://raw.githubusercontent.com/kubernetes/website/main/content/ja/examples/admin/resource/memory-defaults.yaml download=admin/resource/memory-defaults.yaml><code>admin/resource/memory-defaults.yaml</code></a>
<img src=/images/copycode.svg style=max-height:24px;cursor:pointer onclick='copyCode("admin-resource-memory-defaults-yaml")' title="Copy admin/resource/memory-defaults.yaml to clipboard"></img></div><div class=includecode id=admin-resource-memory-defaults-yaml><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>LimitRange<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>mem-limit-range<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>limits</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>default</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>memory</span>:<span style=color:#bbb> </span>512Mi<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>defaultRequest</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>memory</span>:<span style=color:#bbb> </span>256Mi<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>type</span>:<span style=color:#bbb> </span>Container<span style=color:#bbb>
</span></span></span></code></pre></div></div></div><p>default-mem-exampleネームスペースにLimitRangeを作成します:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl apply -f https://k8s.io/examples/admin/resource/memory-defaults.yaml --namespace<span style=color:#666>=</span>default-mem-example
</span></span></code></pre></div><p>default-mem-exampleネームスペースでPodを作成し、そのPod内のコンテナがメモリー要求とメモリー制限の値を独自に指定しない場合、<a class=glossary-tooltip title=コンテナのライフサイクルを定義、展開、管理するためのAPIとインターフェイスを公開するコンテナオーケストレーションレイヤーです。 data-toggle=tooltip data-placement=top href='/ja/docs/reference/glossary/?all=true#term-control-plane' target=_blank aria-label=コントロールプレーン>コントロールプレーン</a>はデフォルト値のメモリー要求256MiBとメモリー制限512MiBを適用します。</p><p>以下は、コンテナを1つ持つPodのマニフェストの例です。コンテナは、メモリー要求とメモリー制限を指定していません。</p><div class=highlight><div class=copy-code-icon style=text-align:right><a href=https://raw.githubusercontent.com/kubernetes/website/main/content/ja/examples/admin/resource/memory-defaults-pod.yaml download=admin/resource/memory-defaults-pod.yaml><code>admin/resource/memory-defaults-pod.yaml</code></a>
<img src=/images/copycode.svg style=max-height:24px;cursor:pointer onclick='copyCode("admin-resource-memory-defaults-pod-yaml")' title="Copy admin/resource/memory-defaults-pod.yaml to clipboard"></img></div><div class=includecode id=admin-resource-memory-defaults-pod-yaml><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>default-mem-demo<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>default-mem-demo-ctr<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>nginx<span style=color:#bbb>
</span></span></span></code></pre></div></div></div><p>Podを作成します:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl apply -f https://k8s.io/examples/admin/resource/memory-defaults-pod.yaml --namespace<span style=color:#666>=</span>default-mem-example
</span></span></code></pre></div><p>Podの詳細情報を表示します:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get pod default-mem-demo --output<span style=color:#666>=</span>yaml --namespace<span style=color:#666>=</span>default-mem-example
</span></span></code></pre></div><p>この出力は、Podのコンテナのメモリー要求が256MiBで、メモリー制限が512MiBであることを示しています。
これらはLimitRangeで指定されたデフォルト値です。</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>containers:
</span></span><span style=display:flex><span>- image: nginx
</span></span><span style=display:flex><span>  imagePullPolicy: Always
</span></span><span style=display:flex><span>  name: default-mem-demo-ctr
</span></span><span style=display:flex><span>  resources:
</span></span><span style=display:flex><span>    limits:
</span></span><span style=display:flex><span>      memory: 512Mi
</span></span><span style=display:flex><span>    requests:
</span></span><span style=display:flex><span>      memory: 256Mi
</span></span></code></pre></div><p>Podを削除します:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl delete pod default-mem-demo --namespace<span style=color:#666>=</span>default-mem-example
</span></span></code></pre></div><h2 id=コンテナの制限を指定し-要求を指定しない場合>コンテナの制限を指定し、要求を指定しない場合</h2><p>以下は1つのコンテナを持つPodのマニフェストです。コンテナはメモリー制限を指定しますが、メモリー要求は指定しません。</p><div class=highlight><div class=copy-code-icon style=text-align:right><a href=https://raw.githubusercontent.com/kubernetes/website/main/content/ja/examples/admin/resource/memory-defaults-pod-2.yaml download=admin/resource/memory-defaults-pod-2.yaml><code>admin/resource/memory-defaults-pod-2.yaml</code></a>
<img src=/images/copycode.svg style=max-height:24px;cursor:pointer onclick='copyCode("admin-resource-memory-defaults-pod-2-yaml")' title="Copy admin/resource/memory-defaults-pod-2.yaml to clipboard"></img></div><div class=includecode id=admin-resource-memory-defaults-pod-2-yaml><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>default-mem-demo-2<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>default-mem-demo-2-ctr<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>nginx<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>resources</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>limits</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>memory</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;1Gi&#34;</span><span style=color:#bbb>
</span></span></span></code></pre></div></div></div><p>Podを作成します:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl apply -f https://k8s.io/examples/admin/resource/memory-defaults-pod-2.yaml --namespace<span style=color:#666>=</span>default-mem-example
</span></span></code></pre></div><p>Podの詳細情報を表示します:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get pod default-mem-demo-2 --output<span style=color:#666>=</span>yaml --namespace<span style=color:#666>=</span>default-mem-example
</span></span></code></pre></div><p>この出力は、コンテナのメモリー要求がそのメモリー制限に一致するように設定されていることを示しています。
コンテナにはデフォルトのメモリー要求値である256Miが割り当てられていないことに注意してください。</p><pre tabindex=0><code>resources:
  limits:
    memory: 1Gi
  requests:
    memory: 1Gi
</code></pre><h2 id=コンテナの要求を指定し-制限を指定しない場合>コンテナの要求を指定し、制限を指定しない場合</h2><p>1つのコンテナを持つPodのマニフェストです。コンテナはメモリー要求を指定しますが、メモリー制限は指定しません。</p><div class=highlight><div class=copy-code-icon style=text-align:right><a href=https://raw.githubusercontent.com/kubernetes/website/main/content/ja/examples/admin/resource/memory-defaults-pod-3.yaml download=admin/resource/memory-defaults-pod-3.yaml><code>admin/resource/memory-defaults-pod-3.yaml</code></a>
<img src=/images/copycode.svg style=max-height:24px;cursor:pointer onclick='copyCode("admin-resource-memory-defaults-pod-3-yaml")' title="Copy admin/resource/memory-defaults-pod-3.yaml to clipboard"></img></div><div class=includecode id=admin-resource-memory-defaults-pod-3-yaml><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>default-mem-demo-3<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>default-mem-demo-3-ctr<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>nginx<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>resources</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>requests</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>memory</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;128Mi&#34;</span><span style=color:#bbb>
</span></span></span></code></pre></div></div></div><p>Podを作成します:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl apply -f https://k8s.io/examples/admin/resource/memory-defaults-pod-3.yaml --namespace<span style=color:#666>=</span>default-mem-example
</span></span></code></pre></div><p>Podの詳細情報を表示します:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get pod default-mem-demo-3 --output<span style=color:#666>=</span>yaml --namespace<span style=color:#666>=</span>default-mem-example
</span></span></code></pre></div><p>この出力は、コンテナのメモリー要求が、コンテナのマニフェストで指定された値に設定されていることを示しています。
コンテナは512MiB以下のメモリーを使用するように制限されていて、これはネームスペースのデフォルトのメモリー制限と一致します。</p><pre tabindex=0><code>resources:
  limits:
    memory: 512Mi
  requests:
    memory: 128Mi
</code></pre><h2 id=デフォルトのメモリー制限と要求の動機>デフォルトのメモリー制限と要求の動機</h2><p>ネームスペースにメモリー<a class=glossary-tooltip title='Provides constraints that limit aggregate resource consumption per namespace.' data-toggle=tooltip data-placement=top href=/docs/concepts/policy/resource-quotas/ target=_blank aria-label=リソースクォータ>リソースクォータ</a>が設定されている場合、メモリー制限のデフォルト値を設定しておくと便利です。</p><p>以下はリソースクォータがネームスペースに課す制限のうちの2つです。</p><ul><li>ネームスペースで実行されるすべてのPodについて、Podとその各コンテナにメモリー制限を設ける必要があります(Pod内のすべてのコンテナに対してメモリー制限を指定すると、Kubernetesはそのコンテナの制限を合計することでPodレベルのメモリー制限を推測することができます)。</li><li>メモリー制限は、当該Podがスケジュールされているノードのリソース予約を適用します。ネームスペース内のすべてのPodに対して予約されるメモリーの総量は、指定された制限を超えてはなりません。</li><li>また、ネームスペース内のすべてのPodが実際に使用するメモリーの総量も、指定された制限を超えてはなりません。</li></ul><p>LimitRangeの追加時:</p><p>コンテナを含む、そのネームスペース内のいずれかのPodが独自のメモリー制限を指定していない場合、コントロールプレーンはそのコンテナにデフォルトのメモリー制限を適用し、メモリーのResourceQuotaによって制限されているネームスペース内でPodを実行できるようにします。</p><h2 id=クリーンアップ>クリーンアップ</h2><p>ネームスペースを削除します:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl delete namespace default-mem-example
</span></span></code></pre></div><h2 id=次の項目>次の項目</h2><h3 id=クラスター管理者向け>クラスター管理者向け</h3><ul><li><p><a href=/docs/tasks/administer-cluster/manage-resources/cpu-default-namespace/>Configure Default CPU Requests and Limits for a Namespace</a></p></li><li><p><a href=ja/docs/tasks/administer-cluster/manage-resources/memory-constraint-namespace/>Namespaceに対する最小および最大メモリー制約の構成</a></p></li><li><p><a href=/docs/tasks/administer-cluster/manage-resources/cpu-constraint-namespace/>Configure Minimum and Maximum CPU Constraints for a Namespace</a></p></li><li><p><a href=/docs/tasks/administer-cluster/manage-resources/quota-memory-cpu-namespace/>Configure Memory and CPU Quotas for a Namespace</a></p></li><li><p><a href=/docs/tasks/administer-cluster/manage-resources/quota-pod-namespace/>Configure a Pod Quota for a Namespace</a></p></li><li><p><a href=/docs/tasks/administer-cluster/quota-api-object/>Configure Quotas for API Objects</a></p></li></ul><h3 id=アプリケーション開発者向け>アプリケーション開発者向け</h3><ul><li><p><a href=ja/docs/tasks/configure-pod-container/assign-memory-resource/>コンテナおよびPodへのメモリーリソースの割り当て</a></p></li><li><p><a href=ja/docs/tasks/configure-pod-container/assign-cpu-resource/>コンテナおよびPodへのCPUリソースの割り当て</a></p></li><li><p><a href=ja/docs/tasks/configure-pod-container/quality-service-pod/>PodにQuality of Serviceを設定する</a></p></li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-adb489b1ab985c9215657b0d4c6ae92b>3.2 - Namespaceに対する最小および最大メモリー制約の構成</h1><p>このページでは、Namespaceで実行されるコンテナが使用するメモリーの最小値と最大値を設定する方法を説明します。
<a href=/docs/reference/generated/kubernetes-api/v1.25/#limitrange-v1-core>LimitRange</a> で最小値と最大値のメモリー値を指定します。
PodがLimitRangeによって課される制約を満たさない場合、そのNamespaceではPodを作成できません。</p><h2 id=始める前に>始める前に</h2><p><p>Kubernetesクラスターが必要、かつそのクラスターと通信するためにkubectlコマンドラインツールが設定されている必要があります。
このチュートリアルは、コントロールプレーンのホストとして動作していない少なくとも2つのノードを持つクラスターで実行することをおすすめします。
まだクラスターがない場合、<a href=https://minikube.sigs.k8s.io/docs/tutorials/multi_node/>minikube</a>を使って作成するか、
以下のいずれかのKubernetesプレイグラウンドも使用できます:</p><ul><li><a href=https://killercoda.com/playgrounds/scenario/kubernetes>Killercoda</a></li><li><a href=http://labs.play-with-k8s.com/>Play with Kubernetes</a></li></ul>バージョンを確認するには次のコマンドを実行してください: <code>kubectl version</code>.</p><p>クラスター内の各ノードには、少なくとも1GiBのメモリーが必要です。</p><h2 id=namespaceの作成>Namespaceの作成</h2><p>この演習で作成したリソースがクラスターの他の部分から分離されるように、Namespaceを作成します。</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl create namespace constraints-mem-example
</span></span></code></pre></div><h2 id=limitrangeとpodを作成>LimitRangeとPodを作成</h2><p>LimitRangeの設定ファイルです。</p><div class=highlight><div class=copy-code-icon style=text-align:right><a href=https://raw.githubusercontent.com/kubernetes/website/main/content/ja/examples/admin/resource/memory-constraints.yaml download=admin/resource/memory-constraints.yaml><code>admin/resource/memory-constraints.yaml</code></a>
<img src=/images/copycode.svg style=max-height:24px;cursor:pointer onclick='copyCode("admin-resource-memory-constraints-yaml")' title="Copy admin/resource/memory-constraints.yaml to clipboard"></img></div><div class=includecode id=admin-resource-memory-constraints-yaml><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>LimitRange<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>mem-min-max-demo-lr<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>limits</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>max</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>memory</span>:<span style=color:#bbb> </span>1Gi<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>min</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>memory</span>:<span style=color:#bbb> </span>500Mi<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>type</span>:<span style=color:#bbb> </span>Container<span style=color:#bbb>
</span></span></span></code></pre></div></div></div><p>LimitRangeを作成します。</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl apply -f https://k8s.io/examples/admin/resource/memory-constraints.yaml --namespace<span style=color:#666>=</span>constraints-mem-example
</span></span></code></pre></div><p>LimitRangeの詳細情報を表示します。</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get limitrange mem-min-max-demo-lr --namespace<span style=color:#666>=</span>constraints-mem-example --output<span style=color:#666>=</span>yaml
</span></span></code></pre></div><p>出力されるのは、予想通りメモリー制約の最小値と最大値を示しています。
しかし、LimitRangeの設定ファイルでデフォルト値を指定していないにもかかわらず、
自動的に作成されていることに気づきます。</p><pre tabindex=0><code>  limits:
  - default:
      memory: 1Gi
    defaultRequest:
      memory: 1Gi
    max:
      memory: 1Gi
    min:
      memory: 500Mi
    type: Container
</code></pre><p>constraints-mem-exampleNamespaceにコンテナが作成されるたびに、
Kubernetesは以下の手順を実行するようになっています。</p><ul><li><p>コンテナが独自のメモリー要求と制限を指定しない場合は、デフォルトのメモリー要求と制限をコンテナに割り当てます。</p></li><li><p>コンテナに500MiB以上のメモリー要求があることを確認します。</p></li><li><p>コンテナのメモリー制限が1GiB以下であることを確認します。</p></li></ul><p>以下は、1つのコンテナを持つPodの設定ファイルです。設定ファイルのコンテナ(containers)では、600MiBのメモリー要求と800MiBのメモリー制限が指定されています。これらはLimitRangeによって課される最小と最大のメモリー制約を満たしています。</p><div class=highlight><div class=copy-code-icon style=text-align:right><a href=https://raw.githubusercontent.com/kubernetes/website/main/content/ja/examples/admin/resource/memory-constraints-pod.yaml download=admin/resource/memory-constraints-pod.yaml><code>admin/resource/memory-constraints-pod.yaml</code></a>
<img src=/images/copycode.svg style=max-height:24px;cursor:pointer onclick='copyCode("admin-resource-memory-constraints-pod-yaml")' title="Copy admin/resource/memory-constraints-pod.yaml to clipboard"></img></div><div class=includecode id=admin-resource-memory-constraints-pod-yaml><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>constraints-mem-demo<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>constraints-mem-demo-ctr<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>nginx<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>resources</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>limits</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>memory</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;800Mi&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>requests</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>memory</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;600Mi&#34;</span><span style=color:#bbb>
</span></span></span></code></pre></div></div></div><p>Podの作成</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl apply -f https://k8s.io/examples/admin/resource/memory-constraints-pod.yaml --namespace<span style=color:#666>=</span>constraints-mem-example
</span></span></code></pre></div><p>Podのコンテナが実行されていることを確認します。</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get pod constraints-mem-demo --namespace<span style=color:#666>=</span>constraints-mem-example
</span></span></code></pre></div><p>Podの詳細情報を見ます</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get pod constraints-mem-demo --output<span style=color:#666>=</span>yaml --namespace<span style=color:#666>=</span>constraints-mem-example
</span></span></code></pre></div><p>出力は、コンテナが600MiBのメモリ要求と800MiBのメモリー制限になっていることを示しています。これらはLimitRangeによって課される制約を満たしています。</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>resources</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>limits</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>     </span><span style=color:green;font-weight:700>memory</span>:<span style=color:#bbb> </span>800Mi<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>requests</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>memory</span>:<span style=color:#bbb> </span>600Mi<span style=color:#bbb>
</span></span></span></code></pre></div><p>Podを消します。</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl delete pod constraints-mem-demo --namespace<span style=color:#666>=</span>constraints-mem-example
</span></span></code></pre></div><h2 id=最大メモリ制約を超えるpodの作成の試み>最大メモリ制約を超えるPodの作成の試み</h2><p>これは、1つのコンテナを持つPodの設定ファイルです。コンテナは800MiBのメモリー要求と1.5GiBのメモリー制限を指定しています。</p><div class=highlight><div class=copy-code-icon style=text-align:right><a href=https://raw.githubusercontent.com/kubernetes/website/main/content/ja/examples/admin/resource/memory-constraints-pod-2.yaml download=admin/resource/memory-constraints-pod-2.yaml><code>admin/resource/memory-constraints-pod-2.yaml</code></a>
<img src=/images/copycode.svg style=max-height:24px;cursor:pointer onclick='copyCode("admin-resource-memory-constraints-pod-2-yaml")' title="Copy admin/resource/memory-constraints-pod-2.yaml to clipboard"></img></div><div class=includecode id=admin-resource-memory-constraints-pod-2-yaml><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>constraints-mem-demo-2<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>constraints-mem-demo-2-ctr<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>nginx<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>resources</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>limits</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>memory</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;1.5Gi&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>requests</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>memory</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;800Mi&#34;</span><span style=color:#bbb>
</span></span></span></code></pre></div></div></div><p>Podを作成してみます。</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl apply -f https://k8s.io/examples/admin/resource/memory-constraints-pod-2.yaml --namespace<span style=color:#666>=</span>constraints-mem-example
</span></span></code></pre></div><p>出力は、コンテナが大きすぎるメモリー制限を指定しているため、Podが作成されないことを示しています。</p><pre tabindex=0><code>Error from server (Forbidden): error when creating &#34;examples/admin/resource/memory-constraints-pod-2.yaml&#34;:
pods &#34;constraints-mem-demo-2&#34; is forbidden: maximum memory usage per Container is 1Gi, but limit is 1536Mi.
</code></pre><h2 id=最低限のメモリ要求を満たさないpodの作成の試み>最低限のメモリ要求を満たさないPodの作成の試み</h2><p>これは、1つのコンテナを持つPodの設定ファイルです。コンテナは100MiBのメモリー要求と800MiBのメモリー制限を指定しています。</p><div class=highlight><div class=copy-code-icon style=text-align:right><a href=https://raw.githubusercontent.com/kubernetes/website/main/content/ja/examples/admin/resource/memory-constraints-pod-3.yaml download=admin/resource/memory-constraints-pod-3.yaml><code>admin/resource/memory-constraints-pod-3.yaml</code></a>
<img src=/images/copycode.svg style=max-height:24px;cursor:pointer onclick='copyCode("admin-resource-memory-constraints-pod-3-yaml")' title="Copy admin/resource/memory-constraints-pod-3.yaml to clipboard"></img></div><div class=includecode id=admin-resource-memory-constraints-pod-3-yaml><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>constraints-mem-demo-3<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>constraints-mem-demo-3-ctr<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>nginx<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>resources</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>limits</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>memory</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;800Mi&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>requests</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>memory</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;100Mi&#34;</span><span style=color:#bbb>
</span></span></span></code></pre></div></div></div><p>Podを作成してみます。</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl apply -f https://k8s.io/examples/admin/resource/memory-constraints-pod-3.yaml --namespace<span style=color:#666>=</span>constraints-mem-example
</span></span></code></pre></div><p>出力は、コンテナが小さすぎるメモリー要求を指定しているため、Podが作成されないことを示しています。</p><pre tabindex=0><code>Error from server (Forbidden): error when creating &#34;examples/admin/resource/memory-constraints-pod-3.yaml&#34;:
pods &#34;constraints-mem-demo-3&#34; is forbidden: minimum memory usage per Container is 500Mi, but request is 100Mi.
</code></pre><h2 id=メモリ要求や制限を指定しないpodの作成>メモリ要求や制限を指定しないPodの作成</h2><p>これは、1つのコンテナを持つPodの設定ファイルです。コンテナはメモリー要求を指定しておらず、メモリー制限も指定していません。</p><div class=highlight><div class=copy-code-icon style=text-align:right><a href=https://raw.githubusercontent.com/kubernetes/website/main/content/ja/examples/admin/resource/memory-constraints-pod-4.yaml download=admin/resource/memory-constraints-pod-4.yaml><code>admin/resource/memory-constraints-pod-4.yaml</code></a>
<img src=/images/copycode.svg style=max-height:24px;cursor:pointer onclick='copyCode("admin-resource-memory-constraints-pod-4-yaml")' title="Copy admin/resource/memory-constraints-pod-4.yaml to clipboard"></img></div><div class=includecode id=admin-resource-memory-constraints-pod-4-yaml><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>constraints-mem-demo-4<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>constraints-mem-demo-4-ctr<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>nginx<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>
</span></span></span></code></pre></div></div></div><p>Podを作成します。</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl apply -f https://k8s.io/examples/admin/resource/memory-constraints-pod-4.yaml --namespace<span style=color:#666>=</span>constraints-mem-example
</span></span></code></pre></div><p>Podの詳細情報を見ます</p><pre tabindex=0><code>kubectl get pod constraints-mem-demo-4 --namespace=constraints-mem-example --output=yaml
</code></pre><p>出力を見ると、Podのコンテナのメモリ要求は1GiB、メモリー制限は1GiBであることがわかります。
コンテナはどのようにしてこれらの値を取得したのでしょうか？</p><pre tabindex=0><code>resources:
  limits:
    memory: 1Gi
  requests:
    memory: 1Gi
</code></pre><p>コンテナが独自のメモリー要求と制限を指定していなかったため、LimitRangeから与えられのです。
コンテナが独自のメモリー要求と制限を指定していなかったため、LimitRangeから<a href=/docs/tasks/administer-cluster/manage-resources/memory-default-namespace/>デフォルトのメモリー要求と制限</a>が与えられたのです。</p><p>この時点で、コンテナは起動しているかもしれませんし、起動していないかもしれません。このタスクの前提条件は、ノードが少なくとも1GiBのメモリーを持っていることであることを思い出してください。それぞれのノードが1GiBのメモリーしか持っていない場合、どのノードにも1GiBのメモリー要求に対応するのに十分な割り当て可能なメモリーがありません。たまたま2GiBのメモリーを持つノードを使用しているのであれば、おそらく1GiBのメモリーリクエストに対応するのに十分なスペースを持っていることになります。</p><p>Podを削除します。</p><pre tabindex=0><code>kubectl delete pod constraints-mem-demo-4 --namespace=constraints-mem-example
</code></pre><h2 id=最小および最大メモリー制約の強制>最小および最大メモリー制約の強制</h2><p>LimitRangeによってNamespaceに課される最大および最小のメモリー制約は、Podが作成または更新されたときにのみ適用されます。LimitRangeを変更しても、以前に作成されたPodには影響しません。</p><h2 id=最小-最大メモリー制約の動機>最小・最大メモリー制約の動機</h2><p>クラスター管理者としては、Podが使用できるメモリー量に制限を課したいと思うかもしれません。</p><p>例:</p><ul><li><p>クラスター内の各ノードは2GBのメモリーを持っています。クラスタ内のどのノードもその要求をサポートできないため、2GB以上のメモリーを要求するPodは受け入れたくありません。</p></li><li><p>クラスターは運用部門と開発部門で共有されています。 本番用のワークロードでは最大8GBのメモリーを消費しますが、開発用のワークロードでは512MBに制限したいとします。本番用と開発用に別々のNamespaceを作成し、それぞれのNamespaceにメモリー制限を適用します。</p></li></ul><h2 id=クリーンアップ>クリーンアップ</h2><p>Namespaceを削除します。</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl delete namespace constraints-mem-example
</span></span></code></pre></div><h2 id=次の項目>次の項目</h2><h3 id=クラスター管理者向け>クラスター管理者向け</h3><ul><li><p><a href=/docs/tasks/administer-cluster/manage-resources/memory-default-namespace/>名前空間に対するデフォルトのメモリー要求と制限の構成</a></p></li><li><p><a href=/docs/tasks/administer-cluster/manage-resources/cpu-default-namespace/>名前空間に対するデフォルトのCPU要求と制限の構成</a></p></li><li><p><a href=/docs/tasks/administer-cluster/manage-resources/cpu-constraint-namespace/>名前空間に対する最小および最大CPU制約の構成</a></p></li><li><p><a href=/docs/tasks/administer-cluster/manage-resources/quota-memory-cpu-namespace/>名前空間に対するメモリーとCPUのクォータの構成</a></p></li><li><p><a href=/docs/tasks/administer-cluster/manage-resources/quota-pod-namespace/>名前空間に対するPodクォータの設定</a></p></li><li><p><a href=/docs/tasks/administer-cluster/quota-api-object/>APIオブジェクトのクォータの設定</a></p></li></ul><h3 id=アプリケーション開発者向け>アプリケーション開発者向け</h3><ul><li><p><a href=/docs/tasks/configure-pod-container/assign-memory-resource/>コンテナとPodへのメモリーリソースの割り当て</a></p></li><li><p><a href=/docs/tasks/configure-pod-container/assign-cpu-resource/>コンテナとPodへのCPUリソースの割り当て</a></p></li><li><p><a href=/ja/docs/tasks/configure-pod-container/quality-service-pod/>PodのQoS(サービス品質)を設定</a></p></li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-7743f043c43f7b12e8654e2227dbc658>4 - 証明書</h1><p>クライアント証明書認証を使用する場合、<code>easyrsa</code>,<code>openssl</code>または<code>cfssl</code>を使って手動で証明書を生成することができます。</p><h3 id=easyrsa>easyrsa</h3><p><strong>easyrsa</strong>はクラスターの証明書を手動で生成することができます。</p><ol><li><p>パッチが適用されたバージョンのeasyrsa3をダウンロードし、解凍し、初期化します。</p><pre><code>curl -LO https://storage.googleapis.com/kubernetes-release/easy-rsa/easy-rsa.tar.gz
tar xzf easy-rsa.tar.gz
cd easy-rsa-master/easyrsa3
./easyrsa init-pki
</code></pre></li><li><p>新しい認証局(CA)を生成します。
<code>req-cn</code>はCAの新しいルート証明書のコモンネーム(CN)を指定します。</p><pre><code>./easyrsa --batch &quot;--req-cn=${MASTER_IP}@`date +%s`&quot; build-ca nopass
</code></pre></li><li><p>サーバー証明書と鍵を生成します。
引数<code>--subject-alt-name</code>は、APIサーバーがアクセス可能なIPとDNS名を設定します。
<code>MASTER_CLUSTER_IP</code>は通常、APIサーバーとコントローラーマネージャーコンポーネントの両方で<code>--service-cluster-ip-range</code>引数に指定したサービスCIDRの最初のIPとなります。
引数<code>--days</code>は、証明書の有効期限が切れるまでの日数を設定するために使用します。
また、以下のサンプルでは、デフォルトのDNSドメイン名として<code>cluster.local</code>を使用することを想定しています。</p><pre><code>./easyrsa --subject-alt-name=&quot;IP:${MASTER_IP},&quot;\
&quot;IP:${MASTER_CLUSTER_IP},&quot;\
&quot;DNS:kubernetes,&quot;\
&quot;DNS:kubernetes.default,&quot;\
&quot;DNS:kubernetes.default.svc,&quot;\
&quot;DNS:kubernetes.default.svc.cluster,&quot;\
&quot;DNS:kubernetes.default.svc.cluster.local&quot; \
--days=10000 \
build-server-full server nopass
</code></pre></li><li><p><code>pki/ca.crt</code>,<code>pki/issued/server.crt</code>,<code>pki/private/server.key</code>を自分のディレクトリにコピーします。</p></li><li><p>APIサーバーのスタートパラメーターに以下のパラメーターを記入し、追加します。</p><pre><code>--client-ca-file=/yourdirectory/ca.crt
--tls-cert-file=/yourdirectory/server.crt
--tls-private-key-file=/yourdirectory/server.key
</code></pre></li></ol><h3 id=openssl>openssl</h3><p><strong>openssl</strong>は、クラスター用の証明書を手動で生成することができます。</p><ol><li><p>2048bitのca.keyを生成します:</p><pre><code>openssl genrsa -out ca.key 2048
</code></pre></li><li><p>ca.keyに従ってca.crtを生成します(-daysで証明書の有効期限を設定します)。</p><pre><code>openssl req -x509 -new -nodes -key ca.key -subj &quot;/CN=${MASTER_IP}&quot; -days 10000 -out ca.crt
</code></pre></li><li><p>2048bitでserver.keyを生成します:</p><pre><code>openssl genrsa -out server.key 2048
</code></pre></li><li><p>証明書署名要求(CSR)を生成するための設定ファイルを作成します。
角括弧で囲まれた値(例:<code>&lt;MASTER_IP></code>)は必ず実際の値に置き換えてから、ファイル(例:<code>csr.conf</code>)に保存してください。<code>MASTER_CLUSTER_IP</code>の値は、前のサブセクションで説明したように、APIサーバーのサービスクラスターのIPであることに注意してください。また、以下のサンプルでは、デフォルトのDNSドメイン名として<code>cluster.local</code>を使用することを想定しています。</p><pre><code>[ req ]
default_bits = 2048
prompt = no
default_md = sha256
req_extensions = req_ext
distinguished_name = dn

[ dn ]
C = &lt;country&gt;
ST = &lt;state&gt;
L = &lt;city&gt;
O = &lt;organization&gt;
OU = &lt;organization unit&gt;
CN = &lt;MASTER_IP&gt;

[ req_ext ]
subjectAltName = @alt_names

[ alt_names ]
DNS.1 = kubernetes
DNS.2 = kubernetes.default
DNS.3 = kubernetes.default.svc
DNS.4 = kubernetes.default.svc.cluster
DNS.5 = kubernetes.default.svc.cluster.local
IP.1 = &lt;MASTER_IP&gt;
IP.2 = &lt;MASTER_CLUSTER_IP&gt;

[ v3_ext ]
authorityKeyIdentifier=keyid,issuer:always
basicConstraints=CA:FALSE
keyUsage=keyEncipherment,dataEncipherment
extendedKeyUsage=serverAuth,clientAuth
subjectAltName=@alt_names
</code></pre></li><li><p>設定ファイルに基づき、証明書署名要求を生成します:</p><pre><code>openssl req -new -key server.key -out server.csr -config csr.conf
</code></pre></li><li><p>ca.key、ca.crt、server.csrを使用して、サーバー証明書を生成します:</p><pre><code>openssl x509 -req -in server.csr -CA ca.crt -CAkey ca.key \
-CAcreateserial -out server.crt -days 10000 \
-extensions v3_ext -extfile csr.conf
</code></pre></li><li><p>証明書署名要求を表示します:</p><pre><code>openssl req  -noout -text -in ./server.csr
</code></pre></li><li><p>証明書を表示します:</p><pre><code>openssl x509  -noout -text -in ./server.crt
</code></pre></li></ol><p>最後に、同じパラメーターをAPIサーバーのスタートパラメーターに追加します。</p><h3 id=cfssl>cfssl</h3><p><strong>cfssl</strong>も証明書生を成するためのツールです。</p><ol><li><p>以下のように、コマンドラインツールをダウンロードし、解凍して準備してください。
なお、サンプルのコマンドは、お使いのハードウェア・アーキテクチャやCFSSLのバージョンに合わせる必要があるかもしれません。</p><pre><code>curl -L https://github.com/cloudflare/cfssl/releases/download/v1.5.0/cfssl_1.5.0_linux_amd64 -o cfssl
chmod +x cfssl
curl -L https://github.com/cloudflare/cfssl/releases/download/v1.5.0/cfssljson_1.5.0_linux_amd64 -o cfssljson
chmod +x cfssljson
curl -L https://github.com/cloudflare/cfssl/releases/download/v1.5.0/cfssl-certinfo_1.5.0_linux_amd64 -o cfssl-certinfo
chmod +x cfssl-certinfo
</code></pre></li><li><p>成果物を格納するディレクトリを作成し、cfsslを初期化します:</p><pre><code>mkdir cert
cd cert
../cfssl print-defaults config &gt; config.json
../cfssl print-defaults csr &gt; csr.json
</code></pre></li><li><p>CAファイルを生成するためのJSON設定ファイル、例えば<code>ca-config.json</code>を作成します:</p><pre><code>{
  &quot;signing&quot;: {
    &quot;default&quot;: {
      &quot;expiry&quot;: &quot;8760h&quot;
    },
    &quot;profiles&quot;: {
      &quot;kubernetes&quot;: {
        &quot;usages&quot;: [
          &quot;signing&quot;,
          &quot;key encipherment&quot;,
          &quot;server auth&quot;,
          &quot;client auth&quot;
        ],
        &quot;expiry&quot;: &quot;8760h&quot;
      }
    }
  }
}
</code></pre></li><li><p>CA証明書署名要求(CSR)用のJSON設定ファイル(例:<code>ca-csr.json</code>)を作成します。
角括弧で囲まれた値は、必ず使用したい実際の値に置き換えてください。</p><pre><code>{
  &quot;CN&quot;: &quot;kubernetes&quot;,
  &quot;key&quot;: {
    &quot;algo&quot;: &quot;rsa&quot;,
    &quot;size&quot;: 2048
  },
  &quot;names&quot;:[{
    &quot;C&quot;: &quot;&lt;country&gt;&quot;,
    &quot;ST&quot;: &quot;&lt;state&gt;&quot;,
    &quot;L&quot;: &quot;&lt;city&gt;&quot;,
    &quot;O&quot;: &quot;&lt;organization&gt;&quot;,
    &quot;OU&quot;: &quot;&lt;organization unit&gt;&quot;
  }]
}
</code></pre></li><li><p>CAキー(<code>ca-key.pem</code>)と証明書(<code>ca.pem</code>)を生成します:</p><pre><code>../cfssl gencert -initca ca-csr.json | ../cfssljson -bare ca
</code></pre></li><li><p>APIサーバーの鍵と証明書を生成するためのJSON設定ファイル、例えば<code>server-csr.json</code>を作成します。
角括弧内の値は、必ず使用したい実際の値に置き換えてください。
<code>MASTER_CLUSTER_IP</code>は、前のサブセクションで説明したように、APIサーバーのサービスクラスターのIPです。
また、以下のサンプルでは、デフォルトのDNSドメイン名として<code>cluster.local</code>を使用することを想定しています。</p><pre><code>{
  &quot;CN&quot;: &quot;kubernetes&quot;,
  &quot;hosts&quot;: [
    &quot;127.0.0.1&quot;,
    &quot;&lt;MASTER_IP&gt;&quot;,
    &quot;&lt;MASTER_CLUSTER_IP&gt;&quot;,
    &quot;kubernetes&quot;,
    &quot;kubernetes.default&quot;,
    &quot;kubernetes.default.svc&quot;,
    &quot;kubernetes.default.svc.cluster&quot;,
    &quot;kubernetes.default.svc.cluster.local&quot;
  ],
  &quot;key&quot;: {
    &quot;algo&quot;: &quot;rsa&quot;,
    &quot;size&quot;: 2048
  },
  &quot;names&quot;: [{
    &quot;C&quot;: &quot;&lt;country&gt;&quot;,
    &quot;ST&quot;: &quot;&lt;state&gt;&quot;,
    &quot;L&quot;: &quot;&lt;city&gt;&quot;,
    &quot;O&quot;: &quot;&lt;organization&gt;&quot;,
    &quot;OU&quot;: &quot;&lt;organization unit&gt;&quot;
  }]
}
</code></pre></li><li><p>APIサーバーの鍵と証明書を生成します。
デフォルトでは、それぞれ<code>server-key.pem</code>と<code>server.pem</code>というファイルに保存されます:</p><pre><code>../cfssl gencert -ca=ca.pem -ca-key=ca-key.pem \
--config=ca-config.json -profile=kubernetes \
server-csr.json | ../cfssljson -bare server
</code></pre></li></ol><h2 id=自己署名入りca証明書を配布する>自己署名入りCA証明書を配布する</h2><p>クライアントノードが自己署名入りCA証明書を有効なものとして認識できない場合があります。</p><p>非プロダクション環境、または会社のファイアウォールの内側での開発環境であれば、自己署名入りCA証明書をすべてのクライアントに配布し、有効な証明書のローカルリストを更新することができます。</p><p>各クライアントで、次の操作を実行します:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>sudo cp ca.crt /usr/local/share/ca-certificates/kubernetes.crt
</span></span><span style=display:flex><span>sudo update-ca-certificates
</span></span></code></pre></div><pre tabindex=0><code>Updating certificates in /etc/ssl/certs...
1 added, 0 removed; done.
Running hooks in /etc/ca-certificates/update.d....
done.
</code></pre><h2 id=証明書api>証明書API</h2><p>認証に使用するx509証明書のプロビジョニングには<code>certificates.k8s.io</code> APIを使用することができます。<a href=/docs/tasks/tls/managing-tls-in-a-cluster>ここ</a>に記述されています。</p></div><div class=td-content style=page-break-before:always><h1 id=pg-77351865caa548b0a06694b904dd881c>5 - EndpointSliceの有効化</h1><p>このページはKubernetesのEndpointSliceの有効化の概要を説明します。</p><h2 id=始める前に>始める前に</h2><p><p>Kubernetesクラスターが必要、かつそのクラスターと通信するためにkubectlコマンドラインツールが設定されている必要があります。
このチュートリアルは、コントロールプレーンのホストとして動作していない少なくとも2つのノードを持つクラスターで実行することをおすすめします。
まだクラスターがない場合、<a href=https://minikube.sigs.k8s.io/docs/tutorials/multi_node/>minikube</a>を使って作成するか、
以下のいずれかのKubernetesプレイグラウンドも使用できます:</p><ul><li><a href=https://killercoda.com/playgrounds/scenario/kubernetes>Killercoda</a></li><li><a href=http://labs.play-with-k8s.com/>Play with Kubernetes</a></li></ul>バージョンを確認するには次のコマンドを実行してください: <code>kubectl version</code>.</p><h2 id=概要>概要</h2><p>EndpointSliceは、KubernetesのEndpointsに対してスケーラブルで拡張可能な代替手段を提供します。Endpointsが提供する機能のベースの上に構築し、スケーラブルな方法で拡張します。Serviceが多数(100以上)のネットワークエンドポイントを持つ場合、それらは単一の大きなEndpointsリソースではなく、複数の小さなEndpointSliceに分割されます。</p><h2 id=endpointsliceの有効化>EndpointSliceの有効化</h2><div style=margin-top:10px;margin-bottom:10px><b>FEATURE STATE:</b> <code>Kubernetes v1.17 [beta]</code></div><div class="alert alert-info note callout" role=alert><strong>備考:</strong> EndpointSliceは、最終的には既存のEndpointsを置き換える可能性がありますが、多くのKubernetesコンポーネントはまだ既存のEndpointsに依存しています。現時点ではEndpointSliceを有効化することは、Endpointsの置き換えではなく、クラスター内のEndpointsへの追加とみなされる必要があります。</div><p>EndpoitSliceはベータ版の機能です。APIとEndpointSlice<a class=glossary-tooltip title=クラスターの状態をAPIサーバーから取得、見張る制御ループで、現在の状態を望ましい状態に移行するように更新します。 data-toggle=tooltip data-placement=top href=/ja/docs/concepts/architecture/controller/ target=_blank aria-label=コントローラー>コントローラー</a>はデフォルトで有効です。<a class=glossary-tooltip title=kube-proxyはクラスター内の各Nodeで動作しているネットワークプロキシです。 data-toggle=tooltip data-placement=top href=/docs/reference/command-line-tools-reference/kube-proxy/ target=_blank aria-label=kube-proxy>kube-proxy</a>はデフォルトでEndpointSliceではなくEndpointsを使用します。</p><p>スケーラビリティと性能向上のため、kube-proxy上で<code>EndpointSliceProxying</code><a href=/ja/docs/reference/command-line-tools-reference/feature-gates/>フィーチャーゲート</a>を有効にできます。この変更はデータソースをEndpointSliceに移します、これはkube-proxyとKubernetes API間のトラフィックの量を削減します。</p><h2 id=endpointsliceの使用>EndpointSliceの使用</h2><p>クラスター内でEndpointSliceを完全に有効にすると、各Endpointsリソースに対応するEndpointSliceリソースが表示されます。既存のEndpointsの機能をサポートすることに加えて、EndpointSliceはトポロジーなどの新しい情報を含みます。これらにより、クラスター内のネットワークエンドポイントのスケーラビリティと拡張性が大きく向上します。</p><h2 id=次の項目>次の項目</h2><ul><li><a href=/ja/docs/concepts/services-networking/endpoint-slices/>EndpointSlice</a>を参照してください。</li><li><a href=/ja/docs/concepts/services-networking/connect-applications-service/>サービスとアプリケーションの接続</a>を参照してください。</li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-9ceed97f912df7289ed8872e290cfbad>6 - KubernetesクラスターでNodeLocal DNSキャッシュを使用する</h1><p><div style=margin-top:10px;margin-bottom:10px><b>FEATURE STATE:</b> <code>Kubernetes v1.18 [stable]</code></div>このページでは、KubernetesのNodeLocal DNSキャッシュの機能の概要について説明します。</p><h2 id=始める前に>始める前に</h2><p><p>Kubernetesクラスターが必要、かつそのクラスターと通信するためにkubectlコマンドラインツールが設定されている必要があります。
このチュートリアルは、コントロールプレーンのホストとして動作していない少なくとも2つのノードを持つクラスターで実行することをおすすめします。
まだクラスターがない場合、<a href=https://minikube.sigs.k8s.io/docs/tutorials/multi_node/>minikube</a>を使って作成するか、
以下のいずれかのKubernetesプレイグラウンドも使用できます:</p><ul><li><a href=https://killercoda.com/playgrounds/scenario/kubernetes>Killercoda</a></li><li><a href=http://labs.play-with-k8s.com/>Play with Kubernetes</a></li></ul>バージョンを確認するには次のコマンドを実行してください: <code>kubectl version</code>.</p><h2 id=イントロダクション>イントロダクション</h2><p>NodeLocal DNSキャッシュは、クラスターノード上でDNSキャッシュエージェントをDaemonSetで稼働させることで、クラスターのDNSパフォーマンスを向上させます。現在のアーキテクチャーにおいて、ClusterFirstのDNSモードでのPodは、DNSクエリー用にkube-dnsのService IPに疎通します。これにより、kube-proxyによって追加されたiptablesを介してkube-dns/CoreDNSのエンドポイントへ変換されます。この新しいアーキテクチャーによって、Podは同じノード上で稼働するDNSキャッシュエージェントに対して疎通し、それによってiptablesのDNATルールとコネクショントラッキングを回避します。ローカルのキャッシュエージェントはクラスターのホスト名(デフォルトではcluster.localというサフィックス)に対するキャッシュミスがあるときはkube-dnsサービスへ問い合わせます。</p><h2 id=動機>動機</h2><ul><li><p>現在のDNSアーキテクチャーでは、ローカルのkube-dns/CoreDNSがないとき、DNSへの秒間クエリー数が最も高いPodは他のノードへ疎通する可能性があります。ローカルでキャッシュを持つことにより、この状況におけるレイテンシーの改善に役立ちます。</p></li><li><p>iptables DNATとコネクショントラッキングをスキップすることは<a href=https://github.com/kubernetes/kubernetes/issues/56903>conntrackの競合</a>を減らし、UDPでのDNSエントリーがconntrackテーブルを満杯にすることを避けるのに役立ちます。</p></li><li><p>ローカルのキャッシュエージェントからkube-dnsサービスへの接続がTCPにアップグレードされます。タイムアウトをしなくてはならないUDPエントリーと比べ、TCPのconntrackエントリーはコネクションクローズ時に削除されます(<a href=https://www.kernel.org/doc/Documentation/networking/nf_conntrack-sysctl.txt>デフォルトの</a> <code>nf_conntrack_udp_timeout</code> は30秒です)。</p></li><li><p>DNSクエリーをUDPからTCPにアップグレードすることで、UDPパケットの欠損や、通常30秒(10秒のタイムアウトで3回再試行する)であるDNSのタイムアウトによるテイルレイテンシーを減少させます。NodeLocalキャッシュはUDPのDNSクエリーを待ち受けるため、アプリケーションを変更する必要はありません。</p></li><li><p>DNSクエリーに対するノードレベルのメトリクスと可視性を得られます。</p></li><li><p>DNSの不在応答のキャッシュも再度有効にされ、それによりkube-dnsサービスに対するクエリー数を減らします。</p></li></ul><h2 id=アーキテクチャー図>アーキテクチャー図</h2><p>この図はNodeLocal DNSキャッシュが有効にされた後にDNSクエリーがあったときの流れとなります。</p><figure><img src=/images/docs/nodelocaldns.svg alt="NodeLocal DNSCache flow"><figcaption><h4>Nodelocal DNSCacheのフロー</h4><p>この図は、NodeLocal DNSキャッシュがDNSクエリーをどう扱うかを表したものです。</p></figcaption></figure><h2 id=設定>設定</h2><div class="alert alert-info note callout" role=alert><strong>備考:</strong> NodeLocal DNSキャッシュのローカルリッスン用のIPアドレスは、クラスタ内の既存のIPと衝突しないことが保証できるものであれば、どのようなアドレスでもかまいません。例えば、IPv4のリンクローカル範囲169.254.0.0/16やIPv6のユニークローカルアドレス範囲fd00::/8から、ローカルスコープのアドレスを使用することが推奨されています。</div><p>この機能は、下記の手順により有効化できます。</p><ul><li><p><a href=https://github.com/kubernetes/kubernetes/blob/master/cluster/addons/dns/nodelocaldns/nodelocaldns.yaml><code>nodelocaldns.yaml</code></a>と同様のマニフェストを用意し、<code>nodelocaldns.yaml</code>という名前で保存してください。</p></li><li><p>マニフェスト内の変数を正しい値に置き換えてください。</p><ul><li><p>kubedns=<code>kubectl get svc kube-dns -n kube-system -o jsonpath={.spec.clusterIP}</code></p></li><li><p>domain=<code>&lt;cluster-domain></code></p></li><li><p>localdns=<code>&lt;node-local-address></code></p></li></ul><p><code>&lt;cluster-domain></code>はデフォルトで"cluster.local"です。<code>&lt;node-local-address></code> はNodeLocal DNSキャッシュ用に確保されたローカルの待ち受けIPアドレスです。</p><ul><li><p>kube-proxyがIPTABLESモードで稼働中のとき:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>sed -i <span style=color:#b44>&#34;s/__PILLAR__LOCAL__DNS__/</span><span style=color:#b8860b>$localdns</span><span style=color:#b44>/g; s/__PILLAR__DNS__DOMAIN__/</span><span style=color:#b8860b>$domain</span><span style=color:#b44>/g; s/__PILLAR__DNS__SERVER__/</span><span style=color:#b8860b>$kubedns</span><span style=color:#b44>/g&#34;</span> nodelocaldns.yaml
</span></span></code></pre></div><p><code>__PILLAR__CLUSTER__DNS__</code>と<code>__PILLAR__UPSTREAM__SERVERS__</code>はnode-local-dnsというPodによって生成されます。
このモードでは、node-local-dns Podは<code>&lt;node-local-address></code>とkube-dnsのサービスIPの両方で待ち受けるため、PodはIPアドレスでもDNSレコードのルップアップができます。</p></li><li><p>kube-proxyがIPVSモードで稼働中のとき:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span> sed -i <span style=color:#b44>&#34;s/__PILLAR__LOCAL__DNS__/</span><span style=color:#b8860b>$localdns</span><span style=color:#b44>/g; s/__PILLAR__DNS__DOMAIN__/</span><span style=color:#b8860b>$domain</span><span style=color:#b44>/g; s/__PILLAR__DNS__SERVER__//g; s/__PILLAR__CLUSTER__DNS__/</span><span style=color:#b8860b>$kubedns</span><span style=color:#b44>/g&#34;</span> nodelocaldns.yaml
</span></span></code></pre></div><p>このモードでは、node-local-dns Podは<code>&lt;node-local-address></code>上のみで待ち受けます。node-local-dnsのインターフェースはkube-dnsのクラスターIPをバインドしません。なぜならばIPVSロードバランシング用に使われているインターフェースは既にこのアドレスを使用しているためです。
<code>__PILLAR__UPSTREAM__SERVERS__</code> はnode-local-dns Podにより生成されます。</p></li></ul></li><li><p><code>kubectl create -f nodelocaldns.yaml</code>を実行してください。</p></li><li><p>kube-proxyをIPVSモードで使用しているとき、NodeLocal DNSキャッシュが待ち受けている<code>&lt;node-local-address></code>を使用するため、kubeletに対する<code>--cluster-dns</code>フラグを修正する必要があります。IPVSモード以外のとき、<code>--cluster-dns</code>フラグの値を修正する必要はありません。なぜならNodeLocal DNSキャッシュはkube-dnsのサービスIPと<code>&lt;node-local-address></code>の両方で待ち受けているためです。</p></li></ul><p>一度有効にすると、クラスターの各Node上で、kube-systemという名前空間でnode-local-dns Podが、稼働します。このPodは<a href=https://github.com/coredns/coredns>CoreDNS</a>をキャッシュモードで稼働させるため、異なるプラグインによって公開された全てのCoreDNSのメトリクスがNode単位で利用可能となります。</p><p><code>kubectl delete -f &lt;manifest></code>を実行してDaemonSetを削除することによって、この機能を無効にできます。また、kubeletの設定に対して行った全ての変更をリバートすべきです。</p></div><div class=td-content style=page-break-before:always><h1 id=pg-00733cc3747eb3f5fe1c9e0439262967>7 - Serviceトポロジーを有効にする</h1><p>このページでは、Kubernetes上でServiceトポロジーを有効にする方法の概要について説明します。</p><h2 id=始める前に>始める前に</h2><p><p>Kubernetesクラスターが必要、かつそのクラスターと通信するためにkubectlコマンドラインツールが設定されている必要があります。
このチュートリアルは、コントロールプレーンのホストとして動作していない少なくとも2つのノードを持つクラスターで実行することをおすすめします。
まだクラスターがない場合、<a href=https://minikube.sigs.k8s.io/docs/tutorials/multi_node/>minikube</a>を使って作成するか、
以下のいずれかのKubernetesプレイグラウンドも使用できます:</p><ul><li><a href=https://killercoda.com/playgrounds/scenario/kubernetes>Killercoda</a></li><li><a href=http://labs.play-with-k8s.com/>Play with Kubernetes</a></li></ul>バージョンを確認するには次のコマンドを実行してください: <code>kubectl version</code>.</p><h2 id=はじめに>はじめに</h2><p><em>Serviceトポロジー</em>は、クラスターのノードのトポロジーに基づいてトラフィックをルーティングできるようにする機能です。たとえば、あるServiceのトラフィックに対して、できるだけ同じノードや同じアベイラビリティゾーン上にあるエンドポイントを優先してルーティングするように指定できます。</p><h2 id=前提>前提</h2><p>トポロジーを考慮したServiceのルーティングを有効にするには、以下の前提を満たしている必要があります。</p><ul><li>Kubernetesバージョン1.17以降である</li><li><a class=glossary-tooltip title=kube-proxyはクラスター内の各Nodeで動作しているネットワークプロキシです。 data-toggle=tooltip data-placement=top href=/docs/reference/command-line-tools-reference/kube-proxy/ target=_blank aria-label=Kube-proxy>Kube-proxy</a>がiptableモードまたはIPVSモードで稼働している</li><li><a href=/docs/concepts/services-networking/endpoint-slices/>Endpoint Slice</a>を有効にしている</li></ul><h2 id=serviceトポロジーを有効にする>Serviceトポロジーを有効にする</h2><div style=margin-top:10px;margin-bottom:10px><b>FEATURE STATE:</b> <code>Kubernetes v1.17 [alpha]</code></div><p>Serviceトポロジーを有効にするには、すべてのKubernetesコンポーネントで<code>ServiceTopology</code>と<code>EndpointSlice</code>フィーチャーゲートを有効にする必要があります。</p><pre tabindex=0><code>--feature-gates=&#34;ServiceTopology=true,EndpointSlice=true&#34;
</code></pre><h2 id=次の項目>次の項目</h2><ul><li><a href=/ja/docs/concepts/services-networking/service-topology>Serviceトポロジー</a>のコンセプトについて読む</li><li><a href=/docs/concepts/services-networking/endpoint-slices>Endpoint Slice</a>について読む</li><li><a href=/ja/docs/concepts/services-networking/connect-applications-service/>サービスとアプリケーションの接続</a>を読む</li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-e1afcdac8d5e8458274b3c481c5ebcda>8 - サービスディスカバリーにCoreDNSを使用する</h1><p>このページでは、CoreDNSのアップグレードプロセスと、kube-dnsの代わりにCoreDNSをインストールする方法を説明します。</p><h2 id=始める前に>始める前に</h2><p><p>Kubernetesクラスターが必要、かつそのクラスターと通信するためにkubectlコマンドラインツールが設定されている必要があります。
このチュートリアルは、コントロールプレーンのホストとして動作していない少なくとも2つのノードを持つクラスターで実行することをおすすめします。
まだクラスターがない場合、<a href=https://minikube.sigs.k8s.io/docs/tutorials/multi_node/>minikube</a>を使って作成するか、
以下のいずれかのKubernetesプレイグラウンドも使用できます:</p><ul><li><a href=https://killercoda.com/playgrounds/scenario/kubernetes>Killercoda</a></li><li><a href=http://labs.play-with-k8s.com/>Play with Kubernetes</a></li></ul>作業するKubernetesサーバーは次のバージョン以降のものである必要があります: v1.9.
バージョンを確認するには次のコマンドを実行してください: <code>kubectl version</code>.</p><h2 id=about-coredns>CoreDNSについて</h2><p><a href=https://coredns.io>CoreDNS</a>は、KubernetesクラスターDNSとして稼働させることができる柔軟で拡張可能なDNSサーバーです。Kubernetesと同様に、CoreDNSプロジェクトは<a class=glossary-tooltip title='Cloud Native Computing Foundation' data-toggle=tooltip data-placement=top href=https://cncf.io/ target=_blank aria-label=CNCF>CNCF</a>によってホストされています。</p><p>既存のデプロイでkube-dnsを置き換えるか、クラスターのデプロイとアップグレードを代行してくれるkubeadmのようなツールを使用することで、クラスターでkube-dnsの代わりにCoreDNSを使用することができます。</p><h2 id=installing-coredns>CoreDNSのインストール</h2><p>kube-dnsの手動デプロイや置き換えについては、<a href=https://github.com/coredns/deployment/tree/master/kubernetes>CoreDNS GitHub project</a>のドキュメントを参照してください。</p><h2 id=migrating-to-coredns>CoreDNSへの移行</h2><h3 id=upgrading-an-existing-cluster-with-kubeadm>kubeadmを使用した既存のクラスターのアップグレード</h3><p>Kubernetesバージョン1.10以降では、<code>kube-dns</code>を使用しているクラスターを<code>kubeadm</code>を使用してアップグレードするときに、CoreDNSに移行することもできます。この場合、<code>kubeadm</code>は、<code>kube-dns</code> ConfigMapをベースにしてCoreDNS設定("Corefile")を生成し、フェデレーション、スタブドメイン、および上流のネームサーバーの設定を保持します。</p><p>kube-dnsからCoreDNSに移行する場合は、アップグレード時に必ず<code>CoreDNS</code>フィーチャーゲートを<code>true</code>に設定してください。たとえば、<code>v1.11.0</code>のアップグレードは次のようになります:</p><pre tabindex=0><code>kubeadm upgrade apply v1.11.0 --feature-gates=CoreDNS=true
</code></pre><p>Kubernetesバージョン1.13以降では、<code>CoreDNS</code>フィーチャーゲートが削除され、CoreDNSがデフォルトで使用されます。アップグレードしたクラスターでkube-dnsを使用する場合は、<a href=/docs/reference/setup-tools/kubeadm/kubeadm-init-phase#cmd-phase-addon>こちら</a>のガイドに従ってください。</p><p>1.11以前のバージョンでは、Corefileはアップグレード中に作成されたものによって<strong>上書き</strong>されます。<strong>カスタマイズしている場合は、既存のConfigMapを保存する必要があります。</strong> 新しいConfigMapが稼働したら、カスタマイズを再適用できます。</p><p>Kubernetesバージョン1.11以降でCoreDNSを実行している場合、アップグレード中、既存のCorefileは保持されます。</p><h3 id=installing-kube-dns-instead-of-coredns-with-kubeadm>kubeadmを使用してCoreDNSの代わりにkube-dnsをインストールする</h3><div class="alert alert-info note callout" role=alert><strong>備考:</strong> Kubernetes 1.11では、CoreDNSは一般利用可能(GA)にアップグレードされ、デフォルトでインストールされます。</div><div class="alert alert-danger warning callout" role=alert><strong>警告:</strong> Kubernetes 1.18では、kubeadmでのkube-dns使用は非推奨となり、将来のバージョンでは削除されます。</div><p>1.13以前のバージョンにkube-dnsをインストールするには、<code>CoreDNS</code>フィーチャーゲートの値を<code>false</code>に設定します:</p><pre tabindex=0><code>kubeadm init --feature-gates=CoreDNS=false
</code></pre><p>バージョン1.13以降の場合は、<a href=/docs/reference/setup-tools/kubeadm/kubeadm-init-phase#cmd-phase-addon>こちら</a>に記載されているガイドに従ってください。</p><h2 id=upgrading-coredns>CoreDNSのアップグレード</h2><p>CoreDNSはv1.9以降のKubernetesで使用できます。Kubernetesに同梱されているCoreDNSのバージョンと、CoreDNSに加えられた変更は<a href=https://github.com/coredns/deployment/blob/master/kubernetes/CoreDNS-k8s_version.md>こちら</a>で確認できます。</p><p>CoreDNSだけをアップグレードしたい場合や、独自のカスタムイメージを使用したい場合は、CoreDNSを手動でアップグレードすることができます。スムーズなアップグレードのために役立つ<a href=https://github.com/coredns/deployment/blob/master/kubernetes/Upgrading_CoreDNS.md>ガイドラインとウォークスルー</a>が用意されています。</p><h2 id=tuning-coredns>CoreDNSのチューニング</h2><p>リソース使用率が問題になる場合は、CoreDNSの設定を調整すると役立つ場合があります。詳細は、<a href=https://github.com/coredns/deployment/blob/master/kubernetes/Scaling_CoreDNS.md>CoreDNSのスケーリングに関するドキュメント</a>を参照してください。</p><h2 id=次の項目>次の項目</h2><p><a href=https://coredns.io>CoreDNS</a>は、<code>Corefile</code>を変更することで、kube-dnsよりも多くのユースケースをサポートするように設定することができます。詳細は<a href=https://coredns.io/2017/05/08/custom-dns-entries-for-kubernetes/>CoreDNSサイト</a>を参照してください。</p></div><div class=td-content style=page-break-before:always><h1 id=pg-8060aed5bf1172fa62199a4c306a4cd1>9 - ノードのトポロジー管理ポリシーを制御する</h1><div style=margin-top:10px;margin-bottom:10px><b>FEATURE STATE:</b> <code>Kubernetes v1.18 [beta]</code></div><p>近年、CPUやハードウェア・アクセラレーターの組み合わせによって、レイテンシーが致命的となる実行や高いスループットを求められる並列計算をサポートするシステムが増えています。このようなシステムには、通信、科学技術計算、機械学習、金融サービス、データ分析などの分野のワークロードが含まれます。このようなハイブリッドシステムは、高い性能の環境で構成されます。</p><p>最高のパフォーマンスを引き出すために、CPUの分離やメモリーおよびデバイスの位置に関する最適化が求められます。しかしながら、Kubernetesでは、これらの最適化は分断されたコンポーネントによって処理されます。</p><p><em>トポロジーマネージャー</em> はKubeletコンポーネントの1つで最適化の役割を担い、コンポーネント群を調和して機能させます。</p><h2 id=始める前に>始める前に</h2><p><p>Kubernetesクラスターが必要、かつそのクラスターと通信するためにkubectlコマンドラインツールが設定されている必要があります。
このチュートリアルは、コントロールプレーンのホストとして動作していない少なくとも2つのノードを持つクラスターで実行することをおすすめします。
まだクラスターがない場合、<a href=https://minikube.sigs.k8s.io/docs/tutorials/multi_node/>minikube</a>を使って作成するか、
以下のいずれかのKubernetesプレイグラウンドも使用できます:</p><ul><li><a href=https://killercoda.com/playgrounds/scenario/kubernetes>Killercoda</a></li><li><a href=http://labs.play-with-k8s.com/>Play with Kubernetes</a></li></ul>作業するKubernetesサーバーは次のバージョン以降のものである必要があります: v1.18.
バージョンを確認するには次のコマンドを実行してください: <code>kubectl version</code>.</p><h2 id=トポロジーマネージャーはどのように機能するか>トポロジーマネージャーはどのように機能するか</h2><p>トポロジーマネージャー導入前は、KubernetesにおいてCPUマネージャーやデバイスマネージャーはそれぞれ独立してリソースの割り当てを決定します。
これは、マルチソケットのシステムでは望ましくない割り当てとなり、パフォーマンスやレイテンシーが求められるアプリケーションは、この望ましくない割り当てに悩まされます。
この場合の望ましくない例として、CPUやデバイスが異なるNUMAノードに割り当てられ、それによりレイテンシー悪化を招くことが挙げられます。</p><p>トポロジーマネージャーはKubeletコンポーネントであり、信頼できる情報源として振舞います。それによって、他のKubeletコンポーネントはトポロジーに沿ったリソース割り当ての選択を行うことができます。</p><p>トポロジーマネージャーは <em>Hint Providers</em> と呼ばれるコンポーネントのインターフェースを提供し、トポロジー情報を送受信します。トポロジーマネージャーは、ノード単位のポリシー群を保持します。ポリシーについて以下で説明します。</p><p>トポロジーマネージャーは <em>Hint Providers</em> からトポロジー情報を受け取ります。トポロジー情報は、利用可能なNUMAノードと優先割り当て表示を示すビットマスクです。トポロジーマネージャーのポリシーは、提供されたヒントに対して一連の操作を行い、ポリシーに沿ってヒントをまとめて最適な結果を得ます。もし、望ましくないヒントが保存された場合、ヒントの優先フィールドがfalseに設定されます。現在のポリシーでは、最も狭い優先マスクが優先されます。</p><p>選択されたヒントはトポロジーマネージャーの一部として保存されます。設定されたポリシーにしたがい、選択されたヒントに基づいてノードがPodを許可したり、拒否することができます。
トポロジーマネージャーに保存されたヒントは、<em>Hint Providers</em> が使用しリソース割り当てを決定します。</p><h3 id=トポロジーマネージャーの機能を有効にする>トポロジーマネージャーの機能を有効にする</h3><p>トポロジーマネージャーをサポートするには、<code>TopologyManager</code> <a href=/ja/docs/reference/command-line-tools-reference/feature-gates/>フィーチャーゲート</a>を有効にする必要があります。Kubernetes 1.18ではデフォルトで有効です。</p><h2 id=トポロジーマネージャーのスコープとポリシー>トポロジーマネージャーのスコープとポリシー</h2><p>トポロジーマネージャは現在:</p><ul><li>全てのQoAクラスのPodを調整する</li><li>Hint Providerによって提供されたトポロジーヒントから、要求されたリソースを調整する</li></ul><p>これらの条件が合致した場合、トポロジーマネージャーは要求されたリソースを調整します。</p><p>この調整をどのように実行するかカスタマイズするために、トポロジーマネージャーは2つのノブを提供します: <code>スコープ</code> と<code>ポリシー</code>です。</p><p><code>スコープ</code>はリソースの配置を行う粒度を定義します(例:<code>pod</code>や<code>container</code>)。そして、<code>ポリシー</code>は調整を実行するための実戦略を定義します(<code>best-effort</code>, <code>restricted</code>, <code>single-numa-node</code>等)。</p><p>現在利用可能な<code>スコープ</code>と<code>ポリシー</code>の値について詳細は以下の通りです。</p><div class="alert alert-info note callout" role=alert><strong>備考:</strong> PodのSpecにある他の要求リソースとCPUリソースを調整するために、CPUマネージャーを有効にし、適切なCPUマネージャーのポリシーがノードに設定されるべきです。<a href=/docs/tasks/administer-cluster/cpu-management-policies/>CPU管理ポリシー</a>を参照してください。</div><div class="alert alert-info note callout" role=alert><strong>備考:</strong> PodのSpecにある他の要求リソースとメモリー（およびhugepage）リソースを調整するために、メモリーマネージャーを有効にし、適切なメモリーマネージャーポリシーがノードに設定されるべきです。<a href=/docs/tasks/administer-cluster/memory-manager/>メモリーマネージャー</a> のドキュメントを確認してください。</div><h3 id=トポロジーマネージャーのスコープ>トポロジーマネージャーのスコープ</h3><p>トポロジーマネージャーは、以下の複数の異なるスコープでリソースの調整を行う事が可能です:</p><ul><li><code>container</code> (デフォルト)</li><li><code>pod</code></li></ul><p>いずれのオプションも、<code>--topology-manager-scope</code>フラグによって、kubelet起動時に選択できます。</p><h3 id=containerスコープ>containerスコープ</h3><p><code>container</code>スコープはデフォルトで使用されます。</p><p>このスコープでは、トポロジーマネージャーは連続した複数のリソース調整を実行します。つまり、Pod内の各コンテナは、分離された配置計算がされます。言い換えると、このスコープでは、コンテナを特定のNUMAノードのセットにグループ化するという概念はありません。実際には、トポロジーマネージャーは各コンテナのNUMAノードへの配置を任意に実行します。</p><p>コンテナをグループ化するという概念は、以下のスコープで設定・実行されます。例えば、<code>pod</code>スコープが挙げられます。</p><h3 id=podスコープ>podスコープ</h3><p><code>pod</code>スコープを選択するには、コマンドラインで<code>--topology-manager-scope=pod</code>オプションを指定してkubeletを起動します。</p><p>このスコープでは、Pod内全てのコンテナを共通のNUMAノードのセットにグループ化することができます。トポロジーマネージャーはPodをまとめて1つとして扱い、ポッド全体（全てのコンテナ）を単一のNUMAノードまたはNUMAノードの共通セットのいずれかに割り当てようとします。以下の例は、さまざまな場面でトポロジーマネージャーが実行する調整を示します:</p><ul><li>全てのコンテナは、単一のNUMAノードに割り当てられます。</li><li>全てのコンテナは、共有されたNUMAノードのセットに割り当てられます。</li></ul><p>Pod全体に要求される特定のリソースの総量は<a href=/ja/docs/concepts/workloads/pods/init-containers/#resources>有効なリクエスト／リミット</a>の式に従って計算されるため、この総量の値は以下の最大値となります。</p><ul><li>全てのアプリケーションコンテナのリクエストの合計。</li><li>リソースに対するinitコンテナのリクエストの最大値。</li></ul><p><code>pod</code>スコープと<code>single-numa-node</code>トポロジーマネージャーポリシーを併用することは、レイテンシーが重要なワークロードやIPCを行う高スループットのアプリケーションに対して特に有効です。両方のオプションを組み合わせることで、Pod内の全てのコンテナを単一のNUMAノードに配置できます。そのため、PodのNUMA間通信によるオーバーヘッドを排除することができます。</p><p><code>single-numa-node</code>ポリシーの場合、可能な割り当ての中に適切なNUMAノードのセットが存在する場合にのみ、Podが許可されます。上の例をもう一度考えてみましょう:</p><ul><li>1つのNUMAノードのみを含むセット - Podが許可されます。</li><li>2つ以上のNUMAノードを含むセット - Podが拒否されます(1つのNUMAノードの代わりに、割り当てを満たすために2つ以上のNUMAノードが必要となるため)。</li></ul><p>要約すると、トポロジーマネージャーはまずNUMAノードのセットを計算し、それをトポロジーマネージャーのポリシーと照合し、Podの拒否または許可を検証します。</p><h3 id=トポロジーマネージャーのポリシー>トポロジーマネージャーのポリシー</h3><p>トポロジーマネージャーは4つの調整ポリシーをサポートします。<code>--topology-manager-policy</code>というKubeletフラグを通してポリシーを設定できます。
4つのサポートされるポリシーがあります:</p><ul><li><code>none</code> (デフォルト)</li><li><code>best-effort</code></li><li><code>restricted</code></li><li><code>single-numa-node</code></li></ul><div class="alert alert-info note callout" role=alert><strong>備考:</strong> トポロジーマネージャーが <strong>pod</strong> スコープで設定された場合、コンテナはポリシーによって、Pod全体の要求として反映します。
したがって、Podの各コンテナは <strong>同じ</strong> トポロジー調整と同じ結果となります。</div><h3 id=policy-none>none ポリシー</h3><p>これはデフォルトのポリシーで、トポロジーの調整を実行しません。</p><h3 id=policy-best-effort>best-effort ポリシー</h3><p>Pod内の各コンテナに対して、<code>best-effort</code> トポロジー管理ポリシーが設定されたkubeletは、各Hint Providerを呼び出してそれらのリソースの可用性を検出します。
トポロジーマネージャーはこの情報を使用し、そのコンテナの推奨されるNUMAノードのアフィニティーを保存します。アフィニティーが優先されない場合、トポロジーマネージャーはこれを保存し、Podをノードに許可します。</p><p><em>Hint Providers</em> はこの情報を使ってリソースの割り当てを決定します。</p><h3 id=policy-restricted>restricted ポリシー</h3><p>Pod内の各コンテナに対して、<code>restricted</code> トポロジー管理ポリシーが設定されたkubeletは各Hint Providerを呼び出してそれらのリソースの可用性を検出します。
トポロジーマネージャーはこの情報を使用し、そのコンテナの推奨されるNUMAノードのアフィニティーを保存します。アフィニティーが優先されない場合、トポロジーマネージャーはPodをそのノードに割り当てることを拒否します。この結果、PodはPodの受付失敗となり<code>Terminated</code> 状態になります。</p><p>Podが一度<code>Terminated</code>状態になると、KubernetesスケジューラーはPodの再スケジューリングを試み <strong>ません</strong> 。Podの再デプロイをするためには、ReplicasetかDeploymenを使用してください。<code>Topology Affinity</code>エラーとなったpodを再デプロイするために、外部のコントロールループを実行することも可能です。</p><p>Podが許可されれば、 <em>Hint Providers</em> はこの情報を使ってリソースの割り当てを決定します。</p><h3 id=policy-single-numa-node>single-numa-node ポリシー</h3><p>Pod内の各コンテナに対して、<code>single-numa-node</code>トポロジー管理ポリシーが設定されたkubeletは各Hint Prociderを呼び出してそれらのリソースの可用性を検出します。
トポロジーマネージャーはこの情報を使用し、単一のNUMAノードアフィニティが可能かどうか決定します。
可能な場合、トポロジーマネージャーは、この情報を保存し、<em>Hint Providers</em> はこの情報を使ってリソースの割り当てを決定します。
不可能な場合、トポロジーマネージャーは、Podをそのノードに割り当てることを拒否します。この結果、Pod は Pod の受付失敗となり<code>Terminated</code>状態になります。</p><p>Podが一度<code>Terminated</code>状態になると、KubernetesスケジューラーはPodの再スケジューリングを試み<strong>ません</strong>。Podの再デプロイをするためには、ReplicasetかDeploymentを使用してください。<code>Topology Affinity</code>エラーとなったpodを再デプロイするために、外部のコントロールループを実行することも可能です。</p><h3 id=podとトポロジー管理ポリシーの関係>Podとトポロジー管理ポリシーの関係</h3><p>以下のようなpodのSpecで定義されるコンテナを考えます:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>nginx<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>nginx<span style=color:#bbb>
</span></span></span></code></pre></div><p><code>requests</code>も<code>limits</code>も定義されていないため、このPodは<code>BestEffort</code>QoSクラスで実行します。</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>nginx<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>nginx<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>resources</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>limits</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>memory</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;200Mi&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>requests</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>memory</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;100Mi&#34;</span><span style=color:#bbb>
</span></span></span></code></pre></div><p>requestsがlimitsより小さい値のため、このPodは<code>Burstable</code>QoSクラスで実行します。</p><p>選択されたポリシーが<code>none</code>以外の場合、トポロジーマネージャーは、これらのPodのSpecを考慮します。トポロジーマネージャーは、Hint Providersからトポロジーヒントを取得します。CPUマネージャーポリシーが<code>static</code>の場合、デフォルトのトポロジーヒントを返却します。これらのPodは明示的にCPUリソースを要求していないからです。</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>nginx<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>nginx<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>resources</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>limits</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>memory</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;200Mi&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>cpu</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;2&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>example.com/device</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;1&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>requests</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>memory</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;200Mi&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>cpu</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;2&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>example.com/device</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;1&#34;</span><span style=color:#bbb>
</span></span></span></code></pre></div><p>整数値でCPUリクエストを指定されたこのPodは、<code>requests</code>が<code>limits</code>が同じ値のため、<code>Guaranteed</code>QoSクラスで実行します。</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>nginx<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>nginx<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>resources</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>limits</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>memory</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;200Mi&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>cpu</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;300m&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>example.com/device</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;1&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>requests</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>memory</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;200Mi&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>cpu</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;300m&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>example.com/device</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;1&#34;</span><span style=color:#bbb>
</span></span></span></code></pre></div><p>CPUの一部をリクエストで指定されたこのPodは、<code>requests</code>が<code>limits</code>が同じ値のため、<code>Guaranteed</code>QoSクラスで実行します。</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>nginx<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>nginx<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>resources</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>limits</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>example.com/deviceA</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;1&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>example.com/deviceB</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;1&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>requests</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>example.com/deviceA</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;1&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>example.com/deviceB</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;1&#34;</span><span style=color:#bbb>
</span></span></span></code></pre></div><p>CPUもメモリもリクエスト値がないため、このPodは <code>BestEffort</code> QoSクラスで実行します。</p><p>トポロジーマネージャーは、上記Podを考慮します。トポロジーマネージャーは、Hint ProvidersとなるCPUマネージャーとデバイスマネージャーに問い合わせ、トポロジーヒントを取得します。</p><p>整数値でCPU要求を指定された<code>Guaranteed</code>QoSクラスのPodの場合、<code>static</code>が設定されたCPUマネージャーポリシーは、排他的なCPUに関するトポロジーヒントを返却し、デバイスマネージャーは要求されたデバイスのヒントを返します。</p><p>CPUの一部を要求を指定された<code>Guaranteed</code>QoSクラスのPodの場合、排他的ではないCPU要求のため<code>static</code>が設定されたCPUマネージャーポリシーはデフォルトのトポロジーヒントを返却します。デバイスマネージャーは要求されたデバイスのヒントを返します。</p><p>上記の<code>Guaranteed</code>QoSクラスのPodに関する2ケースでは、<code>none</code>で設定されたCPUマネージャーポリシーは、デフォルトのトポロジーヒントを返却します。</p><p><code>BestEffort</code>QoSクラスのPodの場合、<code>static</code>が設定されたCPUマネージャーポリシーは、CPUの要求がないためデフォルトのトポロジーヒントを返却します。デバイスマネージャーは要求されたデバイスごとのヒントを返します。</p><p>トポロジーマネージャーはこの情報を使用してPodに最適なヒントを計算し保存します。保存されたヒントは Hint Providersが使用しリソースを割り当てます。</p><h3 id=既知の制限>既知の制限</h3><ol><li><p>トポロジーマネージャーが許容するNUMAノードの最大値は8です。8より多いNUMAノードでは、可能なNUMAアフィニティを列挙しヒントを生成する際に、生成する状態数が爆発的に増加します。</p></li><li><p>スケジューラーはトポロジーを意識しません。そのため、ノードにスケジュールされた後に実行に失敗する可能性があります。</p></li></ol></div><div class=td-content style=page-break-before:always><h1 id=pg-ce4cd28c8feb9faa783e79b48af37961>10 - クラウドコントローラーマネージャーの運用管理</h1><div style=margin-top:10px;margin-bottom:10px><b>FEATURE STATE:</b> <code>Kubernetes v1.11 [beta]</code></div><p>クラウドプロバイダーはKubernetesプロジェクトとは異なるペースで開発およびリリースされるため、プロバイダー固有のコードを<a class=glossary-tooltip title=サードパーティクラウドプロバイダーにKubernetesを結合するコントロールプレーンコンポーネント data-toggle=tooltip data-placement=top href=/ja/docs/concepts/architecture/cloud-controller/ target=_blank aria-label='`cloud-controller-manager`'>`cloud-controller-manager`</a>バイナリに抽象化することでクラウドベンダーはKubernetesのコアのコードとは独立して開発が可能となりました。</p><p><code>cloud-controller-manager</code>は、<a href=https://github.com/kubernetes/cloud-provider/blob/master/cloud.go>cloudprovider.Interface</a>を満たす任意のクラウドプロバイダーと接続できます。下位互換性のためにKubernetesのコアプロジェクトで提供される<a href=https://github.com/kubernetes/kubernetes/tree/master/cmd/cloud-controller-manager>cloud-controller-manager</a>は<code>kube-controller-manager</code>と同じクラウドライブラリを使用します。Kubernetesのコアリポジトリですでにサポートされているクラウドプロバイダーは、Kubernetesリポジトリにあるcloud-controller-managerを使用してKubernetesのコアから移行することが期待されています。</p><h2 id=運用>運用</h2><h3 id=要件>要件</h3><p>すべてのクラウドには動作させるためにそれぞれのクラウドプロバイダーの統合を行う独自の要件があり、<code>kube-controller-manager</code>を実行する場合の要件とそれほど違わないようにする必要があります。一般的な経験則として、以下のものが必要です。</p><ul><li>クラウドの認証/認可: クラウドではAPIへのアクセスを許可するためにトークンまたはIAMルールが必要になる場合があります</li><li>kubernetesの認証/認可: cloud-controller-managerは、kubernetes apiserverと通信するためにRBACルールの設定を必要とする場合があります</li><li>高可用性: kube-controller-managerのように、リーダー選出を使用したクラウドコントローラーマネージャーの高可用性のセットアップが必要になる場合があります(デフォルトでオンになっています)。</li></ul><h3 id=cloud-controller-managerを動かす>cloud-controller-managerを動かす</h3><p>cloud-controller-managerを正常に実行するにはクラスター構成にいくつかの変更が必要です。</p><ul><li><code>kube-apiserver</code>と<code>kube-controller-manager</code>は**<code>--cloud-provider</code>フラグを指定してはいけません**。これによりクラウドコントローラーマネージャーによって実行されるクラウド固有のループが実行されなくなります。将来このフラグは非推奨になり削除される予定です。</li><li><code>kubelet</code>は<code>--cloud-provider=external</code>で実行する必要があります。これは作業をスケジュールする前にクラウドコントローラーマネージャーによって初期化する必要があることをkubeletが認識できるようにするためです。</li></ul><p>クラウドコントローラーマネージャーを使用するようにクラスターを設定するとクラスターの動作がいくつか変わることに注意してください。</p><ul><li><code>--cloud-provider=external</code>を指定したkubeletは、初期化時に<code>NoSchedule</code>の<code>node.cloudprovider.kubernetes.io/uninitialized</code>汚染を追加します。これによりノードは作業をスケジュールする前に外部のコントローラーからの2回目の初期化が必要であるとマークされます。クラウドコントローラーマネージャーが使用できない場合クラスター内の新しいノードはスケジュールできないままになることに注意してください。スケジューラーはリージョンやタイプ(高CPU、GPU、高メモリ、スポットインスタンスなど)などのノードに関するクラウド固有の情報を必要とする場合があるためこの汚染は重要です。</li><li>クラスター内のノードに関するクラウド情報はローカルメタデータを使用して取得されなくなりましたが、代わりにノード情報を取得するためのすべてのAPI呼び出しはクラウドコントローラーマネージャーを経由して行われるようになります。これはセキュリティを向上させるためにkubeletでクラウドAPIへのアクセスを制限できることを意味します。大規模なクラスターではクラスター内からクラウドのほとんどすべてのAPI呼び出しを行うため、クラウドコントローラーマネージャーがレートリミットに達するかどうかを検討する必要があります。</li></ul><p>クラウドコントローラーマネージャーは以下を実装できます。</p><ul><li>ノードコントローラー - クラウドAPIを使用してkubernetesノードを更新し、クラウドで削除されたkubernetesノードを削除します。</li><li>サービスコントローラー - タイプLoadBalancerのサービスに対応してクラウド上のロードバランサーを操作します。</li><li>ルートコントローラー - クラウド上でネットワークルートを設定します。</li><li>Kubernetesリポジトリの外部にあるプロバイダーを実行している場合はその他の機能の実装。</li></ul><h2 id=例>例</h2><p>現在Kubernetesのコアでサポートされているクラウドを使用していて、クラウドコントローラーマネージャーを利用する場合は、<a href=https://github.com/kubernetes/kubernetes/tree/master/cmd/cloud-controller-manager>kubernetesのコアのクラウドコントローラーマネージャー</a>を参照してください。</p><p>Kubernetesのコアリポジトリにないクラウドコントローラーマネージャーの場合、クラウドベンダーまたはsigリードが管理するリポジトリでプロジェクトを見つけることができます。</p><p>すでにKubernetesのコアリポジトリにあるプロバイダーの場合、クラスター内でデーモンセットとしてKubernetesリポジトリ内部のクラウドコントローラーマネージャーを実行できます。以下をガイドラインとして使用してください。</p><div class=highlight><div class=copy-code-icon style=text-align:right><a href=https://raw.githubusercontent.com/kubernetes/website/main/content/ja/examples/admin/cloud/ccm-example.yaml download=admin/cloud/ccm-example.yaml><code>admin/cloud/ccm-example.yaml</code></a>
<img src=/images/copycode.svg style=max-height:24px;cursor:pointer onclick='copyCode("admin-cloud-ccm-example-yaml")' title="Copy admin/cloud/ccm-example.yaml to clipboard"></img></div><div class=includecode id=admin-cloud-ccm-example-yaml><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#080;font-style:italic># This is an example of how to setup cloud-controller-manager as a Daemonset in your cluster.</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:#080;font-style:italic># It assumes that your masters can run pods and has the role node-role.kubernetes.io/master</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:#080;font-style:italic># Note that this Daemonset will not work straight out of the box for your cloud, this is</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:#080;font-style:italic># meant to be a guideline.</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:#00f;font-weight:700>---</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>ServiceAccount<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>cloud-controller-manager<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>namespace</span>:<span style=color:#bbb> </span>kube-system<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:#00f;font-weight:700>---</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>ClusterRoleBinding<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>rbac.authorization.k8s.io/v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>system:cloud-controller-manager<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>roleRef</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>apiGroup</span>:<span style=color:#bbb> </span>rbac.authorization.k8s.io<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>ClusterRole<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>cluster-admin<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>subjects</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span>- <span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>ServiceAccount<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>cloud-controller-manager<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>namespace</span>:<span style=color:#bbb> </span>kube-system<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:#00f;font-weight:700>---</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>apps/v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>DaemonSet<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>labels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>k8s-app</span>:<span style=color:#bbb> </span>cloud-controller-manager<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>cloud-controller-manager<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>namespace</span>:<span style=color:#bbb> </span>kube-system<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>selector</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>matchLabels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>k8s-app</span>:<span style=color:#bbb> </span>cloud-controller-manager<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>template</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>labels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>k8s-app</span>:<span style=color:#bbb> </span>cloud-controller-manager<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>serviceAccountName</span>:<span style=color:#bbb> </span>cloud-controller-manager<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>cloud-controller-manager<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:#080;font-style:italic># for in-tree providers we use k8s.gcr.io/cloud-controller-manager</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:#080;font-style:italic># this can be replaced with any other image for out-of-tree providers</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>k8s.gcr.io/cloud-controller-manager:v1.8.0<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>command</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span>- /usr/local/bin/cloud-controller-manager<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span>- --cloud-provider=&lt;YOUR_CLOUD_PROVIDER&gt;  <span style=color:#bbb> </span><span style=color:#080;font-style:italic># Add your own cloud provider here!</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span>- --leader-elect=true<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span>- --use-service-account-credentials<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:#080;font-style:italic># these flags will vary for every cloud provider</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span>- --allocate-node-cidrs=true<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span>- --configure-cloud-routes=true<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span>- --cluster-cidr=172.17.0.0/16<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>tolerations</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:#080;font-style:italic># this is required so CCM can bootstrap itself</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- <span style=color:green;font-weight:700>key</span>:<span style=color:#bbb> </span>node.cloudprovider.kubernetes.io/uninitialized<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>value</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;true&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>effect</span>:<span style=color:#bbb> </span>NoSchedule<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:#080;font-style:italic># this is to have the daemonset runnable on master nodes</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:#080;font-style:italic># the taint may vary depending on your cluster setup</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- <span style=color:green;font-weight:700>key</span>:<span style=color:#bbb> </span>node-role.kubernetes.io/master<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>effect</span>:<span style=color:#bbb> </span>NoSchedule<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:#080;font-style:italic># this is to restrict CCM to only run on master nodes</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:#080;font-style:italic># the node selector may vary depending on your cluster setup</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>nodeSelector</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>node-role.kubernetes.io/master</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;&#34;</span><span style=color:#bbb>
</span></span></span></code></pre></div></div></div><h2 id=制限>制限</h2><p>クラウドコントローラーマネージャーの実行にはいくつかの制限があります。これらの制限は今後のリリースで対処されますが、本番のワークロードにおいてはこれらの制限を認識することが重要です。</p><h3 id=ボリュームのサポート>ボリュームのサポート</h3><p>ボリュームの統合にはkubeletとの調整も必要になるためクラウドコントローラーマネージャーは<code>kube-controller-manager</code>にあるボリュームコントローラーを実装しません。CSI(コンテナストレージインターフェイス)が進化してFlexボリュームプラグインの強力なサポートが追加されるにつれ、クラウドがボリュームと完全に統合できるようクラウドコントローラーマネージャーに必要なサポートが追加されます。Kubernetesリポジトリの外部にあるCSIボリュームプラグインの詳細については<a href=https://github.com/kubernetes/features/issues/178>こちら</a>をご覧ください。</p><h3 id=スケーラビリティ>スケーラビリティ</h3><p>cloud-controller-managerは、クラウドプロバイダーのAPIにクエリーを送信して、すべてのノードの情報を取得します。非常に大きなクラスターの場合、リソース要件やAPIレートリミットなどのボトルネックの可能性を考慮する必要があります。</p><h3 id=鶏と卵>鶏と卵</h3><p>クラウドコントローラーマネージャープロジェクトの目標はKubernetesのコアプロジェクトからクラウドに関する機能の開発を切り離すことです。残念ながら、Kubernetesプロジェクトの多くの面でクラウドプロバイダーの機能がKubernetesプロジェクトに緊密に結びついているという前提があります。そのため、この新しいアーキテクチャを採用するとクラウドプロバイダーの情報を要求する状況が発生する可能性がありますが、クラウドコントローラーマネージャーはクラウドプロバイダーへのリクエストが完了するまでその情報を返すことができない場合があります。</p><p>これの良い例は、KubeletのTLSブートストラップ機能です。TLSブートストラップはKubeletがすべてのアドレスタイプ(プライベート、パブリックなど)をクラウドプロバイダー(またはローカルメタデータサービス)に要求する能力を持っていると仮定していますが、クラウドコントローラーマネージャーは最初に初期化されない限りノードのアドレスタイプを設定できないためapiserverと通信するためにはkubeletにTLS証明書が必要です。</p><p>このイニシアチブが成熟するに連れ、今後のリリースでこれらの問題に対処するための変更が行われます。</p><h2 id=次の項目>次の項目</h2><p>独自のクラウドコントローラーマネージャーを構築および開発するには<a href=/ja/docs/tasks/administer-cluster/developing-cloud-controller-manager/>クラウドコントローラーマネージャーの開発</a>を参照してください。</p></div><div class=td-content style=page-break-before:always><h1 id=pg-9585dc0efb0450fd68728e7511754717>11 - クラウドコントローラーマネージャーの開発</h1><p><p>cloud-controller-managerは クラウド特有の制御ロジックを組み込むKubernetesの<a class=glossary-tooltip title=コンテナのライフサイクルを定義、展開、管理するためのAPIとインターフェイスを公開するコンテナオーケストレーションレイヤーです。 data-toggle=tooltip data-placement=top href='/ja/docs/reference/glossary/?all=true#term-control-plane' target=_blank aria-label='control plane'>control plane</a>コンポーネントです。クラウドコントロールマネージャーは、クラスターをクラウドプロバイダーAPIをリンクし、クラスタのみで相互作用するコンポーネントからクラウドプラットフォームで相互作用するコンポーネントを分離します。</p></p><p>Kubernetesと下のクラウドインフラストラクチャー間の相互運用ロジックを分離することで、cloud-controller-managerコンポーネントはクラウドプロバイダを主なKubernetesプロジェクトと比較し異なるペースで機能をリリース可能にします。</p><h2 id=背景>背景</h2><p>クラウドプロバイダーはKubernetesプロジェクトとは異なる速度で開発しリリースすることから、プロバイダー特有なコードを<code>cloud-controller-manager</code>バイナリから抽象化することで、クラウドベンダーはコアKubernetesコードから独立して発展することができます。</p><p>Kubernetesプロジェクトは、(クラウドプロバイダーの)独自実装を組み込めるGoインターフェースを備えたcloud-controller-managerのスケルトンコードを提供しています。これは、クラウドプロバイダーがKubernetesコアからパッケージをインポートすることでcloud-controller-managerを実装できることを意味します。各クラウドプロバイダーは利用可能なクラウドプロバイダーのグローバル変数を更新するために<code>cloudprovider.RegisterCloudProvider</code>を呼び出し、独自のコードを登録します。</p><h2 id=開発>開発</h2><h3 id=kubernetesには登録されていない独自クラウドプロバイダー>Kubernetesには登録されていない独自クラウドプロバイダー</h3><p>Kubernetesには登録されていない独自のクラウドプロバイダーのクラウドコントローラーマネージャーを構築するには、</p><ol><li><a href=https://github.com/kubernetes/cloud-provider/blob/master/cloud.go>cloudprovider.Interface</a>を満たす go パッケージを実装します。</li><li>Kubernetesのコアにある<a href=https://github.com/kubernetes/kubernetes/blob/master/cmd/cloud-controller-manager/controller-manager.go>cloud-controller-managerの<code>main.go</code></a>をあなたの<code>main.go</code>のテンプレートとして利用します。上で述べたように、唯一の違いはインポートされるクラウドパッケージのみです。</li><li>クラウドパッケージを <code>main.go</code> にインポートし、パッケージに <a href=https://github.com/kubernetes/cloud-provider/blob/master/plugins.go><code>cloudprovider.RegisterCloudProvider</code></a> を実行するための <code>init</code> ブロックがあることを確認します。</li></ol><p>多くのクラウドプロバイダーはオープンソースとしてコントローラーマネージャーのコードを公開しています。新たにcloud-controller-managerをスクラッチから開発する際には、既存のKubernetesには登録されていない独自クラウドプロバイダーのコントローラーマネージャーを開始地点とすることができます。</p><h3 id=kubernetesに登録されているクラウドプロバイダー>Kubernetesに登録されているクラウドプロバイダー</h3><p>Kubernetesに登録されているクラウドプロバイダーであれば、<a class=glossary-tooltip title=Podのコピーがクラスター内の一連のNodeに渡って実行されることを保証します。 data-toggle=tooltip data-placement=top href=/docs/concepts/workloads/controllers/daemonset target=_blank aria-label=DaemonSet>DaemonSet</a>を使ってあなたのクラスターで動かすことができます。詳細については<a href=/ja/docs/tasks/administer-cluster/running-cloud-controller/>Kubernetesクラウドコントローラーマネージャー</a>を参照してください。</p></div><div class=td-content style=page-break-before:always><h1 id=pg-12001be83d15fcd7f3242313a55777df>12 - クラスターのセキュリティ</h1><p>このドキュメントでは、偶発的または悪意のあるアクセスからクラスターを保護するためのトピックについて説明します。
また、全体的なセキュリティに関する推奨事項を提供します。</p><h2 id=始める前に>始める前に</h2><ul><li><p>Kubernetesクラスターが必要、かつそのクラスターと通信するためにkubectlコマンドラインツールが設定されている必要があります。
このチュートリアルは、コントロールプレーンのホストとして動作していない少なくとも2つのノードを持つクラスターで実行することをおすすめします。
まだクラスターがない場合、<a href=https://minikube.sigs.k8s.io/docs/tutorials/multi_node/>minikube</a>を使って作成するか、
以下のいずれかのKubernetesプレイグラウンドも使用できます:</p><ul><li><a href=https://killercoda.com/playgrounds/scenario/kubernetes>Killercoda</a></li><li><a href=http://labs.play-with-k8s.com/>Play with Kubernetes</a></li></ul>バージョンを確認するには次のコマンドを実行してください: <code>kubectl version</code>.</li></ul><h2 id=kubernetes-apiへのアクセスの制御>Kubernetes APIへのアクセスの制御</h2><p>Kubernetesは完全にAPI駆動であるため、誰がクラスターにアクセスできるか、どのようなアクションを実行できるかを制御・制限することが第一の防御策となります。</p><h3 id=すべてのapiトラフィックにtls-transport-layer-security-を使用する>すべてのAPIトラフィックにTLS(Transport Layer Security)を使用する</h3><p>Kubernetesは、クラスター内のすべてのAPI通信がデフォルトでTLSにより暗号化されていることを期待しており、大半のインストール方法では、必要な証明書を作成してクラスターコンポーネントに配布することができます。</p><p>コンポーネントやインストール方法によっては、HTTP上のローカルポートを有効にする場合があることに注意してください。管理者は、潜在的に保護されていないトラフィックを特定するために、各コンポーネントの設定に精通している必要があります。</p><h3 id=apiの認証>APIの認証</h3><p>クラスターのインストール時に、共通のアクセスパターンに合わせて、APIサーバーが使用する認証メカニズムを選択します。
例えば、シングルユーザーの小規模なクラスターでは、シンプルな証明書や静的なBearerトークンを使用することができます。
大規模なクラスターでは、ユーザーをグループに細分化できる既存のOIDCまたはLDAPサーバーを統合することができます。</p><p>ノード、プロキシー、スケジューラー、ボリュームプラグインなど、インフラの一部であるものも含めて、すべてのAPIクライアントを認証する必要があります。
これらのクライアントは通常、<a href=/docs/reference/access-authn-authz/service-accounts-admin/>service accounts</a>であるか、またはx509クライアント証明書を使用しており、クラスター起動時に自動的に作成されるか、クラスターインストールの一部として設定されます。</p><p>詳細については、<a href=/ja/docs/reference/access-authn-authz/authentication/>認証</a>を参照してください。</p><h3 id=apiの認可>APIの認可</h3><p>認証されると、すべてのAPIコールは認可チェックを通過することになります。</p><p>Kubernetesには、統合された<a href=/ja/docs/reference/access-authn-authz/rbac/>RBAC</a>コンポーネントが搭載されており、入力されたユーザーやグループを、ロールにまとめられたパーミッションのセットにマッチさせます。
これらのパーミッションは、動詞(get, create, delete)とリソース(pods, services, nodes)を組み合わせたもので、ネームスペース・スコープまたはクラスター・スコープに対応しています。
すぐに使えるロールのセットが提供されており、クライアントが実行したいアクションに応じて、デフォルトで適切な責任の分離を提供します。</p><p><a href=/docs/reference/access-authn-authz/node/>Node</a>と<a href=/ja/docs/reference/access-authn-authz/rbac/>RBAC</a>の承認者は、<a href=/docs/reference/access-authn-authz/admission-controllers/#noderestriction>NodeRestriction</a>のアドミッションプラグインと組み合わせて使用することをお勧めします。</p><p>認証の場合と同様に、小規模なクラスターにはシンプルで幅広い役割が適切かもしれません。
しかし、より多くのユーザーがクラスターに関わるようになるとチームを別の名前空間に分け、より限定的な役割を持たせることが必要になるかもしれません。
認可においては、あるオブジェクトの更新が、他の場所でどのようなアクションを起こすかを理解することが重要です。</p><p>たとえば、ユーザーは直接Podを作成することはできませんが、ユーザーに代わってPodを作成するDeploymentの作成を許可することで、間接的にそれらのPodを作成することができます。
同様に、APIからノードを削除すると、そのノードにスケジューリングされていたPodが終了し、他のノードに再作成されます。
すぐに使えるロールは、柔軟性と一般的なユースケースのバランスを表していますが、より限定的なロールは、偶発的なエスカレーションを防ぐために慎重に検討する必要があります。
すぐに使えるロールがニーズを満たさない場合は、ユースケースに合わせてロールを作成することができます。</p><p>詳しくは<a href=/docs/reference/access-authn-authz/authorization/>authorization reference section</a>に参照してください。</p><h2 id=kubeletへのアクセスの制御>Kubeletへのアクセスの制御</h2><p>Kubeletsは、ノードやコンテナの強力な制御を可能にするHTTPSエンドポイントを公開しています。
デフォルトでは、KubeletsはこのAPIへの認証されていないアクセスを許可しています。</p><p>本番環境のクラスターでは、Kubeletの認証と認可を有効にする必要があります。</p><p>詳細は、<a href=/ja/docs/reference/command-line-tools-reference/kubelet-authentication-authorization>Kubelet 認証/認可</a>に参照してください。</p><h2 id=ワークロードやユーザーのキャパシティーを実行時に制御>ワークロードやユーザーのキャパシティーを実行時に制御</h2><p>Kubernetesにおける権限付与は、意図的にハイレベルであり、リソースに対する粗いアクションに焦点を当てています。</p><p>より強力なコントロールは<strong>policies</strong>として存在し、それらのオブジェクトがクラスタや自身、その他のリソースにどのように作用するかをユースケースによって制限します。</p><h3 id=クラスターのリソース使用量の制限>クラスターのリソース使用量の制限</h3><p><a href=/ja/docs/concepts/policy/resource-quotas/>リソースクォータ</a>は、ネームスペースに付与されるリソースの数や容量を制限するものです。</p><p>これは、ネームスペースが割り当てることのできるCPU、メモリー、永続的なディスクの量を制限するためによく使われますが、各ネームスペースに存在するPod、サービス、ボリュームの数を制御することもできます。</p><p><a href=/docs/tasks/administer-cluster/manage-resources/memory-default-namespace/>Limit ranges</a>は、上記のリソースの一部の最大または最小サイズを制限することで、ユーザーがメモリーなどの一般的に予約されたリソースに対して不当に高いまたは低い値を要求するのを防いだり、何も指定されていない場合にデフォルトの制限を提供したりします。</p><h3 id=コンテナが利用する特権の制御>コンテナが利用する特権の制御</h3><p>Podの定義には、<a href=/docs/tasks/configure-pod-container/security-context/>security context</a>が含まれており、ノード上の特定の Linux ユーザー(rootなど)として実行するためのアクセス、特権的に実行するためのアクセス、ホストネットワークにアクセスするためのアクセス、その他の制御を要求することができます。
<a href=/docs/concepts/policy/pod-security-policy/>Pod security policies</a>は、危険なセキュリティコンテキスト設定を提供できるユーザーやサービスアカウントを制限することができます。</p><p>たとえば、Podのセキュリティポリシーでは、ボリュームマウント、特に<code>hostPath</code>を制限することができ、これはPodの制御すべき側面です。
一般に、ほとんどのアプリケーションワークロードでは、ホストリソースへのアクセスを制限する必要があります。
ホスト情報にアクセスすることなく、ルートプロセス(uid 0)として正常に実行できます。
ただし、ルートユーザーに関連する権限を考慮して、非ルートユーザーとして実行するようにアプリケーションコンテナを記述する必要があります。</p><h2 id=コンテナが不要なカーネルモジュールをロードしないようにします>コンテナが不要なカーネルモジュールをロードしないようにします</h2><p>Linuxカーネルは、ハードウェアが接続されたときやファイルシステムがマウントされたときなど、特定の状況下で必要となるカーネルモジュールをディスクから自動的にロードします。
特にKubernetesでは、非特権プロセスであっても、適切なタイプのソケットを作成するだけで、特定のネットワークプロトコル関連のカーネルモジュールをロードさせることができます。これにより、管理者が使用されていないと思い込んでいるカーネルモジュールのセキュリティホールを攻撃者が利用できる可能性があります。
特定のモジュールが自動的にロードされないようにするには、そのモジュールをノードからアンインストールしたり、ルールを追加してブロックしたりします。</p><p>ほとんどのLinuxディストリビューションでは、<code>/etc/modprobe.d/kubernetes-blacklist.conf</code>のような内容のファイルを作成することで実現できます。</p><pre tabindex=0><code># DCCPは必要性が低く、複数の深刻な脆弱性があり、保守も十分ではありません。
blacklist dccp

# SCTPはほとんどのKubernetesクラスタでは使用されておらず、また過去には脆弱性がありました。
blacklist sctp
</code></pre><p>モジュールのロードをより一般的にブロックするには、SELinuxなどのLinuxセキュリティモジュールを使って、コンテナに対する <code>module_request</code>権限を完全に拒否し、いかなる状況下でもカーネルがコンテナ用のモジュールをロードできないようにすることができます。
(Podは、手動でロードされたモジュールや、より高い権限を持つプロセスに代わってカーネルがロードしたモジュールを使用することはできます)。</p><h3 id=ネットワークアクセスの制限>ネットワークアクセスの制限</h3><p>名前空間の<a href=/ja/docs/tasks/administer-cluster/declare-network-policy/>ネットワークポリシー</a>により、アプリケーション作成者は、他の名前空間のPodが自分の名前空間内のPodやポートにアクセスすることを制限することができます。</p><p>サポートされている<a href=/ja/docs/concepts/cluster-administration/networking/>Kubernetes networking providers</a>の多くは、ネットワークポリシーを尊重するようになりました。
クォータやリミットの範囲は、ユーザーがノードポートや負荷分散サービスを要求するかどうかを制御するためにも使用でき、多くのクラスターでは、ユーザーのアプリケーションがクラスターの外で見えるかどうかを制御できます。
ノードごとのファイアウォール、クロストークを防ぐための物理的なクラスタノードの分離、高度なネットワークポリシーなど、プラグインや環境ごとにネットワークルールを制御する追加の保護機能が利用できる場合もあります。</p><h3 id=クラウドメタデータのapiアクセスを制限>クラウドメタデータのAPIアクセスを制限</h3><p>クラウドプラットフォーム(AWS、Azure、GCEなど)では、しばしばメタデータサービスをインスタンスローカルに公開しています。
デフォルトでは、これらのAPIはインスタンス上で実行されているPodからアクセスでき、そのノードのクラウド認証情報や、kubelet認証情報などのプロビジョニングデータを含むことができます。
これらの認証情報は、クラスター内でのエスカレーションや、同じアカウントの他のクラウドサービスへのエスカレーションに使用できます。</p><p>クラウドプラットフォーム上でKubernetesを実行する場合は、インスタンスの認証情報に与えられるパーミッションを制限し、<a href=/ja/docs/tasks/administer-cluster/declare-network-policy/>ネットワークポリシー</a>を使用してメタデータAPIへのPodのアクセスを制限し、プロビジョニングデータを使用してシークレットを配信することは避けてください。</p><h3 id=podのアクセス可能ノードを制御>Podのアクセス可能ノードを制御</h3><p>デフォルトでは、どのノードがPodを実行できるかについての制限はありません。
Kubernetesは、エンドユーザーが利用できる<a href=/ja/docs/concepts/scheduling-eviction/assign-pod-node/>Node上へのPodのスケジューリング</a>と<a href=/ja/docs/concepts/scheduling-eviction/taint-and-toleration/>TaintとToleration</a>を提供します。
多くのクラスターでは、ワークロードを分離するためにこれらのポリシーを使用することは、作者が採用したり、ツールを使って強制したりする慣習になっています。</p><p>管理者としては、ベータ版のアドミッションプラグイン「PodNodeSelector」を使用して、ネームスペース内のPodをデフォルトまたは特定のノードセレクタを必要とするように強制することができます。
エンドユーザーがネームスペースを変更できない場合は、特定のワークロード内のすべてのPodの配置を強く制限することができます。</p><h2 id=クラスターのコンポーネントの保護>クラスターのコンポーネントの保護</h2><p>このセクションでは、クラスターを危険から守るための一般的なパターンを説明します。</p><h3 id=etcdへのアクセスの制限>etcdへのアクセスの制限</h3><p>API用のetcdバックエンドへの書き込みアクセスは、クラスタ全体のrootを取得するのと同等であり、読み取りアクセスはかなり迅速にエスカレートするために使用できます。
管理者は、TLSクライアント証明書による相互認証など、APIサーバーからetcdサーバーへの強力な認証情報を常に使用すべきであり、API サーバーのみがアクセスできるファイアウォールの後ろにetcdサーバーを隔離することがしばしば推奨されます。</p><div class="alert alert-warning caution callout" role=alert><strong>注意:</strong> クラスター内の他のコンポーネントが、完全なキースペースへの読み取りまたは書き込みアクセスを持つマスターetcdインスタンスへのアクセスを許可することは、クラスター管理者のアクセスを許可することと同じです。
マスター以外のコンポーネントに別のetcdインスタンスを使用するか、またはetcd ACLを使用してキースペースのサブセットへの読み取りおよび書き込みアクセスを制限することを強く推奨します。</div><h3 id=監査ログの有効>監査ログの有効</h3><p><a href=/docs/tasks/debug/debug-cluster/audit/>audit logger</a>はベータ版の機能で、APIによって行われたアクションを記録し、侵害があった場合に後から分析できるようにするものです。</p><p>監査ログを有効にして、ログファイルを安全なサーバーにアーカイブすることをお勧めします。</p><h3 id=アルファまたはベータ機能へのアクセスの制限>アルファまたはベータ機能へのアクセスの制限</h3><p>アルファ版およびベータ版のKubernetesの機能は活発に開発が行われており、セキュリティ上の脆弱性をもたらす制限やバグがある可能性があります。
常に、アルファ版またはベータ版の機能が提供する価値と、セキュリティ体制に起こりうるリスクを比較して評価してください。
疑問がある場合は、使用しない機能を無効にしてください。</p><h3 id=インフラの認証情報を頻繁に交換>インフラの認証情報を頻繁に交換</h3><p>秘密やクレデンシャルの有効期間が短いほど、攻撃者がそのクレデンシャルを利用することは難しくなります。
証明書の有効期間を短く設定し、そのローテーションを自動化します。
発行されたトークンの利用可能期間を制御できる認証プロバイダーを使用し、可能な限り短いライフタイムを使用します。
外部統合でサービス・アカウント・トークンを使用する場合、これらのトークンを頻繁にローテーションすることを計画します。
例えば、ブートストラップ・フェーズが完了したら、ノードのセットアップに使用したブートストラップ・トークンを失効させるか、その認証を解除する必要があります。</p><h3 id=サードパーティの統合を有効にする前に確認>サードパーティの統合を有効にする前に確認</h3><p>Kubernetesへの多くのサードパーティの統合は、クラスターのセキュリティプロファイルを変更する可能性があります。
統合を有効にする際には、アクセスを許可する前に、拡張機能が要求するパーミッションを常に確認してください。</p><p>例えば、多くのセキュリティ統合は、事実上そのコンポーネントをクラスター管理者にしているクラスター上のすべての秘密を見るためのアクセスを要求するかもしれません。
疑問がある場合は、可能な限り単一の名前空間で機能するように統合を制限してください。
Podを作成するコンポーネントも、<code>kube-system</code>名前空間のような名前空間内で行うことができれば、予想外に強力になる可能性があります。これは、サービスアカウントのシークレットにアクセスしたり、サービスアカウントに寛容な<a href=/docs/concepts/policy/pod-security-policy/>pod security policies</a>へのアクセスが許可されている場合に、昇格したパーミッションでPodが実行される可能性があるからです。</p><h3 id=etcdにあるsecretを暗号化>etcdにあるSecretを暗号化</h3><p>一般的に、etcdデータベースにはKubernetes APIを介してアクセス可能なあらゆる情報が含まれており、クラスターの状態に対する大きな可視性を攻撃者へ与える可能性があります。
よく吟味されたバックアップおよび暗号化ソリューションを使用して、常にバックアップを暗号化し、可能な場合はフルディスク暗号化の使用を検討してください。</p><p>Kubernetesは1.7で導入された機能である<a href=/docs/tasks/administer-cluster/encrypt-data/>encryption at rest</a>をサポートしており、これは1.13からはベータ版となっています。
これは、etcdの<code>Secret</code>リソースを暗号化し、etcdのバックアップにアクセスした人が、それらのシークレットの内容を見ることを防ぎます。
この機能は現在ベータ版ですが、バックアップが暗号化されていない場合や、攻撃者がetcdへの読み取りアクセスを得た場合に、追加の防御レベルを提供します。</p><h3 id=セキュリティアップデートのアラートの受信と脆弱性の報告>セキュリティアップデートのアラートの受信と脆弱性の報告</h3><p><a href=https://groups.google.com/forum/#!forum/kubernetes-announce>kubernetes-announce</a>に参加してください。
グループに参加すると、セキュリティアナウンスに関するメールを受け取ることができます。
脆弱性の報告方法については、<a href=/docs/reference/issues-security/security/>security reporting</a>ページを参照してください。</p></div><div class=td-content style=page-break-before:always><h1 id=pg-a3790dfb57271d13517e549dffa805b9>13 - ネットワークポリシーを宣言する</h1><p>このドキュメントでは、Pod同士の通信を制御するネットワークポリシーを定義するための、Kubernetesの<a href=/docs/concepts/services-networking/network-policies/>NetworkPolicy API</a>を使い始める手助けをします。</p><h2 id=始める前に>始める前に</h2><p><p>Kubernetesクラスターが必要、かつそのクラスターと通信するためにkubectlコマンドラインツールが設定されている必要があります。
このチュートリアルは、コントロールプレーンのホストとして動作していない少なくとも2つのノードを持つクラスターで実行することをおすすめします。
まだクラスターがない場合、<a href=https://minikube.sigs.k8s.io/docs/tutorials/multi_node/>minikube</a>を使って作成するか、
以下のいずれかのKubernetesプレイグラウンドも使用できます:</p><ul><li><a href=https://killercoda.com/playgrounds/scenario/kubernetes>Killercoda</a></li><li><a href=http://labs.play-with-k8s.com/>Play with Kubernetes</a></li></ul>作業するKubernetesサーバーは次のバージョン以降のものである必要があります: v1.8.
バージョンを確認するには次のコマンドを実行してください: <code>kubectl version</code>.</p><p>ネットワークポリシーをサポートしているネットワークプロバイダーが設定済みであることを確認してください。さまざまなネットワークプロバイダーがNetworkPolicyをサポートしています。次に挙げるのは一例です。</p><ul><li><a href=/docs/tasks/administer-cluster/network-policy-provider/calico-network-policy/>Calico</a></li><li><a href=/docs/tasks/administer-cluster/network-policy-provider/cilium-network-policy/>Cilium</a></li><li><a href=/docs/tasks/administer-cluster/network-policy-provider/kube-router-network-policy/>Kube-router</a></li><li><a href=/docs/tasks/administer-cluster/network-policy-provider/romana-network-policy/>Romana</a></li><li><a href=/docs/tasks/administer-cluster/network-policy-provider/weave-network-policy/>Weave Net</a></li></ul><div class="alert alert-info note callout" role=alert><strong>備考:</strong> 上記のリストは製品名のアルファベット順にソートされていて、推奨順や好ましい順にソートされているわけではありません。このページの例は、Kubernetesクラスターでこれらのどのプロバイダーを使用していても有効です。</div><h2 id=nginx-deploymentを作成してservice経由で公開する><code>nginx</code> Deploymentを作成してService経由で公開する</h2><p>Kubernetesのネットワークポリシーの仕組みを理解するために、まずは<code>nginx</code> Deploymentを作成することから始めましょう。</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-console data-lang=console><span style=display:flex><span><span style=color:#888>kubectl create deployment nginx --image=nginx
</span></span></span></code></pre></div><pre tabindex=0><code class=language-none data-lang=none>deployment.apps/nginx created
</code></pre><p><code>nginx</code>という名前のService経由でDeploymentを公開します。</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-console data-lang=console><span style=display:flex><span><span style=color:#888>kubectl expose deployment nginx --port=80
</span></span></span></code></pre></div><pre tabindex=0><code class=language-none data-lang=none>service/nginx exposed
</code></pre><p>上記のコマンドを実行すると、nginx Podを持つDeploymentが作成され、そのDeploymentが<code>nginx</code>という名前のService経由で公開されます。<code>nginx</code>のPodおよびDeploymentは<code>default</code>名前空間の中にあります。</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-console data-lang=console><span style=display:flex><span><span style=color:#888>kubectl get svc,pod
</span></span></span></code></pre></div><pre tabindex=0><code class=language-none data-lang=none>NAME                        CLUSTER-IP    EXTERNAL-IP   PORT(S)    AGE
service/kubernetes          10.100.0.1    &lt;none&gt;        443/TCP    46m
service/nginx               10.100.0.16   &lt;none&gt;        80/TCP     33s

NAME                        READY         STATUS        RESTARTS   AGE
pod/nginx-701339712-e0qfq   1/1           Running       0          35s
</code></pre><h2 id=もう1つのpodからアクセスしてserviceを検証する>もう1つのPodからアクセスしてServiceを検証する</h2><p>これで、新しい<code>nginx</code>サービスに他のPodからアクセスできるようになったはずです。<code>default</code>名前空間内の他のPodから<code>nginx</code> Serviceにアクセスするために、busyboxコンテナを起動します。</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-console data-lang=console><span style=display:flex><span><span style=color:#888>kubectl run busybox --rm -ti --image=busybox -- /bin/sh
</span></span></span></code></pre></div><p>シェルの中で、次のコマンドを実行します。</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>wget --spider --timeout<span style=color:#666>=</span><span style=color:#666>1</span> nginx
</span></span></code></pre></div><pre tabindex=0><code class=language-none data-lang=none>Connecting to nginx (10.100.0.16:80)
remote file exists
</code></pre><h2 id=nginx-serviceへのアクセスを制限する><code>nginx</code> Serviceへのアクセスを制限する</h2><p><code>nginx</code> Serviceへのアクセスを制限するために、<code>access: true</code>というラベルが付いたPodだけがクエリできるようにします。次の内容でNetworkPolicyオブジェクトを作成してください。</p><div class=highlight><div class=copy-code-icon style=text-align:right><a href=https://raw.githubusercontent.com/kubernetes/website/main/content/ja/examples/service/networking/nginx-policy.yaml download=service/networking/nginx-policy.yaml><code>service/networking/nginx-policy.yaml</code></a>
<img src=/images/copycode.svg style=max-height:24px;cursor:pointer onclick='copyCode("service-networking-nginx-policy-yaml")' title="Copy service/networking/nginx-policy.yaml to clipboard"></img></div><div class=includecode id=service-networking-nginx-policy-yaml><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>networking.k8s.io/v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>NetworkPolicy<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>access-nginx<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>podSelector</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>matchLabels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>app</span>:<span style=color:#bbb> </span>nginx<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>ingress</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>from</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:green;font-weight:700>podSelector</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>matchLabels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>access</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;true&#34;</span><span style=color:#bbb>
</span></span></span></code></pre></div></div></div><p>NetworkPolicyオブジェクトの名前は、有効な<a href=/ja/docs/concepts/overview/working-with-objects/names#dns-subdomain-names>DNSサブドメイン名</a>でなければなりません。</p><div class="alert alert-info note callout" role=alert><strong>備考:</strong> このNetworkPolicyには、ポリシーを適用するPodのグループを選択するための<code>podSelector</code>が含まれています。このポリシーは、ラベル<code>app=nginx</code>の付いたPodを選択していることがわかります。このラベルは、<code>nginx</code> Deployment内のPodに自動的に追加されたものです。空の<code>podSelector</code>は、その名前空間内のすべてのPodを選択します。</div><h2 id=serviceにポリシーを割り当てる>Serviceにポリシーを割り当てる</h2><p>kubectlを使って、上記の<code>nginx-policy.yaml</code>ファイルからNetworkPolicyを作成します。</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-console data-lang=console><span style=display:flex><span><span style=color:#888>kubectl apply -f https://k8s.io/examples/service/networking/nginx-policy.yaml
</span></span></span></code></pre></div><pre tabindex=0><code class=language-none data-lang=none>networkpolicy.networking.k8s.io/access-nginx created
</code></pre><h2 id=accessラベルが定義されていない状態でserviceへのアクセスをテストする>accessラベルが定義されていない状態でServiceへのアクセスをテストする</h2><p><code>nginx</code> Serviceに正しいラベルが付いていないPodからアクセスを試してみると、リクエストがタイムアウトします。</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-console data-lang=console><span style=display:flex><span><span style=color:#888>kubectl run busybox --rm -ti --image=busybox -- /bin/sh
</span></span></span></code></pre></div><p>シェルの中で、次のコマンドを実行します。</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>wget --spider --timeout<span style=color:#666>=</span><span style=color:#666>1</span> nginx
</span></span></code></pre></div><pre tabindex=0><code class=language-none data-lang=none>Connecting to nginx (10.100.0.16:80)
wget: download timed out
</code></pre><h2 id=accessラベルを定義して再テストする>accessラベルを定義して再テストする</h2><p>正しいラベルが付いたPodを作成すると、リクエストが許可されるようになるのがわかります。</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-console data-lang=console><span style=display:flex><span><span style=color:#888>kubectl run busybox --rm -ti --labels=&#34;access=true&#34; --image=busybox -- /bin/sh
</span></span></span></code></pre></div><p>シェルの中で、次のコマンドを実行します。</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>wget --spider --timeout<span style=color:#666>=</span><span style=color:#666>1</span> nginx
</span></span></code></pre></div><pre tabindex=0><code class=language-none data-lang=none>Connecting to nginx (10.100.0.16:80)
remote file exists
</code></pre></div><div class=td-content style=page-break-before:always><h1 id=pg-a8f6511197efcd7d0db80ade49620f9d>14 - 拡張リソースをNodeにアドバタイズする</h1><p>このページでは、Nodeに対して拡張リソースを指定する方法を説明します。拡張リソースを利用すると、Kubernetesにとって未知のノードレベルのリソースをクラスター管理者がアドバタイズできるようになります。</p><h2 id=始める前に>始める前に</h2><p><p>Kubernetesクラスターが必要、かつそのクラスターと通信するためにkubectlコマンドラインツールが設定されている必要があります。
このチュートリアルは、コントロールプレーンのホストとして動作していない少なくとも2つのノードを持つクラスターで実行することをおすすめします。
まだクラスターがない場合、<a href=https://minikube.sigs.k8s.io/docs/tutorials/multi_node/>minikube</a>を使って作成するか、
以下のいずれかのKubernetesプレイグラウンドも使用できます:</p><ul><li><a href=https://killercoda.com/playgrounds/scenario/kubernetes>Killercoda</a></li><li><a href=http://labs.play-with-k8s.com/>Play with Kubernetes</a></li></ul>バージョンを確認するには次のコマンドを実行してください: <code>kubectl version</code>.</p><h2 id=nodeの名前を取得する>Nodeの名前を取得する</h2><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get nodes
</span></span></code></pre></div><p>この練習で使いたいNodeを1つ選んでください。</p><h2 id=nodeの1つで新しい拡張リソースをアドバタイズする>Nodeの1つで新しい拡張リソースをアドバタイズする</h2><p>Node上の新しい拡張リソースをアドバタイズするには、HTTPのPATCHリクエストをKubernetes APIサーバーに送ります。たとえば、Nodeの1つに4つのドングルが接続されているとします。以下に、4つのドングルリソースをNodeにアドバタイズするPATCHリクエストの例を示します。</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>PATCH /api/v1/nodes/&lt;選択したNodeの名前&gt;/status HTTP/1.1
</span></span><span style=display:flex><span>Accept: application/json
</span></span><span style=display:flex><span>Content-Type: application/json-patch+json
</span></span><span style=display:flex><span>Host: k8s-master:8080
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#666>[</span>
</span></span><span style=display:flex><span>  <span style=color:#666>{</span>
</span></span><span style=display:flex><span>    <span style=color:#b44>&#34;op&#34;</span>: <span style=color:#b44>&#34;add&#34;</span>,
</span></span><span style=display:flex><span>    <span style=color:#b44>&#34;path&#34;</span>: <span style=color:#b44>&#34;/status/capacity/example.com~1dongle&#34;</span>,
</span></span><span style=display:flex><span>    <span style=color:#b44>&#34;value&#34;</span>: <span style=color:#b44>&#34;4&#34;</span>
</span></span><span style=display:flex><span>  <span style=color:#666>}</span>
</span></span><span style=display:flex><span><span style=color:#666>]</span>
</span></span></code></pre></div><p>Kubernetesは、ドングルとは何かも、ドングルが何に利用できるのかを知る必要もないことに注意してください。上のPATCHリクエストは、ただNodeが4つのドングルと呼ばれるものを持っているとKubernetesに教えているだけです。</p><p>Kubernetes APIサーバーに簡単にリクエストを送れるように、プロキシーを実行します。</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl proxy
</span></span></code></pre></div><p>もう1つのコマンドウィンドウを開き、HTTPのPATCHリクエストを送ります。<code>&lt;選択したNodeの名前></code>の部分は、選択したNodeの名前に置き換えてください。</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>curl --header <span style=color:#b44>&#34;Content-Type: application/json-patch+json&#34;</span> <span style=color:#b62;font-weight:700>\
</span></span></span><span style=display:flex><span><span style=color:#b62;font-weight:700></span>--request PATCH <span style=color:#b62;font-weight:700>\
</span></span></span><span style=display:flex><span><span style=color:#b62;font-weight:700></span>--data <span style=color:#b44>&#39;[{&#34;op&#34;: &#34;add&#34;, &#34;path&#34;: &#34;/status/capacity/example.com~1dongle&#34;, &#34;value&#34;: &#34;4&#34;}]&#39;</span> <span style=color:#b62;font-weight:700>\
</span></span></span><span style=display:flex><span><span style=color:#b62;font-weight:700></span>http://localhost:8001/api/v1/nodes/&lt;選択したNodeの名前&gt;/status
</span></span></code></pre></div><div class="alert alert-info note callout" role=alert><strong>備考:</strong> 上のリクエストにある<code>~1</code>は、PATCHのパスにおける<code>/</code>という文字をエンコーディングしたものです。JSON-Patch内のoperationのpathはJSON-Pointerとして解釈されます。詳細については、<a href=https://tools.ietf.org/html/rfc6901>IETF RFC 6901</a>のsection 3を読んでください。</div><p>出力には、Nodeがキャパシティー4のdongleを持っていることが示されます。</p><pre tabindex=0><code>&#34;capacity&#34;: {
  &#34;cpu&#34;: &#34;2&#34;,
  &#34;memory&#34;: &#34;2049008Ki&#34;,
  &#34;example.com/dongle&#34;: &#34;4&#34;,
</code></pre><p>Nodeの説明を確認します。</p><pre tabindex=0><code>kubectl describe node &lt;選択したNodeの名前&gt;
</code></pre><p>出力には、再びdongleリソースが表示されます。</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>Capacity</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb> </span><span style=color:green;font-weight:700>cpu</span>:<span style=color:#bbb>  </span><span style=color:#666>2</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb> </span><span style=color:green;font-weight:700>memory</span>:<span style=color:#bbb>  </span>2049008Ki<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb> </span><span style=color:green;font-weight:700>example.com/dongle</span>:<span style=color:#bbb>  </span><span style=color:#666>4</span><span style=color:#bbb>
</span></span></span></code></pre></div><p>これで、アプリケーション開発者は特定の数のdongleをリクエストするPodを作成できるようになりました。詳しくは、<a href=/ja/docs/tasks/configure-pod-container/extended-resource/>拡張リソースをコンテナに割り当てる</a>を読んでください。</p><h2 id=議論>議論</h2><p>拡張リソースは、メモリやCPUリソースと同様のものです。たとえば、Nodeが持っている特定の量のメモリやCPUがNode上で動作している他のすべてのコンポーネントと共有されるのと同様に、Nodeが搭載している特定の数のdongleが他のすべてのコンポーネントと共有されます。そして、アプリケーション開発者が特定の量のメモリとCPUをリクエストするPodを作成できるのと同様に、Nodeが搭載している特定の数のdongleをリクエストするPodが作成できます。</p><p>拡張リソースはKubernetesには詳細を意図的に公開しないため、Kubernetesは拡張リソースの実体をまったく知りません。Kubernetesが知っているのは、Nodeが特定の数の拡張リソースを持っているということだけです。拡張リソースは整数値でアドバタイズしなければなりません。たとえば、Nodeは4つのdongleをアドバタイズできますが、4.5のdongleというのはアドバタイズできません。</p><h3 id=storageの例>Storageの例</h3><p>Nodeに800GiBの特殊なディスクストレージがあるとします。この特殊なストレージの名前、たとえばexample.com/special-storageという名前の拡張リソースが作れます。そして、そのなかの一定のサイズ、たとえば100GiBのチャンクをアドバタイズできます。この場合、Nodeはexample.com/special-storageという種類のキャパシティ8のリソースを持っているとアドバタイズします。</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>Capacity</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb> </span>...<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb> </span><span style=color:green;font-weight:700>example.com/special-storage</span>:<span style=color:#bbb> </span><span style=color:#666>8</span><span style=color:#bbb>
</span></span></span></code></pre></div><p>特殊なストレージに任意のサイズのリクエストを許可したい場合、特殊なストレージを1バイトのサイズのチャンクでアドバタイズできます。その場合、example.com/special-storageという種類の800Giのリソースとしてアドバタイズします。</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>Capacity</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb> </span>...<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb> </span><span style=color:green;font-weight:700>example.com/special-storage</span>:<span style=color:#bbb>  </span>800Gi<span style=color:#bbb>
</span></span></span></code></pre></div><p>すると、コンテナは好きなバイト数の特殊なストレージを最大800Giまでリクエストできるようになります。</p><h2 id=クリーンアップ>クリーンアップ</h2><p>以下に、dongleのアドバタイズをNodeから削除するPATCHリクエストを示します。</p><pre tabindex=0><code>PATCH /api/v1/nodes/&lt;選択したNodeの名前&gt;/status HTTP/1.1
Accept: application/json
Content-Type: application/json-patch+json
Host: k8s-master:8080

[
  {
    &#34;op&#34;: &#34;remove&#34;,
    &#34;path&#34;: &#34;/status/capacity/example.com~1dongle&#34;,
  }
]
</code></pre><p>Kubernetes APIサーバーに簡単にリクエストを送れるように、プロキシーを実行します。</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl proxy
</span></span></code></pre></div><p>もう1つのコマンドウィンドウで、HTTPのPATCHリクエストを送ります。<code>&lt;選択したNodeの名前></code>の部分は、選択したNodeの名前に置き換えてください。</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>curl --header <span style=color:#b44>&#34;Content-Type: application/json-patch+json&#34;</span> <span style=color:#b62;font-weight:700>\
</span></span></span><span style=display:flex><span><span style=color:#b62;font-weight:700></span>--request PATCH <span style=color:#b62;font-weight:700>\
</span></span></span><span style=display:flex><span><span style=color:#b62;font-weight:700></span>--data <span style=color:#b44>&#39;[{&#34;op&#34;: &#34;remove&#34;, &#34;path&#34;: &#34;/status/capacity/example.com~1dongle&#34;}]&#39;</span> <span style=color:#b62;font-weight:700>\
</span></span></span><span style=display:flex><span><span style=color:#b62;font-weight:700></span>http://localhost:8001/api/v1/nodes/&lt;選択したNodeの名前&gt;/status
</span></span></code></pre></div><p>dongleのアドバタイズが削除されたことを検証します。</p><pre tabindex=0><code>kubectl describe node &lt;選択したNodeの名前&gt; | grep dongle
</code></pre><p>(出力には何も表示されないはずです)</p><h2 id=次の項目>次の項目</h2><h3 id=アプリケーション開発者向け>アプリケーション開発者向け</h3><ul><li><a href=/ja/docs/tasks/configure-pod-container/extended-resource/>拡張リソースをコンテナに割り当てる</a></li></ul><h3 id=クラスター管理者向け>クラスター管理者向け</h3><ul><li><a href=/docs/tasks/administer-cluster/manage-resources/memory-constraint-namespace/>Namespaceに対してメモリの最小値と最大値の制約を設定する</a></li><li><a href=/docs/tasks/administer-cluster/manage-resources/cpu-constraint-namespace/>Namespaceに対してCPUの最小値と最大値の制約を設定する</a></li></ul></div></main></div></div><footer class=d-print-none><div class=footer__links><nav><a class=text-white href=/ja/docs/home/>ホーム</a>
<a class=text-white href=/ja/blog/>Blogs</a>
<a class=text-white href=/ja/training/>トレーニング</a>
<a class=text-white href=/ja/partners/>パートナー</a>
<a class=text-white href=/ja/community/>コミュニティ</a>
<a class=text-white href=/ja/case-studies/>ケーススタディ</a></nav></div><div class=container-fluid><div class=row><div class="col-6 col-sm-2 text-xs-center order-sm-2"><ul class="list-inline mb-0"><li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title="User mailing list" aria-label="User mailing list"><a class=text-white target=_blank href=https://discuss.kubernetes.io><i class="fa fa-envelope"></i></a></li><li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title=Twitter aria-label=Twitter><a class=text-white target=_blank href=https://twitter.com/kubernetesio><i class="fab fa-twitter"></i></a></li><li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title=Calendar aria-label=Calendar><a class=text-white target=_blank href="https://calendar.google.com/calendar/embed?src=calendar%40kubernetes.io"><i class="fas fa-calendar-alt"></i></a></li><li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title=Youtube aria-label=Youtube><a class=text-white target=_blank href=https://youtube.com/kubernetescommunity><i class="fab fa-youtube"></i></a></li></ul></div><div class="col-6 col-sm-2 text-right text-xs-center order-sm-3"><ul class="list-inline mb-0"><li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title=GitHub aria-label=GitHub><a class=text-white target=_blank href=https://github.com/kubernetes/kubernetes><i class="fab fa-github"></i></a></li><li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title=Slack aria-label=Slack><a class=text-white target=_blank href=https://slack.k8s.io><i class="fab fa-slack"></i></a></li><li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title=Contribute aria-label=Contribute><a class=text-white target=_blank href=https://git.k8s.io/community/contributors/guide><i class="fas fa-edit"></i></a></li><li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title="Stack Overflow" aria-label="Stack Overflow"><a class=text-white target=_blank href=https://stackoverflow.com/questions/tagged/kubernetes><i class="fab fa-stack-overflow"></i></a></li></ul></div><div class="col-12 col-sm-8 text-center order-sm-2"><small class=text-white>&copy; 2023 The Kubernetes Authors | Documentation Distributed under <a href=https://git.k8s.io/website/LICENSE class=light-text>CC BY 4.0</a></small><br><small class=text-white>Copyright &copy; 2023 The Linux Foundation &reg;. All rights reserved. The Linux Foundation has registered trademarks and uses trademarks. For a list of trademarks of The Linux Foundation, please see our <a href=https://www.linuxfoundation.org/trademark-usage class=light-text>Trademark Usage page</a></small><br><small class=text-white>ICP license: 京ICP备17074266号-3</small></div></div></div></footer></div><script src=/js/jquery-3.6.0.min.js integrity=sha384-vtXRMe3mGCbOeY7l30aIg8H9p3GdeSe4IFlP6G8JMa7o7lXvnz3GFKzPxzJdPfGK crossorigin=anonymous></script>
<script src=/js/popper-1.16.1.min.js intregrity=sha384-9/reFTGAW83EW2RDu2S0VKaIzap3H66lZH81PoYlFhbGU+6BZp6G7niu735Sk7lN crossorigin=anonymous></script>
<script src=/js/bootstrap-4.6.1.min.js integrity=sha384-VHvPCCyXqtD5DqJeNxl2dtTyhF78xXNXdkwX1CZeRusQfRKp+tA7hAShOK/B/fQ2 crossorigin=anonymous></script>
<script src=/js/script.js></script>
<script async src=/js/mermaid-8.13.4.min.js integrity=sha384-5hHNvPeMrNH14oM3IcQofDoBhiclNK3g2+hnEinKzQ07C4AliMeVpnvxuiwEGpaO crossorigin=anonymous></script>
<script src=/js/main.min.5c0bf7f21dc4f66485f74efbbeeff28a7e4f8cddaac1bae47043159c922ff3a3.js integrity="sha256-XAv38h3E9mSF9077vu/yin5PjN2qwbrkcEMVnJIv86M=" crossorigin=anonymous></script></body></html>