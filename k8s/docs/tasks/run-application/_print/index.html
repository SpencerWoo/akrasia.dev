<!doctype html><html lang=en class=no-js><head><meta name=robots content="noindex, nofollow"><link rel=alternate hreflang=zh-cn href=https://kubernetes.io/zh-cn/docs/tasks/run-application/><link rel=alternate hreflang=ko href=https://kubernetes.io/ko/docs/tasks/run-application/><link rel=alternate hreflang=ja href=https://kubernetes.io/ja/docs/tasks/run-application/><link rel=alternate hreflang=fr href=https://kubernetes.io/fr/docs/tasks/run-application/><link rel=alternate hreflang=de href=https://kubernetes.io/de/docs/tasks/run-application/><link rel=alternate hreflang=es href=https://kubernetes.io/es/docs/tasks/run-application/><link rel=alternate hreflang=id href=https://kubernetes.io/id/docs/tasks/run-application/><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=generator content="Hugo 0.110.0"><link rel=canonical type=text/html href=https://kubernetes.io/docs/tasks/run-application/><link rel="shortcut icon" type=image/png href=/images/favicon.png><link rel=apple-touch-icon href=/favicons/apple-touch-icon-180x180.png sizes=180x180><link rel=manifest href=/manifest.webmanifest><link rel=apple-touch-icon href=/images/kubernetes-192x192.png><title>Run Applications | Kubernetes</title><meta property="og:title" content="Run Applications"><meta property="og:description" content="Run and manage both stateless and stateful applications."><meta property="og:type" content="website"><meta property="og:url" content="https://kubernetes.io/docs/tasks/run-application/"><meta property="og:site_name" content="Kubernetes"><meta itemprop=name content="Run Applications"><meta itemprop=description content="Run and manage both stateless and stateful applications."><meta name=twitter:card content="summary"><meta name=twitter:title content="Run Applications"><meta name=twitter:description content="Run and manage both stateless and stateful applications."><link href=/scss/main.css rel=stylesheet><script type=application/ld+json>{"@context":"https://schema.org","@type":"Organization","url":"https://kubernetes.io","logo":"https://kubernetes.io/images/favicon.png","potentialAction":{"@type":"SearchAction","target":"https://kubernetes.io/search/?q={search_term_string}","query-input":"required name=search_term_string"}}</script><meta name=theme-color content="#326ce5"><link rel=stylesheet href=/css/feature-states.css><meta name=description content="Run and manage both stateless and stateful applications."><meta property="og:description" content="Run and manage both stateless and stateful applications."><meta name=twitter:description content="Run and manage both stateless and stateful applications."><meta property="og:url" content="https://kubernetes.io/docs/tasks/run-application/"><meta property="og:title" content="Run Applications"><meta name=twitter:title content="Run Applications"><meta name=twitter:image content="https://kubernetes.io/images/favicon.png"><meta name=twitter:image:alt content="Kubernetes"><meta property="og:image" content="/images/kubernetes-horizontal-color.png"><meta property="og:type" content="article"><script src=/js/jquery-3.6.0.min.js intregrity=sha384-vtXRMe3mGCbOeY7l30aIg8H9p3GdeSe4IFlP6G8JMa7o7lXvnz3GFKzPxzJdPfGK crossorigin=anonymous></script></head><body class=td-section><header><nav class="js-navbar-scroll navbar navbar-expand navbar-dark flex-column flex-md-row td-navbar" data-auto-burger=primary><a class=navbar-brand href=/></a><div class="td-navbar-nav-scroll ml-md-auto" id=main_navbar><ul class="navbar-nav mt-2 mt-lg-0"><li class="nav-item mr-2 mb-lg-0"><a class="nav-link active" href=/docs/>Documentation</a></li><li class="nav-item mr-2 mb-lg-0"><a class=nav-link href=/blog/>Kubernetes Blog</a></li><li class="nav-item mr-2 mb-lg-0"><a class=nav-link href=/training/>Training</a></li><li class="nav-item mr-2 mb-lg-0"><a class=nav-link href=/partners/>Partners</a></li><li class="nav-item mr-2 mb-lg-0"><a class=nav-link href=/community/>Community</a></li><li class="nav-item mr-2 mb-lg-0"><a class=nav-link href=/case-studies/>Case Studies</a></li><li class="nav-item dropdown"><a class="nav-link dropdown-toggle" href=# id=navbarDropdown role=button data-toggle=dropdown aria-haspopup=true aria-expanded=false>Versions</a><div class="dropdown-menu dropdown-menu-right" aria-labelledby=navbarDropdownMenuLink><a class=dropdown-item href=/releases>Release Information</a>
<a class=dropdown-item href=https://kubernetes.io/docs/tasks/run-application/>v1.25</a>
<a class=dropdown-item href=https://v1-24.docs.kubernetes.io/docs/tasks/run-application/>v1.24</a>
<a class=dropdown-item href=https://v1-23.docs.kubernetes.io/docs/tasks/run-application/>v1.23</a>
<a class=dropdown-item href=https://v1-22.docs.kubernetes.io/docs/tasks/run-application/>v1.22</a>
<a class=dropdown-item href=https://v1-21.docs.kubernetes.io/docs/tasks/run-application/>v1.21</a></div></li><li class="nav-item dropdown"><a class="nav-link dropdown-toggle" href=# id=navbarDropdownMenuLink role=button data-toggle=dropdown aria-haspopup=true aria-expanded=false>English</a><div class="dropdown-menu dropdown-menu-right" aria-labelledby=navbarDropdownMenuLink><a class=dropdown-item href=/zh-cn/docs/tasks/run-application/>中文 (Chinese)</a>
<a class=dropdown-item href=/ko/docs/tasks/run-application/>한국어 (Korean)</a>
<a class=dropdown-item href=/ja/docs/tasks/run-application/>日本語 (Japanese)</a>
<a class=dropdown-item href=/fr/docs/tasks/run-application/>Français (French)</a>
<a class=dropdown-item href=/de/docs/tasks/run-application/>Deutsch (German)</a>
<a class=dropdown-item href=/es/docs/tasks/run-application/>Español (Spanish)</a>
<a class=dropdown-item href=/id/docs/tasks/run-application/>Bahasa Indonesia</a></div></li></ul></div><button id=hamburger onclick=kub.toggleMenu() data-auto-burger-exclude><div></div></button></nav></header><div class="container-fluid td-outer"><div class=td-main><div class="row flex-xl-nowrap"><main class="col-12 col-md-9 col-xl-8 pl-md-5" role=main><div class=td-content><div class="pageinfo pageinfo-primary d-print-none"><p>This is the multi-page printable view of this section.
<a href=# onclick="return print(),!1">Click here to print</a>.</p><p><a href=/docs/tasks/run-application/>Return to the regular view of this page</a>.</p></div><h1 class=title>Run Applications</h1><div class=lead>Run and manage both stateless and stateful applications.</div><ul><li>1: <a href=#pg-790ea02857492b3a822e981e93e3a98b>Run a Stateless Application Using a Deployment</a></li><li>2: <a href=#pg-43398a6f5dc7ce19df59f5f4c2e7922d>Run a Single-Instance Stateful Application</a></li><li>3: <a href=#pg-95b3d561509c573e53bec2368264cf6a>Run a Replicated Stateful Application</a></li><li>4: <a href=#pg-7a9b5779e228083ba3fdeaf414fe704e>Scale a StatefulSet</a></li><li>5: <a href=#pg-c43537b0ee1da992ecb7488f87e6c934>Delete a StatefulSet</a></li><li>6: <a href=#pg-f5f2f7a74377a9d45325c5253353fa8f>Force Delete StatefulSet Pods</a></li><li>7: <a href=#pg-0c0bb1bd76d2a9069e50e2cec6d20c2a>Horizontal Pod Autoscaling</a></li><li>8: <a href=#pg-8138226ce9660ac8e3e82ff86fff8ad2>HorizontalPodAutoscaler Walkthrough</a></li><li>9: <a href=#pg-fbe2744f00d1aa4df4cdf4eea6a082d4>Specifying a Disruption Budget for your Application</a></li><li>10: <a href=#pg-52cd10ee3fc7c74a6c31043a2d489878>Accessing the Kubernetes API from a Pod</a></li></ul><div class=content></div></div><div class=td-content><h1 id=pg-790ea02857492b3a822e981e93e3a98b>1 - Run a Stateless Application Using a Deployment</h1><p>This page shows how to run an application using a Kubernetes Deployment object.</p><h2 id=objectives>Objectives</h2><ul><li>Create an nginx deployment.</li><li>Use kubectl to list information about the deployment.</li><li>Update the deployment.</li></ul><h2 id=before-you-begin>Before you begin</h2><p><p>You need to have a Kubernetes cluster, and the kubectl command-line tool must
be configured to communicate with your cluster. It is recommended to run this tutorial on a cluster with at least two nodes that are not acting as control plane hosts. If you do not already have a
cluster, you can create one by using
<a href=https://minikube.sigs.k8s.io/docs/tutorials/multi_node/>minikube</a>
or you can use one of these Kubernetes playgrounds:</p><ul><li><a href=https://killercoda.com/playgrounds/scenario/kubernetes>Killercoda</a></li><li><a href=http://labs.play-with-k8s.com/>Play with Kubernetes</a></li></ul>Your Kubernetes server must be at or later than version v1.9.
To check the version, enter <code>kubectl version</code>.</p><h2 id=creating-and-exploring-an-nginx-deployment>Creating and exploring an nginx deployment</h2><p>You can run an application by creating a Kubernetes Deployment object, and you
can describe a Deployment in a YAML file. For example, this YAML file describes
a Deployment that runs the nginx:1.14.2 Docker image:</p><div class=highlight><div class=copy-code-icon style=text-align:right><a href=https://raw.githubusercontent.com/kubernetes/website/main/content/en/examples/application/deployment.yaml download=application/deployment.yaml><code>application/deployment.yaml</code></a>
<img src=/images/copycode.svg style=max-height:24px;cursor:pointer onclick='copyCode("application-deployment-yaml")' title="Copy application/deployment.yaml to clipboard"></img></div><div class=includecode id=application-deployment-yaml><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>apps/v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Deployment<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>nginx-deployment<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>selector</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>matchLabels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>app</span>:<span style=color:#bbb> </span>nginx<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>replicas</span>:<span style=color:#bbb> </span><span style=color:#666>2</span><span style=color:#bbb> </span><span style=color:#080;font-style:italic># tells deployment to run 2 pods matching the template</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>template</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>labels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>app</span>:<span style=color:#bbb> </span>nginx<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>nginx<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>nginx:1.14.2<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>ports</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span>- <span style=color:green;font-weight:700>containerPort</span>:<span style=color:#bbb> </span><span style=color:#666>80</span><span style=color:#bbb>
</span></span></span></code></pre></div></div></div><ol><li><p>Create a Deployment based on the YAML file:</p><pre><code> kubectl apply -f https://k8s.io/examples/application/deployment.yaml
</code></pre></li><li><p>Display information about the Deployment:</p><pre><code> kubectl describe deployment nginx-deployment
</code></pre><p>The output is similar to this:</p><pre><code> Name:     nginx-deployment
 Namespace:    default
 CreationTimestamp:  Tue, 30 Aug 2016 18:11:37 -0700
 Labels:     app=nginx
 Annotations:    deployment.kubernetes.io/revision=1
 Selector:   app=nginx
 Replicas:   2 desired | 2 updated | 2 total | 2 available | 0 unavailable
 StrategyType:   RollingUpdate
 MinReadySeconds:  0
 RollingUpdateStrategy:  1 max unavailable, 1 max surge
 Pod Template:
   Labels:       app=nginx
   Containers:
    nginx:
     Image:              nginx:1.14.2
     Port:               80/TCP
     Environment:        &lt;none&gt;
     Mounts:             &lt;none&gt;
   Volumes:              &lt;none&gt;
 Conditions:
   Type          Status  Reason
   ----          ------  ------
   Available     True    MinimumReplicasAvailable
   Progressing   True    NewReplicaSetAvailable
 OldReplicaSets:   &lt;none&gt;
 NewReplicaSet:    nginx-deployment-1771418926 (2/2 replicas created)
 No events.
</code></pre></li><li><p>List the Pods created by the deployment:</p><pre><code> kubectl get pods -l app=nginx
</code></pre><p>The output is similar to this:</p><pre><code> NAME                                READY     STATUS    RESTARTS   AGE
 nginx-deployment-1771418926-7o5ns   1/1       Running   0          16h
 nginx-deployment-1771418926-r18az   1/1       Running   0          16h
</code></pre></li><li><p>Display information about a Pod:</p><pre><code> kubectl describe pod &lt;pod-name&gt;
</code></pre><p>where <code>&lt;pod-name></code> is the name of one of your Pods.</p></li></ol><h2 id=updating-the-deployment>Updating the deployment</h2><p>You can update the deployment by applying a new YAML file. This YAML file
specifies that the deployment should be updated to use nginx 1.16.1.</p><div class=highlight><div class=copy-code-icon style=text-align:right><a href=https://raw.githubusercontent.com/kubernetes/website/main/content/en/examples/application/deployment-update.yaml download=application/deployment-update.yaml><code>application/deployment-update.yaml</code></a>
<img src=/images/copycode.svg style=max-height:24px;cursor:pointer onclick='copyCode("application-deployment-update-yaml")' title="Copy application/deployment-update.yaml to clipboard"></img></div><div class=includecode id=application-deployment-update-yaml><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>apps/v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Deployment<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>nginx-deployment<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>selector</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>matchLabels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>app</span>:<span style=color:#bbb> </span>nginx<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>replicas</span>:<span style=color:#bbb> </span><span style=color:#666>2</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>template</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>labels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>app</span>:<span style=color:#bbb> </span>nginx<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>nginx<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>nginx:1.16.1<span style=color:#bbb> </span><span style=color:#080;font-style:italic># Update the version of nginx from 1.14.2 to 1.16.1</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>ports</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span>- <span style=color:green;font-weight:700>containerPort</span>:<span style=color:#bbb> </span><span style=color:#666>80</span><span style=color:#bbb>
</span></span></span></code></pre></div></div></div><ol><li><p>Apply the new YAML file:</p><pre><code>  kubectl apply -f https://k8s.io/examples/application/deployment-update.yaml
</code></pre></li><li><p>Watch the deployment create pods with new names and delete the old pods:</p><pre><code>  kubectl get pods -l app=nginx
</code></pre></li></ol><h2 id=scaling-the-application-by-increasing-the-replica-count>Scaling the application by increasing the replica count</h2><p>You can increase the number of Pods in your Deployment by applying a new YAML
file. This YAML file sets <code>replicas</code> to 4, which specifies that the Deployment
should have four Pods:</p><div class=highlight><div class=copy-code-icon style=text-align:right><a href=https://raw.githubusercontent.com/kubernetes/website/main/content/en/examples/application/deployment-scale.yaml download=application/deployment-scale.yaml><code>application/deployment-scale.yaml</code></a>
<img src=/images/copycode.svg style=max-height:24px;cursor:pointer onclick='copyCode("application-deployment-scale-yaml")' title="Copy application/deployment-scale.yaml to clipboard"></img></div><div class=includecode id=application-deployment-scale-yaml><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>apps/v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Deployment<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>nginx-deployment<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>selector</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>matchLabels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>app</span>:<span style=color:#bbb> </span>nginx<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>replicas</span>:<span style=color:#bbb> </span><span style=color:#666>4</span><span style=color:#bbb> </span><span style=color:#080;font-style:italic># Update the replicas from 2 to 4</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>template</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>labels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>app</span>:<span style=color:#bbb> </span>nginx<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>nginx<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>nginx:1.16.1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>ports</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span>- <span style=color:green;font-weight:700>containerPort</span>:<span style=color:#bbb> </span><span style=color:#666>80</span><span style=color:#bbb>
</span></span></span></code></pre></div></div></div><ol><li><p>Apply the new YAML file:</p><pre><code> kubectl apply -f https://k8s.io/examples/application/deployment-scale.yaml
</code></pre></li><li><p>Verify that the Deployment has four Pods:</p><pre><code> kubectl get pods -l app=nginx
</code></pre><p>The output is similar to this:</p><pre><code> NAME                               READY     STATUS    RESTARTS   AGE
 nginx-deployment-148880595-4zdqq   1/1       Running   0          25s
 nginx-deployment-148880595-6zgi1   1/1       Running   0          25s
 nginx-deployment-148880595-fxcez   1/1       Running   0          2m
 nginx-deployment-148880595-rwovn   1/1       Running   0          2m
</code></pre></li></ol><h2 id=deleting-a-deployment>Deleting a deployment</h2><p>Delete the deployment by name:</p><pre><code>kubectl delete deployment nginx-deployment
</code></pre><h2 id=replicationcontrollers-the-old-way>ReplicationControllers -- the Old Way</h2><p>The preferred way to create a replicated application is to use a Deployment,
which in turn uses a ReplicaSet. Before the Deployment and ReplicaSet were
added to Kubernetes, replicated applications were configured using a
<a href=/docs/concepts/workloads/controllers/replicationcontroller/>ReplicationController</a>.</p><h2 id=what-s-next>What's next</h2><ul><li>Learn more about <a href=/docs/concepts/workloads/controllers/deployment/>Deployment objects</a>.</li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-43398a6f5dc7ce19df59f5f4c2e7922d>2 - Run a Single-Instance Stateful Application</h1><p>This page shows you how to run a single-instance stateful application
in Kubernetes using a PersistentVolume and a Deployment. The
application is MySQL.</p><h2 id=objectives>Objectives</h2><ul><li>Create a PersistentVolume referencing a disk in your environment.</li><li>Create a MySQL Deployment.</li><li>Expose MySQL to other pods in the cluster at a known DNS name.</li></ul><h2 id=before-you-begin>Before you begin</h2><ul><li><p><p>You need to have a Kubernetes cluster, and the kubectl command-line tool must
be configured to communicate with your cluster. It is recommended to run this tutorial on a cluster with at least two nodes that are not acting as control plane hosts. If you do not already have a
cluster, you can create one by using
<a href=https://minikube.sigs.k8s.io/docs/tutorials/multi_node/>minikube</a>
or you can use one of these Kubernetes playgrounds:</p><ul><li><a href=https://killercoda.com/playgrounds/scenario/kubernetes>Killercoda</a></li><li><a href=http://labs.play-with-k8s.com/>Play with Kubernetes</a></li></ul>To check the version, enter <code>kubectl version</code>.</p></li><li><p>You need to either have a <a href=/docs/concepts/storage/dynamic-provisioning/>dynamic PersistentVolume provisioner</a> with a default
<a href=/docs/concepts/storage/storage-classes/>StorageClass</a>,
or <a href=/docs/concepts/storage/persistent-volumes/#provisioning>statically provision PersistentVolumes</a>
yourself to satisfy the <a href=/docs/concepts/storage/persistent-volumes/#persistentvolumeclaims>PersistentVolumeClaims</a>
used here.</p></li></ul><h2 id=deploy-mysql>Deploy MySQL</h2><p>You can run a stateful application by creating a Kubernetes Deployment
and connecting it to an existing PersistentVolume using a
PersistentVolumeClaim. For example, this YAML file describes a
Deployment that runs MySQL and references the PersistentVolumeClaim. The file
defines a volume mount for /var/lib/mysql, and then creates a
PersistentVolumeClaim that looks for a 20G volume. This claim is
satisfied by any existing volume that meets the requirements,
or by a dynamic provisioner.</p><p>Note: The password is defined in the config yaml, and this is insecure. See
<a href=/docs/concepts/configuration/secret/>Kubernetes Secrets</a>
for a secure solution.</p><p><div class=highlight><div class=copy-code-icon style=text-align:right><a href=https://raw.githubusercontent.com/kubernetes/website/main/content/en/examples/application/mysql/mysql-deployment.yaml download=application/mysql/mysql-deployment.yaml><code>application/mysql/mysql-deployment.yaml</code></a>
<img src=/images/copycode.svg style=max-height:24px;cursor:pointer onclick='copyCode("application-mysql-mysql-deployment-yaml")' title="Copy application/mysql/mysql-deployment.yaml to clipboard"></img></div><div class=includecode id=application-mysql-mysql-deployment-yaml><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Service<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>mysql<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>ports</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>port</span>:<span style=color:#bbb> </span><span style=color:#666>3306</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>selector</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>app</span>:<span style=color:#bbb> </span>mysql<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>clusterIP</span>:<span style=color:#bbb> </span>None<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:#00f;font-weight:700>---</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>apps/v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Deployment<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>mysql<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>selector</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>matchLabels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>app</span>:<span style=color:#bbb> </span>mysql<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>strategy</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>type</span>:<span style=color:#bbb> </span>Recreate<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>template</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>labels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>app</span>:<span style=color:#bbb> </span>mysql<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- <span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>mysql:5.6<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>mysql<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>env</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:#080;font-style:italic># Use secret in real usage</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>MYSQL_ROOT_PASSWORD<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>value</span>:<span style=color:#bbb> </span>password<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>ports</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span>- <span style=color:green;font-weight:700>containerPort</span>:<span style=color:#bbb> </span><span style=color:#666>3306</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>mysql<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>volumeMounts</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>mysql-persistent-storage<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>mountPath</span>:<span style=color:#bbb> </span>/var/lib/mysql<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>volumes</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>mysql-persistent-storage<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>persistentVolumeClaim</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>claimName</span>:<span style=color:#bbb> </span>mysql-pv-claim<span style=color:#bbb>
</span></span></span></code></pre></div></div></div><div class=highlight><div class=copy-code-icon style=text-align:right><a href=https://raw.githubusercontent.com/kubernetes/website/main/content/en/examples/application/mysql/mysql-pv.yaml download=application/mysql/mysql-pv.yaml><code>application/mysql/mysql-pv.yaml</code></a>
<img src=/images/copycode.svg style=max-height:24px;cursor:pointer onclick='copyCode("application-mysql-mysql-pv-yaml")' title="Copy application/mysql/mysql-pv.yaml to clipboard"></img></div><div class=includecode id=application-mysql-mysql-pv-yaml><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>PersistentVolume<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>mysql-pv-volume<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>labels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>type</span>:<span style=color:#bbb> </span>local<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>storageClassName</span>:<span style=color:#bbb> </span>manual<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>capacity</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>storage</span>:<span style=color:#bbb> </span>20Gi<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>accessModes</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- ReadWriteOnce<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>hostPath</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>path</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;/mnt/data&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:#00f;font-weight:700>---</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>PersistentVolumeClaim<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>mysql-pv-claim<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>storageClassName</span>:<span style=color:#bbb> </span>manual<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>accessModes</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- ReadWriteOnce<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>resources</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>requests</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>storage</span>:<span style=color:#bbb> </span>20Gi<span style=color:#bbb>
</span></span></span></code></pre></div></div></div></p><ol><li><p>Deploy the PV and PVC of the YAML file:</p><pre><code> kubectl apply -f https://k8s.io/examples/application/mysql/mysql-pv.yaml
</code></pre></li><li><p>Deploy the contents of the YAML file:</p><pre><code> kubectl apply -f https://k8s.io/examples/application/mysql/mysql-deployment.yaml
</code></pre></li><li><p>Display information about the Deployment:</p><pre><code> kubectl describe deployment mysql
</code></pre><p>The output is similar to this:</p><pre><code> Name:                 mysql
 Namespace:            default
 CreationTimestamp:    Tue, 01 Nov 2016 11:18:45 -0700
 Labels:               app=mysql
 Annotations:          deployment.kubernetes.io/revision=1
 Selector:             app=mysql
 Replicas:             1 desired | 1 updated | 1 total | 0 available | 1 unavailable
 StrategyType:         Recreate
 MinReadySeconds:      0
 Pod Template:
   Labels:       app=mysql
   Containers:
    mysql:
     Image:      mysql:5.6
     Port:       3306/TCP
     Environment:
       MYSQL_ROOT_PASSWORD:      password
     Mounts:
       /var/lib/mysql from mysql-persistent-storage (rw)
   Volumes:
    mysql-persistent-storage:
     Type:       PersistentVolumeClaim (a reference to a PersistentVolumeClaim in the same namespace)
     ClaimName:  mysql-pv-claim
     ReadOnly:   false
 Conditions:
   Type          Status  Reason
   ----          ------  ------
   Available     False   MinimumReplicasUnavailable
   Progressing   True    ReplicaSetUpdated
 OldReplicaSets:       &lt;none&gt;
 NewReplicaSet:        mysql-63082529 (1/1 replicas created)
 Events:
   FirstSeen    LastSeen    Count    From                SubobjectPath    Type        Reason            Message
   ---------    --------    -----    ----                -------------    --------    ------            -------
   33s          33s         1        {deployment-controller }             Normal      ScalingReplicaSet Scaled up replica set mysql-63082529 to 1
</code></pre></li><li><p>List the pods created by the Deployment:</p><pre><code> kubectl get pods -l app=mysql
</code></pre><p>The output is similar to this:</p><pre><code> NAME                   READY     STATUS    RESTARTS   AGE
 mysql-63082529-2z3ki   1/1       Running   0          3m
</code></pre></li><li><p>Inspect the PersistentVolumeClaim:</p><pre><code> kubectl describe pvc mysql-pv-claim
</code></pre><p>The output is similar to this:</p><pre><code> Name:         mysql-pv-claim
 Namespace:    default
 StorageClass:
 Status:       Bound
 Volume:       mysql-pv-volume
 Labels:       &lt;none&gt;
 Annotations:    pv.kubernetes.io/bind-completed=yes
                 pv.kubernetes.io/bound-by-controller=yes
 Capacity:     20Gi
 Access Modes: RWO
 Events:       &lt;none&gt;
</code></pre></li></ol><h2 id=accessing-the-mysql-instance>Accessing the MySQL instance</h2><p>The preceding YAML file creates a service that
allows other Pods in the cluster to access the database. The Service option
<code>clusterIP: None</code> lets the Service DNS name resolve directly to the
Pod's IP address. This is optimal when you have only one Pod
behind a Service and you don't intend to increase the number of Pods.</p><p>Run a MySQL client to connect to the server:</p><pre tabindex=0><code>kubectl run -it --rm --image=mysql:5.6 --restart=Never mysql-client -- mysql -h mysql -ppassword
</code></pre><p>This command creates a new Pod in the cluster running a MySQL client
and connects it to the server through the Service. If it connects, you
know your stateful MySQL database is up and running.</p><pre tabindex=0><code>Waiting for pod default/mysql-client-274442439-zyp6i to be running, status is Pending, pod ready: false
If you don&#39;t see a command prompt, try pressing enter.

mysql&gt;
</code></pre><h2 id=updating>Updating</h2><p>The image or any other part of the Deployment can be updated as usual
with the <code>kubectl apply</code> command. Here are some precautions that are
specific to stateful apps:</p><ul><li>Don't scale the app. This setup is for single-instance apps
only. The underlying PersistentVolume can only be mounted to one
Pod. For clustered stateful apps, see the
<a href=/docs/concepts/workloads/controllers/statefulset/>StatefulSet documentation</a>.</li><li>Use <code>strategy:</code> <code>type: Recreate</code> in the Deployment configuration
YAML file. This instructs Kubernetes to <em>not</em> use rolling
updates. Rolling updates will not work, as you cannot have more than
one Pod running at a time. The <code>Recreate</code> strategy will stop the
first pod before creating a new one with the updated configuration.</li></ul><h2 id=deleting-a-deployment>Deleting a deployment</h2><p>Delete the deployed objects by name:</p><pre tabindex=0><code>kubectl delete deployment,svc mysql
kubectl delete pvc mysql-pv-claim
kubectl delete pv mysql-pv-volume
</code></pre><p>If you manually provisioned a PersistentVolume, you also need to manually
delete it, as well as release the underlying resource.
If you used a dynamic provisioner, it automatically deletes the
PersistentVolume when it sees that you deleted the PersistentVolumeClaim.
Some dynamic provisioners (such as those for EBS and PD) also release the
underlying resource upon deleting the PersistentVolume.</p><h2 id=what-s-next>What's next</h2><ul><li><p>Learn more about <a href=/docs/concepts/workloads/controllers/deployment/>Deployment objects</a>.</p></li><li><p>Learn more about <a href=/docs/tasks/run-application/run-stateless-application-deployment/>Deploying applications</a></p></li><li><p><a href=/docs/reference/generated/kubectl/kubectl-commands/#run>kubectl run documentation</a></p></li><li><p><a href=/docs/concepts/storage/volumes/>Volumes</a> and <a href=/docs/concepts/storage/persistent-volumes/>Persistent Volumes</a></p></li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-95b3d561509c573e53bec2368264cf6a>3 - Run a Replicated Stateful Application</h1><p>This page shows how to run a replicated stateful application using a
<a class=glossary-tooltip title='Manages deployment and scaling of a set of Pods, with durable storage and persistent identifiers for each Pod.' data-toggle=tooltip data-placement=top href=/docs/concepts/workloads/controllers/statefulset/ target=_blank aria-label=StatefulSet>StatefulSet</a>.
This application is a replicated MySQL database. The example topology has a
single primary server and multiple replicas, using asynchronous row-based
replication.</p><div class="alert alert-info note callout" role=alert><strong>Note:</strong> <strong>This is not a production configuration</strong>. MySQL settings remain on insecure defaults to keep the focus
on general patterns for running stateful applications in Kubernetes.</div><h2 id=before-you-begin>Before you begin</h2><ul><li><p>You need to have a Kubernetes cluster, and the kubectl command-line tool must
be configured to communicate with your cluster. It is recommended to run this tutorial on a cluster with at least two nodes that are not acting as control plane hosts. If you do not already have a
cluster, you can create one by using
<a href=https://minikube.sigs.k8s.io/docs/tutorials/multi_node/>minikube</a>
or you can use one of these Kubernetes playgrounds:</p><ul><li><a href=https://killercoda.com/playgrounds/scenario/kubernetes>Killercoda</a></li><li><a href=http://labs.play-with-k8s.com/>Play with Kubernetes</a></li></ul></li><li><p>You need to either have a <a href=/docs/concepts/storage/dynamic-provisioning/>dynamic PersistentVolume provisioner</a> with a default
<a href=/docs/concepts/storage/storage-classes/>StorageClass</a>,
or <a href=/docs/concepts/storage/persistent-volumes/#provisioning>statically provision PersistentVolumes</a>
yourself to satisfy the <a href=/docs/concepts/storage/persistent-volumes/#persistentvolumeclaims>PersistentVolumeClaims</a>
used here.</p></li><li>This tutorial assumes you are familiar with
<a href=/docs/concepts/storage/persistent-volumes/>PersistentVolumes</a>
and <a href=/docs/concepts/workloads/controllers/statefulset/>StatefulSets</a>,
as well as other core concepts like <a href=/docs/concepts/workloads/pods/>Pods</a>,
<a href=/docs/concepts/services-networking/service/>Services</a>, and
<a href=/docs/tasks/configure-pod-container/configure-pod-configmap/>ConfigMaps</a>.</li><li>Some familiarity with MySQL helps, but this tutorial aims to present
general patterns that should be useful for other systems.</li><li>You are using the default namespace or another namespace that does not contain any conflicting objects.</li></ul><h2 id=objectives>Objectives</h2><ul><li>Deploy a replicated MySQL topology with a StatefulSet.</li><li>Send MySQL client traffic.</li><li>Observe resistance to downtime.</li><li>Scale the StatefulSet up and down.</li></ul><h2 id=deploy-mysql>Deploy MySQL</h2><p>The example MySQL deployment consists of a ConfigMap, two Services,
and a StatefulSet.</p><h3 id=configmap>Create a ConfigMap</h3><p>Create the ConfigMap from the following YAML configuration file:</p><div class=highlight><div class=copy-code-icon style=text-align:right><a href=https://raw.githubusercontent.com/kubernetes/website/main/content/en/examples/application/mysql/mysql-configmap.yaml download=application/mysql/mysql-configmap.yaml><code>application/mysql/mysql-configmap.yaml</code></a>
<img src=/images/copycode.svg style=max-height:24px;cursor:pointer onclick='copyCode("application-mysql-mysql-configmap-yaml")' title="Copy application/mysql/mysql-configmap.yaml to clipboard"></img></div><div class=includecode id=application-mysql-mysql-configmap-yaml><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>ConfigMap<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>mysql<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>labels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>app</span>:<span style=color:#bbb> </span>mysql<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>app.kubernetes.io/name</span>:<span style=color:#bbb> </span>mysql<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>data</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>primary.cnf</span>:<span style=color:#bbb> </span>|<span style=color:#b44;font-style:italic>
</span></span></span><span style=display:flex><span><span style=color:#b44;font-style:italic>    # Apply this config only on the primary.
</span></span></span><span style=display:flex><span><span style=color:#b44;font-style:italic>    [mysqld]
</span></span></span><span style=display:flex><span><span style=color:#b44;font-style:italic>    log-bin</span><span style=color:#bbb>    
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>replica.cnf</span>:<span style=color:#bbb> </span>|<span style=color:#b44;font-style:italic>
</span></span></span><span style=display:flex><span><span style=color:#b44;font-style:italic>    # Apply this config only on replicas.
</span></span></span><span style=display:flex><span><span style=color:#b44;font-style:italic>    [mysqld]
</span></span></span><span style=display:flex><span><span style=color:#b44;font-style:italic>    super-read-only</span><span style=color:#bbb>    
</span></span></span><span style=display:flex><span><span style=color:#bbb>
</span></span></span></code></pre></div></div></div><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl apply -f https://k8s.io/examples/application/mysql/mysql-configmap.yaml
</span></span></code></pre></div><p>This ConfigMap provides <code>my.cnf</code> overrides that let you independently control
configuration on the primary MySQL server and its replicas.
In this case, you want the primary server to be able to serve replication logs to replicas
and you want replicas to reject any writes that don't come via replication.</p><p>There's nothing special about the ConfigMap itself that causes different
portions to apply to different Pods.
Each Pod decides which portion to look at as it's initializing,
based on information provided by the StatefulSet controller.</p><h3 id=services>Create Services</h3><p>Create the Services from the following YAML configuration file:</p><div class=highlight><div class=copy-code-icon style=text-align:right><a href=https://raw.githubusercontent.com/kubernetes/website/main/content/en/examples/application/mysql/mysql-services.yaml download=application/mysql/mysql-services.yaml><code>application/mysql/mysql-services.yaml</code></a>
<img src=/images/copycode.svg style=max-height:24px;cursor:pointer onclick='copyCode("application-mysql-mysql-services-yaml")' title="Copy application/mysql/mysql-services.yaml to clipboard"></img></div><div class=includecode id=application-mysql-mysql-services-yaml><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#080;font-style:italic># Headless service for stable DNS entries of StatefulSet members.</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Service<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>mysql<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>labels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>app</span>:<span style=color:#bbb> </span>mysql<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>app.kubernetes.io/name</span>:<span style=color:#bbb> </span>mysql<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>ports</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>mysql<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>port</span>:<span style=color:#bbb> </span><span style=color:#666>3306</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>clusterIP</span>:<span style=color:#bbb> </span>None<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>selector</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>app</span>:<span style=color:#bbb> </span>mysql<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:#00f;font-weight:700>---</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:#080;font-style:italic># Client service for connecting to any MySQL instance for reads.</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:#080;font-style:italic># For writes, you must instead connect to the primary: mysql-0.mysql.</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Service<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>mysql-read<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>labels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>app</span>:<span style=color:#bbb> </span>mysql<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>app.kubernetes.io/name</span>:<span style=color:#bbb> </span>mysql<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>readonly</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;true&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>ports</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>mysql<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>port</span>:<span style=color:#bbb> </span><span style=color:#666>3306</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>selector</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>app</span>:<span style=color:#bbb> </span>mysql<span style=color:#bbb>
</span></span></span></code></pre></div></div></div><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl apply -f https://k8s.io/examples/application/mysql/mysql-services.yaml
</span></span></code></pre></div><p>The headless Service provides a home for the DNS entries that the StatefulSet
<a class=glossary-tooltip title='A control loop that watches the shared state of the cluster through the apiserver and makes changes attempting to move the current state towards the desired state.' data-toggle=tooltip data-placement=top href=/docs/concepts/architecture/controller/ target=_blank aria-label=controllers>controllers</a> creates for each
Pod that's part of the set.
Because the headless Service is named <code>mysql</code>, the Pods are accessible by
resolving <code>&lt;pod-name>.mysql</code> from within any other Pod in the same Kubernetes
cluster and namespace.</p><p>The client Service, called <code>mysql-read</code>, is a normal Service with its own
cluster IP that distributes connections across all MySQL Pods that report
being Ready. The set of potential endpoints includes the primary MySQL server and all
replicas.</p><p>Note that only read queries can use the load-balanced client Service.
Because there is only one primary MySQL server, clients should connect directly to the
primary MySQL Pod (through its DNS entry within the headless Service) to execute
writes.</p><h3 id=statefulset>Create the StatefulSet</h3><p>Finally, create the StatefulSet from the following YAML configuration file:</p><div class=highlight><div class=copy-code-icon style=text-align:right><a href=https://raw.githubusercontent.com/kubernetes/website/main/content/en/examples/application/mysql/mysql-statefulset.yaml download=application/mysql/mysql-statefulset.yaml><code>application/mysql/mysql-statefulset.yaml</code></a>
<img src=/images/copycode.svg style=max-height:24px;cursor:pointer onclick='copyCode("application-mysql-mysql-statefulset-yaml")' title="Copy application/mysql/mysql-statefulset.yaml to clipboard"></img></div><div class=includecode id=application-mysql-mysql-statefulset-yaml><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>apps/v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>StatefulSet<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>mysql<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>selector</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>matchLabels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>app</span>:<span style=color:#bbb> </span>mysql<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>app.kubernetes.io/name</span>:<span style=color:#bbb> </span>mysql<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>serviceName</span>:<span style=color:#bbb> </span>mysql<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>replicas</span>:<span style=color:#bbb> </span><span style=color:#666>3</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>template</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>labels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>app</span>:<span style=color:#bbb> </span>mysql<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>app.kubernetes.io/name</span>:<span style=color:#bbb> </span>mysql<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>initContainers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>init-mysql<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>mysql:5.7<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>command</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span>- bash<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span>- <span style=color:#b44>&#34;-c&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span>- |<span style=color:#b44;font-style:italic>
</span></span></span><span style=display:flex><span><span style=color:#b44;font-style:italic>          set -ex
</span></span></span><span style=display:flex><span><span style=color:#b44;font-style:italic>          # Generate mysql server-id from pod ordinal index.
</span></span></span><span style=display:flex><span><span style=color:#b44;font-style:italic>          [[ $HOSTNAME =~ -([0-9]+)$ ]] || exit 1
</span></span></span><span style=display:flex><span><span style=color:#b44;font-style:italic>          ordinal=${BASH_REMATCH[1]}
</span></span></span><span style=display:flex><span><span style=color:#b44;font-style:italic>          echo [mysqld] &gt; /mnt/conf.d/server-id.cnf
</span></span></span><span style=display:flex><span><span style=color:#b44;font-style:italic>          # Add an offset to avoid reserved server-id=0 value.
</span></span></span><span style=display:flex><span><span style=color:#b44;font-style:italic>          echo server-id=$((100 + $ordinal)) &gt;&gt; /mnt/conf.d/server-id.cnf
</span></span></span><span style=display:flex><span><span style=color:#b44;font-style:italic>          # Copy appropriate conf.d files from config-map to emptyDir.
</span></span></span><span style=display:flex><span><span style=color:#b44;font-style:italic>          if [[ $ordinal -eq 0 ]]; then
</span></span></span><span style=display:flex><span><span style=color:#b44;font-style:italic>            cp /mnt/config-map/primary.cnf /mnt/conf.d/
</span></span></span><span style=display:flex><span><span style=color:#b44;font-style:italic>          else
</span></span></span><span style=display:flex><span><span style=color:#b44;font-style:italic>            cp /mnt/config-map/replica.cnf /mnt/conf.d/
</span></span></span><span style=display:flex><span><span style=color:#b44;font-style:italic>          fi</span><span style=color:#bbb>          
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>volumeMounts</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>conf<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>mountPath</span>:<span style=color:#bbb> </span>/mnt/conf.d<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>config-map<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>mountPath</span>:<span style=color:#bbb> </span>/mnt/config-map<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>clone-mysql<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>gcr.io/google-samples/xtrabackup:1.0<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>command</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span>- bash<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span>- <span style=color:#b44>&#34;-c&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span>- |<span style=color:#b44;font-style:italic>
</span></span></span><span style=display:flex><span><span style=color:#b44;font-style:italic>          set -ex
</span></span></span><span style=display:flex><span><span style=color:#b44;font-style:italic>          # Skip the clone if data already exists.
</span></span></span><span style=display:flex><span><span style=color:#b44;font-style:italic>          [[ -d /var/lib/mysql/mysql ]] &amp;&amp; exit 0
</span></span></span><span style=display:flex><span><span style=color:#b44;font-style:italic>          # Skip the clone on primary (ordinal index 0).
</span></span></span><span style=display:flex><span><span style=color:#b44;font-style:italic>          [[ `hostname` =~ -([0-9]+)$ ]] || exit 1
</span></span></span><span style=display:flex><span><span style=color:#b44;font-style:italic>          ordinal=${BASH_REMATCH[1]}
</span></span></span><span style=display:flex><span><span style=color:#b44;font-style:italic>          [[ $ordinal -eq 0 ]] &amp;&amp; exit 0
</span></span></span><span style=display:flex><span><span style=color:#b44;font-style:italic>          # Clone data from previous peer.
</span></span></span><span style=display:flex><span><span style=color:#b44;font-style:italic>          ncat --recv-only mysql-$(($ordinal-1)).mysql 3307 | xbstream -x -C /var/lib/mysql
</span></span></span><span style=display:flex><span><span style=color:#b44;font-style:italic>          # Prepare the backup.
</span></span></span><span style=display:flex><span><span style=color:#b44;font-style:italic>          xtrabackup --prepare --target-dir=/var/lib/mysql</span><span style=color:#bbb>          
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>volumeMounts</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>data<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>mountPath</span>:<span style=color:#bbb> </span>/var/lib/mysql<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>subPath</span>:<span style=color:#bbb> </span>mysql<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>conf<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>mountPath</span>:<span style=color:#bbb> </span>/etc/mysql/conf.d<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>mysql<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>mysql:5.7<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>env</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>MYSQL_ALLOW_EMPTY_PASSWORD<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>value</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;1&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>ports</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>mysql<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>containerPort</span>:<span style=color:#bbb> </span><span style=color:#666>3306</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>volumeMounts</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>data<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>mountPath</span>:<span style=color:#bbb> </span>/var/lib/mysql<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>subPath</span>:<span style=color:#bbb> </span>mysql<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>conf<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>mountPath</span>:<span style=color:#bbb> </span>/etc/mysql/conf.d<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>resources</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>requests</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>            </span><span style=color:green;font-weight:700>cpu</span>:<span style=color:#bbb> </span>500m<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>            </span><span style=color:green;font-weight:700>memory</span>:<span style=color:#bbb> </span>1Gi<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>livenessProbe</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>exec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>            </span><span style=color:green;font-weight:700>command</span>:<span style=color:#bbb> </span>[<span style=color:#b44>&#34;mysqladmin&#34;</span>,<span style=color:#bbb> </span><span style=color:#b44>&#34;ping&#34;</span>]<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>initialDelaySeconds</span>:<span style=color:#bbb> </span><span style=color:#666>30</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>periodSeconds</span>:<span style=color:#bbb> </span><span style=color:#666>10</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>timeoutSeconds</span>:<span style=color:#bbb> </span><span style=color:#666>5</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>readinessProbe</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>exec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>            </span><span style=color:#080;font-style:italic># Check we can execute queries over TCP (skip-networking is off).</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>            </span><span style=color:green;font-weight:700>command</span>:<span style=color:#bbb> </span>[<span style=color:#b44>&#34;mysql&#34;</span>,<span style=color:#bbb> </span><span style=color:#b44>&#34;-h&#34;</span>,<span style=color:#bbb> </span><span style=color:#b44>&#34;127.0.0.1&#34;</span>,<span style=color:#bbb> </span><span style=color:#b44>&#34;-e&#34;</span>,<span style=color:#bbb> </span><span style=color:#b44>&#34;SELECT 1&#34;</span>]<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>initialDelaySeconds</span>:<span style=color:#bbb> </span><span style=color:#666>5</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>periodSeconds</span>:<span style=color:#bbb> </span><span style=color:#666>2</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>timeoutSeconds</span>:<span style=color:#bbb> </span><span style=color:#666>1</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>xtrabackup<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>gcr.io/google-samples/xtrabackup:1.0<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>ports</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>xtrabackup<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>containerPort</span>:<span style=color:#bbb> </span><span style=color:#666>3307</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>command</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span>- bash<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span>- <span style=color:#b44>&#34;-c&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span>- |<span style=color:#b44;font-style:italic>
</span></span></span><span style=display:flex><span><span style=color:#b44;font-style:italic>          set -ex
</span></span></span><span style=display:flex><span><span style=color:#b44;font-style:italic>          cd /var/lib/mysql
</span></span></span><span style=display:flex><span><span style=color:#b44;font-style:italic>
</span></span></span><span style=display:flex><span><span style=color:#b44;font-style:italic>          # Determine binlog position of cloned data, if any.
</span></span></span><span style=display:flex><span><span style=color:#b44;font-style:italic>          if [[ -f xtrabackup_slave_info &amp;&amp; &#34;x$(&lt;xtrabackup_slave_info)&#34; != &#34;x&#34; ]]; then
</span></span></span><span style=display:flex><span><span style=color:#b44;font-style:italic>            # XtraBackup already generated a partial &#34;CHANGE MASTER TO&#34; query
</span></span></span><span style=display:flex><span><span style=color:#b44;font-style:italic>            # because we&#39;re cloning from an existing replica. (Need to remove the tailing semicolon!)
</span></span></span><span style=display:flex><span><span style=color:#b44;font-style:italic>            cat xtrabackup_slave_info | sed -E &#39;s/;$//g&#39; &gt; change_master_to.sql.in
</span></span></span><span style=display:flex><span><span style=color:#b44;font-style:italic>            # Ignore xtrabackup_binlog_info in this case (it&#39;s useless).
</span></span></span><span style=display:flex><span><span style=color:#b44;font-style:italic>            rm -f xtrabackup_slave_info xtrabackup_binlog_info
</span></span></span><span style=display:flex><span><span style=color:#b44;font-style:italic>          elif [[ -f xtrabackup_binlog_info ]]; then
</span></span></span><span style=display:flex><span><span style=color:#b44;font-style:italic>            # We&#39;re cloning directly from primary. Parse binlog position.
</span></span></span><span style=display:flex><span><span style=color:#b44;font-style:italic>            [[ `cat xtrabackup_binlog_info` =~ ^(.*?)[[:space:]]+(.*?)$ ]] || exit 1
</span></span></span><span style=display:flex><span><span style=color:#b44;font-style:italic>            rm -f xtrabackup_binlog_info xtrabackup_slave_info
</span></span></span><span style=display:flex><span><span style=color:#b44;font-style:italic>            echo &#34;CHANGE MASTER TO MASTER_LOG_FILE=&#39;${BASH_REMATCH[1]}&#39;,\
</span></span></span><span style=display:flex><span><span style=color:#b44;font-style:italic>                  MASTER_LOG_POS=${BASH_REMATCH[2]}&#34; &gt; change_master_to.sql.in
</span></span></span><span style=display:flex><span><span style=color:#b44;font-style:italic>          fi
</span></span></span><span style=display:flex><span><span style=color:#b44;font-style:italic>
</span></span></span><span style=display:flex><span><span style=color:#b44;font-style:italic>          # Check if we need to complete a clone by starting replication.
</span></span></span><span style=display:flex><span><span style=color:#b44;font-style:italic>          if [[ -f change_master_to.sql.in ]]; then
</span></span></span><span style=display:flex><span><span style=color:#b44;font-style:italic>            echo &#34;Waiting for mysqld to be ready (accepting connections)&#34;
</span></span></span><span style=display:flex><span><span style=color:#b44;font-style:italic>            until mysql -h 127.0.0.1 -e &#34;SELECT 1&#34;; do sleep 1; done
</span></span></span><span style=display:flex><span><span style=color:#b44;font-style:italic>
</span></span></span><span style=display:flex><span><span style=color:#b44;font-style:italic>            echo &#34;Initializing replication from clone position&#34;
</span></span></span><span style=display:flex><span><span style=color:#b44;font-style:italic>            mysql -h 127.0.0.1 \
</span></span></span><span style=display:flex><span><span style=color:#b44;font-style:italic>                  -e &#34;$(&lt;change_master_to.sql.in), \
</span></span></span><span style=display:flex><span><span style=color:#b44;font-style:italic>                          MASTER_HOST=&#39;mysql-0.mysql&#39;, \
</span></span></span><span style=display:flex><span><span style=color:#b44;font-style:italic>                          MASTER_USER=&#39;root&#39;, \
</span></span></span><span style=display:flex><span><span style=color:#b44;font-style:italic>                          MASTER_PASSWORD=&#39;&#39;, \
</span></span></span><span style=display:flex><span><span style=color:#b44;font-style:italic>                          MASTER_CONNECT_RETRY=10; \
</span></span></span><span style=display:flex><span><span style=color:#b44;font-style:italic>                        START SLAVE;&#34; || exit 1
</span></span></span><span style=display:flex><span><span style=color:#b44;font-style:italic>            # In case of container restart, attempt this at-most-once.
</span></span></span><span style=display:flex><span><span style=color:#b44;font-style:italic>            mv change_master_to.sql.in change_master_to.sql.orig
</span></span></span><span style=display:flex><span><span style=color:#b44;font-style:italic>          fi
</span></span></span><span style=display:flex><span><span style=color:#b44;font-style:italic>
</span></span></span><span style=display:flex><span><span style=color:#b44;font-style:italic>          # Start a server to send backups when requested by peers.
</span></span></span><span style=display:flex><span><span style=color:#b44;font-style:italic>          exec ncat --listen --keep-open --send-only --max-conns=1 3307 -c \
</span></span></span><span style=display:flex><span><span style=color:#b44;font-style:italic>            &#34;xtrabackup --backup --slave-info --stream=xbstream --host=127.0.0.1 --user=root&#34;</span><span style=color:#bbb>          
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>volumeMounts</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>data<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>mountPath</span>:<span style=color:#bbb> </span>/var/lib/mysql<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>subPath</span>:<span style=color:#bbb> </span>mysql<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>conf<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>mountPath</span>:<span style=color:#bbb> </span>/etc/mysql/conf.d<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>resources</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>requests</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>            </span><span style=color:green;font-weight:700>cpu</span>:<span style=color:#bbb> </span>100m<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>            </span><span style=color:green;font-weight:700>memory</span>:<span style=color:#bbb> </span>100Mi<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>volumes</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>conf<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>emptyDir</span>:<span style=color:#bbb> </span>{}<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>config-map<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>configMap</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>mysql<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>volumeClaimTemplates</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>data<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>accessModes</span>:<span style=color:#bbb> </span>[<span style=color:#b44>&#34;ReadWriteOnce&#34;</span>]<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>resources</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>requests</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>storage</span>:<span style=color:#bbb> </span>10Gi<span style=color:#bbb>
</span></span></span></code></pre></div></div></div><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl apply -f https://k8s.io/examples/application/mysql/mysql-statefulset.yaml
</span></span></code></pre></div><p>You can watch the startup progress by running:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get pods -l <span style=color:#b8860b>app</span><span style=color:#666>=</span>mysql --watch
</span></span></code></pre></div><p>After a while, you should see all 3 Pods become <code>Running</code>:</p><pre tabindex=0><code>NAME      READY     STATUS    RESTARTS   AGE
mysql-0   2/2       Running   0          2m
mysql-1   2/2       Running   0          1m
mysql-2   2/2       Running   0          1m
</code></pre><p>Press <strong>Ctrl+C</strong> to cancel the watch.</p><div class="alert alert-info note callout" role=alert><strong>Note:</strong> If you don't see any progress, make sure you have a dynamic PersistentVolume
provisioner enabled, as mentioned in the <a href=#before-you-begin>prerequisites</a>.</div><p>This manifest uses a variety of techniques for managing stateful Pods as part of
a StatefulSet. The next section highlights some of these techniques to explain
what happens as the StatefulSet creates Pods.</p><h2 id=understanding-stateful-pod-initialization>Understanding stateful Pod initialization</h2><p>The StatefulSet controller starts Pods one at a time, in order by their
ordinal index.
It waits until each Pod reports being Ready before starting the next one.</p><p>In addition, the controller assigns each Pod a unique, stable name of the form
<code>&lt;statefulset-name>-&lt;ordinal-index></code>, which results in Pods named <code>mysql-0</code>,
<code>mysql-1</code>, and <code>mysql-2</code>.</p><p>The Pod template in the above StatefulSet manifest takes advantage of these
properties to perform orderly startup of MySQL replication.</p><h3 id=generating-configuration>Generating configuration</h3><p>Before starting any of the containers in the Pod spec, the Pod first runs any
<a href=/docs/concepts/workloads/pods/init-containers/>init containers</a>
in the order defined.</p><p>The first init container, named <code>init-mysql</code>, generates special MySQL config
files based on the ordinal index.</p><p>The script determines its own ordinal index by extracting it from the end of
the Pod name, which is returned by the <code>hostname</code> command.
Then it saves the ordinal (with a numeric offset to avoid reserved values)
into a file called <code>server-id.cnf</code> in the MySQL <code>conf.d</code> directory.
This translates the unique, stable identity provided by the StatefulSet
into the domain of MySQL server IDs, which require the same properties.</p><p>The script in the <code>init-mysql</code> container also applies either <code>primary.cnf</code> or
<code>replica.cnf</code> from the ConfigMap by copying the contents into <code>conf.d</code>.
Because the example topology consists of a single primary MySQL server and any number of
replicas, the script assigns ordinal <code>0</code> to be the primary server, and everyone
else to be replicas.
Combined with the StatefulSet controller's
<a href=/docs/concepts/workloads/controllers/statefulset/#deployment-and-scaling-guarantees>deployment order guarantee</a>,
this ensures the primary MySQL server is Ready before creating replicas, so they can begin
replicating.</p><h3 id=cloning-existing-data>Cloning existing data</h3><p>In general, when a new Pod joins the set as a replica, it must assume the primary MySQL
server might already have data on it. It also must assume that the replication
logs might not go all the way back to the beginning of time.
These conservative assumptions are the key to allow a running StatefulSet
to scale up and down over time, rather than being fixed at its initial size.</p><p>The second init container, named <code>clone-mysql</code>, performs a clone operation on
a replica Pod the first time it starts up on an empty PersistentVolume.
That means it copies all existing data from another running Pod,
so its local state is consistent enough to begin replicating from the primary server.</p><p>MySQL itself does not provide a mechanism to do this, so the example uses a
popular open-source tool called Percona XtraBackup.
During the clone, the source MySQL server might suffer reduced performance.
To minimize impact on the primary MySQL server, the script instructs each Pod to clone
from the Pod whose ordinal index is one lower.
This works because the StatefulSet controller always ensures Pod <code>N</code> is
Ready before starting Pod <code>N+1</code>.</p><h3 id=starting-replication>Starting replication</h3><p>After the init containers complete successfully, the regular containers run.
The MySQL Pods consist of a <code>mysql</code> container that runs the actual <code>mysqld</code>
server, and an <code>xtrabackup</code> container that acts as a
<a href=/blog/2015/06/the-distributed-system-toolkit-patterns>sidecar</a>.</p><p>The <code>xtrabackup</code> sidecar looks at the cloned data files and determines if
it's necessary to initialize MySQL replication on the replica.
If so, it waits for <code>mysqld</code> to be ready and then executes the
<code>CHANGE MASTER TO</code> and <code>START SLAVE</code> commands with replication parameters
extracted from the XtraBackup clone files.</p><p>Once a replica begins replication, it remembers its primary MySQL server and
reconnects automatically if the server restarts or the connection dies.
Also, because replicas look for the primary server at its stable DNS name
(<code>mysql-0.mysql</code>), they automatically find the primary server even if it gets a new
Pod IP due to being rescheduled.</p><p>Lastly, after starting replication, the <code>xtrabackup</code> container listens for
connections from other Pods requesting a data clone.
This server remains up indefinitely in case the StatefulSet scales up, or in
case the next Pod loses its PersistentVolumeClaim and needs to redo the clone.</p><h2 id=sending-client-traffic>Sending client traffic</h2><p>You can send test queries to the primary MySQL server (hostname <code>mysql-0.mysql</code>)
by running a temporary container with the <code>mysql:5.7</code> image and running the
<code>mysql</code> client binary.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl run mysql-client --image<span style=color:#666>=</span>mysql:5.7 -i --rm --restart<span style=color:#666>=</span>Never --<span style=color:#b62;font-weight:700>\
</span></span></span><span style=display:flex><span><span style=color:#b62;font-weight:700></span>  mysql -h mysql-0.mysql <span style=color:#b44>&lt;&lt;EOF
</span></span></span><span style=display:flex><span><span style=color:#b44>CREATE DATABASE test;
</span></span></span><span style=display:flex><span><span style=color:#b44>CREATE TABLE test.messages (message VARCHAR(250));
</span></span></span><span style=display:flex><span><span style=color:#b44>INSERT INTO test.messages VALUES (&#39;hello&#39;);
</span></span></span><span style=display:flex><span><span style=color:#b44>EOF</span>
</span></span></code></pre></div><p>Use the hostname <code>mysql-read</code> to send test queries to any server that reports
being Ready:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl run mysql-client --image<span style=color:#666>=</span>mysql:5.7 -i -t --rm --restart<span style=color:#666>=</span>Never --<span style=color:#b62;font-weight:700>\
</span></span></span><span style=display:flex><span><span style=color:#b62;font-weight:700></span>  mysql -h mysql-read -e <span style=color:#b44>&#34;SELECT * FROM test.messages&#34;</span>
</span></span></code></pre></div><p>You should get output like this:</p><pre tabindex=0><code>Waiting for pod default/mysql-client to be running, status is Pending, pod ready: false
+---------+
| message |
+---------+
| hello   |
+---------+
pod &#34;mysql-client&#34; deleted
</code></pre><p>To demonstrate that the <code>mysql-read</code> Service distributes connections across
servers, you can run <code>SELECT @@server_id</code> in a loop:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl run mysql-client-loop --image<span style=color:#666>=</span>mysql:5.7 -i -t --rm --restart<span style=color:#666>=</span>Never --<span style=color:#b62;font-weight:700>\
</span></span></span><span style=display:flex><span><span style=color:#b62;font-weight:700></span>  bash -ic <span style=color:#b44>&#34;while sleep 1; do mysql -h mysql-read -e &#39;SELECT @@server_id,NOW()&#39;; done&#34;</span>
</span></span></code></pre></div><p>You should see the reported <code>@@server_id</code> change randomly, because a different
endpoint might be selected upon each connection attempt:</p><pre tabindex=0><code>+-------------+---------------------+
| @@server_id | NOW()               |
+-------------+---------------------+
|         100 | 2006-01-02 15:04:05 |
+-------------+---------------------+
+-------------+---------------------+
| @@server_id | NOW()               |
+-------------+---------------------+
|         102 | 2006-01-02 15:04:06 |
+-------------+---------------------+
+-------------+---------------------+
| @@server_id | NOW()               |
+-------------+---------------------+
|         101 | 2006-01-02 15:04:07 |
+-------------+---------------------+
</code></pre><p>You can press <strong>Ctrl+C</strong> when you want to stop the loop, but it's useful to keep
it running in another window so you can see the effects of the following steps.</p><h2 id=simulate-pod-and-node-downtime>Simulate Pod and Node failure</h2><p>To demonstrate the increased availability of reading from the pool of replicas
instead of a single server, keep the <code>SELECT @@server_id</code> loop from above
running while you force a Pod out of the Ready state.</p><h3 id=break-the-readiness-probe>Break the Readiness probe</h3><p>The <a href=/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/#define-readiness-probes>readiness probe</a>
for the <code>mysql</code> container runs the command <code>mysql -h 127.0.0.1 -e 'SELECT 1'</code>
to make sure the server is up and able to execute queries.</p><p>One way to force this readiness probe to fail is to break that command:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl <span style=color:#a2f>exec</span> mysql-2 -c mysql -- mv /usr/bin/mysql /usr/bin/mysql.off
</span></span></code></pre></div><p>This reaches into the actual container's filesystem for Pod <code>mysql-2</code> and
renames the <code>mysql</code> command so the readiness probe can't find it.
After a few seconds, the Pod should report one of its containers as not Ready,
which you can check by running:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get pod mysql-2
</span></span></code></pre></div><p>Look for <code>1/2</code> in the <code>READY</code> column:</p><pre tabindex=0><code>NAME      READY     STATUS    RESTARTS   AGE
mysql-2   1/2       Running   0          3m
</code></pre><p>At this point, you should see your <code>SELECT @@server_id</code> loop continue to run,
although it never reports <code>102</code> anymore.
Recall that the <code>init-mysql</code> script defined <code>server-id</code> as <code>100 + $ordinal</code>,
so server ID <code>102</code> corresponds to Pod <code>mysql-2</code>.</p><p>Now repair the Pod and it should reappear in the loop output
after a few seconds:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl <span style=color:#a2f>exec</span> mysql-2 -c mysql -- mv /usr/bin/mysql.off /usr/bin/mysql
</span></span></code></pre></div><h3 id=delete-pods>Delete Pods</h3><p>The StatefulSet also recreates Pods if they're deleted, similar to what a
ReplicaSet does for stateless Pods.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl delete pod mysql-2
</span></span></code></pre></div><p>The StatefulSet controller notices that no <code>mysql-2</code> Pod exists anymore,
and creates a new one with the same name and linked to the same
PersistentVolumeClaim.
You should see server ID <code>102</code> disappear from the loop output for a while
and then return on its own.</p><h3 id=drain-a-node>Drain a Node</h3><p>If your Kubernetes cluster has multiple Nodes, you can simulate Node downtime
(such as when Nodes are upgraded) by issuing a
<a href=/docs/reference/generated/kubectl/kubectl-commands/#drain>drain</a>.</p><p>First determine which Node one of the MySQL Pods is on:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get pod mysql-2 -o wide
</span></span></code></pre></div><p>The Node name should show up in the last column:</p><pre tabindex=0><code>NAME      READY     STATUS    RESTARTS   AGE       IP            NODE
mysql-2   2/2       Running   0          15m       10.244.5.27   kubernetes-node-9l2t
</code></pre><p>Then, drain the Node by running the following command, which cordons it so
no new Pods may schedule there, and then evicts any existing Pods.
Replace <code>&lt;node-name></code> with the name of the Node you found in the last step.</p><div class="alert alert-warning caution callout" role=alert><strong>Caution:</strong> Draining a Node can impact other workloads and applications
running on the same node. Only perform the following step in a test
cluster.</div><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span><span style=color:#080;font-style:italic># See above advice about impact on other workloads</span>
</span></span><span style=display:flex><span>kubectl drain &lt;node-name&gt; --force --delete-emptydir-data --ignore-daemonsets
</span></span></code></pre></div><p>Now you can watch as the Pod reschedules on a different Node:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get pod mysql-2 -o wide --watch
</span></span></code></pre></div><p>It should look something like this:</p><pre tabindex=0><code>NAME      READY   STATUS          RESTARTS   AGE       IP            NODE
mysql-2   2/2     Terminating     0          15m       10.244.1.56   kubernetes-node-9l2t
[...]
mysql-2   0/2     Pending         0          0s        &lt;none&gt;        kubernetes-node-fjlm
mysql-2   0/2     Init:0/2        0          0s        &lt;none&gt;        kubernetes-node-fjlm
mysql-2   0/2     Init:1/2        0          20s       10.244.5.32   kubernetes-node-fjlm
mysql-2   0/2     PodInitializing 0          21s       10.244.5.32   kubernetes-node-fjlm
mysql-2   1/2     Running         0          22s       10.244.5.32   kubernetes-node-fjlm
mysql-2   2/2     Running         0          30s       10.244.5.32   kubernetes-node-fjlm
</code></pre><p>And again, you should see server ID <code>102</code> disappear from the
<code>SELECT @@server_id</code> loop output for a while and then return.</p><p>Now uncordon the Node to return it to a normal state:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl uncordon &lt;node-name&gt;
</span></span></code></pre></div><h2 id=scaling-the-number-of-replicas>Scaling the number of replicas</h2><p>When you use MySQL replication, you can scale your read query capacity by
adding replicas.
For a StatefulSet, you can achieve this with a single command:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl scale statefulset mysql  --replicas<span style=color:#666>=</span><span style=color:#666>5</span>
</span></span></code></pre></div><p>Watch the new Pods come up by running:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get pods -l <span style=color:#b8860b>app</span><span style=color:#666>=</span>mysql --watch
</span></span></code></pre></div><p>Once they're up, you should see server IDs <code>103</code> and <code>104</code> start appearing in
the <code>SELECT @@server_id</code> loop output.</p><p>You can also verify that these new servers have the data you added before they
existed:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl run mysql-client --image<span style=color:#666>=</span>mysql:5.7 -i -t --rm --restart<span style=color:#666>=</span>Never --<span style=color:#b62;font-weight:700>\
</span></span></span><span style=display:flex><span><span style=color:#b62;font-weight:700></span>  mysql -h mysql-3.mysql -e <span style=color:#b44>&#34;SELECT * FROM test.messages&#34;</span>
</span></span></code></pre></div><pre tabindex=0><code>Waiting for pod default/mysql-client to be running, status is Pending, pod ready: false
+---------+
| message |
+---------+
| hello   |
+---------+
pod &#34;mysql-client&#34; deleted
</code></pre><p>Scaling back down is also seamless:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl scale statefulset mysql --replicas<span style=color:#666>=</span><span style=color:#666>3</span>
</span></span></code></pre></div><div class="alert alert-info note callout" role=alert><strong>Note:</strong><p>Although scaling up creates new PersistentVolumeClaims
automatically, scaling down does not automatically delete these PVCs.</p><p>This gives you the choice to keep those initialized PVCs around to make
scaling back up quicker, or to extract data before deleting them.</p></div><p>You can see this by running:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get pvc -l <span style=color:#b8860b>app</span><span style=color:#666>=</span>mysql
</span></span></code></pre></div><p>Which shows that all 5 PVCs still exist, despite having scaled the
StatefulSet down to 3:</p><pre tabindex=0><code>NAME           STATUS    VOLUME                                     CAPACITY   ACCESSMODES   AGE
data-mysql-0   Bound     pvc-8acbf5dc-b103-11e6-93fa-42010a800002   10Gi       RWO           20m
data-mysql-1   Bound     pvc-8ad39820-b103-11e6-93fa-42010a800002   10Gi       RWO           20m
data-mysql-2   Bound     pvc-8ad69a6d-b103-11e6-93fa-42010a800002   10Gi       RWO           20m
data-mysql-3   Bound     pvc-50043c45-b1c5-11e6-93fa-42010a800002   10Gi       RWO           2m
data-mysql-4   Bound     pvc-500a9957-b1c5-11e6-93fa-42010a800002   10Gi       RWO           2m
</code></pre><p>If you don't intend to reuse the extra PVCs, you can delete them:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl delete pvc data-mysql-3
</span></span><span style=display:flex><span>kubectl delete pvc data-mysql-4
</span></span></code></pre></div><h2 id=cleaning-up>Cleaning up</h2><ol><li><p>Cancel the <code>SELECT @@server_id</code> loop by pressing <strong>Ctrl+C</strong> in its terminal,
or running the following from another terminal:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl delete pod mysql-client-loop --now
</span></span></code></pre></div></li><li><p>Delete the StatefulSet. This also begins terminating the Pods.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl delete statefulset mysql
</span></span></code></pre></div></li><li><p>Verify that the Pods disappear.
They might take some time to finish terminating.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get pods -l <span style=color:#b8860b>app</span><span style=color:#666>=</span>mysql
</span></span></code></pre></div><p>You'll know the Pods have terminated when the above returns:</p><pre tabindex=0><code>No resources found.
</code></pre></li><li><p>Delete the ConfigMap, Services, and PersistentVolumeClaims.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl delete configmap,service,pvc -l <span style=color:#b8860b>app</span><span style=color:#666>=</span>mysql
</span></span></code></pre></div></li><li><p>If you manually provisioned PersistentVolumes, you also need to manually
delete them, as well as release the underlying resources.
If you used a dynamic provisioner, it automatically deletes the
PersistentVolumes when it sees that you deleted the PersistentVolumeClaims.
Some dynamic provisioners (such as those for EBS and PD) also release the
underlying resources upon deleting the PersistentVolumes.</p></li></ol><h2 id=what-s-next>What's next</h2><ul><li>Learn more about <a href=/docs/tasks/run-application/scale-stateful-set/>scaling a StatefulSet</a>.</li><li>Learn more about <a href=/docs/tasks/debug/debug-application/debug-statefulset/>debugging a StatefulSet</a>.</li><li>Learn more about <a href=/docs/tasks/run-application/delete-stateful-set/>deleting a StatefulSet</a>.</li><li>Learn more about <a href=/docs/tasks/run-application/force-delete-stateful-set-pod/>force deleting StatefulSet Pods</a>.</li><li>Look in the <a href=https://artifacthub.io/>Helm Charts repository</a>
for other stateful application examples.</li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-7a9b5779e228083ba3fdeaf414fe704e>4 - Scale a StatefulSet</h1><p>This task shows how to scale a StatefulSet. Scaling a StatefulSet refers to increasing or decreasing the number of replicas.</p><h2 id=before-you-begin>Before you begin</h2><ul><li><p>StatefulSets are only available in Kubernetes version 1.5 or later.
To check your version of Kubernetes, run <code>kubectl version</code>.</p></li><li><p>Not all stateful applications scale nicely. If you are unsure about whether to scale your StatefulSets, see <a href=/docs/concepts/workloads/controllers/statefulset/>StatefulSet concepts</a> or <a href=/docs/tutorials/stateful-application/basic-stateful-set/>StatefulSet tutorial</a> for further information.</p></li><li><p>You should perform scaling only when you are confident that your stateful application
cluster is completely healthy.</p></li></ul><h2 id=scaling-statefulsets>Scaling StatefulSets</h2><h3 id=use-kubectl-to-scale-statefulsets>Use kubectl to scale StatefulSets</h3><p>First, find the StatefulSet you want to scale.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get statefulsets &lt;stateful-set-name&gt;
</span></span></code></pre></div><p>Change the number of replicas of your StatefulSet:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl scale statefulsets &lt;stateful-set-name&gt; --replicas<span style=color:#666>=</span>&lt;new-replicas&gt;
</span></span></code></pre></div><h3 id=make-in-place-updates-on-your-statefulsets>Make in-place updates on your StatefulSets</h3><p>Alternatively, you can do <a href=/docs/concepts/cluster-administration/manage-deployment/#in-place-updates-of-resources>in-place updates</a> on your StatefulSets.</p><p>If your StatefulSet was initially created with <code>kubectl apply</code>,
update <code>.spec.replicas</code> of the StatefulSet manifests, and then do a <code>kubectl apply</code>:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl apply -f &lt;stateful-set-file-updated&gt;
</span></span></code></pre></div><p>Otherwise, edit that field with <code>kubectl edit</code>:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl edit statefulsets &lt;stateful-set-name&gt;
</span></span></code></pre></div><p>Or use <code>kubectl patch</code>:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl patch statefulsets &lt;stateful-set-name&gt; -p <span style=color:#b44>&#39;{&#34;spec&#34;:{&#34;replicas&#34;:&lt;new-replicas&gt;}}&#39;</span>
</span></span></code></pre></div><h2 id=troubleshooting>Troubleshooting</h2><h3 id=scaling-down-does-not-work-right>Scaling down does not work right</h3><p>You cannot scale down a StatefulSet when any of the stateful Pods it manages is unhealthy. Scaling down only takes place
after those stateful Pods become running and ready.</p><p>If spec.replicas > 1, Kubernetes cannot determine the reason for an unhealthy Pod. It might be the result of a permanent fault or of a transient fault. A transient fault can be caused by a restart required by upgrading or maintenance.</p><p>If the Pod is unhealthy due to a permanent fault, scaling
without correcting the fault may lead to a state where the StatefulSet membership
drops below a certain minimum number of replicas that are needed to function
correctly. This may cause your StatefulSet to become unavailable.</p><p>If the Pod is unhealthy due to a transient fault and the Pod might become available again,
the transient error may interfere with your scale-up or scale-down operation. Some distributed
databases have issues when nodes join and leave at the same time. It is better
to reason about scaling operations at the application level in these cases, and
perform scaling only when you are sure that your stateful application cluster is
completely healthy.</p><h2 id=what-s-next>What's next</h2><ul><li>Learn more about <a href=/docs/tasks/run-application/delete-stateful-set/>deleting a StatefulSet</a>.</li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-c43537b0ee1da992ecb7488f87e6c934>5 - Delete a StatefulSet</h1><p>This task shows you how to delete a <a class=glossary-tooltip title='Manages deployment and scaling of a set of Pods, with durable storage and persistent identifiers for each Pod.' data-toggle=tooltip data-placement=top href=/docs/concepts/workloads/controllers/statefulset/ target=_blank aria-label=StatefulSet>StatefulSet</a>.</p><h2 id=before-you-begin>Before you begin</h2><ul><li>This task assumes you have an application running on your cluster represented by a StatefulSet.</li></ul><h2 id=deleting-a-statefulset>Deleting a StatefulSet</h2><p>You can delete a StatefulSet in the same way you delete other resources in Kubernetes: use the <code>kubectl delete</code> command, and specify the StatefulSet either by file or by name.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl delete -f &lt;file.yaml&gt;
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl delete statefulsets &lt;statefulset-name&gt;
</span></span></code></pre></div><p>You may need to delete the associated headless service separately after the StatefulSet itself is deleted.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl delete service &lt;service-name&gt;
</span></span></code></pre></div><p>When deleting a StatefulSet through <code>kubectl</code>, the StatefulSet scales down to 0. All Pods that are part of this workload are also deleted. If you want to delete only the StatefulSet and not the Pods, use <code>--cascade=orphan</code>.
For example:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl delete -f &lt;file.yaml&gt; --cascade<span style=color:#666>=</span>orphan
</span></span></code></pre></div><p>By passing <code>--cascade=orphan</code> to <code>kubectl delete</code>, the Pods managed by the StatefulSet are left behind even after the StatefulSet object itself is deleted. If the pods have a label <code>app.kubernetes.io/name=MyApp</code>, you can then delete them as follows:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl delete pods -l app.kubernetes.io/name<span style=color:#666>=</span>MyApp
</span></span></code></pre></div><h3 id=persistent-volumes>Persistent Volumes</h3><p>Deleting the Pods in a StatefulSet will not delete the associated volumes. This is to ensure that you have the chance to copy data off the volume before deleting it. Deleting the PVC after the pods have terminated might trigger deletion of the backing Persistent Volumes depending on the storage class and reclaim policy. You should never assume ability to access a volume after claim deletion.</p><div class="alert alert-info note callout" role=alert><strong>Note:</strong> Use caution when deleting a PVC, as it may lead to data loss.</div><h3 id=complete-deletion-of-a-statefulset>Complete deletion of a StatefulSet</h3><p>To delete everything in a StatefulSet, including the associated pods, you can run a series of commands similar to the following:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span><span style=color:#b8860b>grace</span><span style=color:#666>=</span><span style=color:#a2f;font-weight:700>$(</span>kubectl get pods &lt;stateful-set-pod&gt; --template <span style=color:#b44>&#39;{{.spec.terminationGracePeriodSeconds}}&#39;</span><span style=color:#a2f;font-weight:700>)</span>
</span></span><span style=display:flex><span>kubectl delete statefulset -l app.kubernetes.io/name<span style=color:#666>=</span>MyApp
</span></span><span style=display:flex><span>sleep <span style=color:#b8860b>$grace</span>
</span></span><span style=display:flex><span>kubectl delete pvc -l app.kubernetes.io/name<span style=color:#666>=</span>MyApp
</span></span></code></pre></div><p>In the example above, the Pods have the label <code>app.kubernetes.io/name=MyApp</code>; substitute your own label as appropriate.</p><h3 id=force-deletion-of-statefulset-pods>Force deletion of StatefulSet pods</h3><p>If you find that some pods in your StatefulSet are stuck in the 'Terminating' or 'Unknown' states for an extended period of time, you may need to manually intervene to forcefully delete the pods from the apiserver. This is a potentially dangerous task. Refer to <a href=/docs/tasks/run-application/force-delete-stateful-set-pod/>Force Delete StatefulSet Pods</a> for details.</p><h2 id=what-s-next>What's next</h2><p>Learn more about <a href=/docs/tasks/run-application/force-delete-stateful-set-pod/>force deleting StatefulSet Pods</a>.</p></div><div class=td-content style=page-break-before:always><h1 id=pg-f5f2f7a74377a9d45325c5253353fa8f>6 - Force Delete StatefulSet Pods</h1><p>This page shows how to delete Pods which are part of a <a class=glossary-tooltip title='Manages deployment and scaling of a set of Pods, with durable storage and persistent identifiers for each Pod.' data-toggle=tooltip data-placement=top href=/docs/concepts/workloads/controllers/statefulset/ target=_blank aria-label='stateful set'>stateful set</a>, and explains the considerations to keep in mind when doing so.</p><h2 id=before-you-begin>Before you begin</h2><ul><li>This is a fairly advanced task and has the potential to violate some of the properties inherent to StatefulSet.</li><li>Before proceeding, make yourself familiar with the considerations enumerated below.</li></ul><h2 id=statefulset-considerations>StatefulSet considerations</h2><p>In normal operation of a StatefulSet, there is <strong>never</strong> a need to force delete a StatefulSet Pod. The <a href=/docs/concepts/workloads/controllers/statefulset/>StatefulSet controller</a> is responsible for creating, scaling and deleting members of the StatefulSet. It tries to ensure that the specified number of Pods from ordinal 0 through N-1 are alive and ready. StatefulSet ensures that, at any time, there is at most one Pod with a given identity running in a cluster. This is referred to as <em>at most one</em> semantics provided by a StatefulSet.</p><p>Manual force deletion should be undertaken with caution, as it has the potential to violate the at most one semantics inherent to StatefulSet. StatefulSets may be used to run distributed and clustered applications which have a need for a stable network identity and stable storage. These applications often have configuration which relies on an ensemble of a fixed number of members with fixed identities. Having multiple members with the same identity can be disastrous and may lead to data loss (e.g. split brain scenario in quorum-based systems).</p><h2 id=delete-pods>Delete Pods</h2><p>You can perform a graceful pod deletion with the following command:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl delete pods &lt;pod&gt;
</span></span></code></pre></div><p>For the above to lead to graceful termination, the Pod <strong>must not</strong> specify a
<code>pod.Spec.TerminationGracePeriodSeconds</code> of 0. The practice of setting a
<code>pod.Spec.TerminationGracePeriodSeconds</code> of 0 seconds is unsafe and strongly discouraged
for StatefulSet Pods. Graceful deletion is safe and will ensure that the Pod
<a href=/docs/concepts/workloads/pods/pod-lifecycle/#pod-termination>shuts down gracefully</a>
before the kubelet deletes the name from the apiserver.</p><p>A Pod is not deleted automatically when a node is unreachable.
The Pods running on an unreachable Node enter the 'Terminating' or 'Unknown' state after a
<a href=/docs/concepts/architecture/nodes/#condition>timeout</a>.
Pods may also enter these states when the user attempts graceful deletion of a Pod
on an unreachable Node.
The only ways in which a Pod in such a state can be removed from the apiserver are as follows:</p><ul><li>The Node object is deleted (either by you, or by the <a href=/docs/concepts/architecture/nodes/#node-controller>Node Controller</a>).</li><li>The kubelet on the unresponsive Node starts responding, kills the Pod and removes the entry from the apiserver.</li><li>Force deletion of the Pod by the user.</li></ul><p>The recommended best practice is to use the first or second approach. If a Node is confirmed to be dead (e.g. permanently disconnected from the network, powered down, etc), then delete the Node object. If the Node is suffering from a network partition, then try to resolve this or wait for it to resolve. When the partition heals, the kubelet will complete the deletion of the Pod and free up its name in the apiserver.</p><p>Normally, the system completes the deletion once the Pod is no longer running on a Node, or the Node is deleted by an administrator. You may override this by force deleting the Pod.</p><h3 id=force-deletion>Force Deletion</h3><p>Force deletions <strong>do not</strong> wait for confirmation from the kubelet that the Pod has been terminated. Irrespective of whether a force deletion is successful in killing a Pod, it will immediately free up the name from the apiserver. This would let the StatefulSet controller create a replacement Pod with that same identity; this can lead to the duplication of a still-running Pod, and if said Pod can still communicate with the other members of the StatefulSet, will violate the at most one semantics that StatefulSet is designed to guarantee.</p><p>When you force delete a StatefulSet pod, you are asserting that the Pod in question will never again make contact with other Pods in the StatefulSet and its name can be safely freed up for a replacement to be created.</p><p>If you want to delete a Pod forcibly using kubectl version >= 1.5, do the following:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl delete pods &lt;pod&gt; --grace-period<span style=color:#666>=</span><span style=color:#666>0</span> --force
</span></span></code></pre></div><p>If you're using any version of kubectl &lt;= 1.4, you should omit the <code>--force</code> option and use:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl delete pods &lt;pod&gt; --grace-period<span style=color:#666>=</span><span style=color:#666>0</span>
</span></span></code></pre></div><p>If even after these commands the pod is stuck on <code>Unknown</code> state, use the following command to remove the pod from the cluster:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl patch pod &lt;pod&gt; -p <span style=color:#b44>&#39;{&#34;metadata&#34;:{&#34;finalizers&#34;:null}}&#39;</span>
</span></span></code></pre></div><p>Always perform force deletion of StatefulSet Pods carefully and with complete knowledge of the risks involved.</p><h2 id=what-s-next>What's next</h2><p>Learn more about <a href=/docs/tasks/debug/debug-application/debug-statefulset/>debugging a StatefulSet</a>.</p></div><div class=td-content style=page-break-before:always><h1 id=pg-0c0bb1bd76d2a9069e50e2cec6d20c2a>7 - Horizontal Pod Autoscaling</h1><p>In Kubernetes, a <em>HorizontalPodAutoscaler</em> automatically updates a workload resource (such as
a <a class=glossary-tooltip title='Manages a replicated application on your cluster.' data-toggle=tooltip data-placement=top href=/docs/concepts/workloads/controllers/deployment/ target=_blank aria-label=Deployment>Deployment</a> or
<a class=glossary-tooltip title='Manages deployment and scaling of a set of Pods, with durable storage and persistent identifiers for each Pod.' data-toggle=tooltip data-placement=top href=/docs/concepts/workloads/controllers/statefulset/ target=_blank aria-label=StatefulSet>StatefulSet</a>), with the
aim of automatically scaling the workload to match demand.</p><p>Horizontal scaling means that the response to increased load is to deploy more
<a class=glossary-tooltip title='A Pod represents a set of running containers in your cluster.' data-toggle=tooltip data-placement=top href=/docs/concepts/workloads/pods/ target=_blank aria-label=Pods>Pods</a>.
This is different from <em>vertical</em> scaling, which for Kubernetes would mean
assigning more resources (for example: memory or CPU) to the Pods that are already
running for the workload.</p><p>If the load decreases, and the number of Pods is above the configured minimum,
the HorizontalPodAutoscaler instructs the workload resource (the Deployment, StatefulSet,
or other similar resource) to scale back down.</p><p>Horizontal pod autoscaling does not apply to objects that can't be scaled (for example:
a <a class=glossary-tooltip title='Ensures a copy of a Pod is running across a set of nodes in a cluster.' data-toggle=tooltip data-placement=top href=/docs/concepts/workloads/controllers/daemonset target=_blank aria-label=DaemonSet>DaemonSet</a>.)</p><p>The HorizontalPodAutoscaler is implemented as a Kubernetes API resource and a
<a class=glossary-tooltip title='A control loop that watches the shared state of the cluster through the apiserver and makes changes attempting to move the current state towards the desired state.' data-toggle=tooltip data-placement=top href=/docs/concepts/architecture/controller/ target=_blank aria-label=controller>controller</a>.
The resource determines the behavior of the controller.
The horizontal pod autoscaling controller, running within the Kubernetes
<a class=glossary-tooltip title='The container orchestration layer that exposes the API and interfaces to define, deploy, and manage the lifecycle of containers.' data-toggle=tooltip data-placement=top href='/docs/reference/glossary/?all=true#term-control-plane' target=_blank aria-label='control plane'>control plane</a>, periodically adjusts the
desired scale of its target (for example, a Deployment) to match observed metrics such as average
CPU utilization, average memory utilization, or any other custom metric you specify.</p><p>There is <a href=/docs/tasks/run-application/horizontal-pod-autoscale-walkthrough/>walkthrough example</a> of using
horizontal pod autoscaling.</p><h2 id=how-does-a-horizontalpodautoscaler-work>How does a HorizontalPodAutoscaler work?</h2><figure><div class=mermaid>graph BT
hpa[Horizontal Pod Autoscaler] --> scale[Scale]
subgraph rc[RC / Deployment]
scale
end
scale -.-> pod1[Pod 1]
scale -.-> pod2[Pod 2]
scale -.-> pod3[Pod N]
classDef hpa fill:#D5A6BD,stroke:#1E1E1D,stroke-width:1px,color:#1E1E1D;
classDef rc fill:#F9CB9C,stroke:#1E1E1D,stroke-width:1px,color:#1E1E1D;
classDef scale fill:#B6D7A8,stroke:#1E1E1D,stroke-width:1px,color:#1E1E1D;
classDef pod fill:#9FC5E8,stroke:#1E1E1D,stroke-width:1px,color:#1E1E1D;
class hpa hpa;
class rc rc;
class scale scale;
class pod1,pod2,pod3 pod</div></figure><noscript><div class="alert alert-secondary callout" role=alert><em class=javascript-required>JavaScript must be <a href=https://www.enable-javascript.com/>enabled</a> to view this content</em></div></noscript><p>Figure 1. HorizontalPodAutoscaler controls the scale of a Deployment and its ReplicaSet</p><p>Kubernetes implements horizontal pod autoscaling as a control loop that runs intermittently
(it is not a continuous process). The interval is set by the
<code>--horizontal-pod-autoscaler-sync-period</code> parameter to the
<a href=/docs/reference/command-line-tools-reference/kube-controller-manager/><code>kube-controller-manager</code></a>
(and the default interval is 15 seconds).</p><p>Once during each period, the controller manager queries the resource utilization against the
metrics specified in each HorizontalPodAutoscaler definition. The controller manager
finds the target resource defined by the <code>scaleTargetRef</code>,
then selects the pods based on the target resource's <code>.spec.selector</code> labels, and obtains the metrics from either the resource metrics API (for per-pod resource metrics),
or the custom metrics API (for all other metrics).</p><ul><li><p>For per-pod resource metrics (like CPU), the controller fetches the metrics
from the resource metrics API for each Pod targeted by the HorizontalPodAutoscaler.
Then, if a target utilization value is set, the controller calculates the utilization
value as a percentage of the equivalent
<a href=/docs/concepts/configuration/manage-resources-containers/#requests-and-limits>resource request</a>
on the containers in each Pod. If a target raw value is set, the raw metric values are used directly.
The controller then takes the mean of the utilization or the raw value (depending on the type
of target specified) across all targeted Pods, and produces a ratio used to scale
the number of desired replicas.</p><p>Please note that if some of the Pod's containers do not have the relevant resource request set,
CPU utilization for the Pod will not be defined and the autoscaler will
not take any action for that metric. See the <a href=#algorithm-details>algorithm details</a> section below
for more information about how the autoscaling algorithm works.</p></li><li><p>For per-pod custom metrics, the controller functions similarly to per-pod resource metrics,
except that it works with raw values, not utilization values.</p></li><li><p>For object metrics and external metrics, a single metric is fetched, which describes
the object in question. This metric is compared to the target
value, to produce a ratio as above. In the <code>autoscaling/v2</code> API
version, this value can optionally be divided by the number of Pods before the
comparison is made.</p></li></ul><p>The common use for HorizontalPodAutoscaler is to configure it to fetch metrics from
<a class=glossary-tooltip title='The aggregation layer lets you install additional Kubernetes-style APIs in your cluster.' data-toggle=tooltip data-placement=top href=/docs/concepts/extend-kubernetes/api-extension/apiserver-aggregation/ target=_blank aria-label='aggregated APIs'>aggregated APIs</a>
(<code>metrics.k8s.io</code>, <code>custom.metrics.k8s.io</code>, or <code>external.metrics.k8s.io</code>). The <code>metrics.k8s.io</code> API is
usually provided by an add-on named Metrics Server, which needs to be launched separately.
For more information about resource metrics, see
<a href=/docs/tasks/debug/debug-cluster/resource-metrics-pipeline/#metrics-server>Metrics Server</a>.</p><p><a href=#support-for-metrics-apis>Support for metrics APIs</a> explains the stability guarantees and support status for these
different APIs.</p><p>The HorizontalPodAutoscaler controller accesses corresponding workload resources that support scaling (such as Deployments
and StatefulSet). These resources each have a subresource named <code>scale</code>, an interface that allows you to dynamically set the
number of replicas and examine each of their current states.
For general information about subresources in the Kubernetes API, see
<a href=/docs/reference/using-api/api-concepts/>Kubernetes API Concepts</a>.</p><h3 id=algorithm-details>Algorithm details</h3><p>From the most basic perspective, the HorizontalPodAutoscaler controller
operates on the ratio between desired metric value and current metric
value:</p><pre tabindex=0><code>desiredReplicas = ceil[currentReplicas * ( currentMetricValue / desiredMetricValue )]
</code></pre><p>For example, if the current metric value is <code>200m</code>, and the desired value
is <code>100m</code>, the number of replicas will be doubled, since <code>200.0 / 100.0 == 2.0</code> If the current value is instead <code>50m</code>, you'll halve the number of
replicas, since <code>50.0 / 100.0 == 0.5</code>. The control plane skips any scaling
action if the ratio is sufficiently close to 1.0 (within a globally-configurable
tolerance, 0.1 by default).</p><p>When a <code>targetAverageValue</code> or <code>targetAverageUtilization</code> is specified,
the <code>currentMetricValue</code> is computed by taking the average of the given
metric across all Pods in the HorizontalPodAutoscaler's scale target.</p><p>Before checking the tolerance and deciding on the final values, the control
plane also considers whether any metrics are missing, and how many Pods
are <a href=/docs/concepts/workloads/pods/pod-lifecycle/#pod-conditions><code>Ready</code></a>.
All Pods with a deletion timestamp set (objects with a deletion timestamp are
in the process of being shut down / removed) are ignored, and all failed Pods
are discarded.</p><p>If a particular Pod is missing metrics, it is set aside for later; Pods
with missing metrics will be used to adjust the final scaling amount.</p><p>When scaling on CPU, if any pod has yet to become ready (it's still
initializing, or possibly is unhealthy) <em>or</em> the most recent metric point for
the pod was before it became ready, that pod is set aside as well.</p><p>Due to technical constraints, the HorizontalPodAutoscaler controller
cannot exactly determine the first time a pod becomes ready when
determining whether to set aside certain CPU metrics. Instead, it
considers a Pod "not yet ready" if it's unready and transitioned to
ready within a short, configurable window of time since it started.
This value is configured with the <code>--horizontal-pod-autoscaler-initial-readiness-delay</code> flag, and its default is 30
seconds. Once a pod has become ready, it considers any transition to
ready to be the first if it occurred within a longer, configurable time
since it started. This value is configured with the <code>--horizontal-pod-autoscaler-cpu-initialization-period</code> flag, and its
default is 5 minutes.</p><p>The <code>currentMetricValue / desiredMetricValue</code> base scale ratio is then
calculated using the remaining pods not set aside or discarded from above.</p><p>If there were any missing metrics, the control plane recomputes the average more
conservatively, assuming those pods were consuming 100% of the desired
value in case of a scale down, and 0% in case of a scale up. This dampens
the magnitude of any potential scale.</p><p>Furthermore, if any not-yet-ready pods were present, and the workload would have
scaled up without factoring in missing metrics or not-yet-ready pods,
the controller conservatively assumes that the not-yet-ready pods are consuming 0%
of the desired metric, further dampening the magnitude of a scale up.</p><p>After factoring in the not-yet-ready pods and missing metrics, the
controller recalculates the usage ratio. If the new ratio reverses the scale
direction, or is within the tolerance, the controller doesn't take any scaling
action. In other cases, the new ratio is used to decide any change to the
number of Pods.</p><p>Note that the <em>original</em> value for the average utilization is reported
back via the HorizontalPodAutoscaler status, without factoring in the
not-yet-ready pods or missing metrics, even when the new usage ratio is
used.</p><p>If multiple metrics are specified in a HorizontalPodAutoscaler, this
calculation is done for each metric, and then the largest of the desired
replica counts is chosen. If any of these metrics cannot be converted
into a desired replica count (e.g. due to an error fetching the metrics
from the metrics APIs) and a scale down is suggested by the metrics which
can be fetched, scaling is skipped. This means that the HPA is still capable
of scaling up if one or more metrics give a <code>desiredReplicas</code> greater than
the current value.</p><p>Finally, right before HPA scales the target, the scale recommendation is recorded. The
controller considers all recommendations within a configurable window choosing the
highest recommendation from within that window. This value can be configured using the <code>--horizontal-pod-autoscaler-downscale-stabilization</code> flag, which defaults to 5 minutes.
This means that scaledowns will occur gradually, smoothing out the impact of rapidly
fluctuating metric values.</p><h2 id=api-object>API Object</h2><p>The Horizontal Pod Autoscaler is an API resource in the Kubernetes
<code>autoscaling</code> API group. The current stable version can be found in
the <code>autoscaling/v2</code> API version which includes support for scaling on
memory and custom metrics. The new fields introduced in
<code>autoscaling/v2</code> are preserved as annotations when working with
<code>autoscaling/v1</code>.</p><p>When you create a HorizontalPodAutoscaler API object, make sure the name specified is a valid
<a href=/docs/concepts/overview/working-with-objects/names#dns-subdomain-names>DNS subdomain name</a>.
More details about the API object can be found at
<a href=/docs/reference/generated/kubernetes-api/v1.25/#horizontalpodautoscaler-v2-autoscaling>HorizontalPodAutoscaler Object</a>.</p><h2 id=flapping>Stability of workload scale</h2><p>When managing the scale of a group of replicas using the HorizontalPodAutoscaler,
it is possible that the number of replicas keeps fluctuating frequently due to the
dynamic nature of the metrics evaluated. This is sometimes referred to as <em>thrashing</em>,
or <em>flapping</em>. It's similar to the concept of <em>hysteresis</em> in cybernetics.</p><h2 id=autoscaling-during-rolling-update>Autoscaling during rolling update</h2><p>Kubernetes lets you perform a rolling update on a Deployment. In that
case, the Deployment manages the underlying ReplicaSets for you.
When you configure autoscaling for a Deployment, you bind a
HorizontalPodAutoscaler to a single Deployment. The HorizontalPodAutoscaler
manages the <code>replicas</code> field of the Deployment. The deployment controller is responsible
for setting the <code>replicas</code> of the underlying ReplicaSets so that they add up to a suitable
number during the rollout and also afterwards.</p><p>If you perform a rolling update of a StatefulSet that has an autoscaled number of
replicas, the StatefulSet directly manages its set of Pods (there is no intermediate resource
similar to ReplicaSet).</p><h2 id=support-for-resource-metrics>Support for resource metrics</h2><p>Any HPA target can be scaled based on the resource usage of the pods in the scaling target.
When defining the pod specification the resource requests like <code>cpu</code> and <code>memory</code> should
be specified. This is used to determine the resource utilization and used by the HPA controller
to scale the target up or down. To use resource utilization based scaling specify a metric source
like this:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>type</span>:<span style=color:#bbb> </span>Resource<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>resource</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>cpu<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>target</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>type</span>:<span style=color:#bbb> </span>Utilization<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>averageUtilization</span>:<span style=color:#bbb> </span><span style=color:#666>60</span><span style=color:#bbb>
</span></span></span></code></pre></div><p>With this metric the HPA controller will keep the average utilization of the pods in the scaling
target at 60%. Utilization is the ratio between the current usage of resource to the requested
resources of the pod. See <a href=#algorithm-details>Algorithm</a> for more details about how the utilization
is calculated and averaged.</p><div class="alert alert-info note callout" role=alert><strong>Note:</strong> Since the resource usages of all the containers are summed up the total pod utilization may not
accurately represent the individual container resource usage. This could lead to situations where
a single container might be running with high usage and the HPA will not scale out because the overall
pod usage is still within acceptable limits.</div><h3 id=container-resource-metrics>Container resource metrics</h3><div style=margin-top:10px;margin-bottom:10px><b>FEATURE STATE:</b> <code>Kubernetes v1.20 [alpha]</code></div><p>The HorizontalPodAutoscaler API also supports a container metric source where the HPA can track the
resource usage of individual containers across a set of Pods, in order to scale the target resource.
This lets you configure scaling thresholds for the containers that matter most in a particular Pod.
For example, if you have a web application and a logging sidecar, you can scale based on the resource
use of the web application, ignoring the sidecar container and its resource use.</p><p>If you revise the target resource to have a new Pod specification with a different set of containers,
you should revise the HPA spec if that newly added container should also be used for
scaling. If the specified container in the metric source is not present or only present in a subset
of the pods then those pods are ignored and the recommendation is recalculated. See <a href=#algorithm-details>Algorithm</a>
for more details about the calculation. To use container resources for autoscaling define a metric
source as follows:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>type</span>:<span style=color:#bbb> </span>ContainerResource<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>containerResource</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>cpu<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>container</span>:<span style=color:#bbb> </span>application<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>target</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>type</span>:<span style=color:#bbb> </span>Utilization<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>averageUtilization</span>:<span style=color:#bbb> </span><span style=color:#666>60</span><span style=color:#bbb>
</span></span></span></code></pre></div><p>In the above example the HPA controller scales the target such that the average utilization of the cpu
in the <code>application</code> container of all the pods is 60%.</p><div class="alert alert-info note callout" role=alert><strong>Note:</strong><p>If you change the name of a container that a HorizontalPodAutoscaler is tracking, you can
make that change in a specific order to ensure scaling remains available and effective
whilst the change is being applied. Before you update the resource that defines the container
(such as a Deployment), you should update the associated HPA to track both the new and
old container names. This way, the HPA is able to calculate a scaling recommendation
throughout the update process.</p><p>Once you have rolled out the container name change to the workload resource, tidy up by removing
the old container name from the HPA specification.</p></div><h2 id=scaling-on-custom-metrics>Scaling on custom metrics</h2><div style=margin-top:10px;margin-bottom:10px><b>FEATURE STATE:</b> <code>Kubernetes v1.23 [stable]</code></div><p>(the <code>autoscaling/v2beta2</code> API version previously provided this ability as a beta feature)</p><p>Provided that you use the <code>autoscaling/v2</code> API version, you can configure a HorizontalPodAutoscaler
to scale based on a custom metric (that is not built in to Kubernetes or any Kubernetes component).
The HorizontalPodAutoscaler controller then queries for these custom metrics from the Kubernetes
API.</p><p>See <a href=#support-for-metrics-apis>Support for metrics APIs</a> for the requirements.</p><h2 id=scaling-on-multiple-metrics>Scaling on multiple metrics</h2><div style=margin-top:10px;margin-bottom:10px><b>FEATURE STATE:</b> <code>Kubernetes v1.23 [stable]</code></div><p>(the <code>autoscaling/v2beta2</code> API version previously provided this ability as a beta feature)</p><p>Provided that you use the <code>autoscaling/v2</code> API version, you can specify multiple metrics for a
HorizontalPodAutoscaler to scale on. Then, the HorizontalPodAutoscaler controller evaluates each metric,
and proposes a new scale based on that metric. The HorizontalPodAutoscaler takes the maximum scale
recommended for each metric and sets the workload to that size (provided that this isn't larger than the
overall maximum that you configured).</p><h2 id=support-for-metrics-apis>Support for metrics APIs</h2><p>By default, the HorizontalPodAutoscaler controller retrieves metrics from a series of APIs. In order for it to access these
APIs, cluster administrators must ensure that:</p><ul><li><p>The <a href=/docs/tasks/extend-kubernetes/configure-aggregation-layer/>API aggregation layer</a> is enabled.</p></li><li><p>The corresponding APIs are registered:</p><ul><li><p>For resource metrics, this is the <code>metrics.k8s.io</code> API, generally provided by <a href=https://github.com/kubernetes-sigs/metrics-server>metrics-server</a>.
It can be launched as a cluster add-on.</p></li><li><p>For custom metrics, this is the <code>custom.metrics.k8s.io</code> API. It's provided by "adapter" API servers provided by metrics solution vendors.
Check with your metrics pipeline to see if there is a Kubernetes metrics adapter available.</p></li><li><p>For external metrics, this is the <code>external.metrics.k8s.io</code> API. It may be provided by the custom metrics adapters provided above.</p></li></ul></li></ul><p>For more information on these different metrics paths and how they differ please see the relevant design proposals for
<a href=https://git.k8s.io/design-proposals-archive/autoscaling/hpa-v2.md>the HPA V2</a>,
<a href=https://git.k8s.io/design-proposals-archive/instrumentation/custom-metrics-api.md>custom.metrics.k8s.io</a>
and <a href=https://git.k8s.io/design-proposals-archive/instrumentation/external-metrics-api.md>external.metrics.k8s.io</a>.</p><p>For examples of how to use them see <a href=/docs/tasks/run-application/horizontal-pod-autoscale-walkthrough/#autoscaling-on-multiple-metrics-and-custom-metrics>the walkthrough for using custom metrics</a>
and <a href=/docs/tasks/run-application/horizontal-pod-autoscale-walkthrough/#autoscaling-on-metrics-not-related-to-kubernetes-objects>the walkthrough for using external metrics</a>.</p><h2 id=configurable-scaling-behavior>Configurable scaling behavior</h2><div style=margin-top:10px;margin-bottom:10px><b>FEATURE STATE:</b> <code>Kubernetes v1.23 [stable]</code></div><p>(the <code>autoscaling/v2beta2</code> API version previously provided this ability as a beta feature)</p><p>If you use the <code>v2</code> HorizontalPodAutoscaler API, you can use the <code>behavior</code> field
(see the <a href=/docs/reference/kubernetes-api/workload-resources/horizontal-pod-autoscaler-v2/#HorizontalPodAutoscalerSpec>API reference</a>)
to configure separate scale-up and scale-down behaviors.
You specify these behaviours by setting <code>scaleUp</code> and / or <code>scaleDown</code>
under the <code>behavior</code> field.</p><p>You can specify a <em>stabilization window</em> that prevents <a href=#flapping>flapping</a>
the replica count for a scaling target. Scaling policies also let you controls the
rate of change of replicas while scaling.</p><h3 id=scaling-policies>Scaling policies</h3><p>One or more scaling policies can be specified in the <code>behavior</code> section of the spec.
When multiple policies are specified the policy which allows the highest amount of
change is the policy which is selected by default. The following example shows this behavior
while scaling down:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>behavior</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>scaleDown</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>policies</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:green;font-weight:700>type</span>:<span style=color:#bbb> </span>Pods<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>value</span>:<span style=color:#bbb> </span><span style=color:#666>4</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>periodSeconds</span>:<span style=color:#bbb> </span><span style=color:#666>60</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:green;font-weight:700>type</span>:<span style=color:#bbb> </span>Percent<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>value</span>:<span style=color:#bbb> </span><span style=color:#666>10</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>periodSeconds</span>:<span style=color:#bbb> </span><span style=color:#666>60</span><span style=color:#bbb>
</span></span></span></code></pre></div><p><code>periodSeconds</code> indicates the length of time in the past for which the policy must hold true.
The first policy <em>(Pods)</em> allows at most 4 replicas to be scaled down in one minute. The second policy
<em>(Percent)</em> allows at most 10% of the current replicas to be scaled down in one minute.</p><p>Since by default the policy which allows the highest amount of change is selected, the second policy will
only be used when the number of pod replicas is more than 40. With 40 or less replicas, the first policy will be applied.
For instance if there are 80 replicas and the target has to be scaled down to 10 replicas
then during the first step 8 replicas will be reduced. In the next iteration when the number
of replicas is 72, 10% of the pods is 7.2 but the number is rounded up to 8. On each loop of
the autoscaler controller the number of pods to be change is re-calculated based on the number
of current replicas. When the number of replicas falls below 40 the first policy <em>(Pods)</em> is applied
and 4 replicas will be reduced at a time.</p><p>The policy selection can be changed by specifying the <code>selectPolicy</code> field for a scaling
direction. By setting the value to <code>Min</code> which would select the policy which allows the
smallest change in the replica count. Setting the value to <code>Disabled</code> completely disables
scaling in that direction.</p><h3 id=stabilization-window>Stabilization window</h3><p>The stabilization window is used to restrict the <a href=#flapping>flapping</a> of
replica count when the metrics used for scaling keep fluctuating. The autoscaling algorithm
uses this window to infer a previous desired state and avoid unwanted changes to workload
scale.</p><p>For example, in the following example snippet, a stabilization window is specified for <code>scaleDown</code>.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>behavior</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>scaleDown</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>stabilizationWindowSeconds</span>:<span style=color:#bbb> </span><span style=color:#666>300</span><span style=color:#bbb>
</span></span></span></code></pre></div><p>When the metrics indicate that the target should be scaled down the algorithm looks
into previously computed desired states, and uses the highest value from the specified
interval. In the above example, all desired states from the past 5 minutes will be considered.</p><p>This approximates a rolling maximum, and avoids having the scaling algorithm frequently
remove Pods only to trigger recreating an equivalent Pod just moments later.</p><h3 id=default-behavior>Default Behavior</h3><p>To use the custom scaling not all fields have to be specified. Only values which need to be
customized can be specified. These custom values are merged with default values. The default values
match the existing behavior in the HPA algorithm.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>behavior</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>scaleDown</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>stabilizationWindowSeconds</span>:<span style=color:#bbb> </span><span style=color:#666>300</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>policies</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:green;font-weight:700>type</span>:<span style=color:#bbb> </span>Percent<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>value</span>:<span style=color:#bbb> </span><span style=color:#666>100</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>periodSeconds</span>:<span style=color:#bbb> </span><span style=color:#666>15</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>scaleUp</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>stabilizationWindowSeconds</span>:<span style=color:#bbb> </span><span style=color:#666>0</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>policies</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:green;font-weight:700>type</span>:<span style=color:#bbb> </span>Percent<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>value</span>:<span style=color:#bbb> </span><span style=color:#666>100</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>periodSeconds</span>:<span style=color:#bbb> </span><span style=color:#666>15</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:green;font-weight:700>type</span>:<span style=color:#bbb> </span>Pods<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>value</span>:<span style=color:#bbb> </span><span style=color:#666>4</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>periodSeconds</span>:<span style=color:#bbb> </span><span style=color:#666>15</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>selectPolicy</span>:<span style=color:#bbb> </span>Max<span style=color:#bbb>
</span></span></span></code></pre></div><p>For scaling down the stabilization window is <em>300</em> seconds (or the value of the
<code>--horizontal-pod-autoscaler-downscale-stabilization</code> flag if provided). There is only a single policy
for scaling down which allows a 100% of the currently running replicas to be removed which
means the scaling target can be scaled down to the minimum allowed replicas.
For scaling up there is no stabilization window. When the metrics indicate that the target should be
scaled up the target is scaled up immediately. There are 2 policies where 4 pods or a 100% of the currently
running replicas will be added every 15 seconds till the HPA reaches its steady state.</p><h3 id=example-change-downscale-stabilization-window>Example: change downscale stabilization window</h3><p>To provide a custom downscale stabilization window of 1 minute, the following
behavior would be added to the HPA:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>behavior</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>scaleDown</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>stabilizationWindowSeconds</span>:<span style=color:#bbb> </span><span style=color:#666>60</span><span style=color:#bbb>
</span></span></span></code></pre></div><h3 id=example-limit-scale-down-rate>Example: limit scale down rate</h3><p>To limit the rate at which pods are removed by the HPA to 10% per minute, the
following behavior would be added to the HPA:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>behavior</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>scaleDown</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>policies</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:green;font-weight:700>type</span>:<span style=color:#bbb> </span>Percent<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>value</span>:<span style=color:#bbb> </span><span style=color:#666>10</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>periodSeconds</span>:<span style=color:#bbb> </span><span style=color:#666>60</span><span style=color:#bbb>
</span></span></span></code></pre></div><p>To ensure that no more than 5 Pods are removed per minute, you can add a second scale-down
policy with a fixed size of 5, and set <code>selectPolicy</code> to minimum. Setting <code>selectPolicy</code> to <code>Min</code> means
that the autoscaler chooses the policy that affects the smallest number of Pods:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>behavior</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>scaleDown</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>policies</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:green;font-weight:700>type</span>:<span style=color:#bbb> </span>Percent<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>value</span>:<span style=color:#bbb> </span><span style=color:#666>10</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>periodSeconds</span>:<span style=color:#bbb> </span><span style=color:#666>60</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:green;font-weight:700>type</span>:<span style=color:#bbb> </span>Pods<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>value</span>:<span style=color:#bbb> </span><span style=color:#666>5</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>periodSeconds</span>:<span style=color:#bbb> </span><span style=color:#666>60</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>selectPolicy</span>:<span style=color:#bbb> </span>Min<span style=color:#bbb>
</span></span></span></code></pre></div><h3 id=example-disable-scale-down>Example: disable scale down</h3><p>The <code>selectPolicy</code> value of <code>Disabled</code> turns off scaling the given direction.
So to prevent downscaling the following policy would be used:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>behavior</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>scaleDown</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>selectPolicy</span>:<span style=color:#bbb> </span>Disabled<span style=color:#bbb>
</span></span></span></code></pre></div><h2 id=support-for-horizontalpodautoscaler-in-kubectl>Support for HorizontalPodAutoscaler in kubectl</h2><p>HorizontalPodAutoscaler, like every API resource, is supported in a standard way by <code>kubectl</code>.
You can create a new autoscaler using <code>kubectl create</code> command.
You can list autoscalers by <code>kubectl get hpa</code> or get detailed description by <code>kubectl describe hpa</code>.
Finally, you can delete an autoscaler using <code>kubectl delete hpa</code>.</p><p>In addition, there is a special <code>kubectl autoscale</code> command for creating a HorizontalPodAutoscaler object.
For instance, executing <code>kubectl autoscale rs foo --min=2 --max=5 --cpu-percent=80</code>
will create an autoscaler for ReplicaSet <em>foo</em>, with target CPU utilization set to <code>80%</code>
and the number of replicas between 2 and 5.</p><h2 id=implicit-maintenance-mode-deactivation>Implicit maintenance-mode deactivation</h2><p>You can implicitly deactivate the HPA for a target without the
need to change the HPA configuration itself. If the target's desired replica count
is set to 0, and the HPA's minimum replica count is greater than 0, the HPA
stops adjusting the target (and sets the <code>ScalingActive</code> Condition on itself
to <code>false</code>) until you reactivate it by manually adjusting the target's desired
replica count or HPA's minimum replica count.</p><h3 id=migrating-deployments-and-statefulsets-to-horizontal-autoscaling>Migrating Deployments and StatefulSets to horizontal autoscaling</h3><p>When an HPA is enabled, it is recommended that the value of <code>spec.replicas</code> of
the Deployment and / or StatefulSet be removed from their
<a class=glossary-tooltip title='A serialized specification of one or more Kubernetes API objects.' data-toggle=tooltip data-placement=top href='/docs/reference/glossary/?all=true#term-manifest' target=_blank aria-label=manifest(s)>manifest(s)</a>. If this isn't done, any time
a change to that object is applied, for example via <code>kubectl apply -f deployment.yaml</code>, this will instruct Kubernetes to scale the current number of Pods
to the value of the <code>spec.replicas</code> key. This may not be
desired and could be troublesome when an HPA is active.</p><p>Keep in mind that the removal of <code>spec.replicas</code> may incur a one-time
degradation of Pod counts as the default value of this key is 1 (reference
<a href=/docs/concepts/workloads/controllers/deployment#replicas>Deployment Replicas</a>).
Upon the update, all Pods except 1 will begin their termination procedures. Any
deployment application afterwards will behave as normal and respect a rolling
update configuration as desired. You can avoid this degradation by choosing one of the following two
methods based on how you are modifying your deployments:</p><ul class="nav nav-tabs" id=fix-replicas-instructions role=tablist><li class=nav-item><a data-toggle=tab class="nav-link active" href=#fix-replicas-instructions-0 role=tab aria-controls=fix-replicas-instructions-0 aria-selected=true>Client Side Apply (this is the default)</a></li><li class=nav-item><a data-toggle=tab class=nav-link href=#fix-replicas-instructions-1 role=tab aria-controls=fix-replicas-instructions-1>Server Side Apply</a></li></ul><div class=tab-content id=fix-replicas-instructions><div id=fix-replicas-instructions-0 class="tab-pane show active" role=tabpanel aria-labelledby=fix-replicas-instructions-0><p><ol><li><code>kubectl apply edit-last-applied deployment/&lt;deployment_name></code></li><li>In the editor, remove <code>spec.replicas</code>. When you save and exit the editor, <code>kubectl</code>
applies the update. No changes to Pod counts happen at this step.</li><li>You can now remove <code>spec.replicas</code> from the manifest. If you use source code management,
also commit your changes or take whatever other steps for revising the source code
are appropriate for how you track updates.</li><li>From here on out you can run <code>kubectl apply -f deployment.yaml</code></li></ol></div><div id=fix-replicas-instructions-1 class=tab-pane role=tabpanel aria-labelledby=fix-replicas-instructions-1><p><p>When using the <a href=/docs/reference/using-api/server-side-apply/>Server-Side Apply</a>
you can follow the <a href=/docs/reference/using-api/server-side-apply/#transferring-ownership>transferring ownership</a>
guidelines, which cover this exact use case.</p></div></div><h2 id=what-s-next>What's next</h2><p>If you configure autoscaling in your cluster, you may also want to consider running a
cluster-level autoscaler such as <a href=https://github.com/kubernetes/autoscaler/tree/master/cluster-autoscaler>Cluster Autoscaler</a>.</p><p>For more information on HorizontalPodAutoscaler:</p><ul><li>Read a <a href=/docs/tasks/run-application/horizontal-pod-autoscale-walkthrough/>walkthrough example</a> for horizontal pod autoscaling.</li><li>Read documentation for <a href=/docs/reference/generated/kubectl/kubectl-commands/#autoscale><code>kubectl autoscale</code></a>.</li><li>If you would like to write your own custom metrics adapter, check out the
<a href=https://github.com/kubernetes-sigs/custom-metrics-apiserver>boilerplate</a> to get started.</li><li>Read the <a href=/docs/reference/kubernetes-api/workload-resources/horizontal-pod-autoscaler-v2/>API reference</a> for HorizontalPodAutoscaler.</li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-8138226ce9660ac8e3e82ff86fff8ad2>8 - HorizontalPodAutoscaler Walkthrough</h1><p>A <a href=/docs/tasks/run-application/horizontal-pod-autoscale/>HorizontalPodAutoscaler</a>
(HPA for short)
automatically updates a workload resource (such as
a <a class=glossary-tooltip title='Manages a replicated application on your cluster.' data-toggle=tooltip data-placement=top href=/docs/concepts/workloads/controllers/deployment/ target=_blank aria-label=Deployment>Deployment</a> or
<a class=glossary-tooltip title='Manages deployment and scaling of a set of Pods, with durable storage and persistent identifiers for each Pod.' data-toggle=tooltip data-placement=top href=/docs/concepts/workloads/controllers/statefulset/ target=_blank aria-label=StatefulSet>StatefulSet</a>), with the
aim of automatically scaling the workload to match demand.</p><p>Horizontal scaling means that the response to increased load is to deploy more
<a class=glossary-tooltip title='A Pod represents a set of running containers in your cluster.' data-toggle=tooltip data-placement=top href=/docs/concepts/workloads/pods/ target=_blank aria-label=Pods>Pods</a>.
This is different from <em>vertical</em> scaling, which for Kubernetes would mean
assigning more resources (for example: memory or CPU) to the Pods that are already
running for the workload.</p><p>If the load decreases, and the number of Pods is above the configured minimum,
the HorizontalPodAutoscaler instructs the workload resource (the Deployment, StatefulSet,
or other similar resource) to scale back down.</p><p>This document walks you through an example of enabling HorizontalPodAutoscaler to
automatically manage scale for an example web app. This example workload is Apache
httpd running some PHP code.</p><h2 id=before-you-begin>Before you begin</h2><p><p>You need to have a Kubernetes cluster, and the kubectl command-line tool must
be configured to communicate with your cluster. It is recommended to run this tutorial on a cluster with at least two nodes that are not acting as control plane hosts. If you do not already have a
cluster, you can create one by using
<a href=https://minikube.sigs.k8s.io/docs/tutorials/multi_node/>minikube</a>
or you can use one of these Kubernetes playgrounds:</p><ul><li><a href=https://killercoda.com/playgrounds/scenario/kubernetes>Killercoda</a></li><li><a href=http://labs.play-with-k8s.com/>Play with Kubernetes</a></li></ul>Your Kubernetes server must be at or later than version 1.23.
To check the version, enter <code>kubectl version</code>.
If you're running an older
release of Kubernetes, refer to the version of the documentation for that release (see
<a href=/docs/home/supported-doc-versions/>available documentation versions</a>).</p><p>To follow this walkthrough, you also need to use a cluster that has a
<a href=https://github.com/kubernetes-sigs/metrics-server#readme>Metrics Server</a> deployed and configured.
The Kubernetes Metrics Server collects resource metrics from
the <a class=glossary-tooltip title='An agent that runs on each node in the cluster. It makes sure that containers are running in a pod.' data-toggle=tooltip data-placement=top href=/docs/reference/generated/kubelet target=_blank aria-label=kubelets>kubelets</a> in your cluster, and exposes those metrics
through the <a href=/docs/concepts/overview/kubernetes-api/>Kubernetes API</a>,
using an <a href=/docs/concepts/extend-kubernetes/api-extension/apiserver-aggregation/>APIService</a> to add
new kinds of resource that represent metric readings.</p><p>To learn how to deploy the Metrics Server, see the
<a href=https://github.com/kubernetes-sigs/metrics-server#deployment>metrics-server documentation</a>.</p><h2 id=run-and-expose-php-apache-server>Run and expose php-apache server</h2><p>To demonstrate a HorizontalPodAutoscaler, you will first start a Deployment that runs a container using the
<code>hpa-example</code> image, and expose it as a <a class=glossary-tooltip title='A way to expose an application running on a set of Pods as a network service.' data-toggle=tooltip data-placement=top href=/docs/concepts/services-networking/service/ target=_blank aria-label=Service>Service</a>
using the following manifest:</p><div class=highlight><div class=copy-code-icon style=text-align:right><a href=https://raw.githubusercontent.com/kubernetes/website/main/content/en/examples/application/php-apache.yaml download=application/php-apache.yaml><code>application/php-apache.yaml</code></a>
<img src=/images/copycode.svg style=max-height:24px;cursor:pointer onclick='copyCode("application-php-apache-yaml")' title="Copy application/php-apache.yaml to clipboard"></img></div><div class=includecode id=application-php-apache-yaml><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>apps/v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Deployment<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>php-apache<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>selector</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>matchLabels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>run</span>:<span style=color:#bbb> </span>php-apache<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>replicas</span>:<span style=color:#bbb> </span><span style=color:#666>1</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>template</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>labels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>run</span>:<span style=color:#bbb> </span>php-apache<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>php-apache<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>registry.k8s.io/hpa-example<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>ports</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span>- <span style=color:green;font-weight:700>containerPort</span>:<span style=color:#bbb> </span><span style=color:#666>80</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>resources</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>limits</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>            </span><span style=color:green;font-weight:700>cpu</span>:<span style=color:#bbb> </span>500m<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>requests</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>            </span><span style=color:green;font-weight:700>cpu</span>:<span style=color:#bbb> </span>200m<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:#00f;font-weight:700>---</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Service<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>php-apache<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>labels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>run</span>:<span style=color:#bbb> </span>php-apache<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>ports</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>port</span>:<span style=color:#bbb> </span><span style=color:#666>80</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>selector</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>run</span>:<span style=color:#bbb> </span>php-apache<span style=color:#bbb>
</span></span></span></code></pre></div></div></div><p>To do so, run the following command:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl apply -f https://k8s.io/examples/application/php-apache.yaml
</span></span></code></pre></div><pre tabindex=0><code>deployment.apps/php-apache created
service/php-apache created
</code></pre><h2 id=create-horizontal-pod-autoscaler>Create the HorizontalPodAutoscaler</h2><p>Now that the server is running, create the autoscaler using <code>kubectl</code>. There is
<a href=/docs/reference/generated/kubectl/kubectl-commands#autoscale><code>kubectl autoscale</code></a> subcommand,
part of <code>kubectl</code>, that helps you do this.</p><p>You will shortly run a command that creates a HorizontalPodAutoscaler that maintains
between 1 and 10 replicas of the Pods controlled by the php-apache Deployment that
you created in the first step of these instructions.</p><p>Roughly speaking, the HPA <a class=glossary-tooltip title='A control loop that watches the shared state of the cluster through the apiserver and makes changes attempting to move the current state towards the desired state.' data-toggle=tooltip data-placement=top href=/docs/concepts/architecture/controller/ target=_blank aria-label=controller>controller</a> will increase and decrease
the number of replicas (by updating the Deployment) to maintain an average CPU utilization across all Pods of 50%.
The Deployment then updates the ReplicaSet - this is part of how all Deployments work in Kubernetes -
and then the ReplicaSet either adds or removes Pods based on the change to its <code>.spec</code>.</p><p>Since each pod requests 200 milli-cores by <code>kubectl run</code>, this means an average CPU usage of 100 milli-cores.
See <a href=/docs/tasks/run-application/horizontal-pod-autoscale/#algorithm-details>Algorithm details</a> for more details
on the algorithm.</p><p>Create the HorizontalPodAutoscaler:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl autoscale deployment php-apache --cpu-percent<span style=color:#666>=</span><span style=color:#666>50</span> --min<span style=color:#666>=</span><span style=color:#666>1</span> --max<span style=color:#666>=</span><span style=color:#666>10</span>
</span></span></code></pre></div><pre tabindex=0><code>horizontalpodautoscaler.autoscaling/php-apache autoscaled
</code></pre><p>You can check the current status of the newly-made HorizontalPodAutoscaler, by running:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span><span style=color:#080;font-style:italic># You can use &#34;hpa&#34; or &#34;horizontalpodautoscaler&#34;; either name works OK.</span>
</span></span><span style=display:flex><span>kubectl get hpa
</span></span></code></pre></div><p>The output is similar to:</p><pre tabindex=0><code>NAME         REFERENCE                     TARGET    MINPODS   MAXPODS   REPLICAS   AGE
php-apache   Deployment/php-apache/scale   0% / 50%  1         10        1          18s
</code></pre><p>(if you see other HorizontalPodAutoscalers with different names, that means they already existed,
and isn't usually a problem).</p><p>Please note that the current CPU consumption is 0% as there are no clients sending requests to the server
(the <code>TARGET</code> column shows the average across all the Pods controlled by the corresponding deployment).</p><h2 id=increase-load>Increase the load</h2><p>Next, see how the autoscaler reacts to increased load.
To do this, you'll start a different Pod to act as a client. The container within the client Pod
runs in an infinite loop, sending queries to the php-apache service.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span><span style=color:#080;font-style:italic># Run this in a separate terminal</span>
</span></span><span style=display:flex><span><span style=color:#080;font-style:italic># so that the load generation continues and you can carry on with the rest of the steps</span>
</span></span><span style=display:flex><span>kubectl run -i --tty load-generator --rm --image<span style=color:#666>=</span>busybox:1.28 --restart<span style=color:#666>=</span>Never -- /bin/sh -c <span style=color:#b44>&#34;while sleep 0.01; do wget -q -O- http://php-apache; done&#34;</span>
</span></span></code></pre></div><p>Now run:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span><span style=color:#080;font-style:italic># type Ctrl+C to end the watch when you&#39;re ready</span>
</span></span><span style=display:flex><span>kubectl get hpa php-apache --watch
</span></span></code></pre></div><p>Within a minute or so, you should see the higher CPU load; for example:</p><pre tabindex=0><code>NAME         REFERENCE                     TARGET      MINPODS   MAXPODS   REPLICAS   AGE
php-apache   Deployment/php-apache/scale   305% / 50%  1         10        1          3m
</code></pre><p>and then, more replicas. For example:</p><pre tabindex=0><code>NAME         REFERENCE                     TARGET      MINPODS   MAXPODS   REPLICAS   AGE
php-apache   Deployment/php-apache/scale   305% / 50%  1         10        7          3m
</code></pre><p>Here, CPU consumption has increased to 305% of the request.
As a result, the Deployment was resized to 7 replicas:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get deployment php-apache
</span></span></code></pre></div><p>You should see the replica count matching the figure from the HorizontalPodAutoscaler</p><pre tabindex=0><code>NAME         READY   UP-TO-DATE   AVAILABLE   AGE
php-apache   7/7      7           7           19m
</code></pre><div class="alert alert-info note callout" role=alert><strong>Note:</strong> It may take a few minutes to stabilize the number of replicas. Since the amount
of load is not controlled in any way it may happen that the final number of replicas
will differ from this example.</div><h2 id=stop-load>Stop generating load</h2><p>To finish the example, stop sending the load.</p><p>In the terminal where you created the Pod that runs a <code>busybox</code> image, terminate
the load generation by typing <code>&lt;Ctrl> + C</code>.</p><p>Then verify the result state (after a minute or so):</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span><span style=color:#080;font-style:italic># type Ctrl+C to end the watch when you&#39;re ready</span>
</span></span><span style=display:flex><span>kubectl get hpa php-apache --watch
</span></span></code></pre></div><p>The output is similar to:</p><pre tabindex=0><code>NAME         REFERENCE                     TARGET       MINPODS   MAXPODS   REPLICAS   AGE
php-apache   Deployment/php-apache/scale   0% / 50%     1         10        1          11m
</code></pre><p>and the Deployment also shows that it has scaled down:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get deployment php-apache
</span></span></code></pre></div><pre tabindex=0><code>NAME         READY   UP-TO-DATE   AVAILABLE   AGE
php-apache   1/1     1            1           27m
</code></pre><p>Once CPU utilization dropped to 0, the HPA automatically scaled the number of replicas back down to 1.</p><p>Autoscaling the replicas may take a few minutes.</p><h2 id=autoscaling-on-multiple-metrics-and-custom-metrics>Autoscaling on multiple metrics and custom metrics</h2><p>You can introduce additional metrics to use when autoscaling the <code>php-apache</code> Deployment
by making use of the <code>autoscaling/v2</code> API version.</p><p>First, get the YAML of your HorizontalPodAutoscaler in the <code>autoscaling/v2</code> form:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get hpa php-apache -o yaml &gt; /tmp/hpa-v2.yaml
</span></span></code></pre></div><p>Open the <code>/tmp/hpa-v2.yaml</code> file in an editor, and you should see YAML which looks like this:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>autoscaling/v2<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>HorizontalPodAutoscaler<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>php-apache<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>scaleTargetRef</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>apps/v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Deployment<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>php-apache<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>minReplicas</span>:<span style=color:#bbb> </span><span style=color:#666>1</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>maxReplicas</span>:<span style=color:#bbb> </span><span style=color:#666>10</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>metrics</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>type</span>:<span style=color:#bbb> </span>Resource<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>resource</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>cpu<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>target</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>type</span>:<span style=color:#bbb> </span>Utilization<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>averageUtilization</span>:<span style=color:#bbb> </span><span style=color:#666>50</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>status</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>observedGeneration</span>:<span style=color:#bbb> </span><span style=color:#666>1</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>lastScaleTime</span>:<span style=color:#bbb> </span>&lt;some-time&gt;<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>currentReplicas</span>:<span style=color:#bbb> </span><span style=color:#666>1</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>desiredReplicas</span>:<span style=color:#bbb> </span><span style=color:#666>1</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>currentMetrics</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>type</span>:<span style=color:#bbb> </span>Resource<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>resource</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>cpu<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>current</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>averageUtilization</span>:<span style=color:#bbb> </span><span style=color:#666>0</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>averageValue</span>:<span style=color:#bbb> </span><span style=color:#666>0</span><span style=color:#bbb>
</span></span></span></code></pre></div><p>Notice that the <code>targetCPUUtilizationPercentage</code> field has been replaced with an array called <code>metrics</code>.
The CPU utilization metric is a <em>resource metric</em>, since it is represented as a percentage of a resource
specified on pod containers. Notice that you can specify other resource metrics besides CPU. By default,
the only other supported resource metric is memory. These resources do not change names from cluster
to cluster, and should always be available, as long as the <code>metrics.k8s.io</code> API is available.</p><p>You can also specify resource metrics in terms of direct values, instead of as percentages of the
requested value, by using a <code>target.type</code> of <code>AverageValue</code> instead of <code>Utilization</code>, and
setting the corresponding <code>target.averageValue</code> field instead of the <code>target.averageUtilization</code>.</p><p>There are two other types of metrics, both of which are considered <em>custom metrics</em>: pod metrics and
object metrics. These metrics may have names which are cluster specific, and require a more
advanced cluster monitoring setup.</p><p>The first of these alternative metric types is <em>pod metrics</em>. These metrics describe Pods, and
are averaged together across Pods and compared with a target value to determine the replica count.
They work much like resource metrics, except that they <em>only</em> support a <code>target</code> type of <code>AverageValue</code>.</p><p>Pod metrics are specified using a metric block like this:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>type</span>:<span style=color:#bbb> </span>Pods<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>pods</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>metric</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>packets-per-second<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>target</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>type</span>:<span style=color:#bbb> </span>AverageValue<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>averageValue</span>:<span style=color:#bbb> </span>1k<span style=color:#bbb>
</span></span></span></code></pre></div><p>The second alternative metric type is <em>object metrics</em>. These metrics describe a different
object in the same namespace, instead of describing Pods. The metrics are not necessarily
fetched from the object; they only describe it. Object metrics support <code>target</code> types of
both <code>Value</code> and <code>AverageValue</code>. With <code>Value</code>, the target is compared directly to the returned
metric from the API. With <code>AverageValue</code>, the value returned from the custom metrics API is divided
by the number of Pods before being compared to the target. The following example is the YAML
representation of the <code>requests-per-second</code> metric.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>type</span>:<span style=color:#bbb> </span>Object<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>object</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>metric</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>requests-per-second<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>describedObject</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>networking.k8s.io/v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Ingress<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>main-route<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>target</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>type</span>:<span style=color:#bbb> </span>Value<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>value</span>:<span style=color:#bbb> </span>2k<span style=color:#bbb>
</span></span></span></code></pre></div><p>If you provide multiple such metric blocks, the HorizontalPodAutoscaler will consider each metric in turn.
The HorizontalPodAutoscaler will calculate proposed replica counts for each metric, and then choose the
one with the highest replica count.</p><p>For example, if you had your monitoring system collecting metrics about network traffic,
you could update the definition above using <code>kubectl edit</code> to look like this:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>autoscaling/v2<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>HorizontalPodAutoscaler<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>php-apache<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>scaleTargetRef</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>apps/v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Deployment<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>php-apache<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>minReplicas</span>:<span style=color:#bbb> </span><span style=color:#666>1</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>maxReplicas</span>:<span style=color:#bbb> </span><span style=color:#666>10</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>metrics</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>type</span>:<span style=color:#bbb> </span>Resource<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>resource</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>cpu<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>target</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>type</span>:<span style=color:#bbb> </span>Utilization<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>averageUtilization</span>:<span style=color:#bbb> </span><span style=color:#666>50</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>type</span>:<span style=color:#bbb> </span>Pods<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>pods</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>metric</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>packets-per-second<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>target</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>type</span>:<span style=color:#bbb> </span>AverageValue<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>averageValue</span>:<span style=color:#bbb> </span>1k<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>type</span>:<span style=color:#bbb> </span>Object<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>object</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>metric</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>requests-per-second<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>describedObject</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>networking.k8s.io/v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Ingress<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>main-route<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>target</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>type</span>:<span style=color:#bbb> </span>Value<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>value</span>:<span style=color:#bbb> </span>10k<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>status</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>observedGeneration</span>:<span style=color:#bbb> </span><span style=color:#666>1</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>lastScaleTime</span>:<span style=color:#bbb> </span>&lt;some-time&gt;<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>currentReplicas</span>:<span style=color:#bbb> </span><span style=color:#666>1</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>desiredReplicas</span>:<span style=color:#bbb> </span><span style=color:#666>1</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>currentMetrics</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>type</span>:<span style=color:#bbb> </span>Resource<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>resource</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>cpu<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>current</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>averageUtilization</span>:<span style=color:#bbb> </span><span style=color:#666>0</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>averageValue</span>:<span style=color:#bbb> </span><span style=color:#666>0</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>type</span>:<span style=color:#bbb> </span>Object<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>object</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>metric</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>requests-per-second<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>describedObject</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>networking.k8s.io/v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Ingress<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>main-route<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>current</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>value</span>:<span style=color:#bbb> </span>10k<span style=color:#bbb>
</span></span></span></code></pre></div><p>Then, your HorizontalPodAutoscaler would attempt to ensure that each pod was consuming roughly
50% of its requested CPU, serving 1000 packets per second, and that all pods behind the main-route
Ingress were serving a total of 10000 requests per second.</p><h3 id=autoscaling-on-more-specific-metrics>Autoscaling on more specific metrics</h3><p>Many metrics pipelines allow you to describe metrics either by name or by a set of additional
descriptors called <em>labels</em>. For all non-resource metric types (pod, object, and external,
described below), you can specify an additional label selector which is passed to your metric
pipeline. For instance, if you collect a metric <code>http_requests</code> with the <code>verb</code>
label, you can specify the following metric block to scale only on GET requests:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>type</span>:<span style=color:#bbb> </span>Object<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>object</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>metric</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>http_requests<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>selector</span>:<span style=color:#bbb> </span>{<span style=color:green;font-weight:700>matchLabels</span>:<span style=color:#bbb> </span>{<span style=color:green;font-weight:700>verb</span>:<span style=color:#bbb> </span>GET}}<span style=color:#bbb>
</span></span></span></code></pre></div><p>This selector uses the same syntax as the full Kubernetes label selectors. The monitoring pipeline
determines how to collapse multiple series into a single value, if the name and selector
match multiple series. The selector is additive, and cannot select metrics
that describe objects that are <strong>not</strong> the target object (the target pods in the case of the <code>Pods</code>
type, and the described object in the case of the <code>Object</code> type).</p><h3 id=autoscaling-on-metrics-not-related-to-kubernetes-objects>Autoscaling on metrics not related to Kubernetes objects</h3><p>Applications running on Kubernetes may need to autoscale based on metrics that don't have an obvious
relationship to any object in the Kubernetes cluster, such as metrics describing a hosted service with
no direct correlation to Kubernetes namespaces. In Kubernetes 1.10 and later, you can address this use case
with <em>external metrics</em>.</p><p>Using external metrics requires knowledge of your monitoring system; the setup is
similar to that required when using custom metrics. External metrics allow you to autoscale your cluster
based on any metric available in your monitoring system. Provide a <code>metric</code> block with a
<code>name</code> and <code>selector</code>, as above, and use the <code>External</code> metric type instead of <code>Object</code>.
If multiple time series are matched by the <code>metricSelector</code>,
the sum of their values is used by the HorizontalPodAutoscaler.
External metrics support both the <code>Value</code> and <code>AverageValue</code> target types, which function exactly the same
as when you use the <code>Object</code> type.</p><p>For example if your application processes tasks from a hosted queue service, you could add the following
section to your HorizontalPodAutoscaler manifest to specify that you need one worker per 30 outstanding tasks.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span>- <span style=color:green;font-weight:700>type</span>:<span style=color:#bbb> </span>External<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>external</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>metric</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>queue_messages_ready<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>selector</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>matchLabels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>queue</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;worker_tasks&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>target</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>type</span>:<span style=color:#bbb> </span>AverageValue<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>averageValue</span>:<span style=color:#bbb> </span><span style=color:#666>30</span><span style=color:#bbb>
</span></span></span></code></pre></div><p>When possible, it's preferable to use the custom metric target types instead of external metrics, since it's
easier for cluster administrators to secure the custom metrics API. The external metrics API potentially allows
access to any metric, so cluster administrators should take care when exposing it.</p><h2 id=appendix-horizontal-pod-autoscaler-status-conditions>Appendix: Horizontal Pod Autoscaler Status Conditions</h2><p>When using the <code>autoscaling/v2</code> form of the HorizontalPodAutoscaler, you will be able to see
<em>status conditions</em> set by Kubernetes on the HorizontalPodAutoscaler. These status conditions indicate
whether or not the HorizontalPodAutoscaler is able to scale, and whether or not it is currently restricted
in any way.</p><p>The conditions appear in the <code>status.conditions</code> field. To see the conditions affecting a HorizontalPodAutoscaler,
we can use <code>kubectl describe hpa</code>:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl describe hpa cm-test
</span></span></code></pre></div><pre tabindex=0><code>Name:                           cm-test
Namespace:                      prom
Labels:                         &lt;none&gt;
Annotations:                    &lt;none&gt;
CreationTimestamp:              Fri, 16 Jun 2017 18:09:22 +0000
Reference:                      ReplicationController/cm-test
Metrics:                        ( current / target )
  &#34;http_requests&#34; on pods:      66m / 500m
Min replicas:                   1
Max replicas:                   4
ReplicationController pods:     1 current / 1 desired
Conditions:
  Type                  Status  Reason                  Message
  ----                  ------  ------                  -------
  AbleToScale           True    ReadyForNewScale        the last scale time was sufficiently old as to warrant a new scale
  ScalingActive         True    ValidMetricFound        the HPA was able to successfully calculate a replica count from pods metric http_requests
  ScalingLimited        False   DesiredWithinRange      the desired replica count is within the acceptable range
Events:
</code></pre><p>For this HorizontalPodAutoscaler, you can see several conditions in a healthy state. The first,
<code>AbleToScale</code>, indicates whether or not the HPA is able to fetch and update scales, as well as
whether or not any backoff-related conditions would prevent scaling. The second, <code>ScalingActive</code>,
indicates whether or not the HPA is enabled (i.e. the replica count of the target is not zero) and
is able to calculate desired scales. When it is <code>False</code>, it generally indicates problems with
fetching metrics. Finally, the last condition, <code>ScalingLimited</code>, indicates that the desired scale
was capped by the maximum or minimum of the HorizontalPodAutoscaler. This is an indication that
you may wish to raise or lower the minimum or maximum replica count constraints on your
HorizontalPodAutoscaler.</p><h2 id=quantities>Quantities</h2><p>All metrics in the HorizontalPodAutoscaler and metrics APIs are specified using
a special whole-number notation known in Kubernetes as a
<a class=glossary-tooltip title='A whole-number representation of small or large numbers using SI suffixes.' data-toggle=tooltip data-placement=top href='/docs/reference/glossary/?all=true#term-quantity' target=_blank aria-label=quantity>quantity</a>. For example,
the quantity <code>10500m</code> would be written as <code>10.5</code> in decimal notation. The metrics APIs
will return whole numbers without a suffix when possible, and will generally return
quantities in milli-units otherwise. This means you might see your metric value fluctuate
between <code>1</code> and <code>1500m</code>, or <code>1</code> and <code>1.5</code> when written in decimal notation.</p><h2 id=other-possible-scenarios>Other possible scenarios</h2><h3 id=creating-the-autoscaler-declaratively>Creating the autoscaler declaratively</h3><p>Instead of using <code>kubectl autoscale</code> command to create a HorizontalPodAutoscaler imperatively we
can use the following manifest to create it declaratively:</p><div class=highlight><div class=copy-code-icon style=text-align:right><a href=https://raw.githubusercontent.com/kubernetes/website/main/content/en/examples/application/hpa/php-apache.yaml download=application/hpa/php-apache.yaml><code>application/hpa/php-apache.yaml</code></a>
<img src=/images/copycode.svg style=max-height:24px;cursor:pointer onclick='copyCode("application-hpa-php-apache-yaml")' title="Copy application/hpa/php-apache.yaml to clipboard"></img></div><div class=includecode id=application-hpa-php-apache-yaml><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>autoscaling/v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>HorizontalPodAutoscaler<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>php-apache<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>scaleTargetRef</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>apps/v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Deployment<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>php-apache<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>minReplicas</span>:<span style=color:#bbb> </span><span style=color:#666>1</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>maxReplicas</span>:<span style=color:#bbb> </span><span style=color:#666>10</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>targetCPUUtilizationPercentage</span>:<span style=color:#bbb> </span><span style=color:#666>50</span><span style=color:#bbb>
</span></span></span></code></pre></div></div></div><p>Then, create the autoscaler by executing the following command:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl create -f https://k8s.io/examples/application/hpa/php-apache.yaml
</span></span></code></pre></div><pre tabindex=0><code>horizontalpodautoscaler.autoscaling/php-apache created
</code></pre></div><div class=td-content style=page-break-before:always><h1 id=pg-fbe2744f00d1aa4df4cdf4eea6a082d4>9 - Specifying a Disruption Budget for your Application</h1><div style=margin-top:10px;margin-bottom:10px><b>FEATURE STATE:</b> <code>Kubernetes v1.21 [stable]</code></div><p>This page shows how to limit the number of concurrent disruptions
that your application experiences, allowing for higher availability
while permitting the cluster administrator to manage the clusters
nodes.</p><h2 id=before-you-begin>Before you begin</h2>Your Kubernetes server must be at or later than version v1.21.
To check the version, enter <code>kubectl version</code>.<ul><li>You are the owner of an application running on a Kubernetes cluster that requires
high availability.</li><li>You should know how to deploy <a href=/docs/tasks/run-application/run-stateless-application-deployment/>Replicated Stateless Applications</a>
and/or <a href=/docs/tasks/run-application/run-replicated-stateful-application/>Replicated Stateful Applications</a>.</li><li>You should have read about <a href=/docs/concepts/workloads/pods/disruptions/>Pod Disruptions</a>.</li><li>You should confirm with your cluster owner or service provider that they respect
Pod Disruption Budgets.</li></ul><h2 id=protecting-an-application-with-a-poddisruptionbudget>Protecting an Application with a PodDisruptionBudget</h2><ol><li>Identify what application you want to protect with a PodDisruptionBudget (PDB).</li><li>Think about how your application reacts to disruptions.</li><li>Create a PDB definition as a YAML file.</li><li>Create the PDB object from the YAML file.</li></ol><h2 id=identify-an-application-to-protect>Identify an Application to Protect</h2><p>The most common use case when you want to protect an application
specified by one of the built-in Kubernetes controllers:</p><ul><li>Deployment</li><li>ReplicationController</li><li>ReplicaSet</li><li>StatefulSet</li></ul><p>In this case, make a note of the controller's <code>.spec.selector</code>; the same
selector goes into the PDBs <code>.spec.selector</code>.</p><p>From version 1.15 PDBs support custom controllers where the <a href=/docs/tasks/extend-kubernetes/custom-resources/custom-resource-definitions/#scale-subresource>scale subresource</a> is enabled.</p><p>You can also use PDBs with pods which are not controlled by one of the above
controllers, or arbitrary groups of pods, but there are some restrictions,
described in <a href=#arbitrary-controllers-and-selectors>Arbitrary Controllers and Selectors</a>.</p><h2 id=think-about-how-your-application-reacts-to-disruptions>Think about how your application reacts to disruptions</h2><p>Decide how many instances can be down at the same time for a short period
due to a voluntary disruption.</p><ul><li>Stateless frontends:<ul><li>Concern: don't reduce serving capacity by more than 10%.<ul><li>Solution: use PDB with minAvailable 90% for example.</li></ul></li></ul></li><li>Single-instance Stateful Application:<ul><li>Concern: do not terminate this application without talking to me.<ul><li>Possible Solution 1: Do not use a PDB and tolerate occasional downtime.</li><li>Possible Solution 2: Set PDB with maxUnavailable=0. Have an understanding
(outside of Kubernetes) that the cluster operator needs to consult you before
termination. When the cluster operator contacts you, prepare for downtime,
and then delete the PDB to indicate readiness for disruption. Recreate afterwards.</li></ul></li></ul></li><li>Multiple-instance Stateful application such as Consul, ZooKeeper, or etcd:<ul><li>Concern: Do not reduce number of instances below quorum, otherwise writes fail.<ul><li>Possible Solution 1: set maxUnavailable to 1 (works with varying scale of application).</li><li>Possible Solution 2: set minAvailable to quorum-size (e.g. 3 when scale is 5). (Allows more disruptions at once).</li></ul></li></ul></li><li>Restartable Batch Job:<ul><li>Concern: Job needs to complete in case of voluntary disruption.<ul><li>Possible solution: Do not create a PDB. The Job controller will create a replacement pod.</li></ul></li></ul></li></ul><h3 id=rounding-logic-when-specifying-percentages>Rounding logic when specifying percentages</h3><p>Values for <code>minAvailable</code> or <code>maxUnavailable</code> can be expressed as integers or as a percentage.</p><ul><li>When you specify an integer, it represents a number of Pods. For instance, if you set <code>minAvailable</code> to 10, then 10
Pods must always be available, even during a disruption.</li><li>When you specify a percentage by setting the value to a string representation of a percentage (eg. <code>"50%"</code>), it represents a percentage of
total Pods. For instance, if you set <code>maxUnavailable</code> to <code>"50%"</code>, then only 50% of the Pods can be unavailable during a
disruption.</li></ul><p>When you specify the value as a percentage, it may not map to an exact number of Pods. For example, if you have 7 Pods and
you set <code>minAvailable</code> to <code>"50%"</code>, it's not immediately obvious whether that means 3 Pods or 4 Pods must be available.
Kubernetes rounds up to the nearest integer, so in this case, 4 Pods must be available. You can examine the
<a href=https://github.com/kubernetes/kubernetes/blob/23be9587a0f8677eb8091464098881df939c44a9/pkg/controller/disruption/disruption.go#L539>code</a>
that controls this behavior.</p><h2 id=specifying-a-poddisruptionbudget>Specifying a PodDisruptionBudget</h2><p>A <code>PodDisruptionBudget</code> has three fields:</p><ul><li>A label selector <code>.spec.selector</code> to specify the set of
pods to which it applies. This field is required.</li><li><code>.spec.minAvailable</code> which is a description of the number of pods from that
set that must still be available after the eviction, even in the absence
of the evicted pod. <code>minAvailable</code> can be either an absolute number or a percentage.</li><li><code>.spec.maxUnavailable</code> (available in Kubernetes 1.7 and higher) which is a description
of the number of pods from that set that can be unavailable after the eviction.
It can be either an absolute number or a percentage.</li></ul><div class="alert alert-info note callout" role=alert><strong>Note:</strong> The behavior for an empty selector differs between the policy/v1beta1 and policy/v1 APIs for
PodDisruptionBudgets. For policy/v1beta1 an empty selector matches zero pods, while
for policy/v1 an empty selector matches every pod in the namespace.</div><p>You can specify only one of <code>maxUnavailable</code> and <code>minAvailable</code> in a single <code>PodDisruptionBudget</code>.
<code>maxUnavailable</code> can only be used to control the eviction of pods
that have an associated controller managing them. In the examples below, "desired replicas"
is the <code>scale</code> of the controller managing the pods being selected by the
<code>PodDisruptionBudget</code>.</p><p>Example 1: With a <code>minAvailable</code> of 5, evictions are allowed as long as they leave behind
5 or more healthy pods among those selected by the PodDisruptionBudget's <code>selector</code>.</p><p>Example 2: With a <code>minAvailable</code> of 30%, evictions are allowed as long as at least 30%
of the number of desired replicas are healthy.</p><p>Example 3: With a <code>maxUnavailable</code> of 5, evictions are allowed as long as there are at most 5
unhealthy replicas among the total number of desired replicas.</p><p>Example 4: With a <code>maxUnavailable</code> of 30%, evictions are allowed as long as no more than 30%
of the desired replicas are unhealthy.</p><p>In typical usage, a single budget would be used for a collection of pods managed by
a controller—for example, the pods in a single ReplicaSet or StatefulSet.</p><div class="alert alert-info note callout" role=alert><strong>Note:</strong> A disruption budget does not truly guarantee that the specified
number/percentage of pods will always be up. For example, a node that hosts a
pod from the collection may fail when the collection is at the minimum size
specified in the budget, thus bringing the number of available pods from the
collection below the specified size. The budget can only protect against
voluntary evictions, not all causes of unavailability.</div><p>If you set <code>maxUnavailable</code> to 0% or 0, or you set <code>minAvailable</code> to 100% or the number of replicas,
you are requiring zero voluntary evictions. When you set zero voluntary evictions for a workload
object such as ReplicaSet, then you cannot successfully drain a Node running one of those Pods.
If you try to drain a Node where an unevictable Pod is running, the drain never completes. This is permitted as per the
semantics of <code>PodDisruptionBudget</code>.</p><p>You can find examples of pod disruption budgets defined below. They match pods with the label
<code>app: zookeeper</code>.</p><p>Example PDB Using minAvailable:</p><div class=highlight><div class=copy-code-icon style=text-align:right><a href=https://raw.githubusercontent.com/kubernetes/website/main/content/en/examples/policy/zookeeper-pod-disruption-budget-minavailable.yaml download=policy/zookeeper-pod-disruption-budget-minavailable.yaml><code>policy/zookeeper-pod-disruption-budget-minavailable.yaml</code></a>
<img src=/images/copycode.svg style=max-height:24px;cursor:pointer onclick='copyCode("policy-zookeeper-pod-disruption-budget-minavailable-yaml")' title="Copy policy/zookeeper-pod-disruption-budget-minavailable.yaml to clipboard"></img></div><div class=includecode id=policy-zookeeper-pod-disruption-budget-minavailable-yaml><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>policy/v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>PodDisruptionBudget<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>zk-pdb<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>minAvailable</span>:<span style=color:#bbb> </span><span style=color:#666>2</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>selector</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>matchLabels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>app</span>:<span style=color:#bbb> </span>zookeeper<span style=color:#bbb>
</span></span></span></code></pre></div></div></div><p>Example PDB Using maxUnavailable:</p><div class=highlight><div class=copy-code-icon style=text-align:right><a href=https://raw.githubusercontent.com/kubernetes/website/main/content/en/examples/policy/zookeeper-pod-disruption-budget-maxunavailable.yaml download=policy/zookeeper-pod-disruption-budget-maxunavailable.yaml><code>policy/zookeeper-pod-disruption-budget-maxunavailable.yaml</code></a>
<img src=/images/copycode.svg style=max-height:24px;cursor:pointer onclick='copyCode("policy-zookeeper-pod-disruption-budget-maxunavailable-yaml")' title="Copy policy/zookeeper-pod-disruption-budget-maxunavailable.yaml to clipboard"></img></div><div class=includecode id=policy-zookeeper-pod-disruption-budget-maxunavailable-yaml><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>policy/v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>PodDisruptionBudget<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>zk-pdb<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>maxUnavailable</span>:<span style=color:#bbb> </span><span style=color:#666>1</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>selector</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>matchLabels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>app</span>:<span style=color:#bbb> </span>zookeeper<span style=color:#bbb>
</span></span></span></code></pre></div></div></div><p>For example, if the above <code>zk-pdb</code> object selects the pods of a StatefulSet of size 3, both
specifications have the exact same meaning. The use of <code>maxUnavailable</code> is recommended as it
automatically responds to changes in the number of replicas of the corresponding controller.</p><h2 id=create-the-pdb-object>Create the PDB object</h2><p>You can create or update the PDB object using kubectl.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl apply -f mypdb.yaml
</span></span></code></pre></div><h2 id=check-the-status-of-the-pdb>Check the status of the PDB</h2><p>Use kubectl to check that your PDB is created.</p><p>Assuming you don't actually have pods matching <code>app: zookeeper</code> in your namespace,
then you'll see something like this:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get poddisruptionbudgets
</span></span></code></pre></div><pre tabindex=0><code>NAME     MIN AVAILABLE   MAX UNAVAILABLE   ALLOWED DISRUPTIONS   AGE
zk-pdb   2               N/A               0                     7s
</code></pre><p>If there are matching pods (say, 3), then you would see something like this:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get poddisruptionbudgets
</span></span></code></pre></div><pre tabindex=0><code>NAME     MIN AVAILABLE   MAX UNAVAILABLE   ALLOWED DISRUPTIONS   AGE
zk-pdb   2               N/A               1                     7s
</code></pre><p>The non-zero value for <code>ALLOWED DISRUPTIONS</code> means that the disruption controller has seen the pods,
counted the matching pods, and updated the status of the PDB.</p><p>You can get more information about the status of a PDB with this command:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get poddisruptionbudgets zk-pdb -o yaml
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>policy/v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>PodDisruptionBudget<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>annotations</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span>…<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>creationTimestamp</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;2020-03-04T04:22:56Z&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>generation</span>:<span style=color:#bbb> </span><span style=color:#666>1</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>zk-pdb<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span>…<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>status</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>currentHealthy</span>:<span style=color:#bbb> </span><span style=color:#666>3</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>desiredHealthy</span>:<span style=color:#bbb> </span><span style=color:#666>2</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>disruptionsAllowed</span>:<span style=color:#bbb> </span><span style=color:#666>1</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>expectedPods</span>:<span style=color:#bbb> </span><span style=color:#666>3</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>observedGeneration</span>:<span style=color:#bbb> </span><span style=color:#666>1</span><span style=color:#bbb>
</span></span></span></code></pre></div><h2 id=arbitrary-controllers-and-selectors>Arbitrary Controllers and Selectors</h2><p>You can skip this section if you only use PDBs with the built-in
application controllers (Deployment, ReplicationController, ReplicaSet, and StatefulSet),
with the PDB selector matching the controller's selector.</p><p>You can use a PDB with pods controlled by another type of controller, by an
"operator", or bare pods, but with these restrictions:</p><ul><li>only <code>.spec.minAvailable</code> can be used, not <code>.spec.maxUnavailable</code>.</li><li>only an integer value can be used with <code>.spec.minAvailable</code>, not a percentage.</li></ul><p>You can use a selector which selects a subset or superset of the pods belonging to a built-in
controller. The eviction API will disallow eviction of any pod covered by multiple PDBs,
so most users will want to avoid overlapping selectors. One reasonable use of overlapping
PDBs is when pods are being transitioned from one PDB to another.</p></div><div class=td-content style=page-break-before:always><h1 id=pg-52cd10ee3fc7c74a6c31043a2d489878>10 - Accessing the Kubernetes API from a Pod</h1><p>This guide demonstrates how to access the Kubernetes API from within a pod.</p><h2 id=before-you-begin>Before you begin</h2><p>You need to have a Kubernetes cluster, and the kubectl command-line tool must
be configured to communicate with your cluster. It is recommended to run this tutorial on a cluster with at least two nodes that are not acting as control plane hosts. If you do not already have a
cluster, you can create one by using
<a href=https://minikube.sigs.k8s.io/docs/tutorials/multi_node/>minikube</a>
or you can use one of these Kubernetes playgrounds:</p><ul><li><a href=https://killercoda.com/playgrounds/scenario/kubernetes>Killercoda</a></li><li><a href=http://labs.play-with-k8s.com/>Play with Kubernetes</a></li></ul><h2 id=accessing-the-api-from-within-a-pod>Accessing the API from within a Pod</h2><p>When accessing the API from within a Pod, locating and authenticating
to the API server are slightly different to the external client case.</p><p>The easiest way to use the Kubernetes API from a Pod is to use
one of the official <a href=/docs/reference/using-api/client-libraries/>client libraries</a>. These
libraries can automatically discover the API server and authenticate.</p><h3 id=using-official-client-libraries>Using Official Client Libraries</h3><p>From within a Pod, the recommended ways to connect to the Kubernetes API are:</p><ul><li><p>For a Go client, use the official <a href=https://github.com/kubernetes/client-go/>Go client library</a>.
The <code>rest.InClusterConfig()</code> function handles API host discovery and authentication automatically.
See <a href=https://git.k8s.io/client-go/examples/in-cluster-client-configuration/main.go>an example here</a>.</p></li><li><p>For a Python client, use the official <a href=https://github.com/kubernetes-client/python/>Python client library</a>.
The <code>config.load_incluster_config()</code> function handles API host discovery and authentication automatically.
See <a href=https://github.com/kubernetes-client/python/blob/master/examples/in_cluster_config.py>an example here</a>.</p></li><li><p>There are a number of other libraries available, please refer to the <a href=/docs/reference/using-api/client-libraries/>Client Libraries</a> page.</p></li></ul><p>In each case, the service account credentials of the Pod are used to communicate
securely with the API server.</p><h3 id=directly-accessing-the-rest-api>Directly accessing the REST API</h3><p>While running in a Pod, the Kubernetes apiserver is accessible via a Service named
<code>kubernetes</code> in the <code>default</code> namespace. Therefore, Pods can use the
<code>kubernetes.default.svc</code> hostname to query the API server. Official client libraries
do this automatically.</p><p>The recommended way to authenticate to the API server is with a
<a href=/docs/tasks/configure-pod-container/configure-service-account/>service account</a>
credential. By default, a Pod
is associated with a service account, and a credential (token) for that
service account is placed into the filesystem tree of each container in that Pod,
at <code>/var/run/secrets/kubernetes.io/serviceaccount/token</code>.</p><p>If available, a certificate bundle is placed into the filesystem tree of each
container at <code>/var/run/secrets/kubernetes.io/serviceaccount/ca.crt</code>, and should be
used to verify the serving certificate of the API server.</p><p>Finally, the default namespace to be used for namespaced API operations is placed in a file
at <code>/var/run/secrets/kubernetes.io/serviceaccount/namespace</code> in each container.</p><h3 id=using-kubectl-proxy>Using kubectl proxy</h3><p>If you would like to query the API without an official client library, you can run <code>kubectl proxy</code>
as the <a href=/docs/tasks/inject-data-application/define-command-argument-container/>command</a>
of a new sidecar container in the Pod. This way, <code>kubectl proxy</code> will authenticate
to the API and expose it on the <code>localhost</code> interface of the Pod, so that other containers
in the Pod can use it directly.</p><h3 id=without-using-a-proxy>Without using a proxy</h3><p>It is possible to avoid using the kubectl proxy by passing the authentication token
directly to the API server. The internal certificate secures the connection.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span><span style=color:#080;font-style:italic># Point to the internal API server hostname</span>
</span></span><span style=display:flex><span><span style=color:#b8860b>APISERVER</span><span style=color:#666>=</span>https://kubernetes.default.svc
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#080;font-style:italic># Path to ServiceAccount token</span>
</span></span><span style=display:flex><span><span style=color:#b8860b>SERVICEACCOUNT</span><span style=color:#666>=</span>/var/run/secrets/kubernetes.io/serviceaccount
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#080;font-style:italic># Read this Pod&#39;s namespace</span>
</span></span><span style=display:flex><span><span style=color:#b8860b>NAMESPACE</span><span style=color:#666>=</span><span style=color:#a2f;font-weight:700>$(</span>cat <span style=color:#b68;font-weight:700>${</span><span style=color:#b8860b>SERVICEACCOUNT</span><span style=color:#b68;font-weight:700>}</span>/namespace<span style=color:#a2f;font-weight:700>)</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#080;font-style:italic># Read the ServiceAccount bearer token</span>
</span></span><span style=display:flex><span><span style=color:#b8860b>TOKEN</span><span style=color:#666>=</span><span style=color:#a2f;font-weight:700>$(</span>cat <span style=color:#b68;font-weight:700>${</span><span style=color:#b8860b>SERVICEACCOUNT</span><span style=color:#b68;font-weight:700>}</span>/token<span style=color:#a2f;font-weight:700>)</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#080;font-style:italic># Reference the internal certificate authority (CA)</span>
</span></span><span style=display:flex><span><span style=color:#b8860b>CACERT</span><span style=color:#666>=</span><span style=color:#b68;font-weight:700>${</span><span style=color:#b8860b>SERVICEACCOUNT</span><span style=color:#b68;font-weight:700>}</span>/ca.crt
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#080;font-style:italic># Explore the API with TOKEN</span>
</span></span><span style=display:flex><span>curl --cacert <span style=color:#b68;font-weight:700>${</span><span style=color:#b8860b>CACERT</span><span style=color:#b68;font-weight:700>}</span> --header <span style=color:#b44>&#34;Authorization: Bearer </span><span style=color:#b68;font-weight:700>${</span><span style=color:#b8860b>TOKEN</span><span style=color:#b68;font-weight:700>}</span><span style=color:#b44>&#34;</span> -X GET <span style=color:#b68;font-weight:700>${</span><span style=color:#b8860b>APISERVER</span><span style=color:#b68;font-weight:700>}</span>/api
</span></span></code></pre></div><p>The output will be similar to this:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-json data-lang=json><span style=display:flex><span>{
</span></span><span style=display:flex><span>  <span style=color:green;font-weight:700>&#34;kind&#34;</span>: <span style=color:#b44>&#34;APIVersions&#34;</span>,
</span></span><span style=display:flex><span>  <span style=color:green;font-weight:700>&#34;versions&#34;</span>: [
</span></span><span style=display:flex><span>    <span style=color:#b44>&#34;v1&#34;</span>
</span></span><span style=display:flex><span>  ],
</span></span><span style=display:flex><span>  <span style=color:green;font-weight:700>&#34;serverAddressByClientCIDRs&#34;</span>: [
</span></span><span style=display:flex><span>    {
</span></span><span style=display:flex><span>      <span style=color:green;font-weight:700>&#34;clientCIDR&#34;</span>: <span style=color:#b44>&#34;0.0.0.0/0&#34;</span>,
</span></span><span style=display:flex><span>      <span style=color:green;font-weight:700>&#34;serverAddress&#34;</span>: <span style=color:#b44>&#34;10.0.1.149:443&#34;</span>
</span></span><span style=display:flex><span>    }
</span></span><span style=display:flex><span>  ]
</span></span><span style=display:flex><span>}
</span></span></code></pre></div></div></main></div></div><footer class=d-print-none><div class=footer__links><nav><a class=text-white href=/docs/home/>Home</a>
<a class=text-white href=/blog/>Blog</a>
<a class=text-white href=/training/>Training</a>
<a class=text-white href=/partners/>Partners</a>
<a class=text-white href=/community/>Community</a>
<a class=text-white href=/case-studies/>Case Studies</a></nav></div><div class=container-fluid><div class=row><div class="col-6 col-sm-2 text-xs-center order-sm-2"><ul class="list-inline mb-0"><li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title="User mailing list" aria-label="User mailing list"><a class=text-white target=_blank href=https://discuss.kubernetes.io><i class="fa fa-envelope"></i></a></li><li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title=Twitter aria-label=Twitter><a class=text-white target=_blank href=https://twitter.com/kubernetesio><i class="fab fa-twitter"></i></a></li><li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title=Calendar aria-label=Calendar><a class=text-white target=_blank href="https://calendar.google.com/calendar/embed?src=calendar%40kubernetes.io"><i class="fas fa-calendar-alt"></i></a></li><li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title=Youtube aria-label=Youtube><a class=text-white target=_blank href=https://youtube.com/kubernetescommunity><i class="fab fa-youtube"></i></a></li></ul></div><div class="col-6 col-sm-2 text-right text-xs-center order-sm-3"><ul class="list-inline mb-0"><li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title=GitHub aria-label=GitHub><a class=text-white target=_blank href=https://github.com/kubernetes/kubernetes><i class="fab fa-github"></i></a></li><li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title=Slack aria-label=Slack><a class=text-white target=_blank href=https://slack.k8s.io><i class="fab fa-slack"></i></a></li><li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title=Contribute aria-label=Contribute><a class=text-white target=_blank href=https://git.k8s.io/community/contributors/guide><i class="fas fa-edit"></i></a></li><li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title="Stack Overflow" aria-label="Stack Overflow"><a class=text-white target=_blank href=https://stackoverflow.com/questions/tagged/kubernetes><i class="fab fa-stack-overflow"></i></a></li></ul></div><div class="col-12 col-sm-8 text-center order-sm-2"><small class=text-white>&copy; 2023 The Kubernetes Authors | Documentation Distributed under <a href=https://git.k8s.io/website/LICENSE class=light-text>CC BY 4.0</a></small><br><small class=text-white>Copyright &copy; 2023 The Linux Foundation &reg;. All rights reserved. The Linux Foundation has registered trademarks and uses trademarks. For a list of trademarks of The Linux Foundation, please see our <a href=https://www.linuxfoundation.org/trademark-usage class=light-text>Trademark Usage page</a></small><br><small class=text-white>ICP license: 京ICP备17074266号-3</small></div></div></div></footer></div><script src=/js/jquery-3.6.0.min.js integrity=sha384-vtXRMe3mGCbOeY7l30aIg8H9p3GdeSe4IFlP6G8JMa7o7lXvnz3GFKzPxzJdPfGK crossorigin=anonymous></script>
<script src=/js/popper-1.16.1.min.js intregrity=sha384-9/reFTGAW83EW2RDu2S0VKaIzap3H66lZH81PoYlFhbGU+6BZp6G7niu735Sk7lN crossorigin=anonymous></script>
<script src=/js/bootstrap-4.6.1.min.js integrity=sha384-VHvPCCyXqtD5DqJeNxl2dtTyhF78xXNXdkwX1CZeRusQfRKp+tA7hAShOK/B/fQ2 crossorigin=anonymous></script>
<script src=/js/script.js></script>
<script async src=/js/mermaid-8.13.4.min.js integrity=sha384-5hHNvPeMrNH14oM3IcQofDoBhiclNK3g2+hnEinKzQ07C4AliMeVpnvxuiwEGpaO crossorigin=anonymous></script>
<script src=/js/main.min.5c0bf7f21dc4f66485f74efbbeeff28a7e4f8cddaac1bae47043159c922ff3a3.js integrity="sha256-XAv38h3E9mSF9077vu/yin5PjN2qwbrkcEMVnJIv86M=" crossorigin=anonymous></script></body></html>