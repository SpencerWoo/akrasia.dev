<!doctype html><html lang=en class=no-js><head><meta name=robots content="noindex, nofollow"><link rel=alternate hreflang=zh-cn href=https://kubernetes.io/zh-cn/docs/tutorials/><link rel=alternate hreflang=ko href=https://kubernetes.io/ko/docs/tutorials/><link rel=alternate hreflang=ja href=https://kubernetes.io/ja/docs/tutorials/><link rel=alternate hreflang=fr href=https://kubernetes.io/fr/docs/tutorials/><link rel=alternate hreflang=it href=https://kubernetes.io/it/docs/tutorials/><link rel=alternate hreflang=de href=https://kubernetes.io/de/docs/tutorials/><link rel=alternate hreflang=es href=https://kubernetes.io/es/docs/tutorials/><link rel=alternate hreflang=pt-br href=https://kubernetes.io/pt-br/docs/tutorials/><link rel=alternate hreflang=id href=https://kubernetes.io/id/docs/tutorials/><link rel=alternate hreflang=hi href=https://kubernetes.io/hi/docs/tutorials/><link rel=alternate hreflang=ru href=https://kubernetes.io/ru/docs/tutorials/><link rel=alternate hreflang=pl href=https://kubernetes.io/pl/docs/tutorials/><link rel=alternate hreflang=uk href=https://kubernetes.io/uk/docs/tutorials/><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=generator content="Hugo 0.110.0"><link rel=canonical type=text/html href=https://kubernetes.io/docs/tutorials/><link rel="shortcut icon" type=image/png href=/images/favicon.png><link rel=apple-touch-icon href=/favicons/apple-touch-icon-180x180.png sizes=180x180><link rel=manifest href=/manifest.webmanifest><link rel=apple-touch-icon href=/images/kubernetes-192x192.png><title>Tutorials | Kubernetes</title><meta property="og:title" content="Tutorials"><meta property="og:description" content="Production-Grade Container Orchestration"><meta property="og:type" content="website"><meta property="og:url" content="https://kubernetes.io/docs/tutorials/"><meta property="og:site_name" content="Kubernetes"><meta itemprop=name content="Tutorials"><meta itemprop=description content="Production-Grade Container Orchestration"><meta name=twitter:card content="summary"><meta name=twitter:title content="Tutorials"><meta name=twitter:description content="Production-Grade Container Orchestration"><link href=/scss/main.css rel=stylesheet><script type=application/ld+json>{"@context":"https://schema.org","@type":"Organization","url":"https://kubernetes.io","logo":"https://kubernetes.io/images/favicon.png","potentialAction":{"@type":"SearchAction","target":"https://kubernetes.io/search/?q={search_term_string}","query-input":"required name=search_term_string"}}</script><meta name=theme-color content="#326ce5"><link rel=stylesheet href=/css/feature-states.css><meta name=description content="This section of the Kubernetes documentation contains tutorials. A tutorial shows how to accomplish a goal that is larger than a single task. Typically a tutorial has several sections, each of which has a sequence of steps. Before walking through each tutorial, you may want to bookmark the Standardized Glossary page for later references.
Basics Kubernetes Basics is an in-depth interactive tutorial that helps you understand the Kubernetes system and try out some basic Kubernetes features."><meta property="og:description" content="This section of the Kubernetes documentation contains tutorials. A tutorial shows how to accomplish a goal that is larger than a single task. Typically a tutorial has several sections, each of which has a sequence of steps. Before walking through each tutorial, you may want to bookmark the Standardized Glossary page for later references.
Basics Kubernetes Basics is an in-depth interactive tutorial that helps you understand the Kubernetes system and try out some basic Kubernetes features."><meta name=twitter:description content="This section of the Kubernetes documentation contains tutorials. A tutorial shows how to accomplish a goal that is larger than a single task. Typically a tutorial has several sections, each of which has a sequence of steps. Before walking through each tutorial, you may want to bookmark the Standardized Glossary page for later references.
Basics Kubernetes Basics is an in-depth interactive tutorial that helps you understand the Kubernetes system and try out some basic Kubernetes features."><meta property="og:url" content="https://kubernetes.io/docs/tutorials/"><meta property="og:title" content="Tutorials"><meta name=twitter:title content="Tutorials"><meta name=twitter:image content="https://kubernetes.io/images/favicon.png"><meta name=twitter:image:alt content="Kubernetes"><meta property="og:image" content="/images/kubernetes-horizontal-color.png"><meta property="og:type" content="article"><script src=/js/jquery-3.6.0.min.js intregrity=sha384-vtXRMe3mGCbOeY7l30aIg8H9p3GdeSe4IFlP6G8JMa7o7lXvnz3GFKzPxzJdPfGK crossorigin=anonymous></script></head><body class=td-section><header><nav class="js-navbar-scroll navbar navbar-expand navbar-dark flex-column flex-md-row td-navbar" data-auto-burger=primary><a class=navbar-brand href=/></a><div class="td-navbar-nav-scroll ml-md-auto" id=main_navbar><ul class="navbar-nav mt-2 mt-lg-0"><li class="nav-item mr-2 mb-lg-0"><a class="nav-link active" href=/docs/>Documentation</a></li><li class="nav-item mr-2 mb-lg-0"><a class=nav-link href=/blog/>Kubernetes Blog</a></li><li class="nav-item mr-2 mb-lg-0"><a class=nav-link href=/training/>Training</a></li><li class="nav-item mr-2 mb-lg-0"><a class=nav-link href=/partners/>Partners</a></li><li class="nav-item mr-2 mb-lg-0"><a class=nav-link href=/community/>Community</a></li><li class="nav-item mr-2 mb-lg-0"><a class=nav-link href=/case-studies/>Case Studies</a></li><li class="nav-item dropdown"><a class="nav-link dropdown-toggle" href=# id=navbarDropdown role=button data-toggle=dropdown aria-haspopup=true aria-expanded=false>Versions</a><div class="dropdown-menu dropdown-menu-right" aria-labelledby=navbarDropdownMenuLink><a class=dropdown-item href=/releases>Release Information</a>
<a class=dropdown-item href=https://kubernetes.io/docs/tutorials/>v1.25</a>
<a class=dropdown-item href=https://v1-24.docs.kubernetes.io/docs/tutorials/>v1.24</a>
<a class=dropdown-item href=https://v1-23.docs.kubernetes.io/docs/tutorials/>v1.23</a>
<a class=dropdown-item href=https://v1-22.docs.kubernetes.io/docs/tutorials/>v1.22</a>
<a class=dropdown-item href=https://v1-21.docs.kubernetes.io/docs/tutorials/>v1.21</a></div></li><li class="nav-item dropdown"><a class="nav-link dropdown-toggle" href=# id=navbarDropdownMenuLink role=button data-toggle=dropdown aria-haspopup=true aria-expanded=false>English</a><div class="dropdown-menu dropdown-menu-right" aria-labelledby=navbarDropdownMenuLink><a class=dropdown-item href=/zh-cn/docs/tutorials/>中文 (Chinese)</a>
<a class=dropdown-item href=/ko/docs/tutorials/>한국어 (Korean)</a>
<a class=dropdown-item href=/ja/docs/tutorials/>日本語 (Japanese)</a>
<a class=dropdown-item href=/fr/docs/tutorials/>Français (French)</a>
<a class=dropdown-item href=/it/docs/tutorials/>Italiano (Italian)</a>
<a class=dropdown-item href=/de/docs/tutorials/>Deutsch (German)</a>
<a class=dropdown-item href=/es/docs/tutorials/>Español (Spanish)</a>
<a class=dropdown-item href=/pt-br/docs/tutorials/>Português (Portuguese)</a>
<a class=dropdown-item href=/id/docs/tutorials/>Bahasa Indonesia</a>
<a class=dropdown-item href=/hi/docs/tutorials/>हिन्दी (Hindi)</a>
<a class=dropdown-item href=/ru/docs/tutorials/>Русский (Russian)</a>
<a class=dropdown-item href=/pl/docs/tutorials/>Polski (Polish)</a>
<a class=dropdown-item href=/uk/docs/tutorials/>Українська (Ukrainian)</a></div></li></ul></div><button id=hamburger onclick=kub.toggleMenu() data-auto-burger-exclude><div></div></button></nav></header><div class="container-fluid td-outer"><div class=td-main><div class="row flex-xl-nowrap"><main class="col-12 col-md-9 col-xl-8 pl-md-5" role=main><div class=td-content><div class="pageinfo pageinfo-primary d-print-none"><p>This is the multi-page printable view of this section.
<a href=# onclick="return print(),!1">Click here to print</a>.</p><p><a href=/docs/tutorials/>Return to the regular view of this page</a>.</p></div><h1 class=title>Tutorials</h1><ul><li>1: <a href=#pg-5e3051fff9e84735871d9fb5e7b93f33>Hello Minikube</a></li><li>2: <a href=#pg-3c83f53a74233ace9b289ac5e24c3e62>Learn Kubernetes Basics</a></li><ul><li>2.1: <a href=#pg-7df66040311338d6098ebeab43ba9afb>Create a Cluster</a></li><ul><li>2.1.1: <a href=#pg-de49316920e97a82e36763cb66781ada>Using Minikube to Create a Cluster</a></li><li>2.1.2: <a href=#pg-323b75976001e8dfe35d67d61bc74f1a>Interactive Tutorial - Creating a Cluster</a></li></ul><li>2.2: <a href=#pg-76d78b3fba507f7ed33cef14a35b631d>Deploy an App</a></li><ul><li>2.2.1: <a href=#pg-2b1bba431989008c7493109a0f049ece>Using kubectl to Create a Deployment</a></li><li>2.2.2: <a href=#pg-f8997ec143b382fa6c9621941ea62ca3>Interactive Tutorial - Deploying an App</a></li></ul><li>2.3: <a href=#pg-250d620a73ec8be7e1f7d835574c4596>Explore Your App</a></li><ul><li>2.3.1: <a href=#pg-2771f4e8c45321b17cb0114a2d266453>Viewing Pods and Nodes</a></li><li>2.3.2: <a href=#pg-4b01eab98a9844ad91131079654199dd>Interactive Tutorial - Exploring Your App</a></li></ul><li>2.4: <a href=#pg-4b0e31c9e0eae68bbb0a358b4042ada9>Expose Your App Publicly</a></li><ul><li>2.4.1: <a href=#pg-8ef4dad8f743b191a9e8c6f891cb191a>Using a Service to Expose Your App</a></li><li>2.4.2: <a href=#pg-352241d22effe0714772d21c7d1b512d>Interactive Tutorial - Exposing Your App</a></li></ul><li>2.5: <a href=#pg-be4996c93fb39c459a30b6669569d423>Scale Your App</a></li><ul><li>2.5.1: <a href=#pg-d1c15c9bd4f625adbc13149b1475287c>Running Multiple Instances of Your App</a></li><li>2.5.2: <a href=#pg-7bdb3fbaa1177ff5dfa3fe86bd35ef59>Interactive Tutorial - Scaling Your App</a></li></ul><li>2.6: <a href=#pg-62b8b17dadfb55f1801cf8439e944e58>Update Your App</a></li><ul><li>2.6.1: <a href=#pg-12e04355145afad615ca3c38335ba019>Performing a Rolling Update</a></li><li>2.6.2: <a href=#pg-dddc0cb356c280e0339bcf42776987dc>Interactive Tutorial - Updating Your App</a></li></ul></ul><li>3: <a href=#pg-a3a0f1c6af19fc89ce24d8cd42c0249f>Configuration</a></li><ul><li>3.1: <a href=#pg-e08b0be51359b976a754112b96980f54>Example: Configuring a Java Microservice</a></li><ul><li>3.1.1: <a href=#pg-025ef96f86c52822a2738b8b11b60934>Externalizing config using MicroProfile, ConfigMaps and Secrets</a></li><li>3.1.2: <a href=#pg-ef2047c46d3cd16631bac27403e4cfdc>Interactive Tutorial - Configuring a Java Microservice</a></li></ul><li>3.2: <a href=#pg-2efe621cc085b350c8c4574e6f7f1311>Configuring Redis using a ConfigMap</a></li></ul><li>4: <a href=#pg-fe7e92bed8fb92872b139f12c4568cdb>Security</a></li><ul><li>4.1: <a href=#pg-d5f847bcdb6f7efbfc9c8a180d73e29a>Apply Pod Security Standards at the Cluster Level</a></li><li>4.2: <a href=#pg-31a6c137cfc5bfea9d88f4b109109465>Apply Pod Security Standards at the Namespace Level</a></li><li>4.3: <a href=#pg-fca078b8ac6b82352ed52187a2da91b7>Restrict a Container's Access to Resources with AppArmor</a></li><li>4.4: <a href=#pg-8b105172a11322c70d0223bc9dff1904>Restrict a Container's Syscalls with seccomp</a></li></ul><li>5: <a href=#pg-1efbbc2c3015389f835b1661d5effb29>Stateless Applications</a></li><ul><li>5.1: <a href=#pg-62caf420877232190a7404b8d93c6724>Exposing an External IP Address to Access an Application in a Cluster</a></li><li>5.2: <a href=#pg-8c56795c6614cc5f52434ecc756448ac>Example: Deploying PHP Guestbook application with Redis</a></li></ul><li>6: <a href=#pg-d6336d9712aa433eb5f0fb8cbed6bef7>Stateful Applications</a></li><ul><li>6.1: <a href=#pg-42e39658021b706bcc9478c8cc73c4a3>StatefulSet Basics</a></li><li>6.2: <a href=#pg-27580b3f65f3c2da07fc0f83be69da75>Example: Deploying WordPress and MySQL with Persistent Volumes</a></li><li>6.3: <a href=#pg-bf0d8e08fddd6e0282709b9fef8b5f67>Example: Deploying Cassandra with a StatefulSet</a></li><li>6.4: <a href=#pg-4bfac214b5eb9ebddaf1f3811901d327>Running ZooKeeper, A Distributed System Coordinator</a></li></ul><li>7: <a href=#pg-97489f0aa8ac2df31a0d6b444a7bde62>Services</a></li><ul><li>7.1: <a href=#pg-bc0a2760d2865e91c501bc2467cd1a4b>Connecting Applications with Services</a></li><li>7.2: <a href=#pg-5642e8c51749e4fe2e6a2ccc207f1fab>Using Source IP</a></li></ul></ul><div class=content><p>This section of the Kubernetes documentation contains tutorials.
A tutorial shows how to accomplish a goal that is larger than a single
<a href=/docs/tasks/>task</a>. Typically a tutorial has several sections,
each of which has a sequence of steps.
Before walking through each tutorial, you may want to bookmark the
<a href=/docs/reference/glossary/>Standardized Glossary</a> page for later references.</p><h2 id=basics>Basics</h2><ul><li><p><a href=/docs/tutorials/kubernetes-basics/>Kubernetes Basics</a> is an in-depth interactive tutorial that helps you understand the Kubernetes system and try out some basic Kubernetes features.</p></li><li><p><a href=https://www.edx.org/course/introduction-kubernetes-linuxfoundationx-lfs158x#>Introduction to Kubernetes (edX)</a></p></li><li><p><a href=/docs/tutorials/hello-minikube/>Hello Minikube</a></p></li></ul><h2 id=configuration>Configuration</h2><ul><li><p><a href=/docs/tutorials/configuration/configure-java-microservice/>Example: Configuring a Java Microservice</a></p></li><li><p><a href=/docs/tutorials/configuration/configure-redis-using-configmap/>Configuring Redis Using a ConfigMap</a></p></li></ul><h2 id=stateless-applications>Stateless Applications</h2><ul><li><p><a href=/docs/tutorials/stateless-application/expose-external-ip-address/>Exposing an External IP Address to Access an Application in a Cluster</a></p></li><li><p><a href=/docs/tutorials/stateless-application/guestbook/>Example: Deploying PHP Guestbook application with Redis</a></p></li></ul><h2 id=stateful-applications>Stateful Applications</h2><ul><li><p><a href=/docs/tutorials/stateful-application/basic-stateful-set/>StatefulSet Basics</a></p></li><li><p><a href=/docs/tutorials/stateful-application/mysql-wordpress-persistent-volume/>Example: WordPress and MySQL with Persistent Volumes</a></p></li><li><p><a href=/docs/tutorials/stateful-application/cassandra/>Example: Deploying Cassandra with Stateful Sets</a></p></li><li><p><a href=/docs/tutorials/stateful-application/zookeeper/>Running ZooKeeper, A CP Distributed System</a></p></li></ul><h2 id=services>Services</h2><ul><li><a href=/docs/tutorials/services/connect-applications-service/>Connecting Applications with Services</a></li><li><a href=/docs/tutorials/services/source-ip/>Using Source IP</a></li></ul><h2 id=security>Security</h2><ul><li><a href=/docs/tutorials/security/cluster-level-pss/>Apply Pod Security Standards at Cluster level</a></li><li><a href=/docs/tutorials/security/ns-level-pss/>Apply Pod Security Standards at Namespace level</a></li><li><a href=/docs/tutorials/security/apparmor/>AppArmor</a></li><li><a href=/docs/tutorials/security/seccomp/>seccomp</a></li></ul><h2 id=what-s-next>What's next</h2><p>If you would like to write a tutorial, see
<a href=/docs/contribute/style/page-content-types/>Content Page Types</a>
for information about the tutorial page type.</p></div></div><div class=td-content style=page-break-before:always><h1 id=pg-5e3051fff9e84735871d9fb5e7b93f33>1 - Hello Minikube</h1><p>This tutorial shows you how to run a sample app
on Kubernetes using minikube and Katacoda.
Katacoda provides a free, in-browser Kubernetes environment.</p><div class="alert alert-info note callout" role=alert><strong>Note:</strong> You can also follow this tutorial if you've installed minikube locally.
See <a href=https://minikube.sigs.k8s.io/docs/start/>minikube start</a> for installation instructions.</div><h2 id=objectives>Objectives</h2><ul><li>Deploy a sample application to minikube.</li><li>Run the app.</li><li>View application logs.</li></ul><h2 id=before-you-begin>Before you begin</h2><p>This tutorial provides a container image that uses NGINX to echo back all the requests.</p><h2 id=create-a-minikube-cluster>Create a minikube cluster</h2><ol><li><p>Click <strong>Launch Terminal</strong></p><script defer src=https://katacoda.com/embed.js></script>
<button class=button onclick=window.katacoda.init()>Launch Terminal</button></li></ol><div class="alert alert-info note callout" role=alert><strong>Note:</strong> If you installed minikube locally, run <code>minikube start</code>. Before you run <code>minikube dashboard</code>, you should open a new terminal, start <code>minikube dashboard</code> there, and then switch back to the main terminal.</div><ol start=2><li><p>Open the Kubernetes dashboard in a browser:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>minikube dashboard
</span></span></code></pre></div></li><li><p>Katacoda environment only: At the top of the terminal pane, click the plus sign, and then click <strong>Select port to view on Host 1</strong>.</p></li><li><p>Katacoda environment only: Type <code>30000</code>, and then click <strong>Display Port</strong>.</p></li></ol><div class="alert alert-info note callout" role=alert><strong>Note:</strong><p>The <code>dashboard</code> command enables the dashboard add-on and opens the proxy in the default web browser.
You can create Kubernetes resources on the dashboard such as Deployment and Service.</p><p>If you are running in an environment as root, see <a href=#open-dashboard-with-url>Open Dashboard with URL</a>.</p><p>By default, the dashboard is only accessible from within the internal Kubernetes virtual network.
The <code>dashboard</code> command creates a temporary proxy to make the dashboard accessible from outside the Kubernetes virtual network.</p><p>To stop the proxy, run <code>Ctrl+C</code> to exit the process.
After the command exits, the dashboard remains running in the Kubernetes cluster.
You can run the <code>dashboard</code> command again to create another proxy to access the dashboard.</p></div><h2 id=open-dashboard-with-url>Open Dashboard with URL</h2><p>If you don't want to open a web browser, run the dashboard command with the <code>--url</code> flag to emit a URL:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>minikube dashboard --url
</span></span></code></pre></div><h2 id=create-a-deployment>Create a Deployment</h2><p>A Kubernetes <a href=/docs/concepts/workloads/pods/><em>Pod</em></a> is a group of one or more Containers,
tied together for the purposes of administration and networking. The Pod in this
tutorial has only one Container. A Kubernetes
<a href=/docs/concepts/workloads/controllers/deployment/><em>Deployment</em></a> checks on the health of your
Pod and restarts the Pod's Container if it terminates. Deployments are the
recommended way to manage the creation and scaling of Pods.</p><ol><li><p>Use the <code>kubectl create</code> command to create a Deployment that manages a Pod. The
Pod runs a Container based on the provided Docker image.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl create deployment hello-node --image<span style=color:#666>=</span>registry.k8s.io/e2e-test-images/agnhost:2.39 -- /agnhost netexec --http-port<span style=color:#666>=</span><span style=color:#666>8080</span>
</span></span></code></pre></div></li><li><p>View the Deployment:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get deployments
</span></span></code></pre></div><p>The output is similar to:</p><pre tabindex=0><code>NAME         READY   UP-TO-DATE   AVAILABLE   AGE
hello-node   1/1     1            1           1m
</code></pre></li><li><p>View the Pod:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get pods
</span></span></code></pre></div><p>The output is similar to:</p><pre tabindex=0><code>NAME                          READY     STATUS    RESTARTS   AGE
hello-node-5f76cf6ccf-br9b5   1/1       Running   0          1m
</code></pre></li><li><p>View cluster events:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get events
</span></span></code></pre></div></li><li><p>View the <code>kubectl</code> configuration:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl config view
</span></span></code></pre></div></li></ol><div class="alert alert-info note callout" role=alert><strong>Note:</strong> For more information about <code>kubectl</code> commands, see the <a href=/docs/reference/kubectl/>kubectl overview</a>.</div><h2 id=create-a-service>Create a Service</h2><p>By default, the Pod is only accessible by its internal IP address within the
Kubernetes cluster. To make the <code>hello-node</code> Container accessible from outside the
Kubernetes virtual network, you have to expose the Pod as a
Kubernetes <a href=/docs/concepts/services-networking/service/><em>Service</em></a>.</p><ol><li><p>Expose the Pod to the public internet using the <code>kubectl expose</code> command:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl expose deployment hello-node --type<span style=color:#666>=</span>LoadBalancer --port<span style=color:#666>=</span><span style=color:#666>8080</span>
</span></span></code></pre></div><p>The <code>--type=LoadBalancer</code> flag indicates that you want to expose your Service
outside of the cluster.</p><p>The application code inside the image <code>registry.k8s.io/echoserver</code> only listens on TCP port 8080. If you used
<code>kubectl expose</code> to expose a different port, clients could not connect to that other port.</p></li><li><p>View the Service you created:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get services
</span></span></code></pre></div><p>The output is similar to:</p><pre tabindex=0><code>NAME         TYPE           CLUSTER-IP      EXTERNAL-IP   PORT(S)          AGE
hello-node   LoadBalancer   10.108.144.78   &lt;pending&gt;     8080:30369/TCP   21s
kubernetes   ClusterIP      10.96.0.1       &lt;none&gt;        443/TCP          23m
</code></pre><p>On cloud providers that support load balancers,
an external IP address would be provisioned to access the Service. On minikube,
the <code>LoadBalancer</code> type makes the Service accessible through the <code>minikube service</code>
command.</p></li><li><p>Run the following command:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>minikube service hello-node
</span></span></code></pre></div></li><li><p>Katacoda environment only: Click the plus sign, and then click <strong>Select port to view on Host 1</strong>.</p></li><li><p>Katacoda environment only: Note the 5-digit port number displayed opposite to <code>8080</code> in services output. This port number is randomly generated and it can be different for you. Type your number in the port number text box, then click Display Port. Using the example from earlier, you would type <code>30369</code>.</p><p>This opens up a browser window that serves your app and shows the app's response.</p></li></ol><h2 id=enable-addons>Enable addons</h2><p>The minikube tool includes a set of built-in <a class=glossary-tooltip title='Resources that extend the functionality of Kubernetes.' data-toggle=tooltip data-placement=top href=/docs/concepts/cluster-administration/addons/ target=_blank aria-label=addons>addons</a> that can be enabled, disabled and opened in the local Kubernetes environment.</p><ol><li><p>List the currently supported addons:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>minikube addons list
</span></span></code></pre></div><p>The output is similar to:</p><pre tabindex=0><code>addon-manager: enabled
dashboard: enabled
default-storageclass: enabled
efk: disabled
freshpod: disabled
gvisor: disabled
helm-tiller: disabled
ingress: disabled
ingress-dns: disabled
logviewer: disabled
metrics-server: disabled
nvidia-driver-installer: disabled
nvidia-gpu-device-plugin: disabled
registry: disabled
registry-creds: disabled
storage-provisioner: enabled
storage-provisioner-gluster: disabled
</code></pre></li><li><p>Enable an addon, for example, <code>metrics-server</code>:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>minikube addons <span style=color:#a2f>enable</span> metrics-server
</span></span></code></pre></div><p>The output is similar to:</p><pre tabindex=0><code>The &#39;metrics-server&#39; addon is enabled
</code></pre></li><li><p>View the Pod and Service you created:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get pod,svc -n kube-system
</span></span></code></pre></div><p>The output is similar to:</p><pre tabindex=0><code>NAME                                        READY     STATUS    RESTARTS   AGE
pod/coredns-5644d7b6d9-mh9ll                1/1       Running   0          34m
pod/coredns-5644d7b6d9-pqd2t                1/1       Running   0          34m
pod/metrics-server-67fb648c5                1/1       Running   0          26s
pod/etcd-minikube                           1/1       Running   0          34m
pod/influxdb-grafana-b29w8                  2/2       Running   0          26s
pod/kube-addon-manager-minikube             1/1       Running   0          34m
pod/kube-apiserver-minikube                 1/1       Running   0          34m
pod/kube-controller-manager-minikube        1/1       Running   0          34m
pod/kube-proxy-rnlps                        1/1       Running   0          34m
pod/kube-scheduler-minikube                 1/1       Running   0          34m
pod/storage-provisioner                     1/1       Running   0          34m

NAME                           TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)             AGE
service/metrics-server         ClusterIP   10.96.241.45    &lt;none&gt;        80/TCP              26s
service/kube-dns               ClusterIP   10.96.0.10      &lt;none&gt;        53/UDP,53/TCP       34m
service/monitoring-grafana     NodePort    10.99.24.54     &lt;none&gt;        80:30002/TCP        26s
service/monitoring-influxdb    ClusterIP   10.111.169.94   &lt;none&gt;        8083/TCP,8086/TCP   26s
</code></pre></li><li><p>Disable <code>metrics-server</code>:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>minikube addons disable metrics-server
</span></span></code></pre></div><p>The output is similar to:</p><pre tabindex=0><code>metrics-server was successfully disabled
</code></pre></li></ol><h2 id=clean-up>Clean up</h2><p>Now you can clean up the resources you created in your cluster:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl delete service hello-node
</span></span><span style=display:flex><span>kubectl delete deployment hello-node
</span></span></code></pre></div><p>Optionally, stop the Minikube virtual machine (VM):</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>minikube stop
</span></span></code></pre></div><p>Optionally, delete the Minikube VM:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>minikube delete
</span></span></code></pre></div><h2 id=what-s-next>What's next</h2><ul><li>Learn more about <a href=/docs/concepts/workloads/controllers/deployment/>Deployment objects</a>.</li><li>Learn more about <a href=/docs/tasks/run-application/run-stateless-application-deployment/>Deploying applications</a>.</li><li>Learn more about <a href=/docs/concepts/services-networking/service/>Service objects</a>.</li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-3c83f53a74233ace9b289ac5e24c3e62>2 - Learn Kubernetes Basics</h1><!doctype html><html lang=en><body><div class=layout id=top><main class=content><div class=row><div class=col-md-9><h2>Kubernetes Basics</h2><p>This tutorial provides a walkthrough of the basics of the Kubernetes cluster orchestration system. Each module contains some background information on major Kubernetes features and concepts, and includes an interactive online tutorial. These interactive tutorials let you manage a simple cluster and its containerized applications for yourself.</p><p>Using the interactive tutorials, you can learn to:</p><ul><li>Deploy a containerized application on a cluster.</li><li>Scale the deployment.</li><li>Update the containerized application with a new software version.</li><li>Debug the containerized application.</li></ul><p>The tutorials use Katacoda to run a virtual terminal in your web browser that runs Minikube, a small-scale local deployment of Kubernetes that can run anywhere. There's no need to install any software or configure anything; each interactive tutorial runs directly out of your web browser itself.</p></div></div><br><div class=row><div class=col-md-9><h2>What can Kubernetes do for you?</h2><p>With modern web services, users expect applications to be available 24/7, and developers expect to deploy new versions of those applications several times a day. Containerization helps package software to serve these goals, enabling applications to be released and updated without downtime. Kubernetes helps you make sure those containerized applications run where and when you want, and helps them find the resources and tools they need to work. Kubernetes is a production-ready, open source platform designed with Google's accumulated experience in container orchestration, combined with best-of-breed ideas from the community.</p></div></div><br><div id=basics-modules class=content__modules><h2>Kubernetes Basics Modules</h2><div class=row><div class=col-md-12><div class=row><div class=col-md-4><div class=thumbnail><a href=/docs/tutorials/kubernetes-basics/create-cluster/cluster-intro/><img src="/docs/tutorials/kubernetes-basics/public/images/module_01.svg?v=1469803628347" alt></a><div class=caption><a href=/docs/tutorials/kubernetes-basics/create-cluster/cluster-intro/><h5>1. Create a Kubernetes cluster</h5></a></div></div></div><div class=col-md-4><div class=thumbnail><a href=/docs/tutorials/kubernetes-basics/deploy-app/deploy-intro/><img src="/docs/tutorials/kubernetes-basics/public/images/module_02.svg?v=1469803628347" alt></a><div class=caption><a href=/docs/tutorials/kubernetes-basics/deploy-app/deploy-intro/><h5>2. Deploy an app</h5></a></div></div></div><div class=col-md-4><div class=thumbnail><a href=/docs/tutorials/kubernetes-basics/explore/explore-intro/><img src="/docs/tutorials/kubernetes-basics/public/images/module_03.svg?v=1469803628347" alt></a><div class=caption><a href=/docs/tutorials/kubernetes-basics/explore/explore-intro/><h5>3. Explore your app</h5></a></div></div></div></div></div><div class=col-md-12><div class=row><div class=col-md-4><div class=thumbnail><a href=/docs/tutorials/kubernetes-basics/expose/expose-intro/><img src="/docs/tutorials/kubernetes-basics/public/images/module_04.svg?v=1469803628347" alt></a><div class=caption><a href=/docs/tutorials/kubernetes-basics/expose/expose-intro/><h5>4. Expose your app publicly</h5></a></div></div></div><div class=col-md-4><div class=thumbnail><a href=/docs/tutorials/kubernetes-basics/scale/scale-intro/><img src="/docs/tutorials/kubernetes-basics/public/images/module_05.svg?v=1469803628347" alt></a><div class=caption><a href=/docs/tutorials/kubernetes-basics/scale/scale-intro/><h5>5. Scale up your app</h5></a></div></div></div><div class=col-md-4><div class=thumbnail><a href=/docs/tutorials/kubernetes-basics/update/update-intro/><img src="/docs/tutorials/kubernetes-basics/public/images/module_06.svg?v=1469803628347" alt></a><div class=caption><a href=/docs/tutorials/kubernetes-basics/update/update-intro/><h5>6. Update your app</h5></a></div></div></div></div></div></div></div></main></div></body></html></div><div class=td-content style=page-break-before:always><h1 id=pg-7df66040311338d6098ebeab43ba9afb>2.1 - Create a Cluster</h1><p>Learn about Kubernetes <a class=glossary-tooltip title='A set of worker machines, called nodes, that run containerized applications. Every cluster has at least one worker node.' data-toggle=tooltip data-placement=top href='/docs/reference/glossary/?all=true#term-cluster' target=_blank aria-label=cluster>cluster</a> and create a simple cluster using Minikube.</p></div><div class=td-content><h1 id=pg-de49316920e97a82e36763cb66781ada>2.1.1 - Using Minikube to Create a Cluster</h1><!doctype html><html lang=en><body><div class=layout id=top><main class=content><div class=row><div class=col-md-8><h3>Objectives</h3><ul><li>Learn what a Kubernetes cluster is.</li><li>Learn what Minikube is.</li><li>Start a Kubernetes cluster using an online terminal.</li></ul></div><div class=col-md-8><h3>Kubernetes Clusters</h3><p><b>Kubernetes coordinates a highly available cluster of computers that are connected to work as a single unit.</b> The abstractions in Kubernetes allow you to deploy containerized applications to a cluster without tying them specifically to individual machines. To make use of this new model of deployment, applications need to be packaged in a way that decouples them from individual hosts: they need to be containerized. Containerized applications are more flexible and available than in past deployment models, where applications were installed directly onto specific machines as packages deeply integrated into the host. <b>Kubernetes automates the distribution and scheduling of application containers across a cluster in a more efficient way.</b> Kubernetes is an open-source platform and is production-ready.</p><p>A Kubernetes cluster consists of two types of resources:<ul><li>The <b>Control Plane</b> coordinates the cluster</li><li><b>Nodes</b> are the workers that run applications</li></ul></p></div><div class=col-md-4><div class="content__box content__box_lined"><h3>Summary:</h3><ul><li>Kubernetes cluster</li><li>Minikube</li></ul></div><div class="content__box content__box_fill"><p><i>Kubernetes is a production-grade, open-source platform that orchestrates the placement (scheduling) and execution of application containers within and across computer clusters.</i></p></div></div></div><br><div class=row><div class=col-md-8><h2 style=color:#3771e3>Cluster Diagram</h2></div></div><div class=row><div class=col-md-8><p><img src=/docs/tutorials/kubernetes-basics/public/images/module_01_cluster.svg></p></div></div><br><div class=row><div class=col-md-8><p><b>The Control Plane is responsible for managing the cluster.</b> The Control Plane coordinates all activities in your cluster, such as scheduling applications, maintaining applications' desired state, scaling applications, and rolling out new updates.</p><p><b>A node is a VM or a physical computer that serves as a worker machine in a Kubernetes cluster.</b> Each node has a Kubelet, which is an agent for managing the node and communicating with the Kubernetes control plane. The node should also have tools for handling container operations, such as containerd or Docker. A Kubernetes cluster that handles production traffic should have a minimum of three nodes because if one node goes down, both an etcd member and a control plane instance are lost, and redundancy is compromised. You can mitigate this risk by adding more control plane nodes.</p></div><div class=col-md-4><div class="content__box content__box_fill"><p><i>Control Planes manage the cluster and the nodes that are used to host the running applications.</i></p></div></div></div><div class=row><div class=col-md-8><p>When you deploy applications on Kubernetes, you tell the control plane to start the application containers. The control plane schedules the containers to run on the cluster's nodes. <b>The nodes communicate with the control plane using the <a href=/docs/concepts/overview/kubernetes-api/>Kubernetes API</a></b>, which the control plane exposes. End users can also use the Kubernetes API directly to interact with the cluster.</p><p>A Kubernetes cluster can be deployed on either physical or virtual machines. To get started with Kubernetes development, you can use Minikube. Minikube is a lightweight Kubernetes implementation that creates a VM on your local machine and deploys a simple cluster containing only one node. Minikube is available for Linux, macOS, and Windows systems. The Minikube CLI provides basic bootstrapping operations for working with your cluster, including start, stop, status, and delete. For this tutorial, however, you'll use a provided online terminal with Minikube pre-installed.</p><p>Now that you know what Kubernetes is, let's go to the online tutorial and start our first cluster!</p></div></div><br><div class=row><div class=col-md-12><a class="btn btn-lg btn-success" href=/docs/tutorials/kubernetes-basics/create-cluster/cluster-interactive/ role=button>Start Interactive Tutorial <span class=btn__next>›</span></a></div></div></main></div></body></html></div><div class=td-content style=page-break-before:always><h1 id=pg-323b75976001e8dfe35d67d61bc74f1a>2.1.2 - Interactive Tutorial - Creating a Cluster</h1><!doctype html><html lang=en><body><script defer src=https://katacoda.com/embed.js></script><div class=layout id=top><main class="content katacoda-content"><div class=katacoda><div class=katacoda__alert>The screen is too narrow to interact with the Terminal, please use a desktop/tablet.</div><div class=katacoda__box id=inline-terminal-1 data-katacoda-id=kubernetes-bootcamp/1 data-katacoda-color=326de6 data-katacoda-secondary=273d6d data-katacoda-hideintro=false data-katacoda-prompt="Kubernetes Bootcamp Terminal" style=height:600px></div></div><div class=row><div class=col-md-12><a class="btn btn-lg btn-success" href=/docs/tutorials/kubernetes-basics/ role=button>Home<span></span></a>
<a class="btn btn-lg btn-success" href=/docs/tutorials/kubernetes-basics/deploy-app/deploy-intro/ role=button>Continue to Module 2 ><span></span></a></div></div></main></div></body></html></div><div class=td-content style=page-break-before:always><h1 id=pg-76d78b3fba507f7ed33cef14a35b631d>2.2 - Deploy an App</h1></div><div class=td-content><h1 id=pg-2b1bba431989008c7493109a0f049ece>2.2.1 - Using kubectl to Create a Deployment</h1><!doctype html><html lang=en><body><div class=layout id=top><main class=content><div class=row><div class=col-md-8><h3>Objectives</h3><ul><li>Learn about application Deployments.</li><li>Deploy your first app on Kubernetes with kubectl.</li></ul></div><div class=col-md-8><h3>Kubernetes Deployments</h3><p>Once you have a running Kubernetes cluster, you can deploy your containerized applications on top of it.
To do so, you create a Kubernetes <b>Deployment</b> configuration. The Deployment instructs Kubernetes
how to create and update instances of your application. Once you've created a Deployment, the Kubernetes
control plane schedules the application instances included in that Deployment to run on individual Nodes in the
cluster.</p><p>Once the application instances are created, a Kubernetes Deployment Controller continuously monitors those instances. If the Node hosting an instance goes down or is deleted, the Deployment controller replaces the instance with an instance on another Node in the cluster. <b>This provides a self-healing mechanism to address machine failure or maintenance.</b></p><p>In a pre-orchestration world, installation scripts would often be used to start applications, but they did not allow recovery from machine failure. By both creating your application instances and keeping them running across Nodes, Kubernetes Deployments provide a fundamentally different approach to application management.</p></div><div class=col-md-4><div class="content__box content__box_lined"><h3>Summary:</h3><ul><li>Deployments</li><li>Kubectl</li></ul></div><div class="content__box content__box_fill"><p><i>A Deployment is responsible for creating and updating instances of your application</i></p></div></div></div><br><div class=row><div class=col-md-8><h2 style=color:#3771e3>Deploying your first app on Kubernetes</h2></div></div><div class=row><div class=col-md-8><p><img src=/docs/tutorials/kubernetes-basics/public/images/module_02_first_app.svg></p></div></div><br><div class=row><div class=col-md-8><p>You can create and manage a Deployment by using the Kubernetes command line interface, <b>Kubectl</b>. Kubectl uses the Kubernetes API to interact with the cluster. In this module, you'll learn the most common Kubectl commands needed to create Deployments that run your applications on a Kubernetes cluster.</p><p>When you create a Deployment, you'll need to specify the container image for your application and the number of replicas that you want to run. You can change that information later by updating your Deployment; Modules <a href=/docs/tutorials/kubernetes-basics/scale/scale-intro/>5</a> and <a href=/docs/tutorials/kubernetes-basics/update/update-intro/>6</a> of the bootcamp discuss how you can scale and update your Deployments.</p></div><div class=col-md-4><div class="content__box content__box_fill"><p><i>Applications need to be packaged into one of the supported container formats in order to be deployed on Kubernetes</i></p></div></div></div><div class=row><div class=col-md-8><p>For your first Deployment, you'll use a hello-node application packaged in a Docker container that uses NGINX to echo back all the requests. (If you didn't already try creating a hello-node application and deploying it using a container, you can do that first by following the instructions from the <a href=/docs/tutorials/hello-minikube/>Hello Minikube tutorial</a>).<p><p>Now that you know what Deployments are, let's go to the online tutorial and deploy our first app!</p></div></div><br><div class=row><div class=col-md-12><a class="btn btn-lg btn-success" href=/docs/tutorials/kubernetes-basics/deploy-app/deploy-interactive/ role=button>Start Interactive Tutorial <span class=btn__next>›</span></a></div></div></main></div></body></html></div><div class=td-content style=page-break-before:always><h1 id=pg-f8997ec143b382fa6c9621941ea62ca3>2.2.2 - Interactive Tutorial - Deploying an App</h1><!doctype html><html lang=en><body><script defer src=https://katacoda.com/embed.js></script><div class=layout id=top><main class="content katacoda-content"><div class=row><div class=col-md-12><p>A Pod is the basic execution unit of a Kubernetes application. Each Pod represents a part of a workload that is running on your cluster. <a href=/docs/concepts/workloads/pods/>Learn more about Pods</a>.</p></div></div><br><div class=katacoda><div class=katacoda__alert>To interact with the Terminal, please use the desktop/tablet version</div><div class=katacoda__box id=inline-terminal-1 data-katacoda-id=kubernetes-bootcamp/7 data-katacoda-color=326de6 data-katacoda-secondary=273d6d data-katacoda-hideintro=false data-katacoda-prompt="Kubernetes Bootcamp Terminal" style=height:600px></div></div><div class=row><div class=col-md-12><a class="btn btn-lg btn-success" href=/docs/tutorials/kubernetes-basics/create-cluster/cluster-intro/ role=button>&lt; Return to Module 1<span></span></a>
<a class="btn btn-lg btn-success" href=/docs/tutorials/kubernetes-basics/ role=button>Home<span></span></a>
<a class="btn btn-lg btn-success" href=/docs/tutorials/kubernetes-basics/explore/explore-intro/ role=button>Continue to Module 3 ><span></span></a></div></div></main></div></body></html></div><div class=td-content style=page-break-before:always><h1 id=pg-250d620a73ec8be7e1f7d835574c4596>2.3 - Explore Your App</h1></div><div class=td-content><h1 id=pg-2771f4e8c45321b17cb0114a2d266453>2.3.1 - Viewing Pods and Nodes</h1><!doctype html><html lang=en><body><div class=layout id=top><main class=content><div class=row><div class=col-md-8><h3>Objectives</h3><ul><li>Learn about Kubernetes Pods.</li><li>Learn about Kubernetes Nodes.</li><li>Troubleshoot deployed applications.</li></ul></div><div class=col-md-8><h2>Kubernetes Pods</h2><p>When you created a Deployment in Module <a href=/docs/tutorials/kubernetes-basics/deploy-app/deploy-intro/>2</a>, Kubernetes created a <b>Pod</b> to host your application instance. A Pod is a Kubernetes abstraction that represents a group of one or more application containers (such as Docker), and some shared resources for those containers. Those resources include:</p><ul><li>Shared storage, as Volumes</li><li>Networking, as a unique cluster IP address</li><li>Information about how to run each container, such as the container image version or specific ports to use</li></ul><p>A Pod models an application-specific "logical host" and can contain different application containers which are relatively tightly coupled. For example, a Pod might include both the container with your Node.js app as well as a different container that feeds the data to be published by the Node.js webserver. The containers in a Pod share an IP Address and port space, are always co-located and co-scheduled, and run in a shared context on the same Node.</p><p>Pods are the atomic unit on the Kubernetes platform. When we create a Deployment on Kubernetes, that Deployment creates Pods with containers inside them (as opposed to creating containers directly). Each Pod is tied to the Node where it is scheduled, and remains there until termination (according to restart policy) or deletion. In case of a Node failure, identical Pods are scheduled on other available Nodes in the cluster.</p></div><div class=col-md-4><div class="content__box content__box_lined"><h3>Summary:</h3><ul><li>Pods</li><li>Nodes</li><li>Kubectl main commands</li></ul></div><div class="content__box content__box_fill"><p><i>A Pod is a group of one or more application containers (such as Docker) and includes shared storage (volumes), IP address and information about how to run them.</i></p></div></div></div><br><div class=row><div class=col-md-8><h2 style=color:#3771e3>Pods overview</h2></div></div><div class=row><div class=col-md-8><p><img src=/docs/tutorials/kubernetes-basics/public/images/module_03_pods.svg></p></div></div><br><div class=row><div class=col-md-8><h2>Nodes</h2><p>A Pod always runs on a <b>Node</b>. A Node is a worker machine in Kubernetes and may be either a virtual or a physical machine, depending on the cluster. Each Node is managed by the control plane. A Node can have multiple pods, and the Kubernetes control plane automatically handles scheduling the pods across the Nodes in the cluster. The control plane's automatic scheduling takes into account the available resources on each Node.</p><p>Every Kubernetes Node runs at least:</p><ul><li>Kubelet, a process responsible for communication between the Kubernetes control plane and the Node; it manages the Pods and the containers running on a machine.</li><li>A container runtime (like Docker) responsible for pulling the container image from a registry, unpacking the container, and running the application.</li></ul></div><div class=col-md-4><div class="content__box content__box_fill"><p><i>Containers should only be scheduled together in a single Pod if they are tightly coupled and need to share resources such as disk.</i></p></div></div></div><br><div class=row><div class=col-md-8><h2 style=color:#3771e3>Node overview</h2></div></div><div class=row><div class=col-md-8><p><img src=/docs/tutorials/kubernetes-basics/public/images/module_03_nodes.svg></p></div></div><br><div class=row><div class=col-md-8><h2>Troubleshooting with kubectl</h2><p>In Module <a href=/docs/tutorials/kubernetes-basics/deploy-app/deploy-intro/>2</a>, you used Kubectl command-line interface. You'll continue to use it in Module 3 to get information about deployed applications and their environments. The most common operations can be done with the following kubectl commands:</p><ul><li><b>kubectl get</b> - list resources</li><li><b>kubectl describe</b> - show detailed information about a resource</li><li><b>kubectl logs</b> - print the logs from a container in a pod</li><li><b>kubectl exec</b> - execute a command on a container in a pod</li></ul><p>You can use these commands to see when applications were deployed, what their current statuses are, where they are running and what their configurations are.</p><p>Now that we know more about our cluster components and the command line, let's explore our application.</p></div><div class=col-md-4><div class="content__box content__box_fill"><p><i>A node is a worker machine in Kubernetes and may be a VM or physical machine, depending on the cluster. Multiple Pods can run on one Node.</i></p></div></div></div><br><div class=row><div class=col-md-12><a class="btn btn-lg btn-success" href=/docs/tutorials/kubernetes-basics/explore/explore-interactive/ role=button>Start Interactive Tutorial <span class=btn__next>›</span></a></div></div></main></div></body></html></div><div class=td-content style=page-break-before:always><h1 id=pg-4b01eab98a9844ad91131079654199dd>2.3.2 - Interactive Tutorial - Exploring Your App</h1><!doctype html><html lang=en><body><script defer src=https://katacoda.com/embed.js></script><div class=layout id=top><main class="content katacoda-content"><br><div class=katacoda><div class=katacoda__alert>To interact with the Terminal, please use the desktop/tablet version</div><div class=katacoda__box id=inline-terminal-1 data-katacoda-id=kubernetes-bootcamp/4 data-katacoda-color=326de6 data-katacoda-secondary=273d6d data-katacoda-hideintro=false data-katacoda-prompt="Kubernetes Bootcamp Terminal" style=height:600px></div></div><div class=row><div class=col-md-12><a class="btn btn-lg btn-success" href=/docs/tutorials/kubernetes-basics/deploy-app/deploy-intro/ role=button>&lt; Return to Module 2<span class=btn></span></a>
<a class="btn btn-lg btn-success" href=/docs/tutorials/kubernetes-basics/ role=button>Home<span></span></a>
<a class="btn btn-lg btn-success" href=/docs/tutorials/kubernetes-basics/expose/expose-intro/ role=button>Continue to Module 4 ><span class=btn></span></a></div></div></main></div></body></html></div><div class=td-content style=page-break-before:always><h1 id=pg-4b0e31c9e0eae68bbb0a358b4042ada9>2.4 - Expose Your App Publicly</h1></div><div class=td-content><h1 id=pg-8ef4dad8f743b191a9e8c6f891cb191a>2.4.1 - Using a Service to Expose Your App</h1><!doctype html><html lang=en><body><div class=layout id=top><main class=content><div class=row><div class=col-md-8><h3>Objectives</h3><ul><li>Learn about a Service in Kubernetes</li><li>Understand how labels and LabelSelector objects relate to a Service</li><li>Expose an application outside a Kubernetes cluster using a Service</li></ul></div><div class=col-md-8><h3>Overview of Kubernetes Services</h3><p>Kubernetes <a href=/docs/concepts/workloads/pods/>Pods</a> are mortal. Pods have a <a href=/docs/concepts/workloads/pods/pod-lifecycle/>lifecycle</a>. When a worker node dies, the Pods running on the Node are also lost. A <a href=/docs/concepts/workloads/controllers/replicaset/>ReplicaSet</a> might then dynamically drive the cluster back to the desired state via the creation of new Pods to keep your application running. As another example, consider an image-processing backend with 3 replicas. Those replicas are exchangeable; the front-end system should not care about backend replicas or even if a Pod is lost and recreated. That said, each Pod in a Kubernetes cluster has a unique IP address, even Pods on the same Node, so there needs to be a way of automatically reconciling changes among Pods so that your applications continue to function.</p><p>A Service in Kubernetes is an abstraction which defines a logical set of Pods and a policy by which to access them. Services enable a loose coupling between dependent Pods. A Service is defined using YAML <a href=/docs/concepts/configuration/overview/#general-configuration-tips>(preferred)</a> or JSON, like all Kubernetes objects. The set of Pods targeted by a Service is usually determined by a <i>LabelSelector</i> (see below for why you might want a Service without including a <code>selector</code> in the spec).</p><p>Although each Pod has a unique IP address, those IPs are not exposed outside the cluster without a Service. Services allow your applications to receive traffic. Services can be exposed in different ways by specifying a <code>type</code> in the ServiceSpec:</p><ul><li><i>ClusterIP</i> (default) - Exposes the Service on an internal IP in the cluster. This type makes the Service only reachable from within the cluster.</li><li><i>NodePort</i> - Exposes the Service on the same port of each selected Node in the cluster using NAT. Makes a Service accessible from outside the cluster using <code>&lt;NodeIP>:&lt;NodePort></code>. Superset of ClusterIP.</li><li><i>LoadBalancer</i> - Creates an external load balancer in the current cloud (if supported) and assigns a fixed, external IP to the Service. Superset of NodePort.</li><li><i>ExternalName</i> - Maps the Service to the contents of the <code>externalName</code> field (e.g. <code>foo.bar.example.com</code>), by returning a <code>CNAME</code> record with its value. No proxying of any kind is set up. This type requires v1.7 or higher of <code>kube-dns</code>, or CoreDNS version 0.0.8 or higher.</li></ul><p>More information about the different types of Services can be found in the <a href=/docs/tutorials/services/source-ip/>Using Source IP</a> tutorial. Also see <a href=/docs/tutorials/services/connect-applications-service/>Connecting Applications with Services</a>.</p><p>Additionally, note that there are some use cases with Services that involve not defining a <code>selector</code> in the spec. A Service created without <code>selector</code> will also not create the corresponding Endpoints object. This allows users to manually map a Service to specific endpoints. Another possibility why there may be no selector is you are strictly using <code>type: ExternalName</code>.</p></div><div class=col-md-4><div class="content__box content__box_lined"><h3>Summary</h3><ul><li>Exposing Pods to external traffic</li><li>Load balancing traffic across multiple Pods</li><li>Using labels</li></ul></div><div class="content__box content__box_fill"><p><i>A Kubernetes Service is an abstraction layer which defines a logical set of Pods and enables external traffic exposure, load balancing and service discovery for those Pods.</i></p></div></div></div><br><div class=row><div class=col-md-8><h3>Services and Labels</h3></div></div><div class=row><div class=col-md-8><p>A Service routes traffic across a set of Pods. Services are the abstraction that allows pods to die and replicate in Kubernetes without impacting your application. Discovery and routing among dependent Pods (such as the frontend and backend components in an application) are handled by Kubernetes Services.</p><p>Services match a set of Pods using <a href=/docs/concepts/overview/working-with-objects/labels>labels and selectors</a>, a grouping primitive that allows logical operation on objects in Kubernetes. Labels are key/value pairs attached to objects and can be used in any number of ways:</p><ul><li>Designate objects for development, test, and production</li><li>Embed version tags</li><li>Classify an object using tags</li></ul></div></div><br><div class=row><div class=col-md-8><p><img src=/docs/tutorials/kubernetes-basics/public/images/module_04_labels.svg></p></div></div><br><div class=row><div class=col-md-8><p>Labels can be attached to objects at creation time or later on. They can be modified at any time. Let's expose our application now using a Service and apply some labels.</p></div></div><br><div class=row><div class=col-md-12><a class="btn btn-lg btn-success" href=/docs/tutorials/kubernetes-basics/expose/expose-interactive/ role=button>Start Interactive Tutorial<span class=btn__next>›</span></a></div></div></main></div></body></html></div><div class=td-content style=page-break-before:always><h1 id=pg-352241d22effe0714772d21c7d1b512d>2.4.2 - Interactive Tutorial - Exposing Your App</h1><!doctype html><html lang=en><body><script defer src=https://katacoda.com/embed.js></script><div class=layout id=top><main class="content katacoda-content"><div class=katacoda><div class=katacoda__alert>To interact with the Terminal, please use the desktop/tablet version</div><div class=katacoda__box id=inline-terminal-1 data-katacoda-id=kubernetes-bootcamp/8 data-katacoda-color=326de6 data-katacoda-secondary=273d6d data-katacoda-hideintro=false data-katacoda-prompt="Kubernetes Bootcamp Terminal" style=height:600px></div></div><div class=row><div class=col-md-12><a class="btn btn-lg btn-success" href=/docs/tutorials/kubernetes-basics/explore/explore-intro/ role=button>&lt; Return to Module 3<span></span></a>
<a class="btn btn-lg btn-success" href=/docs/tutorials/kubernetes-basics/ role=button>Home<span></span></a>
<a class="btn btn-lg btn-success" href=/docs/tutorials/kubernetes-basics/scale/scale-intro/ role=button>Continue to Module 5 ><span></span></a></div></div></main></div></body></html></div><div class=td-content style=page-break-before:always><h1 id=pg-be4996c93fb39c459a30b6669569d423>2.5 - Scale Your App</h1></div><div class=td-content><h1 id=pg-d1c15c9bd4f625adbc13149b1475287c>2.5.1 - Running Multiple Instances of Your App</h1><!doctype html><html lang=en><body><div class=layout id=top><main class=content><div class=row><div class=col-md-8><h3>Objectives</h3><ul><li>Scale an app using kubectl.</li></ul></div><div class=col-md-8><h3>Scaling an application</h3><p>In the previous modules we created a <a href=/docs/concepts/workloads/controllers/deployment/>Deployment</a>, and then exposed it publicly via a <a href=/docs/concepts/services-networking/service/>Service</a>. The Deployment created only one Pod for running our application. When traffic increases, we will need to scale the application to keep up with user demand.</p><p><b>Scaling</b> is accomplished by changing the number of replicas in a Deployment</p></div><div class=col-md-4><div class="content__box content__box_lined"><h3>Summary:</h3><ul><li>Scaling a Deployment</li></ul></div><div class="content__box content__box_fill"><p><i>You can create from the start a Deployment with multiple instances using the --replicas parameter for the kubectl create deployment command</i></p></div></div></div><br><div class=row><div class=col-md-8><h2 style=color:#3771e3>Scaling overview</h2></div></div><div class=row><div class=col-md-1></div><div class=col-md-8><div id=myCarousel class=carousel data-ride=carousel data-interval=3000><ol class=carousel-indicators><li data-target=#myCarousel data-slide-to=0 class=active></li><li data-target=#myCarousel data-slide-to=1></li></ol><div class=carousel-inner role=listbox><div class="item carousel-item active"><img src=/docs/tutorials/kubernetes-basics/public/images/module_05_scaling1.svg></div><div class="item carousel-item"><img src=/docs/tutorials/kubernetes-basics/public/images/module_05_scaling2.svg></div></div><a class="left carousel-control" href=#myCarousel role=button data-slide=prev><span class=sr-only>Previous</span></a>
<a class="right carousel-control" href=#myCarousel role=button data-slide=next><span class=sr-only>Next</span></a></div></div></div><br><div class=row><div class=col-md-8><p>Scaling out a Deployment will ensure new Pods are created and scheduled to Nodes with available resources. Scaling will increase the number of Pods to the new desired state. Kubernetes also supports <a href=/docs/user-guide/horizontal-pod-autoscaling/>autoscaling</a> of Pods, but it is outside of the scope of this tutorial. Scaling to zero is also possible, and it will terminate all Pods of the specified Deployment.</p><p>Running multiple instances of an application will require a way to distribute the traffic to all of them. Services have an integrated load-balancer that will distribute network traffic to all Pods of an exposed Deployment. Services will monitor continuously the running Pods using endpoints, to ensure the traffic is sent only to available Pods.</p></div><div class=col-md-4><div class="content__box content__box_fill"><p><i>Scaling is accomplished by changing the number of replicas in a Deployment.</i></p></div></div></div><br><div class=row><div class=col-md-8><p>Once you have multiple instances of an Application running, you would be able to do Rolling updates without downtime. We'll cover that in the next module. Now, let's go to the online terminal and scale our application.</p></div></div><br><div class=row><div class=col-md-12><a class="btn btn-lg btn-success" href=/docs/tutorials/kubernetes-basics/scale/scale-interactive/ role=button>Start Interactive Tutorial <span class=btn__next>›</span></a></div></div></main></div></body></html></div><div class=td-content style=page-break-before:always><h1 id=pg-7bdb3fbaa1177ff5dfa3fe86bd35ef59>2.5.2 - Interactive Tutorial - Scaling Your App</h1><!doctype html><html lang=en><body><script defer src=https://katacoda.com/embed.js></script><div class=layout id=top><main class="content katacoda-content"><div class=katacoda><div class=katacoda__alert>To interact with the Terminal, please use the desktop/tablet version</div><div class=katacoda__box id=inline-terminal-1 data-katacoda-id=kubernetes-bootcamp/5 data-katacoda-color=326de6 data-katacoda-secondary=273d6d data-katacoda-hideintro=false data-katacoda-prompt="Kubernetes Bootcamp Terminal" style=height:600px></div></div><div class=row><div class=col-md-12><a class="btn btn-lg btn-success" href=/docs/tutorials/kubernetes-basics/expose/expose-interactive/ role=button>&lt; Return to Module 4<span></span></a>
<a class="btn btn-lg btn-success" href=/docs/tutorials/kubernetes-basics/ role=button>Home<span></span></a>
<a class="btn btn-lg btn-success" href=/docs/tutorials/kubernetes-basics/update/update-intro/ role=button>Continue to Module 6 ><span></span></a></div></div></main><a class=scrolltop href=#top></a></div></body></html></div><div class=td-content style=page-break-before:always><h1 id=pg-62b8b17dadfb55f1801cf8439e944e58>2.6 - Update Your App</h1></div><div class=td-content><h1 id=pg-12e04355145afad615ca3c38335ba019>2.6.1 - Performing a Rolling Update</h1><!doctype html><html lang=en><body><div class=layout id=top><main class=content><div class=row><div class=col-md-8><h3>Objectives</h3><ul><li>Perform a rolling update using kubectl.</li></ul></div><div class=col-md-8><h3>Updating an application</h3><p>Users expect applications to be available all the time and developers are expected to deploy new versions of them several times a day. In Kubernetes this is done with rolling updates. <b>Rolling updates</b> allow Deployments' update to take place with zero downtime by incrementally updating Pods instances with new ones. The new Pods will be scheduled on Nodes with available resources.</p><p>In the previous module we scaled our application to run multiple instances. This is a requirement for performing updates without affecting application availability. By default, the maximum number of Pods that can be unavailable during the update and the maximum number of new Pods that can be created, is one. Both options can be configured to either numbers or percentages (of Pods).
In Kubernetes, updates are versioned and any Deployment update can be reverted to a previous (stable) version.</p></div><div class=col-md-4><div class="content__box content__box_lined"><h3>Summary:</h3><ul><li>Updating an app</li></ul></div><div class="content__box content__box_fill"><p><i>Rolling updates allow Deployments' update to take place with zero downtime by incrementally updating Pods instances with new ones.</i></p></div></div></div><br><div class=row><div class=col-md-8><h2 style=color:#3771e3>Rolling updates overview</h2></div></div><div class=row><div class=col-md-1></div><div class=col-md-8><div id=myCarousel class=carousel data-ride=carousel data-interval=3000><ol class=carousel-indicators><li data-target=#myCarousel data-slide-to=0 class=active></li><li data-target=#myCarousel data-slide-to=1></li><li data-target=#myCarousel data-slide-to=2></li><li data-target=#myCarousel data-slide-to=3></li></ol><div class=carousel-inner role=listbox><div class="item carousel-item active"><img src=/docs/tutorials/kubernetes-basics/public/images/module_06_rollingupdates1.svg></div><div class="item carousel-item"><img src=/docs/tutorials/kubernetes-basics/public/images/module_06_rollingupdates2.svg></div><div class="item carousel-item"><img src=/docs/tutorials/kubernetes-basics/public/images/module_06_rollingupdates3.svg></div><div class="item carousel-item"><img src=/docs/tutorials/kubernetes-basics/public/images/module_06_rollingupdates4.svg></div></div><a class="left carousel-control" href=#myCarousel role=button data-slide=prev><span class=sr-only>Previous</span></a>
<a class="right carousel-control" href=#myCarousel role=button data-slide=next><span class=sr-only>Next</span></a></div></div></div><br><div class=row><div class=col-md-8><p>Similar to application Scaling, if a Deployment is exposed publicly, the Service will load-balance the traffic only to available Pods during the update. An available Pod is an instance that is available to the users of the application.</p><p>Rolling updates allow the following actions:</p><ul><li>Promote an application from one environment to another (via container image updates)</li><li>Rollback to previous versions</li><li>Continuous Integration and Continuous Delivery of applications with zero downtime</li></ul></div><div class=col-md-4><div class="content__box content__box_fill"><p><i>If a Deployment is exposed publicly, the Service will load-balance the traffic only to available Pods during the update.</i></p></div></div></div><br><div class=row><div class=col-md-8><p>In the following interactive tutorial, we'll update our application to a new version, and also perform a rollback.</p></div></div><br><div class=row><div class=col-md-12><a class="btn btn-lg btn-success" href=/docs/tutorials/kubernetes-basics/update/update-interactive/ role=button>Start Interactive Tutorial <span class=btn__next>›</span></a></div></div></main></div></body></html></div><div class=td-content style=page-break-before:always><h1 id=pg-dddc0cb356c280e0339bcf42776987dc>2.6.2 - Interactive Tutorial - Updating Your App</h1><!doctype html><html lang=en><body><script defer src=https://katacoda.com/embed.js></script><div class=layout id=top><main class="content katacoda-content"><div class=katacoda><div class=katacoda__alert>To interact with the Terminal, please use the desktop/tablet version</div><div class=katacoda__box id=inline-terminal-1 data-katacoda-id=kubernetes-bootcamp/6 data-katacoda-color=326de6 data-katacoda-secondary=273d6d data-katacoda-hideintro=false data-katacoda-prompt="Kubernetes Bootcamp Terminal" style=height:600px></div></div><div class=row><div class=col-md-12><a class="btn btn-lg btn-success" href=/docs/tutorials/kubernetes-basics/scale/scale-interactive/ role=button>&lt; Return to Module 5<span></span></a>
<a class="btn btn-lg btn-success" href=/docs/tutorials/kubernetes-basics/ role=button>Return to Kubernetes Basics<span></span></a></div></div></main></div></body></html></div><div class=td-content style=page-break-before:always><h1 id=pg-a3a0f1c6af19fc89ce24d8cd42c0249f>3 - Configuration</h1></div><div class=td-content><h1 id=pg-e08b0be51359b976a754112b96980f54>3.1 - Example: Configuring a Java Microservice</h1></div><div class=td-content><h1 id=pg-025ef96f86c52822a2738b8b11b60934>3.1.1 - Externalizing config using MicroProfile, ConfigMaps and Secrets</h1><p>In this tutorial you will learn how and why to externalize your microservice’s configuration.
Specifically, you will learn how to use Kubernetes ConfigMaps and Secrets to set environment
variables and then consume them using MicroProfile Config.</p><h2 id=before-you-begin>Before you begin</h2><h3 id=creating-kubernetes-configmaps-secrets>Creating Kubernetes ConfigMaps & Secrets</h3><p>There are several ways to set environment variables for a Docker container in Kubernetes,
including: Dockerfile, kubernetes.yml, Kubernetes ConfigMaps, and Kubernetes Secrets. In the
tutorial, you will learn how to use the latter two for setting your environment variables whose
values will be injected into your microservices. One of the benefits for using ConfigMaps and
Secrets is that they can be re-used across multiple containers, including being assigned to
different environment variables for the different containers.</p><p>ConfigMaps are API Objects that store non-confidential key-value pairs. In the Interactive
Tutorial you will learn how to use a ConfigMap to store the application's name. For more
information regarding ConfigMaps, you can find the documentation
<a href=/docs/tasks/configure-pod-container/configure-pod-configmap/>here</a>.</p><p>Although Secrets are also used to store key-value pairs, they differ from ConfigMaps in that
they're intended for confidential/sensitive information and are stored using Base64 encoding.
This makes secrets the appropriate choice for storing such things as credentials, keys, and
tokens, the former of which you'll do in the Interactive Tutorial. For more information on
Secrets, you can find the documentation <a href=/docs/concepts/configuration/secret/>here</a>.</p><h3 id=externalizing-config-from-code>Externalizing Config from Code</h3><p>Externalized application configuration is useful because configuration usually changes depending
on your environment. In order to accomplish this, we'll use Java's Contexts and Dependency
Injection (CDI) and MicroProfile Config. MicroProfile Config is a feature of MicroProfile, a set
of open Java technologies for developing and deploying cloud-native microservices.</p><p>CDI provides a standard dependency injection capability enabling an application to be assembled
from collaborating, loosely-coupled beans. MicroProfile Config provides apps and microservices a
standard way to obtain config properties from various sources, including the application, runtime,
and environment. Based on the source's defined priority, the properties are automatically
combined into a single set of properties that the application can access via an API. Together,
CDI & MicroProfile will be used in the Interactive Tutorial to retrieve the externally provided
properties from the Kubernetes ConfigMaps and Secrets and get injected into your application code.</p><p>Many open source frameworks and runtimes implement and support MicroProfile Config. Throughout
the interactive tutorial, you'll be using Open Liberty, a flexible open-source Java runtime for
building and running cloud-native apps and microservices. However, any MicroProfile compatible
runtime could be used instead.</p><h2 id=objectives>Objectives</h2><ul><li>Create a Kubernetes ConfigMap and Secret</li><li>Inject microservice configuration using MicroProfile Config</li></ul><h2 id=example-externalizing-config-using-microprofile-configmaps-and-secrets>Example: Externalizing config using MicroProfile, ConfigMaps and Secrets</h2><p><a href=/docs/tutorials/configuration/configure-java-microservice/configure-java-microservice-interactive/>Start Interactive Tutorial</a></p></div><div class=td-content style=page-break-before:always><h1 id=pg-ef2047c46d3cd16631bac27403e4cfdc>3.1.2 - Interactive Tutorial - Configuring a Java Microservice</h1><!doctype html><html lang=en><body><link href=/docs/tutorials/kubernetes-basics/public/css/styles.css rel=stylesheet><link href=/docs/tutorials/kubernetes-basics/public/css/overrides.css rel=stylesheet><script defer src=https://katacoda.com/embed.js></script><div class=layout id=top><main class="content katacoda-content"><div class=katacoda><div class=katacoda__alert>To interact with the Terminal, please use the desktop/tablet version</div><div class=katacoda__box id=inline-terminal-1 data-katacoda-id=kubernetes-bootcamp/9 data-katacoda-color=326de6 data-katacoda-secondary=273d6d data-katacoda-hideintro=false data-katacoda-prompt="Kubernetes Bootcamp Terminal" style=height:600px></div></div></main></div></body></html></div><div class=td-content style=page-break-before:always><h1 id=pg-2efe621cc085b350c8c4574e6f7f1311>3.2 - Configuring Redis using a ConfigMap</h1><p>This page provides a real world example of how to configure Redis using a ConfigMap and builds upon the <a href=/docs/tasks/configure-pod-container/configure-pod-configmap/>Configure a Pod to Use a ConfigMap</a> task.</p><h2 id=objectives>Objectives</h2><ul><li>Create a ConfigMap with Redis configuration values</li><li>Create a Redis Pod that mounts and uses the created ConfigMap</li><li>Verify that the configuration was correctly applied.</li></ul><h2 id=before-you-begin>Before you begin</h2><p><p>You need to have a Kubernetes cluster, and the kubectl command-line tool must
be configured to communicate with your cluster. It is recommended to run this tutorial on a cluster with at least two nodes that are not acting as control plane hosts. If you do not already have a
cluster, you can create one by using
<a href=https://minikube.sigs.k8s.io/docs/tutorials/multi_node/>minikube</a>
or you can use one of these Kubernetes playgrounds:</p><ul><li><a href=https://killercoda.com/playgrounds/scenario/kubernetes>Killercoda</a></li><li><a href=http://labs.play-with-k8s.com/>Play with Kubernetes</a></li></ul>To check the version, enter <code>kubectl version</code>.</p><ul><li>The example shown on this page works with <code>kubectl</code> 1.14 and above.</li><li>Understand <a href=/docs/tasks/configure-pod-container/configure-pod-configmap/>Configure a Pod to Use a ConfigMap</a>.</li></ul><h2 id=real-world-example-configuring-redis-using-a-configmap>Real World Example: Configuring Redis using a ConfigMap</h2><p>Follow the steps below to configure a Redis cache using data stored in a ConfigMap.</p><p>First create a ConfigMap with an empty configuration block:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>cat <span style=color:#b44>&lt;&lt;EOF &gt;./example-redis-config.yaml
</span></span></span><span style=display:flex><span><span style=color:#b44>apiVersion: v1
</span></span></span><span style=display:flex><span><span style=color:#b44>kind: ConfigMap
</span></span></span><span style=display:flex><span><span style=color:#b44>metadata:
</span></span></span><span style=display:flex><span><span style=color:#b44>  name: example-redis-config
</span></span></span><span style=display:flex><span><span style=color:#b44>data:
</span></span></span><span style=display:flex><span><span style=color:#b44>  redis-config: &#34;&#34;
</span></span></span><span style=display:flex><span><span style=color:#b44>EOF</span>
</span></span></code></pre></div><p>Apply the ConfigMap created above, along with a Redis pod manifest:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl apply -f example-redis-config.yaml
</span></span><span style=display:flex><span>kubectl apply -f https://raw.githubusercontent.com/kubernetes/website/main/content/en/examples/pods/config/redis-pod.yaml
</span></span></code></pre></div><p>Examine the contents of the Redis pod manifest and note the following:</p><ul><li>A volume named <code>config</code> is created by <code>spec.volumes[1]</code></li><li>The <code>key</code> and <code>path</code> under <code>spec.volumes[1].items[0]</code> exposes the <code>redis-config</code> key from the
<code>example-redis-config</code> ConfigMap as a file named <code>redis.conf</code> on the <code>config</code> volume.</li><li>The <code>config</code> volume is then mounted at <code>/redis-master</code> by <code>spec.containers[0].volumeMounts[1]</code>.</li></ul><p>This has the net effect of exposing the data in <code>data.redis-config</code> from the <code>example-redis-config</code>
ConfigMap above as <code>/redis-master/redis.conf</code> inside the Pod.</p><div class=highlight><div class=copy-code-icon style=text-align:right><a href=https://raw.githubusercontent.com/kubernetes/website/main/content/en/examples/pods/config/redis-pod.yaml download=pods/config/redis-pod.yaml><code>pods/config/redis-pod.yaml</code></a>
<img src=/images/copycode.svg style=max-height:24px;cursor:pointer onclick='copyCode("pods-config-redis-pod-yaml")' title="Copy pods/config/redis-pod.yaml to clipboard"></img></div><div class=includecode id=pods-config-redis-pod-yaml><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>redis<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>redis<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>redis:5.0.4<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>command</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- redis-server<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- <span style=color:#b44>&#34;/redis-master/redis.conf&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>env</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>MASTER<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>value</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;true&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>ports</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:green;font-weight:700>containerPort</span>:<span style=color:#bbb> </span><span style=color:#666>6379</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>resources</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>limits</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>cpu</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;0.1&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>volumeMounts</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:green;font-weight:700>mountPath</span>:<span style=color:#bbb> </span>/redis-master-data<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>data<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:green;font-weight:700>mountPath</span>:<span style=color:#bbb> </span>/redis-master<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>config<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>volumes</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>data<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>emptyDir</span>:<span style=color:#bbb> </span>{}<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>config<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>configMap</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>example-redis-config<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>items</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span>- <span style=color:green;font-weight:700>key</span>:<span style=color:#bbb> </span>redis-config<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>path</span>:<span style=color:#bbb> </span>redis.conf<span style=color:#bbb>
</span></span></span></code></pre></div></div></div><p>Examine the created objects:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get pod/redis configmap/example-redis-config 
</span></span></code></pre></div><p>You should see the following output:</p><pre tabindex=0><code>NAME        READY   STATUS    RESTARTS   AGE
pod/redis   1/1     Running   0          8s

NAME                             DATA   AGE
configmap/example-redis-config   1      14s
</code></pre><p>Recall that we left <code>redis-config</code> key in the <code>example-redis-config</code> ConfigMap blank:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl describe configmap/example-redis-config
</span></span></code></pre></div><p>You should see an empty <code>redis-config</code> key:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>Name:         example-redis-config
</span></span><span style=display:flex><span>Namespace:    default
</span></span><span style=display:flex><span>Labels:       &lt;none&gt;
</span></span><span style=display:flex><span>Annotations:  &lt;none&gt;
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#b8860b>Data</span>
</span></span><span style=display:flex><span><span style=color:#666>====</span>
</span></span><span style=display:flex><span>redis-config:
</span></span></code></pre></div><p>Use <code>kubectl exec</code> to enter the pod and run the <code>redis-cli</code> tool to check the current configuration:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl <span style=color:#a2f>exec</span> -it redis -- redis-cli
</span></span></code></pre></div><p>Check <code>maxmemory</code>:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>127.0.0.1:6379&gt; CONFIG GET maxmemory
</span></span></code></pre></div><p>It should show the default value of 0:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>1<span style=color:#666>)</span> <span style=color:#b44>&#34;maxmemory&#34;</span>
</span></span><span style=display:flex><span>2<span style=color:#666>)</span> <span style=color:#b44>&#34;0&#34;</span>
</span></span></code></pre></div><p>Similarly, check <code>maxmemory-policy</code>:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>127.0.0.1:6379&gt; CONFIG GET maxmemory-policy
</span></span></code></pre></div><p>Which should also yield its default value of <code>noeviction</code>:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>1<span style=color:#666>)</span> <span style=color:#b44>&#34;maxmemory-policy&#34;</span>
</span></span><span style=display:flex><span>2<span style=color:#666>)</span> <span style=color:#b44>&#34;noeviction&#34;</span>
</span></span></code></pre></div><p>Now let's add some configuration values to the <code>example-redis-config</code> ConfigMap:</p><div class=highlight><div class=copy-code-icon style=text-align:right><a href=https://raw.githubusercontent.com/kubernetes/website/main/content/en/examples/pods/config/example-redis-config.yaml download=pods/config/example-redis-config.yaml><code>pods/config/example-redis-config.yaml</code></a>
<img src=/images/copycode.svg style=max-height:24px;cursor:pointer onclick='copyCode("pods-config-example-redis-config-yaml")' title="Copy pods/config/example-redis-config.yaml to clipboard"></img></div><div class=includecode id=pods-config-example-redis-config-yaml><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>ConfigMap<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>example-redis-config<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>data</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>redis-config</span>:<span style=color:#bbb> </span>|<span style=color:#b44;font-style:italic>
</span></span></span><span style=display:flex><span><span style=color:#b44;font-style:italic>    maxmemory 2mb
</span></span></span><span style=display:flex><span><span style=color:#b44;font-style:italic>    maxmemory-policy allkeys-lru</span><span style=color:#bbb>    
</span></span></span></code></pre></div></div></div><p>Apply the updated ConfigMap:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl apply -f example-redis-config.yaml
</span></span></code></pre></div><p>Confirm that the ConfigMap was updated:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl describe configmap/example-redis-config
</span></span></code></pre></div><p>You should see the configuration values we just added:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>Name:         example-redis-config
</span></span><span style=display:flex><span>Namespace:    default
</span></span><span style=display:flex><span>Labels:       &lt;none&gt;
</span></span><span style=display:flex><span>Annotations:  &lt;none&gt;
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#b8860b>Data</span>
</span></span><span style=display:flex><span><span style=color:#666>====</span>
</span></span><span style=display:flex><span>redis-config:
</span></span><span style=display:flex><span>----
</span></span><span style=display:flex><span>maxmemory 2mb
</span></span><span style=display:flex><span>maxmemory-policy allkeys-lru
</span></span></code></pre></div><p>Check the Redis Pod again using <code>redis-cli</code> via <code>kubectl exec</code> to see if the configuration was applied:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl <span style=color:#a2f>exec</span> -it redis -- redis-cli
</span></span></code></pre></div><p>Check <code>maxmemory</code>:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>127.0.0.1:6379&gt; CONFIG GET maxmemory
</span></span></code></pre></div><p>It remains at the default value of 0:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>1<span style=color:#666>)</span> <span style=color:#b44>&#34;maxmemory&#34;</span>
</span></span><span style=display:flex><span>2<span style=color:#666>)</span> <span style=color:#b44>&#34;0&#34;</span>
</span></span></code></pre></div><p>Similarly, <code>maxmemory-policy</code> remains at the <code>noeviction</code> default setting:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>127.0.0.1:6379&gt; CONFIG GET maxmemory-policy
</span></span></code></pre></div><p>Returns:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>1<span style=color:#666>)</span> <span style=color:#b44>&#34;maxmemory-policy&#34;</span>
</span></span><span style=display:flex><span>2<span style=color:#666>)</span> <span style=color:#b44>&#34;noeviction&#34;</span>
</span></span></code></pre></div><p>The configuration values have not changed because the Pod needs to be restarted to grab updated
values from associated ConfigMaps. Let's delete and recreate the Pod:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl delete pod redis
</span></span><span style=display:flex><span>kubectl apply -f https://raw.githubusercontent.com/kubernetes/website/main/content/en/examples/pods/config/redis-pod.yaml
</span></span></code></pre></div><p>Now re-check the configuration values one last time:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl <span style=color:#a2f>exec</span> -it redis -- redis-cli
</span></span></code></pre></div><p>Check <code>maxmemory</code>:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>127.0.0.1:6379&gt; CONFIG GET maxmemory
</span></span></code></pre></div><p>It should now return the updated value of 2097152:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>1<span style=color:#666>)</span> <span style=color:#b44>&#34;maxmemory&#34;</span>
</span></span><span style=display:flex><span>2<span style=color:#666>)</span> <span style=color:#b44>&#34;2097152&#34;</span>
</span></span></code></pre></div><p>Similarly, <code>maxmemory-policy</code> has also been updated:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>127.0.0.1:6379&gt; CONFIG GET maxmemory-policy
</span></span></code></pre></div><p>It now reflects the desired value of <code>allkeys-lru</code>:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>1<span style=color:#666>)</span> <span style=color:#b44>&#34;maxmemory-policy&#34;</span>
</span></span><span style=display:flex><span>2<span style=color:#666>)</span> <span style=color:#b44>&#34;allkeys-lru&#34;</span>
</span></span></code></pre></div><p>Clean up your work by deleting the created resources:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl delete pod/redis configmap/example-redis-config
</span></span></code></pre></div><h2 id=what-s-next>What's next</h2><ul><li>Learn more about <a href=/docs/tasks/configure-pod-container/configure-pod-configmap/>ConfigMaps</a>.</li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-fe7e92bed8fb92872b139f12c4568cdb>4 - Security</h1></div><div class=td-content><h1 id=pg-d5f847bcdb6f7efbfc9c8a180d73e29a>4.1 - Apply Pod Security Standards at the Cluster Level</h1><div class="alert alert-primary" role=alert><h4 class=alert-heading>Note</h4>This tutorial applies only for new clusters.</div><p>Pod Security admission (PSA) is enabled by default in v1.23 and later, as it has
<a href=/blog/2021/12/09/pod-security-admission-beta/>graduated to beta</a>.
Pod Security
is an admission controller that carries out checks against the Kubernetes
<a href=/docs/concepts/security/pod-security-standards/>Pod Security Standards</a> when new pods are
created. This tutorial shows you how to enforce the <code>baseline</code> Pod Security
Standard at the cluster level which applies a standard configuration
to all namespaces in a cluster.</p><p>To apply Pod Security Standards to specific namespaces, refer to
<a href=/docs/tutorials/security/ns-level-pss>Apply Pod Security Standards at the namespace level</a>.</p><p>If you are running a version of Kubernetes other than v1.25,
check the documentation for that version.</p><h2 id=before-you-begin>Before you begin</h2><p>Install the following on your workstation:</p><ul><li><a href=https://kind.sigs.k8s.io/docs/user/quick-start/#installation>KinD</a></li><li><a href=/docs/tasks/tools/>kubectl</a></li></ul><h2 id=choose-the-right-pod-security-standard-to-apply>Choose the right Pod Security Standard to apply</h2><p><a href=/docs/concepts/security/pod-security-admission/>Pod Security Admission</a>
lets you apply built-in <a href=/docs/concepts/security/pod-security-standards/>Pod Security Standards</a>
with the following modes: <code>enforce</code>, <code>audit</code>, and <code>warn</code>.</p><p>To gather information that helps you to choose the Pod Security Standards
that are most appropriate for your configuration, do the following:</p><ol><li><p>Create a cluster with no Pod Security Standards applied:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kind create cluster --name psa-wo-cluster-pss --image kindest/node:v1.24.0
</span></span></code></pre></div><p>The output is similar to this:</p><pre tabindex=0><code>Creating cluster &#34;psa-wo-cluster-pss&#34; ...
✓ Ensuring node image (kindest/node:v1.24.0) 🖼
✓ Preparing nodes 📦  
✓ Writing configuration 📜
✓ Starting control-plane 🕹️
✓ Installing CNI 🔌
✓ Installing StorageClass 💾
Set kubectl context to &#34;kind-psa-wo-cluster-pss&#34;
You can now use your cluster with:

kubectl cluster-info --context kind-psa-wo-cluster-pss

Thanks for using kind! 😊
</code></pre></li><li><p>Set the kubectl context to the new cluster:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl cluster-info --context kind-psa-wo-cluster-pss
</span></span></code></pre></div><p>The output is similar to this:</p><pre tabindex=0><code> Kubernetes control plane is running at https://127.0.0.1:61350

CoreDNS is running at https://127.0.0.1:61350/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy

To further debug and diagnose cluster problems, use &#39;kubectl cluster-info dump&#39;.
</code></pre></li><li><p>Get a list of namespaces in the cluster:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get ns
</span></span></code></pre></div><p>The output is similar to this:</p><pre tabindex=0><code>NAME                 STATUS   AGE
default              Active   9m30s
kube-node-lease      Active   9m32s
kube-public          Active   9m32s
kube-system          Active   9m32s
local-path-storage   Active   9m26s
</code></pre></li><li><p>Use <code>--dry-run=server</code> to understand what happens when different Pod Security Standards
are applied:</p><ol><li>Privileged<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl label --dry-run<span style=color:#666>=</span>server --overwrite ns --all <span style=color:#b62;font-weight:700>\
</span></span></span><span style=display:flex><span><span style=color:#b62;font-weight:700></span>pod-security.kubernetes.io/enforce<span style=color:#666>=</span>privileged
</span></span></code></pre></div></li></ol><p>The output is similar to this:</p><pre tabindex=0><code>namespace/default labeled
namespace/kube-node-lease labeled
namespace/kube-public labeled
namespace/kube-system labeled
namespace/local-path-storage labeled
</code></pre><ol start=2><li>Baseline<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl label --dry-run<span style=color:#666>=</span>server --overwrite ns --all <span style=color:#b62;font-weight:700>\
</span></span></span><span style=display:flex><span><span style=color:#b62;font-weight:700></span>pod-security.kubernetes.io/enforce<span style=color:#666>=</span>baseline
</span></span></code></pre></div></li></ol><p>The output is similar to this:</p><pre tabindex=0><code>namespace/default labeled
namespace/kube-node-lease labeled
namespace/kube-public labeled
Warning: existing pods in namespace &#34;kube-system&#34; violate the new PodSecurity enforce level &#34;baseline:latest&#34;
Warning: etcd-psa-wo-cluster-pss-control-plane (and 3 other pods): host namespaces, hostPath volumes
Warning: kindnet-vzj42: non-default capabilities, host namespaces, hostPath volumes
Warning: kube-proxy-m6hwf: host namespaces, hostPath volumes, privileged
namespace/kube-system labeled
namespace/local-path-storage labeled
</code></pre><ol start=3><li>Restricted</li></ol><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span> kubectl label --dry-run<span style=color:#666>=</span>server --overwrite ns --all <span style=color:#b62;font-weight:700>\
</span></span></span><span style=display:flex><span><span style=color:#b62;font-weight:700></span> pod-security.kubernetes.io/enforce<span style=color:#666>=</span>restricted
</span></span></code></pre></div><p>The output is similar to this:</p><pre tabindex=0><code>namespace/default labeled
namespace/kube-node-lease labeled
namespace/kube-public labeled
Warning: existing pods in namespace &#34;kube-system&#34; violate the new PodSecurity enforce level &#34;restricted:latest&#34;
Warning: coredns-7bb9c7b568-hsptc (and 1 other pod): unrestricted capabilities, runAsNonRoot != true, seccompProfile
Warning: etcd-psa-wo-cluster-pss-control-plane (and 3 other pods): host namespaces, hostPath volumes, allowPrivilegeEscalation != false, unrestricted capabilities, restricted volume types, runAsNonRoot != true
Warning: kindnet-vzj42: non-default capabilities, host namespaces, hostPath volumes, allowPrivilegeEscalation != false, unrestricted capabilities, restricted volume types, runAsNonRoot != true, seccompProfile
Warning: kube-proxy-m6hwf: host namespaces, hostPath volumes, privileged, allowPrivilegeEscalation != false, unrestricted capabilities, restricted volume types, runAsNonRoot != true, seccompProfile
namespace/kube-system labeled
Warning: existing pods in namespace &#34;local-path-storage&#34; violate the new PodSecurity enforce level &#34;restricted:latest&#34;
Warning: local-path-provisioner-d6d9f7ffc-lw9lh: allowPrivilegeEscalation != false, unrestricted capabilities, runAsNonRoot != true, seccompProfile
namespace/local-path-storage labeled
</code></pre></li></ol><p>From the previous output, you'll notice that applying the <code>privileged</code> Pod Security Standard shows no warnings
for any namespaces. However, <code>baseline</code> and <code>restricted</code> standards both have
warnings, specifically in the <code>kube-system</code> namespace.</p><h2 id=set-modes-versions-and-standards>Set modes, versions and standards</h2><p>In this section, you apply the following Pod Security Standards to the <code>latest</code> version:</p><ul><li><code>baseline</code> standard in <code>enforce</code> mode.</li><li><code>restricted</code> standard in <code>warn</code> and <code>audit</code> mode.</li></ul><p>The <code>baseline</code> Pod Security Standard provides a convenient
middle ground that allows keeping the exemption list short and prevents known
privilege escalations.</p><p>Additionally, to prevent pods from failing in <code>kube-system</code>, you'll exempt the namespace
from having Pod Security Standards applied.</p><p>When you implement Pod Security Admission in your own environment, consider the
following:</p><ol><li><p>Based on the risk posture applied to a cluster, a stricter Pod Security
Standard like <code>restricted</code> might be a better choice.</p></li><li><p>Exempting the <code>kube-system</code> namespace allows pods to run as
<code>privileged</code> in this namespace. For real world use, the Kubernetes project
strongly recommends that you apply strict RBAC
policies that limit access to <code>kube-system</code>, following the principle of least
privilege.
To implement the preceding standards, do the following:</p></li><li><p>Create a configuration file that can be consumed by the Pod Security
Admission Controller to implement these Pod Security Standards:</p><pre tabindex=0><code>mkdir -p /tmp/pss
cat &lt;&lt;EOF &gt; /tmp/pss/cluster-level-pss.yaml 
apiVersion: apiserver.config.k8s.io/v1
kind: AdmissionConfiguration
plugins:
- name: PodSecurity
  configuration:
    apiVersion: pod-security.admission.config.k8s.io/v1
    kind: PodSecurityConfiguration
    defaults:
      enforce: &#34;baseline&#34;
      enforce-version: &#34;latest&#34;
      audit: &#34;restricted&#34;
      audit-version: &#34;latest&#34;
      warn: &#34;restricted&#34;
      warn-version: &#34;latest&#34;
    exemptions:
      usernames: []
      runtimeClasses: []
      namespaces: [kube-system]
EOF
</code></pre><div class="alert alert-info note callout" role=alert><strong>Note:</strong> <code>pod-security.admission.config.k8s.io/v1</code> configuration requires v1.25+.
For v1.23 and v1.24, use <a href=https://v1-24.docs.kubernetes.io/docs/tasks/configure-pod-container/enforce-standards-admission-controller/>v1beta1</a>.
For v1.22, use <a href=https://v1-22.docs.kubernetes.io/docs/tasks/configure-pod-container/enforce-standards-admission-controller/>v1alpha1</a>.</div></li><li><p>Configure the API server to consume this file during cluster creation:</p><pre tabindex=0><code>cat &lt;&lt;EOF &gt; /tmp/pss/cluster-config.yaml 
kind: Cluster
apiVersion: kind.x-k8s.io/v1alpha4
nodes:
- role: control-plane
  kubeadmConfigPatches:
  - |
    kind: ClusterConfiguration
    apiServer:
        extraArgs:
          admission-control-config-file: /etc/config/cluster-level-pss.yaml
        extraVolumes:
          - name: accf
            hostPath: /etc/config
            mountPath: /etc/config
            readOnly: false
            pathType: &#34;DirectoryOrCreate&#34;
  extraMounts:
  - hostPath: /tmp/pss
    containerPath: /etc/config
    # optional: if set, the mount is read-only.
    # default false
    readOnly: false
    # optional: if set, the mount needs SELinux relabeling.
    # default false
    selinuxRelabel: false
    # optional: set propagation mode (None, HostToContainer or Bidirectional)
    # see https://kubernetes.io/docs/concepts/storage/volumes/#mount-propagation
    # default None
    propagation: None
EOF
</code></pre><div class="alert alert-info note callout" role=alert><strong>Note:</strong> If you use Docker Desktop with KinD on macOS, you can
add <code>/tmp</code> as a Shared Directory under the menu item
<strong>Preferences > Resources > File Sharing</strong>.</div></li><li><p>Create a cluster that uses Pod Security Admission to apply
these Pod Security Standards:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span> kind create cluster --name psa-with-cluster-pss --image kindest/node:v1.24.0 --config /tmp/pss/cluster-config.yaml
</span></span></code></pre></div><p>The output is similar to this:</p><pre tabindex=0><code> Creating cluster &#34;psa-with-cluster-pss&#34; ...
  ✓ Ensuring node image (kindest/node:v1.24.0) 🖼 
  ✓ Preparing nodes 📦  
  ✓ Writing configuration 📜 
  ✓ Starting control-plane 🕹️ 
  ✓ Installing CNI 🔌 
  ✓ Installing StorageClass 💾 
 Set kubectl context to &#34;kind-psa-with-cluster-pss&#34;
 You can now use your cluster with:

 kubectl cluster-info --context kind-psa-with-cluster-pss

 Have a question, bug, or feature request? Let us know! https://kind.sigs.k8s.io/#community 🙂
</code></pre></li><li><p>Point kubectl to the cluster</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span> kubectl cluster-info --context kind-psa-with-cluster-pss
</span></span></code></pre></div><p>The output is similar to this:</p><pre tabindex=0><code> Kubernetes control plane is running at https://127.0.0.1:63855
 CoreDNS is running at https://127.0.0.1:63855/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy

 To further debug and diagnose cluster problems, use &#39;kubectl cluster-info dump&#39;.
</code></pre></li><li><p>Create the following Pod specification for a minimal configuration in the default namespace:</p><pre tabindex=0><code>cat &lt;&lt;EOF &gt; /tmp/pss/nginx-pod.yaml
apiVersion: v1
kind: Pod
metadata:
  name: nginx
spec:
  containers:
    - image: nginx
      name: nginx
      ports:
        - containerPort: 80
EOF
</code></pre></li><li><p>Create the Pod in the cluster:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span> kubectl apply -f /tmp/pss/nginx-pod.yaml
</span></span></code></pre></div><p>The output is similar to this:</p><pre tabindex=0><code> Warning: would violate PodSecurity &#34;restricted:latest&#34;: allowPrivilegeEscalation != false (container &#34;nginx&#34; must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container &#34;nginx&#34; must set securityContext.capabilities.drop=[&#34;ALL&#34;]), runAsNonRoot != true (pod or container &#34;nginx&#34; must set securityContext.runAsNonRoot=true), seccompProfile (pod or container &#34;nginx&#34; must set securityContext.seccompProfile.type to &#34;RuntimeDefault&#34; or &#34;Localhost&#34;)
 pod/nginx created
</code></pre></li></ol><h2 id=clean-up>Clean up</h2><p>Run <code>kind delete cluster --name psa-with-cluster-pss</code> and
<code>kind delete cluster --name psa-wo-cluster-pss</code> to delete the clusters you
created.</p><h2 id=what-s-next>What's next</h2><ul><li>Run a
<a href=/examples/security/kind-with-cluster-level-baseline-pod-security.sh>shell script</a>
to perform all the preceding steps at once:<ol><li>Create a Pod Security Standards based cluster level Configuration</li><li>Create a file to let API server consume this configuration</li><li>Create a cluster that creates an API server with this configuration</li><li>Set kubectl context to this new cluster</li><li>Create a minimal pod yaml file</li><li>Apply this file to create a Pod in the new cluster</li></ol></li><li><a href=/docs/concepts/security/pod-security-admission/>Pod Security Admission</a></li><li><a href=/docs/concepts/security/pod-security-standards/>Pod Security Standards</a></li><li><a href=/docs/tutorials/security/ns-level-pss/>Apply Pod Security Standards at the namespace level</a></li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-31a6c137cfc5bfea9d88f4b109109465>4.2 - Apply Pod Security Standards at the Namespace Level</h1><div class="alert alert-primary" role=alert><h4 class=alert-heading>Note</h4>This tutorial applies only for new clusters.</div><p>Pod Security admission (PSA) is enabled by default in v1.23 and later, as it
<a href=/blog/2021/12/09/pod-security-admission-beta/>graduated to beta</a>. Pod Security Admission
is an admission controller that applies
<a href=/docs/concepts/security/pod-security-standards/>Pod Security Standards</a>
when pods are created. In this tutorial, you will enforce the <code>baseline</code> Pod Security Standard,
one namespace at a time.</p><p>You can also apply Pod Security Standards to multiple namespaces at once at the cluster
level. For instructions, refer to
<a href=/docs/tutorials/security/cluster-level-pss/>Apply Pod Security Standards at the cluster level</a>.</p><h2 id=before-you-begin>Before you begin</h2><p>Install the following on your workstation:</p><ul><li><a href=https://kind.sigs.k8s.io/docs/user/quick-start/#installation>KinD</a></li><li><a href=/docs/tasks/tools/>kubectl</a></li></ul><h2 id=create-cluster>Create cluster</h2><ol><li><p>Create a <code>KinD</code> cluster as follows:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kind create cluster --name psa-ns-level --image kindest/node:v1.23.0
</span></span></code></pre></div><p>The output is similar to this:</p><pre tabindex=0><code>Creating cluster &#34;psa-ns-level&#34; ...
 ✓ Ensuring node image (kindest/node:v1.23.0) 🖼 
 ✓ Preparing nodes 📦  
 ✓ Writing configuration 📜 
 ✓ Starting control-plane 🕹️ 
 ✓ Installing CNI 🔌 
 ✓ Installing StorageClass 💾 
Set kubectl context to &#34;kind-psa-ns-level&#34;
You can now use your cluster with:

kubectl cluster-info --context kind-psa-ns-level

Not sure what to do next? 😅  Check out https://kind.sigs.k8s.io/docs/user/quick-start/
</code></pre></li><li><p>Set the kubectl context to the new cluster:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl cluster-info --context kind-psa-ns-level
</span></span></code></pre></div><p>The output is similar to this:</p><pre tabindex=0><code>Kubernetes control plane is running at https://127.0.0.1:50996
CoreDNS is running at https://127.0.0.1:50996/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy

To further debug and diagnose cluster problems, use &#39;kubectl cluster-info dump&#39;.
</code></pre></li></ol><h2 id=create-a-namespace>Create a namespace</h2><p>Create a new namespace called <code>example</code>:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl create ns example
</span></span></code></pre></div><p>The output is similar to this:</p><pre tabindex=0><code>namespace/example created
</code></pre><h2 id=apply-pod-security-standards>Apply Pod Security Standards</h2><ol><li><p>Enable Pod Security Standards on this namespace using labels supported by
built-in Pod Security Admission. In this step we will warn on baseline pod
security standard as per the latest version (default value)</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl label --overwrite ns example <span style=color:#b62;font-weight:700>\
</span></span></span><span style=display:flex><span><span style=color:#b62;font-weight:700></span>   pod-security.kubernetes.io/warn<span style=color:#666>=</span>baseline <span style=color:#b62;font-weight:700>\
</span></span></span><span style=display:flex><span><span style=color:#b62;font-weight:700></span>   pod-security.kubernetes.io/warn-version<span style=color:#666>=</span>latest
</span></span></code></pre></div></li><li><p>Multiple pod security standards can be enabled on any namespace, using labels.
Following command will <code>enforce</code> the <code>baseline</code> Pod Security Standard, but
<code>warn</code> and <code>audit</code> for <code>restricted</code> Pod Security Standards as per the latest
version (default value)</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl label --overwrite ns example <span style=color:#b62;font-weight:700>\
</span></span></span><span style=display:flex><span><span style=color:#b62;font-weight:700></span>  pod-security.kubernetes.io/enforce<span style=color:#666>=</span>baseline <span style=color:#b62;font-weight:700>\
</span></span></span><span style=display:flex><span><span style=color:#b62;font-weight:700></span>  pod-security.kubernetes.io/enforce-version<span style=color:#666>=</span>latest <span style=color:#b62;font-weight:700>\
</span></span></span><span style=display:flex><span><span style=color:#b62;font-weight:700></span>  pod-security.kubernetes.io/warn<span style=color:#666>=</span>restricted <span style=color:#b62;font-weight:700>\
</span></span></span><span style=display:flex><span><span style=color:#b62;font-weight:700></span>  pod-security.kubernetes.io/warn-version<span style=color:#666>=</span>latest <span style=color:#b62;font-weight:700>\
</span></span></span><span style=display:flex><span><span style=color:#b62;font-weight:700></span>  pod-security.kubernetes.io/audit<span style=color:#666>=</span>restricted <span style=color:#b62;font-weight:700>\
</span></span></span><span style=display:flex><span><span style=color:#b62;font-weight:700></span>  pod-security.kubernetes.io/audit-version<span style=color:#666>=</span>latest
</span></span></code></pre></div></li></ol><h2 id=verify-the-pod-security-standards>Verify the Pod Security Standards</h2><ol><li><p>Create a minimal pod in <code>example</code> namespace:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>cat <span style=color:#b44>&lt;&lt;EOF &gt; /tmp/pss/nginx-pod.yaml
</span></span></span><span style=display:flex><span><span style=color:#b44>apiVersion: v1
</span></span></span><span style=display:flex><span><span style=color:#b44>kind: Pod
</span></span></span><span style=display:flex><span><span style=color:#b44>metadata:
</span></span></span><span style=display:flex><span><span style=color:#b44>  name: nginx
</span></span></span><span style=display:flex><span><span style=color:#b44>spec:
</span></span></span><span style=display:flex><span><span style=color:#b44>  containers:
</span></span></span><span style=display:flex><span><span style=color:#b44>    - image: nginx
</span></span></span><span style=display:flex><span><span style=color:#b44>      name: nginx
</span></span></span><span style=display:flex><span><span style=color:#b44>      ports:
</span></span></span><span style=display:flex><span><span style=color:#b44>        - containerPort: 80
</span></span></span><span style=display:flex><span><span style=color:#b44>EOF</span>
</span></span></code></pre></div></li><li><p>Apply the pod spec to the cluster in <code>example</code> namespace:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl apply -n example -f /tmp/pss/nginx-pod.yaml
</span></span></code></pre></div><p>The output is similar to this:</p><pre tabindex=0><code>Warning: would violate PodSecurity &#34;restricted:latest&#34;: allowPrivilegeEscalation != false (container &#34;nginx&#34; must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container &#34;nginx&#34; must set securityContext.capabilities.drop=[&#34;ALL&#34;]), runAsNonRoot != true (pod or container &#34;nginx&#34; must set securityContext.runAsNonRoot=true), seccompProfile (pod or container &#34;nginx&#34; must set securityContext.seccompProfile.type to &#34;RuntimeDefault&#34; or &#34;Localhost&#34;)
pod/nginx created
</code></pre></li><li><p>Apply the pod spec to the cluster in <code>default</code> namespace:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl apply -n default -f /tmp/pss/nginx-pod.yaml
</span></span></code></pre></div><p>Output is similar to this:</p><pre tabindex=0><code>pod/nginx created
</code></pre></li></ol><p>The Pod Security Standards were applied only to the <code>example</code>
namespace. You could create the same Pod in the <code>default</code> namespace
with no warnings.</p><h2 id=clean-up>Clean up</h2><p>Run <code>kind delete cluster --name psa-ns-level</code> to delete the cluster created.</p><h2 id=what-s-next>What's next</h2><ul><li><p>Run a
<a href=/examples/security/kind-with-namespace-level-baseline-pod-security.sh>shell script</a>
to perform all the preceding steps all at once.</p><ol><li>Create KinD cluster</li><li>Create new namespace</li><li>Apply <code>baseline</code> Pod Security Standard in <code>enforce</code> mode while applying
<code>restricted</code> Pod Security Standard also in <code>warn</code> and <code>audit</code> mode.</li><li>Create a new pod with the following pod security standards applied</li></ol></li><li><p><a href=/docs/concepts/security/pod-security-admission/>Pod Security Admission</a></p></li><li><p><a href=/docs/concepts/security/pod-security-standards/>Pod Security Standards</a></p></li><li><p><a href=/docs/tutorials/security/cluster-level-pss/>Apply Pod Security Standards at the cluster level</a></p></li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-fca078b8ac6b82352ed52187a2da91b7>4.3 - Restrict a Container's Access to Resources with AppArmor</h1><div style=margin-top:10px;margin-bottom:10px><b>FEATURE STATE:</b> <code>Kubernetes v1.4 [beta]</code></div><p>AppArmor is a Linux kernel security module that supplements the standard Linux user and group based
permissions to confine programs to a limited set of resources. AppArmor can be configured for any
application to reduce its potential attack surface and provide greater in-depth defense. It is
configured through profiles tuned to allow the access needed by a specific program or container,
such as Linux capabilities, network access, file permissions, etc. Each profile can be run in either
<em>enforcing</em> mode, which blocks access to disallowed resources, or <em>complain</em> mode, which only reports
violations.</p><p>AppArmor can help you to run a more secure deployment by restricting what containers are allowed to
do, and/or provide better auditing through system logs. However, it is important to keep in mind
that AppArmor is not a silver bullet and can only do so much to protect against exploits in your
application code. It is important to provide good, restrictive profiles, and harden your
applications and cluster from other angles as well.</p><h2 id=objectives>Objectives</h2><ul><li>See an example of how to load a profile on a node</li><li>Learn how to enforce the profile on a Pod</li><li>Learn how to check that the profile is loaded</li><li>See what happens when a profile is violated</li><li>See what happens when a profile cannot be loaded</li></ul><h2 id=before-you-begin>Before you begin</h2><p>Make sure:</p><ol><li><p>Kubernetes version is at least v1.4 -- Kubernetes support for AppArmor was added in
v1.4. Kubernetes components older than v1.4 are not aware of the new AppArmor annotations, and
will <strong>silently ignore</strong> any AppArmor settings that are provided. To ensure that your Pods are
receiving the expected protections, it is important to verify the Kubelet version of your nodes:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get nodes -o<span style=color:#666>=</span><span style=color:#b8860b>jsonpath</span><span style=color:#666>=</span><span style=color:#b44>$&#39;{range .items[*]}{@.metadata.name}: {@.status.nodeInfo.kubeletVersion}\n{end}&#39;</span>
</span></span></code></pre></div><pre tabindex=0><code>gke-test-default-pool-239f5d02-gyn2: v1.4.0
gke-test-default-pool-239f5d02-x1kf: v1.4.0
gke-test-default-pool-239f5d02-xwux: v1.4.0
</code></pre></li><li><p>AppArmor kernel module is enabled -- For the Linux kernel to enforce an AppArmor profile, the
AppArmor kernel module must be installed and enabled. Several distributions enable the module by
default, such as Ubuntu and SUSE, and many others provide optional support. To check whether the
module is enabled, check the <code>/sys/module/apparmor/parameters/enabled</code> file:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>cat /sys/module/apparmor/parameters/enabled
</span></span><span style=display:flex><span>Y
</span></span></code></pre></div><p>If the Kubelet contains AppArmor support (>= v1.4), it will refuse to run a Pod with AppArmor
options if the kernel module is not enabled.</p></li></ol><div class="alert alert-info note callout" role=alert><strong>Note:</strong> Ubuntu carries many AppArmor patches that have not been merged into the upstream Linux
kernel, including patches that add additional hooks and features. Kubernetes has only been
tested with the upstream version, and does not promise support for other features.</div><ol start=3><li><p>Container runtime supports AppArmor -- Currently all common Kubernetes-supported container
runtimes should support AppArmor, like <a class=glossary-tooltip title='Docker is a software technology providing operating-system-level virtualization also known as containers.' data-toggle=tooltip data-placement=top href=https://docs.docker.com/engine/ target=_blank aria-label=Docker>Docker</a>,
<a class=glossary-tooltip title='A lightweight container runtime specifically for Kubernetes' data-toggle=tooltip data-placement=top href=https://cri-o.io/#what-is-cri-o target=_blank aria-label=CRI-O>CRI-O</a> or <a class=glossary-tooltip title='A container runtime with an emphasis on simplicity, robustness and portability' data-toggle=tooltip data-placement=top href=https://containerd.io/docs/ target=_blank aria-label=containerd>containerd</a>.
Please refer to the corresponding runtime documentation and verify that the cluster fulfills
the requirements to use AppArmor.</p></li><li><p>Profile is loaded -- AppArmor is applied to a Pod by specifying an AppArmor profile that each
container should be run with. If any of the specified profiles is not already loaded in the
kernel, the Kubelet (>= v1.4) will reject the Pod. You can view which profiles are loaded on a
node by checking the <code>/sys/kernel/security/apparmor/profiles</code> file. For example:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>ssh gke-test-default-pool-239f5d02-gyn2 <span style=color:#b44>&#34;sudo cat /sys/kernel/security/apparmor/profiles | sort&#34;</span>
</span></span></code></pre></div><pre tabindex=0><code>apparmor-test-deny-write (enforce)
apparmor-test-audit-write (enforce)
docker-default (enforce)
k8s-nginx (enforce)
</code></pre><p>For more details on loading profiles on nodes, see
<a href=#setting-up-nodes-with-profiles>Setting up nodes with profiles</a>.</p></li></ol><p>As long as the Kubelet version includes AppArmor support (>= v1.4), the Kubelet will reject a Pod
with AppArmor options if any of the prerequisites are not met. You can also verify AppArmor support
on nodes by checking the node ready condition message (though this is likely to be removed in a
later release):</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get nodes -o<span style=color:#666>=</span><span style=color:#b8860b>jsonpath</span><span style=color:#666>=</span><span style=color:#b44>&#39;{range .items[*]}{@.metadata.name}: {.status.conditions[?(@.reason==&#34;KubeletReady&#34;)].message}{&#34;\n&#34;}{end}&#39;</span>
</span></span></code></pre></div><pre tabindex=0><code>gke-test-default-pool-239f5d02-gyn2: kubelet is posting ready status. AppArmor enabled
gke-test-default-pool-239f5d02-x1kf: kubelet is posting ready status. AppArmor enabled
gke-test-default-pool-239f5d02-xwux: kubelet is posting ready status. AppArmor enabled
</code></pre><h2 id=securing-a-pod>Securing a Pod</h2><div class="alert alert-info note callout" role=alert><strong>Note:</strong> AppArmor is currently in beta, so options are specified as annotations. Once support graduates to
general availability, the annotations will be replaced with first-class fields (more details in
<a href=#upgrade-path-to-general-availability>Upgrade path to GA</a>).</div><p>AppArmor profiles are specified <em>per-container</em>. To specify the AppArmor profile to run a Pod
container with, add an annotation to the Pod's metadata:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>container.apparmor.security.beta.kubernetes.io/&lt;container_name&gt;</span>:<span style=color:#bbb> </span>&lt;profile_ref&gt;<span style=color:#bbb>
</span></span></span></code></pre></div><p>Where <code>&lt;container_name></code> is the name of the container to apply the profile to, and <code>&lt;profile_ref></code>
specifies the profile to apply. The <code>profile_ref</code> can be one of:</p><ul><li><code>runtime/default</code> to apply the runtime's default profile</li><li><code>localhost/&lt;profile_name></code> to apply the profile loaded on the host with the name <code>&lt;profile_name></code></li><li><code>unconfined</code> to indicate that no profiles will be loaded</li></ul><p>See the <a href=#api-reference>API Reference</a> for the full details on the annotation and profile name formats.</p><p>Kubernetes AppArmor enforcement works by first checking that all the prerequisites have been
met, and then forwarding the profile selection to the container runtime for enforcement. If the
prerequisites have not been met, the Pod will be rejected, and will not run.</p><p>To verify that the profile was applied, you can look for the AppArmor security option listed in the container created event:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get events | grep Created
</span></span></code></pre></div><pre tabindex=0><code>22s        22s         1         hello-apparmor     Pod       spec.containers{hello}   Normal    Created     {kubelet e2e-test-stclair-node-pool-31nt}   Created container with docker id 269a53b202d3; Security:[seccomp=unconfined apparmor=k8s-apparmor-example-deny-write]
</code></pre><p>You can also verify directly that the container's root process is running with the correct profile by checking its proc attr:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl <span style=color:#a2f>exec</span> &lt;pod_name&gt; -- cat /proc/1/attr/current
</span></span></code></pre></div><pre tabindex=0><code>k8s-apparmor-example-deny-write (enforce)
</code></pre><h2 id=example>Example</h2><p><em>This example assumes you have already set up a cluster with AppArmor support.</em></p><p>First, we need to load the profile we want to use onto our nodes. This profile denies all file writes:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span><span style=color:#080;font-style:italic>#include &lt;tunables/global&gt;</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>profile k8s-apparmor-example-deny-write <span style=color:#b8860b>flags</span><span style=color:#666>=(</span>attach_disconnected<span style=color:#666>)</span> <span style=color:#666>{</span>
</span></span><span style=display:flex><span>  <span style=color:#080;font-style:italic>#include &lt;abstractions/base&gt;</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>  file,
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>  <span style=color:#080;font-style:italic># Deny all file writes.</span>
</span></span><span style=display:flex><span>  deny /** w,
</span></span><span style=display:flex><span><span style=color:#666>}</span>
</span></span></code></pre></div><p>Since we don't know where the Pod will be scheduled, we'll need to load the profile on all our
nodes. For this example we'll use SSH to install the profiles, but other approaches are
discussed in <a href=#setting-up-nodes-with-profiles>Setting up nodes with profiles</a>.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span><span style=color:#b8860b>NODES</span><span style=color:#666>=(</span>
</span></span><span style=display:flex><span>    <span style=color:#080;font-style:italic># The SSH-accessible domain names of your nodes</span>
</span></span><span style=display:flex><span>    gke-test-default-pool-239f5d02-gyn2.us-central1-a.my-k8s
</span></span><span style=display:flex><span>    gke-test-default-pool-239f5d02-x1kf.us-central1-a.my-k8s
</span></span><span style=display:flex><span>    gke-test-default-pool-239f5d02-xwux.us-central1-a.my-k8s<span style=color:#666>)</span>
</span></span><span style=display:flex><span><span style=color:#a2f;font-weight:700>for</span> NODE in <span style=color:#b68;font-weight:700>${</span><span style=color:#b8860b>NODES</span>[*]<span style=color:#b68;font-weight:700>}</span>; <span style=color:#a2f;font-weight:700>do</span> ssh <span style=color:#b8860b>$NODE</span> <span style=color:#b44>&#39;sudo apparmor_parser -q &lt;&lt;EOF
</span></span></span><span style=display:flex><span><span style=color:#b44>#include &lt;tunables/global&gt;
</span></span></span><span style=display:flex><span><span style=color:#b44>
</span></span></span><span style=display:flex><span><span style=color:#b44>profile k8s-apparmor-example-deny-write flags=(attach_disconnected) {
</span></span></span><span style=display:flex><span><span style=color:#b44>  #include &lt;abstractions/base&gt;
</span></span></span><span style=display:flex><span><span style=color:#b44>
</span></span></span><span style=display:flex><span><span style=color:#b44>  file,
</span></span></span><span style=display:flex><span><span style=color:#b44>
</span></span></span><span style=display:flex><span><span style=color:#b44>  # Deny all file writes.
</span></span></span><span style=display:flex><span><span style=color:#b44>  deny /** w,
</span></span></span><span style=display:flex><span><span style=color:#b44>}
</span></span></span><span style=display:flex><span><span style=color:#b44>EOF&#39;</span>
</span></span><span style=display:flex><span><span style=color:#a2f;font-weight:700>done</span>
</span></span></code></pre></div><p>Next, we'll run a simple "Hello AppArmor" pod with the deny-write profile:</p><div class=highlight><div class=copy-code-icon style=text-align:right><a href=https://raw.githubusercontent.com/kubernetes/website/main/content/en/examples/pods/security/hello-apparmor.yaml download=pods/security/hello-apparmor.yaml><code>pods/security/hello-apparmor.yaml</code></a>
<img src=/images/copycode.svg style=max-height:24px;cursor:pointer onclick='copyCode("pods-security-hello-apparmor-yaml")' title="Copy pods/security/hello-apparmor.yaml to clipboard"></img></div><div class=includecode id=pods-security-hello-apparmor-yaml><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>hello-apparmor<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>annotations</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:#080;font-style:italic># Tell Kubernetes to apply the AppArmor profile &#34;k8s-apparmor-example-deny-write&#34;.</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:#080;font-style:italic># Note that this is ignored if the Kubernetes node is not running version 1.4 or greater.</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>container.apparmor.security.beta.kubernetes.io/hello</span>:<span style=color:#bbb> </span>localhost/k8s-apparmor-example-deny-write<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>hello<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>busybox:1.28<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>command</span>:<span style=color:#bbb> </span>[<span style=color:#bbb> </span><span style=color:#b44>&#34;sh&#34;</span>,<span style=color:#bbb> </span><span style=color:#b44>&#34;-c&#34;</span>,<span style=color:#bbb> </span><span style=color:#b44>&#34;echo &#39;Hello AppArmor!&#39; &amp;&amp; sleep 1h&#34;</span><span style=color:#bbb> </span>]<span style=color:#bbb>
</span></span></span></code></pre></div></div></div><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl create -f ./hello-apparmor.yaml
</span></span></code></pre></div><p>If we look at the pod events, we can see that the Pod container was created with the AppArmor
profile "k8s-apparmor-example-deny-write":</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get events | grep hello-apparmor
</span></span></code></pre></div><pre tabindex=0><code>14s        14s         1         hello-apparmor   Pod                                Normal    Scheduled   {default-scheduler }                           Successfully assigned hello-apparmor to gke-test-default-pool-239f5d02-gyn2
14s        14s         1         hello-apparmor   Pod       spec.containers{hello}   Normal    Pulling     {kubelet gke-test-default-pool-239f5d02-gyn2}   pulling image &#34;busybox&#34;
13s        13s         1         hello-apparmor   Pod       spec.containers{hello}   Normal    Pulled      {kubelet gke-test-default-pool-239f5d02-gyn2}   Successfully pulled image &#34;busybox&#34;
13s        13s         1         hello-apparmor   Pod       spec.containers{hello}   Normal    Created     {kubelet gke-test-default-pool-239f5d02-gyn2}   Created container with docker id 06b6cd1c0989; Security:[seccomp=unconfined apparmor=k8s-apparmor-example-deny-write]
13s        13s         1         hello-apparmor   Pod       spec.containers{hello}   Normal    Started     {kubelet gke-test-default-pool-239f5d02-gyn2}   Started container with docker id 06b6cd1c0989
</code></pre><p>We can verify that the container is actually running with that profile by checking its proc attr:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl <span style=color:#a2f>exec</span> hello-apparmor -- cat /proc/1/attr/current
</span></span></code></pre></div><pre tabindex=0><code>k8s-apparmor-example-deny-write (enforce)
</code></pre><p>Finally, we can see what happens if we try to violate the profile by writing to a file:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl <span style=color:#a2f>exec</span> hello-apparmor -- touch /tmp/test
</span></span></code></pre></div><pre tabindex=0><code>touch: /tmp/test: Permission denied
error: error executing remote command: command terminated with non-zero exit code: Error executing in Docker Container: 1
</code></pre><p>To wrap up, let's look at what happens if we try to specify a profile that hasn't been loaded:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl create -f /dev/stdin &lt;&lt;EOF
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>hello-apparmor-2<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>annotations</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>container.apparmor.security.beta.kubernetes.io/hello</span>:<span style=color:#bbb> </span>localhost/k8s-apparmor-example-allow-write<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>hello<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>busybox:1.28<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>command</span>:<span style=color:#bbb> </span>[<span style=color:#bbb> </span><span style=color:#b44>&#34;sh&#34;</span>,<span style=color:#bbb> </span><span style=color:#b44>&#34;-c&#34;</span>,<span style=color:#bbb> </span><span style=color:#b44>&#34;echo &#39;Hello AppArmor!&#39; &amp;&amp; sleep 1h&#34;</span><span style=color:#bbb> </span>]<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span>EOF<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span>pod/hello-apparmor-2 created<span style=color:#bbb>
</span></span></span></code></pre></div><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl describe pod hello-apparmor-2
</span></span></code></pre></div><pre tabindex=0><code>Name:          hello-apparmor-2
Namespace:     default
Node:          gke-test-default-pool-239f5d02-x1kf/
Start Time:    Tue, 30 Aug 2016 17:58:56 -0700
Labels:        &lt;none&gt;
Annotations:   container.apparmor.security.beta.kubernetes.io/hello=localhost/k8s-apparmor-example-allow-write
Status:        Pending
Reason:        AppArmor
Message:       Pod Cannot enforce AppArmor: profile &#34;k8s-apparmor-example-allow-write&#34; is not loaded
IP:
Controllers:   &lt;none&gt;
Containers:
  hello:
    Container ID:
    Image:     busybox
    Image ID:
    Port:
    Command:
      sh
      -c
      echo &#39;Hello AppArmor!&#39; &amp;&amp; sleep 1h
    State:              Waiting
      Reason:           Blocked
    Ready:              False
    Restart Count:      0
    Environment:        &lt;none&gt;
    Mounts:
      /var/run/secrets/kubernetes.io/serviceaccount from default-token-dnz7v (ro)
Conditions:
  Type          Status
  Initialized   True
  Ready         False
  PodScheduled  True
Volumes:
  default-token-dnz7v:
    Type:    Secret (a volume populated by a Secret)
    SecretName:    default-token-dnz7v
    Optional:   false
QoS Class:      BestEffort
Node-Selectors: &lt;none&gt;
Tolerations:    &lt;none&gt;
Events:
  FirstSeen    LastSeen    Count    From                        SubobjectPath    Type        Reason        Message
  ---------    --------    -----    ----                        -------------    --------    ------        -------
  23s          23s         1        {default-scheduler }                         Normal      Scheduled     Successfully assigned hello-apparmor-2 to e2e-test-stclair-node-pool-t1f5
  23s          23s         1        {kubelet e2e-test-stclair-node-pool-t1f5}             Warning        AppArmor    Cannot enforce AppArmor: profile &#34;k8s-apparmor-example-allow-write&#34; is not loaded
</code></pre><p>Note the pod status is Pending, with a helpful error message: <code>Pod Cannot enforce AppArmor: profile "k8s-apparmor-example-allow-write" is not loaded</code>. An event was also recorded with the same message.</p><h2 id=administration>Administration</h2><h3 id=setting-up-nodes-with-profiles>Setting up nodes with profiles</h3><p>Kubernetes does not currently provide any native mechanisms for loading AppArmor profiles onto
nodes. There are lots of ways to set up the profiles though, such as:</p><ul><li>Through a <a href=/docs/concepts/workloads/controllers/daemonset/>DaemonSet</a> that runs a Pod on each node to
ensure the correct profiles are loaded. An example implementation can be found
<a href=https://git.k8s.io/kubernetes/test/images/apparmor-loader>here</a>.</li><li>At node initialization time, using your node initialization scripts (e.g. Salt, Ansible, etc.) or
image.</li><li>By copying the profiles to each node and loading them through SSH, as demonstrated in the
<a href=#example>Example</a>.</li></ul><p>The scheduler is not aware of which profiles are loaded onto which node, so the full set of profiles
must be loaded onto every node. An alternative approach is to add a node label for each profile (or
class of profiles) on the node, and use a
<a href=/docs/concepts/scheduling-eviction/assign-pod-node/>node selector</a> to ensure the Pod is run on a
node with the required profile.</p><h3 id=disabling-apparmor>Disabling AppArmor</h3><p>If you do not want AppArmor to be available on your cluster, it can be disabled by a command-line flag:</p><pre tabindex=0><code>--feature-gates=AppArmor=false
</code></pre><p>When disabled, any Pod that includes an AppArmor profile will fail validation with a "Forbidden"
error.</p><div class="alert alert-info note callout" role=alert><strong>Note:</strong> Even if the Kubernetes feature is disabled, runtimes may still enforce the default profile. The
option to disable the AppArmor feature will be removed when AppArmor graduates to general
availability (GA).</div><h2 id=authoring-profiles>Authoring Profiles</h2><p>Getting AppArmor profiles specified correctly can be a tricky business. Fortunately there are some
tools to help with that:</p><ul><li><code>aa-genprof</code> and <code>aa-logprof</code> generate profile rules by monitoring an application's activity and
logs, and admitting the actions it takes. Further instructions are provided by the
<a href=https://gitlab.com/apparmor/apparmor/wikis/Profiling_with_tools>AppArmor documentation</a>.</li><li><a href=https://github.com/jfrazelle/bane>bane</a> is an AppArmor profile generator for Docker that uses a
simplified profile language.</li></ul><p>To debug problems with AppArmor, you can check the system logs to see what, specifically, was
denied. AppArmor logs verbose messages to <code>dmesg</code>, and errors can usually be found in the system
logs or through <code>journalctl</code>. More information is provided in
<a href=https://gitlab.com/apparmor/apparmor/wikis/AppArmor_Failures>AppArmor failures</a>.</p><h2 id=api-reference>API Reference</h2><h3 id=pod-annotation>Pod Annotation</h3><p>Specifying the profile a container will run with:</p><ul><li><strong>key</strong>: <code>container.apparmor.security.beta.kubernetes.io/&lt;container_name></code>
Where <code>&lt;container_name></code> matches the name of a container in the Pod.
A separate profile can be specified for each container in the Pod.</li><li><strong>value</strong>: a profile reference, described below</li></ul><h3 id=profile-reference>Profile Reference</h3><ul><li><code>runtime/default</code>: Refers to the default runtime profile.<ul><li>Equivalent to not specifying a profile, except it still
requires AppArmor to be enabled.</li><li>In practice, many container runtimes use the same OCI default profile, defined here:
<a href=https://github.com/containers/common/blob/main/pkg/apparmor/apparmor_linux_template.go>https://github.com/containers/common/blob/main/pkg/apparmor/apparmor_linux_template.go</a></li></ul></li><li><code>localhost/&lt;profile_name></code>: Refers to a profile loaded on the node (localhost) by name.<ul><li>The possible profile names are detailed in the
<a href=https://gitlab.com/apparmor/apparmor/wikis/AppArmor_Core_Policy_Reference#profile-names-and-attachment-specifications>core policy reference</a>.</li></ul></li><li><code>unconfined</code>: This effectively disables AppArmor on the container.</li></ul><p>Any other profile reference format is invalid.</p><h2 id=what-s-next>What's next</h2><p>Additional resources:</p><ul><li><a href=https://gitlab.com/apparmor/apparmor/wikis/QuickProfileLanguage>Quick guide to the AppArmor profile language</a></li><li><a href=https://gitlab.com/apparmor/apparmor/wikis/Policy_Layout>AppArmor core policy reference</a></li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-8b105172a11322c70d0223bc9dff1904>4.4 - Restrict a Container's Syscalls with seccomp</h1><div style=margin-top:10px;margin-bottom:10px><b>FEATURE STATE:</b> <code>Kubernetes v1.19 [stable]</code></div><p>Seccomp stands for secure computing mode and has been a feature of the Linux
kernel since version 2.6.12. It can be used to sandbox the privileges of a
process, restricting the calls it is able to make from userspace into the
kernel. Kubernetes lets you automatically apply seccomp profiles loaded onto a
<a class=glossary-tooltip title='A node is a worker machine in Kubernetes.' data-toggle=tooltip data-placement=top href=/docs/concepts/architecture/nodes/ target=_blank aria-label=node>node</a> to your Pods and containers.</p><p>Identifying the privileges required for your workloads can be difficult. In this
tutorial, you will go through how to load seccomp profiles into a local
Kubernetes cluster, how to apply them to a Pod, and how you can begin to craft
profiles that give only the necessary privileges to your container processes.</p><h2 id=objectives>Objectives</h2><ul><li>Learn how to load seccomp profiles on a node</li><li>Learn how to apply a seccomp profile to a container</li><li>Observe auditing of syscalls made by a container process</li><li>Observe behavior when a missing profile is specified</li><li>Observe a violation of a seccomp profile</li><li>Learn how to create fine-grained seccomp profiles</li><li>Learn how to apply a container runtime default seccomp profile</li></ul><h2 id=before-you-begin>Before you begin</h2><p>In order to complete all steps in this tutorial, you must install
<a href=/docs/tasks/tools/#kind>kind</a> and <a href=/docs/tasks/tools/#kubectl>kubectl</a>.</p><p>This tutorial shows some examples that are still beta (since v1.25) and
others that use only generally available seccomp functionality. You should
make sure that your cluster is
<a href=https://kind.sigs.k8s.io/docs/user/quick-start/#setting-kubernetes-version>configured correctly</a>
for the version you are using.</p><p>The tutorial also uses the <code>curl</code> tool for downloading examples to your computer.
You can adapt the steps to use a different tool if you prefer.</p><div class="alert alert-info note callout" role=alert><strong>Note:</strong> It is not possible to apply a seccomp profile to a container running with
<code>privileged: true</code> set in the container's <code>securityContext</code>. Privileged containers always
run as <code>Unconfined</code>.</div><h2 id=download-profiles>Download example seccomp profiles</h2><p>The contents of these profiles will be explored later on, but for now go ahead
and download them into a directory named <code>profiles/</code> so that they can be loaded
into the cluster.</p><ul class="nav nav-tabs" id=tab-with-code role=tablist><li class=nav-item><a data-toggle=tab class="nav-link active" href=#tab-with-code-0 role=tab aria-controls=tab-with-code-0 aria-selected=true>audit.json</a></li><li class=nav-item><a data-toggle=tab class=nav-link href=#tab-with-code-1 role=tab aria-controls=tab-with-code-1>violation.json</a></li><li class=nav-item><a data-toggle=tab class=nav-link href=#tab-with-code-2 role=tab aria-controls=tab-with-code-2>fine-grained.json</a></li></ul><div class=tab-content id=tab-with-code><div id=tab-with-code-0 class="tab-pane show active" role=tabpanel aria-labelledby=tab-with-code-0><p><div class=highlight><div class=copy-code-icon style=text-align:right><a href=https://raw.githubusercontent.com/kubernetes/website/main/content/en/examples/pods/security/seccomp/profiles/audit.json download=pods/security/seccomp/profiles/audit.json><code>pods/security/seccomp/profiles/audit.json</code></a>
<img src=/images/copycode.svg style=max-height:24px;cursor:pointer onclick='copyCode("pods-security-seccomp-profiles-audit-json")' title="Copy pods/security/seccomp/profiles/audit.json to clipboard"></img></div><div class=includecode id=pods-security-seccomp-profiles-audit-json><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-json data-lang=json><span style=display:flex><span>{
</span></span><span style=display:flex><span>    <span style=color:green;font-weight:700>&#34;defaultAction&#34;</span>: <span style=color:#b44>&#34;SCMP_ACT_LOG&#34;</span>
</span></span><span style=display:flex><span>}</span></span></code></pre></div></div></div></div><div id=tab-with-code-1 class=tab-pane role=tabpanel aria-labelledby=tab-with-code-1><p><div class=highlight><div class=copy-code-icon style=text-align:right><a href=https://raw.githubusercontent.com/kubernetes/website/main/content/en/examples/pods/security/seccomp/profiles/violation.json download=pods/security/seccomp/profiles/violation.json><code>pods/security/seccomp/profiles/violation.json</code></a>
<img src=/images/copycode.svg style=max-height:24px;cursor:pointer onclick='copyCode("pods-security-seccomp-profiles-violation-json")' title="Copy pods/security/seccomp/profiles/violation.json to clipboard"></img></div><div class=includecode id=pods-security-seccomp-profiles-violation-json><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-json data-lang=json><span style=display:flex><span>{
</span></span><span style=display:flex><span>    <span style=color:green;font-weight:700>&#34;defaultAction&#34;</span>: <span style=color:#b44>&#34;SCMP_ACT_ERRNO&#34;</span>
</span></span><span style=display:flex><span>}</span></span></code></pre></div></div></div></div><div id=tab-with-code-2 class=tab-pane role=tabpanel aria-labelledby=tab-with-code-2><p><div class=highlight><div class=copy-code-icon style=text-align:right><a href=https://raw.githubusercontent.com/kubernetes/website/main/content/en/examples/pods/security/seccomp/profiles/fine-grained.json download=pods/security/seccomp/profiles/fine-grained.json><code>pods/security/seccomp/profiles/fine-grained.json</code></a>
<img src=/images/copycode.svg style=max-height:24px;cursor:pointer onclick='copyCode("pods-security-seccomp-profiles-fine-grained-json")' title="Copy pods/security/seccomp/profiles/fine-grained.json to clipboard"></img></div><div class=includecode id=pods-security-seccomp-profiles-fine-grained-json><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-json data-lang=json><span style=display:flex><span>{
</span></span><span style=display:flex><span>    <span style=color:green;font-weight:700>&#34;defaultAction&#34;</span>: <span style=color:#b44>&#34;SCMP_ACT_ERRNO&#34;</span>,
</span></span><span style=display:flex><span>    <span style=color:green;font-weight:700>&#34;architectures&#34;</span>: [
</span></span><span style=display:flex><span>        <span style=color:#b44>&#34;SCMP_ARCH_X86_64&#34;</span>,
</span></span><span style=display:flex><span>        <span style=color:#b44>&#34;SCMP_ARCH_X86&#34;</span>,
</span></span><span style=display:flex><span>        <span style=color:#b44>&#34;SCMP_ARCH_X32&#34;</span>
</span></span><span style=display:flex><span>    ],
</span></span><span style=display:flex><span>    <span style=color:green;font-weight:700>&#34;syscalls&#34;</span>: [
</span></span><span style=display:flex><span>        {
</span></span><span style=display:flex><span>            <span style=color:green;font-weight:700>&#34;names&#34;</span>: [
</span></span><span style=display:flex><span>                <span style=color:#b44>&#34;accept4&#34;</span>,
</span></span><span style=display:flex><span>                <span style=color:#b44>&#34;epoll_wait&#34;</span>,
</span></span><span style=display:flex><span>                <span style=color:#b44>&#34;pselect6&#34;</span>,
</span></span><span style=display:flex><span>                <span style=color:#b44>&#34;futex&#34;</span>,
</span></span><span style=display:flex><span>                <span style=color:#b44>&#34;madvise&#34;</span>,
</span></span><span style=display:flex><span>                <span style=color:#b44>&#34;epoll_ctl&#34;</span>,
</span></span><span style=display:flex><span>                <span style=color:#b44>&#34;getsockname&#34;</span>,
</span></span><span style=display:flex><span>                <span style=color:#b44>&#34;setsockopt&#34;</span>,
</span></span><span style=display:flex><span>                <span style=color:#b44>&#34;vfork&#34;</span>,
</span></span><span style=display:flex><span>                <span style=color:#b44>&#34;mmap&#34;</span>,
</span></span><span style=display:flex><span>                <span style=color:#b44>&#34;read&#34;</span>,
</span></span><span style=display:flex><span>                <span style=color:#b44>&#34;write&#34;</span>,
</span></span><span style=display:flex><span>                <span style=color:#b44>&#34;close&#34;</span>,
</span></span><span style=display:flex><span>                <span style=color:#b44>&#34;arch_prctl&#34;</span>,
</span></span><span style=display:flex><span>                <span style=color:#b44>&#34;sched_getaffinity&#34;</span>,
</span></span><span style=display:flex><span>                <span style=color:#b44>&#34;munmap&#34;</span>,
</span></span><span style=display:flex><span>                <span style=color:#b44>&#34;brk&#34;</span>,
</span></span><span style=display:flex><span>                <span style=color:#b44>&#34;rt_sigaction&#34;</span>,
</span></span><span style=display:flex><span>                <span style=color:#b44>&#34;rt_sigprocmask&#34;</span>,
</span></span><span style=display:flex><span>                <span style=color:#b44>&#34;sigaltstack&#34;</span>,
</span></span><span style=display:flex><span>                <span style=color:#b44>&#34;gettid&#34;</span>,
</span></span><span style=display:flex><span>                <span style=color:#b44>&#34;clone&#34;</span>,
</span></span><span style=display:flex><span>                <span style=color:#b44>&#34;bind&#34;</span>,
</span></span><span style=display:flex><span>                <span style=color:#b44>&#34;socket&#34;</span>,
</span></span><span style=display:flex><span>                <span style=color:#b44>&#34;openat&#34;</span>,
</span></span><span style=display:flex><span>                <span style=color:#b44>&#34;readlinkat&#34;</span>,
</span></span><span style=display:flex><span>                <span style=color:#b44>&#34;exit_group&#34;</span>,
</span></span><span style=display:flex><span>                <span style=color:#b44>&#34;epoll_create1&#34;</span>,
</span></span><span style=display:flex><span>                <span style=color:#b44>&#34;listen&#34;</span>,
</span></span><span style=display:flex><span>                <span style=color:#b44>&#34;rt_sigreturn&#34;</span>,
</span></span><span style=display:flex><span>                <span style=color:#b44>&#34;sched_yield&#34;</span>,
</span></span><span style=display:flex><span>                <span style=color:#b44>&#34;clock_gettime&#34;</span>,
</span></span><span style=display:flex><span>                <span style=color:#b44>&#34;connect&#34;</span>,
</span></span><span style=display:flex><span>                <span style=color:#b44>&#34;dup2&#34;</span>,
</span></span><span style=display:flex><span>                <span style=color:#b44>&#34;epoll_pwait&#34;</span>,
</span></span><span style=display:flex><span>                <span style=color:#b44>&#34;execve&#34;</span>,
</span></span><span style=display:flex><span>                <span style=color:#b44>&#34;exit&#34;</span>,
</span></span><span style=display:flex><span>                <span style=color:#b44>&#34;fcntl&#34;</span>,
</span></span><span style=display:flex><span>                <span style=color:#b44>&#34;getpid&#34;</span>,
</span></span><span style=display:flex><span>                <span style=color:#b44>&#34;getuid&#34;</span>,
</span></span><span style=display:flex><span>                <span style=color:#b44>&#34;ioctl&#34;</span>,
</span></span><span style=display:flex><span>                <span style=color:#b44>&#34;mprotect&#34;</span>,
</span></span><span style=display:flex><span>                <span style=color:#b44>&#34;nanosleep&#34;</span>,
</span></span><span style=display:flex><span>                <span style=color:#b44>&#34;open&#34;</span>,
</span></span><span style=display:flex><span>                <span style=color:#b44>&#34;poll&#34;</span>,
</span></span><span style=display:flex><span>                <span style=color:#b44>&#34;recvfrom&#34;</span>,
</span></span><span style=display:flex><span>                <span style=color:#b44>&#34;sendto&#34;</span>,
</span></span><span style=display:flex><span>                <span style=color:#b44>&#34;set_tid_address&#34;</span>,
</span></span><span style=display:flex><span>                <span style=color:#b44>&#34;setitimer&#34;</span>,
</span></span><span style=display:flex><span>                <span style=color:#b44>&#34;writev&#34;</span>
</span></span><span style=display:flex><span>            ],
</span></span><span style=display:flex><span>            <span style=color:green;font-weight:700>&#34;action&#34;</span>: <span style=color:#b44>&#34;SCMP_ACT_ALLOW&#34;</span>
</span></span><span style=display:flex><span>        }
</span></span><span style=display:flex><span>    ]
</span></span><span style=display:flex><span>}</span></span></code></pre></div></div></div></div></div><p>Run these commands:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>mkdir ./profiles
</span></span><span style=display:flex><span>curl -L -o profiles/audit.json https://k8s.io/examples/pods/security/seccomp/profiles/audit.json
</span></span><span style=display:flex><span>curl -L -o profiles/violation.json https://k8s.io/examples/pods/security/seccomp/profiles/violation.json
</span></span><span style=display:flex><span>curl -L -o profiles/fine-grained.json https://k8s.io/examples/pods/security/seccomp/profiles/fine-grained.json
</span></span><span style=display:flex><span>ls profiles
</span></span></code></pre></div><p>You should see three profiles listed at the end of the final step:</p><pre tabindex=0><code>audit.json  fine-grained.json  violation.json
</code></pre><h2 id=create-a-local-kubernetes-cluster-with-kind>Create a local Kubernetes cluster with kind</h2><p>For simplicity, <a href=https://kind.sigs.k8s.io/>kind</a> can be used to create a single
node cluster with the seccomp profiles loaded. Kind runs Kubernetes in Docker,
so each node of the cluster is a container. This allows for files
to be mounted in the filesystem of each container similar to loading files
onto a node.</p><div class=highlight><div class=copy-code-icon style=text-align:right><a href=https://raw.githubusercontent.com/kubernetes/website/main/content/en/examples/pods/security/seccomp/kind.yaml download=pods/security/seccomp/kind.yaml><code>pods/security/seccomp/kind.yaml</code></a>
<img src=/images/copycode.svg style=max-height:24px;cursor:pointer onclick='copyCode("pods-security-seccomp-kind-yaml")' title="Copy pods/security/seccomp/kind.yaml to clipboard"></img></div><div class=includecode id=pods-security-seccomp-kind-yaml><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>kind.x-k8s.io/v1alpha4<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Cluster<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>nodes</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span>- <span style=color:green;font-weight:700>role</span>:<span style=color:#bbb> </span>control-plane<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>extraMounts</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>hostPath</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;./profiles&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>containerPath</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;/var/lib/kubelet/seccomp/profiles&#34;</span></span></span></code></pre></div></div></div><p>Download that example kind configuration, and save it to a file named <code>kind.yaml</code>:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>curl -L -O https://k8s.io/examples/pods/security/seccomp/kind.yaml
</span></span></code></pre></div><p>You can set a specific Kubernetes version by setting the node's container image.
See <a href=https://kind.sigs.k8s.io/docs/user/configuration/#nodes>Nodes</a> within the
kind documentation about configuration for more details on this.
This tutorial assumes you are using Kubernetes v1.25.</p><p>As a beta feature, you can configure Kubernetes to use the profile that the
<a class=glossary-tooltip title='The container runtime is the software that is responsible for running containers.' data-toggle=tooltip data-placement=top href=/docs/setup/production-environment/container-runtimes target=_blank aria-label='container runtime'>container runtime</a>
prefers by default, rather than falling back to <code>Unconfined</code>.
If you want to try that, see
<a href=#enable-the-use-of-runtimedefault-as-the-default-seccomp-profile-for-all-workloads>enable the use of <code>RuntimeDefault</code> as the default seccomp profile for all workloads</a>
before you continue.</p><p>Once you have a kind configuration in place, create the kind cluster with
that configuration:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kind create cluster --config<span style=color:#666>=</span>kind.yaml
</span></span></code></pre></div><p>After the new Kubernetes cluster is ready, identify the Docker container running
as the single node cluster:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>docker ps
</span></span></code></pre></div><p>You should see output indicating that a container is running with name
<code>kind-control-plane</code>. The output is similar to:</p><pre tabindex=0><code>CONTAINER ID        IMAGE                  COMMAND                  CREATED             STATUS              PORTS                       NAMES
6a96207fed4b        kindest/node:v1.18.2   &#34;/usr/local/bin/entr…&#34;   27 seconds ago      Up 24 seconds       127.0.0.1:42223-&gt;6443/tcp   kind-control-plane
</code></pre><p>If observing the filesystem of that container, you should see that the
<code>profiles/</code> directory has been successfully loaded into the default seccomp path
of the kubelet. Use <code>docker exec</code> to run a command in the Pod:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span><span style=color:#080;font-style:italic># Change 6a96207fed4b to the container ID you saw from &#34;docker ps&#34;</span>
</span></span><span style=display:flex><span>docker <span style=color:#a2f>exec</span> -it 6a96207fed4b ls /var/lib/kubelet/seccomp/profiles
</span></span></code></pre></div><pre tabindex=0><code>audit.json  fine-grained.json  violation.json
</code></pre><p>You have verified that these seccomp profiles are available to the kubelet
running within kind.</p><h2 id=enable-the-use-of-runtimedefault-as-the-default-seccomp-profile-for-all-workloads>Enable the use of <code>RuntimeDefault</code> as the default seccomp profile for all workloads</h2><div style=margin-top:10px;margin-bottom:10px><b>FEATURE STATE:</b> <code>Kubernetes v1.25 [beta]</code></div><p>To use seccomp profile defaulting, you must run the kubelet with the <code>SeccompDefault</code>
<a href=/docs/reference/command-line-tools-reference/feature-gates/>feature gate</a> enabled
(this is the default). You must also explicitly enable the defaulting behavior for each
node where you want to use this with the corresponding <code>--seccomp-default</code>
<a href=/docs/reference/command-line-tools-reference/kubelet>command line flag</a>.
Both have to be enabled simultaneously to use the feature.</p><p>If enabled, the kubelet will use the <code>RuntimeDefault</code> seccomp profile by default, which is
defined by the container runtime, instead of using the <code>Unconfined</code> (seccomp disabled) mode.
The default profiles aim to provide a strong set
of security defaults while preserving the functionality of the workload. It is
possible that the default profiles differ between container runtimes and their
release versions, for example when comparing those from CRI-O and containerd.</p><div class="alert alert-info note callout" role=alert><strong>Note:</strong> Enabling the feature will neither change the Kubernetes
<code>securityContext.seccompProfile</code> API field nor add the deprecated annotations of
the workload. This provides users the possibility to rollback anytime without
actually changing the workload configuration. Tools like
<a href=https://github.com/kubernetes-sigs/cri-tools><code>crictl inspect</code></a> can be used to
verify which seccomp profile is being used by a container.</div><p>Some workloads may require a lower amount of syscall restrictions than others.
This means that they can fail during runtime even with the <code>RuntimeDefault</code>
profile. To mitigate such a failure, you can:</p><ul><li>Run the workload explicitly as <code>Unconfined</code>.</li><li>Disable the <code>SeccompDefault</code> feature for the nodes. Also making sure that
workloads get scheduled on nodes where the feature is disabled.</li><li>Create a custom seccomp profile for the workload.</li></ul><p>If you were introducing this feature into production-like cluster, the Kubernetes project
recommends that you enable this feature gate on a subset of your nodes and then
test workload execution before rolling the change out cluster-wide.</p><p>You can find more detailed information about a possible upgrade and downgrade strategy
in the related Kubernetes Enhancement Proposal (KEP):
<a href=https://github.com/kubernetes/enhancements/tree/9a124fd29d1f9ddf2ff455c49a630e3181992c25/keps/sig-node/2413-seccomp-by-default#upgrade--downgrade-strategy>Enable seccomp by default</a>.</p><p>Kubernetes 1.25 lets you configure the seccomp profile
that applies when the spec for a Pod doesn't define a specific seccomp profile.
This is a beta feature and the corresponding <code>SeccompDefault</code> <a href=/docs/reference/command-line-tools-reference/feature-gates/>feature
gate</a> is enabled by
default. However, you still need to enable this defaulting for each node where
you would like to use it.</p><p>If you are running a Kubernetes 1.25 cluster and want to
enable the feature, either run the kubelet with the <code>--seccomp-default</code> command
line flag, or enable it through the <a href=/docs/tasks/administer-cluster/kubelet-config-file/>kubelet configuration
file</a>. To enable the
feature gate in <a href=https://kind.sigs.k8s.io>kind</a>, ensure that <code>kind</code> provides
the minimum required Kubernetes version and enables the <code>SeccompDefault</code> feature
<a href=https://kind.sigs.k8s.io/docs/user/quick-start/#enable-feature-gates-in-your-cluster>in the kind configuration</a>:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Cluster<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>kind.x-k8s.io/v1alpha4<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>featureGates</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>SeccompDefault</span>:<span style=color:#bbb> </span><span style=color:#a2f;font-weight:700>true</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>nodes</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>role</span>:<span style=color:#bbb> </span>control-plane<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>kindest/node:v1.23.0@sha256:49824ab1727c04e56a21a5d8372a402fcd32ea51ac96a2706a12af38934f81ac<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>kubeadmConfigPatches</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- |<span style=color:#b44;font-style:italic>
</span></span></span><span style=display:flex><span><span style=color:#b44;font-style:italic>        kind: JoinConfiguration
</span></span></span><span style=display:flex><span><span style=color:#b44;font-style:italic>        nodeRegistration:
</span></span></span><span style=display:flex><span><span style=color:#b44;font-style:italic>          kubeletExtraArgs:
</span></span></span><span style=display:flex><span><span style=color:#b44;font-style:italic>            seccomp-default: &#34;true&#34;</span><span style=color:#bbb>        
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>role</span>:<span style=color:#bbb> </span>worker<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>kindest/node:v1.23.0@sha256:49824ab1727c04e56a21a5d8372a402fcd32ea51ac96a2706a12af38934f81ac<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>kubeadmConfigPatches</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- |<span style=color:#b44;font-style:italic>
</span></span></span><span style=display:flex><span><span style=color:#b44;font-style:italic>        kind: JoinConfiguration
</span></span></span><span style=display:flex><span><span style=color:#b44;font-style:italic>        nodeRegistration:
</span></span></span><span style=display:flex><span><span style=color:#b44;font-style:italic>          kubeletExtraArgs:
</span></span></span><span style=display:flex><span><span style=color:#b44;font-style:italic>            feature-gates: SeccompDefault=true
</span></span></span><span style=display:flex><span><span style=color:#b44;font-style:italic>            seccomp-default: &#34;true&#34;</span><span style=color:#bbb>        
</span></span></span></code></pre></div><p>If the cluster is ready, then running a pod:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl run --rm -it --restart<span style=color:#666>=</span>Never --image<span style=color:#666>=</span>alpine alpine -- sh
</span></span></code></pre></div><p>Should now have the default seccomp profile attached. This can be verified by
using <code>docker exec</code> to run <code>crictl inspect</code> for the container on the kind
worker:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>docker <span style=color:#a2f>exec</span> -it kind-worker bash -c <span style=color:#b62;font-weight:700>\
</span></span></span><span style=display:flex><span><span style=color:#b62;font-weight:700></span>    <span style=color:#b44>&#39;crictl inspect $(crictl ps --name=alpine -q) | jq .info.runtimeSpec.linux.seccomp&#39;</span>
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-json data-lang=json><span style=display:flex><span>{
</span></span><span style=display:flex><span>  <span style=color:green;font-weight:700>&#34;defaultAction&#34;</span>: <span style=color:#b44>&#34;SCMP_ACT_ERRNO&#34;</span>,
</span></span><span style=display:flex><span>  <span style=color:green;font-weight:700>&#34;architectures&#34;</span>: [<span style=color:#b44>&#34;SCMP_ARCH_X86_64&#34;</span>, <span style=color:#b44>&#34;SCMP_ARCH_X86&#34;</span>, <span style=color:#b44>&#34;SCMP_ARCH_X32&#34;</span>],
</span></span><span style=display:flex><span>  <span style=color:green;font-weight:700>&#34;syscalls&#34;</span>: [
</span></span><span style=display:flex><span>    {
</span></span><span style=display:flex><span>      <span style=color:green;font-weight:700>&#34;names&#34;</span>: [<span style=color:#b44>&#34;...&#34;</span>]
</span></span><span style=display:flex><span>    }
</span></span><span style=display:flex><span>  ]
</span></span><span style=display:flex><span>}
</span></span></code></pre></div><h2 id=create-a-pod-with-a-seccomp-profile-for-syscall-auditing>Create a Pod with a seccomp profile for syscall auditing</h2><p>To start off, apply the <code>audit.json</code> profile, which will log all syscalls of the
process, to a new Pod.</p><p>Here's a manifest for that Pod:</p><div class=highlight><div class=copy-code-icon style=text-align:right><a href=https://raw.githubusercontent.com/kubernetes/website/main/content/en/examples/pods/security/seccomp/ga/audit-pod.yaml download=pods/security/seccomp/ga/audit-pod.yaml><code>pods/security/seccomp/ga/audit-pod.yaml</code></a>
<img src=/images/copycode.svg style=max-height:24px;cursor:pointer onclick='copyCode("pods-security-seccomp-ga-audit-pod-yaml")' title="Copy pods/security/seccomp/ga/audit-pod.yaml to clipboard"></img></div><div class=includecode id=pods-security-seccomp-ga-audit-pod-yaml><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>audit-pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>labels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>app</span>:<span style=color:#bbb> </span>audit-pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>securityContext</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>seccompProfile</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>type</span>:<span style=color:#bbb> </span>Localhost<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>localhostProfile</span>:<span style=color:#bbb> </span>profiles/audit.json<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>test-container<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>hashicorp/http-echo:0.2.3<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>args</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:#b44>&#34;-text=just made some syscalls!&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>securityContext</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>allowPrivilegeEscalation</span>:<span style=color:#bbb> </span><span style=color:#a2f;font-weight:700>false</span></span></span></code></pre></div></div></div><div class="alert alert-info note callout" role=alert><strong>Note:</strong><p>The functional support for the already deprecated seccomp annotations
<code>seccomp.security.alpha.kubernetes.io/pod</code> (for the whole pod) and
<code>container.seccomp.security.alpha.kubernetes.io/[name]</code> (for a single container)
is going to be removed with a future release of Kubernetes. Please always use
the native API fields in favor of the annotations.</p><p>Since Kubernetes v1.25, kubelets no longer support the annotations, use of the
annotations in static pods is no longer supported, and the seccomp annotations
are no longer auto-populated when pods with seccomp fields are created.
Auto-population of the seccomp fields from the annotations is planned to be
removed in a future release.</p></div><p>Create the Pod in the cluster:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl apply -f https://k8s.io/examples/pods/security/seccomp/ga/audit-pod.yaml
</span></span></code></pre></div><p>This profile does not restrict any syscalls, so the Pod should start
successfully.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get pod/audit-pod
</span></span></code></pre></div><pre tabindex=0><code>NAME        READY   STATUS    RESTARTS   AGE
audit-pod   1/1     Running   0          30s
</code></pre><p>In order to be able to interact with this endpoint exposed by this
container, create a NodePort <a class=glossary-tooltip title='A way to expose an application running on a set of Pods as a network service.' data-toggle=tooltip data-placement=top href=/docs/concepts/services-networking/service/ target=_blank aria-label=Services>Services</a>
that allows access to the endpoint from inside the kind control plane container.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl expose pod audit-pod --type NodePort --port <span style=color:#666>5678</span>
</span></span></code></pre></div><p>Check what port the Service has been assigned on the node.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get service audit-pod
</span></span></code></pre></div><p>The output is similar to:</p><pre tabindex=0><code>NAME        TYPE       CLUSTER-IP      EXTERNAL-IP   PORT(S)          AGE
audit-pod   NodePort   10.111.36.142   &lt;none&gt;        5678:32373/TCP   72s
</code></pre><p>Now you can use <code>curl</code> to access that endpoint from inside the kind control plane container,
at the port exposed by this Service. Use <code>docker exec</code> to run the <code>curl</code> command within the
container belonging to that control plane container:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span><span style=color:#080;font-style:italic># Change 6a96207fed4b to the control plane container ID you saw from &#34;docker ps&#34;</span>
</span></span><span style=display:flex><span>docker <span style=color:#a2f>exec</span> -it 6a96207fed4b curl localhost:32373
</span></span></code></pre></div><pre tabindex=0><code>just made some syscalls!
</code></pre><p>You can see that the process is running, but what syscalls did it actually make?
Because this Pod is running in a local cluster, you should be able to see those
in <code>/var/log/syslog</code>. Open up a new terminal window and <code>tail</code> the output for
calls from <code>http-echo</code>:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>tail -f /var/log/syslog | grep <span style=color:#b44>&#39;http-echo&#39;</span>
</span></span></code></pre></div><p>You should already see some logs of syscalls made by <code>http-echo</code>, and if you
<code>curl</code> the endpoint in the control plane container you will see more written.</p><p>For example:</p><pre tabindex=0><code>Jul  6 15:37:40 my-machine kernel: [369128.669452] audit: type=1326 audit(1594067860.484:14536): auid=4294967295 uid=0 gid=0 ses=4294967295 pid=29064 comm=&#34;http-echo&#34; exe=&#34;/http-echo&#34; sig=0 arch=c000003e syscall=51 compat=0 ip=0x46fe1f code=0x7ffc0000
Jul  6 15:37:40 my-machine kernel: [369128.669453] audit: type=1326 audit(1594067860.484:14537): auid=4294967295 uid=0 gid=0 ses=4294967295 pid=29064 comm=&#34;http-echo&#34; exe=&#34;/http-echo&#34; sig=0 arch=c000003e syscall=54 compat=0 ip=0x46fdba code=0x7ffc0000
Jul  6 15:37:40 my-machine kernel: [369128.669455] audit: type=1326 audit(1594067860.484:14538): auid=4294967295 uid=0 gid=0 ses=4294967295 pid=29064 comm=&#34;http-echo&#34; exe=&#34;/http-echo&#34; sig=0 arch=c000003e syscall=202 compat=0 ip=0x455e53 code=0x7ffc0000
Jul  6 15:37:40 my-machine kernel: [369128.669456] audit: type=1326 audit(1594067860.484:14539): auid=4294967295 uid=0 gid=0 ses=4294967295 pid=29064 comm=&#34;http-echo&#34; exe=&#34;/http-echo&#34; sig=0 arch=c000003e syscall=288 compat=0 ip=0x46fdba code=0x7ffc0000
Jul  6 15:37:40 my-machine kernel: [369128.669517] audit: type=1326 audit(1594067860.484:14540): auid=4294967295 uid=0 gid=0 ses=4294967295 pid=29064 comm=&#34;http-echo&#34; exe=&#34;/http-echo&#34; sig=0 arch=c000003e syscall=0 compat=0 ip=0x46fd44 code=0x7ffc0000
Jul  6 15:37:40 my-machine kernel: [369128.669519] audit: type=1326 audit(1594067860.484:14541): auid=4294967295 uid=0 gid=0 ses=4294967295 pid=29064 comm=&#34;http-echo&#34; exe=&#34;/http-echo&#34; sig=0 arch=c000003e syscall=270 compat=0 ip=0x4559b1 code=0x7ffc0000
Jul  6 15:38:40 my-machine kernel: [369188.671648] audit: type=1326 audit(1594067920.488:14559): auid=4294967295 uid=0 gid=0 ses=4294967295 pid=29064 comm=&#34;http-echo&#34; exe=&#34;/http-echo&#34; sig=0 arch=c000003e syscall=270 compat=0 ip=0x4559b1 code=0x7ffc0000
Jul  6 15:38:40 my-machine kernel: [369188.671726] audit: type=1326 audit(1594067920.488:14560): auid=4294967295 uid=0 gid=0 ses=4294967295 pid=29064 comm=&#34;http-echo&#34; exe=&#34;/http-echo&#34; sig=0 arch=c000003e syscall=202 compat=0 ip=0x455e53 code=0x7ffc0000
</code></pre><p>You can begin to understand the syscalls required by the <code>http-echo</code> process by
looking at the <code>syscall=</code> entry on each line. While these are unlikely to
encompass all syscalls it uses, it can serve as a basis for a seccomp profile
for this container.</p><p>Clean up that Pod and Service before moving to the next section:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl delete service audit-pod --wait
</span></span><span style=display:flex><span>kubectl delete pod audit-pod --wait --now
</span></span></code></pre></div><h2 id=create-pod-with-a-seccomp-profile-that-causes-violation>Create Pod with a seccomp profile that causes violation</h2><p>For demonstration, apply a profile to the Pod that does not allow for any
syscalls.</p><p>The manifest for this demonstration is:</p><div class=highlight><div class=copy-code-icon style=text-align:right><a href=https://raw.githubusercontent.com/kubernetes/website/main/content/en/examples/pods/security/seccomp/ga/violation-pod.yaml download=pods/security/seccomp/ga/violation-pod.yaml><code>pods/security/seccomp/ga/violation-pod.yaml</code></a>
<img src=/images/copycode.svg style=max-height:24px;cursor:pointer onclick='copyCode("pods-security-seccomp-ga-violation-pod-yaml")' title="Copy pods/security/seccomp/ga/violation-pod.yaml to clipboard"></img></div><div class=includecode id=pods-security-seccomp-ga-violation-pod-yaml><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>violation-pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>labels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>app</span>:<span style=color:#bbb> </span>violation-pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>securityContext</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>seccompProfile</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>type</span>:<span style=color:#bbb> </span>Localhost<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>localhostProfile</span>:<span style=color:#bbb> </span>profiles/violation.json<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>test-container<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>hashicorp/http-echo:0.2.3<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>args</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:#b44>&#34;-text=just made some syscalls!&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>securityContext</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>allowPrivilegeEscalation</span>:<span style=color:#bbb> </span><span style=color:#a2f;font-weight:700>false</span></span></span></code></pre></div></div></div><p>Attempt to create the Pod in the cluster:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl apply -f https://k8s.io/examples/pods/security/seccomp/ga/violation-pod.yaml
</span></span></code></pre></div><p>The Pod creates, but there is an issue.
If you check the status of the Pod, you should see that it failed to start.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get pod/violation-pod
</span></span></code></pre></div><pre tabindex=0><code>NAME            READY   STATUS             RESTARTS   AGE
violation-pod   0/1     CrashLoopBackOff   1          6s
</code></pre><p>As seen in the previous example, the <code>http-echo</code> process requires quite a few
syscalls. Here seccomp has been instructed to error on any syscall by setting
<code>"defaultAction": "SCMP_ACT_ERRNO"</code>. This is extremely secure, but removes the
ability to do anything meaningful. What you really want is to give workloads
only the privileges they need.</p><p>Clean up that Pod before moving to the next section:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl delete pod violation-pod --wait --now
</span></span></code></pre></div><h2 id=create-pod-with-a-seccomp-profile-that-only-allows-necessary-syscalls>Create Pod with a seccomp profile that only allows necessary syscalls</h2><p>If you take a look at the <code>fine-grained.json</code> profile, you will notice some of the syscalls
seen in syslog of the first example where the profile set <code>"defaultAction": "SCMP_ACT_LOG"</code>. Now the profile is setting <code>"defaultAction": "SCMP_ACT_ERRNO"</code>,
but explicitly allowing a set of syscalls in the <code>"action": "SCMP_ACT_ALLOW"</code>
block. Ideally, the container will run successfully and you will see no messages
sent to <code>syslog</code>.</p><p>The manifest for this example is:</p><div class=highlight><div class=copy-code-icon style=text-align:right><a href=https://raw.githubusercontent.com/kubernetes/website/main/content/en/examples/pods/security/seccomp/ga/fine-pod.yaml download=pods/security/seccomp/ga/fine-pod.yaml><code>pods/security/seccomp/ga/fine-pod.yaml</code></a>
<img src=/images/copycode.svg style=max-height:24px;cursor:pointer onclick='copyCode("pods-security-seccomp-ga-fine-pod-yaml")' title="Copy pods/security/seccomp/ga/fine-pod.yaml to clipboard"></img></div><div class=includecode id=pods-security-seccomp-ga-fine-pod-yaml><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>fine-pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>labels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>app</span>:<span style=color:#bbb> </span>fine-pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>securityContext</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>seccompProfile</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>type</span>:<span style=color:#bbb> </span>Localhost<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>localhostProfile</span>:<span style=color:#bbb> </span>profiles/fine-grained.json<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>test-container<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>hashicorp/http-echo:0.2.3<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>args</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:#b44>&#34;-text=just made some syscalls!&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>securityContext</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>allowPrivilegeEscalation</span>:<span style=color:#bbb> </span><span style=color:#a2f;font-weight:700>false</span></span></span></code></pre></div></div></div><p>Create the Pod in your cluster:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl apply -f https://k8s.io/examples/pods/security/seccomp/ga/fine-pod.yaml
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get pod fine-pod
</span></span></code></pre></div><p>The Pod should be showing as having started successfully:</p><pre tabindex=0><code>NAME        READY   STATUS    RESTARTS   AGE
fine-pod   1/1     Running   0          30s
</code></pre><p>Open up a new terminal window and use <code>tail</code> to monitor for log entries that
mention calls from <code>http-echo</code>:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span><span style=color:#080;font-style:italic># The log path on your computer might be different from &#34;/var/log/syslog&#34;</span>
</span></span><span style=display:flex><span>tail -f /var/log/syslog | grep <span style=color:#b44>&#39;http-echo&#39;</span>
</span></span></code></pre></div><p>Next, expose the Pod with a NodePort Service:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl expose pod fine-pod --type NodePort --port <span style=color:#666>5678</span>
</span></span></code></pre></div><p>Check what port the Service has been assigned on the node:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get service fine-pod
</span></span></code></pre></div><p>The output is similar to:</p><pre tabindex=0><code>NAME        TYPE       CLUSTER-IP      EXTERNAL-IP   PORT(S)          AGE
fine-pod    NodePort   10.111.36.142   &lt;none&gt;        5678:32373/TCP   72s
</code></pre><p>Use <code>curl</code> to access that endpoint from inside the kind control plane container:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span><span style=color:#080;font-style:italic># Change 6a96207fed4b to the control plane container ID you saw from &#34;docker ps&#34;</span>
</span></span><span style=display:flex><span>docker <span style=color:#a2f>exec</span> -it 6a96207fed4b curl localhost:32373
</span></span></code></pre></div><pre tabindex=0><code>just made some syscalls!
</code></pre><p>You should see no output in the <code>syslog</code>. This is because the profile allowed all
necessary syscalls and specified that an error should occur if one outside of
the list is invoked. This is an ideal situation from a security perspective, but
required some effort in analyzing the program. It would be nice if there was a
simple way to get closer to this security without requiring as much effort.</p><p>Clean up that Pod and Service before moving to the next section:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl delete service fine-pod --wait
</span></span><span style=display:flex><span>kubectl delete pod fine-pod --wait --now
</span></span></code></pre></div><h2 id=create-pod-that-uses-the-container-runtime-default-seccomp-profile>Create Pod that uses the container runtime default seccomp profile</h2><p>Most container runtimes provide a sane set of default syscalls that are allowed
or not. You can adopt these defaults for your workload by setting the seccomp
type in the security context of a pod or container to <code>RuntimeDefault</code>.</p><div class="alert alert-info note callout" role=alert><strong>Note:</strong> If you have the <code>SeccompDefault</code> <a href=/docs/reference/command-line-tools-reference/feature-gates/>feature gate</a> enabled, then Pods use the <code>RuntimeDefault</code> seccomp profile whenever
no other seccomp profile is specified. Otherwise, the default is <code>Unconfined</code>.</div><p>Here's a manifest for a Pod that requests the <code>RuntimeDefault</code> seccomp profile
for all its containers:</p><div class=highlight><div class=copy-code-icon style=text-align:right><a href=https://raw.githubusercontent.com/kubernetes/website/main/content/en/examples/pods/security/seccomp/ga/default-pod.yaml download=pods/security/seccomp/ga/default-pod.yaml><code>pods/security/seccomp/ga/default-pod.yaml</code></a>
<img src=/images/copycode.svg style=max-height:24px;cursor:pointer onclick='copyCode("pods-security-seccomp-ga-default-pod-yaml")' title="Copy pods/security/seccomp/ga/default-pod.yaml to clipboard"></img></div><div class=includecode id=pods-security-seccomp-ga-default-pod-yaml><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>default-pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>labels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>app</span>:<span style=color:#bbb> </span>default-pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>securityContext</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>seccompProfile</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>type</span>:<span style=color:#bbb> </span>RuntimeDefault<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>test-container<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>hashicorp/http-echo:0.2.3<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>args</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:#b44>&#34;-text=just made some more syscalls!&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>securityContext</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>allowPrivilegeEscalation</span>:<span style=color:#bbb> </span><span style=color:#a2f;font-weight:700>false</span></span></span></code></pre></div></div></div><p>Create that Pod:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl apply -f https://k8s.io/examples/pods/security/seccomp/ga/default-pod.yaml
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get pod default-pod
</span></span></code></pre></div><p>The Pod should be showing as having started successfully:</p><pre tabindex=0><code>NAME        READY   STATUS    RESTARTS   AGE
default-pod 1/1     Running   0          20s
</code></pre><p>Finally, now that you saw that work OK, clean up:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl delete pod default-pod --wait --now
</span></span></code></pre></div><h2 id=what-s-next>What's next</h2><p>You can learn more about Linux seccomp:</p><ul><li><a href=https://lwn.net/Articles/656307/>A seccomp Overview</a></li><li><a href=https://docs.docker.com/engine/security/seccomp/>Seccomp Security Profiles for Docker</a></li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-1efbbc2c3015389f835b1661d5effb29>5 - Stateless Applications</h1></div><div class=td-content><h1 id=pg-62caf420877232190a7404b8d93c6724>5.1 - Exposing an External IP Address to Access an Application in a Cluster</h1><p>This page shows how to create a Kubernetes Service object that exposes an
external IP address.</p><h2 id=before-you-begin>Before you begin</h2><ul><li>Install <a href=/docs/tasks/tools/>kubectl</a>.</li><li>Use a cloud provider like Google Kubernetes Engine or Amazon Web Services to
create a Kubernetes cluster. This tutorial creates an
<a href=/docs/tasks/access-application-cluster/create-external-load-balancer/>external load balancer</a>,
which requires a cloud provider.</li><li>Configure <code>kubectl</code> to communicate with your Kubernetes API server. For instructions, see the
documentation for your cloud provider.</li></ul><h2 id=objectives>Objectives</h2><ul><li>Run five instances of a Hello World application.</li><li>Create a Service object that exposes an external IP address.</li><li>Use the Service object to access the running application.</li></ul><h2 id=creating-a-service-for-an-application-running-in-five-pods>Creating a service for an application running in five pods</h2><ol><li><p>Run a Hello World application in your cluster:</p><div class=highlight><div class=copy-code-icon style=text-align:right><a href=https://raw.githubusercontent.com/kubernetes/website/main/content/en/examples/service/load-balancer-example.yaml download=service/load-balancer-example.yaml><code>service/load-balancer-example.yaml</code></a>
<img src=/images/copycode.svg style=max-height:24px;cursor:pointer onclick='copyCode("service-load-balancer-example-yaml")' title="Copy service/load-balancer-example.yaml to clipboard"></img></div><div class=includecode id=service-load-balancer-example-yaml><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>apps/v1<span style=color:#bbb>
   </span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Deployment<span style=color:#bbb>
   </span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
   </span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>labels</span>:<span style=color:#bbb>
   </span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>app.kubernetes.io/name</span>:<span style=color:#bbb> </span>load-balancer-example<span style=color:#bbb>
   </span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>hello-world<span style=color:#bbb>
   </span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
   </span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>replicas</span>:<span style=color:#bbb> </span><span style=color:#666>5</span><span style=color:#bbb>
   </span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>selector</span>:<span style=color:#bbb>
   </span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>matchLabels</span>:<span style=color:#bbb>
   </span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>app.kubernetes.io/name</span>:<span style=color:#bbb> </span>load-balancer-example<span style=color:#bbb>
   </span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>template</span>:<span style=color:#bbb>
   </span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
   </span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>labels</span>:<span style=color:#bbb>
   </span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>app.kubernetes.io/name</span>:<span style=color:#bbb> </span>load-balancer-example<span style=color:#bbb>
   </span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
   </span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
   </span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- <span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>gcr.io/google-samples/node-hello:1.0<span style=color:#bbb>
   </span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>hello-world<span style=color:#bbb>
   </span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>ports</span>:<span style=color:#bbb>
   </span></span></span><span style=display:flex><span><span style=color:#bbb>        </span>- <span style=color:green;font-weight:700>containerPort</span>:<span style=color:#bbb> </span><span style=color:#666>8080</span><span style=color:#bbb>
   </span></span></span></code></pre></div></div></div><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl apply -f https://k8s.io/examples/service/load-balancer-example.yaml
</span></span></code></pre></div><p>The preceding command creates a
<a class=glossary-tooltip title='Manages a replicated application on your cluster.' data-toggle=tooltip data-placement=top href=/docs/concepts/workloads/controllers/deployment/ target=_blank aria-label=Deployment>Deployment</a>
and an associated
<a class=glossary-tooltip title='ReplicaSet ensures that a specified number of Pod replicas are running at one time' data-toggle=tooltip data-placement=top href=/docs/concepts/workloads/controllers/replicaset/ target=_blank aria-label=ReplicaSet>ReplicaSet</a>.
The ReplicaSet has five
<a class=glossary-tooltip title='A Pod represents a set of running containers in your cluster.' data-toggle=tooltip data-placement=top href=/docs/concepts/workloads/pods/ target=_blank aria-label=Pods>Pods</a>
each of which runs the Hello World application.</p></li><li><p>Display information about the Deployment:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get deployments hello-world
</span></span><span style=display:flex><span>kubectl describe deployments hello-world
</span></span></code></pre></div></li><li><p>Display information about your ReplicaSet objects:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get replicasets
</span></span><span style=display:flex><span>kubectl describe replicasets
</span></span></code></pre></div></li><li><p>Create a Service object that exposes the deployment:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl expose deployment hello-world --type<span style=color:#666>=</span>LoadBalancer --name<span style=color:#666>=</span>my-service
</span></span></code></pre></div></li><li><p>Display information about the Service:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get services my-service
</span></span></code></pre></div><p>The output is similar to:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-console data-lang=console><span style=display:flex><span><span style=color:#888>NAME         TYPE           CLUSTER-IP     EXTERNAL-IP      PORT(S)    AGE
</span></span></span><span style=display:flex><span><span style=color:#888>my-service   LoadBalancer   10.3.245.137   104.198.205.71   8080/TCP   54s
</span></span></span></code></pre></div><div class="alert alert-info note callout" role=alert><strong>Note:</strong> The <code>type=LoadBalancer</code> service is backed by external cloud providers, which is not covered in this example, please refer to <a href=/docs/concepts/services-networking/service/#loadbalancer>this page</a> for the details.</div><div class="alert alert-info note callout" role=alert><strong>Note:</strong> If the external IP address is shown as &lt;pending>, wait for a minute and enter the same command again.</div></li><li><p>Display detailed information about the Service:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl describe services my-service
</span></span></code></pre></div><p>The output is similar to:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-console data-lang=console><span style=display:flex><span><span style=color:#888>Name:           my-service
</span></span></span><span style=display:flex><span><span style=color:#888>Namespace:      default
</span></span></span><span style=display:flex><span><span style=color:#888>Labels:         app.kubernetes.io/name=load-balancer-example
</span></span></span><span style=display:flex><span><span style=color:#888>Annotations:    &lt;none&gt;
</span></span></span><span style=display:flex><span><span style=color:#888>Selector:       app.kubernetes.io/name=load-balancer-example
</span></span></span><span style=display:flex><span><span style=color:#888>Type:           LoadBalancer
</span></span></span><span style=display:flex><span><span style=color:#888>IP:             10.3.245.137
</span></span></span><span style=display:flex><span><span style=color:#888>LoadBalancer Ingress:   104.198.205.71
</span></span></span><span style=display:flex><span><span style=color:#888>Port:           &lt;unset&gt; 8080/TCP
</span></span></span><span style=display:flex><span><span style=color:#888>NodePort:       &lt;unset&gt; 32377/TCP
</span></span></span><span style=display:flex><span><span style=color:#888>Endpoints:      10.0.0.6:8080,10.0.1.6:8080,10.0.1.7:8080 + 2 more...
</span></span></span><span style=display:flex><span><span style=color:#888>Session Affinity:   None
</span></span></span><span style=display:flex><span><span style=color:#888>Events:         &lt;none&gt;
</span></span></span></code></pre></div><p>Make a note of the external IP address (<code>LoadBalancer Ingress</code>) exposed by
your service. In this example, the external IP address is 104.198.205.71.
Also note the value of <code>Port</code> and <code>NodePort</code>. In this example, the <code>Port</code>
is 8080 and the <code>NodePort</code> is 32377.</p></li><li><p>In the preceding output, you can see that the service has several endpoints:
10.0.0.6:8080,10.0.1.6:8080,10.0.1.7:8080 + 2 more. These are internal
addresses of the pods that are running the Hello World application. To
verify these are pod addresses, enter this command:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get pods --output<span style=color:#666>=</span>wide
</span></span></code></pre></div><p>The output is similar to:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-console data-lang=console><span style=display:flex><span><span style=color:#888>NAME                         ...  IP         NODE
</span></span></span><span style=display:flex><span><span style=color:#888>hello-world-2895499144-1jaz9 ...  10.0.1.6   gke-cluster-1-default-pool-e0b8d269-1afc
</span></span></span><span style=display:flex><span><span style=color:#888>hello-world-2895499144-2e5uh ...  10.0.1.8   gke-cluster-1-default-pool-e0b8d269-1afc
</span></span></span><span style=display:flex><span><span style=color:#888>hello-world-2895499144-9m4h1 ...  10.0.0.6   gke-cluster-1-default-pool-e0b8d269-5v7a
</span></span></span><span style=display:flex><span><span style=color:#888>hello-world-2895499144-o4z13 ...  10.0.1.7   gke-cluster-1-default-pool-e0b8d269-1afc
</span></span></span><span style=display:flex><span><span style=color:#888>hello-world-2895499144-segjf ...  10.0.2.5   gke-cluster-1-default-pool-e0b8d269-cpuc
</span></span></span></code></pre></div></li><li><p>Use the external IP address (<code>LoadBalancer Ingress</code>) to access the Hello
World application:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>curl http://&lt;external-ip&gt;:&lt;port&gt;
</span></span></code></pre></div><p>where <code>&lt;external-ip></code> is the external IP address (<code>LoadBalancer Ingress</code>)
of your Service, and <code>&lt;port></code> is the value of <code>Port</code> in your Service
description.
If you are using minikube, typing <code>minikube service my-service</code> will
automatically open the Hello World application in a browser.</p><p>The response to a successful request is a hello message:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>Hello Kubernetes!
</span></span></code></pre></div></li></ol><h2 id=cleaning-up>Cleaning up</h2><p>To delete the Service, enter this command:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl delete services my-service
</span></span></code></pre></div><p>To delete the Deployment, the ReplicaSet, and the Pods that are running
the Hello World application, enter this command:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl delete deployment hello-world
</span></span></code></pre></div><h2 id=what-s-next>What's next</h2><p>Learn more about
<a href=/docs/tutorials/services/connect-applications-service/>connecting applications with services</a>.</p></div><div class=td-content style=page-break-before:always><h1 id=pg-8c56795c6614cc5f52434ecc756448ac>5.2 - Example: Deploying PHP Guestbook application with Redis</h1><p>This tutorial shows you how to build and deploy a simple <em>(not production
ready)</em>, multi-tier web application using Kubernetes and
<a href=https://www.docker.com/>Docker</a>. This example consists of the following
components:</p><ul><li>A single-instance <a href=https://www.redis.io/>Redis</a> to store guestbook entries</li><li>Multiple web frontend instances</li></ul><h2 id=objectives>Objectives</h2><ul><li>Start up a Redis leader.</li><li>Start up two Redis followers.</li><li>Start up the guestbook frontend.</li><li>Expose and view the Frontend Service.</li><li>Clean up.</li></ul><h2 id=before-you-begin>Before you begin</h2><p>You need to have a Kubernetes cluster, and the kubectl command-line tool must
be configured to communicate with your cluster. It is recommended to run this tutorial on a cluster with at least two nodes that are not acting as control plane hosts. If you do not already have a
cluster, you can create one by using
<a href=https://minikube.sigs.k8s.io/docs/tutorials/multi_node/>minikube</a>
or you can use one of these Kubernetes playgrounds:</p><ul><li><a href=https://killercoda.com/playgrounds/scenario/kubernetes>Killercoda</a></li><li><a href=http://labs.play-with-k8s.com/>Play with Kubernetes</a></li></ul>Your Kubernetes server must be at or later than version v1.14.
To check the version, enter <code>kubectl version</code>.<h2 id=start-up-the-redis-database>Start up the Redis Database</h2><p>The guestbook application uses Redis to store its data.</p><h3 id=creating-the-redis-deployment>Creating the Redis Deployment</h3><p>The manifest file, included below, specifies a Deployment controller that runs a single replica Redis Pod.</p><div class=highlight><div class=copy-code-icon style=text-align:right><a href=https://raw.githubusercontent.com/kubernetes/website/main/content/en/examples/application/guestbook/redis-leader-deployment.yaml download=application/guestbook/redis-leader-deployment.yaml><code>application/guestbook/redis-leader-deployment.yaml</code></a>
<img src=/images/copycode.svg style=max-height:24px;cursor:pointer onclick='copyCode("application-guestbook-redis-leader-deployment-yaml")' title="Copy application/guestbook/redis-leader-deployment.yaml to clipboard"></img></div><div class=includecode id=application-guestbook-redis-leader-deployment-yaml><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#080;font-style:italic># SOURCE: https://cloud.google.com/kubernetes-engine/docs/tutorials/guestbook</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>apps/v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Deployment<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>redis-leader<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>labels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>app</span>:<span style=color:#bbb> </span>redis<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>role</span>:<span style=color:#bbb> </span>leader<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>tier</span>:<span style=color:#bbb> </span>backend<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>replicas</span>:<span style=color:#bbb> </span><span style=color:#666>1</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>selector</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>matchLabels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>app</span>:<span style=color:#bbb> </span>redis<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>template</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>labels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>app</span>:<span style=color:#bbb> </span>redis<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>role</span>:<span style=color:#bbb> </span>leader<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>tier</span>:<span style=color:#bbb> </span>backend<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>leader<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;docker.io/redis:6.0.5&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>resources</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>requests</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>            </span><span style=color:green;font-weight:700>cpu</span>:<span style=color:#bbb> </span>100m<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>            </span><span style=color:green;font-weight:700>memory</span>:<span style=color:#bbb> </span>100Mi<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>ports</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span>- <span style=color:green;font-weight:700>containerPort</span>:<span style=color:#bbb> </span><span style=color:#666>6379</span></span></span></code></pre></div></div></div><ol><li><p>Launch a terminal window in the directory you downloaded the manifest files.</p></li><li><p>Apply the Redis Deployment from the <code>redis-leader-deployment.yaml</code> file:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl apply -f https://k8s.io/examples/application/guestbook/redis-leader-deployment.yaml
</span></span></code></pre></div></li><li><p>Query the list of Pods to verify that the Redis Pod is running:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get pods
</span></span></code></pre></div><p>The response should be similar to this:</p><pre tabindex=0><code>NAME                           READY   STATUS    RESTARTS   AGE
redis-leader-fb76b4755-xjr2n   1/1     Running   0          13s
</code></pre></li><li><p>Run the following command to view the logs from the Redis leader Pod:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl logs -f deployment/redis-leader
</span></span></code></pre></div></li></ol><h3 id=creating-the-redis-leader-service>Creating the Redis leader Service</h3><p>The guestbook application needs to communicate to the Redis to write its data.
You need to apply a <a href=/docs/concepts/services-networking/service/>Service</a> to
proxy the traffic to the Redis Pod. A Service defines a policy to access the
Pods.</p><div class=highlight><div class=copy-code-icon style=text-align:right><a href=https://raw.githubusercontent.com/kubernetes/website/main/content/en/examples/application/guestbook/redis-leader-service.yaml download=application/guestbook/redis-leader-service.yaml><code>application/guestbook/redis-leader-service.yaml</code></a>
<img src=/images/copycode.svg style=max-height:24px;cursor:pointer onclick='copyCode("application-guestbook-redis-leader-service-yaml")' title="Copy application/guestbook/redis-leader-service.yaml to clipboard"></img></div><div class=includecode id=application-guestbook-redis-leader-service-yaml><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#080;font-style:italic># SOURCE: https://cloud.google.com/kubernetes-engine/docs/tutorials/guestbook</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Service<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>redis-leader<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>labels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>app</span>:<span style=color:#bbb> </span>redis<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>role</span>:<span style=color:#bbb> </span>leader<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>tier</span>:<span style=color:#bbb> </span>backend<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>ports</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>port</span>:<span style=color:#bbb> </span><span style=color:#666>6379</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>targetPort</span>:<span style=color:#bbb> </span><span style=color:#666>6379</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>selector</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>app</span>:<span style=color:#bbb> </span>redis<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>role</span>:<span style=color:#bbb> </span>leader<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>tier</span>:<span style=color:#bbb> </span>backend</span></span></code></pre></div></div></div><ol><li><p>Apply the Redis Service from the following <code>redis-leader-service.yaml</code> file:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl apply -f https://k8s.io/examples/application/guestbook/redis-leader-service.yaml
</span></span></code></pre></div></li><li><p>Query the list of Services to verify that the Redis Service is running:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get service
</span></span></code></pre></div><p>The response should be similar to this:</p><pre tabindex=0><code>NAME           TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)    AGE
kubernetes     ClusterIP   10.0.0.1     &lt;none&gt;        443/TCP    1m
redis-leader   ClusterIP   10.103.78.24 &lt;none&gt;        6379/TCP   16s
</code></pre></li></ol><div class="alert alert-info note callout" role=alert><strong>Note:</strong> This manifest file creates a Service named <code>redis-leader</code> with a set of labels
that match the labels previously defined, so the Service routes network
traffic to the Redis Pod.</div><h3 id=set-up-redis-followers>Set up Redis followers</h3><p>Although the Redis leader is a single Pod, you can make it highly available
and meet traffic demands by adding a few Redis followers, or replicas.</p><div class=highlight><div class=copy-code-icon style=text-align:right><a href=https://raw.githubusercontent.com/kubernetes/website/main/content/en/examples/application/guestbook/redis-follower-deployment.yaml download=application/guestbook/redis-follower-deployment.yaml><code>application/guestbook/redis-follower-deployment.yaml</code></a>
<img src=/images/copycode.svg style=max-height:24px;cursor:pointer onclick='copyCode("application-guestbook-redis-follower-deployment-yaml")' title="Copy application/guestbook/redis-follower-deployment.yaml to clipboard"></img></div><div class=includecode id=application-guestbook-redis-follower-deployment-yaml><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#080;font-style:italic># SOURCE: https://cloud.google.com/kubernetes-engine/docs/tutorials/guestbook</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>apps/v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Deployment<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>redis-follower<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>labels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>app</span>:<span style=color:#bbb> </span>redis<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>role</span>:<span style=color:#bbb> </span>follower<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>tier</span>:<span style=color:#bbb> </span>backend<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>replicas</span>:<span style=color:#bbb> </span><span style=color:#666>2</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>selector</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>matchLabels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>app</span>:<span style=color:#bbb> </span>redis<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>template</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>labels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>app</span>:<span style=color:#bbb> </span>redis<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>role</span>:<span style=color:#bbb> </span>follower<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>tier</span>:<span style=color:#bbb> </span>backend<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>follower<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>gcr.io/google_samples/gb-redis-follower:v2<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>resources</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>requests</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>            </span><span style=color:green;font-weight:700>cpu</span>:<span style=color:#bbb> </span>100m<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>            </span><span style=color:green;font-weight:700>memory</span>:<span style=color:#bbb> </span>100Mi<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>ports</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span>- <span style=color:green;font-weight:700>containerPort</span>:<span style=color:#bbb> </span><span style=color:#666>6379</span></span></span></code></pre></div></div></div><ol><li><p>Apply the Redis Deployment from the following <code>redis-follower-deployment.yaml</code> file:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl apply -f https://k8s.io/examples/application/guestbook/redis-follower-deployment.yaml
</span></span></code></pre></div></li><li><p>Verify that the two Redis follower replicas are running by querying the list of Pods:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get pods
</span></span></code></pre></div><p>The response should be similar to this:</p><pre tabindex=0><code>NAME                             READY   STATUS    RESTARTS   AGE
redis-follower-dddfbdcc9-82sfr   1/1     Running   0          37s
redis-follower-dddfbdcc9-qrt5k   1/1     Running   0          38s
redis-leader-fb76b4755-xjr2n     1/1     Running   0          11m
</code></pre></li></ol><h3 id=creating-the-redis-follower-service>Creating the Redis follower service</h3><p>The guestbook application needs to communicate with the Redis followers to
read data. To make the Redis followers discoverable, you must set up another
<a href=/docs/concepts/services-networking/service/>Service</a>.</p><div class=highlight><div class=copy-code-icon style=text-align:right><a href=https://raw.githubusercontent.com/kubernetes/website/main/content/en/examples/application/guestbook/redis-follower-service.yaml download=application/guestbook/redis-follower-service.yaml><code>application/guestbook/redis-follower-service.yaml</code></a>
<img src=/images/copycode.svg style=max-height:24px;cursor:pointer onclick='copyCode("application-guestbook-redis-follower-service-yaml")' title="Copy application/guestbook/redis-follower-service.yaml to clipboard"></img></div><div class=includecode id=application-guestbook-redis-follower-service-yaml><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#080;font-style:italic># SOURCE: https://cloud.google.com/kubernetes-engine/docs/tutorials/guestbook</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Service<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>redis-follower<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>labels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>app</span>:<span style=color:#bbb> </span>redis<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>role</span>:<span style=color:#bbb> </span>follower<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>tier</span>:<span style=color:#bbb> </span>backend<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>ports</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:#080;font-style:italic># the port that this service should serve on</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>port</span>:<span style=color:#bbb> </span><span style=color:#666>6379</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>selector</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>app</span>:<span style=color:#bbb> </span>redis<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>role</span>:<span style=color:#bbb> </span>follower<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>tier</span>:<span style=color:#bbb> </span>backend</span></span></code></pre></div></div></div><ol><li><p>Apply the Redis Service from the following <code>redis-follower-service.yaml</code> file:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl apply -f https://k8s.io/examples/application/guestbook/redis-follower-service.yaml
</span></span></code></pre></div></li><li><p>Query the list of Services to verify that the Redis Service is running:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get service
</span></span></code></pre></div><p>The response should be similar to this:</p><pre tabindex=0><code>NAME             TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)    AGE
kubernetes       ClusterIP   10.96.0.1       &lt;none&gt;        443/TCP    3d19h
redis-follower   ClusterIP   10.110.162.42   &lt;none&gt;        6379/TCP   9s
redis-leader     ClusterIP   10.103.78.24    &lt;none&gt;        6379/TCP   6m10s
</code></pre></li></ol><div class="alert alert-info note callout" role=alert><strong>Note:</strong> This manifest file creates a Service named <code>redis-follower</code> with a set of
labels that match the labels previously defined, so the Service routes network
traffic to the Redis Pod.</div><h2 id=set-up-and-expose-the-guestbook-frontend>Set up and Expose the Guestbook Frontend</h2><p>Now that you have the Redis storage of your guestbook up and running, start
the guestbook web servers. Like the Redis followers, the frontend is deployed
using a Kubernetes Deployment.</p><p>The guestbook app uses a PHP frontend. It is configured to communicate with
either the Redis follower or leader Services, depending on whether the request
is a read or a write. The frontend exposes a JSON interface, and serves a
jQuery-Ajax-based UX.</p><h3 id=creating-the-guestbook-frontend-deployment>Creating the Guestbook Frontend Deployment</h3><div class=highlight><div class=copy-code-icon style=text-align:right><a href=https://raw.githubusercontent.com/kubernetes/website/main/content/en/examples/application/guestbook/frontend-deployment.yaml download=application/guestbook/frontend-deployment.yaml><code>application/guestbook/frontend-deployment.yaml</code></a>
<img src=/images/copycode.svg style=max-height:24px;cursor:pointer onclick='copyCode("application-guestbook-frontend-deployment-yaml")' title="Copy application/guestbook/frontend-deployment.yaml to clipboard"></img></div><div class=includecode id=application-guestbook-frontend-deployment-yaml><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#080;font-style:italic># SOURCE: https://cloud.google.com/kubernetes-engine/docs/tutorials/guestbook</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>apps/v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Deployment<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>frontend<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>replicas</span>:<span style=color:#bbb> </span><span style=color:#666>3</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>selector</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>matchLabels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>app</span>:<span style=color:#bbb> </span>guestbook<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>tier</span>:<span style=color:#bbb> </span>frontend<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>template</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>labels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>app</span>:<span style=color:#bbb> </span>guestbook<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>tier</span>:<span style=color:#bbb> </span>frontend<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>php-redis<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>gcr.io/google_samples/gb-frontend:v5<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>env</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>GET_HOSTS_FROM<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>value</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;dns&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>resources</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>requests</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>            </span><span style=color:green;font-weight:700>cpu</span>:<span style=color:#bbb> </span>100m<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>            </span><span style=color:green;font-weight:700>memory</span>:<span style=color:#bbb> </span>100Mi<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>ports</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span>- <span style=color:green;font-weight:700>containerPort</span>:<span style=color:#bbb> </span><span style=color:#666>80</span></span></span></code></pre></div></div></div><ol><li><p>Apply the frontend Deployment from the <code>frontend-deployment.yaml</code> file:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl apply -f https://k8s.io/examples/application/guestbook/frontend-deployment.yaml
</span></span></code></pre></div></li><li><p>Query the list of Pods to verify that the three frontend replicas are running:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get pods -l <span style=color:#b8860b>app</span><span style=color:#666>=</span>guestbook -l <span style=color:#b8860b>tier</span><span style=color:#666>=</span>frontend
</span></span></code></pre></div><p>The response should be similar to this:</p><pre tabindex=0><code>NAME                        READY   STATUS    RESTARTS   AGE
frontend-85595f5bf9-5tqhb   1/1     Running   0          47s
frontend-85595f5bf9-qbzwm   1/1     Running   0          47s
frontend-85595f5bf9-zchwc   1/1     Running   0          47s
</code></pre></li></ol><h3 id=creating-the-frontend-service>Creating the Frontend Service</h3><p>The <code>Redis</code> Services you applied is only accessible within the Kubernetes
cluster because the default type for a Service is
<a href=/docs/concepts/services-networking/service/#publishing-services-service-types>ClusterIP</a>.
<code>ClusterIP</code> provides a single IP address for the set of Pods the Service is
pointing to. This IP address is accessible only within the cluster.</p><p>If you want guests to be able to access your guestbook, you must configure the
frontend Service to be externally visible, so a client can request the Service
from outside the Kubernetes cluster. However a Kubernetes user can use
<code>kubectl port-forward</code> to access the service even though it uses a
<code>ClusterIP</code>.</p><div class="alert alert-info note callout" role=alert><strong>Note:</strong> Some cloud providers, like Google Compute Engine or Google Kubernetes Engine,
support external load balancers. If your cloud provider supports load
balancers and you want to use it, uncomment <code>type: LoadBalancer</code>.</div><div class=highlight><div class=copy-code-icon style=text-align:right><a href=https://raw.githubusercontent.com/kubernetes/website/main/content/en/examples/application/guestbook/frontend-service.yaml download=application/guestbook/frontend-service.yaml><code>application/guestbook/frontend-service.yaml</code></a>
<img src=/images/copycode.svg style=max-height:24px;cursor:pointer onclick='copyCode("application-guestbook-frontend-service-yaml")' title="Copy application/guestbook/frontend-service.yaml to clipboard"></img></div><div class=includecode id=application-guestbook-frontend-service-yaml><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#080;font-style:italic># SOURCE: https://cloud.google.com/kubernetes-engine/docs/tutorials/guestbook</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Service<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>frontend<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>labels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>app</span>:<span style=color:#bbb> </span>guestbook<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>tier</span>:<span style=color:#bbb> </span>frontend<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:#080;font-style:italic># if your cluster supports it, uncomment the following to automatically create</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:#080;font-style:italic># an external load-balanced IP for the frontend service.</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:#080;font-style:italic># type: LoadBalancer</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:#080;font-style:italic>#type: LoadBalancer</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>ports</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:#080;font-style:italic># the port that this service should serve on</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>port</span>:<span style=color:#bbb> </span><span style=color:#666>80</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>selector</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>app</span>:<span style=color:#bbb> </span>guestbook<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>tier</span>:<span style=color:#bbb> </span>frontend</span></span></code></pre></div></div></div><ol><li><p>Apply the frontend Service from the <code>frontend-service.yaml</code> file:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl apply -f https://k8s.io/examples/application/guestbook/frontend-service.yaml
</span></span></code></pre></div></li><li><p>Query the list of Services to verify that the frontend Service is running:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get services
</span></span></code></pre></div><p>The response should be similar to this:</p><pre tabindex=0><code>NAME             TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)    AGE
frontend         ClusterIP   10.97.28.230    &lt;none&gt;        80/TCP     19s
kubernetes       ClusterIP   10.96.0.1       &lt;none&gt;        443/TCP    3d19h
redis-follower   ClusterIP   10.110.162.42   &lt;none&gt;        6379/TCP   5m48s
redis-leader     ClusterIP   10.103.78.24    &lt;none&gt;        6379/TCP   11m
</code></pre></li></ol><h3 id=viewing-the-frontend-service-via-kubectl-port-forward>Viewing the Frontend Service via <code>kubectl port-forward</code></h3><ol><li><p>Run the following command to forward port <code>8080</code> on your local machine to port <code>80</code> on the service.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl port-forward svc/frontend 8080:80
</span></span></code></pre></div><p>The response should be similar to this:</p><pre tabindex=0><code>Forwarding from 127.0.0.1:8080 -&gt; 80
Forwarding from [::1]:8080 -&gt; 80
</code></pre></li><li><p>load the page <a href=http://localhost:8080>http://localhost:8080</a> in your browser to view your guestbook.</p></li></ol><h3 id=viewing-the-frontend-service-via-loadbalancer>Viewing the Frontend Service via <code>LoadBalancer</code></h3><p>If you deployed the <code>frontend-service.yaml</code> manifest with type: <code>LoadBalancer</code>
you need to find the IP address to view your Guestbook.</p><ol><li><p>Run the following command to get the IP address for the frontend Service.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get service frontend
</span></span></code></pre></div><p>The response should be similar to this:</p><pre tabindex=0><code>NAME       TYPE           CLUSTER-IP      EXTERNAL-IP        PORT(S)        AGE
frontend   LoadBalancer   10.51.242.136   109.197.92.229     80:32372/TCP   1m
</code></pre></li><li><p>Copy the external IP address, and load the page in your browser to view your guestbook.</p></li></ol><div class="alert alert-info note callout" role=alert><strong>Note:</strong> Try adding some guestbook entries by typing in a message, and clicking Submit.
The message you typed appears in the frontend. This message indicates that
data is successfully added to Redis through the Services you created earlier.</div><h2 id=scale-the-web-frontend>Scale the Web Frontend</h2><p>You can scale up or down as needed because your servers are defined as a
Service that uses a Deployment controller.</p><ol><li><p>Run the following command to scale up the number of frontend Pods:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl scale deployment frontend --replicas<span style=color:#666>=</span><span style=color:#666>5</span>
</span></span></code></pre></div></li><li><p>Query the list of Pods to verify the number of frontend Pods running:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get pods
</span></span></code></pre></div><p>The response should look similar to this:</p><pre tabindex=0><code>NAME                             READY   STATUS    RESTARTS   AGE
frontend-85595f5bf9-5df5m        1/1     Running   0          83s
frontend-85595f5bf9-7zmg5        1/1     Running   0          83s
frontend-85595f5bf9-cpskg        1/1     Running   0          15m
frontend-85595f5bf9-l2l54        1/1     Running   0          14m
frontend-85595f5bf9-l9c8z        1/1     Running   0          14m
redis-follower-dddfbdcc9-82sfr   1/1     Running   0          97m
redis-follower-dddfbdcc9-qrt5k   1/1     Running   0          97m
redis-leader-fb76b4755-xjr2n     1/1     Running   0          108m
</code></pre></li><li><p>Run the following command to scale down the number of frontend Pods:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl scale deployment frontend --replicas<span style=color:#666>=</span><span style=color:#666>2</span>
</span></span></code></pre></div></li><li><p>Query the list of Pods to verify the number of frontend Pods running:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get pods
</span></span></code></pre></div><p>The response should look similar to this:</p><pre tabindex=0><code>NAME                             READY   STATUS    RESTARTS   AGE
frontend-85595f5bf9-cpskg        1/1     Running   0          16m
frontend-85595f5bf9-l9c8z        1/1     Running   0          15m
redis-follower-dddfbdcc9-82sfr   1/1     Running   0          98m
redis-follower-dddfbdcc9-qrt5k   1/1     Running   0          98m
redis-leader-fb76b4755-xjr2n     1/1     Running   0          109m
</code></pre></li></ol><h2 id=cleaning-up>Cleaning up</h2><p>Deleting the Deployments and Services also deletes any running Pods. Use
labels to delete multiple resources with one command.</p><ol><li><p>Run the following commands to delete all Pods, Deployments, and Services.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl delete deployment -l <span style=color:#b8860b>app</span><span style=color:#666>=</span>redis
</span></span><span style=display:flex><span>kubectl delete service -l <span style=color:#b8860b>app</span><span style=color:#666>=</span>redis
</span></span><span style=display:flex><span>kubectl delete deployment frontend
</span></span><span style=display:flex><span>kubectl delete service frontend
</span></span></code></pre></div><p>The response should look similar to this:</p><pre tabindex=0><code>deployment.apps &#34;redis-follower&#34; deleted
deployment.apps &#34;redis-leader&#34; deleted
deployment.apps &#34;frontend&#34; deleted
service &#34;frontend&#34; deleted
</code></pre></li><li><p>Query the list of Pods to verify that no Pods are running:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get pods
</span></span></code></pre></div><p>The response should look similar to this:</p><pre tabindex=0><code>No resources found in default namespace.
</code></pre></li></ol><h2 id=what-s-next>What's next</h2><ul><li>Complete the <a href=/docs/tutorials/kubernetes-basics/>Kubernetes Basics</a> Interactive Tutorials</li><li>Use Kubernetes to create a blog using <a href=/docs/tutorials/stateful-application/mysql-wordpress-persistent-volume/#visit-your-new-wordpress-blog>Persistent Volumes for MySQL and Wordpress</a></li><li>Read more about <a href=/docs/tutorials/services/connect-applications-service/>connecting applications with services</a></li><li>Read more about <a href=/docs/concepts/cluster-administration/manage-deployment/#using-labels-effectively>Managing Resources</a></li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-d6336d9712aa433eb5f0fb8cbed6bef7>6 - Stateful Applications</h1></div><div class=td-content><h1 id=pg-42e39658021b706bcc9478c8cc73c4a3>6.1 - StatefulSet Basics</h1><p>This tutorial provides an introduction to managing applications with
<a class=glossary-tooltip title='Manages deployment and scaling of a set of Pods, with durable storage and persistent identifiers for each Pod.' data-toggle=tooltip data-placement=top href=/docs/concepts/workloads/controllers/statefulset/ target=_blank aria-label=StatefulSets>StatefulSets</a>.
It demonstrates how to create, delete, scale, and update the Pods of StatefulSets.</p><h2 id=before-you-begin>Before you begin</h2><p>Before you begin this tutorial, you should familiarize yourself with the
following Kubernetes concepts:</p><ul><li><a href=/docs/concepts/workloads/pods/>Pods</a></li><li><a href=/docs/concepts/services-networking/dns-pod-service/>Cluster DNS</a></li><li><a href=/docs/concepts/services-networking/service/#headless-services>Headless Services</a></li><li><a href=/docs/concepts/storage/persistent-volumes/>PersistentVolumes</a></li><li><a href=https://github.com/kubernetes/examples/tree/master/staging/persistent-volume-provisioning/>PersistentVolume Provisioning</a></li><li><a href=/docs/concepts/workloads/controllers/statefulset/>StatefulSets</a></li><li>The <a href=/docs/reference/kubectl/kubectl/>kubectl</a> command line tool</li></ul><div class="alert alert-info note callout" role=alert><strong>Note:</strong> This tutorial assumes that your cluster is configured to dynamically provision
PersistentVolumes. If your cluster is not configured to do so, you
will have to manually provision two 1 GiB volumes prior to starting this
tutorial.</div><h2 id=objectives>Objectives</h2><p>StatefulSets are intended to be used with stateful applications and distributed
systems. However, the administration of stateful applications and
distributed systems on Kubernetes is a broad, complex topic. In order to
demonstrate the basic features of a StatefulSet, and not to conflate the former
topic with the latter, you will deploy a simple web application using a StatefulSet.</p><p>After this tutorial, you will be familiar with the following.</p><ul><li>How to create a StatefulSet</li><li>How a StatefulSet manages its Pods</li><li>How to delete a StatefulSet</li><li>How to scale a StatefulSet</li><li>How to update a StatefulSet's Pods</li></ul><h2 id=creating-a-statefulset>Creating a StatefulSet</h2><p>Begin by creating a StatefulSet using the example below. It is similar to the
example presented in the
<a href=/docs/concepts/workloads/controllers/statefulset/>StatefulSets</a> concept.
It creates a <a href=/docs/concepts/services-networking/service/#headless-services>headless Service</a>,
<code>nginx</code>, to publish the IP addresses of Pods in the StatefulSet, <code>web</code>.</p><div class=highlight><div class=copy-code-icon style=text-align:right><a href=https://raw.githubusercontent.com/kubernetes/website/main/content/en/examples/application/web/web.yaml download=application/web/web.yaml><code>application/web/web.yaml</code></a>
<img src=/images/copycode.svg style=max-height:24px;cursor:pointer onclick='copyCode("application-web-web-yaml")' title="Copy application/web/web.yaml to clipboard"></img></div><div class=includecode id=application-web-web-yaml><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Service<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>nginx<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>labels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>app</span>:<span style=color:#bbb> </span>nginx<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>ports</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>port</span>:<span style=color:#bbb> </span><span style=color:#666>80</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>web<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>clusterIP</span>:<span style=color:#bbb> </span>None<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>selector</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>app</span>:<span style=color:#bbb> </span>nginx<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:#00f;font-weight:700>---</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>apps/v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>StatefulSet<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>web<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>serviceName</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;nginx&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>replicas</span>:<span style=color:#bbb> </span><span style=color:#666>2</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>selector</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>matchLabels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>app</span>:<span style=color:#bbb> </span>nginx<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>template</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>labels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>app</span>:<span style=color:#bbb> </span>nginx<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>nginx<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>registry.k8s.io/nginx-slim:0.8<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>ports</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span>- <span style=color:green;font-weight:700>containerPort</span>:<span style=color:#bbb> </span><span style=color:#666>80</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>web<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>volumeMounts</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>www<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>mountPath</span>:<span style=color:#bbb> </span>/usr/share/nginx/html<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>volumeClaimTemplates</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>www<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>accessModes</span>:<span style=color:#bbb> </span>[<span style=color:#bbb> </span><span style=color:#b44>&#34;ReadWriteOnce&#34;</span><span style=color:#bbb> </span>]<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>resources</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>requests</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>storage</span>:<span style=color:#bbb> </span>1Gi<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>
</span></span></span></code></pre></div></div></div><p>Download the example above, and save it to a file named <code>web.yaml</code></p><p>You will need to use two terminal windows. In the first terminal, use
<a href=/docs/reference/generated/kubectl/kubectl-commands/#get><code>kubectl get</code></a> to watch the creation
of the StatefulSet's Pods.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get pods -w -l <span style=color:#b8860b>app</span><span style=color:#666>=</span>nginx
</span></span></code></pre></div><p>In the second terminal, use
<a href=/docs/reference/generated/kubectl/kubectl-commands/#apply><code>kubectl apply</code></a> to create the
headless Service and StatefulSet defined in <code>web.yaml</code>.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl apply -f web.yaml
</span></span></code></pre></div><pre tabindex=0><code>service/nginx created
statefulset.apps/web created
</code></pre><p>The command above creates two Pods, each running an
<a href=https://www.nginx.com>NGINX</a> webserver. Get the <code>nginx</code> Service...</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get service nginx
</span></span></code></pre></div><pre tabindex=0><code>NAME      TYPE         CLUSTER-IP   EXTERNAL-IP   PORT(S)   AGE
nginx     ClusterIP    None         &lt;none&gt;        80/TCP    12s
</code></pre><p>...then get the <code>web</code> StatefulSet, to verify that both were created successfully:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get statefulset web
</span></span></code></pre></div><pre tabindex=0><code>NAME      DESIRED   CURRENT   AGE
web       2         1         20s
</code></pre><h3 id=ordered-pod-creation>Ordered Pod Creation</h3><p>For a StatefulSet with <em>n</em> replicas, when Pods are being deployed, they are
created sequentially, ordered from <em>{0..n-1}</em>. Examine the output of the
<code>kubectl get</code> command in the first terminal. Eventually, the output will
look like the example below.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get pods -w -l <span style=color:#b8860b>app</span><span style=color:#666>=</span>nginx
</span></span></code></pre></div><pre tabindex=0><code>NAME      READY     STATUS    RESTARTS   AGE
web-0     0/1       Pending   0          0s
web-0     0/1       Pending   0         0s
web-0     0/1       ContainerCreating   0         0s
web-0     1/1       Running   0         19s
web-1     0/1       Pending   0         0s
web-1     0/1       Pending   0         0s
web-1     0/1       ContainerCreating   0         0s
web-1     1/1       Running   0         18s
</code></pre><p>Notice that the <code>web-1</code> Pod is not launched until the <code>web-0</code> Pod is
<em>Running</em> (see <a href=/docs/concepts/workloads/pods/pod-lifecycle/#pod-phase>Pod Phase</a>)
and <em>Ready</em> (see <code>type</code> in <a href=/docs/concepts/workloads/pods/pod-lifecycle/#pod-conditions>Pod Conditions</a>).</p><h2 id=pods-in-a-statefulset>Pods in a StatefulSet</h2><p>Pods in a StatefulSet have a unique ordinal index and a stable network identity.</p><h3 id=examining-the-pod-s-ordinal-index>Examining the Pod's Ordinal Index</h3><p>Get the StatefulSet's Pods:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get pods -l <span style=color:#b8860b>app</span><span style=color:#666>=</span>nginx
</span></span></code></pre></div><pre tabindex=0><code>NAME      READY     STATUS    RESTARTS   AGE
web-0     1/1       Running   0          1m
web-1     1/1       Running   0          1m
</code></pre><p>As mentioned in the <a href=/docs/concepts/workloads/controllers/statefulset/>StatefulSets</a>
concept, the Pods in a StatefulSet have a sticky, unique identity. This identity
is based on a unique ordinal index that is assigned to each Pod by the
StatefulSet <a class=glossary-tooltip title='A control loop that watches the shared state of the cluster through the apiserver and makes changes attempting to move the current state towards the desired state.' data-toggle=tooltip data-placement=top href=/docs/concepts/architecture/controller/ target=_blank aria-label=controller>controller</a>.<br>The Pods' names take the form <code>&lt;statefulset name>-&lt;ordinal index></code>.
Since the <code>web</code> StatefulSet has two replicas, it creates two Pods, <code>web-0</code> and <code>web-1</code>.</p><h3 id=using-stable-network-identities>Using Stable Network Identities</h3><p>Each Pod has a stable hostname based on its ordinal index. Use
<a href=/docs/reference/generated/kubectl/kubectl-commands/#exec><code>kubectl exec</code></a> to execute the
<code>hostname</code> command in each Pod:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span><span style=color:#a2f;font-weight:700>for</span> i in <span style=color:#666>0</span> 1; <span style=color:#a2f;font-weight:700>do</span> kubectl <span style=color:#a2f>exec</span> <span style=color:#b44>&#34;web-</span><span style=color:#b8860b>$i</span><span style=color:#b44>&#34;</span> -- sh -c <span style=color:#b44>&#39;hostname&#39;</span>; <span style=color:#a2f;font-weight:700>done</span>
</span></span></code></pre></div><pre tabindex=0><code>web-0
web-1
</code></pre><p>Use <a href=/docs/reference/generated/kubectl/kubectl-commands/#run><code>kubectl run</code></a> to execute
a container that provides the <code>nslookup</code> command from the <code>dnsutils</code> package.
Using <code>nslookup</code> on the Pods' hostnames, you can examine their in-cluster DNS
addresses:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl run -i --tty --image busybox:1.28 dns-test --restart<span style=color:#666>=</span>Never --rm
</span></span></code></pre></div><p>which starts a new shell. In that new shell, run:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span><span style=color:#080;font-style:italic># Run this in the dns-test container shell</span>
</span></span><span style=display:flex><span>nslookup web-0.nginx
</span></span></code></pre></div><p>The output is similar to:</p><pre tabindex=0><code>Server:    10.0.0.10
Address 1: 10.0.0.10 kube-dns.kube-system.svc.cluster.local

Name:      web-0.nginx
Address 1: 10.244.1.6

nslookup web-1.nginx
Server:    10.0.0.10
Address 1: 10.0.0.10 kube-dns.kube-system.svc.cluster.local

Name:      web-1.nginx
Address 1: 10.244.2.6
</code></pre><p>(and now exit the container shell: <code>exit</code>)</p><p>The CNAME of the headless service points to SRV records (one for each Pod that
is Running and Ready). The SRV records point to A record entries that
contain the Pods' IP addresses.</p><p>In one terminal, watch the StatefulSet's Pods:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get pod -w -l <span style=color:#b8860b>app</span><span style=color:#666>=</span>nginx
</span></span></code></pre></div><p>In a second terminal, use
<a href=/docs/reference/generated/kubectl/kubectl-commands/#delete><code>kubectl delete</code></a> to delete all
the Pods in the StatefulSet:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl delete pod -l <span style=color:#b8860b>app</span><span style=color:#666>=</span>nginx
</span></span></code></pre></div><pre tabindex=0><code>pod &#34;web-0&#34; deleted
pod &#34;web-1&#34; deleted
</code></pre><p>Wait for the StatefulSet to restart them, and for both Pods to transition to
Running and Ready:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get pod -w -l <span style=color:#b8860b>app</span><span style=color:#666>=</span>nginx
</span></span></code></pre></div><pre tabindex=0><code>NAME      READY     STATUS              RESTARTS   AGE
web-0     0/1       ContainerCreating   0          0s
NAME      READY     STATUS    RESTARTS   AGE
web-0     1/1       Running   0          2s
web-1     0/1       Pending   0         0s
web-1     0/1       Pending   0         0s
web-1     0/1       ContainerCreating   0         0s
web-1     1/1       Running   0         34s
</code></pre><p>Use <code>kubectl exec</code> and <code>kubectl run</code> to view the Pods' hostnames and in-cluster
DNS entries. First, view the Pods' hostnames:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span><span style=color:#a2f;font-weight:700>for</span> i in <span style=color:#666>0</span> 1; <span style=color:#a2f;font-weight:700>do</span> kubectl <span style=color:#a2f>exec</span> web-<span style=color:#b8860b>$i</span> -- sh -c <span style=color:#b44>&#39;hostname&#39;</span>; <span style=color:#a2f;font-weight:700>done</span>
</span></span></code></pre></div><pre tabindex=0><code>web-0
web-1
</code></pre><p>then, run:</p><pre tabindex=0><code>kubectl run -i --tty --image busybox:1.28 dns-test --restart=Never --rm /bin/sh
</code></pre><p>which starts a new shell.<br>In that new shell, run:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span><span style=color:#080;font-style:italic># Run this in the dns-test container shell</span>
</span></span><span style=display:flex><span>nslookup web-0.nginx
</span></span></code></pre></div><p>The output is similar to:</p><pre tabindex=0><code>Server:    10.0.0.10
Address 1: 10.0.0.10 kube-dns.kube-system.svc.cluster.local

Name:      web-0.nginx
Address 1: 10.244.1.7

nslookup web-1.nginx
Server:    10.0.0.10
Address 1: 10.0.0.10 kube-dns.kube-system.svc.cluster.local

Name:      web-1.nginx
Address 1: 10.244.2.8
</code></pre><p>(and now exit the container shell: <code>exit</code>)</p><p>The Pods' ordinals, hostnames, SRV records, and A record names have not changed,
but the IP addresses associated with the Pods may have changed. In the cluster
used for this tutorial, they have. This is why it is important not to configure
other applications to connect to Pods in a StatefulSet by IP address.</p><p>If you need to find and connect to the active members of a StatefulSet, you
should query the CNAME of the headless Service
(<code>nginx.default.svc.cluster.local</code>). The SRV records associated with the
CNAME will contain only the Pods in the StatefulSet that are Running and
Ready.</p><p>If your application already implements connection logic that tests for
liveness and readiness, you can use the SRV records of the Pods (
<code>web-0.nginx.default.svc.cluster.local</code>,
<code>web-1.nginx.default.svc.cluster.local</code>), as they are stable, and your
application will be able to discover the Pods' addresses when they transition
to Running and Ready.</p><h3 id=writing-to-stable-storage>Writing to Stable Storage</h3><p>Get the PersistentVolumeClaims for <code>web-0</code> and <code>web-1</code>:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get pvc -l <span style=color:#b8860b>app</span><span style=color:#666>=</span>nginx
</span></span></code></pre></div><p>The output is similar to:</p><pre tabindex=0><code>NAME        STATUS    VOLUME                                     CAPACITY   ACCESSMODES   AGE
www-web-0   Bound     pvc-15c268c7-b507-11e6-932f-42010a800002   1Gi        RWO           48s
www-web-1   Bound     pvc-15c79307-b507-11e6-932f-42010a800002   1Gi        RWO           48s
</code></pre><p>The StatefulSet controller created two
<a class=glossary-tooltip title='Claims storage resources defined in a PersistentVolume so that it can be mounted as a volume in a container.' data-toggle=tooltip data-placement=top href=/docs/concepts/storage/persistent-volumes/#persistentvolumeclaims target=_blank aria-label=PersistentVolumeClaims>PersistentVolumeClaims</a>
that are bound to two
<a class=glossary-tooltip title='An API object that represents a piece of storage in the cluster. Available as a general, pluggable resource that persists beyond the lifecycle of any individual Pod.' data-toggle=tooltip data-placement=top href=/docs/concepts/storage/persistent-volumes/ target=_blank aria-label=PersistentVolumes>PersistentVolumes</a>.</p><p>As the cluster used in this tutorial is configured to dynamically provision PersistentVolumes,
the PersistentVolumes were created and bound automatically.</p><p>The NGINX webserver, by default, serves an index file from
<code>/usr/share/nginx/html/index.html</code>. The <code>volumeMounts</code> field in the
StatefulSet's <code>spec</code> ensures that the <code>/usr/share/nginx/html</code> directory is
backed by a PersistentVolume.</p><p>Write the Pods' hostnames to their <code>index.html</code> files and verify that the NGINX
webservers serve the hostnames:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span><span style=color:#a2f;font-weight:700>for</span> i in <span style=color:#666>0</span> 1; <span style=color:#a2f;font-weight:700>do</span> kubectl <span style=color:#a2f>exec</span> <span style=color:#b44>&#34;web-</span><span style=color:#b8860b>$i</span><span style=color:#b44>&#34;</span> -- sh -c <span style=color:#b44>&#39;echo &#34;$(hostname)&#34; &gt; /usr/share/nginx/html/index.html&#39;</span>; <span style=color:#a2f;font-weight:700>done</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#a2f;font-weight:700>for</span> i in <span style=color:#666>0</span> 1; <span style=color:#a2f;font-weight:700>do</span> kubectl <span style=color:#a2f>exec</span> -i -t <span style=color:#b44>&#34;web-</span><span style=color:#b8860b>$i</span><span style=color:#b44>&#34;</span> -- curl http://localhost/; <span style=color:#a2f;font-weight:700>done</span>
</span></span></code></pre></div><pre tabindex=0><code>web-0
web-1
</code></pre><div class="alert alert-info note callout" role=alert><strong>Note:</strong><p>If you instead see <strong>403 Forbidden</strong> responses for the above curl command,
you will need to fix the permissions of the directory mounted by the <code>volumeMounts</code>
(due to a <a href=https://github.com/kubernetes/kubernetes/issues/2630>bug when using hostPath volumes</a>),
by running:</p><p><code>for i in 0 1; do kubectl exec web-$i -- chmod 755 /usr/share/nginx/html; done</code></p><p>before retrying the <code>curl</code> command above.</p></div><p>In one terminal, watch the StatefulSet's Pods:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get pod -w -l <span style=color:#b8860b>app</span><span style=color:#666>=</span>nginx
</span></span></code></pre></div><p>In a second terminal, delete all of the StatefulSet's Pods:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl delete pod -l <span style=color:#b8860b>app</span><span style=color:#666>=</span>nginx
</span></span></code></pre></div><pre tabindex=0><code>pod &#34;web-0&#34; deleted
pod &#34;web-1&#34; deleted
</code></pre><p>Examine the output of the <code>kubectl get</code> command in the first terminal, and wait
for all of the Pods to transition to Running and Ready.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get pod -w -l <span style=color:#b8860b>app</span><span style=color:#666>=</span>nginx
</span></span></code></pre></div><pre tabindex=0><code>NAME      READY     STATUS              RESTARTS   AGE
web-0     0/1       ContainerCreating   0          0s
NAME      READY     STATUS    RESTARTS   AGE
web-0     1/1       Running   0          2s
web-1     0/1       Pending   0         0s
web-1     0/1       Pending   0         0s
web-1     0/1       ContainerCreating   0         0s
web-1     1/1       Running   0         34s
</code></pre><p>Verify the web servers continue to serve their hostnames:</p><pre tabindex=0><code>for i in 0 1; do kubectl exec -i -t &#34;web-$i&#34; -- curl http://localhost/; done
</code></pre><pre tabindex=0><code>web-0
web-1
</code></pre><p>Even though <code>web-0</code> and <code>web-1</code> were rescheduled, they continue to serve their
hostnames because the PersistentVolumes associated with their
PersistentVolumeClaims are remounted to their <code>volumeMounts</code>. No matter what
node <code>web-0</code>and <code>web-1</code> are scheduled on, their PersistentVolumes will be
mounted to the appropriate mount points.</p><h2 id=scaling-a-statefulset>Scaling a StatefulSet</h2><p>Scaling a StatefulSet refers to increasing or decreasing the number of replicas.
This is accomplished by updating the <code>replicas</code> field. You can use either
<a href=/docs/reference/generated/kubectl/kubectl-commands/#scale><code>kubectl scale</code></a> or
<a href=/docs/reference/generated/kubectl/kubectl-commands/#patch><code>kubectl patch</code></a> to scale a StatefulSet.</p><h3 id=scaling-up>Scaling Up</h3><p>In one terminal window, watch the Pods in the StatefulSet:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get pods -w -l <span style=color:#b8860b>app</span><span style=color:#666>=</span>nginx
</span></span></code></pre></div><p>In another terminal window, use <code>kubectl scale</code> to scale the number of replicas
to 5:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl scale sts web --replicas<span style=color:#666>=</span><span style=color:#666>5</span>
</span></span></code></pre></div><pre tabindex=0><code>statefulset.apps/web scaled
</code></pre><p>Examine the output of the <code>kubectl get</code> command in the first terminal, and wait
for the three additional Pods to transition to Running and Ready.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get pods -w -l <span style=color:#b8860b>app</span><span style=color:#666>=</span>nginx
</span></span></code></pre></div><pre tabindex=0><code>NAME      READY     STATUS    RESTARTS   AGE
web-0     1/1       Running   0          2h
web-1     1/1       Running   0          2h
NAME      READY     STATUS    RESTARTS   AGE
web-2     0/1       Pending   0          0s
web-2     0/1       Pending   0         0s
web-2     0/1       ContainerCreating   0         0s
web-2     1/1       Running   0         19s
web-3     0/1       Pending   0         0s
web-3     0/1       Pending   0         0s
web-3     0/1       ContainerCreating   0         0s
web-3     1/1       Running   0         18s
web-4     0/1       Pending   0         0s
web-4     0/1       Pending   0         0s
web-4     0/1       ContainerCreating   0         0s
web-4     1/1       Running   0         19s
</code></pre><p>The StatefulSet controller scaled the number of replicas. As with
<a href=#ordered-pod-creation>StatefulSet creation</a>, the StatefulSet controller
created each Pod sequentially with respect to its ordinal index, and it
waited for each Pod's predecessor to be Running and Ready before launching the
subsequent Pod.</p><h3 id=scaling-down>Scaling Down</h3><p>In one terminal, watch the StatefulSet's Pods:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get pods -w -l <span style=color:#b8860b>app</span><span style=color:#666>=</span>nginx
</span></span></code></pre></div><p>In another terminal, use <code>kubectl patch</code> to scale the StatefulSet back down to
three replicas:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl patch sts web -p <span style=color:#b44>&#39;{&#34;spec&#34;:{&#34;replicas&#34;:3}}&#39;</span>
</span></span></code></pre></div><pre tabindex=0><code>statefulset.apps/web patched
</code></pre><p>Wait for <code>web-4</code> and <code>web-3</code> to transition to Terminating.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get pods -w -l <span style=color:#b8860b>app</span><span style=color:#666>=</span>nginx
</span></span></code></pre></div><pre tabindex=0><code>NAME      READY     STATUS              RESTARTS   AGE
web-0     1/1       Running             0          3h
web-1     1/1       Running             0          3h
web-2     1/1       Running             0          55s
web-3     1/1       Running             0          36s
web-4     0/1       ContainerCreating   0          18s
NAME      READY     STATUS    RESTARTS   AGE
web-4     1/1       Running   0          19s
web-4     1/1       Terminating   0         24s
web-4     1/1       Terminating   0         24s
web-3     1/1       Terminating   0         42s
web-3     1/1       Terminating   0         42s
</code></pre><h3 id=ordered-pod-termination>Ordered Pod Termination</h3><p>The controller deleted one Pod at a time, in reverse order with respect to its
ordinal index, and it waited for each to be completely shutdown before
deleting the next.</p><p>Get the StatefulSet's PersistentVolumeClaims:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get pvc -l <span style=color:#b8860b>app</span><span style=color:#666>=</span>nginx
</span></span></code></pre></div><pre tabindex=0><code>NAME        STATUS    VOLUME                                     CAPACITY   ACCESSMODES   AGE
www-web-0   Bound     pvc-15c268c7-b507-11e6-932f-42010a800002   1Gi        RWO           13h
www-web-1   Bound     pvc-15c79307-b507-11e6-932f-42010a800002   1Gi        RWO           13h
www-web-2   Bound     pvc-e1125b27-b508-11e6-932f-42010a800002   1Gi        RWO           13h
www-web-3   Bound     pvc-e1176df6-b508-11e6-932f-42010a800002   1Gi        RWO           13h
www-web-4   Bound     pvc-e11bb5f8-b508-11e6-932f-42010a800002   1Gi        RWO           13h
</code></pre><p>There are still five PersistentVolumeClaims and five PersistentVolumes.
When exploring a Pod's <a href=#writing-to-stable-storage>stable storage</a>, we saw that the PersistentVolumes mounted to the Pods of a StatefulSet are not deleted when the StatefulSet's Pods are deleted. This is still true when Pod deletion is caused by scaling the StatefulSet down.</p><h2 id=updating-statefulsets>Updating StatefulSets</h2><p>In Kubernetes 1.7 and later, the StatefulSet controller supports automated updates. The
strategy used is determined by the <code>spec.updateStrategy</code> field of the
StatefulSet API Object. This feature can be used to upgrade the container
images, resource requests and/or limits, labels, and annotations of the Pods in a
StatefulSet. There are two valid update strategies, <code>RollingUpdate</code> and
<code>OnDelete</code>.</p><p><code>RollingUpdate</code> update strategy is the default for StatefulSets.</p><h3 id=rolling-update>Rolling Update</h3><p>The <code>RollingUpdate</code> update strategy will update all Pods in a StatefulSet, in
reverse ordinal order, while respecting the StatefulSet guarantees.</p><p>Patch the <code>web</code> StatefulSet to apply the <code>RollingUpdate</code> update strategy:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl patch statefulset web -p <span style=color:#b44>&#39;{&#34;spec&#34;:{&#34;updateStrategy&#34;:{&#34;type&#34;:&#34;RollingUpdate&#34;}}}&#39;</span>
</span></span></code></pre></div><pre tabindex=0><code>statefulset.apps/web patched
</code></pre><p>In one terminal window, patch the <code>web</code> StatefulSet to change the container
image again:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl patch statefulset web --type<span style=color:#666>=</span><span style=color:#b44>&#39;json&#39;</span> -p<span style=color:#666>=</span><span style=color:#b44>&#39;[{&#34;op&#34;: &#34;replace&#34;, &#34;path&#34;: &#34;/spec/template/spec/containers/0/image&#34;, &#34;value&#34;:&#34;gcr.io/google_containers/nginx-slim:0.8&#34;}]&#39;</span>
</span></span></code></pre></div><pre tabindex=0><code>statefulset.apps/web patched
</code></pre><p>In another terminal, watch the Pods in the StatefulSet:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get pod -l <span style=color:#b8860b>app</span><span style=color:#666>=</span>nginx -w
</span></span></code></pre></div><p>The output is similar to:</p><pre tabindex=0><code>NAME      READY     STATUS    RESTARTS   AGE
web-0     1/1       Running   0          7m
web-1     1/1       Running   0          7m
web-2     1/1       Running   0          8m
web-2     1/1       Terminating   0         8m
web-2     1/1       Terminating   0         8m
web-2     0/1       Terminating   0         8m
web-2     0/1       Terminating   0         8m
web-2     0/1       Terminating   0         8m
web-2     0/1       Terminating   0         8m
web-2     0/1       Pending   0         0s
web-2     0/1       Pending   0         0s
web-2     0/1       ContainerCreating   0         0s
web-2     1/1       Running   0         19s
web-1     1/1       Terminating   0         8m
web-1     0/1       Terminating   0         8m
web-1     0/1       Terminating   0         8m
web-1     0/1       Terminating   0         8m
web-1     0/1       Pending   0         0s
web-1     0/1       Pending   0         0s
web-1     0/1       ContainerCreating   0         0s
web-1     1/1       Running   0         6s
web-0     1/1       Terminating   0         7m
web-0     1/1       Terminating   0         7m
web-0     0/1       Terminating   0         7m
web-0     0/1       Terminating   0         7m
web-0     0/1       Terminating   0         7m
web-0     0/1       Terminating   0         7m
web-0     0/1       Pending   0         0s
web-0     0/1       Pending   0         0s
web-0     0/1       ContainerCreating   0         0s
web-0     1/1       Running   0         10s
</code></pre><p>The Pods in the StatefulSet are updated in reverse ordinal order. The
StatefulSet controller terminates each Pod, and waits for it to transition to Running and
Ready prior to updating the next Pod. Note that, even though the StatefulSet
controller will not proceed to update the next Pod until its ordinal successor
is Running and Ready, it will restore any Pod that fails during the update to
its current version.</p><p>Pods that have already received the update will be restored to the updated version,
and Pods that have not yet received the update will be restored to the previous
version. In this way, the controller attempts to continue to keep the application
healthy and the update consistent in the presence of intermittent failures.</p><p>Get the Pods to view their container images:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span><span style=color:#a2f;font-weight:700>for</span> p in <span style=color:#666>0</span> <span style=color:#666>1</span> 2; <span style=color:#a2f;font-weight:700>do</span> kubectl get pod <span style=color:#b44>&#34;web-</span><span style=color:#b8860b>$p</span><span style=color:#b44>&#34;</span> --template <span style=color:#b44>&#39;{{range $i, $c := .spec.containers}}{{$c.image}}{{end}}&#39;</span>; echo; <span style=color:#a2f;font-weight:700>done</span>
</span></span></code></pre></div><pre tabindex=0><code>registry.k8s.io/nginx-slim:0.8
registry.k8s.io/nginx-slim:0.8
registry.k8s.io/nginx-slim:0.8
</code></pre><p>All the Pods in the StatefulSet are now running the previous container image.</p><div class="alert alert-info note callout" role=alert><strong>Note:</strong> You can also use <code>kubectl rollout status sts/&lt;name></code> to view
the status of a rolling update to a StatefulSet</div><h4 id=staging-an-update>Staging an Update</h4><p>You can stage an update to a StatefulSet by using the <code>partition</code> parameter of
the <code>RollingUpdate</code> update strategy. A staged update will keep all of the Pods
in the StatefulSet at the current version while allowing mutations to the
StatefulSet's <code>.spec.template</code>.</p><p>Patch the <code>web</code> StatefulSet to add a partition to the <code>updateStrategy</code> field:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl patch statefulset web -p <span style=color:#b44>&#39;{&#34;spec&#34;:{&#34;updateStrategy&#34;:{&#34;type&#34;:&#34;RollingUpdate&#34;,&#34;rollingUpdate&#34;:{&#34;partition&#34;:3}}}}&#39;</span>
</span></span></code></pre></div><pre tabindex=0><code>statefulset.apps/web patched
</code></pre><p>Patch the StatefulSet again to change the container's image:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl patch statefulset web --type<span style=color:#666>=</span><span style=color:#b44>&#39;json&#39;</span> -p<span style=color:#666>=</span><span style=color:#b44>&#39;[{&#34;op&#34;: &#34;replace&#34;, &#34;path&#34;: &#34;/spec/template/spec/containers/0/image&#34;, &#34;value&#34;:&#34;registry.k8s.io/nginx-slim:0.7&#34;}]&#39;</span>
</span></span></code></pre></div><pre tabindex=0><code>statefulset.apps/web patched
</code></pre><p>Delete a Pod in the StatefulSet:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl delete pod web-2
</span></span></code></pre></div><pre tabindex=0><code>pod &#34;web-2&#34; deleted
</code></pre><p>Wait for the Pod to be Running and Ready.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get pod -l <span style=color:#b8860b>app</span><span style=color:#666>=</span>nginx -w
</span></span></code></pre></div><pre tabindex=0><code>NAME      READY     STATUS              RESTARTS   AGE
web-0     1/1       Running             0          4m
web-1     1/1       Running             0          4m
web-2     0/1       ContainerCreating   0          11s
web-2     1/1       Running   0         18s
</code></pre><p>Get the Pod's container image:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get pod web-2 --template <span style=color:#b44>&#39;{{range $i, $c := .spec.containers}}{{$c.image}}{{end}}&#39;</span>
</span></span></code></pre></div><pre tabindex=0><code>registry.k8s.io/nginx-slim:0.8
</code></pre><p>Notice that, even though the update strategy is <code>RollingUpdate</code> the StatefulSet
restored the Pod with its original container. This is because the
ordinal of the Pod is less than the <code>partition</code> specified by the
<code>updateStrategy</code>.</p><h4 id=rolling-out-a-canary>Rolling Out a Canary</h4><p>You can roll out a canary to test a modification by decrementing the <code>partition</code>
you specified <a href=#staging-an-update>above</a>.</p><p>Patch the StatefulSet to decrement the partition:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl patch statefulset web -p <span style=color:#b44>&#39;{&#34;spec&#34;:{&#34;updateStrategy&#34;:{&#34;type&#34;:&#34;RollingUpdate&#34;,&#34;rollingUpdate&#34;:{&#34;partition&#34;:2}}}}&#39;</span>
</span></span></code></pre></div><pre tabindex=0><code>statefulset.apps/web patched
</code></pre><p>Wait for <code>web-2</code> to be Running and Ready.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get pod -l <span style=color:#b8860b>app</span><span style=color:#666>=</span>nginx -w
</span></span></code></pre></div><pre tabindex=0><code>NAME      READY     STATUS              RESTARTS   AGE
web-0     1/1       Running             0          4m
web-1     1/1       Running             0          4m
web-2     0/1       ContainerCreating   0          11s
web-2     1/1       Running   0         18s
</code></pre><p>Get the Pod's container:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get pod web-2 --template <span style=color:#b44>&#39;{{range $i, $c := .spec.containers}}{{$c.image}}{{end}}&#39;</span>
</span></span></code></pre></div><pre tabindex=0><code>registry.k8s.io/nginx-slim:0.7
</code></pre><p>When you changed the <code>partition</code>, the StatefulSet controller automatically
updated the <code>web-2</code> Pod because the Pod's ordinal was greater than or equal to
the <code>partition</code>.</p><p>Delete the <code>web-1</code> Pod:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl delete pod web-1
</span></span></code></pre></div><pre tabindex=0><code>pod &#34;web-1&#34; deleted
</code></pre><p>Wait for the <code>web-1</code> Pod to be Running and Ready.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get pod -l <span style=color:#b8860b>app</span><span style=color:#666>=</span>nginx -w
</span></span></code></pre></div><p>The output is similar to:</p><pre tabindex=0><code>NAME      READY     STATUS        RESTARTS   AGE
web-0     1/1       Running       0          6m
web-1     0/1       Terminating   0          6m
web-2     1/1       Running       0          2m
web-1     0/1       Terminating   0         6m
web-1     0/1       Terminating   0         6m
web-1     0/1       Terminating   0         6m
web-1     0/1       Pending   0         0s
web-1     0/1       Pending   0         0s
web-1     0/1       ContainerCreating   0         0s
web-1     1/1       Running   0         18s
</code></pre><p>Get the <code>web-1</code> Pod's container image:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get pod web-1 --template <span style=color:#b44>&#39;{{range $i, $c := .spec.containers}}{{$c.image}}{{end}}&#39;</span>
</span></span></code></pre></div><pre tabindex=0><code>registry.k8s.io/nginx-slim:0.8
</code></pre><p><code>web-1</code> was restored to its original configuration because the Pod's ordinal
was less than the partition. When a partition is specified, all Pods with an
ordinal that is greater than or equal to the partition will be updated when the
StatefulSet's <code>.spec.template</code> is updated. If a Pod that has an ordinal less
than the partition is deleted or otherwise terminated, it will be restored to
its original configuration.</p><h4 id=phased-roll-outs>Phased Roll Outs</h4><p>You can perform a phased roll out (e.g. a linear, geometric, or exponential
roll out) using a partitioned rolling update in a similar manner to how you
rolled out a <a href=#rolling-out-a-canary>canary</a>. To perform a phased roll out, set
the <code>partition</code> to the ordinal at which you want the controller to pause the
update.</p><p>The partition is currently set to <code>2</code>. Set the partition to <code>0</code>:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl patch statefulset web -p <span style=color:#b44>&#39;{&#34;spec&#34;:{&#34;updateStrategy&#34;:{&#34;type&#34;:&#34;RollingUpdate&#34;,&#34;rollingUpdate&#34;:{&#34;partition&#34;:0}}}}&#39;</span>
</span></span></code></pre></div><pre tabindex=0><code>statefulset.apps/web patched
</code></pre><p>Wait for all of the Pods in the StatefulSet to become Running and Ready.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get pod -l <span style=color:#b8860b>app</span><span style=color:#666>=</span>nginx -w
</span></span></code></pre></div><p>The output is similar to:</p><pre tabindex=0><code>NAME      READY     STATUS              RESTARTS   AGE
web-0     1/1       Running             0          3m
web-1     0/1       ContainerCreating   0          11s
web-2     1/1       Running             0          2m
web-1     1/1       Running   0         18s
web-0     1/1       Terminating   0         3m
web-0     1/1       Terminating   0         3m
web-0     0/1       Terminating   0         3m
web-0     0/1       Terminating   0         3m
web-0     0/1       Terminating   0         3m
web-0     0/1       Terminating   0         3m
web-0     0/1       Pending   0         0s
web-0     0/1       Pending   0         0s
web-0     0/1       ContainerCreating   0         0s
web-0     1/1       Running   0         3s
</code></pre><p>Get the container image details for the Pods in the StatefulSet:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span><span style=color:#a2f;font-weight:700>for</span> p in <span style=color:#666>0</span> <span style=color:#666>1</span> 2; <span style=color:#a2f;font-weight:700>do</span> kubectl get pod <span style=color:#b44>&#34;web-</span><span style=color:#b8860b>$p</span><span style=color:#b44>&#34;</span> --template <span style=color:#b44>&#39;{{range $i, $c := .spec.containers}}{{$c.image}}{{end}}&#39;</span>; echo; <span style=color:#a2f;font-weight:700>done</span>
</span></span></code></pre></div><pre tabindex=0><code>registry.k8s.io/nginx-slim:0.7
registry.k8s.io/nginx-slim:0.7
registry.k8s.io/nginx-slim:0.7
</code></pre><p>By moving the <code>partition</code> to <code>0</code>, you allowed the StatefulSet to
continue the update process.</p><h3 id=on-delete>On Delete</h3><p>The <code>OnDelete</code> update strategy implements the legacy (1.6 and prior) behavior,
When you select this update strategy, the StatefulSet controller will not
automatically update Pods when a modification is made to the StatefulSet's
<code>.spec.template</code> field. This strategy can be selected by setting the
<code>.spec.template.updateStrategy.type</code> to <code>OnDelete</code>.</p><h2 id=deleting-statefulsets>Deleting StatefulSets</h2><p>StatefulSet supports both Non-Cascading and Cascading deletion. In a
Non-Cascading Delete, the StatefulSet's Pods are not deleted when the StatefulSet is deleted. In a Cascading Delete, both the StatefulSet and its Pods are
deleted.</p><h3 id=non-cascading-delete>Non-Cascading Delete</h3><p>In one terminal window, watch the Pods in the StatefulSet.</p><pre tabindex=0><code>kubectl get pods -w -l app=nginx
</code></pre><p>Use <a href=/docs/reference/generated/kubectl/kubectl-commands/#delete><code>kubectl delete</code></a> to delete the
StatefulSet. Make sure to supply the <code>--cascade=orphan</code> parameter to the
command. This parameter tells Kubernetes to only delete the StatefulSet, and to
not delete any of its Pods.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl delete statefulset web --cascade<span style=color:#666>=</span>orphan
</span></span></code></pre></div><pre tabindex=0><code>statefulset.apps &#34;web&#34; deleted
</code></pre><p>Get the Pods, to examine their status:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get pods -l <span style=color:#b8860b>app</span><span style=color:#666>=</span>nginx
</span></span></code></pre></div><pre tabindex=0><code>NAME      READY     STATUS    RESTARTS   AGE
web-0     1/1       Running   0          6m
web-1     1/1       Running   0          7m
web-2     1/1       Running   0          5m
</code></pre><p>Even though <code>web</code> has been deleted, all of the Pods are still Running and Ready.
Delete <code>web-0</code>:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl delete pod web-0
</span></span></code></pre></div><pre tabindex=0><code>pod &#34;web-0&#34; deleted
</code></pre><p>Get the StatefulSet's Pods:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get pods -l <span style=color:#b8860b>app</span><span style=color:#666>=</span>nginx
</span></span></code></pre></div><pre tabindex=0><code>NAME      READY     STATUS    RESTARTS   AGE
web-1     1/1       Running   0          10m
web-2     1/1       Running   0          7m
</code></pre><p>As the <code>web</code> StatefulSet has been deleted, <code>web-0</code> has not been relaunched.</p><p>In one terminal, watch the StatefulSet's Pods.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get pods -w -l <span style=color:#b8860b>app</span><span style=color:#666>=</span>nginx
</span></span></code></pre></div><p>In a second terminal, recreate the StatefulSet. Note that, unless
you deleted the <code>nginx</code> Service (which you should not have), you will see
an error indicating that the Service already exists.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl apply -f web.yaml
</span></span></code></pre></div><pre tabindex=0><code>statefulset.apps/web created
service/nginx unchanged
</code></pre><p>Ignore the error. It only indicates that an attempt was made to create the <em>nginx</em>
headless Service even though that Service already exists.</p><p>Examine the output of the <code>kubectl get</code> command running in the first terminal.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get pods -w -l <span style=color:#b8860b>app</span><span style=color:#666>=</span>nginx
</span></span></code></pre></div><pre tabindex=0><code>NAME      READY     STATUS    RESTARTS   AGE
web-1     1/1       Running   0          16m
web-2     1/1       Running   0          2m
NAME      READY     STATUS    RESTARTS   AGE
web-0     0/1       Pending   0          0s
web-0     0/1       Pending   0         0s
web-0     0/1       ContainerCreating   0         0s
web-0     1/1       Running   0         18s
web-2     1/1       Terminating   0         3m
web-2     0/1       Terminating   0         3m
web-2     0/1       Terminating   0         3m
web-2     0/1       Terminating   0         3m
</code></pre><p>When the <code>web</code> StatefulSet was recreated, it first relaunched <code>web-0</code>.
Since <code>web-1</code> was already Running and Ready, when <code>web-0</code> transitioned to
Running and Ready, it adopted this Pod. Since you recreated the StatefulSet
with <code>replicas</code> equal to 2, once <code>web-0</code> had been recreated, and once
<code>web-1</code> had been determined to already be Running and Ready, <code>web-2</code> was
terminated.</p><p>Let's take another look at the contents of the <code>index.html</code> file served by the
Pods' webservers:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span><span style=color:#a2f;font-weight:700>for</span> i in <span style=color:#666>0</span> 1; <span style=color:#a2f;font-weight:700>do</span> kubectl <span style=color:#a2f>exec</span> -i -t <span style=color:#b44>&#34;web-</span><span style=color:#b8860b>$i</span><span style=color:#b44>&#34;</span> -- curl http://localhost/; <span style=color:#a2f;font-weight:700>done</span>
</span></span></code></pre></div><pre tabindex=0><code>web-0
web-1
</code></pre><p>Even though you deleted both the StatefulSet and the <code>web-0</code> Pod, it still
serves the hostname originally entered into its <code>index.html</code> file. This is
because the StatefulSet never deletes the PersistentVolumes associated with a
Pod. When you recreated the StatefulSet and it relaunched <code>web-0</code>, its original
PersistentVolume was remounted.</p><h3 id=cascading-delete>Cascading Delete</h3><p>In one terminal window, watch the Pods in the StatefulSet.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get pods -w -l <span style=color:#b8860b>app</span><span style=color:#666>=</span>nginx
</span></span></code></pre></div><p>In another terminal, delete the StatefulSet again. This time, omit the
<code>--cascade=orphan</code> parameter.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl delete statefulset web
</span></span></code></pre></div><pre tabindex=0><code>statefulset.apps &#34;web&#34; deleted
</code></pre><p>Examine the output of the <code>kubectl get</code> command running in the first terminal,
and wait for all of the Pods to transition to Terminating.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get pods -w -l <span style=color:#b8860b>app</span><span style=color:#666>=</span>nginx
</span></span></code></pre></div><pre tabindex=0><code>NAME      READY     STATUS    RESTARTS   AGE
web-0     1/1       Running   0          11m
web-1     1/1       Running   0          27m
NAME      READY     STATUS        RESTARTS   AGE
web-0     1/1       Terminating   0          12m
web-1     1/1       Terminating   0         29m
web-0     0/1       Terminating   0         12m
web-0     0/1       Terminating   0         12m
web-0     0/1       Terminating   0         12m
web-1     0/1       Terminating   0         29m
web-1     0/1       Terminating   0         29m
web-1     0/1       Terminating   0         29m
</code></pre><p>As you saw in the <a href=#scaling-down>Scaling Down</a> section, the Pods
are terminated one at a time, with respect to the reverse order of their ordinal
indices. Before terminating a Pod, the StatefulSet controller waits for
the Pod's successor to be completely terminated.</p><div class="alert alert-info note callout" role=alert><strong>Note:</strong> Although a cascading delete removes a StatefulSet together with its Pods,
the cascade does not delete the headless Service associated with the StatefulSet.
You must delete the <code>nginx</code> Service manually.</div><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl delete service nginx
</span></span></code></pre></div><pre tabindex=0><code>service &#34;nginx&#34; deleted
</code></pre><p>Recreate the StatefulSet and headless Service one more time:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl apply -f web.yaml
</span></span></code></pre></div><pre tabindex=0><code>service/nginx created
statefulset.apps/web created
</code></pre><p>When all of the StatefulSet's Pods transition to Running and Ready, retrieve
the contents of their <code>index.html</code> files:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span><span style=color:#a2f;font-weight:700>for</span> i in <span style=color:#666>0</span> 1; <span style=color:#a2f;font-weight:700>do</span> kubectl <span style=color:#a2f>exec</span> -i -t <span style=color:#b44>&#34;web-</span><span style=color:#b8860b>$i</span><span style=color:#b44>&#34;</span> -- curl http://localhost/; <span style=color:#a2f;font-weight:700>done</span>
</span></span></code></pre></div><pre tabindex=0><code>web-0
web-1
</code></pre><p>Even though you completely deleted the StatefulSet, and all of its Pods, the
Pods are recreated with their PersistentVolumes mounted, and <code>web-0</code> and
<code>web-1</code> continue to serve their hostnames.</p><p>Finally, delete the <code>nginx</code> Service...</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl delete service nginx
</span></span></code></pre></div><pre tabindex=0><code>service &#34;nginx&#34; deleted
</code></pre><p>...and the <code>web</code> StatefulSet:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl delete statefulset web
</span></span></code></pre></div><pre tabindex=0><code>statefulset &#34;web&#34; deleted
</code></pre><h2 id=pod-management-policy>Pod Management Policy</h2><p>For some distributed systems, the StatefulSet ordering guarantees are
unnecessary and/or undesirable. These systems require only uniqueness and
identity. To address this, in Kubernetes 1.7, we introduced
<code>.spec.podManagementPolicy</code> to the StatefulSet API Object.</p><h3 id=orderedready-pod-management>OrderedReady Pod Management</h3><p><code>OrderedReady</code> pod management is the default for StatefulSets. It tells the
StatefulSet controller to respect the ordering guarantees demonstrated
above.</p><h3 id=parallel-pod-management>Parallel Pod Management</h3><p><code>Parallel</code> pod management tells the StatefulSet controller to launch or
terminate all Pods in parallel, and not to wait for Pods to become Running
and Ready or completely terminated prior to launching or terminating another
Pod. This option only affects the behavior for scaling operations. Updates are not affected.</p><div class=highlight><div class=copy-code-icon style=text-align:right><a href=https://raw.githubusercontent.com/kubernetes/website/main/content/en/examples/application/web/web-parallel.yaml download=application/web/web-parallel.yaml><code>application/web/web-parallel.yaml</code></a>
<img src=/images/copycode.svg style=max-height:24px;cursor:pointer onclick='copyCode("application-web-web-parallel-yaml")' title="Copy application/web/web-parallel.yaml to clipboard"></img></div><div class=includecode id=application-web-web-parallel-yaml><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Service<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>nginx<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>labels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>app</span>:<span style=color:#bbb> </span>nginx<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>ports</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>port</span>:<span style=color:#bbb> </span><span style=color:#666>80</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>web<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>clusterIP</span>:<span style=color:#bbb> </span>None<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>selector</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>app</span>:<span style=color:#bbb> </span>nginx<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:#00f;font-weight:700>---</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>apps/v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>StatefulSet<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>web<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>serviceName</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;nginx&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>podManagementPolicy</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;Parallel&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>replicas</span>:<span style=color:#bbb> </span><span style=color:#666>2</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>selector</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>matchLabels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>app</span>:<span style=color:#bbb> </span>nginx<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>template</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>labels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>app</span>:<span style=color:#bbb> </span>nginx<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>nginx<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>registry.k8s.io/nginx-slim:0.8<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>ports</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span>- <span style=color:green;font-weight:700>containerPort</span>:<span style=color:#bbb> </span><span style=color:#666>80</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>web<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>volumeMounts</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>www<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>mountPath</span>:<span style=color:#bbb> </span>/usr/share/nginx/html<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>volumeClaimTemplates</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>www<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>accessModes</span>:<span style=color:#bbb> </span>[<span style=color:#bbb> </span><span style=color:#b44>&#34;ReadWriteOnce&#34;</span><span style=color:#bbb> </span>]<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>resources</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>requests</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>storage</span>:<span style=color:#bbb> </span>1Gi<span style=color:#bbb>
</span></span></span></code></pre></div></div></div><p>Download the example above, and save it to a file named <code>web-parallel.yaml</code></p><p>This manifest is identical to the one you downloaded above except that the <code>.spec.podManagementPolicy</code>
of the <code>web</code> StatefulSet is set to <code>Parallel</code>.</p><p>In one terminal, watch the Pods in the StatefulSet.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get pod -l <span style=color:#b8860b>app</span><span style=color:#666>=</span>nginx -w
</span></span></code></pre></div><p>In another terminal, create the StatefulSet and Service in the manifest:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl apply -f web-parallel.yaml
</span></span></code></pre></div><pre tabindex=0><code>service/nginx created
statefulset.apps/web created
</code></pre><p>Examine the output of the <code>kubectl get</code> command that you executed in the first terminal.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get pod -l <span style=color:#b8860b>app</span><span style=color:#666>=</span>nginx -w
</span></span></code></pre></div><pre tabindex=0><code>NAME      READY     STATUS    RESTARTS   AGE
web-0     0/1       Pending   0          0s
web-0     0/1       Pending   0         0s
web-1     0/1       Pending   0         0s
web-1     0/1       Pending   0         0s
web-0     0/1       ContainerCreating   0         0s
web-1     0/1       ContainerCreating   0         0s
web-0     1/1       Running   0         10s
web-1     1/1       Running   0         10s
</code></pre><p>The StatefulSet controller launched both <code>web-0</code> and <code>web-1</code> at the same time.</p><p>Keep the second terminal open, and, in another terminal window scale the
StatefulSet:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl scale statefulset/web --replicas<span style=color:#666>=</span><span style=color:#666>4</span>
</span></span></code></pre></div><pre tabindex=0><code>statefulset.apps/web scaled
</code></pre><p>Examine the output of the terminal where the <code>kubectl get</code> command is running.</p><pre tabindex=0><code>web-3     0/1       Pending   0         0s
web-3     0/1       Pending   0         0s
web-3     0/1       Pending   0         7s
web-3     0/1       ContainerCreating   0         7s
web-2     1/1       Running   0         10s
web-3     1/1       Running   0         26s
</code></pre><p>The StatefulSet launched two new Pods, and it did not wait for
the first to become Running and Ready prior to launching the second.</p><h2 id=cleaning-up>Cleaning up</h2><p>You should have two terminals open, ready for you to run <code>kubectl</code> commands as
part of cleanup.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl delete sts web
</span></span><span style=display:flex><span><span style=color:#080;font-style:italic># sts is an abbreviation for statefulset</span>
</span></span></code></pre></div><p>You can watch <code>kubectl get</code> to see those Pods being deleted.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get pod -l <span style=color:#b8860b>app</span><span style=color:#666>=</span>nginx -w
</span></span></code></pre></div><pre tabindex=0><code>web-3     1/1       Terminating   0         9m
web-2     1/1       Terminating   0         9m
web-3     1/1       Terminating   0         9m
web-2     1/1       Terminating   0         9m
web-1     1/1       Terminating   0         44m
web-0     1/1       Terminating   0         44m
web-0     0/1       Terminating   0         44m
web-3     0/1       Terminating   0         9m
web-2     0/1       Terminating   0         9m
web-1     0/1       Terminating   0         44m
web-0     0/1       Terminating   0         44m
web-2     0/1       Terminating   0         9m
web-2     0/1       Terminating   0         9m
web-2     0/1       Terminating   0         9m
web-1     0/1       Terminating   0         44m
web-1     0/1       Terminating   0         44m
web-1     0/1       Terminating   0         44m
web-0     0/1       Terminating   0         44m
web-0     0/1       Terminating   0         44m
web-0     0/1       Terminating   0         44m
web-3     0/1       Terminating   0         9m
web-3     0/1       Terminating   0         9m
web-3     0/1       Terminating   0         9m
</code></pre><p>During deletion, a StatefulSet removes all Pods concurrently; it does not wait for
a Pod's ordinal successor to terminate prior to deleting that Pod.</p><p>Close the terminal where the <code>kubectl get</code> command is running and delete the <code>nginx</code>
Service:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl delete svc nginx
</span></span></code></pre></div><p>Delete the persistent storage media for the PersistentVolumes used in this tutorial.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get pvc
</span></span></code></pre></div><pre tabindex=0><code>NAME        STATUS   VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS   AGE
www-web-0   Bound    pvc-2bf00408-d366-4a12-bad0-1869c65d0bee   1Gi        RWO            standard       25m
www-web-1   Bound    pvc-ba3bfe9c-413e-4b95-a2c0-3ea8a54dbab4   1Gi        RWO            standard       24m
www-web-2   Bound    pvc-cba6cfa6-3a47-486b-a138-db5930207eaf   1Gi        RWO            standard       15m
www-web-3   Bound    pvc-0c04d7f0-787a-4977-8da3-d9d3a6d8d752   1Gi        RWO            standard       15m
www-web-4   Bound    pvc-b2c73489-e70b-4a4e-9ec1-9eab439aa43e   1Gi        RWO            standard       14m
</code></pre><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get pv
</span></span></code></pre></div><pre tabindex=0><code>NAME                                       CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS   CLAIM               STORAGECLASS   REASON   AGE
pvc-0c04d7f0-787a-4977-8da3-d9d3a6d8d752   1Gi        RWO            Delete           Bound    default/www-web-3   standard                15m
pvc-2bf00408-d366-4a12-bad0-1869c65d0bee   1Gi        RWO            Delete           Bound    default/www-web-0   standard                25m
pvc-b2c73489-e70b-4a4e-9ec1-9eab439aa43e   1Gi        RWO            Delete           Bound    default/www-web-4   standard                14m
pvc-ba3bfe9c-413e-4b95-a2c0-3ea8a54dbab4   1Gi        RWO            Delete           Bound    default/www-web-1   standard                24m
pvc-cba6cfa6-3a47-486b-a138-db5930207eaf   1Gi        RWO            Delete           Bound    default/www-web-2   standard                15m
</code></pre><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl delete pvc www-web-0 www-web-1 www-web-2 www-web-3 www-web-4
</span></span></code></pre></div><pre tabindex=0><code>persistentvolumeclaim &#34;www-web-0&#34; deleted
persistentvolumeclaim &#34;www-web-1&#34; deleted
persistentvolumeclaim &#34;www-web-2&#34; deleted
persistentvolumeclaim &#34;www-web-3&#34; deleted
persistentvolumeclaim &#34;www-web-4&#34; deleted
</code></pre><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get pvc
</span></span></code></pre></div><pre tabindex=0><code>No resources found in default namespace.
</code></pre><div class="alert alert-info note callout" role=alert><strong>Note:</strong> You also need to delete the persistent storage media for the PersistentVolumes
used in this tutorial.
Follow the necessary steps, based on your environment, storage configuration,
and provisioning method, to ensure that all storage is reclaimed.</div></div><div class=td-content style=page-break-before:always><h1 id=pg-27580b3f65f3c2da07fc0f83be69da75>6.2 - Example: Deploying WordPress and MySQL with Persistent Volumes</h1><p>This tutorial shows you how to deploy a WordPress site and a MySQL database using Minikube. Both applications use PersistentVolumes and PersistentVolumeClaims to store data.</p><p>A <a href=/docs/concepts/storage/persistent-volumes/>PersistentVolume</a> (PV) is a piece of storage in the cluster that has been manually provisioned by an administrator, or dynamically provisioned by Kubernetes using a <a href=/docs/concepts/storage/storage-classes>StorageClass</a>. A <a href=/docs/concepts/storage/persistent-volumes/#persistentvolumeclaims>PersistentVolumeClaim</a> (PVC) is a request for storage by a user that can be fulfilled by a PV. PersistentVolumes and PersistentVolumeClaims are independent from Pod lifecycles and preserve data through restarting, rescheduling, and even deleting Pods.</p><div class="alert alert-danger warning callout" role=alert><strong>Warning:</strong> This deployment is not suitable for production use cases, as it uses single instance WordPress and MySQL Pods. Consider using <a href=https://github.com/bitnami/charts/tree/master/bitnami/wordpress>WordPress Helm Chart</a> to deploy WordPress in production.</div><div class="alert alert-info note callout" role=alert><strong>Note:</strong> The files provided in this tutorial are using GA Deployment APIs and are specific to kubernetes version 1.9 and later. If you wish to use this tutorial with an earlier version of Kubernetes, please update the API version appropriately, or reference earlier versions of this tutorial.</div><h2 id=objectives>Objectives</h2><ul><li>Create PersistentVolumeClaims and PersistentVolumes</li><li>Create a <code>kustomization.yaml</code> with<ul><li>a Secret generator</li><li>MySQL resource configs</li><li>WordPress resource configs</li></ul></li><li>Apply the kustomization directory by <code>kubectl apply -k ./</code></li><li>Clean up</li></ul><h2 id=before-you-begin>Before you begin</h2><p><p>You need to have a Kubernetes cluster, and the kubectl command-line tool must
be configured to communicate with your cluster. It is recommended to run this tutorial on a cluster with at least two nodes that are not acting as control plane hosts. If you do not already have a
cluster, you can create one by using
<a href=https://minikube.sigs.k8s.io/docs/tutorials/multi_node/>minikube</a>
or you can use one of these Kubernetes playgrounds:</p><ul><li><a href=https://killercoda.com/playgrounds/scenario/kubernetes>Killercoda</a></li><li><a href=http://labs.play-with-k8s.com/>Play with Kubernetes</a></li></ul>To check the version, enter <code>kubectl version</code>.
The example shown on this page works with <code>kubectl</code> 1.14 and above.</p><p>Download the following configuration files:</p><ol><li><p><a href=/examples/application/wordpress/mysql-deployment.yaml>mysql-deployment.yaml</a></p></li><li><p><a href=/examples/application/wordpress/wordpress-deployment.yaml>wordpress-deployment.yaml</a></p></li></ol><h2 id=create-persistentvolumeclaims-and-persistentvolumes>Create PersistentVolumeClaims and PersistentVolumes</h2><p>MySQL and Wordpress each require a PersistentVolume to store data. Their PersistentVolumeClaims will be created at the deployment step.</p><p>Many cluster environments have a default StorageClass installed. When a StorageClass is not specified in the PersistentVolumeClaim, the cluster's default StorageClass is used instead.</p><p>When a PersistentVolumeClaim is created, a PersistentVolume is dynamically provisioned based on the StorageClass configuration.</p><div class="alert alert-danger warning callout" role=alert><strong>Warning:</strong> In local clusters, the default StorageClass uses the <code>hostPath</code> provisioner. <code>hostPath</code> volumes are only suitable for development and testing. With <code>hostPath</code> volumes, your data lives in <code>/tmp</code> on the node the Pod is scheduled onto and does not move between nodes. If a Pod dies and gets scheduled to another node in the cluster, or the node is rebooted, the data is lost.</div><div class="alert alert-info note callout" role=alert><strong>Note:</strong> If you are bringing up a cluster that needs to use the <code>hostPath</code> provisioner, the <code>--enable-hostpath-provisioner</code> flag must be set in the <code>controller-manager</code> component.</div><div class="alert alert-info note callout" role=alert><strong>Note:</strong> If you have a Kubernetes cluster running on Google Kubernetes Engine, please follow <a href=https://cloud.google.com/kubernetes-engine/docs/tutorials/persistent-disk>this guide</a>.</div><h2 id=create-a-kustomization-yaml>Create a kustomization.yaml</h2><h3 id=add-a-secret-generator>Add a Secret generator</h3><p>A <a href=/docs/concepts/configuration/secret/>Secret</a> is an object that stores a piece of sensitive data like a password or key. Since 1.14, <code>kubectl</code> supports the management of Kubernetes objects using a kustomization file. You can create a Secret by generators in <code>kustomization.yaml</code>.</p><p>Add a Secret generator in <code>kustomization.yaml</code> from the following command. You will need to replace <code>YOUR_PASSWORD</code> with the password you want to use.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>cat <span style=color:#b44>&lt;&lt;EOF &gt;./kustomization.yaml
</span></span></span><span style=display:flex><span><span style=color:#b44>secretGenerator:
</span></span></span><span style=display:flex><span><span style=color:#b44>- name: mysql-pass
</span></span></span><span style=display:flex><span><span style=color:#b44>  literals:
</span></span></span><span style=display:flex><span><span style=color:#b44>  - password=YOUR_PASSWORD
</span></span></span><span style=display:flex><span><span style=color:#b44>EOF</span>
</span></span></code></pre></div><h2 id=add-resource-configs-for-mysql-and-wordpress>Add resource configs for MySQL and WordPress</h2><p>The following manifest describes a single-instance MySQL Deployment. The MySQL container mounts the PersistentVolume at /var/lib/mysql. The <code>MYSQL_ROOT_PASSWORD</code> environment variable sets the database password from the Secret.</p><div class=highlight><div class=copy-code-icon style=text-align:right><a href=https://raw.githubusercontent.com/kubernetes/website/main/content/en/examples/application/wordpress/mysql-deployment.yaml download=application/wordpress/mysql-deployment.yaml><code>application/wordpress/mysql-deployment.yaml</code></a>
<img src=/images/copycode.svg style=max-height:24px;cursor:pointer onclick='copyCode("application-wordpress-mysql-deployment-yaml")' title="Copy application/wordpress/mysql-deployment.yaml to clipboard"></img></div><div class=includecode id=application-wordpress-mysql-deployment-yaml><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Service<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>wordpress-mysql<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>labels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>app</span>:<span style=color:#bbb> </span>wordpress<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>ports</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:green;font-weight:700>port</span>:<span style=color:#bbb> </span><span style=color:#666>3306</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>selector</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>app</span>:<span style=color:#bbb> </span>wordpress<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>tier</span>:<span style=color:#bbb> </span>mysql<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>clusterIP</span>:<span style=color:#bbb> </span>None<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:#00f;font-weight:700>---</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>PersistentVolumeClaim<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>mysql-pv-claim<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>labels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>app</span>:<span style=color:#bbb> </span>wordpress<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>accessModes</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- ReadWriteOnce<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>resources</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>requests</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>storage</span>:<span style=color:#bbb> </span>20Gi<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:#00f;font-weight:700>---</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>apps/v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Deployment<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>wordpress-mysql<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>labels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>app</span>:<span style=color:#bbb> </span>wordpress<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>selector</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>matchLabels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>app</span>:<span style=color:#bbb> </span>wordpress<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>tier</span>:<span style=color:#bbb> </span>mysql<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>strategy</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>type</span>:<span style=color:#bbb> </span>Recreate<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>template</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>labels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>app</span>:<span style=color:#bbb> </span>wordpress<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>tier</span>:<span style=color:#bbb> </span>mysql<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- <span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>mysql:5.6<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>mysql<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>env</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>MYSQL_ROOT_PASSWORD<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>valueFrom</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>            </span><span style=color:green;font-weight:700>secretKeyRef</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>              </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>mysql-pass<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>              </span><span style=color:green;font-weight:700>key</span>:<span style=color:#bbb> </span>password<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>ports</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span>- <span style=color:green;font-weight:700>containerPort</span>:<span style=color:#bbb> </span><span style=color:#666>3306</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>mysql<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>volumeMounts</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>mysql-persistent-storage<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>mountPath</span>:<span style=color:#bbb> </span>/var/lib/mysql<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>volumes</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>mysql-persistent-storage<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>persistentVolumeClaim</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>claimName</span>:<span style=color:#bbb> </span>mysql-pv-claim<span style=color:#bbb>
</span></span></span></code></pre></div></div></div><p>The following manifest describes a single-instance WordPress Deployment. The WordPress container mounts the
PersistentVolume at <code>/var/www/html</code> for website data files. The <code>WORDPRESS_DB_HOST</code> environment variable sets
the name of the MySQL Service defined above, and WordPress will access the database by Service. The
<code>WORDPRESS_DB_PASSWORD</code> environment variable sets the database password from the Secret kustomize generated.</p><div class=highlight><div class=copy-code-icon style=text-align:right><a href=https://raw.githubusercontent.com/kubernetes/website/main/content/en/examples/application/wordpress/wordpress-deployment.yaml download=application/wordpress/wordpress-deployment.yaml><code>application/wordpress/wordpress-deployment.yaml</code></a>
<img src=/images/copycode.svg style=max-height:24px;cursor:pointer onclick='copyCode("application-wordpress-wordpress-deployment-yaml")' title="Copy application/wordpress/wordpress-deployment.yaml to clipboard"></img></div><div class=includecode id=application-wordpress-wordpress-deployment-yaml><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Service<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>wordpress<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>labels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>app</span>:<span style=color:#bbb> </span>wordpress<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>ports</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:green;font-weight:700>port</span>:<span style=color:#bbb> </span><span style=color:#666>80</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>selector</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>app</span>:<span style=color:#bbb> </span>wordpress<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>tier</span>:<span style=color:#bbb> </span>frontend<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>type</span>:<span style=color:#bbb> </span>LoadBalancer<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:#00f;font-weight:700>---</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>PersistentVolumeClaim<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>wp-pv-claim<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>labels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>app</span>:<span style=color:#bbb> </span>wordpress<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>accessModes</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- ReadWriteOnce<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>resources</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>requests</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>storage</span>:<span style=color:#bbb> </span>20Gi<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:#00f;font-weight:700>---</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>apps/v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Deployment<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>wordpress<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>labels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>app</span>:<span style=color:#bbb> </span>wordpress<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>selector</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>matchLabels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>app</span>:<span style=color:#bbb> </span>wordpress<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>tier</span>:<span style=color:#bbb> </span>frontend<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>strategy</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>type</span>:<span style=color:#bbb> </span>Recreate<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>template</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>labels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>app</span>:<span style=color:#bbb> </span>wordpress<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>tier</span>:<span style=color:#bbb> </span>frontend<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- <span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>wordpress:4.8-apache<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>wordpress<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>env</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>WORDPRESS_DB_HOST<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>value</span>:<span style=color:#bbb> </span>wordpress-mysql<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>WORDPRESS_DB_PASSWORD<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>valueFrom</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>            </span><span style=color:green;font-weight:700>secretKeyRef</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>              </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>mysql-pass<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>              </span><span style=color:green;font-weight:700>key</span>:<span style=color:#bbb> </span>password<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>ports</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span>- <span style=color:green;font-weight:700>containerPort</span>:<span style=color:#bbb> </span><span style=color:#666>80</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>wordpress<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>volumeMounts</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>wordpress-persistent-storage<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>mountPath</span>:<span style=color:#bbb> </span>/var/www/html<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>volumes</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>wordpress-persistent-storage<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>persistentVolumeClaim</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>claimName</span>:<span style=color:#bbb> </span>wp-pv-claim<span style=color:#bbb>
</span></span></span></code></pre></div></div></div><ol><li><p>Download the MySQL deployment configuration file.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>curl -LO https://k8s.io/examples/application/wordpress/mysql-deployment.yaml
</span></span></code></pre></div></li><li><p>Download the WordPress configuration file.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>curl -LO https://k8s.io/examples/application/wordpress/wordpress-deployment.yaml
</span></span></code></pre></div></li><li><p>Add them to <code>kustomization.yaml</code> file.</p></li></ol><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>cat <span style=color:#b44>&lt;&lt;EOF &gt;&gt;./kustomization.yaml
</span></span></span><span style=display:flex><span><span style=color:#b44>resources:
</span></span></span><span style=display:flex><span><span style=color:#b44>  - mysql-deployment.yaml
</span></span></span><span style=display:flex><span><span style=color:#b44>  - wordpress-deployment.yaml
</span></span></span><span style=display:flex><span><span style=color:#b44>EOF</span>
</span></span></code></pre></div><h2 id=apply-and-verify>Apply and Verify</h2><p>The <code>kustomization.yaml</code> contains all the resources for deploying a WordPress site and a
MySQL database. You can apply the directory by</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl apply -k ./
</span></span></code></pre></div><p>Now you can verify that all objects exist.</p><ol><li><p>Verify that the Secret exists by running the following command:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get secrets
</span></span></code></pre></div><p>The response should be like this:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>NAME                    TYPE                                  DATA   AGE
</span></span><span style=display:flex><span>mysql-pass-c57bb4t7mf   Opaque                                <span style=color:#666>1</span>      9s
</span></span></code></pre></div></li><li><p>Verify that a PersistentVolume got dynamically provisioned.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get pvc
</span></span></code></pre></div><div class="alert alert-info note callout" role=alert><strong>Note:</strong> It can take up to a few minutes for the PVs to be provisioned and bound.</div><p>The response should be like this:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>NAME             STATUS    VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS       AGE
</span></span><span style=display:flex><span>mysql-pv-claim   Bound     pvc-8cbd7b2e-4044-11e9-b2bb-42010a800002   20Gi       RWO            standard           77s
</span></span><span style=display:flex><span>wp-pv-claim      Bound     pvc-8cd0df54-4044-11e9-b2bb-42010a800002   20Gi       RWO            standard           77s
</span></span></code></pre></div></li><li><p>Verify that the Pod is running by running the following command:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get pods
</span></span></code></pre></div><div class="alert alert-info note callout" role=alert><strong>Note:</strong> It can take up to a few minutes for the Pod's Status to be <code>RUNNING</code>.</div><p>The response should be like this:</p><pre tabindex=0><code>NAME                               READY     STATUS    RESTARTS   AGE
wordpress-mysql-1894417608-x5dzt   1/1       Running   0          40s
</code></pre></li><li><p>Verify that the Service is running by running the following command:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get services wordpress
</span></span></code></pre></div><p>The response should be like this:</p><pre tabindex=0><code>NAME        TYPE            CLUSTER-IP   EXTERNAL-IP   PORT(S)        AGE
wordpress   LoadBalancer    10.0.0.89    &lt;pending&gt;     80:32406/TCP   4m
</code></pre><div class="alert alert-info note callout" role=alert><strong>Note:</strong> Minikube can only expose Services through <code>NodePort</code>. The EXTERNAL-IP is always pending.</div></li><li><p>Run the following command to get the IP Address for the WordPress Service:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>minikube service wordpress --url
</span></span></code></pre></div><p>The response should be like this:</p><pre tabindex=0><code>http://1.2.3.4:32406
</code></pre></li><li><p>Copy the IP address, and load the page in your browser to view your site.</p><p>You should see the WordPress set up page similar to the following screenshot.</p><p><img src=https://raw.githubusercontent.com/kubernetes/examples/master/mysql-wordpress-pd/WordPress.png alt=wordpress-init></p></li></ol><div class="alert alert-danger warning callout" role=alert><strong>Warning:</strong> Do not leave your WordPress installation on this page. If another user finds it, they can set up a website on your instance and use it to serve malicious content.<br><br>Either install WordPress by creating a username and password or delete your instance.</div><h2 id=cleaning-up>Cleaning up</h2><ol><li><p>Run the following command to delete your Secret, Deployments, Services and PersistentVolumeClaims:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl delete -k ./
</span></span></code></pre></div></li></ol><h2 id=what-s-next>What's next</h2><ul><li>Learn more about <a href=/docs/tasks/debug/debug-application/debug-running-pod/>Introspection and Debugging</a></li><li>Learn more about <a href=/docs/concepts/workloads/controllers/job/>Jobs</a></li><li>Learn more about <a href=/docs/tasks/access-application-cluster/port-forward-access-application-cluster/>Port Forwarding</a></li><li>Learn how to <a href=/docs/tasks/debug/debug-application/get-shell-running-container/>Get a Shell to a Container</a></li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-bf0d8e08fddd6e0282709b9fef8b5f67>6.3 - Example: Deploying Cassandra with a StatefulSet</h1><p>This tutorial shows you how to run <a href=https://cassandra.apache.org/>Apache Cassandra</a> on Kubernetes.
Cassandra, a database, needs persistent storage to provide data durability (application <em>state</em>).
In this example, a custom Cassandra seed provider lets the database discover new Cassandra instances as they join the Cassandra cluster.</p><p><em>StatefulSets</em> make it easier to deploy stateful applications into your Kubernetes cluster.
For more information on the features used in this tutorial, see
<a href=/docs/concepts/workloads/controllers/statefulset/>StatefulSet</a>.</p><div class="alert alert-info note callout" role=alert><strong>Note:</strong><p>Cassandra and Kubernetes both use the term <em>node</em> to mean a member of a cluster. In this
tutorial, the Pods that belong to the StatefulSet are Cassandra nodes and are members
of the Cassandra cluster (called a <em>ring</em>). When those Pods run in your Kubernetes cluster,
the Kubernetes control plane schedules those Pods onto Kubernetes
<a class=glossary-tooltip title='A node is a worker machine in Kubernetes.' data-toggle=tooltip data-placement=top href=/docs/concepts/architecture/nodes/ target=_blank aria-label=Nodes>Nodes</a>.</p><p>When a Cassandra node starts, it uses a <em>seed list</em> to bootstrap discovery of other
nodes in the ring.
This tutorial deploys a custom Cassandra seed provider that lets the database discover
new Cassandra Pods as they appear inside your Kubernetes cluster.</p></div><h2 id=objectives>Objectives</h2><ul><li>Create and validate a Cassandra headless <a class=glossary-tooltip title='A way to expose an application running on a set of Pods as a network service.' data-toggle=tooltip data-placement=top href=/docs/concepts/services-networking/service/ target=_blank aria-label=Service>Service</a>.</li><li>Use a <a class=glossary-tooltip title='Manages deployment and scaling of a set of Pods, with durable storage and persistent identifiers for each Pod.' data-toggle=tooltip data-placement=top href=/docs/concepts/workloads/controllers/statefulset/ target=_blank aria-label=StatefulSet>StatefulSet</a> to create a Cassandra ring.</li><li>Validate the StatefulSet.</li><li>Modify the StatefulSet.</li><li>Delete the StatefulSet and its <a class=glossary-tooltip title='A Pod represents a set of running containers in your cluster.' data-toggle=tooltip data-placement=top href=/docs/concepts/workloads/pods/ target=_blank aria-label=Pods>Pods</a>.</li></ul><h2 id=before-you-begin>Before you begin</h2><p>You need to have a Kubernetes cluster, and the kubectl command-line tool must
be configured to communicate with your cluster. It is recommended to run this tutorial on a cluster with at least two nodes that are not acting as control plane hosts. If you do not already have a
cluster, you can create one by using
<a href=https://minikube.sigs.k8s.io/docs/tutorials/multi_node/>minikube</a>
or you can use one of these Kubernetes playgrounds:</p><ul><li><a href=https://killercoda.com/playgrounds/scenario/kubernetes>Killercoda</a></li><li><a href=http://labs.play-with-k8s.com/>Play with Kubernetes</a></li></ul><p>To complete this tutorial, you should already have a basic familiarity with
<a class=glossary-tooltip title='A Pod represents a set of running containers in your cluster.' data-toggle=tooltip data-placement=top href=/docs/concepts/workloads/pods/ target=_blank aria-label=Pods>Pods</a>,
<a class=glossary-tooltip title='A way to expose an application running on a set of Pods as a network service.' data-toggle=tooltip data-placement=top href=/docs/concepts/services-networking/service/ target=_blank aria-label=Services>Services</a>, and
<a class=glossary-tooltip title='Manages deployment and scaling of a set of Pods, with durable storage and persistent identifiers for each Pod.' data-toggle=tooltip data-placement=top href=/docs/concepts/workloads/controllers/statefulset/ target=_blank aria-label=StatefulSets>StatefulSets</a>.</p><h3 id=additional-minikube-setup-instructions>Additional Minikube setup instructions</h3><div class="alert alert-warning caution callout" role=alert><strong>Caution:</strong><p><a href=https://minikube.sigs.k8s.io/docs/>Minikube</a> defaults to 2048MB of memory and 2 CPU.
Running Minikube with the default resource configuration results in insufficient resource
errors during this tutorial. To avoid these errors, start Minikube with the following settings:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>minikube start --memory <span style=color:#666>5120</span> --cpus<span style=color:#666>=</span><span style=color:#666>4</span>
</span></span></code></pre></div></div><h2 id=creating-a-cassandra-headless-service>Creating a headless Service for Cassandra</h2><p>In Kubernetes, a <a class=glossary-tooltip title='A way to expose an application running on a set of Pods as a network service.' data-toggle=tooltip data-placement=top href=/docs/concepts/services-networking/service/ target=_blank aria-label=Service>Service</a> describes a set of
<a class=glossary-tooltip title='A Pod represents a set of running containers in your cluster.' data-toggle=tooltip data-placement=top href=/docs/concepts/workloads/pods/ target=_blank aria-label=Pods>Pods</a> that perform the same task.</p><p>The following Service is used for DNS lookups between Cassandra Pods and clients within your cluster:</p><div class=highlight><div class=copy-code-icon style=text-align:right><a href=https://raw.githubusercontent.com/kubernetes/website/main/content/en/examples/application/cassandra/cassandra-service.yaml download=application/cassandra/cassandra-service.yaml><code>application/cassandra/cassandra-service.yaml</code></a>
<img src=/images/copycode.svg style=max-height:24px;cursor:pointer onclick='copyCode("application-cassandra-cassandra-service-yaml")' title="Copy application/cassandra/cassandra-service.yaml to clipboard"></img></div><div class=includecode id=application-cassandra-cassandra-service-yaml><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Service<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>labels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>app</span>:<span style=color:#bbb> </span>cassandra<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>cassandra<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>clusterIP</span>:<span style=color:#bbb> </span>None<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>ports</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>port</span>:<span style=color:#bbb> </span><span style=color:#666>9042</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>selector</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>app</span>:<span style=color:#bbb> </span>cassandra<span style=color:#bbb>
</span></span></span></code></pre></div></div></div><p>Create a Service to track all Cassandra StatefulSet members from the <code>cassandra-service.yaml</code> file:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl apply -f https://k8s.io/examples/application/cassandra/cassandra-service.yaml
</span></span></code></pre></div><h3 id=validating>Validating (optional)</h3><p>Get the Cassandra Service.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get svc cassandra
</span></span></code></pre></div><p>The response is</p><pre tabindex=0><code>NAME        TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)    AGE
cassandra   ClusterIP   None         &lt;none&gt;        9042/TCP   45s
</code></pre><p>If you don't see a Service named <code>cassandra</code>, that means creation failed. Read
<a href=/docs/tasks/debug/debug-application/debug-service/>Debug Services</a>
for help troubleshooting common issues.</p><h2 id=using-a-statefulset-to-create-a-cassandra-ring>Using a StatefulSet to create a Cassandra ring</h2><p>The StatefulSet manifest, included below, creates a Cassandra ring that consists of three Pods.</p><div class="alert alert-info note callout" role=alert><strong>Note:</strong> This example uses the default provisioner for Minikube.
Please update the following StatefulSet for the cloud you are working with.</div><div class=highlight><div class=copy-code-icon style=text-align:right><a href=https://raw.githubusercontent.com/kubernetes/website/main/content/en/examples/application/cassandra/cassandra-statefulset.yaml download=application/cassandra/cassandra-statefulset.yaml><code>application/cassandra/cassandra-statefulset.yaml</code></a>
<img src=/images/copycode.svg style=max-height:24px;cursor:pointer onclick='copyCode("application-cassandra-cassandra-statefulset-yaml")' title="Copy application/cassandra/cassandra-statefulset.yaml to clipboard"></img></div><div class=includecode id=application-cassandra-cassandra-statefulset-yaml><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>apps/v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>StatefulSet<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>cassandra<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>labels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>app</span>:<span style=color:#bbb> </span>cassandra<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>serviceName</span>:<span style=color:#bbb> </span>cassandra<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>replicas</span>:<span style=color:#bbb> </span><span style=color:#666>3</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>selector</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>matchLabels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>app</span>:<span style=color:#bbb> </span>cassandra<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>template</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>labels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>app</span>:<span style=color:#bbb> </span>cassandra<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>terminationGracePeriodSeconds</span>:<span style=color:#bbb> </span><span style=color:#666>1800</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>cassandra<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>gcr.io/google-samples/cassandra:v13<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>imagePullPolicy</span>:<span style=color:#bbb> </span>Always<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>ports</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span>- <span style=color:green;font-weight:700>containerPort</span>:<span style=color:#bbb> </span><span style=color:#666>7000</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>intra-node<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span>- <span style=color:green;font-weight:700>containerPort</span>:<span style=color:#bbb> </span><span style=color:#666>7001</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>tls-intra-node<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span>- <span style=color:green;font-weight:700>containerPort</span>:<span style=color:#bbb> </span><span style=color:#666>7199</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>jmx<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span>- <span style=color:green;font-weight:700>containerPort</span>:<span style=color:#bbb> </span><span style=color:#666>9042</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>cql<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>resources</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>limits</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>            </span><span style=color:green;font-weight:700>cpu</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;500m&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>            </span><span style=color:green;font-weight:700>memory</span>:<span style=color:#bbb> </span>1Gi<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>requests</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>            </span><span style=color:green;font-weight:700>cpu</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;500m&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>            </span><span style=color:green;font-weight:700>memory</span>:<span style=color:#bbb> </span>1Gi<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>securityContext</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>capabilities</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>            </span><span style=color:green;font-weight:700>add</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>              </span>- IPC_LOCK<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>lifecycle</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>preStop</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>            </span><span style=color:green;font-weight:700>exec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>              </span><span style=color:green;font-weight:700>command</span>:<span style=color:#bbb> 
</span></span></span><span style=display:flex><span><span style=color:#bbb>              </span>- /bin/sh<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>              </span>- -c<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>              </span>- nodetool drain<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>env</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>MAX_HEAP_SIZE<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>            </span><span style=color:green;font-weight:700>value</span>:<span style=color:#bbb> </span>512M<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>HEAP_NEWSIZE<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>            </span><span style=color:green;font-weight:700>value</span>:<span style=color:#bbb> </span>100M<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>CASSANDRA_SEEDS<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>            </span><span style=color:green;font-weight:700>value</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;cassandra-0.cassandra.default.svc.cluster.local&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>CASSANDRA_CLUSTER_NAME<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>            </span><span style=color:green;font-weight:700>value</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;K8Demo&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>CASSANDRA_DC<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>            </span><span style=color:green;font-weight:700>value</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;DC1-K8Demo&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>CASSANDRA_RACK<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>            </span><span style=color:green;font-weight:700>value</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;Rack1-K8Demo&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>POD_IP<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>            </span><span style=color:green;font-weight:700>valueFrom</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>              </span><span style=color:green;font-weight:700>fieldRef</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>                </span><span style=color:green;font-weight:700>fieldPath</span>:<span style=color:#bbb> </span>status.podIP<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>readinessProbe</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>exec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>            </span><span style=color:green;font-weight:700>command</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>            </span>- /bin/bash<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>            </span>- -c<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>            </span>- /ready-probe.sh<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>initialDelaySeconds</span>:<span style=color:#bbb> </span><span style=color:#666>15</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>timeoutSeconds</span>:<span style=color:#bbb> </span><span style=color:#666>5</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:#080;font-style:italic># These volume mounts are persistent. They are like inline claims,</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:#080;font-style:italic># but not exactly because the names need to match exactly one of</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:#080;font-style:italic># the stateful pod volumes.</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>volumeMounts</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>cassandra-data<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>mountPath</span>:<span style=color:#bbb> </span>/cassandra_data<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:#080;font-style:italic># These are converted to volume claims by the controller</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:#080;font-style:italic># and mounted at the paths mentioned above.</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:#080;font-style:italic># do not use these in production until ssd GCEPersistentDisk or other ssd pd</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>volumeClaimTemplates</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>cassandra-data<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>accessModes</span>:<span style=color:#bbb> </span>[<span style=color:#bbb> </span><span style=color:#b44>&#34;ReadWriteOnce&#34;</span><span style=color:#bbb> </span>]<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>storageClassName</span>:<span style=color:#bbb> </span>fast<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>resources</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>requests</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>storage</span>:<span style=color:#bbb> </span>1Gi<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:#00f;font-weight:700>---</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>StorageClass<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>storage.k8s.io/v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>fast<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>provisioner</span>:<span style=color:#bbb> </span>k8s.io/minikube-hostpath<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>parameters</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>type</span>:<span style=color:#bbb> </span>pd-ssd<span style=color:#bbb>
</span></span></span></code></pre></div></div></div><p>Create the Cassandra StatefulSet from the <code>cassandra-statefulset.yaml</code> file:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span><span style=color:#080;font-style:italic># Use this if you are able to apply cassandra-statefulset.yaml unmodified</span>
</span></span><span style=display:flex><span>kubectl apply -f https://k8s.io/examples/application/cassandra/cassandra-statefulset.yaml
</span></span></code></pre></div><p>If you need to modify <code>cassandra-statefulset.yaml</code> to suit your cluster, download
<a href=https://k8s.io/examples/application/cassandra/cassandra-statefulset.yaml>https://k8s.io/examples/application/cassandra/cassandra-statefulset.yaml</a> and then apply
that manifest, from the folder you saved the modified version into:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span><span style=color:#080;font-style:italic># Use this if you needed to modify cassandra-statefulset.yaml locally</span>
</span></span><span style=display:flex><span>kubectl apply -f cassandra-statefulset.yaml
</span></span></code></pre></div><h2 id=validating-the-cassandra-statefulset>Validating the Cassandra StatefulSet</h2><ol><li><p>Get the Cassandra StatefulSet:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get statefulset cassandra
</span></span></code></pre></div><p>The response should be similar to:</p><pre tabindex=0><code>NAME        DESIRED   CURRENT   AGE
cassandra   3         0         13s
</code></pre><p>The <code>StatefulSet</code> resource deploys Pods sequentially.</p></li><li><p>Get the Pods to see the ordered creation status:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get pods -l<span style=color:#666>=</span><span style=color:#b44>&#34;app=cassandra&#34;</span>
</span></span></code></pre></div><p>The response should be similar to:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>NAME          READY     STATUS              RESTARTS   AGE
</span></span><span style=display:flex><span>cassandra-0   1/1       Running             <span style=color:#666>0</span>          1m
</span></span><span style=display:flex><span>cassandra-1   0/1       ContainerCreating   <span style=color:#666>0</span>          8s
</span></span></code></pre></div><p>It can take several minutes for all three Pods to deploy. Once they are deployed, the same command
returns output similar to:</p><pre tabindex=0><code>NAME          READY     STATUS    RESTARTS   AGE
cassandra-0   1/1       Running   0          10m
cassandra-1   1/1       Running   0          9m
cassandra-2   1/1       Running   0          8m
</code></pre></li><li><p>Run the Cassandra <a href=https://cwiki.apache.org/confluence/display/CASSANDRA2/NodeTool>nodetool</a> inside the first Pod, to
display the status of the ring.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl <span style=color:#a2f>exec</span> -it cassandra-0 -- nodetool status
</span></span></code></pre></div><p>The response should look something like:</p><pre tabindex=0><code>Datacenter: DC1-K8Demo
======================
Status=Up/Down
|/ State=Normal/Leaving/Joining/Moving
--  Address     Load       Tokens       Owns (effective)  Host ID                               Rack
UN  172.17.0.5  83.57 KiB  32           74.0%             e2dd09e6-d9d3-477e-96c5-45094c08db0f  Rack1-K8Demo
UN  172.17.0.4  101.04 KiB  32           58.8%             f89d6835-3a42-4419-92b3-0e62cae1479c  Rack1-K8Demo
UN  172.17.0.6  84.74 KiB  32           67.1%             a6a1e8c2-3dc5-4417-b1a0-26507af2aaad  Rack1-K8Demo
</code></pre></li></ol><h2 id=modifying-the-cassandra-statefulset>Modifying the Cassandra StatefulSet</h2><p>Use <code>kubectl edit</code> to modify the size of a Cassandra StatefulSet.</p><ol><li><p>Run the following command:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl edit statefulset cassandra
</span></span></code></pre></div><p>This command opens an editor in your terminal. The line you need to change is the <code>replicas</code> field.
The following sample is an excerpt of the StatefulSet file:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#080;font-style:italic># Please edit the object below. Lines beginning with a &#39;#&#39; will be ignored,</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:#080;font-style:italic># and an empty file will abort the edit. If an error occurs while saving this file will be</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:#080;font-style:italic># reopened with the relevant failures.</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:#080;font-style:italic>#</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>apps/v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>StatefulSet<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>creationTimestamp</span>:<span style=color:#bbb> </span>2016-08-13T18:40:58Z<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>generation</span>:<span style=color:#bbb> </span><span style=color:#666>1</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>labels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>app</span>:<span style=color:#bbb> </span>cassandra<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>cassandra<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>namespace</span>:<span style=color:#bbb> </span>default<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>resourceVersion</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;323&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>uid</span>:<span style=color:#bbb> </span>7a219483-6185-11e6-a910-42010a8a0fc0<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>replicas</span>:<span style=color:#bbb> </span><span style=color:#666>3</span><span style=color:#bbb>
</span></span></span></code></pre></div></li><li><p>Change the number of replicas to 4, and then save the manifest.</p><p>The StatefulSet now scales to run with 4 Pods.</p></li><li><p>Get the Cassandra StatefulSet to verify your change:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get statefulset cassandra
</span></span></code></pre></div><p>The response should be similar to:</p><pre tabindex=0><code>NAME        DESIRED   CURRENT   AGE
cassandra   4         4         36m
</code></pre></li></ol><h2 id=cleaning-up>Cleaning up</h2><p>Deleting or scaling a StatefulSet down does not delete the volumes associated with the StatefulSet.
This setting is for your safety because your data is more valuable than automatically purging all related StatefulSet resources.</p><div class="alert alert-danger warning callout" role=alert><strong>Warning:</strong> Depending on the storage class and reclaim policy, deleting the <em>PersistentVolumeClaims</em> may cause the associated volumes
to also be deleted. Never assume you'll be able to access data if its volume claims are deleted.</div><ol><li><p>Run the following commands (chained together into a single command) to delete everything in the Cassandra StatefulSet:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span><span style=color:#b8860b>grace</span><span style=color:#666>=</span><span style=color:#a2f;font-weight:700>$(</span>kubectl get pod cassandra-0 -o<span style=color:#666>=</span><span style=color:#b8860b>jsonpath</span><span style=color:#666>=</span><span style=color:#b44>&#39;{.spec.terminationGracePeriodSeconds}&#39;</span><span style=color:#a2f;font-weight:700>)</span> <span style=color:#b62;font-weight:700>\
</span></span></span><span style=display:flex><span><span style=color:#b62;font-weight:700></span>  <span style=color:#666>&amp;&amp;</span> kubectl delete statefulset -l <span style=color:#b8860b>app</span><span style=color:#666>=</span>cassandra <span style=color:#b62;font-weight:700>\
</span></span></span><span style=display:flex><span><span style=color:#b62;font-weight:700></span>  <span style=color:#666>&amp;&amp;</span> <span style=color:#a2f>echo</span> <span style=color:#b44>&#34;Sleeping </span><span style=color:#b68;font-weight:700>${</span><span style=color:#b8860b>grace</span><span style=color:#b68;font-weight:700>}</span><span style=color:#b44> seconds&#34;</span> 1&gt;&amp;<span style=color:#666>2</span> <span style=color:#b62;font-weight:700>\
</span></span></span><span style=display:flex><span><span style=color:#b62;font-weight:700></span>  <span style=color:#666>&amp;&amp;</span> sleep <span style=color:#b8860b>$grace</span> <span style=color:#b62;font-weight:700>\
</span></span></span><span style=display:flex><span><span style=color:#b62;font-weight:700></span>  <span style=color:#666>&amp;&amp;</span> kubectl delete persistentvolumeclaim -l <span style=color:#b8860b>app</span><span style=color:#666>=</span>cassandra
</span></span></code></pre></div></li><li><p>Run the following command to delete the Service you set up for Cassandra:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl delete service -l <span style=color:#b8860b>app</span><span style=color:#666>=</span>cassandra
</span></span></code></pre></div></li></ol><h2 id=cassandra-container-environment-variables>Cassandra container environment variables</h2><p>The Pods in this tutorial use the <a href=https://github.com/kubernetes/examples/blob/master/cassandra/image/Dockerfile><code>gcr.io/google-samples/cassandra:v13</code></a>
image from Google's <a href=https://cloud.google.com/container-registry/docs/>container registry</a>.
The Docker image above is based on <a href=https://github.com/kubernetes/release/tree/master/images/build/debian-base>debian-base</a>
and includes OpenJDK 8.</p><p>This image includes a standard Cassandra installation from the Apache Debian repo.
By using environment variables you can change values that are inserted into <code>cassandra.yaml</code>.</p><table><thead><tr><th>Environment variable</th><th style=text-align:center>Default value</th></tr></thead><tbody><tr><td><code>CASSANDRA_CLUSTER_NAME</code></td><td style=text-align:center><code>'Test Cluster'</code></td></tr><tr><td><code>CASSANDRA_NUM_TOKENS</code></td><td style=text-align:center><code>32</code></td></tr><tr><td><code>CASSANDRA_RPC_ADDRESS</code></td><td style=text-align:center><code>0.0.0.0</code></td></tr></tbody></table><h2 id=what-s-next>What's next</h2><ul><li>Learn how to <a href=/docs/tasks/run-application/scale-stateful-set/>Scale a StatefulSet</a>.</li><li>Learn more about the <a href=https://github.com/kubernetes/examples/blob/master/cassandra/java/src/main/java/io/k8s/cassandra/KubernetesSeedProvider.java><em>KubernetesSeedProvider</em></a></li><li>See more custom <a href=https://git.k8s.io/examples/cassandra/java/README.md>Seed Provider Configurations</a></li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-4bfac214b5eb9ebddaf1f3811901d327>6.4 - Running ZooKeeper, A Distributed System Coordinator</h1><p>This tutorial demonstrates running <a href=https://zookeeper.apache.org>Apache Zookeeper</a> on
Kubernetes using <a href=/docs/concepts/workloads/controllers/statefulset/>StatefulSets</a>,
<a href=/docs/concepts/workloads/pods/disruptions/#pod-disruption-budget>PodDisruptionBudgets</a>,
and <a href=/docs/concepts/scheduling-eviction/assign-pod-node/#affinity-and-anti-affinity>PodAntiAffinity</a>.</p><h2 id=before-you-begin>Before you begin</h2><p>Before starting this tutorial, you should be familiar with the following
Kubernetes concepts:</p><ul><li><a href=/docs/concepts/workloads/pods/>Pods</a></li><li><a href=/docs/concepts/services-networking/dns-pod-service/>Cluster DNS</a></li><li><a href=/docs/concepts/services-networking/service/#headless-services>Headless Services</a></li><li><a href=/docs/concepts/storage/volumes/>PersistentVolumes</a></li><li><a href=https://github.com/kubernetes/examples/tree/master/staging/persistent-volume-provisioning/>PersistentVolume Provisioning</a></li><li><a href=/docs/concepts/workloads/controllers/statefulset/>StatefulSets</a></li><li><a href=/docs/concepts/workloads/pods/disruptions/#pod-disruption-budget>PodDisruptionBudgets</a></li><li><a href=/docs/concepts/scheduling-eviction/assign-pod-node/#affinity-and-anti-affinity>PodAntiAffinity</a></li><li><a href=/docs/reference/kubectl/kubectl/>kubectl CLI</a></li></ul><p>You must have a cluster with at least four nodes, and each node requires at least 2 CPUs and 4 GiB of memory. In this tutorial you will cordon and drain the cluster's nodes. <strong>This means that the cluster will terminate and evict all Pods on its nodes, and the nodes will temporarily become unschedulable.</strong> You should use a dedicated cluster for this tutorial, or you should ensure that the disruption you cause will not interfere with other tenants.</p><p>This tutorial assumes that you have configured your cluster to dynamically provision
PersistentVolumes. If your cluster is not configured to do so, you
will have to manually provision three 20 GiB volumes before starting this
tutorial.</p><h2 id=objectives>Objectives</h2><p>After this tutorial, you will know the following.</p><ul><li>How to deploy a ZooKeeper ensemble using StatefulSet.</li><li>How to consistently configure the ensemble.</li><li>How to spread the deployment of ZooKeeper servers in the ensemble.</li><li>How to use PodDisruptionBudgets to ensure service availability during planned maintenance.</li></ul><h3 id=zookeeper>ZooKeeper</h3><p><a href=https://zookeeper.apache.org/doc/current/>Apache ZooKeeper</a> is a
distributed, open-source coordination service for distributed applications.
ZooKeeper allows you to read, write, and observe updates to data. Data are
organized in a file system like hierarchy and replicated to all ZooKeeper
servers in the ensemble (a set of ZooKeeper servers). All operations on data
are atomic and sequentially consistent. ZooKeeper ensures this by using the
<a href=https://pdfs.semanticscholar.org/b02c/6b00bd5dbdbd951fddb00b906c82fa80f0b3.pdf>Zab</a>
consensus protocol to replicate a state machine across all servers in the ensemble.</p><p>The ensemble uses the Zab protocol to elect a leader, and the ensemble cannot write data until that election is complete. Once complete, the ensemble uses Zab to ensure that it replicates all writes to a quorum before it acknowledges and makes them visible to clients. Without respect to weighted quorums, a quorum is a majority component of the ensemble containing the current leader. For instance, if the ensemble has three servers, a component that contains the leader and one other server constitutes a quorum. If the ensemble can not achieve a quorum, the ensemble cannot write data.</p><p>ZooKeeper servers keep their entire state machine in memory, and write every mutation to a durable WAL (Write Ahead Log) on storage media. When a server crashes, it can recover its previous state by replaying the WAL. To prevent the WAL from growing without bound, ZooKeeper servers will periodically snapshot them in memory state to storage media. These snapshots can be loaded directly into memory, and all WAL entries that preceded the snapshot may be discarded.</p><h2 id=creating-a-zookeeper-ensemble>Creating a ZooKeeper ensemble</h2><p>The manifest below contains a
<a href=/docs/concepts/services-networking/service/#headless-services>Headless Service</a>,
a <a href=/docs/concepts/services-networking/service/>Service</a>,
a <a href=/docs/concepts/workloads/pods/disruptions/#pod-disruption-budgets>PodDisruptionBudget</a>,
and a <a href=/docs/concepts/workloads/controllers/statefulset/>StatefulSet</a>.</p><div class=highlight><div class=copy-code-icon style=text-align:right><a href=https://raw.githubusercontent.com/kubernetes/website/main/content/en/examples/application/zookeeper/zookeeper.yaml download=application/zookeeper/zookeeper.yaml><code>application/zookeeper/zookeeper.yaml</code></a>
<img src=/images/copycode.svg style=max-height:24px;cursor:pointer onclick='copyCode("application-zookeeper-zookeeper-yaml")' title="Copy application/zookeeper/zookeeper.yaml to clipboard"></img></div><div class=includecode id=application-zookeeper-zookeeper-yaml><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Service<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>zk-hs<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>labels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>app</span>:<span style=color:#bbb> </span>zk<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>ports</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>port</span>:<span style=color:#bbb> </span><span style=color:#666>2888</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>server<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>port</span>:<span style=color:#bbb> </span><span style=color:#666>3888</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>leader-election<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>clusterIP</span>:<span style=color:#bbb> </span>None<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>selector</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>app</span>:<span style=color:#bbb> </span>zk<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:#00f;font-weight:700>---</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Service<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>zk-cs<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>labels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>app</span>:<span style=color:#bbb> </span>zk<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>ports</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>port</span>:<span style=color:#bbb> </span><span style=color:#666>2181</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>client<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>selector</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>app</span>:<span style=color:#bbb> </span>zk<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:#00f;font-weight:700>---</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>policy/v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>PodDisruptionBudget<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>zk-pdb<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>selector</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>matchLabels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>app</span>:<span style=color:#bbb> </span>zk<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>maxUnavailable</span>:<span style=color:#bbb> </span><span style=color:#666>1</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:#00f;font-weight:700>---</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>apps/v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>StatefulSet<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>zk<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>selector</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>matchLabels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>app</span>:<span style=color:#bbb> </span>zk<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>serviceName</span>:<span style=color:#bbb> </span>zk-hs<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>replicas</span>:<span style=color:#bbb> </span><span style=color:#666>3</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>updateStrategy</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>type</span>:<span style=color:#bbb> </span>RollingUpdate<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>podManagementPolicy</span>:<span style=color:#bbb> </span>OrderedReady<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>template</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>labels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>app</span>:<span style=color:#bbb> </span>zk<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>affinity</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>podAntiAffinity</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>requiredDuringSchedulingIgnoredDuringExecution</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>            </span>- <span style=color:green;font-weight:700>labelSelector</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>                </span><span style=color:green;font-weight:700>matchExpressions</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>                  </span>- <span style=color:green;font-weight:700>key</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;app&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>                    </span><span style=color:green;font-weight:700>operator</span>:<span style=color:#bbb> </span>In<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>                    </span><span style=color:green;font-weight:700>values</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>                    </span>- zk<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>              </span><span style=color:green;font-weight:700>topologyKey</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;kubernetes.io/hostname&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>kubernetes-zookeeper<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>imagePullPolicy</span>:<span style=color:#bbb> </span>Always<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;registry.k8s.io/kubernetes-zookeeper:1.0-3.4.10&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>resources</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>requests</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>            </span><span style=color:green;font-weight:700>memory</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;1Gi&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>            </span><span style=color:green;font-weight:700>cpu</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;0.5&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>ports</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span>- <span style=color:green;font-weight:700>containerPort</span>:<span style=color:#bbb> </span><span style=color:#666>2181</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>client<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span>- <span style=color:green;font-weight:700>containerPort</span>:<span style=color:#bbb> </span><span style=color:#666>2888</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>server<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span>- <span style=color:green;font-weight:700>containerPort</span>:<span style=color:#bbb> </span><span style=color:#666>3888</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>leader-election<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>command</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span>- sh<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span>- -c<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span>- <span style=color:#b44>&#34;start-zookeeper \
</span></span></span><span style=display:flex><span><span style=color:#b44>          --servers=3 \
</span></span></span><span style=display:flex><span><span style=color:#b44>          --data_dir=/var/lib/zookeeper/data \
</span></span></span><span style=display:flex><span><span style=color:#b44>          --data_log_dir=/var/lib/zookeeper/data/log \
</span></span></span><span style=display:flex><span><span style=color:#b44>          --conf_dir=/opt/zookeeper/conf \
</span></span></span><span style=display:flex><span><span style=color:#b44>          --client_port=2181 \
</span></span></span><span style=display:flex><span><span style=color:#b44>          --election_port=3888 \
</span></span></span><span style=display:flex><span><span style=color:#b44>          --server_port=2888 \
</span></span></span><span style=display:flex><span><span style=color:#b44>          --tick_time=2000 \
</span></span></span><span style=display:flex><span><span style=color:#b44>          --init_limit=10 \
</span></span></span><span style=display:flex><span><span style=color:#b44>          --sync_limit=5 \
</span></span></span><span style=display:flex><span><span style=color:#b44>          --heap=512M \
</span></span></span><span style=display:flex><span><span style=color:#b44>          --max_client_cnxns=60 \
</span></span></span><span style=display:flex><span><span style=color:#b44>          --snap_retain_count=3 \
</span></span></span><span style=display:flex><span><span style=color:#b44>          --purge_interval=12 \
</span></span></span><span style=display:flex><span><span style=color:#b44>          --max_session_timeout=40000 \
</span></span></span><span style=display:flex><span><span style=color:#b44>          --min_session_timeout=4000 \
</span></span></span><span style=display:flex><span><span style=color:#b44>          --log_level=INFO&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>readinessProbe</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>exec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>            </span><span style=color:green;font-weight:700>command</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>            </span>- sh<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>            </span>- -c<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>            </span>- <span style=color:#b44>&#34;zookeeper-ready 2181&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>initialDelaySeconds</span>:<span style=color:#bbb> </span><span style=color:#666>10</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>timeoutSeconds</span>:<span style=color:#bbb> </span><span style=color:#666>5</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>livenessProbe</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>exec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>            </span><span style=color:green;font-weight:700>command</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>            </span>- sh<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>            </span>- -c<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>            </span>- <span style=color:#b44>&#34;zookeeper-ready 2181&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>initialDelaySeconds</span>:<span style=color:#bbb> </span><span style=color:#666>10</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>timeoutSeconds</span>:<span style=color:#bbb> </span><span style=color:#666>5</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>volumeMounts</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>datadir<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>mountPath</span>:<span style=color:#bbb> </span>/var/lib/zookeeper<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>securityContext</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>runAsUser</span>:<span style=color:#bbb> </span><span style=color:#666>1000</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>fsGroup</span>:<span style=color:#bbb> </span><span style=color:#666>1000</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>volumeClaimTemplates</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>datadir<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>accessModes</span>:<span style=color:#bbb> </span>[<span style=color:#bbb> </span><span style=color:#b44>&#34;ReadWriteOnce&#34;</span><span style=color:#bbb> </span>]<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>resources</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>requests</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>storage</span>:<span style=color:#bbb> </span>10Gi<span style=color:#bbb>
</span></span></span></code></pre></div></div></div><p>Open a terminal, and use the
<a href=/docs/reference/generated/kubectl/kubectl-commands/#apply><code>kubectl apply</code></a> command to create the
manifest.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl apply -f https://k8s.io/examples/application/zookeeper/zookeeper.yaml
</span></span></code></pre></div><p>This creates the <code>zk-hs</code> Headless Service, the <code>zk-cs</code> Service,
the <code>zk-pdb</code> PodDisruptionBudget, and the <code>zk</code> StatefulSet.</p><pre tabindex=0><code>service/zk-hs created
service/zk-cs created
poddisruptionbudget.policy/zk-pdb created
statefulset.apps/zk created
</code></pre><p>Use <a href=/docs/reference/generated/kubectl/kubectl-commands/#get><code>kubectl get</code></a> to watch the
StatefulSet controller create the StatefulSet's Pods.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get pods -w -l <span style=color:#b8860b>app</span><span style=color:#666>=</span>zk
</span></span></code></pre></div><p>Once the <code>zk-2</code> Pod is Running and Ready, use <code>CTRL-C</code> to terminate kubectl.</p><pre tabindex=0><code>NAME      READY     STATUS    RESTARTS   AGE
zk-0      0/1       Pending   0          0s
zk-0      0/1       Pending   0         0s
zk-0      0/1       ContainerCreating   0         0s
zk-0      0/1       Running   0         19s
zk-0      1/1       Running   0         40s
zk-1      0/1       Pending   0         0s
zk-1      0/1       Pending   0         0s
zk-1      0/1       ContainerCreating   0         0s
zk-1      0/1       Running   0         18s
zk-1      1/1       Running   0         40s
zk-2      0/1       Pending   0         0s
zk-2      0/1       Pending   0         0s
zk-2      0/1       ContainerCreating   0         0s
zk-2      0/1       Running   0         19s
zk-2      1/1       Running   0         40s
</code></pre><p>The StatefulSet controller creates three Pods, and each Pod has a container with
a <a href=https://archive.apache.org/dist/zookeeper/stable/>ZooKeeper</a> server.</p><h3 id=facilitating-leader-election>Facilitating leader election</h3><p>Because there is no terminating algorithm for electing a leader in an anonymous network, Zab requires explicit membership configuration to perform leader election. Each server in the ensemble needs to have a unique identifier, all servers need to know the global set of identifiers, and each identifier needs to be associated with a network address.</p><p>Use <a href=/docs/reference/generated/kubectl/kubectl-commands/#exec><code>kubectl exec</code></a> to get the hostnames
of the Pods in the <code>zk</code> StatefulSet.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span><span style=color:#a2f;font-weight:700>for</span> i in <span style=color:#666>0</span> <span style=color:#666>1</span> 2; <span style=color:#a2f;font-weight:700>do</span> kubectl <span style=color:#a2f>exec</span> zk-<span style=color:#b8860b>$i</span> -- hostname; <span style=color:#a2f;font-weight:700>done</span>
</span></span></code></pre></div><p>The StatefulSet controller provides each Pod with a unique hostname based on its ordinal index. The hostnames take the form of <code>&lt;statefulset name>-&lt;ordinal index></code>. Because the <code>replicas</code> field of the <code>zk</code> StatefulSet is set to <code>3</code>, the Set's controller creates three Pods with their hostnames set to <code>zk-0</code>, <code>zk-1</code>, and
<code>zk-2</code>.</p><pre tabindex=0><code>zk-0
zk-1
zk-2
</code></pre><p>The servers in a ZooKeeper ensemble use natural numbers as unique identifiers, and store each server's identifier in a file called <code>myid</code> in the server's data directory.</p><p>To examine the contents of the <code>myid</code> file for each server use the following command.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span><span style=color:#a2f;font-weight:700>for</span> i in <span style=color:#666>0</span> <span style=color:#666>1</span> 2; <span style=color:#a2f;font-weight:700>do</span> <span style=color:#a2f>echo</span> <span style=color:#b44>&#34;myid zk-</span><span style=color:#b8860b>$i</span><span style=color:#b44>&#34;</span>;kubectl <span style=color:#a2f>exec</span> zk-<span style=color:#b8860b>$i</span> -- cat /var/lib/zookeeper/data/myid; <span style=color:#a2f;font-weight:700>done</span>
</span></span></code></pre></div><p>Because the identifiers are natural numbers and the ordinal indices are non-negative integers, you can generate an identifier by adding 1 to the ordinal.</p><pre tabindex=0><code>myid zk-0
1
myid zk-1
2
myid zk-2
3
</code></pre><p>To get the Fully Qualified Domain Name (FQDN) of each Pod in the <code>zk</code> StatefulSet use the following command.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span><span style=color:#a2f;font-weight:700>for</span> i in <span style=color:#666>0</span> <span style=color:#666>1</span> 2; <span style=color:#a2f;font-weight:700>do</span> kubectl <span style=color:#a2f>exec</span> zk-<span style=color:#b8860b>$i</span> -- hostname -f; <span style=color:#a2f;font-weight:700>done</span>
</span></span></code></pre></div><p>The <code>zk-hs</code> Service creates a domain for all of the Pods,
<code>zk-hs.default.svc.cluster.local</code>.</p><pre tabindex=0><code>zk-0.zk-hs.default.svc.cluster.local
zk-1.zk-hs.default.svc.cluster.local
zk-2.zk-hs.default.svc.cluster.local
</code></pre><p>The A records in <a href=/docs/concepts/services-networking/dns-pod-service/>Kubernetes DNS</a> resolve the FQDNs to the Pods' IP addresses. If Kubernetes reschedules the Pods, it will update the A records with the Pods' new IP addresses, but the A records names will not change.</p><p>ZooKeeper stores its application configuration in a file named <code>zoo.cfg</code>. Use <code>kubectl exec</code> to view the contents of the <code>zoo.cfg</code> file in the <code>zk-0</code> Pod.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl <span style=color:#a2f>exec</span> zk-0 -- cat /opt/zookeeper/conf/zoo.cfg
</span></span></code></pre></div><p>In the <code>server.1</code>, <code>server.2</code>, and <code>server.3</code> properties at the bottom of
the file, the <code>1</code>, <code>2</code>, and <code>3</code> correspond to the identifiers in the
ZooKeeper servers' <code>myid</code> files. They are set to the FQDNs for the Pods in
the <code>zk</code> StatefulSet.</p><pre tabindex=0><code>clientPort=2181
dataDir=/var/lib/zookeeper/data
dataLogDir=/var/lib/zookeeper/log
tickTime=2000
initLimit=10
syncLimit=2000
maxClientCnxns=60
minSessionTimeout= 4000
maxSessionTimeout= 40000
autopurge.snapRetainCount=3
autopurge.purgeInterval=0
server.1=zk-0.zk-hs.default.svc.cluster.local:2888:3888
server.2=zk-1.zk-hs.default.svc.cluster.local:2888:3888
server.3=zk-2.zk-hs.default.svc.cluster.local:2888:3888
</code></pre><h3 id=achieving-consensus>Achieving consensus</h3><p>Consensus protocols require that the identifiers of each participant be unique. No two participants in the Zab protocol should claim the same unique identifier. This is necessary to allow the processes in the system to agree on which processes have committed which data. If two Pods are launched with the same ordinal, two ZooKeeper servers would both identify themselves as the same server.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get pods -w -l <span style=color:#b8860b>app</span><span style=color:#666>=</span>zk
</span></span></code></pre></div><pre tabindex=0><code>NAME      READY     STATUS    RESTARTS   AGE
zk-0      0/1       Pending   0          0s
zk-0      0/1       Pending   0         0s
zk-0      0/1       ContainerCreating   0         0s
zk-0      0/1       Running   0         19s
zk-0      1/1       Running   0         40s
zk-1      0/1       Pending   0         0s
zk-1      0/1       Pending   0         0s
zk-1      0/1       ContainerCreating   0         0s
zk-1      0/1       Running   0         18s
zk-1      1/1       Running   0         40s
zk-2      0/1       Pending   0         0s
zk-2      0/1       Pending   0         0s
zk-2      0/1       ContainerCreating   0         0s
zk-2      0/1       Running   0         19s
zk-2      1/1       Running   0         40s
</code></pre><p>The A records for each Pod are entered when the Pod becomes Ready. Therefore,
the FQDNs of the ZooKeeper servers will resolve to a single endpoint, and that
endpoint will be the unique ZooKeeper server claiming the identity configured
in its <code>myid</code> file.</p><pre tabindex=0><code>zk-0.zk-hs.default.svc.cluster.local
zk-1.zk-hs.default.svc.cluster.local
zk-2.zk-hs.default.svc.cluster.local
</code></pre><p>This ensures that the <code>servers</code> properties in the ZooKeepers' <code>zoo.cfg</code> files
represents a correctly configured ensemble.</p><pre tabindex=0><code>server.1=zk-0.zk-hs.default.svc.cluster.local:2888:3888
server.2=zk-1.zk-hs.default.svc.cluster.local:2888:3888
server.3=zk-2.zk-hs.default.svc.cluster.local:2888:3888
</code></pre><p>When the servers use the Zab protocol to attempt to commit a value, they will either achieve consensus and commit the value (if leader election has succeeded and at least two of the Pods are Running and Ready), or they will fail to do so (if either of the conditions are not met). No state will arise where one server acknowledges a write on behalf of another.</p><h3 id=sanity-testing-the-ensemble>Sanity testing the ensemble</h3><p>The most basic sanity test is to write data to one ZooKeeper server and
to read the data from another.</p><p>The command below executes the <code>zkCli.sh</code> script to write <code>world</code> to the path <code>/hello</code> on the <code>zk-0</code> Pod in the ensemble.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl <span style=color:#a2f>exec</span> zk-0 -- zkCli.sh create /hello world
</span></span></code></pre></div><pre tabindex=0><code>WATCHER::

WatchedEvent state:SyncConnected type:None path:null
Created /hello
</code></pre><p>To get the data from the <code>zk-1</code> Pod use the following command.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl <span style=color:#a2f>exec</span> zk-1 -- zkCli.sh get /hello
</span></span></code></pre></div><p>The data that you created on <code>zk-0</code> is available on all the servers in the
ensemble.</p><pre tabindex=0><code>WATCHER::

WatchedEvent state:SyncConnected type:None path:null
world
cZxid = 0x100000002
ctime = Thu Dec 08 15:13:30 UTC 2016
mZxid = 0x100000002
mtime = Thu Dec 08 15:13:30 UTC 2016
pZxid = 0x100000002
cversion = 0
dataVersion = 0
aclVersion = 0
ephemeralOwner = 0x0
dataLength = 5
numChildren = 0
</code></pre><h3 id=providing-durable-storage>Providing durable storage</h3><p>As mentioned in the <a href=#zookeeper>ZooKeeper Basics</a> section,
ZooKeeper commits all entries to a durable WAL, and periodically writes snapshots
in memory state, to storage media. Using WALs to provide durability is a common
technique for applications that use consensus protocols to achieve a replicated
state machine.</p><p>Use the <a href=/docs/reference/generated/kubectl/kubectl-commands/#delete><code>kubectl delete</code></a> command to delete the
<code>zk</code> StatefulSet.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl delete statefulset zk
</span></span></code></pre></div><pre tabindex=0><code>statefulset.apps &#34;zk&#34; deleted
</code></pre><p>Watch the termination of the Pods in the StatefulSet.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get pods -w -l <span style=color:#b8860b>app</span><span style=color:#666>=</span>zk
</span></span></code></pre></div><p>When <code>zk-0</code> if fully terminated, use <code>CTRL-C</code> to terminate kubectl.</p><pre tabindex=0><code>zk-2      1/1       Terminating   0         9m
zk-0      1/1       Terminating   0         11m
zk-1      1/1       Terminating   0         10m
zk-2      0/1       Terminating   0         9m
zk-2      0/1       Terminating   0         9m
zk-2      0/1       Terminating   0         9m
zk-1      0/1       Terminating   0         10m
zk-1      0/1       Terminating   0         10m
zk-1      0/1       Terminating   0         10m
zk-0      0/1       Terminating   0         11m
zk-0      0/1       Terminating   0         11m
zk-0      0/1       Terminating   0         11m
</code></pre><p>Reapply the manifest in <code>zookeeper.yaml</code>.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl apply -f https://k8s.io/examples/application/zookeeper/zookeeper.yaml
</span></span></code></pre></div><p>This creates the <code>zk</code> StatefulSet object, but the other API objects in the manifest are not modified because they already exist.</p><p>Watch the StatefulSet controller recreate the StatefulSet's Pods.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get pods -w -l <span style=color:#b8860b>app</span><span style=color:#666>=</span>zk
</span></span></code></pre></div><p>Once the <code>zk-2</code> Pod is Running and Ready, use <code>CTRL-C</code> to terminate kubectl.</p><pre tabindex=0><code>NAME      READY     STATUS    RESTARTS   AGE
zk-0      0/1       Pending   0          0s
zk-0      0/1       Pending   0         0s
zk-0      0/1       ContainerCreating   0         0s
zk-0      0/1       Running   0         19s
zk-0      1/1       Running   0         40s
zk-1      0/1       Pending   0         0s
zk-1      0/1       Pending   0         0s
zk-1      0/1       ContainerCreating   0         0s
zk-1      0/1       Running   0         18s
zk-1      1/1       Running   0         40s
zk-2      0/1       Pending   0         0s
zk-2      0/1       Pending   0         0s
zk-2      0/1       ContainerCreating   0         0s
zk-2      0/1       Running   0         19s
zk-2      1/1       Running   0         40s
</code></pre><p>Use the command below to get the value you entered during the <a href=#sanity-testing-the-ensemble>sanity test</a>,
from the <code>zk-2</code> Pod.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl <span style=color:#a2f>exec</span> zk-2 zkCli.sh get /hello
</span></span></code></pre></div><p>Even though you terminated and recreated all of the Pods in the <code>zk</code> StatefulSet, the ensemble still serves the original value.</p><pre tabindex=0><code>WATCHER::

WatchedEvent state:SyncConnected type:None path:null
world
cZxid = 0x100000002
ctime = Thu Dec 08 15:13:30 UTC 2016
mZxid = 0x100000002
mtime = Thu Dec 08 15:13:30 UTC 2016
pZxid = 0x100000002
cversion = 0
dataVersion = 0
aclVersion = 0
ephemeralOwner = 0x0
dataLength = 5
numChildren = 0
</code></pre><p>The <code>volumeClaimTemplates</code> field of the <code>zk</code> StatefulSet's <code>spec</code> specifies a PersistentVolume provisioned for each Pod.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>volumeClaimTemplates</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>datadir<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>annotations</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>volume.alpha.kubernetes.io/storage-class</span>:<span style=color:#bbb> </span>anything<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>accessModes</span>:<span style=color:#bbb> </span>[<span style=color:#bbb> </span><span style=color:#b44>&#34;ReadWriteOnce&#34;</span><span style=color:#bbb> </span>]<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>resources</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>requests</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>storage</span>:<span style=color:#bbb> </span>20Gi<span style=color:#bbb>
</span></span></span></code></pre></div><p>The <code>StatefulSet</code> controller generates a <code>PersistentVolumeClaim</code> for each Pod in
the <code>StatefulSet</code>.</p><p>Use the following command to get the <code>StatefulSet</code>'s <code>PersistentVolumeClaims</code>.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get pvc -l <span style=color:#b8860b>app</span><span style=color:#666>=</span>zk
</span></span></code></pre></div><p>When the <code>StatefulSet</code> recreated its Pods, it remounts the Pods' PersistentVolumes.</p><pre tabindex=0><code>NAME           STATUS    VOLUME                                     CAPACITY   ACCESSMODES   AGE
datadir-zk-0   Bound     pvc-bed742cd-bcb1-11e6-994f-42010a800002   20Gi       RWO           1h
datadir-zk-1   Bound     pvc-bedd27d2-bcb1-11e6-994f-42010a800002   20Gi       RWO           1h
datadir-zk-2   Bound     pvc-bee0817e-bcb1-11e6-994f-42010a800002   20Gi       RWO           1h
</code></pre><p>The <code>volumeMounts</code> section of the <code>StatefulSet</code>'s container <code>template</code> mounts the PersistentVolumes in the ZooKeeper servers' data directories.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>volumeMounts</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>datadir<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>mountPath</span>:<span style=color:#bbb> </span>/var/lib/zookeeper<span style=color:#bbb>
</span></span></span></code></pre></div><p>When a Pod in the <code>zk</code> <code>StatefulSet</code> is (re)scheduled, it will always have the
same <code>PersistentVolume</code> mounted to the ZooKeeper server's data directory.
Even when the Pods are rescheduled, all the writes made to the ZooKeeper
servers' WALs, and all their snapshots, remain durable.</p><h2 id=ensuring-consistent-configuration>Ensuring consistent configuration</h2><p>As noted in the <a href=#facilitating-leader-election>Facilitating Leader Election</a> and
<a href=#achieving-consensus>Achieving Consensus</a> sections, the servers in a
ZooKeeper ensemble require consistent configuration to elect a leader
and form a quorum. They also require consistent configuration of the Zab protocol
in order for the protocol to work correctly over a network. In our example we
achieve consistent configuration by embedding the configuration directly into
the manifest.</p><p>Get the <code>zk</code> StatefulSet.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get sts zk -o yaml
</span></span></code></pre></div><pre tabindex=0><code>…
command:
      - sh
      - -c
      - &#34;start-zookeeper \
        --servers=3 \
        --data_dir=/var/lib/zookeeper/data \
        --data_log_dir=/var/lib/zookeeper/data/log \
        --conf_dir=/opt/zookeeper/conf \
        --client_port=2181 \
        --election_port=3888 \
        --server_port=2888 \
        --tick_time=2000 \
        --init_limit=10 \
        --sync_limit=5 \
        --heap=512M \
        --max_client_cnxns=60 \
        --snap_retain_count=3 \
        --purge_interval=12 \
        --max_session_timeout=40000 \
        --min_session_timeout=4000 \
        --log_level=INFO&#34;
…
</code></pre><p>The command used to start the ZooKeeper servers passed the configuration as command line parameter. You can also use environment variables to pass configuration to the ensemble.</p><h3 id=configuring-logging>Configuring logging</h3><p>One of the files generated by the <code>zkGenConfig.sh</code> script controls ZooKeeper's logging.
ZooKeeper uses <a href=https://logging.apache.org/log4j/2.x/>Log4j</a>, and, by default,
it uses a time and size based rolling file appender for its logging configuration.</p><p>Use the command below to get the logging configuration from one of Pods in the <code>zk</code> <code>StatefulSet</code>.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl <span style=color:#a2f>exec</span> zk-0 cat /usr/etc/zookeeper/log4j.properties
</span></span></code></pre></div><p>The logging configuration below will cause the ZooKeeper process to write all
of its logs to the standard output file stream.</p><pre tabindex=0><code>zookeeper.root.logger=CONSOLE
zookeeper.console.threshold=INFO
log4j.rootLogger=${zookeeper.root.logger}
log4j.appender.CONSOLE=org.apache.log4j.ConsoleAppender
log4j.appender.CONSOLE.Threshold=${zookeeper.console.threshold}
log4j.appender.CONSOLE.layout=org.apache.log4j.PatternLayout
log4j.appender.CONSOLE.layout.ConversionPattern=%d{ISO8601} [myid:%X{myid}] - %-5p [%t:%C{1}@%L] - %m%n
</code></pre><p>This is the simplest possible way to safely log inside the container.
Because the applications write logs to standard out, Kubernetes will handle log rotation for you.
Kubernetes also implements a sane retention policy that ensures application logs written to
standard out and standard error do not exhaust local storage media.</p><p>Use <a href=/docs/reference/generated/kubectl/kubectl-commands/#logs><code>kubectl logs</code></a> to retrieve the last 20 log lines from one of the Pods.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl logs zk-0 --tail <span style=color:#666>20</span>
</span></span></code></pre></div><p>You can view application logs written to standard out or standard error using <code>kubectl logs</code> and from the Kubernetes Dashboard.</p><pre tabindex=0><code>2016-12-06 19:34:16,236 [myid:1] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxn@827] - Processing ruok command from /127.0.0.1:52740
2016-12-06 19:34:16,237 [myid:1] - INFO  [Thread-1136:NIOServerCnxn@1008] - Closed socket connection for client /127.0.0.1:52740 (no session established for client)
2016-12-06 19:34:26,155 [myid:1] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxnFactory@192] - Accepted socket connection from /127.0.0.1:52749
2016-12-06 19:34:26,155 [myid:1] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxn@827] - Processing ruok command from /127.0.0.1:52749
2016-12-06 19:34:26,156 [myid:1] - INFO  [Thread-1137:NIOServerCnxn@1008] - Closed socket connection for client /127.0.0.1:52749 (no session established for client)
2016-12-06 19:34:26,222 [myid:1] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxnFactory@192] - Accepted socket connection from /127.0.0.1:52750
2016-12-06 19:34:26,222 [myid:1] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxn@827] - Processing ruok command from /127.0.0.1:52750
2016-12-06 19:34:26,226 [myid:1] - INFO  [Thread-1138:NIOServerCnxn@1008] - Closed socket connection for client /127.0.0.1:52750 (no session established for client)
2016-12-06 19:34:36,151 [myid:1] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxnFactory@192] - Accepted socket connection from /127.0.0.1:52760
2016-12-06 19:34:36,152 [myid:1] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxn@827] - Processing ruok command from /127.0.0.1:52760
2016-12-06 19:34:36,152 [myid:1] - INFO  [Thread-1139:NIOServerCnxn@1008] - Closed socket connection for client /127.0.0.1:52760 (no session established for client)
2016-12-06 19:34:36,230 [myid:1] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxnFactory@192] - Accepted socket connection from /127.0.0.1:52761
2016-12-06 19:34:36,231 [myid:1] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxn@827] - Processing ruok command from /127.0.0.1:52761
2016-12-06 19:34:36,231 [myid:1] - INFO  [Thread-1140:NIOServerCnxn@1008] - Closed socket connection for client /127.0.0.1:52761 (no session established for client)
2016-12-06 19:34:46,149 [myid:1] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxnFactory@192] - Accepted socket connection from /127.0.0.1:52767
2016-12-06 19:34:46,149 [myid:1] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxn@827] - Processing ruok command from /127.0.0.1:52767
2016-12-06 19:34:46,149 [myid:1] - INFO  [Thread-1141:NIOServerCnxn@1008] - Closed socket connection for client /127.0.0.1:52767 (no session established for client)
2016-12-06 19:34:46,230 [myid:1] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxnFactory@192] - Accepted socket connection from /127.0.0.1:52768
2016-12-06 19:34:46,230 [myid:1] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxn@827] - Processing ruok command from /127.0.0.1:52768
2016-12-06 19:34:46,230 [myid:1] - INFO  [Thread-1142:NIOServerCnxn@1008] - Closed socket connection for client /127.0.0.1:52768 (no session established for client)
</code></pre><p>Kubernetes integrates with many logging solutions. You can choose a logging solution
that best fits your cluster and applications. For cluster-level logging and aggregation,
consider deploying a <a href=/docs/concepts/cluster-administration/logging#sidecar-container-with-logging-agent>sidecar container</a> to rotate and ship your logs.</p><h3 id=configuring-a-non-privileged-user>Configuring a non-privileged user</h3><p>The best practices to allow an application to run as a privileged
user inside of a container are a matter of debate. If your organization requires
that applications run as a non-privileged user you can use a
<a href=/docs/tasks/configure-pod-container/security-context/>SecurityContext</a> to control the user that
the entry point runs as.</p><p>The <code>zk</code> <code>StatefulSet</code>'s Pod <code>template</code> contains a <code>SecurityContext</code>.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>securityContext</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>runAsUser</span>:<span style=color:#bbb> </span><span style=color:#666>1000</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>fsGroup</span>:<span style=color:#bbb> </span><span style=color:#666>1000</span><span style=color:#bbb>
</span></span></span></code></pre></div><p>In the Pods' containers, UID 1000 corresponds to the zookeeper user and GID 1000
corresponds to the zookeeper group.</p><p>Get the ZooKeeper process information from the <code>zk-0</code> Pod.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl <span style=color:#a2f>exec</span> zk-0 -- ps -elf
</span></span></code></pre></div><p>As the <code>runAsUser</code> field of the <code>securityContext</code> object is set to 1000,
instead of running as root, the ZooKeeper process runs as the zookeeper user.</p><pre tabindex=0><code>F S UID        PID  PPID  C PRI  NI ADDR SZ WCHAN  STIME TTY          TIME CMD
4 S zookeep+     1     0  0  80   0 -  1127 -      20:46 ?        00:00:00 sh -c zkGenConfig.sh &amp;&amp; zkServer.sh start-foreground
0 S zookeep+    27     1  0  80   0 - 1155556 -    20:46 ?        00:00:19 /usr/lib/jvm/java-8-openjdk-amd64/bin/java -Dzookeeper.log.dir=/var/log/zookeeper -Dzookeeper.root.logger=INFO,CONSOLE -cp /usr/bin/../build/classes:/usr/bin/../build/lib/*.jar:/usr/bin/../share/zookeeper/zookeeper-3.4.9.jar:/usr/bin/../share/zookeeper/slf4j-log4j12-1.6.1.jar:/usr/bin/../share/zookeeper/slf4j-api-1.6.1.jar:/usr/bin/../share/zookeeper/netty-3.10.5.Final.jar:/usr/bin/../share/zookeeper/log4j-1.2.16.jar:/usr/bin/../share/zookeeper/jline-0.9.94.jar:/usr/bin/../src/java/lib/*.jar:/usr/bin/../etc/zookeeper: -Xmx2G -Xms2G -Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.local.only=false org.apache.zookeeper.server.quorum.QuorumPeerMain /usr/bin/../etc/zookeeper/zoo.cfg
</code></pre><p>By default, when the Pod's PersistentVolumes is mounted to the ZooKeeper server's data directory, it is only accessible by the root user. This configuration prevents the ZooKeeper process from writing to its WAL and storing its snapshots.</p><p>Use the command below to get the file permissions of the ZooKeeper data directory on the <code>zk-0</code> Pod.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl <span style=color:#a2f>exec</span> -ti zk-0 -- ls -ld /var/lib/zookeeper/data
</span></span></code></pre></div><p>Because the <code>fsGroup</code> field of the <code>securityContext</code> object is set to 1000, the ownership of the Pods' PersistentVolumes is set to the zookeeper group, and the ZooKeeper process is able to read and write its data.</p><pre tabindex=0><code>drwxr-sr-x 3 zookeeper zookeeper 4096 Dec  5 20:45 /var/lib/zookeeper/data
</code></pre><h2 id=managing-the-zookeeper-process>Managing the ZooKeeper process</h2><p>The <a href=https://zookeeper.apache.org/doc/current/zookeeperAdmin.html#sc_supervision>ZooKeeper documentation</a>
mentions that "You will want to have a supervisory process that
manages each of your ZooKeeper server processes (JVM)." Utilizing a watchdog
(supervisory process) to restart failed processes in a distributed system is a
common pattern. When deploying an application in Kubernetes, rather than using
an external utility as a supervisory process, you should use Kubernetes as the
watchdog for your application.</p><h3 id=updating-the-ensemble>Updating the ensemble</h3><p>The <code>zk</code> <code>StatefulSet</code> is configured to use the <code>RollingUpdate</code> update strategy.</p><p>You can use <code>kubectl patch</code> to update the number of <code>cpus</code> allocated to the servers.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl patch sts zk --type<span style=color:#666>=</span><span style=color:#b44>&#39;json&#39;</span> -p<span style=color:#666>=</span><span style=color:#b44>&#39;[{&#34;op&#34;: &#34;replace&#34;, &#34;path&#34;: &#34;/spec/template/spec/containers/0/resources/requests/cpu&#34;, &#34;value&#34;:&#34;0.3&#34;}]&#39;</span>
</span></span></code></pre></div><pre tabindex=0><code>statefulset.apps/zk patched
</code></pre><p>Use <code>kubectl rollout status</code> to watch the status of the update.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl rollout status sts/zk
</span></span></code></pre></div><pre tabindex=0><code>waiting for statefulset rolling update to complete 0 pods at revision zk-5db4499664...
Waiting for 1 pods to be ready...
Waiting for 1 pods to be ready...
waiting for statefulset rolling update to complete 1 pods at revision zk-5db4499664...
Waiting for 1 pods to be ready...
Waiting for 1 pods to be ready...
waiting for statefulset rolling update to complete 2 pods at revision zk-5db4499664...
Waiting for 1 pods to be ready...
Waiting for 1 pods to be ready...
statefulset rolling update complete 3 pods at revision zk-5db4499664...
</code></pre><p>This terminates the Pods, one at a time, in reverse ordinal order, and recreates them with the new configuration. This ensures that quorum is maintained during a rolling update.</p><p>Use the <code>kubectl rollout history</code> command to view a history or previous configurations.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl rollout <span style=color:#a2f>history</span> sts/zk
</span></span></code></pre></div><p>The output is similar to this:</p><pre tabindex=0><code>statefulsets &#34;zk&#34;
REVISION
1
2
</code></pre><p>Use the <code>kubectl rollout undo</code> command to roll back the modification.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl rollout undo sts/zk
</span></span></code></pre></div><p>The output is similar to this:</p><pre tabindex=0><code>statefulset.apps/zk rolled back
</code></pre><h3 id=handling-process-failure>Handling process failure</h3><p><a href=/docs/concepts/workloads/pods/pod-lifecycle/#restart-policy>Restart Policies</a> control how
Kubernetes handles process failures for the entry point of the container in a Pod.
For Pods in a <code>StatefulSet</code>, the only appropriate <code>RestartPolicy</code> is Always, and this
is the default value. For stateful applications you should <strong>never</strong> override
the default policy.</p><p>Use the following command to examine the process tree for the ZooKeeper server running in the <code>zk-0</code> Pod.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl <span style=color:#a2f>exec</span> zk-0 -- ps -ef
</span></span></code></pre></div><p>The command used as the container's entry point has PID 1, and
the ZooKeeper process, a child of the entry point, has PID 27.</p><pre tabindex=0><code>UID        PID  PPID  C STIME TTY          TIME CMD
zookeep+     1     0  0 15:03 ?        00:00:00 sh -c zkGenConfig.sh &amp;&amp; zkServer.sh start-foreground
zookeep+    27     1  0 15:03 ?        00:00:03 /usr/lib/jvm/java-8-openjdk-amd64/bin/java -Dzookeeper.log.dir=/var/log/zookeeper -Dzookeeper.root.logger=INFO,CONSOLE -cp /usr/bin/../build/classes:/usr/bin/../build/lib/*.jar:/usr/bin/../share/zookeeper/zookeeper-3.4.9.jar:/usr/bin/../share/zookeeper/slf4j-log4j12-1.6.1.jar:/usr/bin/../share/zookeeper/slf4j-api-1.6.1.jar:/usr/bin/../share/zookeeper/netty-3.10.5.Final.jar:/usr/bin/../share/zookeeper/log4j-1.2.16.jar:/usr/bin/../share/zookeeper/jline-0.9.94.jar:/usr/bin/../src/java/lib/*.jar:/usr/bin/../etc/zookeeper: -Xmx2G -Xms2G -Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.local.only=false org.apache.zookeeper.server.quorum.QuorumPeerMain /usr/bin/../etc/zookeeper/zoo.cfg
</code></pre><p>In another terminal watch the Pods in the <code>zk</code> <code>StatefulSet</code> with the following command.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get pod -w -l <span style=color:#b8860b>app</span><span style=color:#666>=</span>zk
</span></span></code></pre></div><p>In another terminal, terminate the ZooKeeper process in Pod <code>zk-0</code> with the following command.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl <span style=color:#a2f>exec</span> zk-0 -- pkill java
</span></span></code></pre></div><p>The termination of the ZooKeeper process caused its parent process to terminate. Because the <code>RestartPolicy</code> of the container is Always, it restarted the parent process.</p><pre tabindex=0><code>NAME      READY     STATUS    RESTARTS   AGE
zk-0      1/1       Running   0          21m
zk-1      1/1       Running   0          20m
zk-2      1/1       Running   0          19m
NAME      READY     STATUS    RESTARTS   AGE
zk-0      0/1       Error     0          29m
zk-0      0/1       Running   1         29m
zk-0      1/1       Running   1         29m
</code></pre><p>If your application uses a script (such as <code>zkServer.sh</code>) to launch the process
that implements the application's business logic, the script must terminate with the
child process. This ensures that Kubernetes will restart the application's
container when the process implementing the application's business logic fails.</p><h3 id=testing-for-liveness>Testing for liveness</h3><p>Configuring your application to restart failed processes is not enough to
keep a distributed system healthy. There are scenarios where
a system's processes can be both alive and unresponsive, or otherwise
unhealthy. You should use liveness probes to notify Kubernetes
that your application's processes are unhealthy and it should restart them.</p><p>The Pod <code>template</code> for the <code>zk</code> <code>StatefulSet</code> specifies a liveness probe.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>livenessProbe</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>exec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>command</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- sh<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- -c<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- <span style=color:#b44>&#34;zookeeper-ready 2181&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>initialDelaySeconds</span>:<span style=color:#bbb> </span><span style=color:#666>15</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>timeoutSeconds</span>:<span style=color:#bbb> </span><span style=color:#666>5</span><span style=color:#bbb>
</span></span></span></code></pre></div><p>The probe calls a bash script that uses the ZooKeeper <code>ruok</code> four letter
word to test the server's health.</p><pre tabindex=0><code>OK=$(echo ruok | nc 127.0.0.1 $1)
if [ &#34;$OK&#34; == &#34;imok&#34; ]; then
    exit 0
else
    exit 1
fi
</code></pre><p>In one terminal window, use the following command to watch the Pods in the <code>zk</code> StatefulSet.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get pod -w -l <span style=color:#b8860b>app</span><span style=color:#666>=</span>zk
</span></span></code></pre></div><p>In another window, using the following command to delete the <code>zookeeper-ready</code> script from the file system of Pod <code>zk-0</code>.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl <span style=color:#a2f>exec</span> zk-0 -- rm /opt/zookeeper/bin/zookeeper-ready
</span></span></code></pre></div><p>When the liveness probe for the ZooKeeper process fails, Kubernetes will
automatically restart the process for you, ensuring that unhealthy processes in
the ensemble are restarted.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get pod -w -l <span style=color:#b8860b>app</span><span style=color:#666>=</span>zk
</span></span></code></pre></div><pre tabindex=0><code>NAME      READY     STATUS    RESTARTS   AGE
zk-0      1/1       Running   0          1h
zk-1      1/1       Running   0          1h
zk-2      1/1       Running   0          1h
NAME      READY     STATUS    RESTARTS   AGE
zk-0      0/1       Running   0          1h
zk-0      0/1       Running   1         1h
zk-0      1/1       Running   1         1h
</code></pre><h3 id=testing-for-readiness>Testing for readiness</h3><p>Readiness is not the same as liveness. If a process is alive, it is scheduled
and healthy. If a process is ready, it is able to process input. Liveness is
a necessary, but not sufficient, condition for readiness. There are cases,
particularly during initialization and termination, when a process can be
alive but not ready.</p><p>If you specify a readiness probe, Kubernetes will ensure that your application's
processes will not receive network traffic until their readiness checks pass.</p><p>For a ZooKeeper server, liveness implies readiness. Therefore, the readiness
probe from the <code>zookeeper.yaml</code> manifest is identical to the liveness probe.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>readinessProbe</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>exec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>command</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- sh<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- -c<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- <span style=color:#b44>&#34;zookeeper-ready 2181&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>initialDelaySeconds</span>:<span style=color:#bbb> </span><span style=color:#666>15</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>timeoutSeconds</span>:<span style=color:#bbb> </span><span style=color:#666>5</span><span style=color:#bbb>
</span></span></span></code></pre></div><p>Even though the liveness and readiness probes are identical, it is important
to specify both. This ensures that only healthy servers in the ZooKeeper
ensemble receive network traffic.</p><h2 id=tolerating-node-failure>Tolerating Node failure</h2><p>ZooKeeper needs a quorum of servers to successfully commit mutations
to data. For a three server ensemble, two servers must be healthy for
writes to succeed. In quorum based systems, members are deployed across failure
domains to ensure availability. To avoid an outage, due to the loss of an
individual machine, best practices preclude co-locating multiple instances of the
application on the same machine.</p><p>By default, Kubernetes may co-locate Pods in a <code>StatefulSet</code> on the same node.
For the three server ensemble you created, if two servers are on the same node, and that node fails,
the clients of your ZooKeeper service will experience an outage until at least one of the Pods can be rescheduled.</p><p>You should always provision additional capacity to allow the processes of critical
systems to be rescheduled in the event of node failures. If you do so, then the
outage will only last until the Kubernetes scheduler reschedules one of the ZooKeeper
servers. However, if you want your service to tolerate node failures with no downtime,
you should set <code>podAntiAffinity</code>.</p><p>Use the command below to get the nodes for Pods in the <code>zk</code> <code>StatefulSet</code>.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span><span style=color:#a2f;font-weight:700>for</span> i in <span style=color:#666>0</span> <span style=color:#666>1</span> 2; <span style=color:#a2f;font-weight:700>do</span> kubectl get pod zk-<span style=color:#b8860b>$i</span> --template <span style=color:#666>{{</span>.spec.nodeName<span style=color:#666>}}</span>; <span style=color:#a2f>echo</span> <span style=color:#b44>&#34;&#34;</span>; <span style=color:#a2f;font-weight:700>done</span>
</span></span></code></pre></div><p>All of the Pods in the <code>zk</code> <code>StatefulSet</code> are deployed on different nodes.</p><pre tabindex=0><code>kubernetes-node-cxpk
kubernetes-node-a5aq
kubernetes-node-2g2d
</code></pre><p>This is because the Pods in the <code>zk</code> <code>StatefulSet</code> have a <code>PodAntiAffinity</code> specified.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>affinity</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>podAntiAffinity</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>requiredDuringSchedulingIgnoredDuringExecution</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- <span style=color:green;font-weight:700>labelSelector</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>matchExpressions</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>            </span>- <span style=color:green;font-weight:700>key</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;app&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>              </span><span style=color:green;font-weight:700>operator</span>:<span style=color:#bbb> </span>In<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>              </span><span style=color:green;font-weight:700>values</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>                </span>- zk<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>topologyKey</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;kubernetes.io/hostname&#34;</span><span style=color:#bbb>
</span></span></span></code></pre></div><p>The <code>requiredDuringSchedulingIgnoredDuringExecution</code> field tells the
Kubernetes Scheduler that it should never co-locate two Pods which have <code>app</code> label
as <code>zk</code> in the domain defined by the <code>topologyKey</code>. The <code>topologyKey</code>
<code>kubernetes.io/hostname</code> indicates that the domain is an individual node. Using
different rules, labels, and selectors, you can extend this technique to spread
your ensemble across physical, network, and power failure domains.</p><h2 id=surviving-maintenance>Surviving maintenance</h2><p>In this section you will cordon and drain nodes. If you are using this tutorial
on a shared cluster, be sure that this will not adversely affect other tenants.</p><p>The previous section showed you how to spread your Pods across nodes to survive
unplanned node failures, but you also need to plan for temporary node failures
that occur due to planned maintenance.</p><p>Use this command to get the nodes in your cluster.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get nodes
</span></span></code></pre></div><p>This tutorial assumes a cluster with at least four nodes. If the cluster has more than four, use <a href=/docs/reference/generated/kubectl/kubectl-commands/#cordon><code>kubectl cordon</code></a> to cordon all but four nodes. Constraining to four nodes will ensure Kubernetes encounters affinity and PodDisruptionBudget constraints when scheduling zookeeper Pods in the following maintenance simulation.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl cordon &lt;node-name&gt;
</span></span></code></pre></div><p>Use this command to get the <code>zk-pdb</code> <code>PodDisruptionBudget</code>.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get pdb zk-pdb
</span></span></code></pre></div><p>The <code>max-unavailable</code> field indicates to Kubernetes that at most one Pod from
<code>zk</code> <code>StatefulSet</code> can be unavailable at any time.</p><pre tabindex=0><code>NAME      MIN-AVAILABLE   MAX-UNAVAILABLE   ALLOWED-DISRUPTIONS   AGE
zk-pdb    N/A             1                 1
</code></pre><p>In one terminal, use this command to watch the Pods in the <code>zk</code> <code>StatefulSet</code>.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get pods -w -l <span style=color:#b8860b>app</span><span style=color:#666>=</span>zk
</span></span></code></pre></div><p>In another terminal, use this command to get the nodes that the Pods are currently scheduled on.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span><span style=color:#a2f;font-weight:700>for</span> i in <span style=color:#666>0</span> <span style=color:#666>1</span> 2; <span style=color:#a2f;font-weight:700>do</span> kubectl get pod zk-<span style=color:#b8860b>$i</span> --template <span style=color:#666>{{</span>.spec.nodeName<span style=color:#666>}}</span>; <span style=color:#a2f>echo</span> <span style=color:#b44>&#34;&#34;</span>; <span style=color:#a2f;font-weight:700>done</span>
</span></span></code></pre></div><p>The output is similar to this:</p><pre tabindex=0><code>kubernetes-node-pb41
kubernetes-node-ixsl
kubernetes-node-i4c4
</code></pre><p>Use <a href=/docs/reference/generated/kubectl/kubectl-commands/#drain><code>kubectl drain</code></a> to cordon and
drain the node on which the <code>zk-0</code> Pod is scheduled.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl drain <span style=color:#a2f;font-weight:700>$(</span>kubectl get pod zk-0 --template <span style=color:#666>{{</span>.spec.nodeName<span style=color:#666>}}</span><span style=color:#a2f;font-weight:700>)</span> --ignore-daemonsets --force --delete-emptydir-data
</span></span></code></pre></div><p>The output is similar to this:</p><pre tabindex=0><code>node &#34;kubernetes-node-pb41&#34; cordoned

WARNING: Deleting pods not managed by ReplicationController, ReplicaSet, Job, or DaemonSet: fluentd-cloud-logging-kubernetes-node-pb41, kube-proxy-kubernetes-node-pb41; Ignoring DaemonSet-managed pods: node-problem-detector-v0.1-o5elz
pod &#34;zk-0&#34; deleted
node &#34;kubernetes-node-pb41&#34; drained
</code></pre><p>As there are four nodes in your cluster, <code>kubectl drain</code>, succeeds and the
<code>zk-0</code> is rescheduled to another node.</p><pre tabindex=0><code>NAME      READY     STATUS    RESTARTS   AGE
zk-0      1/1       Running   2          1h
zk-1      1/1       Running   0          1h
zk-2      1/1       Running   0          1h
NAME      READY     STATUS        RESTARTS   AGE
zk-0      1/1       Terminating   2          2h
zk-0      0/1       Terminating   2         2h
zk-0      0/1       Terminating   2         2h
zk-0      0/1       Terminating   2         2h
zk-0      0/1       Pending   0         0s
zk-0      0/1       Pending   0         0s
zk-0      0/1       ContainerCreating   0         0s
zk-0      0/1       Running   0         51s
zk-0      1/1       Running   0         1m
</code></pre><p>Keep watching the <code>StatefulSet</code>'s Pods in the first terminal and drain the node on which
<code>zk-1</code> is scheduled.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl drain <span style=color:#a2f;font-weight:700>$(</span>kubectl get pod zk-1 --template <span style=color:#666>{{</span>.spec.nodeName<span style=color:#666>}}</span><span style=color:#a2f;font-weight:700>)</span> --ignore-daemonsets --force --delete-emptydir-data
</span></span></code></pre></div><p>The output is similar to this:</p><pre tabindex=0><code>&#34;kubernetes-node-ixsl&#34; cordoned
WARNING: Deleting pods not managed by ReplicationController, ReplicaSet, Job, or DaemonSet: fluentd-cloud-logging-kubernetes-node-ixsl, kube-proxy-kubernetes-node-ixsl; Ignoring DaemonSet-managed pods: node-problem-detector-v0.1-voc74
pod &#34;zk-1&#34; deleted
node &#34;kubernetes-node-ixsl&#34; drained
</code></pre><p>The <code>zk-1</code> Pod cannot be scheduled because the <code>zk</code> <code>StatefulSet</code> contains a <code>PodAntiAffinity</code> rule preventing
co-location of the Pods, and as only two nodes are schedulable, the Pod will remain in a Pending state.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get pods -w -l <span style=color:#b8860b>app</span><span style=color:#666>=</span>zk
</span></span></code></pre></div><p>The output is similar to this:</p><pre tabindex=0><code>NAME      READY     STATUS    RESTARTS   AGE
zk-0      1/1       Running   2          1h
zk-1      1/1       Running   0          1h
zk-2      1/1       Running   0          1h
NAME      READY     STATUS        RESTARTS   AGE
zk-0      1/1       Terminating   2          2h
zk-0      0/1       Terminating   2         2h
zk-0      0/1       Terminating   2         2h
zk-0      0/1       Terminating   2         2h
zk-0      0/1       Pending   0         0s
zk-0      0/1       Pending   0         0s
zk-0      0/1       ContainerCreating   0         0s
zk-0      0/1       Running   0         51s
zk-0      1/1       Running   0         1m
zk-1      1/1       Terminating   0         2h
zk-1      0/1       Terminating   0         2h
zk-1      0/1       Terminating   0         2h
zk-1      0/1       Terminating   0         2h
zk-1      0/1       Pending   0         0s
zk-1      0/1       Pending   0         0s
</code></pre><p>Continue to watch the Pods of the StatefulSet, and drain the node on which
<code>zk-2</code> is scheduled.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl drain <span style=color:#a2f;font-weight:700>$(</span>kubectl get pod zk-2 --template <span style=color:#666>{{</span>.spec.nodeName<span style=color:#666>}}</span><span style=color:#a2f;font-weight:700>)</span> --ignore-daemonsets --force --delete-emptydir-data
</span></span></code></pre></div><p>The output is similar to this:</p><pre tabindex=0><code>node &#34;kubernetes-node-i4c4&#34; cordoned

WARNING: Deleting pods not managed by ReplicationController, ReplicaSet, Job, or DaemonSet: fluentd-cloud-logging-kubernetes-node-i4c4, kube-proxy-kubernetes-node-i4c4; Ignoring DaemonSet-managed pods: node-problem-detector-v0.1-dyrog
WARNING: Ignoring DaemonSet-managed pods: node-problem-detector-v0.1-dyrog; Deleting pods not managed by ReplicationController, ReplicaSet, Job, or DaemonSet: fluentd-cloud-logging-kubernetes-node-i4c4, kube-proxy-kubernetes-node-i4c4
There are pending pods when an error occurred: Cannot evict pod as it would violate the pod&#39;s disruption budget.
pod/zk-2
</code></pre><p>Use <code>CTRL-C</code> to terminate kubectl.</p><p>You cannot drain the third node because evicting <code>zk-2</code> would violate <code>zk-budget</code>. However, the node will remain cordoned.</p><p>Use <code>zkCli.sh</code> to retrieve the value you entered during the sanity test from <code>zk-0</code>.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl <span style=color:#a2f>exec</span> zk-0 zkCli.sh get /hello
</span></span></code></pre></div><p>The service is still available because its <code>PodDisruptionBudget</code> is respected.</p><pre tabindex=0><code>WatchedEvent state:SyncConnected type:None path:null
world
cZxid = 0x200000002
ctime = Wed Dec 07 00:08:59 UTC 2016
mZxid = 0x200000002
mtime = Wed Dec 07 00:08:59 UTC 2016
pZxid = 0x200000002
cversion = 0
dataVersion = 0
aclVersion = 0
ephemeralOwner = 0x0
dataLength = 5
numChildren = 0
</code></pre><p>Use <a href=/docs/reference/generated/kubectl/kubectl-commands/#uncordon><code>kubectl uncordon</code></a> to uncordon the first node.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl uncordon kubernetes-node-pb41
</span></span></code></pre></div><p>The output is similar to this:</p><pre tabindex=0><code>node &#34;kubernetes-node-pb41&#34; uncordoned
</code></pre><p><code>zk-1</code> is rescheduled on this node. Wait until <code>zk-1</code> is Running and Ready.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get pods -w -l <span style=color:#b8860b>app</span><span style=color:#666>=</span>zk
</span></span></code></pre></div><p>The output is similar to this:</p><pre tabindex=0><code>NAME      READY     STATUS    RESTARTS   AGE
zk-0      1/1       Running   2          1h
zk-1      1/1       Running   0          1h
zk-2      1/1       Running   0          1h
NAME      READY     STATUS        RESTARTS   AGE
zk-0      1/1       Terminating   2          2h
zk-0      0/1       Terminating   2         2h
zk-0      0/1       Terminating   2         2h
zk-0      0/1       Terminating   2         2h
zk-0      0/1       Pending   0         0s
zk-0      0/1       Pending   0         0s
zk-0      0/1       ContainerCreating   0         0s
zk-0      0/1       Running   0         51s
zk-0      1/1       Running   0         1m
zk-1      1/1       Terminating   0         2h
zk-1      0/1       Terminating   0         2h
zk-1      0/1       Terminating   0         2h
zk-1      0/1       Terminating   0         2h
zk-1      0/1       Pending   0         0s
zk-1      0/1       Pending   0         0s
zk-1      0/1       Pending   0         12m
zk-1      0/1       ContainerCreating   0         12m
zk-1      0/1       Running   0         13m
zk-1      1/1       Running   0         13m
</code></pre><p>Attempt to drain the node on which <code>zk-2</code> is scheduled.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl drain <span style=color:#a2f;font-weight:700>$(</span>kubectl get pod zk-2 --template <span style=color:#666>{{</span>.spec.nodeName<span style=color:#666>}}</span><span style=color:#a2f;font-weight:700>)</span> --ignore-daemonsets --force --delete-emptydir-data
</span></span></code></pre></div><p>The output is similar to this:</p><pre tabindex=0><code>node &#34;kubernetes-node-i4c4&#34; already cordoned
WARNING: Deleting pods not managed by ReplicationController, ReplicaSet, Job, or DaemonSet: fluentd-cloud-logging-kubernetes-node-i4c4, kube-proxy-kubernetes-node-i4c4; Ignoring DaemonSet-managed pods: node-problem-detector-v0.1-dyrog
pod &#34;heapster-v1.2.0-2604621511-wht1r&#34; deleted
pod &#34;zk-2&#34; deleted
node &#34;kubernetes-node-i4c4&#34; drained
</code></pre><p>This time <code>kubectl drain</code> succeeds.</p><p>Uncordon the second node to allow <code>zk-2</code> to be rescheduled.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl uncordon kubernetes-node-ixsl
</span></span></code></pre></div><p>The output is similar to this:</p><pre tabindex=0><code>node &#34;kubernetes-node-ixsl&#34; uncordoned
</code></pre><p>You can use <code>kubectl drain</code> in conjunction with <code>PodDisruptionBudgets</code> to ensure that your services remain available during maintenance.
If drain is used to cordon nodes and evict pods prior to taking the node offline for maintenance,
services that express a disruption budget will have that budget respected.
You should always allocate additional capacity for critical services so that their Pods can be immediately rescheduled.</p><h2 id=cleaning-up>Cleaning up</h2><ul><li>Use <code>kubectl uncordon</code> to uncordon all the nodes in your cluster.</li><li>You must delete the persistent storage media for the PersistentVolumes used in this tutorial.
Follow the necessary steps, based on your environment, storage configuration,
and provisioning method, to ensure that all storage is reclaimed.</li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-97489f0aa8ac2df31a0d6b444a7bde62>7 - Services</h1></div><div class=td-content><h1 id=pg-bc0a2760d2865e91c501bc2467cd1a4b>7.1 - Connecting Applications with Services</h1><h2 id=the-kubernetes-model-for-connecting-containers>The Kubernetes model for connecting containers</h2><p>Now that you have a continuously running, replicated application you can expose it on a network.</p><p>Kubernetes assumes that pods can communicate with other pods, regardless of which host they land on. Kubernetes gives every pod its own cluster-private IP address, so you do not need to explicitly create links between pods or map container ports to host ports. This means that containers within a Pod can all reach each other's ports on localhost, and all pods in a cluster can see each other without NAT. The rest of this document elaborates on how you can run reliable services on such a networking model.</p><p>This tutorial uses a simple nginx web server to demonstrate the concept.</p><h2 id=exposing-pods-to-the-cluster>Exposing pods to the cluster</h2><p>We did this in a previous example, but let's do it once again and focus on the networking perspective.
Create an nginx Pod, and note that it has a container port specification:</p><div class=highlight><div class=copy-code-icon style=text-align:right><a href=https://raw.githubusercontent.com/kubernetes/website/main/content/en/examples/service/networking/run-my-nginx.yaml download=service/networking/run-my-nginx.yaml><code>service/networking/run-my-nginx.yaml</code></a>
<img src=/images/copycode.svg style=max-height:24px;cursor:pointer onclick='copyCode("service-networking-run-my-nginx-yaml")' title="Copy service/networking/run-my-nginx.yaml to clipboard"></img></div><div class=includecode id=service-networking-run-my-nginx-yaml><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>apps/v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Deployment<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>my-nginx<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>selector</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>matchLabels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>run</span>:<span style=color:#bbb> </span>my-nginx<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>replicas</span>:<span style=color:#bbb> </span><span style=color:#666>2</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>template</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>labels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>run</span>:<span style=color:#bbb> </span>my-nginx<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>my-nginx<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>nginx<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>ports</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span>- <span style=color:green;font-weight:700>containerPort</span>:<span style=color:#bbb> </span><span style=color:#666>80</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>
</span></span></span></code></pre></div></div></div><p>This makes it accessible from any node in your cluster. Check the nodes the Pod is running on:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl apply -f ./run-my-nginx.yaml
</span></span><span style=display:flex><span>kubectl get pods -l <span style=color:#b8860b>run</span><span style=color:#666>=</span>my-nginx -o wide
</span></span></code></pre></div><pre tabindex=0><code>NAME                        READY     STATUS    RESTARTS   AGE       IP            NODE
my-nginx-3800858182-jr4a2   1/1       Running   0          13s       10.244.3.4    kubernetes-minion-905m
my-nginx-3800858182-kna2y   1/1       Running   0          13s       10.244.2.5    kubernetes-minion-ljyd
</code></pre><p>Check your pods' IPs:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get pods -l <span style=color:#b8860b>run</span><span style=color:#666>=</span>my-nginx -o custom-columns<span style=color:#666>=</span>POD_IP:.status.podIPs
</span></span><span style=display:flex><span>    POD_IP
</span></span><span style=display:flex><span>    <span style=color:#666>[</span>map<span style=color:#666>[</span>ip:10.244.3.4<span style=color:#666>]]</span>
</span></span><span style=display:flex><span>    <span style=color:#666>[</span>map<span style=color:#666>[</span>ip:10.244.2.5<span style=color:#666>]]</span>
</span></span></code></pre></div><p>You should be able to ssh into any node in your cluster and use a tool such as <code>curl</code> to make queries against both IPs. Note that the containers are <em>not</em> using port 80 on the node, nor are there any special NAT rules to route traffic to the pod. This means you can run multiple nginx pods on the same node all using the same <code>containerPort</code>, and access them from any other pod or node in your cluster using the assigned IP address for the Service. If you want to arrange for a specific port on the host Node to be forwarded to backing Pods, you can - but the networking model should mean that you do not need to do so.</p><p>You can read more about the <a href=/docs/concepts/cluster-administration/networking/#the-kubernetes-network-model>Kubernetes Networking Model</a> if you're curious.</p><h2 id=creating-a-service>Creating a Service</h2><p>So we have pods running nginx in a flat, cluster wide, address space. In theory, you could talk to these pods directly, but what happens when a node dies? The pods die with it, and the Deployment will create new ones, with different IPs. This is the problem a Service solves.</p><p>A Kubernetes Service is an abstraction which defines a logical set of Pods running somewhere in your cluster, that all provide the same functionality. When created, each Service is assigned a unique IP address (also called clusterIP). This address is tied to the lifespan of the Service, and will not change while the Service is alive. Pods can be configured to talk to the Service, and know that communication to the Service will be automatically load-balanced out to some pod that is a member of the Service.</p><p>You can create a Service for your 2 nginx replicas with <code>kubectl expose</code>:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl expose deployment/my-nginx
</span></span></code></pre></div><pre tabindex=0><code>service/my-nginx exposed
</code></pre><p>This is equivalent to <code>kubectl apply -f</code> the following yaml:</p><div class=highlight><div class=copy-code-icon style=text-align:right><a href=https://raw.githubusercontent.com/kubernetes/website/main/content/en/examples/service/networking/nginx-svc.yaml download=service/networking/nginx-svc.yaml><code>service/networking/nginx-svc.yaml</code></a>
<img src=/images/copycode.svg style=max-height:24px;cursor:pointer onclick='copyCode("service-networking-nginx-svc-yaml")' title="Copy service/networking/nginx-svc.yaml to clipboard"></img></div><div class=includecode id=service-networking-nginx-svc-yaml><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Service<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>my-nginx<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>labels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>run</span>:<span style=color:#bbb> </span>my-nginx<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>ports</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>port</span>:<span style=color:#bbb> </span><span style=color:#666>80</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>protocol</span>:<span style=color:#bbb> </span>TCP<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>selector</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>run</span>:<span style=color:#bbb> </span>my-nginx<span style=color:#bbb>
</span></span></span></code></pre></div></div></div><p>This specification will create a Service which targets TCP port 80 on any Pod
with the <code>run: my-nginx</code> label, and expose it on an abstracted Service port
(<code>targetPort</code>: is the port the container accepts traffic on, <code>port</code>: is the
abstracted Service port, which can be any port other pods use to access the
Service).
View <a href=/docs/reference/generated/kubernetes-api/v1.25/#service-v1-core>Service</a>
API object to see the list of supported fields in service definition.
Check your Service:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get svc my-nginx
</span></span></code></pre></div><pre tabindex=0><code>NAME       TYPE        CLUSTER-IP     EXTERNAL-IP   PORT(S)   AGE
my-nginx   ClusterIP   10.0.162.149   &lt;none&gt;        80/TCP    21s
</code></pre><p>As mentioned previously, a Service is backed by a group of Pods. These Pods are
exposed through
<a class=glossary-tooltip title='A way to group network endpoints together with Kubernetes resources.' data-toggle=tooltip data-placement=top href=/docs/concepts/services-networking/endpoint-slices/ target=_blank aria-label=EndpointSlices>EndpointSlices</a>.
The Service's selector will be evaluated continuously and the results will be POSTed
to an EndpointSlice that is connected to the Service using a
<a class=glossary-tooltip title='Tags objects with identifying attributes that are meaningful and relevant to users.' data-toggle=tooltip data-placement=top href=/docs/concepts/overview/working-with-objects/labels target=_blank aria-label=labels>labels</a>.
When a Pod dies, it is automatically removed from the EndpointSlices that contain it
as an endpoint. New Pods that match the Service's selector will automatically get added
to an EndpointSlice for that Service.
Check the endpoints, and note that the IPs are the same as the Pods created in
the first step:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl describe svc my-nginx
</span></span></code></pre></div><pre tabindex=0><code>Name:                my-nginx
Namespace:           default
Labels:              run=my-nginx
Annotations:         &lt;none&gt;
Selector:            run=my-nginx
Type:                ClusterIP
IP:                  10.0.162.149
Port:                &lt;unset&gt; 80/TCP
Endpoints:           10.244.2.5:80,10.244.3.4:80
Session Affinity:    None
Events:              &lt;none&gt;
</code></pre><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get endpointslices -l kubernetes.io/service-name<span style=color:#666>=</span>my-nginx
</span></span></code></pre></div><pre tabindex=0><code>NAME             ADDRESSTYPE   PORTS   ENDPOINTS               AGE
my-nginx-7vzhx   IPv4          80      10.244.2.5,10.244.3.4   21s
</code></pre><p>You should now be able to curl the nginx Service on <code>&lt;CLUSTER-IP>:&lt;PORT></code> from
any node in your cluster. Note that the Service IP is completely virtual, it
never hits the wire. If you're curious about how this works you can read more
about the <a href=/docs/concepts/services-networking/service/#virtual-ips-and-service-proxies>service proxy</a>.</p><h2 id=accessing-the-service>Accessing the Service</h2><p>Kubernetes supports 2 primary modes of finding a Service - environment variables
and DNS. The former works out of the box while the latter requires the
<a href=https://releases.k8s.io/v1.25.0/cluster/addons/dns/coredns>CoreDNS cluster addon</a>.<div class="alert alert-info note callout" role=alert><strong>Note:</strong> If the service environment variables are not desired (because possible clashing with expected program ones,
too many variables to process, only using DNS, etc) you can disable this mode by setting the <code>enableServiceLinks</code>
flag to <code>false</code> on the <a href=/docs/reference/generated/kubernetes-api/v1.25/#pod-v1-core>pod spec</a>.</div></p><h3 id=environment-variables>Environment Variables</h3><p>When a Pod runs on a Node, the kubelet adds a set of environment variables for
each active Service. This introduces an ordering problem. To see why, inspect
the environment of your running nginx Pods (your Pod name will be different):</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl <span style=color:#a2f>exec</span> my-nginx-3800858182-jr4a2 -- printenv | grep SERVICE
</span></span></code></pre></div><pre tabindex=0><code>KUBERNETES_SERVICE_HOST=10.0.0.1
KUBERNETES_SERVICE_PORT=443
KUBERNETES_SERVICE_PORT_HTTPS=443
</code></pre><p>Note there's no mention of your Service. This is because you created the replicas
before the Service. Another disadvantage of doing this is that the scheduler might
put both Pods on the same machine, which will take your entire Service down if
it dies. We can do this the right way by killing the 2 Pods and waiting for the
Deployment to recreate them. This time around the Service exists <em>before</em> the
replicas. This will give you scheduler-level Service spreading of your Pods
(provided all your nodes have equal capacity), as well as the right environment
variables:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl scale deployment my-nginx --replicas<span style=color:#666>=</span>0; kubectl scale deployment my-nginx --replicas<span style=color:#666>=</span>2;
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>kubectl get pods -l <span style=color:#b8860b>run</span><span style=color:#666>=</span>my-nginx -o wide
</span></span></code></pre></div><pre tabindex=0><code>NAME                        READY     STATUS    RESTARTS   AGE     IP            NODE
my-nginx-3800858182-e9ihh   1/1       Running   0          5s      10.244.2.7    kubernetes-minion-ljyd
my-nginx-3800858182-j4rm4   1/1       Running   0          5s      10.244.3.8    kubernetes-minion-905m
</code></pre><p>You may notice that the pods have different names, since they are killed and recreated.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl <span style=color:#a2f>exec</span> my-nginx-3800858182-e9ihh -- printenv | grep SERVICE
</span></span></code></pre></div><pre tabindex=0><code>KUBERNETES_SERVICE_PORT=443
MY_NGINX_SERVICE_HOST=10.0.162.149
KUBERNETES_SERVICE_HOST=10.0.0.1
MY_NGINX_SERVICE_PORT=80
KUBERNETES_SERVICE_PORT_HTTPS=443
</code></pre><h3 id=dns>DNS</h3><p>Kubernetes offers a DNS cluster addon Service that automatically assigns dns names to other Services. You can check if it's running on your cluster:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get services kube-dns --namespace<span style=color:#666>=</span>kube-system
</span></span></code></pre></div><pre tabindex=0><code>NAME       TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)         AGE
kube-dns   ClusterIP   10.0.0.10    &lt;none&gt;        53/UDP,53/TCP   8m
</code></pre><p>The rest of this section will assume you have a Service with a long lived IP
(my-nginx), and a DNS server that has assigned a name to that IP. Here we use the CoreDNS cluster addon (application name <code>kube-dns</code>), so you can talk to the Service from any pod in your cluster using standard methods (e.g. <code>gethostbyname()</code>). If CoreDNS isn't running, you can enable it referring to the <a href=https://github.com/coredns/deployment/tree/master/kubernetes>CoreDNS README</a> or <a href=/docs/tasks/administer-cluster/coredns/#installing-coredns>Installing CoreDNS</a>. Let's run another curl application to test this:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl run curl --image<span style=color:#666>=</span>radial/busyboxplus:curl -i --tty
</span></span></code></pre></div><pre tabindex=0><code>Waiting for pod default/curl-131556218-9fnch to be running, status is Pending, pod ready: false
Hit enter for command prompt
</code></pre><p>Then, hit enter and run <code>nslookup my-nginx</code>:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span><span style=color:#666>[</span> root@curl-131556218-9fnch:/ <span style=color:#666>]</span>$ nslookup my-nginx
</span></span><span style=display:flex><span>Server:    10.0.0.10
</span></span><span style=display:flex><span>Address 1: 10.0.0.10
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>Name:      my-nginx
</span></span><span style=display:flex><span>Address 1: 10.0.162.149
</span></span></code></pre></div><h2 id=securing-the-service>Securing the Service</h2><p>Till now we have only accessed the nginx server from within the cluster. Before exposing the Service to the internet, you want to make sure the communication channel is secure. For this, you will need:</p><ul><li>Self signed certificates for https (unless you already have an identity certificate)</li><li>An nginx server configured to use the certificates</li><li>A <a href=/docs/concepts/configuration/secret/>secret</a> that makes the certificates accessible to pods</li></ul><p>You can acquire all these from the <a href=https://github.com/kubernetes/examples/tree/master/staging/https-nginx/>nginx https example</a>. This requires having go and make tools installed. If you don't want to install those, then follow the manual steps later. In short:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>make keys <span style=color:#b8860b>KEY</span><span style=color:#666>=</span>/tmp/nginx.key <span style=color:#b8860b>CERT</span><span style=color:#666>=</span>/tmp/nginx.crt
</span></span><span style=display:flex><span>kubectl create secret tls nginxsecret --key /tmp/nginx.key --cert /tmp/nginx.crt
</span></span></code></pre></div><pre tabindex=0><code>secret/nginxsecret created
</code></pre><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get secrets
</span></span></code></pre></div><pre tabindex=0><code>NAME                  TYPE                                  DATA      AGE
nginxsecret           kubernetes.io/tls                     2         1m
</code></pre><p>And also the configmap:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl create configmap nginxconfigmap --from-file<span style=color:#666>=</span>default.conf
</span></span></code></pre></div><pre tabindex=0><code>configmap/nginxconfigmap created
</code></pre><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get configmaps
</span></span></code></pre></div><pre tabindex=0><code>NAME             DATA   AGE
nginxconfigmap   1      114s
</code></pre><p>Following are the manual steps to follow in case you run into problems running make (on windows for example):</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span><span style=color:#080;font-style:italic># Create a public private key pair</span>
</span></span><span style=display:flex><span>openssl req -x509 -nodes -days <span style=color:#666>365</span> -newkey rsa:2048 -keyout /d/tmp/nginx.key -out /d/tmp/nginx.crt -subj <span style=color:#b44>&#34;/CN=my-nginx/O=my-nginx&#34;</span>
</span></span><span style=display:flex><span><span style=color:#080;font-style:italic># Convert the keys to base64 encoding</span>
</span></span><span style=display:flex><span>cat /d/tmp/nginx.crt | base64
</span></span><span style=display:flex><span>cat /d/tmp/nginx.key | base64
</span></span></code></pre></div><p>Use the output from the previous commands to create a yaml file as follows. The base64 encoded value should all be on a single line.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;v1&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;Secret&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;nginxsecret&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>namespace</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;default&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>type</span>:<span style=color:#bbb> </span>kubernetes.io/tls<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>data</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>tls.crt</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSURIekNDQWdlZ0F3SUJBZ0lKQUp5M3lQK0pzMlpJTUEwR0NTcUdTSWIzRFFFQkJRVUFNQ1l4RVRBUEJnTlYKQkFNVENHNW5hVzU0YzNaak1SRXdEd1lEVlFRS0V3aHVaMmx1ZUhOMll6QWVGdzB4TnpFd01qWXdOekEzTVRKYQpGdzB4T0RFd01qWXdOekEzTVRKYU1DWXhFVEFQQmdOVkJBTVRDRzVuYVc1NGMzWmpNUkV3RHdZRFZRUUtFd2h1CloybHVlSE4yWXpDQ0FTSXdEUVlKS29aSWh2Y05BUUVCQlFBRGdnRVBBRENDQVFvQ2dnRUJBSjFxSU1SOVdWM0IKMlZIQlRMRmtobDRONXljMEJxYUhIQktMSnJMcy8vdzZhU3hRS29GbHlJSU94NGUrMlN5ajBFcndCLzlYTnBwbQppeW1CL3JkRldkOXg5UWhBQUxCZkVaTmNiV3NsTVFVcnhBZW50VWt1dk1vLzgvMHRpbGhjc3paenJEYVJ4NEo5Ci82UVRtVVI3a0ZTWUpOWTVQZkR3cGc3dlVvaDZmZ1Voam92VG42eHNVR0M2QURVODBpNXFlZWhNeVI1N2lmU2YKNHZpaXdIY3hnL3lZR1JBRS9mRTRqakxCdmdONjc2SU90S01rZXV3R0ljNDFhd05tNnNTSzRqYUNGeGpYSnZaZQp2by9kTlEybHhHWCtKT2l3SEhXbXNhdGp4WTRaNVk3R1ZoK0QrWnYvcW1mMFgvbVY0Rmo1NzV3ajFMWVBocWtsCmdhSXZYRyt4U1FVQ0F3RUFBYU5RTUU0d0hRWURWUjBPQkJZRUZPNG9OWkI3YXc1OUlsYkROMzhIYkduYnhFVjcKTUI4R0ExVWRJd1FZTUJhQUZPNG9OWkI3YXc1OUlsYkROMzhIYkduYnhFVjdNQXdHQTFVZEV3UUZNQU1CQWY4dwpEUVlKS29aSWh2Y05BUUVGQlFBRGdnRUJBRVhTMW9FU0lFaXdyMDhWcVA0K2NwTHI3TW5FMTducDBvMm14alFvCjRGb0RvRjdRZnZqeE04Tzd2TjB0clcxb2pGSW0vWDE4ZnZaL3k4ZzVaWG40Vm8zc3hKVmRBcStNZC9jTStzUGEKNmJjTkNUekZqeFpUV0UrKzE5NS9zb2dmOUZ3VDVDK3U2Q3B5N0M3MTZvUXRUakViV05VdEt4cXI0Nk1OZWNCMApwRFhWZmdWQTRadkR4NFo3S2RiZDY5eXM3OVFHYmg5ZW1PZ05NZFlsSUswSGt0ejF5WU4vbVpmK3FqTkJqbWZjCkNnMnlwbGQ0Wi8rUUNQZjl3SkoybFIrY2FnT0R4elBWcGxNSEcybzgvTHFDdnh6elZPUDUxeXdLZEtxaUMwSVEKQ0I5T2wwWW5scE9UNEh1b2hSUzBPOStlMm9KdFZsNUIyczRpbDlhZ3RTVXFxUlU9Ci0tLS0tRU5EIENFUlRJRklDQVRFLS0tLS0K&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>tls.key</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;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&#34;</span><span style=color:#bbb>
</span></span></span></code></pre></div><p>Now create the secrets using the file:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl apply -f nginxsecrets.yaml
</span></span><span style=display:flex><span>kubectl get secrets
</span></span></code></pre></div><pre tabindex=0><code>NAME                  TYPE                                  DATA      AGE
nginxsecret           kubernetes.io/tls                     2         1m
</code></pre><p>Now modify your nginx replicas to start an https server using the certificate in the secret, and the Service, to expose both ports (80 and 443):</p><div class=highlight><div class=copy-code-icon style=text-align:right><a href=https://raw.githubusercontent.com/kubernetes/website/main/content/en/examples/service/networking/nginx-secure-app.yaml download=service/networking/nginx-secure-app.yaml><code>service/networking/nginx-secure-app.yaml</code></a>
<img src=/images/copycode.svg style=max-height:24px;cursor:pointer onclick='copyCode("service-networking-nginx-secure-app-yaml")' title="Copy service/networking/nginx-secure-app.yaml to clipboard"></img></div><div class=includecode id=service-networking-nginx-secure-app-yaml><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Service<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>my-nginx<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>labels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>run</span>:<span style=color:#bbb> </span>my-nginx<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>type</span>:<span style=color:#bbb> </span>NodePort<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>ports</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>port</span>:<span style=color:#bbb> </span><span style=color:#666>8080</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>targetPort</span>:<span style=color:#bbb> </span><span style=color:#666>80</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>protocol</span>:<span style=color:#bbb> </span>TCP<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>http<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>port</span>:<span style=color:#bbb> </span><span style=color:#666>443</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>protocol</span>:<span style=color:#bbb> </span>TCP<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>https<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>selector</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>run</span>:<span style=color:#bbb> </span>my-nginx<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:#00f;font-weight:700>---</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>apps/v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Deployment<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>my-nginx<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>selector</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>matchLabels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>run</span>:<span style=color:#bbb> </span>my-nginx<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>replicas</span>:<span style=color:#bbb> </span><span style=color:#666>1</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>template</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>labels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>run</span>:<span style=color:#bbb> </span>my-nginx<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>volumes</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>secret-volume<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>secret</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>secretName</span>:<span style=color:#bbb> </span>nginxsecret<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>configmap-volume<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>configMap</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>nginxconfigmap<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>nginxhttps<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>bprashanth/nginxhttps:1.0<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>ports</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span>- <span style=color:green;font-weight:700>containerPort</span>:<span style=color:#bbb> </span><span style=color:#666>443</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span>- <span style=color:green;font-weight:700>containerPort</span>:<span style=color:#bbb> </span><span style=color:#666>80</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>volumeMounts</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span>- <span style=color:green;font-weight:700>mountPath</span>:<span style=color:#bbb> </span>/etc/nginx/ssl<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>secret-volume<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span>- <span style=color:green;font-weight:700>mountPath</span>:<span style=color:#bbb> </span>/etc/nginx/conf.d<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>configmap-volume<span style=color:#bbb>
</span></span></span></code></pre></div></div></div><p>Noteworthy points about the nginx-secure-app manifest:</p><ul><li>It contains both Deployment and Service specification in the same file.</li><li>The <a href=https://github.com/kubernetes/examples/tree/master/staging/https-nginx/default.conf>nginx server</a>
serves HTTP traffic on port 80 and HTTPS traffic on 443, and nginx Service
exposes both ports.</li><li>Each container has access to the keys through a volume mounted at <code>/etc/nginx/ssl</code>.
This is set up <em>before</em> the nginx server is started.</li></ul><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl delete deployments,svc my-nginx; kubectl create -f ./nginx-secure-app.yaml
</span></span></code></pre></div><p>At this point you can reach the nginx server from any node.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get pods -l <span style=color:#b8860b>run</span><span style=color:#666>=</span>my-nginx -o custom-columns<span style=color:#666>=</span>POD_IP:.status.podIPs
</span></span><span style=display:flex><span>    POD_IP
</span></span><span style=display:flex><span>    <span style=color:#666>[</span>map<span style=color:#666>[</span>ip:10.244.3.5<span style=color:#666>]]</span>
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>node $ curl -k https://10.244.3.5
</span></span><span style=display:flex><span>...
</span></span><span style=display:flex><span>&lt;h1&gt;Welcome to nginx!&lt;/h1&gt;
</span></span></code></pre></div><p>Note how we supplied the <code>-k</code> parameter to curl in the last step, this is because we don't know anything about the pods running nginx at certificate generation time,
so we have to tell curl to ignore the CName mismatch. By creating a Service we linked the CName used in the certificate with the actual DNS name used by pods during Service lookup.
Let's test this from a pod (the same secret is being reused for simplicity, the pod only needs nginx.crt to access the Service):</p><div class=highlight><div class=copy-code-icon style=text-align:right><a href=https://raw.githubusercontent.com/kubernetes/website/main/content/en/examples/service/networking/curlpod.yaml download=service/networking/curlpod.yaml><code>service/networking/curlpod.yaml</code></a>
<img src=/images/copycode.svg style=max-height:24px;cursor:pointer onclick='copyCode("service-networking-curlpod-yaml")' title="Copy service/networking/curlpod.yaml to clipboard"></img></div><div class=includecode id=service-networking-curlpod-yaml><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>apps/v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Deployment<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>curl-deployment<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>selector</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>matchLabels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>app</span>:<span style=color:#bbb> </span>curlpod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>replicas</span>:<span style=color:#bbb> </span><span style=color:#666>1</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>template</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>labels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>app</span>:<span style=color:#bbb> </span>curlpod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>volumes</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>secret-volume<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>secret</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>secretName</span>:<span style=color:#bbb> </span>nginxsecret<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>curlpod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>command</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span>- sh<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span>- -c<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span>- while true; do sleep 1; done<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>radial/busyboxplus:curl<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>volumeMounts</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span>- <span style=color:green;font-weight:700>mountPath</span>:<span style=color:#bbb> </span>/etc/nginx/ssl<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>secret-volume<span style=color:#bbb>
</span></span></span></code></pre></div></div></div><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl apply -f ./curlpod.yaml
</span></span><span style=display:flex><span>kubectl get pods -l <span style=color:#b8860b>app</span><span style=color:#666>=</span>curlpod
</span></span></code></pre></div><pre tabindex=0><code>NAME                               READY     STATUS    RESTARTS   AGE
curl-deployment-1515033274-1410r   1/1       Running   0          1m
</code></pre><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl <span style=color:#a2f>exec</span> curl-deployment-1515033274-1410r -- curl https://my-nginx --cacert /etc/nginx/ssl/tls.crt
</span></span><span style=display:flex><span>...
</span></span><span style=display:flex><span>&lt;title&gt;Welcome to nginx!&lt;/title&gt;
</span></span><span style=display:flex><span>...
</span></span></code></pre></div><h2 id=exposing-the-service>Exposing the Service</h2><p>For some parts of your applications you may want to expose a Service onto an
external IP address. Kubernetes supports two ways of doing this: NodePorts and
LoadBalancers. The Service created in the last section already used <code>NodePort</code>,
so your nginx HTTPS replica is ready to serve traffic on the internet if your
node has a public IP.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get svc my-nginx -o yaml | grep nodePort -C <span style=color:#666>5</span>
</span></span><span style=display:flex><span>  uid: 07191fb3-f61a-11e5-8ae5-42010af00002
</span></span><span style=display:flex><span>spec:
</span></span><span style=display:flex><span>  clusterIP: 10.0.162.149
</span></span><span style=display:flex><span>  ports:
</span></span><span style=display:flex><span>  - name: http
</span></span><span style=display:flex><span>    nodePort: <span style=color:#666>31704</span>
</span></span><span style=display:flex><span>    port: <span style=color:#666>8080</span>
</span></span><span style=display:flex><span>    protocol: TCP
</span></span><span style=display:flex><span>    targetPort: <span style=color:#666>80</span>
</span></span><span style=display:flex><span>  - name: https
</span></span><span style=display:flex><span>    nodePort: <span style=color:#666>32453</span>
</span></span><span style=display:flex><span>    port: <span style=color:#666>443</span>
</span></span><span style=display:flex><span>    protocol: TCP
</span></span><span style=display:flex><span>    targetPort: <span style=color:#666>443</span>
</span></span><span style=display:flex><span>  selector:
</span></span><span style=display:flex><span>    run: my-nginx
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get nodes -o yaml | grep ExternalIP -C <span style=color:#666>1</span>
</span></span><span style=display:flex><span>    - address: 104.197.41.11
</span></span><span style=display:flex><span>      type: ExternalIP
</span></span><span style=display:flex><span>    allocatable:
</span></span><span style=display:flex><span>--
</span></span><span style=display:flex><span>    - address: 23.251.152.56
</span></span><span style=display:flex><span>      type: ExternalIP
</span></span><span style=display:flex><span>    allocatable:
</span></span><span style=display:flex><span>...
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>$ curl https://&lt;EXTERNAL-IP&gt;:&lt;NODE-PORT&gt; -k
</span></span><span style=display:flex><span>...
</span></span><span style=display:flex><span>&lt;h1&gt;Welcome to nginx!&lt;/h1&gt;
</span></span></code></pre></div><p>Let's now recreate the Service to use a cloud load balancer. Change the <code>Type</code> of <code>my-nginx</code> Service from <code>NodePort</code> to <code>LoadBalancer</code>:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl edit svc my-nginx
</span></span><span style=display:flex><span>kubectl get svc my-nginx
</span></span></code></pre></div><pre tabindex=0><code>NAME       TYPE           CLUSTER-IP     EXTERNAL-IP        PORT(S)               AGE
my-nginx   LoadBalancer   10.0.162.149     xx.xxx.xxx.xxx     8080:30163/TCP        21s
</code></pre><pre tabindex=0><code>curl https://&lt;EXTERNAL-IP&gt; -k
...
&lt;title&gt;Welcome to nginx!&lt;/title&gt;
</code></pre><p>The IP address in the <code>EXTERNAL-IP</code> column is the one that is available on the public internet. The <code>CLUSTER-IP</code> is only available inside your
cluster/private cloud network.</p><p>Note that on AWS, type <code>LoadBalancer</code> creates an ELB, which uses a (long)
hostname, not an IP. It's too long to fit in the standard <code>kubectl get svc</code>
output, in fact, so you'll need to do <code>kubectl describe service my-nginx</code> to
see it. You'll see something like this:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl describe service my-nginx
</span></span><span style=display:flex><span>...
</span></span><span style=display:flex><span>LoadBalancer Ingress:   a320587ffd19711e5a37606cf4a74574-1142138393.us-east-1.elb.amazonaws.com
</span></span><span style=display:flex><span>...
</span></span></code></pre></div><h2 id=what-s-next>What's next</h2><ul><li>Learn more about <a href=/docs/tasks/access-application-cluster/service-access-application-cluster/>Using a Service to Access an Application in a Cluster</a></li><li>Learn more about <a href=/docs/tasks/access-application-cluster/connecting-frontend-backend/>Connecting a Front End to a Back End Using a Service</a></li><li>Learn more about <a href=/docs/tasks/access-application-cluster/create-external-load-balancer/>Creating an External Load Balancer</a></li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-5642e8c51749e4fe2e6a2ccc207f1fab>7.2 - Using Source IP</h1><p>Applications running in a Kubernetes cluster find and communicate with each
other, and the outside world, through the Service abstraction. This document
explains what happens to the source IP of packets sent to different types
of Services, and how you can toggle this behavior according to your needs.</p><h2 id=before-you-begin>Before you begin</h2><h3 id=terminology>Terminology</h3><p>This document makes use of the following terms:</p><dl><dt><a href=https://en.wikipedia.org/wiki/Network_address_translation>NAT</a></dt><dd>network address translation</dd><dt><a href=https://en.wikipedia.org/wiki/Network_address_translation#SNAT>Source NAT</a></dt><dd>replacing the source IP on a packet; in this page, that usually means replacing with the IP address of a node.</dd><dt><a href=https://en.wikipedia.org/wiki/Network_address_translation#DNAT>Destination NAT</a></dt><dd>replacing the destination IP on a packet; in this page, that usually means replacing with the IP address of a <a class=glossary-tooltip title='A Pod represents a set of running containers in your cluster.' data-toggle=tooltip data-placement=top href=/docs/concepts/workloads/pods/ target=_blank aria-label=Pod>Pod</a></dd><dt><a href=/docs/concepts/services-networking/service/#virtual-ips-and-service-proxies>VIP</a></dt><dd>a virtual IP address, such as the one assigned to every <a class=glossary-tooltip title='A way to expose an application running on a set of Pods as a network service.' data-toggle=tooltip data-placement=top href=/docs/concepts/services-networking/service/ target=_blank aria-label=Service>Service</a> in Kubernetes</dd><dt><a href=/docs/concepts/services-networking/service/#virtual-ips-and-service-proxies>kube-proxy</a></dt><dd>a network daemon that orchestrates Service VIP management on every node</dd></dl><h3 id=prerequisites>Prerequisites</h3><p>You need to have a Kubernetes cluster, and the kubectl command-line tool must
be configured to communicate with your cluster. It is recommended to run this tutorial on a cluster with at least two nodes that are not acting as control plane hosts. If you do not already have a
cluster, you can create one by using
<a href=https://minikube.sigs.k8s.io/docs/tutorials/multi_node/>minikube</a>
or you can use one of these Kubernetes playgrounds:</p><ul><li><a href=https://killercoda.com/playgrounds/scenario/kubernetes>Killercoda</a></li><li><a href=http://labs.play-with-k8s.com/>Play with Kubernetes</a></li></ul><p>The examples use a small nginx webserver that echoes back the source
IP of requests it receives through an HTTP header. You can create it as follows:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl create deployment source-ip-app --image<span style=color:#666>=</span>registry.k8s.io/echoserver:1.4
</span></span></code></pre></div><p>The output is:</p><pre tabindex=0><code>deployment.apps/source-ip-app created
</code></pre><h2 id=objectives>Objectives</h2><ul><li>Expose a simple application through various types of Services</li><li>Understand how each Service type handles source IP NAT</li><li>Understand the tradeoffs involved in preserving source IP</li></ul><h2 id=source-ip-for-services-with-type-clusterip>Source IP for Services with <code>Type=ClusterIP</code></h2><p>Packets sent to ClusterIP from within the cluster are never source NAT'd if
you're running kube-proxy in
<a href=/docs/concepts/services-networking/service/#proxy-mode-iptables>iptables mode</a>,
(the default). You can query the kube-proxy mode by fetching
<code>http://localhost:10249/proxyMode</code> on the node where kube-proxy is running.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-console data-lang=console><span style=display:flex><span><span style=color:#888>kubectl get nodes
</span></span></span></code></pre></div><p>The output is similar to this:</p><pre tabindex=0><code>NAME                           STATUS     ROLES    AGE     VERSION
kubernetes-node-6jst   Ready      &lt;none&gt;   2h      v1.13.0
kubernetes-node-cx31   Ready      &lt;none&gt;   2h      v1.13.0
kubernetes-node-jj1t   Ready      &lt;none&gt;   2h      v1.13.0
</code></pre><p>Get the proxy mode on one of the nodes (kube-proxy listens on port 10249):</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span><span style=color:#080;font-style:italic># Run this in a shell on the node you want to query.</span>
</span></span><span style=display:flex><span>curl http://localhost:10249/proxyMode
</span></span></code></pre></div><p>The output is:</p><pre tabindex=0><code>iptables
</code></pre><p>You can test source IP preservation by creating a Service over the source IP app:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl expose deployment source-ip-app --name<span style=color:#666>=</span>clusterip --port<span style=color:#666>=</span><span style=color:#666>80</span> --target-port<span style=color:#666>=</span><span style=color:#666>8080</span>
</span></span></code></pre></div><p>The output is:</p><pre tabindex=0><code>service/clusterip exposed
</code></pre><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get svc clusterip
</span></span></code></pre></div><p>The output is similar to:</p><pre tabindex=0><code>NAME         TYPE        CLUSTER-IP    EXTERNAL-IP   PORT(S)   AGE
clusterip    ClusterIP   10.0.170.92   &lt;none&gt;        80/TCP    51s
</code></pre><p>And hitting the <code>ClusterIP</code> from a pod in the same cluster:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl run busybox -it --image<span style=color:#666>=</span>busybox:1.28 --restart<span style=color:#666>=</span>Never --rm
</span></span></code></pre></div><p>The output is similar to this:</p><pre tabindex=0><code>Waiting for pod default/busybox to be running, status is Pending, pod ready: false
If you don&#39;t see a command prompt, try pressing enter.
</code></pre><p>You can then run a command inside that Pod:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span><span style=color:#080;font-style:italic># Run this inside the terminal from &#34;kubectl run&#34;</span>
</span></span><span style=display:flex><span>ip addr
</span></span></code></pre></div><pre tabindex=0><code>1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue
    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
    inet 127.0.0.1/8 scope host lo
       valid_lft forever preferred_lft forever
    inet6 ::1/128 scope host
       valid_lft forever preferred_lft forever
3: eth0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1460 qdisc noqueue
    link/ether 0a:58:0a:f4:03:08 brd ff:ff:ff:ff:ff:ff
    inet 10.244.3.8/24 scope global eth0
       valid_lft forever preferred_lft forever
    inet6 fe80::188a:84ff:feb0:26a5/64 scope link
       valid_lft forever preferred_lft forever
</code></pre><p>…then use <code>wget</code> to query the local webserver</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span><span style=color:#080;font-style:italic># Replace &#34;10.0.170.92&#34; with the IPv4 address of the Service named &#34;clusterip&#34;</span>
</span></span><span style=display:flex><span>wget -qO - 10.0.170.92
</span></span></code></pre></div><pre tabindex=0><code>CLIENT VALUES:
client_address=10.244.3.8
command=GET
...
</code></pre><p>The <code>client_address</code> is always the client pod's IP address, whether the client pod and server pod are in the same node or in different nodes.</p><h2 id=source-ip-for-services-with-type-nodeport>Source IP for Services with <code>Type=NodePort</code></h2><p>Packets sent to Services with
<a href=/docs/concepts/services-networking/service/#type-nodeport><code>Type=NodePort</code></a>
are source NAT'd by default. You can test this by creating a <code>NodePort</code> Service:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl expose deployment source-ip-app --name<span style=color:#666>=</span>nodeport --port<span style=color:#666>=</span><span style=color:#666>80</span> --target-port<span style=color:#666>=</span><span style=color:#666>8080</span> --type<span style=color:#666>=</span>NodePort
</span></span></code></pre></div><p>The output is:</p><pre tabindex=0><code>service/nodeport exposed
</code></pre><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span><span style=color:#b8860b>NODEPORT</span><span style=color:#666>=</span><span style=color:#a2f;font-weight:700>$(</span>kubectl get -o <span style=color:#b8860b>jsonpath</span><span style=color:#666>=</span><span style=color:#b44>&#34;{.spec.ports[0].nodePort}&#34;</span> services nodeport<span style=color:#a2f;font-weight:700>)</span>
</span></span><span style=display:flex><span><span style=color:#b8860b>NODES</span><span style=color:#666>=</span><span style=color:#a2f;font-weight:700>$(</span>kubectl get nodes -o <span style=color:#b8860b>jsonpath</span><span style=color:#666>=</span><span style=color:#b44>&#39;{ $.items[*].status.addresses[?(@.type==&#34;InternalIP&#34;)].address }&#39;</span><span style=color:#a2f;font-weight:700>)</span>
</span></span></code></pre></div><p>If you're running on a cloud provider, you may need to open up a firewall-rule
for the <code>nodes:nodeport</code> reported above.
Now you can try reaching the Service from outside the cluster through the node
port allocated above.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span><span style=color:#a2f;font-weight:700>for</span> node in <span style=color:#b8860b>$NODES</span>; <span style=color:#a2f;font-weight:700>do</span> curl -s <span style=color:#b8860b>$node</span>:<span style=color:#b8860b>$NODEPORT</span> | grep -i client_address; <span style=color:#a2f;font-weight:700>done</span>
</span></span></code></pre></div><p>The output is similar to:</p><pre tabindex=0><code>client_address=10.180.1.1
client_address=10.240.0.5
client_address=10.240.0.3
</code></pre><p>Note that these are not the correct client IPs, they're cluster internal IPs. This is what happens:</p><ul><li>Client sends packet to <code>node2:nodePort</code></li><li><code>node2</code> replaces the source IP address (SNAT) in the packet with its own IP address</li><li><code>node2</code> replaces the destination IP on the packet with the pod IP</li><li>packet is routed to node 1, and then to the endpoint</li><li>the pod's reply is routed back to node2</li><li>the pod's reply is sent back to the client</li></ul><p>Visually:</p><figure class=diagram-large><a href=https://mermaid.live/edit#pako:eNqNkV9rwyAUxb-K3LysYEqS_WFYKAzat9GHdW9zDxKvi9RoMIZtlH732ZjSbE970cu5v3s86hFqJxEYfHjRNeT5ZcUtIbXRaMNN2hZ5vrYRqt52cSXV-4iMSuwkZiYtyX739EqWaahMQ-V1qPxDVLNOvkYrO6fj2dupWMR2iiT6foOKdEZoS5Q2hmVSStoH7w7IMqXUVOefWoaG3XVftHbGeZYVRbH6ZXJ47CeL2-qhxvt_ucTe1SUlpuMN6CX12XeGpLdJiaMMFFr0rdAyvvfxjHEIDbbIgcVSohKDCRy4PUV06KQIuJU6OA9MCdMjBTEEt_-2NbDgB7xAGy3i97VJPP0ABRmcqg><img src=/docs/images/tutor-service-nodePort-fig01.svg alt="source IP nodeport figure 01"></a><figcaption><p>Figure. Source IP Type=NodePort using SNAT</p></figcaption></figure><p>To avoid this, Kubernetes has a feature to
<a href=/docs/tasks/access-application-cluster/create-external-load-balancer/#preserving-the-client-source-ip>preserve the client source IP</a>.
If you set <code>service.spec.externalTrafficPolicy</code> to the value <code>Local</code>,
kube-proxy only proxies proxy requests to local endpoints, and does not
forward traffic to other nodes. This approach preserves the original
source IP address. If there are no local endpoints, packets sent to the
node are dropped, so you can rely on the correct source-ip in any packet
processing rules you might apply a packet that make it through to the
endpoint.</p><p>Set the <code>service.spec.externalTrafficPolicy</code> field as follows:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl patch svc nodeport -p <span style=color:#b44>&#39;{&#34;spec&#34;:{&#34;externalTrafficPolicy&#34;:&#34;Local&#34;}}&#39;</span>
</span></span></code></pre></div><p>The output is:</p><pre tabindex=0><code>service/nodeport patched
</code></pre><p>Now, re-run the test:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span><span style=color:#a2f;font-weight:700>for</span> node in <span style=color:#b8860b>$NODES</span>; <span style=color:#a2f;font-weight:700>do</span> curl --connect-timeout <span style=color:#666>1</span> -s <span style=color:#b8860b>$node</span>:<span style=color:#b8860b>$NODEPORT</span> | grep -i client_address; <span style=color:#a2f;font-weight:700>done</span>
</span></span></code></pre></div><p>The output is similar to:</p><pre tabindex=0><code>client_address=198.51.100.79
</code></pre><p>Note that you only got one reply, with the <em>right</em> client IP, from the one node on which the endpoint pod
is running.</p><p>This is what happens:</p><ul><li>client sends packet to <code>node2:nodePort</code>, which doesn't have any endpoints</li><li>packet is dropped</li><li>client sends packet to <code>node1:nodePort</code>, which <em>does</em> have endpoints</li><li>node1 routes packet to endpoint with the correct source IP</li></ul><p>Visually:</p><figure class=diagram-large><img src=/docs/images/tutor-service-nodePort-fig02.svg alt="source IP nodeport figure 02"><figcaption><p>Figure. Source IP Type=NodePort preserves client source IP address</p></figcaption></figure><h2 id=source-ip-for-services-with-type-loadbalancer>Source IP for Services with <code>Type=LoadBalancer</code></h2><p>Packets sent to Services with
<a href=/docs/concepts/services-networking/service/#loadbalancer><code>Type=LoadBalancer</code></a>
are source NAT'd by default, because all schedulable Kubernetes nodes in the
<code>Ready</code> state are eligible for load-balanced traffic. So if packets arrive
at a node without an endpoint, the system proxies it to a node <em>with</em> an
endpoint, replacing the source IP on the packet with the IP of the node (as
described in the previous section).</p><p>You can test this by exposing the source-ip-app through a load balancer:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl expose deployment source-ip-app --name<span style=color:#666>=</span>loadbalancer --port<span style=color:#666>=</span><span style=color:#666>80</span> --target-port<span style=color:#666>=</span><span style=color:#666>8080</span> --type<span style=color:#666>=</span>LoadBalancer
</span></span></code></pre></div><p>The output is:</p><pre tabindex=0><code>service/loadbalancer exposed
</code></pre><p>Print out the IP addresses of the Service:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-console data-lang=console><span style=display:flex><span><span style=color:#888>kubectl get svc loadbalancer
</span></span></span></code></pre></div><p>The output is similar to this:</p><pre tabindex=0><code>NAME           TYPE           CLUSTER-IP    EXTERNAL-IP       PORT(S)   AGE
loadbalancer   LoadBalancer   10.0.65.118   203.0.113.140     80/TCP    5m
</code></pre><p>Next, send a request to this Service's external-ip:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>curl 203.0.113.140
</span></span></code></pre></div><p>The output is similar to this:</p><pre tabindex=0><code>CLIENT VALUES:
client_address=10.240.0.5
...
</code></pre><p>However, if you're running on Google Kubernetes Engine/GCE, setting the same <code>service.spec.externalTrafficPolicy</code>
field to <code>Local</code> forces nodes <em>without</em> Service endpoints to remove
themselves from the list of nodes eligible for loadbalanced traffic by
deliberately failing health checks.</p><p>Visually:</p><p><img src=/images/docs/sourceip-externaltrafficpolicy.svg alt="Source IP with externalTrafficPolicy"></p><p>You can test this by setting the annotation:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl patch svc loadbalancer -p <span style=color:#b44>&#39;{&#34;spec&#34;:{&#34;externalTrafficPolicy&#34;:&#34;Local&#34;}}&#39;</span>
</span></span></code></pre></div><p>You should immediately see the <code>service.spec.healthCheckNodePort</code> field allocated
by Kubernetes:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get svc loadbalancer -o yaml | grep -i healthCheckNodePort
</span></span></code></pre></div><p>The output is similar to this:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>healthCheckNodePort</span>:<span style=color:#bbb> </span><span style=color:#666>32122</span><span style=color:#bbb>
</span></span></span></code></pre></div><p>The <code>service.spec.healthCheckNodePort</code> field points to a port on every node
serving the health check at <code>/healthz</code>. You can test this:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get pod -o wide -l <span style=color:#b8860b>app</span><span style=color:#666>=</span>source-ip-app
</span></span></code></pre></div><p>The output is similar to this:</p><pre tabindex=0><code>NAME                            READY     STATUS    RESTARTS   AGE       IP             NODE
source-ip-app-826191075-qehz4   1/1       Running   0          20h       10.180.1.136   kubernetes-node-6jst
</code></pre><p>Use <code>curl</code> to fetch the <code>/healthz</code> endpoint on various nodes:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span><span style=color:#080;font-style:italic># Run this locally on a node you choose</span>
</span></span><span style=display:flex><span>curl localhost:32122/healthz
</span></span></code></pre></div><pre tabindex=0><code>1 Service Endpoints found
</code></pre><p>On a different node you might get a different result:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span><span style=color:#080;font-style:italic># Run this locally on a node you choose</span>
</span></span><span style=display:flex><span>curl localhost:32122/healthz
</span></span></code></pre></div><pre tabindex=0><code>No Service Endpoints Found
</code></pre><p>A controller running on the
<a class=glossary-tooltip title='The container orchestration layer that exposes the API and interfaces to define, deploy, and manage the lifecycle of containers.' data-toggle=tooltip data-placement=top href='/docs/reference/glossary/?all=true#term-control-plane' target=_blank aria-label='control plane'>control plane</a> is
responsible for allocating the cloud load balancer. The same controller also
allocates HTTP health checks pointing to this port/path on each node. Wait
about 10 seconds for the 2 nodes without endpoints to fail health checks,
then use <code>curl</code> to query the IPv4 address of the load balancer:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>curl 203.0.113.140
</span></span></code></pre></div><p>The output is similar to this:</p><pre tabindex=0><code>CLIENT VALUES:
client_address=198.51.100.79
...
</code></pre><h2 id=cross-platform-support>Cross-platform support</h2><p>Only some cloud providers offer support for source IP preservation through
Services with <code>Type=LoadBalancer</code>.
The cloud provider you're running on might fulfill the request for a loadbalancer
in a few different ways:</p><ol><li><p>With a proxy that terminates the client connection and opens a new connection
to your nodes/endpoints. In such cases the source IP will always be that of the
cloud LB, not that of the client.</p></li><li><p>With a packet forwarder, such that requests from the client sent to the
loadbalancer VIP end up at the node with the source IP of the client, not
an intermediate proxy.</p></li></ol><p>Load balancers in the first category must use an agreed upon
protocol between the loadbalancer and backend to communicate the true client IP
such as the HTTP <a href=https://tools.ietf.org/html/rfc7239#section-5.2>Forwarded</a>
or <a href=https://en.wikipedia.org/wiki/X-Forwarded-For>X-FORWARDED-FOR</a>
headers, or the
<a href=https://www.haproxy.org/download/1.8/doc/proxy-protocol.txt>proxy protocol</a>.
Load balancers in the second category can leverage the feature described above
by creating an HTTP health check pointing at the port stored in
the <code>service.spec.healthCheckNodePort</code> field on the Service.</p><h2 id=cleaning-up>Cleaning up</h2><p>Delete the Services:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl delete svc -l <span style=color:#b8860b>app</span><span style=color:#666>=</span>source-ip-app
</span></span></code></pre></div><p>Delete the Deployment, ReplicaSet and Pod:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl delete deployment source-ip-app
</span></span></code></pre></div><h2 id=what-s-next>What's next</h2><ul><li>Learn more about <a href=/docs/tutorials/services/connect-applications-service/>connecting applications via services</a></li><li>Read how to <a href=/docs/tasks/access-application-cluster/create-external-load-balancer/>Create an External Load Balancer</a></li></ul></div></main></div></div><footer class=d-print-none><div class=footer__links><nav><a class=text-white href=/docs/home/>Home</a>
<a class=text-white href=/blog/>Blog</a>
<a class=text-white href=/training/>Training</a>
<a class=text-white href=/partners/>Partners</a>
<a class=text-white href=/community/>Community</a>
<a class=text-white href=/case-studies/>Case Studies</a></nav></div><div class=container-fluid><div class=row><div class="col-6 col-sm-2 text-xs-center order-sm-2"><ul class="list-inline mb-0"><li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title="User mailing list" aria-label="User mailing list"><a class=text-white target=_blank href=https://discuss.kubernetes.io><i class="fa fa-envelope"></i></a></li><li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title=Twitter aria-label=Twitter><a class=text-white target=_blank href=https://twitter.com/kubernetesio><i class="fab fa-twitter"></i></a></li><li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title=Calendar aria-label=Calendar><a class=text-white target=_blank href="https://calendar.google.com/calendar/embed?src=calendar%40kubernetes.io"><i class="fas fa-calendar-alt"></i></a></li><li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title=Youtube aria-label=Youtube><a class=text-white target=_blank href=https://youtube.com/kubernetescommunity><i class="fab fa-youtube"></i></a></li></ul></div><div class="col-6 col-sm-2 text-right text-xs-center order-sm-3"><ul class="list-inline mb-0"><li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title=GitHub aria-label=GitHub><a class=text-white target=_blank href=https://github.com/kubernetes/kubernetes><i class="fab fa-github"></i></a></li><li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title=Slack aria-label=Slack><a class=text-white target=_blank href=https://slack.k8s.io><i class="fab fa-slack"></i></a></li><li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title=Contribute aria-label=Contribute><a class=text-white target=_blank href=https://git.k8s.io/community/contributors/guide><i class="fas fa-edit"></i></a></li><li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title="Stack Overflow" aria-label="Stack Overflow"><a class=text-white target=_blank href=https://stackoverflow.com/questions/tagged/kubernetes><i class="fab fa-stack-overflow"></i></a></li></ul></div><div class="col-12 col-sm-8 text-center order-sm-2"><small class=text-white>&copy; 2023 The Kubernetes Authors | Documentation Distributed under <a href=https://git.k8s.io/website/LICENSE class=light-text>CC BY 4.0</a></small><br><small class=text-white>Copyright &copy; 2023 The Linux Foundation &reg;. All rights reserved. The Linux Foundation has registered trademarks and uses trademarks. For a list of trademarks of The Linux Foundation, please see our <a href=https://www.linuxfoundation.org/trademark-usage class=light-text>Trademark Usage page</a></small><br><small class=text-white>ICP license: 京ICP备17074266号-3</small></div></div></div></footer></div><script src=/js/jquery-3.6.0.min.js integrity=sha384-vtXRMe3mGCbOeY7l30aIg8H9p3GdeSe4IFlP6G8JMa7o7lXvnz3GFKzPxzJdPfGK crossorigin=anonymous></script>
<script src=/js/popper-1.16.1.min.js intregrity=sha384-9/reFTGAW83EW2RDu2S0VKaIzap3H66lZH81PoYlFhbGU+6BZp6G7niu735Sk7lN crossorigin=anonymous></script>
<script src=/js/bootstrap-4.6.1.min.js integrity=sha384-VHvPCCyXqtD5DqJeNxl2dtTyhF78xXNXdkwX1CZeRusQfRKp+tA7hAShOK/B/fQ2 crossorigin=anonymous></script>
<script src=/js/script.js></script>
<script async src=/js/mermaid-8.13.4.min.js integrity=sha384-5hHNvPeMrNH14oM3IcQofDoBhiclNK3g2+hnEinKzQ07C4AliMeVpnvxuiwEGpaO crossorigin=anonymous></script>
<script src=/js/main.min.5c0bf7f21dc4f66485f74efbbeeff28a7e4f8cddaac1bae47043159c922ff3a3.js integrity="sha256-XAv38h3E9mSF9077vu/yin5PjN2qwbrkcEMVnJIv86M=" crossorigin=anonymous></script></body></html>