<!doctype html><html lang=en class=no-js><head><meta name=robots content="noindex, nofollow"><link rel=alternate hreflang=zh-cn href=https://kubernetes.io/zh-cn/docs/tutorials/stateful-application/><link rel=alternate hreflang=ko href=https://kubernetes.io/ko/docs/tutorials/stateful-application/><link rel=alternate hreflang=ja href=https://kubernetes.io/ja/docs/tutorials/stateful-application/><link rel=alternate hreflang=fr href=https://kubernetes.io/fr/docs/tutorials/stateful-application/><link rel=alternate hreflang=es href=https://kubernetes.io/es/docs/tutorials/stateful-application/><link rel=alternate hreflang=id href=https://kubernetes.io/id/docs/tutorials/stateful-application/><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=generator content="Hugo 0.110.0"><link rel=canonical type=text/html href=https://kubernetes.io/docs/tutorials/stateful-application/><link rel="shortcut icon" type=image/png href=/images/favicon.png><link rel=apple-touch-icon href=/favicons/apple-touch-icon-180x180.png sizes=180x180><link rel=manifest href=/manifest.webmanifest><link rel=apple-touch-icon href=/images/kubernetes-192x192.png><title>Stateful Applications | Kubernetes</title><meta property="og:title" content="Stateful Applications"><meta property="og:description" content="Production-Grade Container Orchestration"><meta property="og:type" content="website"><meta property="og:url" content="https://kubernetes.io/docs/tutorials/stateful-application/"><meta property="og:site_name" content="Kubernetes"><meta itemprop=name content="Stateful Applications"><meta itemprop=description content="Production-Grade Container Orchestration"><meta name=twitter:card content="summary"><meta name=twitter:title content="Stateful Applications"><meta name=twitter:description content="Production-Grade Container Orchestration"><link href=/scss/main.css rel=stylesheet><script type=application/ld+json>{"@context":"https://schema.org","@type":"Organization","url":"https://kubernetes.io","logo":"https://kubernetes.io/images/favicon.png","potentialAction":{"@type":"SearchAction","target":"https://kubernetes.io/search/?q={search_term_string}","query-input":"required name=search_term_string"}}</script><meta name=theme-color content="#326ce5"><link rel=stylesheet href=/css/feature-states.css><meta name=description content><meta property="og:description" content><meta name=twitter:description content><meta property="og:url" content="https://kubernetes.io/docs/tutorials/stateful-application/"><meta property="og:title" content="Stateful Applications"><meta name=twitter:title content="Stateful Applications"><meta name=twitter:image content="https://kubernetes.io/images/favicon.png"><meta name=twitter:image:alt content="Kubernetes"><meta property="og:image" content="/images/kubernetes-horizontal-color.png"><meta property="og:type" content="article"><script src=/js/jquery-3.6.0.min.js intregrity=sha384-vtXRMe3mGCbOeY7l30aIg8H9p3GdeSe4IFlP6G8JMa7o7lXvnz3GFKzPxzJdPfGK crossorigin=anonymous></script></head><body class=td-section><header><nav class="js-navbar-scroll navbar navbar-expand navbar-dark flex-column flex-md-row td-navbar" data-auto-burger=primary><a class=navbar-brand href=/></a><div class="td-navbar-nav-scroll ml-md-auto" id=main_navbar><ul class="navbar-nav mt-2 mt-lg-0"><li class="nav-item mr-2 mb-lg-0"><a class="nav-link active" href=/docs/>Documentation</a></li><li class="nav-item mr-2 mb-lg-0"><a class=nav-link href=/blog/>Kubernetes Blog</a></li><li class="nav-item mr-2 mb-lg-0"><a class=nav-link href=/training/>Training</a></li><li class="nav-item mr-2 mb-lg-0"><a class=nav-link href=/partners/>Partners</a></li><li class="nav-item mr-2 mb-lg-0"><a class=nav-link href=/community/>Community</a></li><li class="nav-item mr-2 mb-lg-0"><a class=nav-link href=/case-studies/>Case Studies</a></li><li class="nav-item dropdown"><a class="nav-link dropdown-toggle" href=# id=navbarDropdown role=button data-toggle=dropdown aria-haspopup=true aria-expanded=false>Versions</a><div class="dropdown-menu dropdown-menu-right" aria-labelledby=navbarDropdownMenuLink><a class=dropdown-item href=/releases>Release Information</a>
<a class=dropdown-item href=https://kubernetes.io/docs/tutorials/stateful-application/>v1.25</a>
<a class=dropdown-item href=https://v1-24.docs.kubernetes.io/docs/tutorials/stateful-application/>v1.24</a>
<a class=dropdown-item href=https://v1-23.docs.kubernetes.io/docs/tutorials/stateful-application/>v1.23</a>
<a class=dropdown-item href=https://v1-22.docs.kubernetes.io/docs/tutorials/stateful-application/>v1.22</a>
<a class=dropdown-item href=https://v1-21.docs.kubernetes.io/docs/tutorials/stateful-application/>v1.21</a></div></li><li class="nav-item dropdown"><a class="nav-link dropdown-toggle" href=# id=navbarDropdownMenuLink role=button data-toggle=dropdown aria-haspopup=true aria-expanded=false>English</a><div class="dropdown-menu dropdown-menu-right" aria-labelledby=navbarDropdownMenuLink><a class=dropdown-item href=/zh-cn/docs/tutorials/stateful-application/>中文 (Chinese)</a>
<a class=dropdown-item href=/ko/docs/tutorials/stateful-application/>한국어 (Korean)</a>
<a class=dropdown-item href=/ja/docs/tutorials/stateful-application/>日本語 (Japanese)</a>
<a class=dropdown-item href=/fr/docs/tutorials/stateful-application/>Français (French)</a>
<a class=dropdown-item href=/es/docs/tutorials/stateful-application/>Español (Spanish)</a>
<a class=dropdown-item href=/id/docs/tutorials/stateful-application/>Bahasa Indonesia</a></div></li></ul></div><button id=hamburger onclick=kub.toggleMenu() data-auto-burger-exclude><div></div></button></nav></header><div class="container-fluid td-outer"><div class=td-main><div class="row flex-xl-nowrap"><main class="col-12 col-md-9 col-xl-8 pl-md-5" role=main><div class=td-content><div class="pageinfo pageinfo-primary d-print-none"><p>This is the multi-page printable view of this section.
<a href=# onclick="return print(),!1">Click here to print</a>.</p><p><a href=/docs/tutorials/stateful-application/>Return to the regular view of this page</a>.</p></div><h1 class=title>Stateful Applications</h1><ul><li>1: <a href=#pg-42e39658021b706bcc9478c8cc73c4a3>StatefulSet Basics</a></li><li>2: <a href=#pg-27580b3f65f3c2da07fc0f83be69da75>Example: Deploying WordPress and MySQL with Persistent Volumes</a></li><li>3: <a href=#pg-bf0d8e08fddd6e0282709b9fef8b5f67>Example: Deploying Cassandra with a StatefulSet</a></li><li>4: <a href=#pg-4bfac214b5eb9ebddaf1f3811901d327>Running ZooKeeper, A Distributed System Coordinator</a></li></ul><div class=content></div></div><div class=td-content><h1 id=pg-42e39658021b706bcc9478c8cc73c4a3>1 - StatefulSet Basics</h1><p>This tutorial provides an introduction to managing applications with
<a class=glossary-tooltip title='Manages deployment and scaling of a set of Pods, with durable storage and persistent identifiers for each Pod.' data-toggle=tooltip data-placement=top href=/docs/concepts/workloads/controllers/statefulset/ target=_blank aria-label=StatefulSets>StatefulSets</a>.
It demonstrates how to create, delete, scale, and update the Pods of StatefulSets.</p><h2 id=before-you-begin>Before you begin</h2><p>Before you begin this tutorial, you should familiarize yourself with the
following Kubernetes concepts:</p><ul><li><a href=/docs/concepts/workloads/pods/>Pods</a></li><li><a href=/docs/concepts/services-networking/dns-pod-service/>Cluster DNS</a></li><li><a href=/docs/concepts/services-networking/service/#headless-services>Headless Services</a></li><li><a href=/docs/concepts/storage/persistent-volumes/>PersistentVolumes</a></li><li><a href=https://github.com/kubernetes/examples/tree/master/staging/persistent-volume-provisioning/>PersistentVolume Provisioning</a></li><li><a href=/docs/concepts/workloads/controllers/statefulset/>StatefulSets</a></li><li>The <a href=/docs/reference/kubectl/kubectl/>kubectl</a> command line tool</li></ul><div class="alert alert-info note callout" role=alert><strong>Note:</strong> This tutorial assumes that your cluster is configured to dynamically provision
PersistentVolumes. If your cluster is not configured to do so, you
will have to manually provision two 1 GiB volumes prior to starting this
tutorial.</div><h2 id=objectives>Objectives</h2><p>StatefulSets are intended to be used with stateful applications and distributed
systems. However, the administration of stateful applications and
distributed systems on Kubernetes is a broad, complex topic. In order to
demonstrate the basic features of a StatefulSet, and not to conflate the former
topic with the latter, you will deploy a simple web application using a StatefulSet.</p><p>After this tutorial, you will be familiar with the following.</p><ul><li>How to create a StatefulSet</li><li>How a StatefulSet manages its Pods</li><li>How to delete a StatefulSet</li><li>How to scale a StatefulSet</li><li>How to update a StatefulSet's Pods</li></ul><h2 id=creating-a-statefulset>Creating a StatefulSet</h2><p>Begin by creating a StatefulSet using the example below. It is similar to the
example presented in the
<a href=/docs/concepts/workloads/controllers/statefulset/>StatefulSets</a> concept.
It creates a <a href=/docs/concepts/services-networking/service/#headless-services>headless Service</a>,
<code>nginx</code>, to publish the IP addresses of Pods in the StatefulSet, <code>web</code>.</p><div class=highlight><div class=copy-code-icon style=text-align:right><a href=https://raw.githubusercontent.com/kubernetes/website/main/content/en/examples/application/web/web.yaml download=application/web/web.yaml><code>application/web/web.yaml</code></a>
<img src=/images/copycode.svg style=max-height:24px;cursor:pointer onclick='copyCode("application-web-web-yaml")' title="Copy application/web/web.yaml to clipboard"></img></div><div class=includecode id=application-web-web-yaml><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Service<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>nginx<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>labels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>app</span>:<span style=color:#bbb> </span>nginx<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>ports</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>port</span>:<span style=color:#bbb> </span><span style=color:#666>80</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>web<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>clusterIP</span>:<span style=color:#bbb> </span>None<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>selector</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>app</span>:<span style=color:#bbb> </span>nginx<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:#00f;font-weight:700>---</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>apps/v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>StatefulSet<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>web<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>serviceName</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;nginx&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>replicas</span>:<span style=color:#bbb> </span><span style=color:#666>2</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>selector</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>matchLabels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>app</span>:<span style=color:#bbb> </span>nginx<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>template</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>labels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>app</span>:<span style=color:#bbb> </span>nginx<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>nginx<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>registry.k8s.io/nginx-slim:0.8<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>ports</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span>- <span style=color:green;font-weight:700>containerPort</span>:<span style=color:#bbb> </span><span style=color:#666>80</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>web<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>volumeMounts</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>www<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>mountPath</span>:<span style=color:#bbb> </span>/usr/share/nginx/html<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>volumeClaimTemplates</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>www<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>accessModes</span>:<span style=color:#bbb> </span>[<span style=color:#bbb> </span><span style=color:#b44>&#34;ReadWriteOnce&#34;</span><span style=color:#bbb> </span>]<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>resources</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>requests</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>storage</span>:<span style=color:#bbb> </span>1Gi<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>
</span></span></span></code></pre></div></div></div><p>Download the example above, and save it to a file named <code>web.yaml</code></p><p>You will need to use two terminal windows. In the first terminal, use
<a href=/docs/reference/generated/kubectl/kubectl-commands/#get><code>kubectl get</code></a> to watch the creation
of the StatefulSet's Pods.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get pods -w -l <span style=color:#b8860b>app</span><span style=color:#666>=</span>nginx
</span></span></code></pre></div><p>In the second terminal, use
<a href=/docs/reference/generated/kubectl/kubectl-commands/#apply><code>kubectl apply</code></a> to create the
headless Service and StatefulSet defined in <code>web.yaml</code>.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl apply -f web.yaml
</span></span></code></pre></div><pre tabindex=0><code>service/nginx created
statefulset.apps/web created
</code></pre><p>The command above creates two Pods, each running an
<a href=https://www.nginx.com>NGINX</a> webserver. Get the <code>nginx</code> Service...</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get service nginx
</span></span></code></pre></div><pre tabindex=0><code>NAME      TYPE         CLUSTER-IP   EXTERNAL-IP   PORT(S)   AGE
nginx     ClusterIP    None         &lt;none&gt;        80/TCP    12s
</code></pre><p>...then get the <code>web</code> StatefulSet, to verify that both were created successfully:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get statefulset web
</span></span></code></pre></div><pre tabindex=0><code>NAME      DESIRED   CURRENT   AGE
web       2         1         20s
</code></pre><h3 id=ordered-pod-creation>Ordered Pod Creation</h3><p>For a StatefulSet with <em>n</em> replicas, when Pods are being deployed, they are
created sequentially, ordered from <em>{0..n-1}</em>. Examine the output of the
<code>kubectl get</code> command in the first terminal. Eventually, the output will
look like the example below.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get pods -w -l <span style=color:#b8860b>app</span><span style=color:#666>=</span>nginx
</span></span></code></pre></div><pre tabindex=0><code>NAME      READY     STATUS    RESTARTS   AGE
web-0     0/1       Pending   0          0s
web-0     0/1       Pending   0         0s
web-0     0/1       ContainerCreating   0         0s
web-0     1/1       Running   0         19s
web-1     0/1       Pending   0         0s
web-1     0/1       Pending   0         0s
web-1     0/1       ContainerCreating   0         0s
web-1     1/1       Running   0         18s
</code></pre><p>Notice that the <code>web-1</code> Pod is not launched until the <code>web-0</code> Pod is
<em>Running</em> (see <a href=/docs/concepts/workloads/pods/pod-lifecycle/#pod-phase>Pod Phase</a>)
and <em>Ready</em> (see <code>type</code> in <a href=/docs/concepts/workloads/pods/pod-lifecycle/#pod-conditions>Pod Conditions</a>).</p><h2 id=pods-in-a-statefulset>Pods in a StatefulSet</h2><p>Pods in a StatefulSet have a unique ordinal index and a stable network identity.</p><h3 id=examining-the-pod-s-ordinal-index>Examining the Pod's Ordinal Index</h3><p>Get the StatefulSet's Pods:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get pods -l <span style=color:#b8860b>app</span><span style=color:#666>=</span>nginx
</span></span></code></pre></div><pre tabindex=0><code>NAME      READY     STATUS    RESTARTS   AGE
web-0     1/1       Running   0          1m
web-1     1/1       Running   0          1m
</code></pre><p>As mentioned in the <a href=/docs/concepts/workloads/controllers/statefulset/>StatefulSets</a>
concept, the Pods in a StatefulSet have a sticky, unique identity. This identity
is based on a unique ordinal index that is assigned to each Pod by the
StatefulSet <a class=glossary-tooltip title='A control loop that watches the shared state of the cluster through the apiserver and makes changes attempting to move the current state towards the desired state.' data-toggle=tooltip data-placement=top href=/docs/concepts/architecture/controller/ target=_blank aria-label=controller>controller</a>.<br>The Pods' names take the form <code>&lt;statefulset name>-&lt;ordinal index></code>.
Since the <code>web</code> StatefulSet has two replicas, it creates two Pods, <code>web-0</code> and <code>web-1</code>.</p><h3 id=using-stable-network-identities>Using Stable Network Identities</h3><p>Each Pod has a stable hostname based on its ordinal index. Use
<a href=/docs/reference/generated/kubectl/kubectl-commands/#exec><code>kubectl exec</code></a> to execute the
<code>hostname</code> command in each Pod:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span><span style=color:#a2f;font-weight:700>for</span> i in <span style=color:#666>0</span> 1; <span style=color:#a2f;font-weight:700>do</span> kubectl <span style=color:#a2f>exec</span> <span style=color:#b44>&#34;web-</span><span style=color:#b8860b>$i</span><span style=color:#b44>&#34;</span> -- sh -c <span style=color:#b44>&#39;hostname&#39;</span>; <span style=color:#a2f;font-weight:700>done</span>
</span></span></code></pre></div><pre tabindex=0><code>web-0
web-1
</code></pre><p>Use <a href=/docs/reference/generated/kubectl/kubectl-commands/#run><code>kubectl run</code></a> to execute
a container that provides the <code>nslookup</code> command from the <code>dnsutils</code> package.
Using <code>nslookup</code> on the Pods' hostnames, you can examine their in-cluster DNS
addresses:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl run -i --tty --image busybox:1.28 dns-test --restart<span style=color:#666>=</span>Never --rm
</span></span></code></pre></div><p>which starts a new shell. In that new shell, run:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span><span style=color:#080;font-style:italic># Run this in the dns-test container shell</span>
</span></span><span style=display:flex><span>nslookup web-0.nginx
</span></span></code></pre></div><p>The output is similar to:</p><pre tabindex=0><code>Server:    10.0.0.10
Address 1: 10.0.0.10 kube-dns.kube-system.svc.cluster.local

Name:      web-0.nginx
Address 1: 10.244.1.6

nslookup web-1.nginx
Server:    10.0.0.10
Address 1: 10.0.0.10 kube-dns.kube-system.svc.cluster.local

Name:      web-1.nginx
Address 1: 10.244.2.6
</code></pre><p>(and now exit the container shell: <code>exit</code>)</p><p>The CNAME of the headless service points to SRV records (one for each Pod that
is Running and Ready). The SRV records point to A record entries that
contain the Pods' IP addresses.</p><p>In one terminal, watch the StatefulSet's Pods:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get pod -w -l <span style=color:#b8860b>app</span><span style=color:#666>=</span>nginx
</span></span></code></pre></div><p>In a second terminal, use
<a href=/docs/reference/generated/kubectl/kubectl-commands/#delete><code>kubectl delete</code></a> to delete all
the Pods in the StatefulSet:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl delete pod -l <span style=color:#b8860b>app</span><span style=color:#666>=</span>nginx
</span></span></code></pre></div><pre tabindex=0><code>pod &#34;web-0&#34; deleted
pod &#34;web-1&#34; deleted
</code></pre><p>Wait for the StatefulSet to restart them, and for both Pods to transition to
Running and Ready:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get pod -w -l <span style=color:#b8860b>app</span><span style=color:#666>=</span>nginx
</span></span></code></pre></div><pre tabindex=0><code>NAME      READY     STATUS              RESTARTS   AGE
web-0     0/1       ContainerCreating   0          0s
NAME      READY     STATUS    RESTARTS   AGE
web-0     1/1       Running   0          2s
web-1     0/1       Pending   0         0s
web-1     0/1       Pending   0         0s
web-1     0/1       ContainerCreating   0         0s
web-1     1/1       Running   0         34s
</code></pre><p>Use <code>kubectl exec</code> and <code>kubectl run</code> to view the Pods' hostnames and in-cluster
DNS entries. First, view the Pods' hostnames:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span><span style=color:#a2f;font-weight:700>for</span> i in <span style=color:#666>0</span> 1; <span style=color:#a2f;font-weight:700>do</span> kubectl <span style=color:#a2f>exec</span> web-<span style=color:#b8860b>$i</span> -- sh -c <span style=color:#b44>&#39;hostname&#39;</span>; <span style=color:#a2f;font-weight:700>done</span>
</span></span></code></pre></div><pre tabindex=0><code>web-0
web-1
</code></pre><p>then, run:</p><pre tabindex=0><code>kubectl run -i --tty --image busybox:1.28 dns-test --restart=Never --rm /bin/sh
</code></pre><p>which starts a new shell.<br>In that new shell, run:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span><span style=color:#080;font-style:italic># Run this in the dns-test container shell</span>
</span></span><span style=display:flex><span>nslookup web-0.nginx
</span></span></code></pre></div><p>The output is similar to:</p><pre tabindex=0><code>Server:    10.0.0.10
Address 1: 10.0.0.10 kube-dns.kube-system.svc.cluster.local

Name:      web-0.nginx
Address 1: 10.244.1.7

nslookup web-1.nginx
Server:    10.0.0.10
Address 1: 10.0.0.10 kube-dns.kube-system.svc.cluster.local

Name:      web-1.nginx
Address 1: 10.244.2.8
</code></pre><p>(and now exit the container shell: <code>exit</code>)</p><p>The Pods' ordinals, hostnames, SRV records, and A record names have not changed,
but the IP addresses associated with the Pods may have changed. In the cluster
used for this tutorial, they have. This is why it is important not to configure
other applications to connect to Pods in a StatefulSet by IP address.</p><p>If you need to find and connect to the active members of a StatefulSet, you
should query the CNAME of the headless Service
(<code>nginx.default.svc.cluster.local</code>). The SRV records associated with the
CNAME will contain only the Pods in the StatefulSet that are Running and
Ready.</p><p>If your application already implements connection logic that tests for
liveness and readiness, you can use the SRV records of the Pods (
<code>web-0.nginx.default.svc.cluster.local</code>,
<code>web-1.nginx.default.svc.cluster.local</code>), as they are stable, and your
application will be able to discover the Pods' addresses when they transition
to Running and Ready.</p><h3 id=writing-to-stable-storage>Writing to Stable Storage</h3><p>Get the PersistentVolumeClaims for <code>web-0</code> and <code>web-1</code>:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get pvc -l <span style=color:#b8860b>app</span><span style=color:#666>=</span>nginx
</span></span></code></pre></div><p>The output is similar to:</p><pre tabindex=0><code>NAME        STATUS    VOLUME                                     CAPACITY   ACCESSMODES   AGE
www-web-0   Bound     pvc-15c268c7-b507-11e6-932f-42010a800002   1Gi        RWO           48s
www-web-1   Bound     pvc-15c79307-b507-11e6-932f-42010a800002   1Gi        RWO           48s
</code></pre><p>The StatefulSet controller created two
<a class=glossary-tooltip title='Claims storage resources defined in a PersistentVolume so that it can be mounted as a volume in a container.' data-toggle=tooltip data-placement=top href=/docs/concepts/storage/persistent-volumes/#persistentvolumeclaims target=_blank aria-label=PersistentVolumeClaims>PersistentVolumeClaims</a>
that are bound to two
<a class=glossary-tooltip title='An API object that represents a piece of storage in the cluster. Available as a general, pluggable resource that persists beyond the lifecycle of any individual Pod.' data-toggle=tooltip data-placement=top href=/docs/concepts/storage/persistent-volumes/ target=_blank aria-label=PersistentVolumes>PersistentVolumes</a>.</p><p>As the cluster used in this tutorial is configured to dynamically provision PersistentVolumes,
the PersistentVolumes were created and bound automatically.</p><p>The NGINX webserver, by default, serves an index file from
<code>/usr/share/nginx/html/index.html</code>. The <code>volumeMounts</code> field in the
StatefulSet's <code>spec</code> ensures that the <code>/usr/share/nginx/html</code> directory is
backed by a PersistentVolume.</p><p>Write the Pods' hostnames to their <code>index.html</code> files and verify that the NGINX
webservers serve the hostnames:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span><span style=color:#a2f;font-weight:700>for</span> i in <span style=color:#666>0</span> 1; <span style=color:#a2f;font-weight:700>do</span> kubectl <span style=color:#a2f>exec</span> <span style=color:#b44>&#34;web-</span><span style=color:#b8860b>$i</span><span style=color:#b44>&#34;</span> -- sh -c <span style=color:#b44>&#39;echo &#34;$(hostname)&#34; &gt; /usr/share/nginx/html/index.html&#39;</span>; <span style=color:#a2f;font-weight:700>done</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#a2f;font-weight:700>for</span> i in <span style=color:#666>0</span> 1; <span style=color:#a2f;font-weight:700>do</span> kubectl <span style=color:#a2f>exec</span> -i -t <span style=color:#b44>&#34;web-</span><span style=color:#b8860b>$i</span><span style=color:#b44>&#34;</span> -- curl http://localhost/; <span style=color:#a2f;font-weight:700>done</span>
</span></span></code></pre></div><pre tabindex=0><code>web-0
web-1
</code></pre><div class="alert alert-info note callout" role=alert><strong>Note:</strong><p>If you instead see <strong>403 Forbidden</strong> responses for the above curl command,
you will need to fix the permissions of the directory mounted by the <code>volumeMounts</code>
(due to a <a href=https://github.com/kubernetes/kubernetes/issues/2630>bug when using hostPath volumes</a>),
by running:</p><p><code>for i in 0 1; do kubectl exec web-$i -- chmod 755 /usr/share/nginx/html; done</code></p><p>before retrying the <code>curl</code> command above.</p></div><p>In one terminal, watch the StatefulSet's Pods:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get pod -w -l <span style=color:#b8860b>app</span><span style=color:#666>=</span>nginx
</span></span></code></pre></div><p>In a second terminal, delete all of the StatefulSet's Pods:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl delete pod -l <span style=color:#b8860b>app</span><span style=color:#666>=</span>nginx
</span></span></code></pre></div><pre tabindex=0><code>pod &#34;web-0&#34; deleted
pod &#34;web-1&#34; deleted
</code></pre><p>Examine the output of the <code>kubectl get</code> command in the first terminal, and wait
for all of the Pods to transition to Running and Ready.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get pod -w -l <span style=color:#b8860b>app</span><span style=color:#666>=</span>nginx
</span></span></code></pre></div><pre tabindex=0><code>NAME      READY     STATUS              RESTARTS   AGE
web-0     0/1       ContainerCreating   0          0s
NAME      READY     STATUS    RESTARTS   AGE
web-0     1/1       Running   0          2s
web-1     0/1       Pending   0         0s
web-1     0/1       Pending   0         0s
web-1     0/1       ContainerCreating   0         0s
web-1     1/1       Running   0         34s
</code></pre><p>Verify the web servers continue to serve their hostnames:</p><pre tabindex=0><code>for i in 0 1; do kubectl exec -i -t &#34;web-$i&#34; -- curl http://localhost/; done
</code></pre><pre tabindex=0><code>web-0
web-1
</code></pre><p>Even though <code>web-0</code> and <code>web-1</code> were rescheduled, they continue to serve their
hostnames because the PersistentVolumes associated with their
PersistentVolumeClaims are remounted to their <code>volumeMounts</code>. No matter what
node <code>web-0</code>and <code>web-1</code> are scheduled on, their PersistentVolumes will be
mounted to the appropriate mount points.</p><h2 id=scaling-a-statefulset>Scaling a StatefulSet</h2><p>Scaling a StatefulSet refers to increasing or decreasing the number of replicas.
This is accomplished by updating the <code>replicas</code> field. You can use either
<a href=/docs/reference/generated/kubectl/kubectl-commands/#scale><code>kubectl scale</code></a> or
<a href=/docs/reference/generated/kubectl/kubectl-commands/#patch><code>kubectl patch</code></a> to scale a StatefulSet.</p><h3 id=scaling-up>Scaling Up</h3><p>In one terminal window, watch the Pods in the StatefulSet:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get pods -w -l <span style=color:#b8860b>app</span><span style=color:#666>=</span>nginx
</span></span></code></pre></div><p>In another terminal window, use <code>kubectl scale</code> to scale the number of replicas
to 5:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl scale sts web --replicas<span style=color:#666>=</span><span style=color:#666>5</span>
</span></span></code></pre></div><pre tabindex=0><code>statefulset.apps/web scaled
</code></pre><p>Examine the output of the <code>kubectl get</code> command in the first terminal, and wait
for the three additional Pods to transition to Running and Ready.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get pods -w -l <span style=color:#b8860b>app</span><span style=color:#666>=</span>nginx
</span></span></code></pre></div><pre tabindex=0><code>NAME      READY     STATUS    RESTARTS   AGE
web-0     1/1       Running   0          2h
web-1     1/1       Running   0          2h
NAME      READY     STATUS    RESTARTS   AGE
web-2     0/1       Pending   0          0s
web-2     0/1       Pending   0         0s
web-2     0/1       ContainerCreating   0         0s
web-2     1/1       Running   0         19s
web-3     0/1       Pending   0         0s
web-3     0/1       Pending   0         0s
web-3     0/1       ContainerCreating   0         0s
web-3     1/1       Running   0         18s
web-4     0/1       Pending   0         0s
web-4     0/1       Pending   0         0s
web-4     0/1       ContainerCreating   0         0s
web-4     1/1       Running   0         19s
</code></pre><p>The StatefulSet controller scaled the number of replicas. As with
<a href=#ordered-pod-creation>StatefulSet creation</a>, the StatefulSet controller
created each Pod sequentially with respect to its ordinal index, and it
waited for each Pod's predecessor to be Running and Ready before launching the
subsequent Pod.</p><h3 id=scaling-down>Scaling Down</h3><p>In one terminal, watch the StatefulSet's Pods:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get pods -w -l <span style=color:#b8860b>app</span><span style=color:#666>=</span>nginx
</span></span></code></pre></div><p>In another terminal, use <code>kubectl patch</code> to scale the StatefulSet back down to
three replicas:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl patch sts web -p <span style=color:#b44>&#39;{&#34;spec&#34;:{&#34;replicas&#34;:3}}&#39;</span>
</span></span></code></pre></div><pre tabindex=0><code>statefulset.apps/web patched
</code></pre><p>Wait for <code>web-4</code> and <code>web-3</code> to transition to Terminating.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get pods -w -l <span style=color:#b8860b>app</span><span style=color:#666>=</span>nginx
</span></span></code></pre></div><pre tabindex=0><code>NAME      READY     STATUS              RESTARTS   AGE
web-0     1/1       Running             0          3h
web-1     1/1       Running             0          3h
web-2     1/1       Running             0          55s
web-3     1/1       Running             0          36s
web-4     0/1       ContainerCreating   0          18s
NAME      READY     STATUS    RESTARTS   AGE
web-4     1/1       Running   0          19s
web-4     1/1       Terminating   0         24s
web-4     1/1       Terminating   0         24s
web-3     1/1       Terminating   0         42s
web-3     1/1       Terminating   0         42s
</code></pre><h3 id=ordered-pod-termination>Ordered Pod Termination</h3><p>The controller deleted one Pod at a time, in reverse order with respect to its
ordinal index, and it waited for each to be completely shutdown before
deleting the next.</p><p>Get the StatefulSet's PersistentVolumeClaims:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get pvc -l <span style=color:#b8860b>app</span><span style=color:#666>=</span>nginx
</span></span></code></pre></div><pre tabindex=0><code>NAME        STATUS    VOLUME                                     CAPACITY   ACCESSMODES   AGE
www-web-0   Bound     pvc-15c268c7-b507-11e6-932f-42010a800002   1Gi        RWO           13h
www-web-1   Bound     pvc-15c79307-b507-11e6-932f-42010a800002   1Gi        RWO           13h
www-web-2   Bound     pvc-e1125b27-b508-11e6-932f-42010a800002   1Gi        RWO           13h
www-web-3   Bound     pvc-e1176df6-b508-11e6-932f-42010a800002   1Gi        RWO           13h
www-web-4   Bound     pvc-e11bb5f8-b508-11e6-932f-42010a800002   1Gi        RWO           13h
</code></pre><p>There are still five PersistentVolumeClaims and five PersistentVolumes.
When exploring a Pod's <a href=#writing-to-stable-storage>stable storage</a>, we saw that the PersistentVolumes mounted to the Pods of a StatefulSet are not deleted when the StatefulSet's Pods are deleted. This is still true when Pod deletion is caused by scaling the StatefulSet down.</p><h2 id=updating-statefulsets>Updating StatefulSets</h2><p>In Kubernetes 1.7 and later, the StatefulSet controller supports automated updates. The
strategy used is determined by the <code>spec.updateStrategy</code> field of the
StatefulSet API Object. This feature can be used to upgrade the container
images, resource requests and/or limits, labels, and annotations of the Pods in a
StatefulSet. There are two valid update strategies, <code>RollingUpdate</code> and
<code>OnDelete</code>.</p><p><code>RollingUpdate</code> update strategy is the default for StatefulSets.</p><h3 id=rolling-update>Rolling Update</h3><p>The <code>RollingUpdate</code> update strategy will update all Pods in a StatefulSet, in
reverse ordinal order, while respecting the StatefulSet guarantees.</p><p>Patch the <code>web</code> StatefulSet to apply the <code>RollingUpdate</code> update strategy:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl patch statefulset web -p <span style=color:#b44>&#39;{&#34;spec&#34;:{&#34;updateStrategy&#34;:{&#34;type&#34;:&#34;RollingUpdate&#34;}}}&#39;</span>
</span></span></code></pre></div><pre tabindex=0><code>statefulset.apps/web patched
</code></pre><p>In one terminal window, patch the <code>web</code> StatefulSet to change the container
image again:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl patch statefulset web --type<span style=color:#666>=</span><span style=color:#b44>&#39;json&#39;</span> -p<span style=color:#666>=</span><span style=color:#b44>&#39;[{&#34;op&#34;: &#34;replace&#34;, &#34;path&#34;: &#34;/spec/template/spec/containers/0/image&#34;, &#34;value&#34;:&#34;gcr.io/google_containers/nginx-slim:0.8&#34;}]&#39;</span>
</span></span></code></pre></div><pre tabindex=0><code>statefulset.apps/web patched
</code></pre><p>In another terminal, watch the Pods in the StatefulSet:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get pod -l <span style=color:#b8860b>app</span><span style=color:#666>=</span>nginx -w
</span></span></code></pre></div><p>The output is similar to:</p><pre tabindex=0><code>NAME      READY     STATUS    RESTARTS   AGE
web-0     1/1       Running   0          7m
web-1     1/1       Running   0          7m
web-2     1/1       Running   0          8m
web-2     1/1       Terminating   0         8m
web-2     1/1       Terminating   0         8m
web-2     0/1       Terminating   0         8m
web-2     0/1       Terminating   0         8m
web-2     0/1       Terminating   0         8m
web-2     0/1       Terminating   0         8m
web-2     0/1       Pending   0         0s
web-2     0/1       Pending   0         0s
web-2     0/1       ContainerCreating   0         0s
web-2     1/1       Running   0         19s
web-1     1/1       Terminating   0         8m
web-1     0/1       Terminating   0         8m
web-1     0/1       Terminating   0         8m
web-1     0/1       Terminating   0         8m
web-1     0/1       Pending   0         0s
web-1     0/1       Pending   0         0s
web-1     0/1       ContainerCreating   0         0s
web-1     1/1       Running   0         6s
web-0     1/1       Terminating   0         7m
web-0     1/1       Terminating   0         7m
web-0     0/1       Terminating   0         7m
web-0     0/1       Terminating   0         7m
web-0     0/1       Terminating   0         7m
web-0     0/1       Terminating   0         7m
web-0     0/1       Pending   0         0s
web-0     0/1       Pending   0         0s
web-0     0/1       ContainerCreating   0         0s
web-0     1/1       Running   0         10s
</code></pre><p>The Pods in the StatefulSet are updated in reverse ordinal order. The
StatefulSet controller terminates each Pod, and waits for it to transition to Running and
Ready prior to updating the next Pod. Note that, even though the StatefulSet
controller will not proceed to update the next Pod until its ordinal successor
is Running and Ready, it will restore any Pod that fails during the update to
its current version.</p><p>Pods that have already received the update will be restored to the updated version,
and Pods that have not yet received the update will be restored to the previous
version. In this way, the controller attempts to continue to keep the application
healthy and the update consistent in the presence of intermittent failures.</p><p>Get the Pods to view their container images:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span><span style=color:#a2f;font-weight:700>for</span> p in <span style=color:#666>0</span> <span style=color:#666>1</span> 2; <span style=color:#a2f;font-weight:700>do</span> kubectl get pod <span style=color:#b44>&#34;web-</span><span style=color:#b8860b>$p</span><span style=color:#b44>&#34;</span> --template <span style=color:#b44>&#39;{{range $i, $c := .spec.containers}}{{$c.image}}{{end}}&#39;</span>; echo; <span style=color:#a2f;font-weight:700>done</span>
</span></span></code></pre></div><pre tabindex=0><code>registry.k8s.io/nginx-slim:0.8
registry.k8s.io/nginx-slim:0.8
registry.k8s.io/nginx-slim:0.8
</code></pre><p>All the Pods in the StatefulSet are now running the previous container image.</p><div class="alert alert-info note callout" role=alert><strong>Note:</strong> You can also use <code>kubectl rollout status sts/&lt;name></code> to view
the status of a rolling update to a StatefulSet</div><h4 id=staging-an-update>Staging an Update</h4><p>You can stage an update to a StatefulSet by using the <code>partition</code> parameter of
the <code>RollingUpdate</code> update strategy. A staged update will keep all of the Pods
in the StatefulSet at the current version while allowing mutations to the
StatefulSet's <code>.spec.template</code>.</p><p>Patch the <code>web</code> StatefulSet to add a partition to the <code>updateStrategy</code> field:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl patch statefulset web -p <span style=color:#b44>&#39;{&#34;spec&#34;:{&#34;updateStrategy&#34;:{&#34;type&#34;:&#34;RollingUpdate&#34;,&#34;rollingUpdate&#34;:{&#34;partition&#34;:3}}}}&#39;</span>
</span></span></code></pre></div><pre tabindex=0><code>statefulset.apps/web patched
</code></pre><p>Patch the StatefulSet again to change the container's image:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl patch statefulset web --type<span style=color:#666>=</span><span style=color:#b44>&#39;json&#39;</span> -p<span style=color:#666>=</span><span style=color:#b44>&#39;[{&#34;op&#34;: &#34;replace&#34;, &#34;path&#34;: &#34;/spec/template/spec/containers/0/image&#34;, &#34;value&#34;:&#34;registry.k8s.io/nginx-slim:0.7&#34;}]&#39;</span>
</span></span></code></pre></div><pre tabindex=0><code>statefulset.apps/web patched
</code></pre><p>Delete a Pod in the StatefulSet:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl delete pod web-2
</span></span></code></pre></div><pre tabindex=0><code>pod &#34;web-2&#34; deleted
</code></pre><p>Wait for the Pod to be Running and Ready.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get pod -l <span style=color:#b8860b>app</span><span style=color:#666>=</span>nginx -w
</span></span></code></pre></div><pre tabindex=0><code>NAME      READY     STATUS              RESTARTS   AGE
web-0     1/1       Running             0          4m
web-1     1/1       Running             0          4m
web-2     0/1       ContainerCreating   0          11s
web-2     1/1       Running   0         18s
</code></pre><p>Get the Pod's container image:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get pod web-2 --template <span style=color:#b44>&#39;{{range $i, $c := .spec.containers}}{{$c.image}}{{end}}&#39;</span>
</span></span></code></pre></div><pre tabindex=0><code>registry.k8s.io/nginx-slim:0.8
</code></pre><p>Notice that, even though the update strategy is <code>RollingUpdate</code> the StatefulSet
restored the Pod with its original container. This is because the
ordinal of the Pod is less than the <code>partition</code> specified by the
<code>updateStrategy</code>.</p><h4 id=rolling-out-a-canary>Rolling Out a Canary</h4><p>You can roll out a canary to test a modification by decrementing the <code>partition</code>
you specified <a href=#staging-an-update>above</a>.</p><p>Patch the StatefulSet to decrement the partition:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl patch statefulset web -p <span style=color:#b44>&#39;{&#34;spec&#34;:{&#34;updateStrategy&#34;:{&#34;type&#34;:&#34;RollingUpdate&#34;,&#34;rollingUpdate&#34;:{&#34;partition&#34;:2}}}}&#39;</span>
</span></span></code></pre></div><pre tabindex=0><code>statefulset.apps/web patched
</code></pre><p>Wait for <code>web-2</code> to be Running and Ready.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get pod -l <span style=color:#b8860b>app</span><span style=color:#666>=</span>nginx -w
</span></span></code></pre></div><pre tabindex=0><code>NAME      READY     STATUS              RESTARTS   AGE
web-0     1/1       Running             0          4m
web-1     1/1       Running             0          4m
web-2     0/1       ContainerCreating   0          11s
web-2     1/1       Running   0         18s
</code></pre><p>Get the Pod's container:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get pod web-2 --template <span style=color:#b44>&#39;{{range $i, $c := .spec.containers}}{{$c.image}}{{end}}&#39;</span>
</span></span></code></pre></div><pre tabindex=0><code>registry.k8s.io/nginx-slim:0.7
</code></pre><p>When you changed the <code>partition</code>, the StatefulSet controller automatically
updated the <code>web-2</code> Pod because the Pod's ordinal was greater than or equal to
the <code>partition</code>.</p><p>Delete the <code>web-1</code> Pod:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl delete pod web-1
</span></span></code></pre></div><pre tabindex=0><code>pod &#34;web-1&#34; deleted
</code></pre><p>Wait for the <code>web-1</code> Pod to be Running and Ready.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get pod -l <span style=color:#b8860b>app</span><span style=color:#666>=</span>nginx -w
</span></span></code></pre></div><p>The output is similar to:</p><pre tabindex=0><code>NAME      READY     STATUS        RESTARTS   AGE
web-0     1/1       Running       0          6m
web-1     0/1       Terminating   0          6m
web-2     1/1       Running       0          2m
web-1     0/1       Terminating   0         6m
web-1     0/1       Terminating   0         6m
web-1     0/1       Terminating   0         6m
web-1     0/1       Pending   0         0s
web-1     0/1       Pending   0         0s
web-1     0/1       ContainerCreating   0         0s
web-1     1/1       Running   0         18s
</code></pre><p>Get the <code>web-1</code> Pod's container image:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get pod web-1 --template <span style=color:#b44>&#39;{{range $i, $c := .spec.containers}}{{$c.image}}{{end}}&#39;</span>
</span></span></code></pre></div><pre tabindex=0><code>registry.k8s.io/nginx-slim:0.8
</code></pre><p><code>web-1</code> was restored to its original configuration because the Pod's ordinal
was less than the partition. When a partition is specified, all Pods with an
ordinal that is greater than or equal to the partition will be updated when the
StatefulSet's <code>.spec.template</code> is updated. If a Pod that has an ordinal less
than the partition is deleted or otherwise terminated, it will be restored to
its original configuration.</p><h4 id=phased-roll-outs>Phased Roll Outs</h4><p>You can perform a phased roll out (e.g. a linear, geometric, or exponential
roll out) using a partitioned rolling update in a similar manner to how you
rolled out a <a href=#rolling-out-a-canary>canary</a>. To perform a phased roll out, set
the <code>partition</code> to the ordinal at which you want the controller to pause the
update.</p><p>The partition is currently set to <code>2</code>. Set the partition to <code>0</code>:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl patch statefulset web -p <span style=color:#b44>&#39;{&#34;spec&#34;:{&#34;updateStrategy&#34;:{&#34;type&#34;:&#34;RollingUpdate&#34;,&#34;rollingUpdate&#34;:{&#34;partition&#34;:0}}}}&#39;</span>
</span></span></code></pre></div><pre tabindex=0><code>statefulset.apps/web patched
</code></pre><p>Wait for all of the Pods in the StatefulSet to become Running and Ready.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get pod -l <span style=color:#b8860b>app</span><span style=color:#666>=</span>nginx -w
</span></span></code></pre></div><p>The output is similar to:</p><pre tabindex=0><code>NAME      READY     STATUS              RESTARTS   AGE
web-0     1/1       Running             0          3m
web-1     0/1       ContainerCreating   0          11s
web-2     1/1       Running             0          2m
web-1     1/1       Running   0         18s
web-0     1/1       Terminating   0         3m
web-0     1/1       Terminating   0         3m
web-0     0/1       Terminating   0         3m
web-0     0/1       Terminating   0         3m
web-0     0/1       Terminating   0         3m
web-0     0/1       Terminating   0         3m
web-0     0/1       Pending   0         0s
web-0     0/1       Pending   0         0s
web-0     0/1       ContainerCreating   0         0s
web-0     1/1       Running   0         3s
</code></pre><p>Get the container image details for the Pods in the StatefulSet:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span><span style=color:#a2f;font-weight:700>for</span> p in <span style=color:#666>0</span> <span style=color:#666>1</span> 2; <span style=color:#a2f;font-weight:700>do</span> kubectl get pod <span style=color:#b44>&#34;web-</span><span style=color:#b8860b>$p</span><span style=color:#b44>&#34;</span> --template <span style=color:#b44>&#39;{{range $i, $c := .spec.containers}}{{$c.image}}{{end}}&#39;</span>; echo; <span style=color:#a2f;font-weight:700>done</span>
</span></span></code></pre></div><pre tabindex=0><code>registry.k8s.io/nginx-slim:0.7
registry.k8s.io/nginx-slim:0.7
registry.k8s.io/nginx-slim:0.7
</code></pre><p>By moving the <code>partition</code> to <code>0</code>, you allowed the StatefulSet to
continue the update process.</p><h3 id=on-delete>On Delete</h3><p>The <code>OnDelete</code> update strategy implements the legacy (1.6 and prior) behavior,
When you select this update strategy, the StatefulSet controller will not
automatically update Pods when a modification is made to the StatefulSet's
<code>.spec.template</code> field. This strategy can be selected by setting the
<code>.spec.template.updateStrategy.type</code> to <code>OnDelete</code>.</p><h2 id=deleting-statefulsets>Deleting StatefulSets</h2><p>StatefulSet supports both Non-Cascading and Cascading deletion. In a
Non-Cascading Delete, the StatefulSet's Pods are not deleted when the StatefulSet is deleted. In a Cascading Delete, both the StatefulSet and its Pods are
deleted.</p><h3 id=non-cascading-delete>Non-Cascading Delete</h3><p>In one terminal window, watch the Pods in the StatefulSet.</p><pre tabindex=0><code>kubectl get pods -w -l app=nginx
</code></pre><p>Use <a href=/docs/reference/generated/kubectl/kubectl-commands/#delete><code>kubectl delete</code></a> to delete the
StatefulSet. Make sure to supply the <code>--cascade=orphan</code> parameter to the
command. This parameter tells Kubernetes to only delete the StatefulSet, and to
not delete any of its Pods.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl delete statefulset web --cascade<span style=color:#666>=</span>orphan
</span></span></code></pre></div><pre tabindex=0><code>statefulset.apps &#34;web&#34; deleted
</code></pre><p>Get the Pods, to examine their status:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get pods -l <span style=color:#b8860b>app</span><span style=color:#666>=</span>nginx
</span></span></code></pre></div><pre tabindex=0><code>NAME      READY     STATUS    RESTARTS   AGE
web-0     1/1       Running   0          6m
web-1     1/1       Running   0          7m
web-2     1/1       Running   0          5m
</code></pre><p>Even though <code>web</code> has been deleted, all of the Pods are still Running and Ready.
Delete <code>web-0</code>:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl delete pod web-0
</span></span></code></pre></div><pre tabindex=0><code>pod &#34;web-0&#34; deleted
</code></pre><p>Get the StatefulSet's Pods:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get pods -l <span style=color:#b8860b>app</span><span style=color:#666>=</span>nginx
</span></span></code></pre></div><pre tabindex=0><code>NAME      READY     STATUS    RESTARTS   AGE
web-1     1/1       Running   0          10m
web-2     1/1       Running   0          7m
</code></pre><p>As the <code>web</code> StatefulSet has been deleted, <code>web-0</code> has not been relaunched.</p><p>In one terminal, watch the StatefulSet's Pods.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get pods -w -l <span style=color:#b8860b>app</span><span style=color:#666>=</span>nginx
</span></span></code></pre></div><p>In a second terminal, recreate the StatefulSet. Note that, unless
you deleted the <code>nginx</code> Service (which you should not have), you will see
an error indicating that the Service already exists.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl apply -f web.yaml
</span></span></code></pre></div><pre tabindex=0><code>statefulset.apps/web created
service/nginx unchanged
</code></pre><p>Ignore the error. It only indicates that an attempt was made to create the <em>nginx</em>
headless Service even though that Service already exists.</p><p>Examine the output of the <code>kubectl get</code> command running in the first terminal.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get pods -w -l <span style=color:#b8860b>app</span><span style=color:#666>=</span>nginx
</span></span></code></pre></div><pre tabindex=0><code>NAME      READY     STATUS    RESTARTS   AGE
web-1     1/1       Running   0          16m
web-2     1/1       Running   0          2m
NAME      READY     STATUS    RESTARTS   AGE
web-0     0/1       Pending   0          0s
web-0     0/1       Pending   0         0s
web-0     0/1       ContainerCreating   0         0s
web-0     1/1       Running   0         18s
web-2     1/1       Terminating   0         3m
web-2     0/1       Terminating   0         3m
web-2     0/1       Terminating   0         3m
web-2     0/1       Terminating   0         3m
</code></pre><p>When the <code>web</code> StatefulSet was recreated, it first relaunched <code>web-0</code>.
Since <code>web-1</code> was already Running and Ready, when <code>web-0</code> transitioned to
Running and Ready, it adopted this Pod. Since you recreated the StatefulSet
with <code>replicas</code> equal to 2, once <code>web-0</code> had been recreated, and once
<code>web-1</code> had been determined to already be Running and Ready, <code>web-2</code> was
terminated.</p><p>Let's take another look at the contents of the <code>index.html</code> file served by the
Pods' webservers:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span><span style=color:#a2f;font-weight:700>for</span> i in <span style=color:#666>0</span> 1; <span style=color:#a2f;font-weight:700>do</span> kubectl <span style=color:#a2f>exec</span> -i -t <span style=color:#b44>&#34;web-</span><span style=color:#b8860b>$i</span><span style=color:#b44>&#34;</span> -- curl http://localhost/; <span style=color:#a2f;font-weight:700>done</span>
</span></span></code></pre></div><pre tabindex=0><code>web-0
web-1
</code></pre><p>Even though you deleted both the StatefulSet and the <code>web-0</code> Pod, it still
serves the hostname originally entered into its <code>index.html</code> file. This is
because the StatefulSet never deletes the PersistentVolumes associated with a
Pod. When you recreated the StatefulSet and it relaunched <code>web-0</code>, its original
PersistentVolume was remounted.</p><h3 id=cascading-delete>Cascading Delete</h3><p>In one terminal window, watch the Pods in the StatefulSet.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get pods -w -l <span style=color:#b8860b>app</span><span style=color:#666>=</span>nginx
</span></span></code></pre></div><p>In another terminal, delete the StatefulSet again. This time, omit the
<code>--cascade=orphan</code> parameter.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl delete statefulset web
</span></span></code></pre></div><pre tabindex=0><code>statefulset.apps &#34;web&#34; deleted
</code></pre><p>Examine the output of the <code>kubectl get</code> command running in the first terminal,
and wait for all of the Pods to transition to Terminating.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get pods -w -l <span style=color:#b8860b>app</span><span style=color:#666>=</span>nginx
</span></span></code></pre></div><pre tabindex=0><code>NAME      READY     STATUS    RESTARTS   AGE
web-0     1/1       Running   0          11m
web-1     1/1       Running   0          27m
NAME      READY     STATUS        RESTARTS   AGE
web-0     1/1       Terminating   0          12m
web-1     1/1       Terminating   0         29m
web-0     0/1       Terminating   0         12m
web-0     0/1       Terminating   0         12m
web-0     0/1       Terminating   0         12m
web-1     0/1       Terminating   0         29m
web-1     0/1       Terminating   0         29m
web-1     0/1       Terminating   0         29m
</code></pre><p>As you saw in the <a href=#scaling-down>Scaling Down</a> section, the Pods
are terminated one at a time, with respect to the reverse order of their ordinal
indices. Before terminating a Pod, the StatefulSet controller waits for
the Pod's successor to be completely terminated.</p><div class="alert alert-info note callout" role=alert><strong>Note:</strong> Although a cascading delete removes a StatefulSet together with its Pods,
the cascade does not delete the headless Service associated with the StatefulSet.
You must delete the <code>nginx</code> Service manually.</div><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl delete service nginx
</span></span></code></pre></div><pre tabindex=0><code>service &#34;nginx&#34; deleted
</code></pre><p>Recreate the StatefulSet and headless Service one more time:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl apply -f web.yaml
</span></span></code></pre></div><pre tabindex=0><code>service/nginx created
statefulset.apps/web created
</code></pre><p>When all of the StatefulSet's Pods transition to Running and Ready, retrieve
the contents of their <code>index.html</code> files:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span><span style=color:#a2f;font-weight:700>for</span> i in <span style=color:#666>0</span> 1; <span style=color:#a2f;font-weight:700>do</span> kubectl <span style=color:#a2f>exec</span> -i -t <span style=color:#b44>&#34;web-</span><span style=color:#b8860b>$i</span><span style=color:#b44>&#34;</span> -- curl http://localhost/; <span style=color:#a2f;font-weight:700>done</span>
</span></span></code></pre></div><pre tabindex=0><code>web-0
web-1
</code></pre><p>Even though you completely deleted the StatefulSet, and all of its Pods, the
Pods are recreated with their PersistentVolumes mounted, and <code>web-0</code> and
<code>web-1</code> continue to serve their hostnames.</p><p>Finally, delete the <code>nginx</code> Service...</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl delete service nginx
</span></span></code></pre></div><pre tabindex=0><code>service &#34;nginx&#34; deleted
</code></pre><p>...and the <code>web</code> StatefulSet:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl delete statefulset web
</span></span></code></pre></div><pre tabindex=0><code>statefulset &#34;web&#34; deleted
</code></pre><h2 id=pod-management-policy>Pod Management Policy</h2><p>For some distributed systems, the StatefulSet ordering guarantees are
unnecessary and/or undesirable. These systems require only uniqueness and
identity. To address this, in Kubernetes 1.7, we introduced
<code>.spec.podManagementPolicy</code> to the StatefulSet API Object.</p><h3 id=orderedready-pod-management>OrderedReady Pod Management</h3><p><code>OrderedReady</code> pod management is the default for StatefulSets. It tells the
StatefulSet controller to respect the ordering guarantees demonstrated
above.</p><h3 id=parallel-pod-management>Parallel Pod Management</h3><p><code>Parallel</code> pod management tells the StatefulSet controller to launch or
terminate all Pods in parallel, and not to wait for Pods to become Running
and Ready or completely terminated prior to launching or terminating another
Pod. This option only affects the behavior for scaling operations. Updates are not affected.</p><div class=highlight><div class=copy-code-icon style=text-align:right><a href=https://raw.githubusercontent.com/kubernetes/website/main/content/en/examples/application/web/web-parallel.yaml download=application/web/web-parallel.yaml><code>application/web/web-parallel.yaml</code></a>
<img src=/images/copycode.svg style=max-height:24px;cursor:pointer onclick='copyCode("application-web-web-parallel-yaml")' title="Copy application/web/web-parallel.yaml to clipboard"></img></div><div class=includecode id=application-web-web-parallel-yaml><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Service<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>nginx<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>labels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>app</span>:<span style=color:#bbb> </span>nginx<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>ports</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>port</span>:<span style=color:#bbb> </span><span style=color:#666>80</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>web<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>clusterIP</span>:<span style=color:#bbb> </span>None<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>selector</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>app</span>:<span style=color:#bbb> </span>nginx<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:#00f;font-weight:700>---</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>apps/v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>StatefulSet<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>web<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>serviceName</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;nginx&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>podManagementPolicy</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;Parallel&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>replicas</span>:<span style=color:#bbb> </span><span style=color:#666>2</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>selector</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>matchLabels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>app</span>:<span style=color:#bbb> </span>nginx<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>template</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>labels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>app</span>:<span style=color:#bbb> </span>nginx<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>nginx<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>registry.k8s.io/nginx-slim:0.8<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>ports</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span>- <span style=color:green;font-weight:700>containerPort</span>:<span style=color:#bbb> </span><span style=color:#666>80</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>web<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>volumeMounts</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>www<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>mountPath</span>:<span style=color:#bbb> </span>/usr/share/nginx/html<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>volumeClaimTemplates</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>www<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>accessModes</span>:<span style=color:#bbb> </span>[<span style=color:#bbb> </span><span style=color:#b44>&#34;ReadWriteOnce&#34;</span><span style=color:#bbb> </span>]<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>resources</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>requests</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>storage</span>:<span style=color:#bbb> </span>1Gi<span style=color:#bbb>
</span></span></span></code></pre></div></div></div><p>Download the example above, and save it to a file named <code>web-parallel.yaml</code></p><p>This manifest is identical to the one you downloaded above except that the <code>.spec.podManagementPolicy</code>
of the <code>web</code> StatefulSet is set to <code>Parallel</code>.</p><p>In one terminal, watch the Pods in the StatefulSet.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get pod -l <span style=color:#b8860b>app</span><span style=color:#666>=</span>nginx -w
</span></span></code></pre></div><p>In another terminal, create the StatefulSet and Service in the manifest:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl apply -f web-parallel.yaml
</span></span></code></pre></div><pre tabindex=0><code>service/nginx created
statefulset.apps/web created
</code></pre><p>Examine the output of the <code>kubectl get</code> command that you executed in the first terminal.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get pod -l <span style=color:#b8860b>app</span><span style=color:#666>=</span>nginx -w
</span></span></code></pre></div><pre tabindex=0><code>NAME      READY     STATUS    RESTARTS   AGE
web-0     0/1       Pending   0          0s
web-0     0/1       Pending   0         0s
web-1     0/1       Pending   0         0s
web-1     0/1       Pending   0         0s
web-0     0/1       ContainerCreating   0         0s
web-1     0/1       ContainerCreating   0         0s
web-0     1/1       Running   0         10s
web-1     1/1       Running   0         10s
</code></pre><p>The StatefulSet controller launched both <code>web-0</code> and <code>web-1</code> at the same time.</p><p>Keep the second terminal open, and, in another terminal window scale the
StatefulSet:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl scale statefulset/web --replicas<span style=color:#666>=</span><span style=color:#666>4</span>
</span></span></code></pre></div><pre tabindex=0><code>statefulset.apps/web scaled
</code></pre><p>Examine the output of the terminal where the <code>kubectl get</code> command is running.</p><pre tabindex=0><code>web-3     0/1       Pending   0         0s
web-3     0/1       Pending   0         0s
web-3     0/1       Pending   0         7s
web-3     0/1       ContainerCreating   0         7s
web-2     1/1       Running   0         10s
web-3     1/1       Running   0         26s
</code></pre><p>The StatefulSet launched two new Pods, and it did not wait for
the first to become Running and Ready prior to launching the second.</p><h2 id=cleaning-up>Cleaning up</h2><p>You should have two terminals open, ready for you to run <code>kubectl</code> commands as
part of cleanup.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl delete sts web
</span></span><span style=display:flex><span><span style=color:#080;font-style:italic># sts is an abbreviation for statefulset</span>
</span></span></code></pre></div><p>You can watch <code>kubectl get</code> to see those Pods being deleted.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get pod -l <span style=color:#b8860b>app</span><span style=color:#666>=</span>nginx -w
</span></span></code></pre></div><pre tabindex=0><code>web-3     1/1       Terminating   0         9m
web-2     1/1       Terminating   0         9m
web-3     1/1       Terminating   0         9m
web-2     1/1       Terminating   0         9m
web-1     1/1       Terminating   0         44m
web-0     1/1       Terminating   0         44m
web-0     0/1       Terminating   0         44m
web-3     0/1       Terminating   0         9m
web-2     0/1       Terminating   0         9m
web-1     0/1       Terminating   0         44m
web-0     0/1       Terminating   0         44m
web-2     0/1       Terminating   0         9m
web-2     0/1       Terminating   0         9m
web-2     0/1       Terminating   0         9m
web-1     0/1       Terminating   0         44m
web-1     0/1       Terminating   0         44m
web-1     0/1       Terminating   0         44m
web-0     0/1       Terminating   0         44m
web-0     0/1       Terminating   0         44m
web-0     0/1       Terminating   0         44m
web-3     0/1       Terminating   0         9m
web-3     0/1       Terminating   0         9m
web-3     0/1       Terminating   0         9m
</code></pre><p>During deletion, a StatefulSet removes all Pods concurrently; it does not wait for
a Pod's ordinal successor to terminate prior to deleting that Pod.</p><p>Close the terminal where the <code>kubectl get</code> command is running and delete the <code>nginx</code>
Service:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl delete svc nginx
</span></span></code></pre></div><p>Delete the persistent storage media for the PersistentVolumes used in this tutorial.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get pvc
</span></span></code></pre></div><pre tabindex=0><code>NAME        STATUS   VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS   AGE
www-web-0   Bound    pvc-2bf00408-d366-4a12-bad0-1869c65d0bee   1Gi        RWO            standard       25m
www-web-1   Bound    pvc-ba3bfe9c-413e-4b95-a2c0-3ea8a54dbab4   1Gi        RWO            standard       24m
www-web-2   Bound    pvc-cba6cfa6-3a47-486b-a138-db5930207eaf   1Gi        RWO            standard       15m
www-web-3   Bound    pvc-0c04d7f0-787a-4977-8da3-d9d3a6d8d752   1Gi        RWO            standard       15m
www-web-4   Bound    pvc-b2c73489-e70b-4a4e-9ec1-9eab439aa43e   1Gi        RWO            standard       14m
</code></pre><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get pv
</span></span></code></pre></div><pre tabindex=0><code>NAME                                       CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS   CLAIM               STORAGECLASS   REASON   AGE
pvc-0c04d7f0-787a-4977-8da3-d9d3a6d8d752   1Gi        RWO            Delete           Bound    default/www-web-3   standard                15m
pvc-2bf00408-d366-4a12-bad0-1869c65d0bee   1Gi        RWO            Delete           Bound    default/www-web-0   standard                25m
pvc-b2c73489-e70b-4a4e-9ec1-9eab439aa43e   1Gi        RWO            Delete           Bound    default/www-web-4   standard                14m
pvc-ba3bfe9c-413e-4b95-a2c0-3ea8a54dbab4   1Gi        RWO            Delete           Bound    default/www-web-1   standard                24m
pvc-cba6cfa6-3a47-486b-a138-db5930207eaf   1Gi        RWO            Delete           Bound    default/www-web-2   standard                15m
</code></pre><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl delete pvc www-web-0 www-web-1 www-web-2 www-web-3 www-web-4
</span></span></code></pre></div><pre tabindex=0><code>persistentvolumeclaim &#34;www-web-0&#34; deleted
persistentvolumeclaim &#34;www-web-1&#34; deleted
persistentvolumeclaim &#34;www-web-2&#34; deleted
persistentvolumeclaim &#34;www-web-3&#34; deleted
persistentvolumeclaim &#34;www-web-4&#34; deleted
</code></pre><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get pvc
</span></span></code></pre></div><pre tabindex=0><code>No resources found in default namespace.
</code></pre><div class="alert alert-info note callout" role=alert><strong>Note:</strong> You also need to delete the persistent storage media for the PersistentVolumes
used in this tutorial.
Follow the necessary steps, based on your environment, storage configuration,
and provisioning method, to ensure that all storage is reclaimed.</div></div><div class=td-content style=page-break-before:always><h1 id=pg-27580b3f65f3c2da07fc0f83be69da75>2 - Example: Deploying WordPress and MySQL with Persistent Volumes</h1><p>This tutorial shows you how to deploy a WordPress site and a MySQL database using Minikube. Both applications use PersistentVolumes and PersistentVolumeClaims to store data.</p><p>A <a href=/docs/concepts/storage/persistent-volumes/>PersistentVolume</a> (PV) is a piece of storage in the cluster that has been manually provisioned by an administrator, or dynamically provisioned by Kubernetes using a <a href=/docs/concepts/storage/storage-classes>StorageClass</a>. A <a href=/docs/concepts/storage/persistent-volumes/#persistentvolumeclaims>PersistentVolumeClaim</a> (PVC) is a request for storage by a user that can be fulfilled by a PV. PersistentVolumes and PersistentVolumeClaims are independent from Pod lifecycles and preserve data through restarting, rescheduling, and even deleting Pods.</p><div class="alert alert-danger warning callout" role=alert><strong>Warning:</strong> This deployment is not suitable for production use cases, as it uses single instance WordPress and MySQL Pods. Consider using <a href=https://github.com/bitnami/charts/tree/master/bitnami/wordpress>WordPress Helm Chart</a> to deploy WordPress in production.</div><div class="alert alert-info note callout" role=alert><strong>Note:</strong> The files provided in this tutorial are using GA Deployment APIs and are specific to kubernetes version 1.9 and later. If you wish to use this tutorial with an earlier version of Kubernetes, please update the API version appropriately, or reference earlier versions of this tutorial.</div><h2 id=objectives>Objectives</h2><ul><li>Create PersistentVolumeClaims and PersistentVolumes</li><li>Create a <code>kustomization.yaml</code> with<ul><li>a Secret generator</li><li>MySQL resource configs</li><li>WordPress resource configs</li></ul></li><li>Apply the kustomization directory by <code>kubectl apply -k ./</code></li><li>Clean up</li></ul><h2 id=before-you-begin>Before you begin</h2><p><p>You need to have a Kubernetes cluster, and the kubectl command-line tool must
be configured to communicate with your cluster. It is recommended to run this tutorial on a cluster with at least two nodes that are not acting as control plane hosts. If you do not already have a
cluster, you can create one by using
<a href=https://minikube.sigs.k8s.io/docs/tutorials/multi_node/>minikube</a>
or you can use one of these Kubernetes playgrounds:</p><ul><li><a href=https://killercoda.com/playgrounds/scenario/kubernetes>Killercoda</a></li><li><a href=http://labs.play-with-k8s.com/>Play with Kubernetes</a></li></ul>To check the version, enter <code>kubectl version</code>.
The example shown on this page works with <code>kubectl</code> 1.14 and above.</p><p>Download the following configuration files:</p><ol><li><p><a href=/examples/application/wordpress/mysql-deployment.yaml>mysql-deployment.yaml</a></p></li><li><p><a href=/examples/application/wordpress/wordpress-deployment.yaml>wordpress-deployment.yaml</a></p></li></ol><h2 id=create-persistentvolumeclaims-and-persistentvolumes>Create PersistentVolumeClaims and PersistentVolumes</h2><p>MySQL and Wordpress each require a PersistentVolume to store data. Their PersistentVolumeClaims will be created at the deployment step.</p><p>Many cluster environments have a default StorageClass installed. When a StorageClass is not specified in the PersistentVolumeClaim, the cluster's default StorageClass is used instead.</p><p>When a PersistentVolumeClaim is created, a PersistentVolume is dynamically provisioned based on the StorageClass configuration.</p><div class="alert alert-danger warning callout" role=alert><strong>Warning:</strong> In local clusters, the default StorageClass uses the <code>hostPath</code> provisioner. <code>hostPath</code> volumes are only suitable for development and testing. With <code>hostPath</code> volumes, your data lives in <code>/tmp</code> on the node the Pod is scheduled onto and does not move between nodes. If a Pod dies and gets scheduled to another node in the cluster, or the node is rebooted, the data is lost.</div><div class="alert alert-info note callout" role=alert><strong>Note:</strong> If you are bringing up a cluster that needs to use the <code>hostPath</code> provisioner, the <code>--enable-hostpath-provisioner</code> flag must be set in the <code>controller-manager</code> component.</div><div class="alert alert-info note callout" role=alert><strong>Note:</strong> If you have a Kubernetes cluster running on Google Kubernetes Engine, please follow <a href=https://cloud.google.com/kubernetes-engine/docs/tutorials/persistent-disk>this guide</a>.</div><h2 id=create-a-kustomization-yaml>Create a kustomization.yaml</h2><h3 id=add-a-secret-generator>Add a Secret generator</h3><p>A <a href=/docs/concepts/configuration/secret/>Secret</a> is an object that stores a piece of sensitive data like a password or key. Since 1.14, <code>kubectl</code> supports the management of Kubernetes objects using a kustomization file. You can create a Secret by generators in <code>kustomization.yaml</code>.</p><p>Add a Secret generator in <code>kustomization.yaml</code> from the following command. You will need to replace <code>YOUR_PASSWORD</code> with the password you want to use.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>cat <span style=color:#b44>&lt;&lt;EOF &gt;./kustomization.yaml
</span></span></span><span style=display:flex><span><span style=color:#b44>secretGenerator:
</span></span></span><span style=display:flex><span><span style=color:#b44>- name: mysql-pass
</span></span></span><span style=display:flex><span><span style=color:#b44>  literals:
</span></span></span><span style=display:flex><span><span style=color:#b44>  - password=YOUR_PASSWORD
</span></span></span><span style=display:flex><span><span style=color:#b44>EOF</span>
</span></span></code></pre></div><h2 id=add-resource-configs-for-mysql-and-wordpress>Add resource configs for MySQL and WordPress</h2><p>The following manifest describes a single-instance MySQL Deployment. The MySQL container mounts the PersistentVolume at /var/lib/mysql. The <code>MYSQL_ROOT_PASSWORD</code> environment variable sets the database password from the Secret.</p><div class=highlight><div class=copy-code-icon style=text-align:right><a href=https://raw.githubusercontent.com/kubernetes/website/main/content/en/examples/application/wordpress/mysql-deployment.yaml download=application/wordpress/mysql-deployment.yaml><code>application/wordpress/mysql-deployment.yaml</code></a>
<img src=/images/copycode.svg style=max-height:24px;cursor:pointer onclick='copyCode("application-wordpress-mysql-deployment-yaml")' title="Copy application/wordpress/mysql-deployment.yaml to clipboard"></img></div><div class=includecode id=application-wordpress-mysql-deployment-yaml><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Service<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>wordpress-mysql<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>labels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>app</span>:<span style=color:#bbb> </span>wordpress<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>ports</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:green;font-weight:700>port</span>:<span style=color:#bbb> </span><span style=color:#666>3306</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>selector</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>app</span>:<span style=color:#bbb> </span>wordpress<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>tier</span>:<span style=color:#bbb> </span>mysql<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>clusterIP</span>:<span style=color:#bbb> </span>None<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:#00f;font-weight:700>---</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>PersistentVolumeClaim<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>mysql-pv-claim<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>labels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>app</span>:<span style=color:#bbb> </span>wordpress<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>accessModes</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- ReadWriteOnce<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>resources</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>requests</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>storage</span>:<span style=color:#bbb> </span>20Gi<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:#00f;font-weight:700>---</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>apps/v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Deployment<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>wordpress-mysql<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>labels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>app</span>:<span style=color:#bbb> </span>wordpress<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>selector</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>matchLabels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>app</span>:<span style=color:#bbb> </span>wordpress<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>tier</span>:<span style=color:#bbb> </span>mysql<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>strategy</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>type</span>:<span style=color:#bbb> </span>Recreate<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>template</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>labels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>app</span>:<span style=color:#bbb> </span>wordpress<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>tier</span>:<span style=color:#bbb> </span>mysql<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- <span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>mysql:5.6<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>mysql<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>env</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>MYSQL_ROOT_PASSWORD<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>valueFrom</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>            </span><span style=color:green;font-weight:700>secretKeyRef</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>              </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>mysql-pass<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>              </span><span style=color:green;font-weight:700>key</span>:<span style=color:#bbb> </span>password<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>ports</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span>- <span style=color:green;font-weight:700>containerPort</span>:<span style=color:#bbb> </span><span style=color:#666>3306</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>mysql<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>volumeMounts</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>mysql-persistent-storage<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>mountPath</span>:<span style=color:#bbb> </span>/var/lib/mysql<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>volumes</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>mysql-persistent-storage<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>persistentVolumeClaim</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>claimName</span>:<span style=color:#bbb> </span>mysql-pv-claim<span style=color:#bbb>
</span></span></span></code></pre></div></div></div><p>The following manifest describes a single-instance WordPress Deployment. The WordPress container mounts the
PersistentVolume at <code>/var/www/html</code> for website data files. The <code>WORDPRESS_DB_HOST</code> environment variable sets
the name of the MySQL Service defined above, and WordPress will access the database by Service. The
<code>WORDPRESS_DB_PASSWORD</code> environment variable sets the database password from the Secret kustomize generated.</p><div class=highlight><div class=copy-code-icon style=text-align:right><a href=https://raw.githubusercontent.com/kubernetes/website/main/content/en/examples/application/wordpress/wordpress-deployment.yaml download=application/wordpress/wordpress-deployment.yaml><code>application/wordpress/wordpress-deployment.yaml</code></a>
<img src=/images/copycode.svg style=max-height:24px;cursor:pointer onclick='copyCode("application-wordpress-wordpress-deployment-yaml")' title="Copy application/wordpress/wordpress-deployment.yaml to clipboard"></img></div><div class=includecode id=application-wordpress-wordpress-deployment-yaml><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Service<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>wordpress<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>labels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>app</span>:<span style=color:#bbb> </span>wordpress<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>ports</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:green;font-weight:700>port</span>:<span style=color:#bbb> </span><span style=color:#666>80</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>selector</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>app</span>:<span style=color:#bbb> </span>wordpress<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>tier</span>:<span style=color:#bbb> </span>frontend<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>type</span>:<span style=color:#bbb> </span>LoadBalancer<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:#00f;font-weight:700>---</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>PersistentVolumeClaim<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>wp-pv-claim<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>labels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>app</span>:<span style=color:#bbb> </span>wordpress<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>accessModes</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- ReadWriteOnce<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>resources</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>requests</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>storage</span>:<span style=color:#bbb> </span>20Gi<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:#00f;font-weight:700>---</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>apps/v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Deployment<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>wordpress<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>labels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>app</span>:<span style=color:#bbb> </span>wordpress<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>selector</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>matchLabels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>app</span>:<span style=color:#bbb> </span>wordpress<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>tier</span>:<span style=color:#bbb> </span>frontend<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>strategy</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>type</span>:<span style=color:#bbb> </span>Recreate<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>template</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>labels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>app</span>:<span style=color:#bbb> </span>wordpress<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>tier</span>:<span style=color:#bbb> </span>frontend<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- <span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>wordpress:4.8-apache<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>wordpress<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>env</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>WORDPRESS_DB_HOST<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>value</span>:<span style=color:#bbb> </span>wordpress-mysql<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>WORDPRESS_DB_PASSWORD<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>valueFrom</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>            </span><span style=color:green;font-weight:700>secretKeyRef</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>              </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>mysql-pass<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>              </span><span style=color:green;font-weight:700>key</span>:<span style=color:#bbb> </span>password<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>ports</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span>- <span style=color:green;font-weight:700>containerPort</span>:<span style=color:#bbb> </span><span style=color:#666>80</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>wordpress<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>volumeMounts</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>wordpress-persistent-storage<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>mountPath</span>:<span style=color:#bbb> </span>/var/www/html<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>volumes</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>wordpress-persistent-storage<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>persistentVolumeClaim</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>claimName</span>:<span style=color:#bbb> </span>wp-pv-claim<span style=color:#bbb>
</span></span></span></code></pre></div></div></div><ol><li><p>Download the MySQL deployment configuration file.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>curl -LO https://k8s.io/examples/application/wordpress/mysql-deployment.yaml
</span></span></code></pre></div></li><li><p>Download the WordPress configuration file.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>curl -LO https://k8s.io/examples/application/wordpress/wordpress-deployment.yaml
</span></span></code></pre></div></li><li><p>Add them to <code>kustomization.yaml</code> file.</p></li></ol><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>cat <span style=color:#b44>&lt;&lt;EOF &gt;&gt;./kustomization.yaml
</span></span></span><span style=display:flex><span><span style=color:#b44>resources:
</span></span></span><span style=display:flex><span><span style=color:#b44>  - mysql-deployment.yaml
</span></span></span><span style=display:flex><span><span style=color:#b44>  - wordpress-deployment.yaml
</span></span></span><span style=display:flex><span><span style=color:#b44>EOF</span>
</span></span></code></pre></div><h2 id=apply-and-verify>Apply and Verify</h2><p>The <code>kustomization.yaml</code> contains all the resources for deploying a WordPress site and a
MySQL database. You can apply the directory by</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl apply -k ./
</span></span></code></pre></div><p>Now you can verify that all objects exist.</p><ol><li><p>Verify that the Secret exists by running the following command:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get secrets
</span></span></code></pre></div><p>The response should be like this:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>NAME                    TYPE                                  DATA   AGE
</span></span><span style=display:flex><span>mysql-pass-c57bb4t7mf   Opaque                                <span style=color:#666>1</span>      9s
</span></span></code></pre></div></li><li><p>Verify that a PersistentVolume got dynamically provisioned.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get pvc
</span></span></code></pre></div><div class="alert alert-info note callout" role=alert><strong>Note:</strong> It can take up to a few minutes for the PVs to be provisioned and bound.</div><p>The response should be like this:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>NAME             STATUS    VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS       AGE
</span></span><span style=display:flex><span>mysql-pv-claim   Bound     pvc-8cbd7b2e-4044-11e9-b2bb-42010a800002   20Gi       RWO            standard           77s
</span></span><span style=display:flex><span>wp-pv-claim      Bound     pvc-8cd0df54-4044-11e9-b2bb-42010a800002   20Gi       RWO            standard           77s
</span></span></code></pre></div></li><li><p>Verify that the Pod is running by running the following command:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get pods
</span></span></code></pre></div><div class="alert alert-info note callout" role=alert><strong>Note:</strong> It can take up to a few minutes for the Pod's Status to be <code>RUNNING</code>.</div><p>The response should be like this:</p><pre tabindex=0><code>NAME                               READY     STATUS    RESTARTS   AGE
wordpress-mysql-1894417608-x5dzt   1/1       Running   0          40s
</code></pre></li><li><p>Verify that the Service is running by running the following command:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get services wordpress
</span></span></code></pre></div><p>The response should be like this:</p><pre tabindex=0><code>NAME        TYPE            CLUSTER-IP   EXTERNAL-IP   PORT(S)        AGE
wordpress   LoadBalancer    10.0.0.89    &lt;pending&gt;     80:32406/TCP   4m
</code></pre><div class="alert alert-info note callout" role=alert><strong>Note:</strong> Minikube can only expose Services through <code>NodePort</code>. The EXTERNAL-IP is always pending.</div></li><li><p>Run the following command to get the IP Address for the WordPress Service:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>minikube service wordpress --url
</span></span></code></pre></div><p>The response should be like this:</p><pre tabindex=0><code>http://1.2.3.4:32406
</code></pre></li><li><p>Copy the IP address, and load the page in your browser to view your site.</p><p>You should see the WordPress set up page similar to the following screenshot.</p><p><img src=https://raw.githubusercontent.com/kubernetes/examples/master/mysql-wordpress-pd/WordPress.png alt=wordpress-init></p></li></ol><div class="alert alert-danger warning callout" role=alert><strong>Warning:</strong> Do not leave your WordPress installation on this page. If another user finds it, they can set up a website on your instance and use it to serve malicious content.<br><br>Either install WordPress by creating a username and password or delete your instance.</div><h2 id=cleaning-up>Cleaning up</h2><ol><li><p>Run the following command to delete your Secret, Deployments, Services and PersistentVolumeClaims:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl delete -k ./
</span></span></code></pre></div></li></ol><h2 id=what-s-next>What's next</h2><ul><li>Learn more about <a href=/docs/tasks/debug/debug-application/debug-running-pod/>Introspection and Debugging</a></li><li>Learn more about <a href=/docs/concepts/workloads/controllers/job/>Jobs</a></li><li>Learn more about <a href=/docs/tasks/access-application-cluster/port-forward-access-application-cluster/>Port Forwarding</a></li><li>Learn how to <a href=/docs/tasks/debug/debug-application/get-shell-running-container/>Get a Shell to a Container</a></li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-bf0d8e08fddd6e0282709b9fef8b5f67>3 - Example: Deploying Cassandra with a StatefulSet</h1><p>This tutorial shows you how to run <a href=https://cassandra.apache.org/>Apache Cassandra</a> on Kubernetes.
Cassandra, a database, needs persistent storage to provide data durability (application <em>state</em>).
In this example, a custom Cassandra seed provider lets the database discover new Cassandra instances as they join the Cassandra cluster.</p><p><em>StatefulSets</em> make it easier to deploy stateful applications into your Kubernetes cluster.
For more information on the features used in this tutorial, see
<a href=/docs/concepts/workloads/controllers/statefulset/>StatefulSet</a>.</p><div class="alert alert-info note callout" role=alert><strong>Note:</strong><p>Cassandra and Kubernetes both use the term <em>node</em> to mean a member of a cluster. In this
tutorial, the Pods that belong to the StatefulSet are Cassandra nodes and are members
of the Cassandra cluster (called a <em>ring</em>). When those Pods run in your Kubernetes cluster,
the Kubernetes control plane schedules those Pods onto Kubernetes
<a class=glossary-tooltip title='A node is a worker machine in Kubernetes.' data-toggle=tooltip data-placement=top href=/docs/concepts/architecture/nodes/ target=_blank aria-label=Nodes>Nodes</a>.</p><p>When a Cassandra node starts, it uses a <em>seed list</em> to bootstrap discovery of other
nodes in the ring.
This tutorial deploys a custom Cassandra seed provider that lets the database discover
new Cassandra Pods as they appear inside your Kubernetes cluster.</p></div><h2 id=objectives>Objectives</h2><ul><li>Create and validate a Cassandra headless <a class=glossary-tooltip title='A way to expose an application running on a set of Pods as a network service.' data-toggle=tooltip data-placement=top href=/docs/concepts/services-networking/service/ target=_blank aria-label=Service>Service</a>.</li><li>Use a <a class=glossary-tooltip title='Manages deployment and scaling of a set of Pods, with durable storage and persistent identifiers for each Pod.' data-toggle=tooltip data-placement=top href=/docs/concepts/workloads/controllers/statefulset/ target=_blank aria-label=StatefulSet>StatefulSet</a> to create a Cassandra ring.</li><li>Validate the StatefulSet.</li><li>Modify the StatefulSet.</li><li>Delete the StatefulSet and its <a class=glossary-tooltip title='A Pod represents a set of running containers in your cluster.' data-toggle=tooltip data-placement=top href=/docs/concepts/workloads/pods/ target=_blank aria-label=Pods>Pods</a>.</li></ul><h2 id=before-you-begin>Before you begin</h2><p>You need to have a Kubernetes cluster, and the kubectl command-line tool must
be configured to communicate with your cluster. It is recommended to run this tutorial on a cluster with at least two nodes that are not acting as control plane hosts. If you do not already have a
cluster, you can create one by using
<a href=https://minikube.sigs.k8s.io/docs/tutorials/multi_node/>minikube</a>
or you can use one of these Kubernetes playgrounds:</p><ul><li><a href=https://killercoda.com/playgrounds/scenario/kubernetes>Killercoda</a></li><li><a href=http://labs.play-with-k8s.com/>Play with Kubernetes</a></li></ul><p>To complete this tutorial, you should already have a basic familiarity with
<a class=glossary-tooltip title='A Pod represents a set of running containers in your cluster.' data-toggle=tooltip data-placement=top href=/docs/concepts/workloads/pods/ target=_blank aria-label=Pods>Pods</a>,
<a class=glossary-tooltip title='A way to expose an application running on a set of Pods as a network service.' data-toggle=tooltip data-placement=top href=/docs/concepts/services-networking/service/ target=_blank aria-label=Services>Services</a>, and
<a class=glossary-tooltip title='Manages deployment and scaling of a set of Pods, with durable storage and persistent identifiers for each Pod.' data-toggle=tooltip data-placement=top href=/docs/concepts/workloads/controllers/statefulset/ target=_blank aria-label=StatefulSets>StatefulSets</a>.</p><h3 id=additional-minikube-setup-instructions>Additional Minikube setup instructions</h3><div class="alert alert-warning caution callout" role=alert><strong>Caution:</strong><p><a href=https://minikube.sigs.k8s.io/docs/>Minikube</a> defaults to 2048MB of memory and 2 CPU.
Running Minikube with the default resource configuration results in insufficient resource
errors during this tutorial. To avoid these errors, start Minikube with the following settings:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>minikube start --memory <span style=color:#666>5120</span> --cpus<span style=color:#666>=</span><span style=color:#666>4</span>
</span></span></code></pre></div></div><h2 id=creating-a-cassandra-headless-service>Creating a headless Service for Cassandra</h2><p>In Kubernetes, a <a class=glossary-tooltip title='A way to expose an application running on a set of Pods as a network service.' data-toggle=tooltip data-placement=top href=/docs/concepts/services-networking/service/ target=_blank aria-label=Service>Service</a> describes a set of
<a class=glossary-tooltip title='A Pod represents a set of running containers in your cluster.' data-toggle=tooltip data-placement=top href=/docs/concepts/workloads/pods/ target=_blank aria-label=Pods>Pods</a> that perform the same task.</p><p>The following Service is used for DNS lookups between Cassandra Pods and clients within your cluster:</p><div class=highlight><div class=copy-code-icon style=text-align:right><a href=https://raw.githubusercontent.com/kubernetes/website/main/content/en/examples/application/cassandra/cassandra-service.yaml download=application/cassandra/cassandra-service.yaml><code>application/cassandra/cassandra-service.yaml</code></a>
<img src=/images/copycode.svg style=max-height:24px;cursor:pointer onclick='copyCode("application-cassandra-cassandra-service-yaml")' title="Copy application/cassandra/cassandra-service.yaml to clipboard"></img></div><div class=includecode id=application-cassandra-cassandra-service-yaml><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Service<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>labels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>app</span>:<span style=color:#bbb> </span>cassandra<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>cassandra<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>clusterIP</span>:<span style=color:#bbb> </span>None<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>ports</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>port</span>:<span style=color:#bbb> </span><span style=color:#666>9042</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>selector</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>app</span>:<span style=color:#bbb> </span>cassandra<span style=color:#bbb>
</span></span></span></code></pre></div></div></div><p>Create a Service to track all Cassandra StatefulSet members from the <code>cassandra-service.yaml</code> file:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl apply -f https://k8s.io/examples/application/cassandra/cassandra-service.yaml
</span></span></code></pre></div><h3 id=validating>Validating (optional)</h3><p>Get the Cassandra Service.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get svc cassandra
</span></span></code></pre></div><p>The response is</p><pre tabindex=0><code>NAME        TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)    AGE
cassandra   ClusterIP   None         &lt;none&gt;        9042/TCP   45s
</code></pre><p>If you don't see a Service named <code>cassandra</code>, that means creation failed. Read
<a href=/docs/tasks/debug/debug-application/debug-service/>Debug Services</a>
for help troubleshooting common issues.</p><h2 id=using-a-statefulset-to-create-a-cassandra-ring>Using a StatefulSet to create a Cassandra ring</h2><p>The StatefulSet manifest, included below, creates a Cassandra ring that consists of three Pods.</p><div class="alert alert-info note callout" role=alert><strong>Note:</strong> This example uses the default provisioner for Minikube.
Please update the following StatefulSet for the cloud you are working with.</div><div class=highlight><div class=copy-code-icon style=text-align:right><a href=https://raw.githubusercontent.com/kubernetes/website/main/content/en/examples/application/cassandra/cassandra-statefulset.yaml download=application/cassandra/cassandra-statefulset.yaml><code>application/cassandra/cassandra-statefulset.yaml</code></a>
<img src=/images/copycode.svg style=max-height:24px;cursor:pointer onclick='copyCode("application-cassandra-cassandra-statefulset-yaml")' title="Copy application/cassandra/cassandra-statefulset.yaml to clipboard"></img></div><div class=includecode id=application-cassandra-cassandra-statefulset-yaml><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>apps/v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>StatefulSet<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>cassandra<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>labels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>app</span>:<span style=color:#bbb> </span>cassandra<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>serviceName</span>:<span style=color:#bbb> </span>cassandra<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>replicas</span>:<span style=color:#bbb> </span><span style=color:#666>3</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>selector</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>matchLabels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>app</span>:<span style=color:#bbb> </span>cassandra<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>template</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>labels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>app</span>:<span style=color:#bbb> </span>cassandra<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>terminationGracePeriodSeconds</span>:<span style=color:#bbb> </span><span style=color:#666>1800</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>cassandra<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>gcr.io/google-samples/cassandra:v13<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>imagePullPolicy</span>:<span style=color:#bbb> </span>Always<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>ports</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span>- <span style=color:green;font-weight:700>containerPort</span>:<span style=color:#bbb> </span><span style=color:#666>7000</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>intra-node<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span>- <span style=color:green;font-weight:700>containerPort</span>:<span style=color:#bbb> </span><span style=color:#666>7001</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>tls-intra-node<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span>- <span style=color:green;font-weight:700>containerPort</span>:<span style=color:#bbb> </span><span style=color:#666>7199</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>jmx<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span>- <span style=color:green;font-weight:700>containerPort</span>:<span style=color:#bbb> </span><span style=color:#666>9042</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>cql<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>resources</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>limits</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>            </span><span style=color:green;font-weight:700>cpu</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;500m&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>            </span><span style=color:green;font-weight:700>memory</span>:<span style=color:#bbb> </span>1Gi<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>requests</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>            </span><span style=color:green;font-weight:700>cpu</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;500m&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>            </span><span style=color:green;font-weight:700>memory</span>:<span style=color:#bbb> </span>1Gi<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>securityContext</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>capabilities</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>            </span><span style=color:green;font-weight:700>add</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>              </span>- IPC_LOCK<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>lifecycle</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>preStop</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>            </span><span style=color:green;font-weight:700>exec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>              </span><span style=color:green;font-weight:700>command</span>:<span style=color:#bbb> 
</span></span></span><span style=display:flex><span><span style=color:#bbb>              </span>- /bin/sh<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>              </span>- -c<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>              </span>- nodetool drain<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>env</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>MAX_HEAP_SIZE<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>            </span><span style=color:green;font-weight:700>value</span>:<span style=color:#bbb> </span>512M<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>HEAP_NEWSIZE<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>            </span><span style=color:green;font-weight:700>value</span>:<span style=color:#bbb> </span>100M<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>CASSANDRA_SEEDS<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>            </span><span style=color:green;font-weight:700>value</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;cassandra-0.cassandra.default.svc.cluster.local&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>CASSANDRA_CLUSTER_NAME<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>            </span><span style=color:green;font-weight:700>value</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;K8Demo&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>CASSANDRA_DC<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>            </span><span style=color:green;font-weight:700>value</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;DC1-K8Demo&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>CASSANDRA_RACK<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>            </span><span style=color:green;font-weight:700>value</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;Rack1-K8Demo&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>POD_IP<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>            </span><span style=color:green;font-weight:700>valueFrom</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>              </span><span style=color:green;font-weight:700>fieldRef</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>                </span><span style=color:green;font-weight:700>fieldPath</span>:<span style=color:#bbb> </span>status.podIP<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>readinessProbe</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>exec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>            </span><span style=color:green;font-weight:700>command</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>            </span>- /bin/bash<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>            </span>- -c<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>            </span>- /ready-probe.sh<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>initialDelaySeconds</span>:<span style=color:#bbb> </span><span style=color:#666>15</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>timeoutSeconds</span>:<span style=color:#bbb> </span><span style=color:#666>5</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:#080;font-style:italic># These volume mounts are persistent. They are like inline claims,</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:#080;font-style:italic># but not exactly because the names need to match exactly one of</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:#080;font-style:italic># the stateful pod volumes.</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>volumeMounts</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>cassandra-data<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>mountPath</span>:<span style=color:#bbb> </span>/cassandra_data<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:#080;font-style:italic># These are converted to volume claims by the controller</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:#080;font-style:italic># and mounted at the paths mentioned above.</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:#080;font-style:italic># do not use these in production until ssd GCEPersistentDisk or other ssd pd</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>volumeClaimTemplates</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>cassandra-data<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>accessModes</span>:<span style=color:#bbb> </span>[<span style=color:#bbb> </span><span style=color:#b44>&#34;ReadWriteOnce&#34;</span><span style=color:#bbb> </span>]<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>storageClassName</span>:<span style=color:#bbb> </span>fast<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>resources</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>requests</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>storage</span>:<span style=color:#bbb> </span>1Gi<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:#00f;font-weight:700>---</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>StorageClass<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>storage.k8s.io/v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>fast<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>provisioner</span>:<span style=color:#bbb> </span>k8s.io/minikube-hostpath<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>parameters</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>type</span>:<span style=color:#bbb> </span>pd-ssd<span style=color:#bbb>
</span></span></span></code></pre></div></div></div><p>Create the Cassandra StatefulSet from the <code>cassandra-statefulset.yaml</code> file:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span><span style=color:#080;font-style:italic># Use this if you are able to apply cassandra-statefulset.yaml unmodified</span>
</span></span><span style=display:flex><span>kubectl apply -f https://k8s.io/examples/application/cassandra/cassandra-statefulset.yaml
</span></span></code></pre></div><p>If you need to modify <code>cassandra-statefulset.yaml</code> to suit your cluster, download
<a href=https://k8s.io/examples/application/cassandra/cassandra-statefulset.yaml>https://k8s.io/examples/application/cassandra/cassandra-statefulset.yaml</a> and then apply
that manifest, from the folder you saved the modified version into:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span><span style=color:#080;font-style:italic># Use this if you needed to modify cassandra-statefulset.yaml locally</span>
</span></span><span style=display:flex><span>kubectl apply -f cassandra-statefulset.yaml
</span></span></code></pre></div><h2 id=validating-the-cassandra-statefulset>Validating the Cassandra StatefulSet</h2><ol><li><p>Get the Cassandra StatefulSet:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get statefulset cassandra
</span></span></code></pre></div><p>The response should be similar to:</p><pre tabindex=0><code>NAME        DESIRED   CURRENT   AGE
cassandra   3         0         13s
</code></pre><p>The <code>StatefulSet</code> resource deploys Pods sequentially.</p></li><li><p>Get the Pods to see the ordered creation status:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get pods -l<span style=color:#666>=</span><span style=color:#b44>&#34;app=cassandra&#34;</span>
</span></span></code></pre></div><p>The response should be similar to:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>NAME          READY     STATUS              RESTARTS   AGE
</span></span><span style=display:flex><span>cassandra-0   1/1       Running             <span style=color:#666>0</span>          1m
</span></span><span style=display:flex><span>cassandra-1   0/1       ContainerCreating   <span style=color:#666>0</span>          8s
</span></span></code></pre></div><p>It can take several minutes for all three Pods to deploy. Once they are deployed, the same command
returns output similar to:</p><pre tabindex=0><code>NAME          READY     STATUS    RESTARTS   AGE
cassandra-0   1/1       Running   0          10m
cassandra-1   1/1       Running   0          9m
cassandra-2   1/1       Running   0          8m
</code></pre></li><li><p>Run the Cassandra <a href=https://cwiki.apache.org/confluence/display/CASSANDRA2/NodeTool>nodetool</a> inside the first Pod, to
display the status of the ring.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl <span style=color:#a2f>exec</span> -it cassandra-0 -- nodetool status
</span></span></code></pre></div><p>The response should look something like:</p><pre tabindex=0><code>Datacenter: DC1-K8Demo
======================
Status=Up/Down
|/ State=Normal/Leaving/Joining/Moving
--  Address     Load       Tokens       Owns (effective)  Host ID                               Rack
UN  172.17.0.5  83.57 KiB  32           74.0%             e2dd09e6-d9d3-477e-96c5-45094c08db0f  Rack1-K8Demo
UN  172.17.0.4  101.04 KiB  32           58.8%             f89d6835-3a42-4419-92b3-0e62cae1479c  Rack1-K8Demo
UN  172.17.0.6  84.74 KiB  32           67.1%             a6a1e8c2-3dc5-4417-b1a0-26507af2aaad  Rack1-K8Demo
</code></pre></li></ol><h2 id=modifying-the-cassandra-statefulset>Modifying the Cassandra StatefulSet</h2><p>Use <code>kubectl edit</code> to modify the size of a Cassandra StatefulSet.</p><ol><li><p>Run the following command:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl edit statefulset cassandra
</span></span></code></pre></div><p>This command opens an editor in your terminal. The line you need to change is the <code>replicas</code> field.
The following sample is an excerpt of the StatefulSet file:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#080;font-style:italic># Please edit the object below. Lines beginning with a &#39;#&#39; will be ignored,</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:#080;font-style:italic># and an empty file will abort the edit. If an error occurs while saving this file will be</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:#080;font-style:italic># reopened with the relevant failures.</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:#080;font-style:italic>#</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>apps/v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>StatefulSet<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>creationTimestamp</span>:<span style=color:#bbb> </span>2016-08-13T18:40:58Z<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>generation</span>:<span style=color:#bbb> </span><span style=color:#666>1</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>labels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>app</span>:<span style=color:#bbb> </span>cassandra<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>cassandra<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>namespace</span>:<span style=color:#bbb> </span>default<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>resourceVersion</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;323&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>uid</span>:<span style=color:#bbb> </span>7a219483-6185-11e6-a910-42010a8a0fc0<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>replicas</span>:<span style=color:#bbb> </span><span style=color:#666>3</span><span style=color:#bbb>
</span></span></span></code></pre></div></li><li><p>Change the number of replicas to 4, and then save the manifest.</p><p>The StatefulSet now scales to run with 4 Pods.</p></li><li><p>Get the Cassandra StatefulSet to verify your change:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get statefulset cassandra
</span></span></code></pre></div><p>The response should be similar to:</p><pre tabindex=0><code>NAME        DESIRED   CURRENT   AGE
cassandra   4         4         36m
</code></pre></li></ol><h2 id=cleaning-up>Cleaning up</h2><p>Deleting or scaling a StatefulSet down does not delete the volumes associated with the StatefulSet.
This setting is for your safety because your data is more valuable than automatically purging all related StatefulSet resources.</p><div class="alert alert-danger warning callout" role=alert><strong>Warning:</strong> Depending on the storage class and reclaim policy, deleting the <em>PersistentVolumeClaims</em> may cause the associated volumes
to also be deleted. Never assume you'll be able to access data if its volume claims are deleted.</div><ol><li><p>Run the following commands (chained together into a single command) to delete everything in the Cassandra StatefulSet:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span><span style=color:#b8860b>grace</span><span style=color:#666>=</span><span style=color:#a2f;font-weight:700>$(</span>kubectl get pod cassandra-0 -o<span style=color:#666>=</span><span style=color:#b8860b>jsonpath</span><span style=color:#666>=</span><span style=color:#b44>&#39;{.spec.terminationGracePeriodSeconds}&#39;</span><span style=color:#a2f;font-weight:700>)</span> <span style=color:#b62;font-weight:700>\
</span></span></span><span style=display:flex><span><span style=color:#b62;font-weight:700></span>  <span style=color:#666>&amp;&amp;</span> kubectl delete statefulset -l <span style=color:#b8860b>app</span><span style=color:#666>=</span>cassandra <span style=color:#b62;font-weight:700>\
</span></span></span><span style=display:flex><span><span style=color:#b62;font-weight:700></span>  <span style=color:#666>&amp;&amp;</span> <span style=color:#a2f>echo</span> <span style=color:#b44>&#34;Sleeping </span><span style=color:#b68;font-weight:700>${</span><span style=color:#b8860b>grace</span><span style=color:#b68;font-weight:700>}</span><span style=color:#b44> seconds&#34;</span> 1&gt;&amp;<span style=color:#666>2</span> <span style=color:#b62;font-weight:700>\
</span></span></span><span style=display:flex><span><span style=color:#b62;font-weight:700></span>  <span style=color:#666>&amp;&amp;</span> sleep <span style=color:#b8860b>$grace</span> <span style=color:#b62;font-weight:700>\
</span></span></span><span style=display:flex><span><span style=color:#b62;font-weight:700></span>  <span style=color:#666>&amp;&amp;</span> kubectl delete persistentvolumeclaim -l <span style=color:#b8860b>app</span><span style=color:#666>=</span>cassandra
</span></span></code></pre></div></li><li><p>Run the following command to delete the Service you set up for Cassandra:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl delete service -l <span style=color:#b8860b>app</span><span style=color:#666>=</span>cassandra
</span></span></code></pre></div></li></ol><h2 id=cassandra-container-environment-variables>Cassandra container environment variables</h2><p>The Pods in this tutorial use the <a href=https://github.com/kubernetes/examples/blob/master/cassandra/image/Dockerfile><code>gcr.io/google-samples/cassandra:v13</code></a>
image from Google's <a href=https://cloud.google.com/container-registry/docs/>container registry</a>.
The Docker image above is based on <a href=https://github.com/kubernetes/release/tree/master/images/build/debian-base>debian-base</a>
and includes OpenJDK 8.</p><p>This image includes a standard Cassandra installation from the Apache Debian repo.
By using environment variables you can change values that are inserted into <code>cassandra.yaml</code>.</p><table><thead><tr><th>Environment variable</th><th style=text-align:center>Default value</th></tr></thead><tbody><tr><td><code>CASSANDRA_CLUSTER_NAME</code></td><td style=text-align:center><code>'Test Cluster'</code></td></tr><tr><td><code>CASSANDRA_NUM_TOKENS</code></td><td style=text-align:center><code>32</code></td></tr><tr><td><code>CASSANDRA_RPC_ADDRESS</code></td><td style=text-align:center><code>0.0.0.0</code></td></tr></tbody></table><h2 id=what-s-next>What's next</h2><ul><li>Learn how to <a href=/docs/tasks/run-application/scale-stateful-set/>Scale a StatefulSet</a>.</li><li>Learn more about the <a href=https://github.com/kubernetes/examples/blob/master/cassandra/java/src/main/java/io/k8s/cassandra/KubernetesSeedProvider.java><em>KubernetesSeedProvider</em></a></li><li>See more custom <a href=https://git.k8s.io/examples/cassandra/java/README.md>Seed Provider Configurations</a></li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-4bfac214b5eb9ebddaf1f3811901d327>4 - Running ZooKeeper, A Distributed System Coordinator</h1><p>This tutorial demonstrates running <a href=https://zookeeper.apache.org>Apache Zookeeper</a> on
Kubernetes using <a href=/docs/concepts/workloads/controllers/statefulset/>StatefulSets</a>,
<a href=/docs/concepts/workloads/pods/disruptions/#pod-disruption-budget>PodDisruptionBudgets</a>,
and <a href=/docs/concepts/scheduling-eviction/assign-pod-node/#affinity-and-anti-affinity>PodAntiAffinity</a>.</p><h2 id=before-you-begin>Before you begin</h2><p>Before starting this tutorial, you should be familiar with the following
Kubernetes concepts:</p><ul><li><a href=/docs/concepts/workloads/pods/>Pods</a></li><li><a href=/docs/concepts/services-networking/dns-pod-service/>Cluster DNS</a></li><li><a href=/docs/concepts/services-networking/service/#headless-services>Headless Services</a></li><li><a href=/docs/concepts/storage/volumes/>PersistentVolumes</a></li><li><a href=https://github.com/kubernetes/examples/tree/master/staging/persistent-volume-provisioning/>PersistentVolume Provisioning</a></li><li><a href=/docs/concepts/workloads/controllers/statefulset/>StatefulSets</a></li><li><a href=/docs/concepts/workloads/pods/disruptions/#pod-disruption-budget>PodDisruptionBudgets</a></li><li><a href=/docs/concepts/scheduling-eviction/assign-pod-node/#affinity-and-anti-affinity>PodAntiAffinity</a></li><li><a href=/docs/reference/kubectl/kubectl/>kubectl CLI</a></li></ul><p>You must have a cluster with at least four nodes, and each node requires at least 2 CPUs and 4 GiB of memory. In this tutorial you will cordon and drain the cluster's nodes. <strong>This means that the cluster will terminate and evict all Pods on its nodes, and the nodes will temporarily become unschedulable.</strong> You should use a dedicated cluster for this tutorial, or you should ensure that the disruption you cause will not interfere with other tenants.</p><p>This tutorial assumes that you have configured your cluster to dynamically provision
PersistentVolumes. If your cluster is not configured to do so, you
will have to manually provision three 20 GiB volumes before starting this
tutorial.</p><h2 id=objectives>Objectives</h2><p>After this tutorial, you will know the following.</p><ul><li>How to deploy a ZooKeeper ensemble using StatefulSet.</li><li>How to consistently configure the ensemble.</li><li>How to spread the deployment of ZooKeeper servers in the ensemble.</li><li>How to use PodDisruptionBudgets to ensure service availability during planned maintenance.</li></ul><h3 id=zookeeper>ZooKeeper</h3><p><a href=https://zookeeper.apache.org/doc/current/>Apache ZooKeeper</a> is a
distributed, open-source coordination service for distributed applications.
ZooKeeper allows you to read, write, and observe updates to data. Data are
organized in a file system like hierarchy and replicated to all ZooKeeper
servers in the ensemble (a set of ZooKeeper servers). All operations on data
are atomic and sequentially consistent. ZooKeeper ensures this by using the
<a href=https://pdfs.semanticscholar.org/b02c/6b00bd5dbdbd951fddb00b906c82fa80f0b3.pdf>Zab</a>
consensus protocol to replicate a state machine across all servers in the ensemble.</p><p>The ensemble uses the Zab protocol to elect a leader, and the ensemble cannot write data until that election is complete. Once complete, the ensemble uses Zab to ensure that it replicates all writes to a quorum before it acknowledges and makes them visible to clients. Without respect to weighted quorums, a quorum is a majority component of the ensemble containing the current leader. For instance, if the ensemble has three servers, a component that contains the leader and one other server constitutes a quorum. If the ensemble can not achieve a quorum, the ensemble cannot write data.</p><p>ZooKeeper servers keep their entire state machine in memory, and write every mutation to a durable WAL (Write Ahead Log) on storage media. When a server crashes, it can recover its previous state by replaying the WAL. To prevent the WAL from growing without bound, ZooKeeper servers will periodically snapshot them in memory state to storage media. These snapshots can be loaded directly into memory, and all WAL entries that preceded the snapshot may be discarded.</p><h2 id=creating-a-zookeeper-ensemble>Creating a ZooKeeper ensemble</h2><p>The manifest below contains a
<a href=/docs/concepts/services-networking/service/#headless-services>Headless Service</a>,
a <a href=/docs/concepts/services-networking/service/>Service</a>,
a <a href=/docs/concepts/workloads/pods/disruptions/#pod-disruption-budgets>PodDisruptionBudget</a>,
and a <a href=/docs/concepts/workloads/controllers/statefulset/>StatefulSet</a>.</p><div class=highlight><div class=copy-code-icon style=text-align:right><a href=https://raw.githubusercontent.com/kubernetes/website/main/content/en/examples/application/zookeeper/zookeeper.yaml download=application/zookeeper/zookeeper.yaml><code>application/zookeeper/zookeeper.yaml</code></a>
<img src=/images/copycode.svg style=max-height:24px;cursor:pointer onclick='copyCode("application-zookeeper-zookeeper-yaml")' title="Copy application/zookeeper/zookeeper.yaml to clipboard"></img></div><div class=includecode id=application-zookeeper-zookeeper-yaml><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Service<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>zk-hs<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>labels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>app</span>:<span style=color:#bbb> </span>zk<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>ports</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>port</span>:<span style=color:#bbb> </span><span style=color:#666>2888</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>server<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>port</span>:<span style=color:#bbb> </span><span style=color:#666>3888</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>leader-election<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>clusterIP</span>:<span style=color:#bbb> </span>None<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>selector</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>app</span>:<span style=color:#bbb> </span>zk<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:#00f;font-weight:700>---</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Service<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>zk-cs<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>labels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>app</span>:<span style=color:#bbb> </span>zk<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>ports</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>port</span>:<span style=color:#bbb> </span><span style=color:#666>2181</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>client<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>selector</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>app</span>:<span style=color:#bbb> </span>zk<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:#00f;font-weight:700>---</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>policy/v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>PodDisruptionBudget<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>zk-pdb<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>selector</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>matchLabels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>app</span>:<span style=color:#bbb> </span>zk<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>maxUnavailable</span>:<span style=color:#bbb> </span><span style=color:#666>1</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:#00f;font-weight:700>---</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>apps/v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>StatefulSet<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>zk<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>selector</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>matchLabels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>app</span>:<span style=color:#bbb> </span>zk<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>serviceName</span>:<span style=color:#bbb> </span>zk-hs<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>replicas</span>:<span style=color:#bbb> </span><span style=color:#666>3</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>updateStrategy</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>type</span>:<span style=color:#bbb> </span>RollingUpdate<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>podManagementPolicy</span>:<span style=color:#bbb> </span>OrderedReady<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>template</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>labels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>app</span>:<span style=color:#bbb> </span>zk<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>affinity</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>podAntiAffinity</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>requiredDuringSchedulingIgnoredDuringExecution</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>            </span>- <span style=color:green;font-weight:700>labelSelector</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>                </span><span style=color:green;font-weight:700>matchExpressions</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>                  </span>- <span style=color:green;font-weight:700>key</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;app&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>                    </span><span style=color:green;font-weight:700>operator</span>:<span style=color:#bbb> </span>In<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>                    </span><span style=color:green;font-weight:700>values</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>                    </span>- zk<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>              </span><span style=color:green;font-weight:700>topologyKey</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;kubernetes.io/hostname&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>kubernetes-zookeeper<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>imagePullPolicy</span>:<span style=color:#bbb> </span>Always<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;registry.k8s.io/kubernetes-zookeeper:1.0-3.4.10&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>resources</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>requests</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>            </span><span style=color:green;font-weight:700>memory</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;1Gi&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>            </span><span style=color:green;font-weight:700>cpu</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;0.5&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>ports</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span>- <span style=color:green;font-weight:700>containerPort</span>:<span style=color:#bbb> </span><span style=color:#666>2181</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>client<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span>- <span style=color:green;font-weight:700>containerPort</span>:<span style=color:#bbb> </span><span style=color:#666>2888</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>server<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span>- <span style=color:green;font-weight:700>containerPort</span>:<span style=color:#bbb> </span><span style=color:#666>3888</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>leader-election<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>command</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span>- sh<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span>- -c<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span>- <span style=color:#b44>&#34;start-zookeeper \
</span></span></span><span style=display:flex><span><span style=color:#b44>          --servers=3 \
</span></span></span><span style=display:flex><span><span style=color:#b44>          --data_dir=/var/lib/zookeeper/data \
</span></span></span><span style=display:flex><span><span style=color:#b44>          --data_log_dir=/var/lib/zookeeper/data/log \
</span></span></span><span style=display:flex><span><span style=color:#b44>          --conf_dir=/opt/zookeeper/conf \
</span></span></span><span style=display:flex><span><span style=color:#b44>          --client_port=2181 \
</span></span></span><span style=display:flex><span><span style=color:#b44>          --election_port=3888 \
</span></span></span><span style=display:flex><span><span style=color:#b44>          --server_port=2888 \
</span></span></span><span style=display:flex><span><span style=color:#b44>          --tick_time=2000 \
</span></span></span><span style=display:flex><span><span style=color:#b44>          --init_limit=10 \
</span></span></span><span style=display:flex><span><span style=color:#b44>          --sync_limit=5 \
</span></span></span><span style=display:flex><span><span style=color:#b44>          --heap=512M \
</span></span></span><span style=display:flex><span><span style=color:#b44>          --max_client_cnxns=60 \
</span></span></span><span style=display:flex><span><span style=color:#b44>          --snap_retain_count=3 \
</span></span></span><span style=display:flex><span><span style=color:#b44>          --purge_interval=12 \
</span></span></span><span style=display:flex><span><span style=color:#b44>          --max_session_timeout=40000 \
</span></span></span><span style=display:flex><span><span style=color:#b44>          --min_session_timeout=4000 \
</span></span></span><span style=display:flex><span><span style=color:#b44>          --log_level=INFO&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>readinessProbe</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>exec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>            </span><span style=color:green;font-weight:700>command</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>            </span>- sh<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>            </span>- -c<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>            </span>- <span style=color:#b44>&#34;zookeeper-ready 2181&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>initialDelaySeconds</span>:<span style=color:#bbb> </span><span style=color:#666>10</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>timeoutSeconds</span>:<span style=color:#bbb> </span><span style=color:#666>5</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>livenessProbe</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>exec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>            </span><span style=color:green;font-weight:700>command</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>            </span>- sh<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>            </span>- -c<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>            </span>- <span style=color:#b44>&#34;zookeeper-ready 2181&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>initialDelaySeconds</span>:<span style=color:#bbb> </span><span style=color:#666>10</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>timeoutSeconds</span>:<span style=color:#bbb> </span><span style=color:#666>5</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>volumeMounts</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>datadir<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>mountPath</span>:<span style=color:#bbb> </span>/var/lib/zookeeper<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>securityContext</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>runAsUser</span>:<span style=color:#bbb> </span><span style=color:#666>1000</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>fsGroup</span>:<span style=color:#bbb> </span><span style=color:#666>1000</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>volumeClaimTemplates</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>datadir<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>accessModes</span>:<span style=color:#bbb> </span>[<span style=color:#bbb> </span><span style=color:#b44>&#34;ReadWriteOnce&#34;</span><span style=color:#bbb> </span>]<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>resources</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>requests</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>storage</span>:<span style=color:#bbb> </span>10Gi<span style=color:#bbb>
</span></span></span></code></pre></div></div></div><p>Open a terminal, and use the
<a href=/docs/reference/generated/kubectl/kubectl-commands/#apply><code>kubectl apply</code></a> command to create the
manifest.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl apply -f https://k8s.io/examples/application/zookeeper/zookeeper.yaml
</span></span></code></pre></div><p>This creates the <code>zk-hs</code> Headless Service, the <code>zk-cs</code> Service,
the <code>zk-pdb</code> PodDisruptionBudget, and the <code>zk</code> StatefulSet.</p><pre tabindex=0><code>service/zk-hs created
service/zk-cs created
poddisruptionbudget.policy/zk-pdb created
statefulset.apps/zk created
</code></pre><p>Use <a href=/docs/reference/generated/kubectl/kubectl-commands/#get><code>kubectl get</code></a> to watch the
StatefulSet controller create the StatefulSet's Pods.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get pods -w -l <span style=color:#b8860b>app</span><span style=color:#666>=</span>zk
</span></span></code></pre></div><p>Once the <code>zk-2</code> Pod is Running and Ready, use <code>CTRL-C</code> to terminate kubectl.</p><pre tabindex=0><code>NAME      READY     STATUS    RESTARTS   AGE
zk-0      0/1       Pending   0          0s
zk-0      0/1       Pending   0         0s
zk-0      0/1       ContainerCreating   0         0s
zk-0      0/1       Running   0         19s
zk-0      1/1       Running   0         40s
zk-1      0/1       Pending   0         0s
zk-1      0/1       Pending   0         0s
zk-1      0/1       ContainerCreating   0         0s
zk-1      0/1       Running   0         18s
zk-1      1/1       Running   0         40s
zk-2      0/1       Pending   0         0s
zk-2      0/1       Pending   0         0s
zk-2      0/1       ContainerCreating   0         0s
zk-2      0/1       Running   0         19s
zk-2      1/1       Running   0         40s
</code></pre><p>The StatefulSet controller creates three Pods, and each Pod has a container with
a <a href=https://archive.apache.org/dist/zookeeper/stable/>ZooKeeper</a> server.</p><h3 id=facilitating-leader-election>Facilitating leader election</h3><p>Because there is no terminating algorithm for electing a leader in an anonymous network, Zab requires explicit membership configuration to perform leader election. Each server in the ensemble needs to have a unique identifier, all servers need to know the global set of identifiers, and each identifier needs to be associated with a network address.</p><p>Use <a href=/docs/reference/generated/kubectl/kubectl-commands/#exec><code>kubectl exec</code></a> to get the hostnames
of the Pods in the <code>zk</code> StatefulSet.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span><span style=color:#a2f;font-weight:700>for</span> i in <span style=color:#666>0</span> <span style=color:#666>1</span> 2; <span style=color:#a2f;font-weight:700>do</span> kubectl <span style=color:#a2f>exec</span> zk-<span style=color:#b8860b>$i</span> -- hostname; <span style=color:#a2f;font-weight:700>done</span>
</span></span></code></pre></div><p>The StatefulSet controller provides each Pod with a unique hostname based on its ordinal index. The hostnames take the form of <code>&lt;statefulset name>-&lt;ordinal index></code>. Because the <code>replicas</code> field of the <code>zk</code> StatefulSet is set to <code>3</code>, the Set's controller creates three Pods with their hostnames set to <code>zk-0</code>, <code>zk-1</code>, and
<code>zk-2</code>.</p><pre tabindex=0><code>zk-0
zk-1
zk-2
</code></pre><p>The servers in a ZooKeeper ensemble use natural numbers as unique identifiers, and store each server's identifier in a file called <code>myid</code> in the server's data directory.</p><p>To examine the contents of the <code>myid</code> file for each server use the following command.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span><span style=color:#a2f;font-weight:700>for</span> i in <span style=color:#666>0</span> <span style=color:#666>1</span> 2; <span style=color:#a2f;font-weight:700>do</span> <span style=color:#a2f>echo</span> <span style=color:#b44>&#34;myid zk-</span><span style=color:#b8860b>$i</span><span style=color:#b44>&#34;</span>;kubectl <span style=color:#a2f>exec</span> zk-<span style=color:#b8860b>$i</span> -- cat /var/lib/zookeeper/data/myid; <span style=color:#a2f;font-weight:700>done</span>
</span></span></code></pre></div><p>Because the identifiers are natural numbers and the ordinal indices are non-negative integers, you can generate an identifier by adding 1 to the ordinal.</p><pre tabindex=0><code>myid zk-0
1
myid zk-1
2
myid zk-2
3
</code></pre><p>To get the Fully Qualified Domain Name (FQDN) of each Pod in the <code>zk</code> StatefulSet use the following command.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span><span style=color:#a2f;font-weight:700>for</span> i in <span style=color:#666>0</span> <span style=color:#666>1</span> 2; <span style=color:#a2f;font-weight:700>do</span> kubectl <span style=color:#a2f>exec</span> zk-<span style=color:#b8860b>$i</span> -- hostname -f; <span style=color:#a2f;font-weight:700>done</span>
</span></span></code></pre></div><p>The <code>zk-hs</code> Service creates a domain for all of the Pods,
<code>zk-hs.default.svc.cluster.local</code>.</p><pre tabindex=0><code>zk-0.zk-hs.default.svc.cluster.local
zk-1.zk-hs.default.svc.cluster.local
zk-2.zk-hs.default.svc.cluster.local
</code></pre><p>The A records in <a href=/docs/concepts/services-networking/dns-pod-service/>Kubernetes DNS</a> resolve the FQDNs to the Pods' IP addresses. If Kubernetes reschedules the Pods, it will update the A records with the Pods' new IP addresses, but the A records names will not change.</p><p>ZooKeeper stores its application configuration in a file named <code>zoo.cfg</code>. Use <code>kubectl exec</code> to view the contents of the <code>zoo.cfg</code> file in the <code>zk-0</code> Pod.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl <span style=color:#a2f>exec</span> zk-0 -- cat /opt/zookeeper/conf/zoo.cfg
</span></span></code></pre></div><p>In the <code>server.1</code>, <code>server.2</code>, and <code>server.3</code> properties at the bottom of
the file, the <code>1</code>, <code>2</code>, and <code>3</code> correspond to the identifiers in the
ZooKeeper servers' <code>myid</code> files. They are set to the FQDNs for the Pods in
the <code>zk</code> StatefulSet.</p><pre tabindex=0><code>clientPort=2181
dataDir=/var/lib/zookeeper/data
dataLogDir=/var/lib/zookeeper/log
tickTime=2000
initLimit=10
syncLimit=2000
maxClientCnxns=60
minSessionTimeout= 4000
maxSessionTimeout= 40000
autopurge.snapRetainCount=3
autopurge.purgeInterval=0
server.1=zk-0.zk-hs.default.svc.cluster.local:2888:3888
server.2=zk-1.zk-hs.default.svc.cluster.local:2888:3888
server.3=zk-2.zk-hs.default.svc.cluster.local:2888:3888
</code></pre><h3 id=achieving-consensus>Achieving consensus</h3><p>Consensus protocols require that the identifiers of each participant be unique. No two participants in the Zab protocol should claim the same unique identifier. This is necessary to allow the processes in the system to agree on which processes have committed which data. If two Pods are launched with the same ordinal, two ZooKeeper servers would both identify themselves as the same server.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get pods -w -l <span style=color:#b8860b>app</span><span style=color:#666>=</span>zk
</span></span></code></pre></div><pre tabindex=0><code>NAME      READY     STATUS    RESTARTS   AGE
zk-0      0/1       Pending   0          0s
zk-0      0/1       Pending   0         0s
zk-0      0/1       ContainerCreating   0         0s
zk-0      0/1       Running   0         19s
zk-0      1/1       Running   0         40s
zk-1      0/1       Pending   0         0s
zk-1      0/1       Pending   0         0s
zk-1      0/1       ContainerCreating   0         0s
zk-1      0/1       Running   0         18s
zk-1      1/1       Running   0         40s
zk-2      0/1       Pending   0         0s
zk-2      0/1       Pending   0         0s
zk-2      0/1       ContainerCreating   0         0s
zk-2      0/1       Running   0         19s
zk-2      1/1       Running   0         40s
</code></pre><p>The A records for each Pod are entered when the Pod becomes Ready. Therefore,
the FQDNs of the ZooKeeper servers will resolve to a single endpoint, and that
endpoint will be the unique ZooKeeper server claiming the identity configured
in its <code>myid</code> file.</p><pre tabindex=0><code>zk-0.zk-hs.default.svc.cluster.local
zk-1.zk-hs.default.svc.cluster.local
zk-2.zk-hs.default.svc.cluster.local
</code></pre><p>This ensures that the <code>servers</code> properties in the ZooKeepers' <code>zoo.cfg</code> files
represents a correctly configured ensemble.</p><pre tabindex=0><code>server.1=zk-0.zk-hs.default.svc.cluster.local:2888:3888
server.2=zk-1.zk-hs.default.svc.cluster.local:2888:3888
server.3=zk-2.zk-hs.default.svc.cluster.local:2888:3888
</code></pre><p>When the servers use the Zab protocol to attempt to commit a value, they will either achieve consensus and commit the value (if leader election has succeeded and at least two of the Pods are Running and Ready), or they will fail to do so (if either of the conditions are not met). No state will arise where one server acknowledges a write on behalf of another.</p><h3 id=sanity-testing-the-ensemble>Sanity testing the ensemble</h3><p>The most basic sanity test is to write data to one ZooKeeper server and
to read the data from another.</p><p>The command below executes the <code>zkCli.sh</code> script to write <code>world</code> to the path <code>/hello</code> on the <code>zk-0</code> Pod in the ensemble.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl <span style=color:#a2f>exec</span> zk-0 -- zkCli.sh create /hello world
</span></span></code></pre></div><pre tabindex=0><code>WATCHER::

WatchedEvent state:SyncConnected type:None path:null
Created /hello
</code></pre><p>To get the data from the <code>zk-1</code> Pod use the following command.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl <span style=color:#a2f>exec</span> zk-1 -- zkCli.sh get /hello
</span></span></code></pre></div><p>The data that you created on <code>zk-0</code> is available on all the servers in the
ensemble.</p><pre tabindex=0><code>WATCHER::

WatchedEvent state:SyncConnected type:None path:null
world
cZxid = 0x100000002
ctime = Thu Dec 08 15:13:30 UTC 2016
mZxid = 0x100000002
mtime = Thu Dec 08 15:13:30 UTC 2016
pZxid = 0x100000002
cversion = 0
dataVersion = 0
aclVersion = 0
ephemeralOwner = 0x0
dataLength = 5
numChildren = 0
</code></pre><h3 id=providing-durable-storage>Providing durable storage</h3><p>As mentioned in the <a href=#zookeeper>ZooKeeper Basics</a> section,
ZooKeeper commits all entries to a durable WAL, and periodically writes snapshots
in memory state, to storage media. Using WALs to provide durability is a common
technique for applications that use consensus protocols to achieve a replicated
state machine.</p><p>Use the <a href=/docs/reference/generated/kubectl/kubectl-commands/#delete><code>kubectl delete</code></a> command to delete the
<code>zk</code> StatefulSet.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl delete statefulset zk
</span></span></code></pre></div><pre tabindex=0><code>statefulset.apps &#34;zk&#34; deleted
</code></pre><p>Watch the termination of the Pods in the StatefulSet.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get pods -w -l <span style=color:#b8860b>app</span><span style=color:#666>=</span>zk
</span></span></code></pre></div><p>When <code>zk-0</code> if fully terminated, use <code>CTRL-C</code> to terminate kubectl.</p><pre tabindex=0><code>zk-2      1/1       Terminating   0         9m
zk-0      1/1       Terminating   0         11m
zk-1      1/1       Terminating   0         10m
zk-2      0/1       Terminating   0         9m
zk-2      0/1       Terminating   0         9m
zk-2      0/1       Terminating   0         9m
zk-1      0/1       Terminating   0         10m
zk-1      0/1       Terminating   0         10m
zk-1      0/1       Terminating   0         10m
zk-0      0/1       Terminating   0         11m
zk-0      0/1       Terminating   0         11m
zk-0      0/1       Terminating   0         11m
</code></pre><p>Reapply the manifest in <code>zookeeper.yaml</code>.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl apply -f https://k8s.io/examples/application/zookeeper/zookeeper.yaml
</span></span></code></pre></div><p>This creates the <code>zk</code> StatefulSet object, but the other API objects in the manifest are not modified because they already exist.</p><p>Watch the StatefulSet controller recreate the StatefulSet's Pods.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get pods -w -l <span style=color:#b8860b>app</span><span style=color:#666>=</span>zk
</span></span></code></pre></div><p>Once the <code>zk-2</code> Pod is Running and Ready, use <code>CTRL-C</code> to terminate kubectl.</p><pre tabindex=0><code>NAME      READY     STATUS    RESTARTS   AGE
zk-0      0/1       Pending   0          0s
zk-0      0/1       Pending   0         0s
zk-0      0/1       ContainerCreating   0         0s
zk-0      0/1       Running   0         19s
zk-0      1/1       Running   0         40s
zk-1      0/1       Pending   0         0s
zk-1      0/1       Pending   0         0s
zk-1      0/1       ContainerCreating   0         0s
zk-1      0/1       Running   0         18s
zk-1      1/1       Running   0         40s
zk-2      0/1       Pending   0         0s
zk-2      0/1       Pending   0         0s
zk-2      0/1       ContainerCreating   0         0s
zk-2      0/1       Running   0         19s
zk-2      1/1       Running   0         40s
</code></pre><p>Use the command below to get the value you entered during the <a href=#sanity-testing-the-ensemble>sanity test</a>,
from the <code>zk-2</code> Pod.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl <span style=color:#a2f>exec</span> zk-2 zkCli.sh get /hello
</span></span></code></pre></div><p>Even though you terminated and recreated all of the Pods in the <code>zk</code> StatefulSet, the ensemble still serves the original value.</p><pre tabindex=0><code>WATCHER::

WatchedEvent state:SyncConnected type:None path:null
world
cZxid = 0x100000002
ctime = Thu Dec 08 15:13:30 UTC 2016
mZxid = 0x100000002
mtime = Thu Dec 08 15:13:30 UTC 2016
pZxid = 0x100000002
cversion = 0
dataVersion = 0
aclVersion = 0
ephemeralOwner = 0x0
dataLength = 5
numChildren = 0
</code></pre><p>The <code>volumeClaimTemplates</code> field of the <code>zk</code> StatefulSet's <code>spec</code> specifies a PersistentVolume provisioned for each Pod.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>volumeClaimTemplates</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>datadir<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>annotations</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>volume.alpha.kubernetes.io/storage-class</span>:<span style=color:#bbb> </span>anything<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>accessModes</span>:<span style=color:#bbb> </span>[<span style=color:#bbb> </span><span style=color:#b44>&#34;ReadWriteOnce&#34;</span><span style=color:#bbb> </span>]<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>resources</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>requests</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>storage</span>:<span style=color:#bbb> </span>20Gi<span style=color:#bbb>
</span></span></span></code></pre></div><p>The <code>StatefulSet</code> controller generates a <code>PersistentVolumeClaim</code> for each Pod in
the <code>StatefulSet</code>.</p><p>Use the following command to get the <code>StatefulSet</code>'s <code>PersistentVolumeClaims</code>.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get pvc -l <span style=color:#b8860b>app</span><span style=color:#666>=</span>zk
</span></span></code></pre></div><p>When the <code>StatefulSet</code> recreated its Pods, it remounts the Pods' PersistentVolumes.</p><pre tabindex=0><code>NAME           STATUS    VOLUME                                     CAPACITY   ACCESSMODES   AGE
datadir-zk-0   Bound     pvc-bed742cd-bcb1-11e6-994f-42010a800002   20Gi       RWO           1h
datadir-zk-1   Bound     pvc-bedd27d2-bcb1-11e6-994f-42010a800002   20Gi       RWO           1h
datadir-zk-2   Bound     pvc-bee0817e-bcb1-11e6-994f-42010a800002   20Gi       RWO           1h
</code></pre><p>The <code>volumeMounts</code> section of the <code>StatefulSet</code>'s container <code>template</code> mounts the PersistentVolumes in the ZooKeeper servers' data directories.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>volumeMounts</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>datadir<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>mountPath</span>:<span style=color:#bbb> </span>/var/lib/zookeeper<span style=color:#bbb>
</span></span></span></code></pre></div><p>When a Pod in the <code>zk</code> <code>StatefulSet</code> is (re)scheduled, it will always have the
same <code>PersistentVolume</code> mounted to the ZooKeeper server's data directory.
Even when the Pods are rescheduled, all the writes made to the ZooKeeper
servers' WALs, and all their snapshots, remain durable.</p><h2 id=ensuring-consistent-configuration>Ensuring consistent configuration</h2><p>As noted in the <a href=#facilitating-leader-election>Facilitating Leader Election</a> and
<a href=#achieving-consensus>Achieving Consensus</a> sections, the servers in a
ZooKeeper ensemble require consistent configuration to elect a leader
and form a quorum. They also require consistent configuration of the Zab protocol
in order for the protocol to work correctly over a network. In our example we
achieve consistent configuration by embedding the configuration directly into
the manifest.</p><p>Get the <code>zk</code> StatefulSet.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get sts zk -o yaml
</span></span></code></pre></div><pre tabindex=0><code>…
command:
      - sh
      - -c
      - &#34;start-zookeeper \
        --servers=3 \
        --data_dir=/var/lib/zookeeper/data \
        --data_log_dir=/var/lib/zookeeper/data/log \
        --conf_dir=/opt/zookeeper/conf \
        --client_port=2181 \
        --election_port=3888 \
        --server_port=2888 \
        --tick_time=2000 \
        --init_limit=10 \
        --sync_limit=5 \
        --heap=512M \
        --max_client_cnxns=60 \
        --snap_retain_count=3 \
        --purge_interval=12 \
        --max_session_timeout=40000 \
        --min_session_timeout=4000 \
        --log_level=INFO&#34;
…
</code></pre><p>The command used to start the ZooKeeper servers passed the configuration as command line parameter. You can also use environment variables to pass configuration to the ensemble.</p><h3 id=configuring-logging>Configuring logging</h3><p>One of the files generated by the <code>zkGenConfig.sh</code> script controls ZooKeeper's logging.
ZooKeeper uses <a href=https://logging.apache.org/log4j/2.x/>Log4j</a>, and, by default,
it uses a time and size based rolling file appender for its logging configuration.</p><p>Use the command below to get the logging configuration from one of Pods in the <code>zk</code> <code>StatefulSet</code>.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl <span style=color:#a2f>exec</span> zk-0 cat /usr/etc/zookeeper/log4j.properties
</span></span></code></pre></div><p>The logging configuration below will cause the ZooKeeper process to write all
of its logs to the standard output file stream.</p><pre tabindex=0><code>zookeeper.root.logger=CONSOLE
zookeeper.console.threshold=INFO
log4j.rootLogger=${zookeeper.root.logger}
log4j.appender.CONSOLE=org.apache.log4j.ConsoleAppender
log4j.appender.CONSOLE.Threshold=${zookeeper.console.threshold}
log4j.appender.CONSOLE.layout=org.apache.log4j.PatternLayout
log4j.appender.CONSOLE.layout.ConversionPattern=%d{ISO8601} [myid:%X{myid}] - %-5p [%t:%C{1}@%L] - %m%n
</code></pre><p>This is the simplest possible way to safely log inside the container.
Because the applications write logs to standard out, Kubernetes will handle log rotation for you.
Kubernetes also implements a sane retention policy that ensures application logs written to
standard out and standard error do not exhaust local storage media.</p><p>Use <a href=/docs/reference/generated/kubectl/kubectl-commands/#logs><code>kubectl logs</code></a> to retrieve the last 20 log lines from one of the Pods.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl logs zk-0 --tail <span style=color:#666>20</span>
</span></span></code></pre></div><p>You can view application logs written to standard out or standard error using <code>kubectl logs</code> and from the Kubernetes Dashboard.</p><pre tabindex=0><code>2016-12-06 19:34:16,236 [myid:1] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxn@827] - Processing ruok command from /127.0.0.1:52740
2016-12-06 19:34:16,237 [myid:1] - INFO  [Thread-1136:NIOServerCnxn@1008] - Closed socket connection for client /127.0.0.1:52740 (no session established for client)
2016-12-06 19:34:26,155 [myid:1] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxnFactory@192] - Accepted socket connection from /127.0.0.1:52749
2016-12-06 19:34:26,155 [myid:1] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxn@827] - Processing ruok command from /127.0.0.1:52749
2016-12-06 19:34:26,156 [myid:1] - INFO  [Thread-1137:NIOServerCnxn@1008] - Closed socket connection for client /127.0.0.1:52749 (no session established for client)
2016-12-06 19:34:26,222 [myid:1] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxnFactory@192] - Accepted socket connection from /127.0.0.1:52750
2016-12-06 19:34:26,222 [myid:1] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxn@827] - Processing ruok command from /127.0.0.1:52750
2016-12-06 19:34:26,226 [myid:1] - INFO  [Thread-1138:NIOServerCnxn@1008] - Closed socket connection for client /127.0.0.1:52750 (no session established for client)
2016-12-06 19:34:36,151 [myid:1] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxnFactory@192] - Accepted socket connection from /127.0.0.1:52760
2016-12-06 19:34:36,152 [myid:1] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxn@827] - Processing ruok command from /127.0.0.1:52760
2016-12-06 19:34:36,152 [myid:1] - INFO  [Thread-1139:NIOServerCnxn@1008] - Closed socket connection for client /127.0.0.1:52760 (no session established for client)
2016-12-06 19:34:36,230 [myid:1] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxnFactory@192] - Accepted socket connection from /127.0.0.1:52761
2016-12-06 19:34:36,231 [myid:1] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxn@827] - Processing ruok command from /127.0.0.1:52761
2016-12-06 19:34:36,231 [myid:1] - INFO  [Thread-1140:NIOServerCnxn@1008] - Closed socket connection for client /127.0.0.1:52761 (no session established for client)
2016-12-06 19:34:46,149 [myid:1] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxnFactory@192] - Accepted socket connection from /127.0.0.1:52767
2016-12-06 19:34:46,149 [myid:1] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxn@827] - Processing ruok command from /127.0.0.1:52767
2016-12-06 19:34:46,149 [myid:1] - INFO  [Thread-1141:NIOServerCnxn@1008] - Closed socket connection for client /127.0.0.1:52767 (no session established for client)
2016-12-06 19:34:46,230 [myid:1] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxnFactory@192] - Accepted socket connection from /127.0.0.1:52768
2016-12-06 19:34:46,230 [myid:1] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxn@827] - Processing ruok command from /127.0.0.1:52768
2016-12-06 19:34:46,230 [myid:1] - INFO  [Thread-1142:NIOServerCnxn@1008] - Closed socket connection for client /127.0.0.1:52768 (no session established for client)
</code></pre><p>Kubernetes integrates with many logging solutions. You can choose a logging solution
that best fits your cluster and applications. For cluster-level logging and aggregation,
consider deploying a <a href=/docs/concepts/cluster-administration/logging#sidecar-container-with-logging-agent>sidecar container</a> to rotate and ship your logs.</p><h3 id=configuring-a-non-privileged-user>Configuring a non-privileged user</h3><p>The best practices to allow an application to run as a privileged
user inside of a container are a matter of debate. If your organization requires
that applications run as a non-privileged user you can use a
<a href=/docs/tasks/configure-pod-container/security-context/>SecurityContext</a> to control the user that
the entry point runs as.</p><p>The <code>zk</code> <code>StatefulSet</code>'s Pod <code>template</code> contains a <code>SecurityContext</code>.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>securityContext</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>runAsUser</span>:<span style=color:#bbb> </span><span style=color:#666>1000</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>fsGroup</span>:<span style=color:#bbb> </span><span style=color:#666>1000</span><span style=color:#bbb>
</span></span></span></code></pre></div><p>In the Pods' containers, UID 1000 corresponds to the zookeeper user and GID 1000
corresponds to the zookeeper group.</p><p>Get the ZooKeeper process information from the <code>zk-0</code> Pod.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl <span style=color:#a2f>exec</span> zk-0 -- ps -elf
</span></span></code></pre></div><p>As the <code>runAsUser</code> field of the <code>securityContext</code> object is set to 1000,
instead of running as root, the ZooKeeper process runs as the zookeeper user.</p><pre tabindex=0><code>F S UID        PID  PPID  C PRI  NI ADDR SZ WCHAN  STIME TTY          TIME CMD
4 S zookeep+     1     0  0  80   0 -  1127 -      20:46 ?        00:00:00 sh -c zkGenConfig.sh &amp;&amp; zkServer.sh start-foreground
0 S zookeep+    27     1  0  80   0 - 1155556 -    20:46 ?        00:00:19 /usr/lib/jvm/java-8-openjdk-amd64/bin/java -Dzookeeper.log.dir=/var/log/zookeeper -Dzookeeper.root.logger=INFO,CONSOLE -cp /usr/bin/../build/classes:/usr/bin/../build/lib/*.jar:/usr/bin/../share/zookeeper/zookeeper-3.4.9.jar:/usr/bin/../share/zookeeper/slf4j-log4j12-1.6.1.jar:/usr/bin/../share/zookeeper/slf4j-api-1.6.1.jar:/usr/bin/../share/zookeeper/netty-3.10.5.Final.jar:/usr/bin/../share/zookeeper/log4j-1.2.16.jar:/usr/bin/../share/zookeeper/jline-0.9.94.jar:/usr/bin/../src/java/lib/*.jar:/usr/bin/../etc/zookeeper: -Xmx2G -Xms2G -Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.local.only=false org.apache.zookeeper.server.quorum.QuorumPeerMain /usr/bin/../etc/zookeeper/zoo.cfg
</code></pre><p>By default, when the Pod's PersistentVolumes is mounted to the ZooKeeper server's data directory, it is only accessible by the root user. This configuration prevents the ZooKeeper process from writing to its WAL and storing its snapshots.</p><p>Use the command below to get the file permissions of the ZooKeeper data directory on the <code>zk-0</code> Pod.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl <span style=color:#a2f>exec</span> -ti zk-0 -- ls -ld /var/lib/zookeeper/data
</span></span></code></pre></div><p>Because the <code>fsGroup</code> field of the <code>securityContext</code> object is set to 1000, the ownership of the Pods' PersistentVolumes is set to the zookeeper group, and the ZooKeeper process is able to read and write its data.</p><pre tabindex=0><code>drwxr-sr-x 3 zookeeper zookeeper 4096 Dec  5 20:45 /var/lib/zookeeper/data
</code></pre><h2 id=managing-the-zookeeper-process>Managing the ZooKeeper process</h2><p>The <a href=https://zookeeper.apache.org/doc/current/zookeeperAdmin.html#sc_supervision>ZooKeeper documentation</a>
mentions that "You will want to have a supervisory process that
manages each of your ZooKeeper server processes (JVM)." Utilizing a watchdog
(supervisory process) to restart failed processes in a distributed system is a
common pattern. When deploying an application in Kubernetes, rather than using
an external utility as a supervisory process, you should use Kubernetes as the
watchdog for your application.</p><h3 id=updating-the-ensemble>Updating the ensemble</h3><p>The <code>zk</code> <code>StatefulSet</code> is configured to use the <code>RollingUpdate</code> update strategy.</p><p>You can use <code>kubectl patch</code> to update the number of <code>cpus</code> allocated to the servers.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl patch sts zk --type<span style=color:#666>=</span><span style=color:#b44>&#39;json&#39;</span> -p<span style=color:#666>=</span><span style=color:#b44>&#39;[{&#34;op&#34;: &#34;replace&#34;, &#34;path&#34;: &#34;/spec/template/spec/containers/0/resources/requests/cpu&#34;, &#34;value&#34;:&#34;0.3&#34;}]&#39;</span>
</span></span></code></pre></div><pre tabindex=0><code>statefulset.apps/zk patched
</code></pre><p>Use <code>kubectl rollout status</code> to watch the status of the update.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl rollout status sts/zk
</span></span></code></pre></div><pre tabindex=0><code>waiting for statefulset rolling update to complete 0 pods at revision zk-5db4499664...
Waiting for 1 pods to be ready...
Waiting for 1 pods to be ready...
waiting for statefulset rolling update to complete 1 pods at revision zk-5db4499664...
Waiting for 1 pods to be ready...
Waiting for 1 pods to be ready...
waiting for statefulset rolling update to complete 2 pods at revision zk-5db4499664...
Waiting for 1 pods to be ready...
Waiting for 1 pods to be ready...
statefulset rolling update complete 3 pods at revision zk-5db4499664...
</code></pre><p>This terminates the Pods, one at a time, in reverse ordinal order, and recreates them with the new configuration. This ensures that quorum is maintained during a rolling update.</p><p>Use the <code>kubectl rollout history</code> command to view a history or previous configurations.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl rollout <span style=color:#a2f>history</span> sts/zk
</span></span></code></pre></div><p>The output is similar to this:</p><pre tabindex=0><code>statefulsets &#34;zk&#34;
REVISION
1
2
</code></pre><p>Use the <code>kubectl rollout undo</code> command to roll back the modification.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl rollout undo sts/zk
</span></span></code></pre></div><p>The output is similar to this:</p><pre tabindex=0><code>statefulset.apps/zk rolled back
</code></pre><h3 id=handling-process-failure>Handling process failure</h3><p><a href=/docs/concepts/workloads/pods/pod-lifecycle/#restart-policy>Restart Policies</a> control how
Kubernetes handles process failures for the entry point of the container in a Pod.
For Pods in a <code>StatefulSet</code>, the only appropriate <code>RestartPolicy</code> is Always, and this
is the default value. For stateful applications you should <strong>never</strong> override
the default policy.</p><p>Use the following command to examine the process tree for the ZooKeeper server running in the <code>zk-0</code> Pod.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl <span style=color:#a2f>exec</span> zk-0 -- ps -ef
</span></span></code></pre></div><p>The command used as the container's entry point has PID 1, and
the ZooKeeper process, a child of the entry point, has PID 27.</p><pre tabindex=0><code>UID        PID  PPID  C STIME TTY          TIME CMD
zookeep+     1     0  0 15:03 ?        00:00:00 sh -c zkGenConfig.sh &amp;&amp; zkServer.sh start-foreground
zookeep+    27     1  0 15:03 ?        00:00:03 /usr/lib/jvm/java-8-openjdk-amd64/bin/java -Dzookeeper.log.dir=/var/log/zookeeper -Dzookeeper.root.logger=INFO,CONSOLE -cp /usr/bin/../build/classes:/usr/bin/../build/lib/*.jar:/usr/bin/../share/zookeeper/zookeeper-3.4.9.jar:/usr/bin/../share/zookeeper/slf4j-log4j12-1.6.1.jar:/usr/bin/../share/zookeeper/slf4j-api-1.6.1.jar:/usr/bin/../share/zookeeper/netty-3.10.5.Final.jar:/usr/bin/../share/zookeeper/log4j-1.2.16.jar:/usr/bin/../share/zookeeper/jline-0.9.94.jar:/usr/bin/../src/java/lib/*.jar:/usr/bin/../etc/zookeeper: -Xmx2G -Xms2G -Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.local.only=false org.apache.zookeeper.server.quorum.QuorumPeerMain /usr/bin/../etc/zookeeper/zoo.cfg
</code></pre><p>In another terminal watch the Pods in the <code>zk</code> <code>StatefulSet</code> with the following command.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get pod -w -l <span style=color:#b8860b>app</span><span style=color:#666>=</span>zk
</span></span></code></pre></div><p>In another terminal, terminate the ZooKeeper process in Pod <code>zk-0</code> with the following command.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl <span style=color:#a2f>exec</span> zk-0 -- pkill java
</span></span></code></pre></div><p>The termination of the ZooKeeper process caused its parent process to terminate. Because the <code>RestartPolicy</code> of the container is Always, it restarted the parent process.</p><pre tabindex=0><code>NAME      READY     STATUS    RESTARTS   AGE
zk-0      1/1       Running   0          21m
zk-1      1/1       Running   0          20m
zk-2      1/1       Running   0          19m
NAME      READY     STATUS    RESTARTS   AGE
zk-0      0/1       Error     0          29m
zk-0      0/1       Running   1         29m
zk-0      1/1       Running   1         29m
</code></pre><p>If your application uses a script (such as <code>zkServer.sh</code>) to launch the process
that implements the application's business logic, the script must terminate with the
child process. This ensures that Kubernetes will restart the application's
container when the process implementing the application's business logic fails.</p><h3 id=testing-for-liveness>Testing for liveness</h3><p>Configuring your application to restart failed processes is not enough to
keep a distributed system healthy. There are scenarios where
a system's processes can be both alive and unresponsive, or otherwise
unhealthy. You should use liveness probes to notify Kubernetes
that your application's processes are unhealthy and it should restart them.</p><p>The Pod <code>template</code> for the <code>zk</code> <code>StatefulSet</code> specifies a liveness probe.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>livenessProbe</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>exec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>command</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- sh<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- -c<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- <span style=color:#b44>&#34;zookeeper-ready 2181&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>initialDelaySeconds</span>:<span style=color:#bbb> </span><span style=color:#666>15</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>timeoutSeconds</span>:<span style=color:#bbb> </span><span style=color:#666>5</span><span style=color:#bbb>
</span></span></span></code></pre></div><p>The probe calls a bash script that uses the ZooKeeper <code>ruok</code> four letter
word to test the server's health.</p><pre tabindex=0><code>OK=$(echo ruok | nc 127.0.0.1 $1)
if [ &#34;$OK&#34; == &#34;imok&#34; ]; then
    exit 0
else
    exit 1
fi
</code></pre><p>In one terminal window, use the following command to watch the Pods in the <code>zk</code> StatefulSet.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get pod -w -l <span style=color:#b8860b>app</span><span style=color:#666>=</span>zk
</span></span></code></pre></div><p>In another window, using the following command to delete the <code>zookeeper-ready</code> script from the file system of Pod <code>zk-0</code>.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl <span style=color:#a2f>exec</span> zk-0 -- rm /opt/zookeeper/bin/zookeeper-ready
</span></span></code></pre></div><p>When the liveness probe for the ZooKeeper process fails, Kubernetes will
automatically restart the process for you, ensuring that unhealthy processes in
the ensemble are restarted.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get pod -w -l <span style=color:#b8860b>app</span><span style=color:#666>=</span>zk
</span></span></code></pre></div><pre tabindex=0><code>NAME      READY     STATUS    RESTARTS   AGE
zk-0      1/1       Running   0          1h
zk-1      1/1       Running   0          1h
zk-2      1/1       Running   0          1h
NAME      READY     STATUS    RESTARTS   AGE
zk-0      0/1       Running   0          1h
zk-0      0/1       Running   1         1h
zk-0      1/1       Running   1         1h
</code></pre><h3 id=testing-for-readiness>Testing for readiness</h3><p>Readiness is not the same as liveness. If a process is alive, it is scheduled
and healthy. If a process is ready, it is able to process input. Liveness is
a necessary, but not sufficient, condition for readiness. There are cases,
particularly during initialization and termination, when a process can be
alive but not ready.</p><p>If you specify a readiness probe, Kubernetes will ensure that your application's
processes will not receive network traffic until their readiness checks pass.</p><p>For a ZooKeeper server, liveness implies readiness. Therefore, the readiness
probe from the <code>zookeeper.yaml</code> manifest is identical to the liveness probe.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>readinessProbe</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>exec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>command</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- sh<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- -c<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- <span style=color:#b44>&#34;zookeeper-ready 2181&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>initialDelaySeconds</span>:<span style=color:#bbb> </span><span style=color:#666>15</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>timeoutSeconds</span>:<span style=color:#bbb> </span><span style=color:#666>5</span><span style=color:#bbb>
</span></span></span></code></pre></div><p>Even though the liveness and readiness probes are identical, it is important
to specify both. This ensures that only healthy servers in the ZooKeeper
ensemble receive network traffic.</p><h2 id=tolerating-node-failure>Tolerating Node failure</h2><p>ZooKeeper needs a quorum of servers to successfully commit mutations
to data. For a three server ensemble, two servers must be healthy for
writes to succeed. In quorum based systems, members are deployed across failure
domains to ensure availability. To avoid an outage, due to the loss of an
individual machine, best practices preclude co-locating multiple instances of the
application on the same machine.</p><p>By default, Kubernetes may co-locate Pods in a <code>StatefulSet</code> on the same node.
For the three server ensemble you created, if two servers are on the same node, and that node fails,
the clients of your ZooKeeper service will experience an outage until at least one of the Pods can be rescheduled.</p><p>You should always provision additional capacity to allow the processes of critical
systems to be rescheduled in the event of node failures. If you do so, then the
outage will only last until the Kubernetes scheduler reschedules one of the ZooKeeper
servers. However, if you want your service to tolerate node failures with no downtime,
you should set <code>podAntiAffinity</code>.</p><p>Use the command below to get the nodes for Pods in the <code>zk</code> <code>StatefulSet</code>.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span><span style=color:#a2f;font-weight:700>for</span> i in <span style=color:#666>0</span> <span style=color:#666>1</span> 2; <span style=color:#a2f;font-weight:700>do</span> kubectl get pod zk-<span style=color:#b8860b>$i</span> --template <span style=color:#666>{{</span>.spec.nodeName<span style=color:#666>}}</span>; <span style=color:#a2f>echo</span> <span style=color:#b44>&#34;&#34;</span>; <span style=color:#a2f;font-weight:700>done</span>
</span></span></code></pre></div><p>All of the Pods in the <code>zk</code> <code>StatefulSet</code> are deployed on different nodes.</p><pre tabindex=0><code>kubernetes-node-cxpk
kubernetes-node-a5aq
kubernetes-node-2g2d
</code></pre><p>This is because the Pods in the <code>zk</code> <code>StatefulSet</code> have a <code>PodAntiAffinity</code> specified.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>affinity</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>podAntiAffinity</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>requiredDuringSchedulingIgnoredDuringExecution</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- <span style=color:green;font-weight:700>labelSelector</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>matchExpressions</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>            </span>- <span style=color:green;font-weight:700>key</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;app&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>              </span><span style=color:green;font-weight:700>operator</span>:<span style=color:#bbb> </span>In<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>              </span><span style=color:green;font-weight:700>values</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>                </span>- zk<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>topologyKey</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;kubernetes.io/hostname&#34;</span><span style=color:#bbb>
</span></span></span></code></pre></div><p>The <code>requiredDuringSchedulingIgnoredDuringExecution</code> field tells the
Kubernetes Scheduler that it should never co-locate two Pods which have <code>app</code> label
as <code>zk</code> in the domain defined by the <code>topologyKey</code>. The <code>topologyKey</code>
<code>kubernetes.io/hostname</code> indicates that the domain is an individual node. Using
different rules, labels, and selectors, you can extend this technique to spread
your ensemble across physical, network, and power failure domains.</p><h2 id=surviving-maintenance>Surviving maintenance</h2><p>In this section you will cordon and drain nodes. If you are using this tutorial
on a shared cluster, be sure that this will not adversely affect other tenants.</p><p>The previous section showed you how to spread your Pods across nodes to survive
unplanned node failures, but you also need to plan for temporary node failures
that occur due to planned maintenance.</p><p>Use this command to get the nodes in your cluster.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get nodes
</span></span></code></pre></div><p>This tutorial assumes a cluster with at least four nodes. If the cluster has more than four, use <a href=/docs/reference/generated/kubectl/kubectl-commands/#cordon><code>kubectl cordon</code></a> to cordon all but four nodes. Constraining to four nodes will ensure Kubernetes encounters affinity and PodDisruptionBudget constraints when scheduling zookeeper Pods in the following maintenance simulation.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl cordon &lt;node-name&gt;
</span></span></code></pre></div><p>Use this command to get the <code>zk-pdb</code> <code>PodDisruptionBudget</code>.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get pdb zk-pdb
</span></span></code></pre></div><p>The <code>max-unavailable</code> field indicates to Kubernetes that at most one Pod from
<code>zk</code> <code>StatefulSet</code> can be unavailable at any time.</p><pre tabindex=0><code>NAME      MIN-AVAILABLE   MAX-UNAVAILABLE   ALLOWED-DISRUPTIONS   AGE
zk-pdb    N/A             1                 1
</code></pre><p>In one terminal, use this command to watch the Pods in the <code>zk</code> <code>StatefulSet</code>.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get pods -w -l <span style=color:#b8860b>app</span><span style=color:#666>=</span>zk
</span></span></code></pre></div><p>In another terminal, use this command to get the nodes that the Pods are currently scheduled on.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span><span style=color:#a2f;font-weight:700>for</span> i in <span style=color:#666>0</span> <span style=color:#666>1</span> 2; <span style=color:#a2f;font-weight:700>do</span> kubectl get pod zk-<span style=color:#b8860b>$i</span> --template <span style=color:#666>{{</span>.spec.nodeName<span style=color:#666>}}</span>; <span style=color:#a2f>echo</span> <span style=color:#b44>&#34;&#34;</span>; <span style=color:#a2f;font-weight:700>done</span>
</span></span></code></pre></div><p>The output is similar to this:</p><pre tabindex=0><code>kubernetes-node-pb41
kubernetes-node-ixsl
kubernetes-node-i4c4
</code></pre><p>Use <a href=/docs/reference/generated/kubectl/kubectl-commands/#drain><code>kubectl drain</code></a> to cordon and
drain the node on which the <code>zk-0</code> Pod is scheduled.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl drain <span style=color:#a2f;font-weight:700>$(</span>kubectl get pod zk-0 --template <span style=color:#666>{{</span>.spec.nodeName<span style=color:#666>}}</span><span style=color:#a2f;font-weight:700>)</span> --ignore-daemonsets --force --delete-emptydir-data
</span></span></code></pre></div><p>The output is similar to this:</p><pre tabindex=0><code>node &#34;kubernetes-node-pb41&#34; cordoned

WARNING: Deleting pods not managed by ReplicationController, ReplicaSet, Job, or DaemonSet: fluentd-cloud-logging-kubernetes-node-pb41, kube-proxy-kubernetes-node-pb41; Ignoring DaemonSet-managed pods: node-problem-detector-v0.1-o5elz
pod &#34;zk-0&#34; deleted
node &#34;kubernetes-node-pb41&#34; drained
</code></pre><p>As there are four nodes in your cluster, <code>kubectl drain</code>, succeeds and the
<code>zk-0</code> is rescheduled to another node.</p><pre tabindex=0><code>NAME      READY     STATUS    RESTARTS   AGE
zk-0      1/1       Running   2          1h
zk-1      1/1       Running   0          1h
zk-2      1/1       Running   0          1h
NAME      READY     STATUS        RESTARTS   AGE
zk-0      1/1       Terminating   2          2h
zk-0      0/1       Terminating   2         2h
zk-0      0/1       Terminating   2         2h
zk-0      0/1       Terminating   2         2h
zk-0      0/1       Pending   0         0s
zk-0      0/1       Pending   0         0s
zk-0      0/1       ContainerCreating   0         0s
zk-0      0/1       Running   0         51s
zk-0      1/1       Running   0         1m
</code></pre><p>Keep watching the <code>StatefulSet</code>'s Pods in the first terminal and drain the node on which
<code>zk-1</code> is scheduled.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl drain <span style=color:#a2f;font-weight:700>$(</span>kubectl get pod zk-1 --template <span style=color:#666>{{</span>.spec.nodeName<span style=color:#666>}}</span><span style=color:#a2f;font-weight:700>)</span> --ignore-daemonsets --force --delete-emptydir-data
</span></span></code></pre></div><p>The output is similar to this:</p><pre tabindex=0><code>&#34;kubernetes-node-ixsl&#34; cordoned
WARNING: Deleting pods not managed by ReplicationController, ReplicaSet, Job, or DaemonSet: fluentd-cloud-logging-kubernetes-node-ixsl, kube-proxy-kubernetes-node-ixsl; Ignoring DaemonSet-managed pods: node-problem-detector-v0.1-voc74
pod &#34;zk-1&#34; deleted
node &#34;kubernetes-node-ixsl&#34; drained
</code></pre><p>The <code>zk-1</code> Pod cannot be scheduled because the <code>zk</code> <code>StatefulSet</code> contains a <code>PodAntiAffinity</code> rule preventing
co-location of the Pods, and as only two nodes are schedulable, the Pod will remain in a Pending state.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get pods -w -l <span style=color:#b8860b>app</span><span style=color:#666>=</span>zk
</span></span></code></pre></div><p>The output is similar to this:</p><pre tabindex=0><code>NAME      READY     STATUS    RESTARTS   AGE
zk-0      1/1       Running   2          1h
zk-1      1/1       Running   0          1h
zk-2      1/1       Running   0          1h
NAME      READY     STATUS        RESTARTS   AGE
zk-0      1/1       Terminating   2          2h
zk-0      0/1       Terminating   2         2h
zk-0      0/1       Terminating   2         2h
zk-0      0/1       Terminating   2         2h
zk-0      0/1       Pending   0         0s
zk-0      0/1       Pending   0         0s
zk-0      0/1       ContainerCreating   0         0s
zk-0      0/1       Running   0         51s
zk-0      1/1       Running   0         1m
zk-1      1/1       Terminating   0         2h
zk-1      0/1       Terminating   0         2h
zk-1      0/1       Terminating   0         2h
zk-1      0/1       Terminating   0         2h
zk-1      0/1       Pending   0         0s
zk-1      0/1       Pending   0         0s
</code></pre><p>Continue to watch the Pods of the StatefulSet, and drain the node on which
<code>zk-2</code> is scheduled.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl drain <span style=color:#a2f;font-weight:700>$(</span>kubectl get pod zk-2 --template <span style=color:#666>{{</span>.spec.nodeName<span style=color:#666>}}</span><span style=color:#a2f;font-weight:700>)</span> --ignore-daemonsets --force --delete-emptydir-data
</span></span></code></pre></div><p>The output is similar to this:</p><pre tabindex=0><code>node &#34;kubernetes-node-i4c4&#34; cordoned

WARNING: Deleting pods not managed by ReplicationController, ReplicaSet, Job, or DaemonSet: fluentd-cloud-logging-kubernetes-node-i4c4, kube-proxy-kubernetes-node-i4c4; Ignoring DaemonSet-managed pods: node-problem-detector-v0.1-dyrog
WARNING: Ignoring DaemonSet-managed pods: node-problem-detector-v0.1-dyrog; Deleting pods not managed by ReplicationController, ReplicaSet, Job, or DaemonSet: fluentd-cloud-logging-kubernetes-node-i4c4, kube-proxy-kubernetes-node-i4c4
There are pending pods when an error occurred: Cannot evict pod as it would violate the pod&#39;s disruption budget.
pod/zk-2
</code></pre><p>Use <code>CTRL-C</code> to terminate kubectl.</p><p>You cannot drain the third node because evicting <code>zk-2</code> would violate <code>zk-budget</code>. However, the node will remain cordoned.</p><p>Use <code>zkCli.sh</code> to retrieve the value you entered during the sanity test from <code>zk-0</code>.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl <span style=color:#a2f>exec</span> zk-0 zkCli.sh get /hello
</span></span></code></pre></div><p>The service is still available because its <code>PodDisruptionBudget</code> is respected.</p><pre tabindex=0><code>WatchedEvent state:SyncConnected type:None path:null
world
cZxid = 0x200000002
ctime = Wed Dec 07 00:08:59 UTC 2016
mZxid = 0x200000002
mtime = Wed Dec 07 00:08:59 UTC 2016
pZxid = 0x200000002
cversion = 0
dataVersion = 0
aclVersion = 0
ephemeralOwner = 0x0
dataLength = 5
numChildren = 0
</code></pre><p>Use <a href=/docs/reference/generated/kubectl/kubectl-commands/#uncordon><code>kubectl uncordon</code></a> to uncordon the first node.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl uncordon kubernetes-node-pb41
</span></span></code></pre></div><p>The output is similar to this:</p><pre tabindex=0><code>node &#34;kubernetes-node-pb41&#34; uncordoned
</code></pre><p><code>zk-1</code> is rescheduled on this node. Wait until <code>zk-1</code> is Running and Ready.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get pods -w -l <span style=color:#b8860b>app</span><span style=color:#666>=</span>zk
</span></span></code></pre></div><p>The output is similar to this:</p><pre tabindex=0><code>NAME      READY     STATUS    RESTARTS   AGE
zk-0      1/1       Running   2          1h
zk-1      1/1       Running   0          1h
zk-2      1/1       Running   0          1h
NAME      READY     STATUS        RESTARTS   AGE
zk-0      1/1       Terminating   2          2h
zk-0      0/1       Terminating   2         2h
zk-0      0/1       Terminating   2         2h
zk-0      0/1       Terminating   2         2h
zk-0      0/1       Pending   0         0s
zk-0      0/1       Pending   0         0s
zk-0      0/1       ContainerCreating   0         0s
zk-0      0/1       Running   0         51s
zk-0      1/1       Running   0         1m
zk-1      1/1       Terminating   0         2h
zk-1      0/1       Terminating   0         2h
zk-1      0/1       Terminating   0         2h
zk-1      0/1       Terminating   0         2h
zk-1      0/1       Pending   0         0s
zk-1      0/1       Pending   0         0s
zk-1      0/1       Pending   0         12m
zk-1      0/1       ContainerCreating   0         12m
zk-1      0/1       Running   0         13m
zk-1      1/1       Running   0         13m
</code></pre><p>Attempt to drain the node on which <code>zk-2</code> is scheduled.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl drain <span style=color:#a2f;font-weight:700>$(</span>kubectl get pod zk-2 --template <span style=color:#666>{{</span>.spec.nodeName<span style=color:#666>}}</span><span style=color:#a2f;font-weight:700>)</span> --ignore-daemonsets --force --delete-emptydir-data
</span></span></code></pre></div><p>The output is similar to this:</p><pre tabindex=0><code>node &#34;kubernetes-node-i4c4&#34; already cordoned
WARNING: Deleting pods not managed by ReplicationController, ReplicaSet, Job, or DaemonSet: fluentd-cloud-logging-kubernetes-node-i4c4, kube-proxy-kubernetes-node-i4c4; Ignoring DaemonSet-managed pods: node-problem-detector-v0.1-dyrog
pod &#34;heapster-v1.2.0-2604621511-wht1r&#34; deleted
pod &#34;zk-2&#34; deleted
node &#34;kubernetes-node-i4c4&#34; drained
</code></pre><p>This time <code>kubectl drain</code> succeeds.</p><p>Uncordon the second node to allow <code>zk-2</code> to be rescheduled.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl uncordon kubernetes-node-ixsl
</span></span></code></pre></div><p>The output is similar to this:</p><pre tabindex=0><code>node &#34;kubernetes-node-ixsl&#34; uncordoned
</code></pre><p>You can use <code>kubectl drain</code> in conjunction with <code>PodDisruptionBudgets</code> to ensure that your services remain available during maintenance.
If drain is used to cordon nodes and evict pods prior to taking the node offline for maintenance,
services that express a disruption budget will have that budget respected.
You should always allocate additional capacity for critical services so that their Pods can be immediately rescheduled.</p><h2 id=cleaning-up>Cleaning up</h2><ul><li>Use <code>kubectl uncordon</code> to uncordon all the nodes in your cluster.</li><li>You must delete the persistent storage media for the PersistentVolumes used in this tutorial.
Follow the necessary steps, based on your environment, storage configuration,
and provisioning method, to ensure that all storage is reclaimed.</li></ul></div></main></div></div><footer class=d-print-none><div class=footer__links><nav><a class=text-white href=/docs/home/>Home</a>
<a class=text-white href=/blog/>Blog</a>
<a class=text-white href=/training/>Training</a>
<a class=text-white href=/partners/>Partners</a>
<a class=text-white href=/community/>Community</a>
<a class=text-white href=/case-studies/>Case Studies</a></nav></div><div class=container-fluid><div class=row><div class="col-6 col-sm-2 text-xs-center order-sm-2"><ul class="list-inline mb-0"><li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title="User mailing list" aria-label="User mailing list"><a class=text-white target=_blank href=https://discuss.kubernetes.io><i class="fa fa-envelope"></i></a></li><li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title=Twitter aria-label=Twitter><a class=text-white target=_blank href=https://twitter.com/kubernetesio><i class="fab fa-twitter"></i></a></li><li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title=Calendar aria-label=Calendar><a class=text-white target=_blank href="https://calendar.google.com/calendar/embed?src=calendar%40kubernetes.io"><i class="fas fa-calendar-alt"></i></a></li><li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title=Youtube aria-label=Youtube><a class=text-white target=_blank href=https://youtube.com/kubernetescommunity><i class="fab fa-youtube"></i></a></li></ul></div><div class="col-6 col-sm-2 text-right text-xs-center order-sm-3"><ul class="list-inline mb-0"><li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title=GitHub aria-label=GitHub><a class=text-white target=_blank href=https://github.com/kubernetes/kubernetes><i class="fab fa-github"></i></a></li><li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title=Slack aria-label=Slack><a class=text-white target=_blank href=https://slack.k8s.io><i class="fab fa-slack"></i></a></li><li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title=Contribute aria-label=Contribute><a class=text-white target=_blank href=https://git.k8s.io/community/contributors/guide><i class="fas fa-edit"></i></a></li><li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title="Stack Overflow" aria-label="Stack Overflow"><a class=text-white target=_blank href=https://stackoverflow.com/questions/tagged/kubernetes><i class="fab fa-stack-overflow"></i></a></li></ul></div><div class="col-12 col-sm-8 text-center order-sm-2"><small class=text-white>&copy; 2023 The Kubernetes Authors | Documentation Distributed under <a href=https://git.k8s.io/website/LICENSE class=light-text>CC BY 4.0</a></small><br><small class=text-white>Copyright &copy; 2023 The Linux Foundation &reg;. All rights reserved. The Linux Foundation has registered trademarks and uses trademarks. For a list of trademarks of The Linux Foundation, please see our <a href=https://www.linuxfoundation.org/trademark-usage class=light-text>Trademark Usage page</a></small><br><small class=text-white>ICP license: 京ICP备17074266号-3</small></div></div></div></footer></div><script src=/js/jquery-3.6.0.min.js integrity=sha384-vtXRMe3mGCbOeY7l30aIg8H9p3GdeSe4IFlP6G8JMa7o7lXvnz3GFKzPxzJdPfGK crossorigin=anonymous></script>
<script src=/js/popper-1.16.1.min.js intregrity=sha384-9/reFTGAW83EW2RDu2S0VKaIzap3H66lZH81PoYlFhbGU+6BZp6G7niu735Sk7lN crossorigin=anonymous></script>
<script src=/js/bootstrap-4.6.1.min.js integrity=sha384-VHvPCCyXqtD5DqJeNxl2dtTyhF78xXNXdkwX1CZeRusQfRKp+tA7hAShOK/B/fQ2 crossorigin=anonymous></script>
<script src=/js/script.js></script>
<script async src=/js/mermaid-8.13.4.min.js integrity=sha384-5hHNvPeMrNH14oM3IcQofDoBhiclNK3g2+hnEinKzQ07C4AliMeVpnvxuiwEGpaO crossorigin=anonymous></script>
<script src=/js/main.min.5c0bf7f21dc4f66485f74efbbeeff28a7e4f8cddaac1bae47043159c922ff3a3.js integrity="sha256-XAv38h3E9mSF9077vu/yin5PjN2qwbrkcEMVnJIv86M=" crossorigin=anonymous></script></body></html>