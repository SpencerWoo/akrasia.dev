<!doctype html><html lang=en class=no-js><head><meta name=robots content="noindex, nofollow"><link rel=alternate hreflang=zh-cn href=https://kubernetes.io/zh-cn/docs/concepts/storage/><link rel=alternate hreflang=ko href=https://kubernetes.io/ko/docs/concepts/storage/><link rel=alternate hreflang=ja href=https://kubernetes.io/ja/docs/concepts/storage/><link rel=alternate hreflang=fr href=https://kubernetes.io/fr/docs/concepts/storage/><link rel=alternate hreflang=de href=https://kubernetes.io/de/docs/concepts/storage/><link rel=alternate hreflang=es href=https://kubernetes.io/es/docs/concepts/storage/><link rel=alternate hreflang=pt-br href=https://kubernetes.io/pt-br/docs/concepts/storage/><link rel=alternate hreflang=id href=https://kubernetes.io/id/docs/concepts/storage/><link rel=alternate hreflang=uk href=https://kubernetes.io/uk/docs/concepts/storage/><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=generator content="Hugo 0.110.0"><link rel=canonical type=text/html href=https://kubernetes.io/docs/concepts/storage/><link rel="shortcut icon" type=image/png href=/images/favicon.png><link rel=apple-touch-icon href=/favicons/apple-touch-icon-180x180.png sizes=180x180><link rel=manifest href=/manifest.webmanifest><link rel=apple-touch-icon href=/images/kubernetes-192x192.png><title>Storage | Kubernetes</title><meta property="og:title" content="Storage"><meta property="og:description" content="Ways to provide both long-term and temporary storage to Pods in your cluster.
"><meta property="og:type" content="website"><meta property="og:url" content="https://kubernetes.io/docs/concepts/storage/"><meta property="og:site_name" content="Kubernetes"><meta itemprop=name content="Storage"><meta itemprop=description content="Ways to provide both long-term and temporary storage to Pods in your cluster.
"><meta name=twitter:card content="summary"><meta name=twitter:title content="Storage"><meta name=twitter:description content="Ways to provide both long-term and temporary storage to Pods in your cluster.
"><link href=/scss/main.css rel=stylesheet><script type=application/ld+json>{"@context":"https://schema.org","@type":"Organization","url":"https://kubernetes.io","logo":"https://kubernetes.io/images/favicon.png","potentialAction":{"@type":"SearchAction","target":"https://kubernetes.io/search/?q={search_term_string}","query-input":"required name=search_term_string"}}</script><meta name=theme-color content="#326ce5"><link rel=stylesheet href=/css/feature-states.css><meta name=description content="Ways to provide both long-term and temporary storage to Pods in your cluster.
"><meta property="og:description" content="Ways to provide both long-term and temporary storage to Pods in your cluster.
"><meta name=twitter:description content="Ways to provide both long-term and temporary storage to Pods in your cluster.
"><meta property="og:url" content="https://kubernetes.io/docs/concepts/storage/"><meta property="og:title" content="Storage"><meta name=twitter:title content="Storage"><meta name=twitter:image content="https://kubernetes.io/images/favicon.png"><meta name=twitter:image:alt content="Kubernetes"><meta property="og:image" content="/images/kubernetes-horizontal-color.png"><meta property="og:type" content="article"><script src=/js/jquery-3.6.0.min.js intregrity=sha384-vtXRMe3mGCbOeY7l30aIg8H9p3GdeSe4IFlP6G8JMa7o7lXvnz3GFKzPxzJdPfGK crossorigin=anonymous></script></head><body class=td-section><header><nav class="js-navbar-scroll navbar navbar-expand navbar-dark flex-column flex-md-row td-navbar" data-auto-burger=primary><a class=navbar-brand href=/></a><div class="td-navbar-nav-scroll ml-md-auto" id=main_navbar><ul class="navbar-nav mt-2 mt-lg-0"><li class="nav-item mr-2 mb-lg-0"><a class="nav-link active" href=/docs/>Documentation</a></li><li class="nav-item mr-2 mb-lg-0"><a class=nav-link href=/blog/>Kubernetes Blog</a></li><li class="nav-item mr-2 mb-lg-0"><a class=nav-link href=/training/>Training</a></li><li class="nav-item mr-2 mb-lg-0"><a class=nav-link href=/partners/>Partners</a></li><li class="nav-item mr-2 mb-lg-0"><a class=nav-link href=/community/>Community</a></li><li class="nav-item mr-2 mb-lg-0"><a class=nav-link href=/case-studies/>Case Studies</a></li><li class="nav-item dropdown"><a class="nav-link dropdown-toggle" href=# id=navbarDropdown role=button data-toggle=dropdown aria-haspopup=true aria-expanded=false>Versions</a><div class="dropdown-menu dropdown-menu-right" aria-labelledby=navbarDropdownMenuLink><a class=dropdown-item href=/releases>Release Information</a>
<a class=dropdown-item href=https://kubernetes.io/docs/concepts/storage/>v1.25</a>
<a class=dropdown-item href=https://v1-24.docs.kubernetes.io/docs/concepts/storage/>v1.24</a>
<a class=dropdown-item href=https://v1-23.docs.kubernetes.io/docs/concepts/storage/>v1.23</a>
<a class=dropdown-item href=https://v1-22.docs.kubernetes.io/docs/concepts/storage/>v1.22</a>
<a class=dropdown-item href=https://v1-21.docs.kubernetes.io/docs/concepts/storage/>v1.21</a></div></li><li class="nav-item dropdown"><a class="nav-link dropdown-toggle" href=# id=navbarDropdownMenuLink role=button data-toggle=dropdown aria-haspopup=true aria-expanded=false>English</a><div class="dropdown-menu dropdown-menu-right" aria-labelledby=navbarDropdownMenuLink><a class=dropdown-item href=/zh-cn/docs/concepts/storage/>中文 (Chinese)</a>
<a class=dropdown-item href=/ko/docs/concepts/storage/>한국어 (Korean)</a>
<a class=dropdown-item href=/ja/docs/concepts/storage/>日本語 (Japanese)</a>
<a class=dropdown-item href=/fr/docs/concepts/storage/>Français (French)</a>
<a class=dropdown-item href=/de/docs/concepts/storage/>Deutsch (German)</a>
<a class=dropdown-item href=/es/docs/concepts/storage/>Español (Spanish)</a>
<a class=dropdown-item href=/pt-br/docs/concepts/storage/>Português (Portuguese)</a>
<a class=dropdown-item href=/id/docs/concepts/storage/>Bahasa Indonesia</a>
<a class=dropdown-item href=/uk/docs/concepts/storage/>Українська (Ukrainian)</a></div></li></ul></div><button id=hamburger onclick=kub.toggleMenu() data-auto-burger-exclude><div></div></button></nav></header><div class="container-fluid td-outer"><div class=td-main><div class="row flex-xl-nowrap"><main class="col-12 col-md-9 col-xl-8 pl-md-5" role=main><div class=td-content><div class="pageinfo pageinfo-primary d-print-none"><p>This is the multi-page printable view of this section.
<a href=# onclick="return print(),!1">Click here to print</a>.</p><p><a href=/docs/concepts/storage/>Return to the regular view of this page</a>.</p></div><h1 class=title>Storage</h1><div class=lead>Ways to provide both long-term and temporary storage to Pods in your cluster.</div><ul><li>1: <a href=#pg-27795584640a03bd2024f1fe3b3ab754>Volumes</a></li><li>2: <a href=#pg-ffd12528a12882b282e1bd19e29f9e75>Persistent Volumes</a></li><li>3: <a href=#pg-2db414b26d4daec3ebed19dd837830c3>Projected Volumes</a></li><li>4: <a href=#pg-df33eab51202c17bb0fe551d1d5cc5d2>Ephemeral Volumes</a></li><li>5: <a href=#pg-f0276d05eef111249272a1c932a91e2c>Storage Classes</a></li><li>6: <a href=#pg-018f0a7fc6e2f6d16da37702fc39b4f3>Dynamic Volume Provisioning</a></li><li>7: <a href=#pg-c262af210c6828dec445d2f55a1d877a>Volume Snapshots</a></li><li>8: <a href=#pg-4d00116c86dade62bdd5be7dc2afa1ca>Volume Snapshot Classes</a></li><li>9: <a href=#pg-707ca81a34eb1ca202f34692e9917d1e>CSI Volume Cloning</a></li><li>10: <a href=#pg-00cd24f4570b7acaac75c2551c948bc7>Storage Capacity</a></li><li>11: <a href=#pg-b2e4b16ac37988c678a3312a4a6639f8>Node-specific Volume Limits</a></li><li>12: <a href=#pg-4f40cb95a671e51b4f0156a409d95c6d>Volume Health Monitoring</a></li><li>13: <a href=#pg-055a8df536f8ba8f3aa0217bd2db5437>Windows Storage</a></li></ul><div class=content></div></div><div class=td-content><h1 id=pg-27795584640a03bd2024f1fe3b3ab754>1 - Volumes</h1><p>On-disk files in a container are ephemeral, which presents some problems for
non-trivial applications when running in containers. One problem
is the loss of files when a container crashes. The kubelet restarts the container
but with a clean state. A second problem occurs when sharing files
between containers running together in a <code>Pod</code>.
The Kubernetes <a class=glossary-tooltip title='A directory containing data, accessible to the containers in a pod.' data-toggle=tooltip data-placement=top href=/docs/concepts/storage/volumes/ target=_blank aria-label=volume>volume</a> abstraction
solves both of these problems.
Familiarity with <a href=/docs/concepts/workloads/pods/>Pods</a> is suggested.</p><h2 id=background>Background</h2><p>Docker has a concept of
<a href=https://docs.docker.com/storage/>volumes</a>, though it is
somewhat looser and less managed. A Docker volume is a directory on
disk or in another container. Docker provides volume
drivers, but the functionality is somewhat limited.</p><p>Kubernetes supports many types of volumes. A <a class=glossary-tooltip title='A Pod represents a set of running containers in your cluster.' data-toggle=tooltip data-placement=top href=/docs/concepts/workloads/pods/ target=_blank aria-label=Pod>Pod</a>
can use any number of volume types simultaneously.
Ephemeral volume types have a lifetime of a pod, but persistent volumes exist beyond
the lifetime of a pod. When a pod ceases to exist, Kubernetes destroys ephemeral volumes;
however, Kubernetes does not destroy persistent volumes.
For any kind of volume in a given pod, data is preserved across container restarts.</p><p>At its core, a volume is a directory, possibly with some data in it, which
is accessible to the containers in a pod. How that directory comes to be, the
medium that backs it, and the contents of it are determined by the particular
volume type used.</p><p>To use a volume, specify the volumes to provide for the Pod in <code>.spec.volumes</code>
and declare where to mount those volumes into containers in <code>.spec.containers[*].volumeMounts</code>.
A process in a container sees a filesystem view composed from the initial contents of
the <a class=glossary-tooltip title='Stored instance of a container that holds a set of software needed to run an application.' data-toggle=tooltip data-placement=top href='/docs/reference/glossary/?all=true#term-image' target=_blank aria-label='container image'>container image</a>, plus volumes
(if defined) mounted inside the container.
The process sees a root filesystem that initially matches the contents of the container
image.
Any writes to within that filesystem hierarchy, if allowed, affect what that process views
when it performs a subsequent filesystem access.
Volumes mount at the <a href=#using-subpath>specified paths</a> within
the image.
For each container defined within a Pod, you must independently specify where
to mount each volume that the container uses.</p><p>Volumes cannot mount within other volumes (but see <a href=#using-subpath>Using subPath</a>
for a related mechanism). Also, a volume cannot contain a hard link to anything in
a different volume.</p><h2 id=volume-types>Types of volumes</h2><p>Kubernetes supports several types of volumes.</p><h3 id=awselasticblockstore>awsElasticBlockStore (deprecated)</h3><div style=margin-top:10px;margin-bottom:10px><b>FEATURE STATE:</b> <code>Kubernetes v1.17 [deprecated]</code></div><p>An <code>awsElasticBlockStore</code> volume mounts an Amazon Web Services (AWS)
<a href=https://aws.amazon.com/ebs/>EBS volume</a> into your pod. Unlike
<code>emptyDir</code>, which is erased when a pod is removed, the contents of an EBS
volume are persisted and the volume is unmounted. This means that an
EBS volume can be pre-populated with data, and that data can be shared between pods.</p><div class="alert alert-info note callout" role=alert><strong>Note:</strong> You must create an EBS volume by using <code>aws ec2 create-volume</code> or the AWS API before you can use it.</div><p>There are some restrictions when using an <code>awsElasticBlockStore</code> volume:</p><ul><li>the nodes on which pods are running must be AWS EC2 instances</li><li>those instances need to be in the same region and availability zone as the EBS volume</li><li>EBS only supports a single EC2 instance mounting a volume</li></ul><h4 id=creating-an-aws-ebs-volume>Creating an AWS EBS volume</h4><p>Before you can use an EBS volume with a pod, you need to create it.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>aws ec2 create-volume --availability-zone<span style=color:#666>=</span>eu-west-1a --size<span style=color:#666>=</span><span style=color:#666>10</span> --volume-type<span style=color:#666>=</span>gp2
</span></span></code></pre></div><p>Make sure the zone matches the zone you brought up your cluster in. Check that the size and EBS volume
type are suitable for your use.</p><h4 id=aws-ebs-configuration-example>AWS EBS configuration example</h4><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>test-ebs<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>registry.k8s.io/test-webserver<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>test-container<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>volumeMounts</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:green;font-weight:700>mountPath</span>:<span style=color:#bbb> </span>/test-ebs<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>test-volume<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>volumes</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>test-volume<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:#080;font-style:italic># This AWS EBS volume must already exist.</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>awsElasticBlockStore</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>volumeID</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;&lt;volume id&gt;&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>fsType</span>:<span style=color:#bbb> </span>ext4<span style=color:#bbb>
</span></span></span></code></pre></div><p>If the EBS volume is partitioned, you can supply the optional field <code>partition: "&lt;partition number>"</code> to specify which partition to mount on.</p><h4 id=aws-ebs-csi-migration>AWS EBS CSI migration</h4><div style=margin-top:10px;margin-bottom:10px><b>FEATURE STATE:</b> <code>Kubernetes v1.25 [stable]</code></div><p>The <code>CSIMigration</code> feature for <code>awsElasticBlockStore</code>, when enabled, redirects
all plugin operations from the existing in-tree plugin to the <code>ebs.csi.aws.com</code> Container
Storage Interface (CSI) driver. In order to use this feature, the <a href=https://github.com/kubernetes-sigs/aws-ebs-csi-driver>AWS EBS CSI
driver</a>
must be installed on the cluster.</p><h4 id=aws-ebs-csi-migration-complete>AWS EBS CSI migration complete</h4><div style=margin-top:10px;margin-bottom:10px><b>FEATURE STATE:</b> <code>Kubernetes v1.17 [alpha]</code></div><p>To disable the <code>awsElasticBlockStore</code> storage plugin from being loaded by the controller manager
and the kubelet, set the <code>InTreePluginAWSUnregister</code> flag to <code>true</code>.</p><h3 id=azuredisk>azureDisk (deprecated)</h3><div style=margin-top:10px;margin-bottom:10px><b>FEATURE STATE:</b> <code>Kubernetes v1.19 [deprecated]</code></div><p>The <code>azureDisk</code> volume type mounts a Microsoft Azure <a href=https://docs.microsoft.com/en-us/azure/aks/csi-storage-drivers>Data Disk</a> into a pod.</p><p>For more details, see the <a href=https://github.com/kubernetes/examples/tree/master/staging/volumes/azure_disk/README.md><code>azureDisk</code> volume plugin</a>.</p><h4 id=azuredisk-csi-migration>azureDisk CSI migration</h4><div style=margin-top:10px;margin-bottom:10px><b>FEATURE STATE:</b> <code>Kubernetes v1.24 [stable]</code></div><p>The <code>CSIMigration</code> feature for <code>azureDisk</code>, when enabled, redirects all plugin operations
from the existing in-tree plugin to the <code>disk.csi.azure.com</code> Container
Storage Interface (CSI) Driver. In order to use this feature, the
<a href=https://github.com/kubernetes-sigs/azuredisk-csi-driver>Azure Disk CSI Driver</a>
must be installed on the cluster.</p><h4 id=azuredisk-csi-migration-complete>azureDisk CSI migration complete</h4><div style=margin-top:10px;margin-bottom:10px><b>FEATURE STATE:</b> <code>Kubernetes v1.21 [alpha]</code></div><p>To disable the <code>azureDisk</code> storage plugin from being loaded by the controller manager
and the kubelet, set the <code>InTreePluginAzureDiskUnregister</code> flag to <code>true</code>.</p><h3 id=azurefile>azureFile (deprecated)</h3><div style=margin-top:10px;margin-bottom:10px><b>FEATURE STATE:</b> <code>Kubernetes v1.21 [deprecated]</code></div><p>The <code>azureFile</code> volume type mounts a Microsoft Azure File volume (SMB 2.1 and 3.0)
into a pod.</p><p>For more details, see the <a href=https://github.com/kubernetes/examples/tree/master/staging/volumes/azure_file/README.md><code>azureFile</code> volume plugin</a>.</p><h4 id=azurefile-csi-migration>azureFile CSI migration</h4><div style=margin-top:10px;margin-bottom:10px><b>FEATURE STATE:</b> <code>Kubernetes v1.21 [beta]</code></div><p>The <code>CSIMigration</code> feature for <code>azureFile</code>, when enabled, redirects all plugin operations
from the existing in-tree plugin to the <code>file.csi.azure.com</code> Container
Storage Interface (CSI) Driver. In order to use this feature, the <a href=https://github.com/kubernetes-sigs/azurefile-csi-driver>Azure File CSI
Driver</a>
must be installed on the cluster and the <code>CSIMigrationAzureFile</code>
<a href=/docs/reference/command-line-tools-reference/feature-gates/>feature gates</a> must be enabled.</p><p>Azure File CSI driver does not support using same volume with different fsgroups. If
<code>CSIMigrationAzureFile</code> is enabled, using same volume with different fsgroups won't be supported at all.</p><h4 id=azurefile-csi-migration-complete>azureFile CSI migration complete</h4><div style=margin-top:10px;margin-bottom:10px><b>FEATURE STATE:</b> <code>Kubernetes v1.21 [alpha]</code></div><p>To disable the <code>azureFile</code> storage plugin from being loaded by the controller manager
and the kubelet, set the <code>InTreePluginAzureFileUnregister</code> flag to <code>true</code>.</p><h3 id=cephfs>cephfs</h3><p>A <code>cephfs</code> volume allows an existing CephFS volume to be
mounted into your Pod. Unlike <code>emptyDir</code>, which is erased when a pod is
removed, the contents of a <code>cephfs</code> volume are preserved and the volume is merely
unmounted. This means that a <code>cephfs</code> volume can be pre-populated with data, and
that data can be shared between pods. The <code>cephfs</code> volume can be mounted by multiple
writers simultaneously.</p><div class="alert alert-info note callout" role=alert><strong>Note:</strong> You must have your own Ceph server running with the share exported before you can use it.</div><p>See the <a href=https://github.com/kubernetes/examples/tree/master/volumes/cephfs/>CephFS example</a> for more details.</p><h3 id=cinder>cinder (deprecated)</h3><div style=margin-top:10px;margin-bottom:10px><b>FEATURE STATE:</b> <code>Kubernetes v1.18 [deprecated]</code></div><div class="alert alert-info note callout" role=alert><strong>Note:</strong> Kubernetes must be configured with the OpenStack cloud provider.</div><p>The <code>cinder</code> volume type is used to mount the OpenStack Cinder volume into your pod.</p><h4 id=cinder-volume-configuration-example>Cinder volume configuration example</h4><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>test-cinder<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>registry.k8s.io/test-webserver<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>test-cinder-container<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>volumeMounts</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:green;font-weight:700>mountPath</span>:<span style=color:#bbb> </span>/test-cinder<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>test-volume<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>volumes</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>test-volume<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:#080;font-style:italic># This OpenStack volume must already exist.</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>cinder</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>volumeID</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;&lt;volume id&gt;&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>fsType</span>:<span style=color:#bbb> </span>ext4<span style=color:#bbb>
</span></span></span></code></pre></div><h4 id=openstack-csi-migration>OpenStack CSI migration</h4><div style=margin-top:10px;margin-bottom:10px><b>FEATURE STATE:</b> <code>Kubernetes v1.24 [stable]</code></div><p>The <code>CSIMigration</code> feature for Cinder is enabled by default since Kubernetes 1.21.
It redirects all plugin operations from the existing in-tree plugin to the
<code>cinder.csi.openstack.org</code> Container Storage Interface (CSI) Driver.
<a href=https://github.com/kubernetes/cloud-provider-openstack/blob/master/docs/cinder-csi-plugin/using-cinder-csi-plugin.md>OpenStack Cinder CSI Driver</a>
must be installed on the cluster.</p><p>To disable the in-tree Cinder plugin from being loaded by the controller manager
and the kubelet, you can enable the <code>InTreePluginOpenStackUnregister</code>
<a href=/docs/reference/command-line-tools-reference/feature-gates/>feature gate</a>.</p><h3 id=configmap>configMap</h3><p>A <a href=/docs/tasks/configure-pod-container/configure-pod-configmap/>ConfigMap</a>
provides a way to inject configuration data into pods.
The data stored in a ConfigMap can be referenced in a volume of type
<code>configMap</code> and then consumed by containerized applications running in a pod.</p><p>When referencing a ConfigMap, you provide the name of the ConfigMap in the
volume. You can customize the path to use for a specific
entry in the ConfigMap. The following configuration shows how to mount
the <code>log-config</code> ConfigMap onto a Pod called <code>configmap-pod</code>:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>configmap-pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>test<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>busybox:1.28<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>volumeMounts</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>config-vol<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>mountPath</span>:<span style=color:#bbb> </span>/etc/config<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>volumes</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>config-vol<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>configMap</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>log-config<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>items</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span>- <span style=color:green;font-weight:700>key</span>:<span style=color:#bbb> </span>log_level<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>            </span><span style=color:green;font-weight:700>path</span>:<span style=color:#bbb> </span>log_level<span style=color:#bbb>
</span></span></span></code></pre></div><p>The <code>log-config</code> ConfigMap is mounted as a volume, and all contents stored in
its <code>log_level</code> entry are mounted into the Pod at path <code>/etc/config/log_level</code>.
Note that this path is derived from the volume's <code>mountPath</code> and the <code>path</code>
keyed with <code>log_level</code>.</p><div class="alert alert-info note callout" role=alert><strong>Note:</strong><ul><li><p>You must create a <a href=/docs/tasks/configure-pod-container/configure-pod-configmap/>ConfigMap</a>
before you can use it.</p></li><li><p>A container using a ConfigMap as a <a href=#using-subpath><code>subPath</code></a> volume mount will not
receive ConfigMap updates.</p></li><li><p>Text data is exposed as files using the UTF-8 character encoding. For other character encodings, use <code>binaryData</code>.</p></li></ul></div><h3 id=downwardapi>downwardAPI</h3><p>A <code>downwardAPI</code> volume makes <a class=glossary-tooltip title='A mechanism to expose Pod and container field values to code running in a container.' data-toggle=tooltip data-placement=top href=/docs/concepts/workloads/pods/downward-api/ target=_blank aria-label='downward API'>downward API</a>
data available to applications. Within the volume, you can find the exposed
data as read-only files in plain text format.</p><div class="alert alert-info note callout" role=alert><strong>Note:</strong> A container using the downward API as a <a href=#using-subpath><code>subPath</code></a> volume mount does not
receive updates when field values change.</div><p>See <a href=/docs/tasks/inject-data-application/downward-api-volume-expose-pod-information/>Expose Pod Information to Containers Through Files</a>
to learn more.</p><h3 id=emptydir>emptyDir</h3><p>An <code>emptyDir</code> volume is first created when a Pod is assigned to a node, and
exists as long as that Pod is running on that node. As the name says, the
<code>emptyDir</code> volume is initially empty. All containers in the Pod can read and write the same
files in the <code>emptyDir</code> volume, though that volume can be mounted at the same
or different paths in each container. When a Pod is removed from a node for
any reason, the data in the <code>emptyDir</code> is deleted permanently.</p><div class="alert alert-info note callout" role=alert><strong>Note:</strong> A container crashing does <em>not</em> remove a Pod from a node. The data in an <code>emptyDir</code> volume
is safe across container crashes.</div><p>Some uses for an <code>emptyDir</code> are:</p><ul><li>scratch space, such as for a disk-based merge sort</li><li>checkpointing a long computation for recovery from crashes</li><li>holding files that a content-manager container fetches while a webserver
container serves the data</li></ul><p>The <code>emptyDir.medium</code> field controls where <code>emptyDir</code> volumes are stored. By
default <code>emptyDir</code> volumes are stored on whatever medium that backs the node
such as disk, SSD, or network storage, depending on your environment. If you set
the <code>emptyDir.medium</code> field to <code>"Memory"</code>, Kubernetes mounts a tmpfs (RAM-backed
filesystem) for you instead. While tmpfs is very fast, be aware that unlike
disks, tmpfs is cleared on node reboot and any files you write count against
your container's memory limit.</p><p>A size limit can be specified for the default medium, which limits the capacity
of the <code>emptyDir</code> volume. The storage is allocated from <a href=/docs/concepts/configuration/manage-resources-containers/#setting-requests-and-limits-for-local-ephemeral-storage>node ephemeral
storage</a>.
If that is filled up from another source (for example, log files or image
overlays), the <code>emptyDir</code> may run out of capacity before this limit.</p><div class="alert alert-info note callout" role=alert><strong>Note:</strong> If the <code>SizeMemoryBackedVolumes</code> <a href=/docs/reference/command-line-tools-reference/feature-gates/>feature gate</a> is enabled,
you can specify a size for memory backed volumes. If no size is specified, memory
backed volumes are sized to 50% of the memory on a Linux host.</div><h4 id=emptydir-configuration-example>emptyDir configuration example</h4><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>test-pd<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>registry.k8s.io/test-webserver<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>test-container<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>volumeMounts</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:green;font-weight:700>mountPath</span>:<span style=color:#bbb> </span>/cache<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>cache-volume<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>volumes</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>cache-volume<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>emptyDir</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>sizeLimit</span>:<span style=color:#bbb> </span>500Mi<span style=color:#bbb>
</span></span></span></code></pre></div><h3 id=fc>fc (fibre channel)</h3><p>An <code>fc</code> volume type allows an existing fibre channel block storage volume
to mount in a Pod. You can specify single or multiple target world wide names (WWNs)
using the parameter <code>targetWWNs</code> in your Volume configuration. If multiple WWNs are specified,
targetWWNs expect that those WWNs are from multi-path connections.</p><div class="alert alert-info note callout" role=alert><strong>Note:</strong> You must configure FC SAN Zoning to allocate and mask those LUNs (volumes) to the target WWNs
beforehand so that Kubernetes hosts can access them.</div><p>See the <a href=https://github.com/kubernetes/examples/tree/master/staging/volumes/fibre_channel>fibre channel example</a> for more details.</p><h3 id=gcepersistentdisk>gcePersistentDisk (deprecated)</h3><div style=margin-top:10px;margin-bottom:10px><b>FEATURE STATE:</b> <code>Kubernetes v1.17 [deprecated]</code></div><p>A <code>gcePersistentDisk</code> volume mounts a Google Compute Engine (GCE)
<a href=https://cloud.google.com/compute/docs/disks>persistent disk</a> (PD) into your Pod.
Unlike <code>emptyDir</code>, which is erased when a pod is removed, the contents of a PD are
preserved and the volume is merely unmounted. This means that a PD can be
pre-populated with data, and that data can be shared between pods.</p><div class="alert alert-info note callout" role=alert><strong>Note:</strong> You must create a PD using <code>gcloud</code> or the GCE API or UI before you can use it.</div><p>There are some restrictions when using a <code>gcePersistentDisk</code>:</p><ul><li>the nodes on which Pods are running must be GCE VMs</li><li>those VMs need to be in the same GCE project and zone as the persistent disk</li></ul><p>One feature of GCE persistent disk is concurrent read-only access to a persistent disk.
A <code>gcePersistentDisk</code> volume permits multiple consumers to simultaneously
mount a persistent disk as read-only. This means that you can pre-populate a PD with your dataset
and then serve it in parallel from as many Pods as you need. Unfortunately,
PDs can only be mounted by a single consumer in read-write mode. Simultaneous
writers are not allowed.</p><p>Using a GCE persistent disk with a Pod controlled by a ReplicaSet will fail unless
the PD is read-only or the replica count is 0 or 1.</p><h4 id=gce-create-persistent-disk>Creating a GCE persistent disk</h4><p>Before you can use a GCE persistent disk with a Pod, you need to create it.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>gcloud compute disks create --size<span style=color:#666>=</span>500GB --zone<span style=color:#666>=</span>us-central1-a my-data-disk
</span></span></code></pre></div><h4 id=gce-persistent-disk-configuration-example>GCE persistent disk configuration example</h4><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>test-pd<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>registry.k8s.io/test-webserver<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>test-container<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>volumeMounts</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:green;font-weight:700>mountPath</span>:<span style=color:#bbb> </span>/test-pd<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>test-volume<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>volumes</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>test-volume<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:#080;font-style:italic># This GCE PD must already exist.</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>gcePersistentDisk</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>pdName</span>:<span style=color:#bbb> </span>my-data-disk<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>fsType</span>:<span style=color:#bbb> </span>ext4<span style=color:#bbb>
</span></span></span></code></pre></div><h4 id=regional-persistent-disks>Regional persistent disks</h4><p>The <a href=https://cloud.google.com/compute/docs/disks/#repds>Regional persistent disks</a>
feature allows the creation of persistent disks that are available in two zones
within the same region. In order to use this feature, the volume must be provisioned
as a PersistentVolume; referencing the volume directly from a pod is not supported.</p><h4 id=manually-provisioning-a-regional-pd-persistentvolume>Manually provisioning a Regional PD PersistentVolume</h4><p>Dynamic provisioning is possible using a
<a href=/docs/concepts/storage/storage-classes/#gce-pd>StorageClass for GCE PD</a>.
Before creating a PersistentVolume, you must create the persistent disk:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>gcloud compute disks create --size<span style=color:#666>=</span>500GB my-data-disk
</span></span><span style=display:flex><span>  --region us-central1
</span></span><span style=display:flex><span>  --replica-zones us-central1-a,us-central1-b
</span></span></code></pre></div><h4 id=regional-persistent-disk-configuration-example>Regional persistent disk configuration example</h4><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>PersistentVolume<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>test-volume<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>capacity</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>storage</span>:<span style=color:#bbb> </span>400Gi<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>accessModes</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- ReadWriteOnce<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>gcePersistentDisk</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>pdName</span>:<span style=color:#bbb> </span>my-data-disk<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>fsType</span>:<span style=color:#bbb> </span>ext4<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>nodeAffinity</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>required</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>nodeSelectorTerms</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- <span style=color:green;font-weight:700>matchExpressions</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:#080;font-style:italic># failure-domain.beta.kubernetes.io/zone should be used prior to 1.21</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span>- <span style=color:green;font-weight:700>key</span>:<span style=color:#bbb> </span>topology.kubernetes.io/zone<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>operator</span>:<span style=color:#bbb> </span>In<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>values</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span>- us-central1-a<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span>- us-central1-b<span style=color:#bbb>
</span></span></span></code></pre></div><h4 id=gce-csi-migration>GCE CSI migration</h4><div style=margin-top:10px;margin-bottom:10px><b>FEATURE STATE:</b> <code>Kubernetes v1.25 [stable]</code></div><p>The <code>CSIMigration</code> feature for GCE PD, when enabled, redirects all plugin operations
from the existing in-tree plugin to the <code>pd.csi.storage.gke.io</code> Container
Storage Interface (CSI) Driver. In order to use this feature, the <a href=https://github.com/kubernetes-sigs/gcp-compute-persistent-disk-csi-driver>GCE PD CSI
Driver</a>
must be installed on the cluster.</p><h4 id=gce-csi-migration-complete>GCE CSI migration complete</h4><div style=margin-top:10px;margin-bottom:10px><b>FEATURE STATE:</b> <code>Kubernetes v1.21 [alpha]</code></div><p>To disable the <code>gcePersistentDisk</code> storage plugin from being loaded by the controller manager
and the kubelet, set the <code>InTreePluginGCEUnregister</code> flag to <code>true</code>.</p><h3 id=gitrepo>gitRepo (deprecated)</h3><div class="alert alert-danger warning callout" role=alert><strong>Warning:</strong> The <code>gitRepo</code> volume type is deprecated. To provision a container with a git repo, mount an <a href=#emptydir>EmptyDir</a> into an InitContainer that clones the repo using git, then mount the <a href=#emptydir>EmptyDir</a> into the Pod's container.</div><p>A <code>gitRepo</code> volume is an example of a volume plugin. This plugin
mounts an empty directory and clones a git repository into this directory
for your Pod to use.</p><p>Here is an example of a <code>gitRepo</code> volume:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>server<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>nginx<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>nginx<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>volumeMounts</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:green;font-weight:700>mountPath</span>:<span style=color:#bbb> </span>/mypath<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>git-volume<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>volumes</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>git-volume<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>gitRepo</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>repository</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;git@somewhere:me/my-git-repository.git&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>revision</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;22f1d8406d464b0c0874075539c1f2e96c253775&#34;</span><span style=color:#bbb>
</span></span></span></code></pre></div><h3 id=glusterfs>glusterfs (deprecated)</h3><div style=margin-top:10px;margin-bottom:10px><b>FEATURE STATE:</b> <code>Kubernetes v1.25 [deprecated]</code></div><p>A <code>glusterfs</code> volume allows a <a href=https://www.gluster.org>Glusterfs</a> (an open
source networked filesystem) volume to be mounted into your Pod. Unlike
<code>emptyDir</code>, which is erased when a Pod is removed, the contents of a
<code>glusterfs</code> volume are preserved and the volume is merely unmounted. This
means that a <code>glusterfs</code> volume can be pre-populated with data, and that data can
be shared between pods. GlusterFS can be mounted by multiple writers
simultaneously.</p><div class="alert alert-info note callout" role=alert><strong>Note:</strong> You must have your own GlusterFS installation running before you can use it.</div><p>See the <a href=https://github.com/kubernetes/examples/tree/master/volumes/glusterfs>GlusterFS example</a> for more details.</p><h3 id=hostpath>hostPath</h3><div class="alert alert-danger warning callout" role=alert><strong>Warning:</strong><p>HostPath volumes present many security risks, and it is a best practice to avoid the use of
HostPaths when possible. When a HostPath volume must be used, it should be scoped to only the
required file or directory, and mounted as ReadOnly.</p><p>If restricting HostPath access to specific directories through AdmissionPolicy, <code>volumeMounts</code> MUST
be required to use <code>readOnly</code> mounts for the policy to be effective.</p></div><p>A <code>hostPath</code> volume mounts a file or directory from the host node's filesystem
into your Pod. This is not something that most Pods will need, but it offers a
powerful escape hatch for some applications.</p><p>For example, some uses for a <code>hostPath</code> are:</p><ul><li>running a container that needs access to Docker internals; use a <code>hostPath</code>
of <code>/var/lib/docker</code></li><li>running cAdvisor in a container; use a <code>hostPath</code> of <code>/sys</code></li><li>allowing a Pod to specify whether a given <code>hostPath</code> should exist prior to the
Pod running, whether it should be created, and what it should exist as</li></ul><p>In addition to the required <code>path</code> property, you can optionally specify a <code>type</code> for a <code>hostPath</code> volume.</p><p>The supported values for field <code>type</code> are:</p><table><thead><tr><th style=text-align:left>Value</th><th style=text-align:left>Behavior</th></tr></thead><tbody><tr><td style=text-align:left></td><td style=text-align:left>Empty string (default) is for backward compatibility, which means that no checks will be performed before mounting the hostPath volume.</td></tr><tr><td style=text-align:left><code>DirectoryOrCreate</code></td><td style=text-align:left>If nothing exists at the given path, an empty directory will be created there as needed with permission set to 0755, having the same group and ownership with Kubelet.</td></tr><tr><td style=text-align:left><code>Directory</code></td><td style=text-align:left>A directory must exist at the given path</td></tr><tr><td style=text-align:left><code>FileOrCreate</code></td><td style=text-align:left>If nothing exists at the given path, an empty file will be created there as needed with permission set to 0644, having the same group and ownership with Kubelet.</td></tr><tr><td style=text-align:left><code>File</code></td><td style=text-align:left>A file must exist at the given path</td></tr><tr><td style=text-align:left><code>Socket</code></td><td style=text-align:left>A UNIX socket must exist at the given path</td></tr><tr><td style=text-align:left><code>CharDevice</code></td><td style=text-align:left>A character device must exist at the given path</td></tr><tr><td style=text-align:left><code>BlockDevice</code></td><td style=text-align:left>A block device must exist at the given path</td></tr></tbody></table><p>Watch out when using this type of volume, because:</p><ul><li>HostPaths can expose privileged system credentials (such as for the Kubelet) or privileged APIs
(such as container runtime socket), which can be used for container escape or to attack other
parts of the cluster.</li><li>Pods with identical configuration (such as created from a PodTemplate) may
behave differently on different nodes due to different files on the nodes</li><li>The files or directories created on the underlying hosts are only writable by root. You
either need to run your process as root in a
<a href=/docs/tasks/configure-pod-container/security-context/>privileged Container</a> or modify the file
permissions on the host to be able to write to a <code>hostPath</code> volume</li></ul><h4 id=hostpath-configuration-example>hostPath configuration example</h4><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>test-pd<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>registry.k8s.io/test-webserver<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>test-container<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>volumeMounts</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:green;font-weight:700>mountPath</span>:<span style=color:#bbb> </span>/test-pd<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>test-volume<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>volumes</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>test-volume<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>hostPath</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:#080;font-style:italic># directory location on host</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>path</span>:<span style=color:#bbb> </span>/data<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:#080;font-style:italic># this field is optional</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>type</span>:<span style=color:#bbb> </span>Directory<span style=color:#bbb>
</span></span></span></code></pre></div><div class="alert alert-warning caution callout" role=alert><strong>Caution:</strong> The <code>FileOrCreate</code> mode does not create the parent directory of the file. If the parent directory
of the mounted file does not exist, the pod fails to start. To ensure that this mode works,
you can try to mount directories and files separately, as shown in the
<a href=#hostpath-fileorcreate-example><code>FileOrCreate</code>configuration</a>.</div><h4 id=hostpath-fileorcreate-example>hostPath FileOrCreate configuration example</h4><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>test-webserver<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>test-webserver<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>registry.k8s.io/test-webserver:latest<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>volumeMounts</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:green;font-weight:700>mountPath</span>:<span style=color:#bbb> </span>/var/local/aaa<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>mydir<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:green;font-weight:700>mountPath</span>:<span style=color:#bbb> </span>/var/local/aaa/1.txt<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>myfile<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>volumes</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>mydir<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>hostPath</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:#080;font-style:italic># Ensure the file directory is created.</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>path</span>:<span style=color:#bbb> </span>/var/local/aaa<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>type</span>:<span style=color:#bbb> </span>DirectoryOrCreate<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>myfile<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>hostPath</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>path</span>:<span style=color:#bbb> </span>/var/local/aaa/1.txt<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>type</span>:<span style=color:#bbb> </span>FileOrCreate<span style=color:#bbb>
</span></span></span></code></pre></div><h3 id=iscsi>iscsi</h3><p>An <code>iscsi</code> volume allows an existing iSCSI (SCSI over IP) volume to be mounted
into your Pod. Unlike <code>emptyDir</code>, which is erased when a Pod is removed, the
contents of an <code>iscsi</code> volume are preserved and the volume is merely
unmounted. This means that an iscsi volume can be pre-populated with data, and
that data can be shared between pods.</p><div class="alert alert-info note callout" role=alert><strong>Note:</strong> You must have your own iSCSI server running with the volume created before you can use it.</div><p>A feature of iSCSI is that it can be mounted as read-only by multiple consumers
simultaneously. This means that you can pre-populate a volume with your dataset
and then serve it in parallel from as many Pods as you need. Unfortunately,
iSCSI volumes can only be mounted by a single consumer in read-write mode.
Simultaneous writers are not allowed.</p><p>See the <a href=https://github.com/kubernetes/examples/tree/master/volumes/iscsi>iSCSI example</a> for more details.</p><h3 id=local>local</h3><p>A <code>local</code> volume represents a mounted local storage device such as a disk,
partition or directory.</p><p>Local volumes can only be used as a statically created PersistentVolume. Dynamic
provisioning is not supported.</p><p>Compared to <code>hostPath</code> volumes, <code>local</code> volumes are used in a durable and
portable manner without manually scheduling pods to nodes. The system is aware
of the volume's node constraints by looking at the node affinity on the PersistentVolume.</p><p>However, <code>local</code> volumes are subject to the availability of the underlying
node and are not suitable for all applications. If a node becomes unhealthy,
then the <code>local</code> volume becomes inaccessible by the pod. The pod using this volume
is unable to run. Applications using <code>local</code> volumes must be able to tolerate this
reduced availability, as well as potential data loss, depending on the
durability characteristics of the underlying disk.</p><p>The following example shows a PersistentVolume using a <code>local</code> volume and
<code>nodeAffinity</code>:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>PersistentVolume<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>example-pv<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>capacity</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>storage</span>:<span style=color:#bbb> </span>100Gi<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>volumeMode</span>:<span style=color:#bbb> </span>Filesystem<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>accessModes</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- ReadWriteOnce<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>persistentVolumeReclaimPolicy</span>:<span style=color:#bbb> </span>Delete<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>storageClassName</span>:<span style=color:#bbb> </span>local-storage<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>local</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>path</span>:<span style=color:#bbb> </span>/mnt/disks/ssd1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>nodeAffinity</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>required</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>nodeSelectorTerms</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- <span style=color:green;font-weight:700>matchExpressions</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span>- <span style=color:green;font-weight:700>key</span>:<span style=color:#bbb> </span>kubernetes.io/hostname<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>operator</span>:<span style=color:#bbb> </span>In<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>values</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span>- example-node<span style=color:#bbb>
</span></span></span></code></pre></div><p>You must set a PersistentVolume <code>nodeAffinity</code> when using <code>local</code> volumes.
The Kubernetes scheduler uses the PersistentVolume <code>nodeAffinity</code> to schedule
these Pods to the correct node.</p><p>PersistentVolume <code>volumeMode</code> can be set to "Block" (instead of the default
value "Filesystem") to expose the local volume as a raw block device.</p><p>When using local volumes, it is recommended to create a StorageClass with
<code>volumeBindingMode</code> set to <code>WaitForFirstConsumer</code>. For more details, see the
local <a href=/docs/concepts/storage/storage-classes/#local>StorageClass</a> example.
Delaying volume binding ensures that the PersistentVolumeClaim binding decision
will also be evaluated with any other node constraints the Pod may have,
such as node resource requirements, node selectors, Pod affinity, and Pod anti-affinity.</p><p>An external static provisioner can be run separately for improved management of
the local volume lifecycle. Note that this provisioner does not support dynamic
provisioning yet. For an example on how to run an external local provisioner,
see the <a href=https://github.com/kubernetes-sigs/sig-storage-local-static-provisioner>local volume provisioner user
guide</a>.</p><div class="alert alert-info note callout" role=alert><strong>Note:</strong> The local PersistentVolume requires manual cleanup and deletion by the
user if the external static provisioner is not used to manage the volume
lifecycle.</div><h3 id=nfs>nfs</h3><p>An <code>nfs</code> volume allows an existing NFS (Network File System) share to be
mounted into a Pod. Unlike <code>emptyDir</code>, which is erased when a Pod is
removed, the contents of an <code>nfs</code> volume are preserved and the volume is merely
unmounted. This means that an NFS volume can be pre-populated with data, and
that data can be shared between pods. NFS can be mounted by multiple
writers simultaneously.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>test-pd<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>registry.k8s.io/test-webserver<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>test-container<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>volumeMounts</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:green;font-weight:700>mountPath</span>:<span style=color:#bbb> </span>/my-nfs-data<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>test-volume<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>volumes</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>test-volume<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>nfs</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>server</span>:<span style=color:#bbb> </span>my-nfs-server.example.com<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>path</span>:<span style=color:#bbb> </span>/my-nfs-volume<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>readOnly</span>:<span style=color:#bbb> </span><span style=color:#a2f;font-weight:700>true</span><span style=color:#bbb>
</span></span></span></code></pre></div><div class="alert alert-info note callout" role=alert><strong>Note:</strong><p>You must have your own NFS server running with the share exported before you can use it.</p><p>Also note that you can't specify NFS mount options in a Pod spec. You can either set mount options server-side or use <a href=https://man7.org/linux/man-pages/man5/nfsmount.conf.5.html>/etc/nfsmount.conf</a>. You can also mount NFS volumes via PersistentVolumes which do allow you to set mount options.</p></div><p>See the <a href=https://github.com/kubernetes/examples/tree/master/staging/volumes/nfs>NFS example</a> for an example of mounting NFS volumes with PersistentVolumes.</p><h3 id=persistentvolumeclaim>persistentVolumeClaim</h3><p>A <code>persistentVolumeClaim</code> volume is used to mount a
<a href=/docs/concepts/storage/persistent-volumes/>PersistentVolume</a> into a Pod. PersistentVolumeClaims
are a way for users to "claim" durable storage (such as a GCE PersistentDisk or an
iSCSI volume) without knowing the details of the particular cloud environment.</p><p>See the information about <a href=/docs/concepts/storage/persistent-volumes/>PersistentVolumes</a> for more
details.</p><h3 id=portworxvolume>portworxVolume (deprecated)</h3><div style=margin-top:10px;margin-bottom:10px><b>FEATURE STATE:</b> <code>Kubernetes v1.25 [deprecated]</code></div><p>A <code>portworxVolume</code> is an elastic block storage layer that runs hyperconverged with
Kubernetes. <a href=https://portworx.com/use-case/kubernetes-storage/>Portworx</a> fingerprints storage
in a server, tiers based on capabilities, and aggregates capacity across multiple servers.
Portworx runs in-guest in virtual machines or on bare metal Linux nodes.</p><p>A <code>portworxVolume</code> can be dynamically created through Kubernetes or it can also
be pre-provisioned and referenced inside a Pod.
Here is an example Pod referencing a pre-provisioned Portworx volume:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>test-portworx-volume-pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>registry.k8s.io/test-webserver<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>test-container<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>volumeMounts</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:green;font-weight:700>mountPath</span>:<span style=color:#bbb> </span>/mnt<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>pxvol<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>volumes</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>pxvol<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:#080;font-style:italic># This Portworx volume must already exist.</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>portworxVolume</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>volumeID</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;pxvol&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>fsType</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;&lt;fs-type&gt;&#34;</span><span style=color:#bbb>
</span></span></span></code></pre></div><div class="alert alert-info note callout" role=alert><strong>Note:</strong> Make sure you have an existing PortworxVolume with name <code>pxvol</code>
before using it in the Pod.</div><p>For more details, see the <a href=https://github.com/kubernetes/examples/tree/master/staging/volumes/portworx/README.md>Portworx volume</a> examples.</p><h4 id=portworx-csi-migration>Portworx CSI migration</h4><div style=margin-top:10px;margin-bottom:10px><b>FEATURE STATE:</b> <code>Kubernetes v1.25 [beta]</code></div><p>The <code>CSIMigration</code> feature for Portworx has been added but disabled by default in Kubernetes 1.23 since it's in alpha state.
It has been beta now since v1.25 but it is still turned off by default.
It redirects all plugin operations from the existing in-tree plugin to the
<code>pxd.portworx.com</code> Container Storage Interface (CSI) Driver.
<a href=https://docs.portworx.com/portworx-install-with-kubernetes/storage-operations/csi/>Portworx CSI Driver</a>
must be installed on the cluster.
To enable the feature, set <code>CSIMigrationPortworx=true</code> in kube-controller-manager and kubelet.</p><h3 id=projected>projected</h3><p>A projected volume maps several existing volume sources into the same
directory. For more details, see <a href=/docs/concepts/storage/projected-volumes/>projected volumes</a>.</p><h3 id=rbd>rbd</h3><p>An <code>rbd</code> volume allows a
<a href=https://docs.ceph.com/en/latest/rbd/>Rados Block Device</a> (RBD) volume to mount
into your Pod. Unlike <code>emptyDir</code>, which is erased when a pod is removed, the
contents of an <code>rbd</code> volume are preserved and the volume is unmounted. This
means that a RBD volume can be pre-populated with data, and that data can be
shared between pods.</p><div class="alert alert-info note callout" role=alert><strong>Note:</strong> You must have a Ceph installation running before you can use RBD.</div><p>A feature of RBD is that it can be mounted as read-only by multiple consumers
simultaneously. This means that you can pre-populate a volume with your dataset
and then serve it in parallel from as many pods as you need. Unfortunately,
RBD volumes can only be mounted by a single consumer in read-write mode.
Simultaneous writers are not allowed.</p><p>See the <a href=https://github.com/kubernetes/examples/tree/master/volumes/rbd>RBD example</a>
for more details.</p><h4 id=rbd-csi-migration>RBD CSI migration</h4><div style=margin-top:10px;margin-bottom:10px><b>FEATURE STATE:</b> <code>Kubernetes v1.23 [alpha]</code></div><p>The <code>CSIMigration</code> feature for <code>RBD</code>, when enabled, redirects all plugin
operations from the existing in-tree plugin to the <code>rbd.csi.ceph.com</code> <a class=glossary-tooltip title='The Container Storage Interface (CSI) defines a standard interface to expose storage systems to containers.' data-toggle=tooltip data-placement=top href=/docs/concepts/storage/volumes/#csi target=_blank aria-label=CSI>CSI</a> driver. In order to use this
feature, the
<a href=https://github.com/ceph/ceph-csi>Ceph CSI driver</a>
must be installed on the cluster and the <code>CSIMigrationRBD</code>
<a href=/docs/reference/command-line-tools-reference/feature-gates/>feature gate</a>
must be enabled. (Note that the <code>csiMigrationRBD</code> flag has been removed and
replaced with <code>CSIMigrationRBD</code> in release v1.24)</p><div class="alert alert-info note callout" role=alert><strong>Note:</strong><p>As a Kubernetes cluster operator that administers storage, here are the
prerequisites that you must complete before you attempt migration to the
RBD CSI driver:</p><ul><li>You must install the Ceph CSI driver (<code>rbd.csi.ceph.com</code>), v3.5.0 or above,
into your Kubernetes cluster.</li><li>considering the <code>clusterID</code> field is a required parameter for CSI driver for
its operations, but in-tree StorageClass has <code>monitors</code> field as a required
parameter, a Kubernetes storage admin has to create a clusterID based on the
monitors hash ( ex:<code>#echo -n '&lt;monitors_string>' | md5sum</code>) in the CSI config map and keep the monitors
under this clusterID configuration.</li><li>Also, if the value of <code>adminId</code> in the in-tree Storageclass is different from
<code>admin</code>, the <code>adminSecretName</code> mentioned in the in-tree Storageclass has to be
patched with the base64 value of the <code>adminId</code> parameter value, otherwise this
step can be skipped.</li></ul></div><h3 id=secret>secret</h3><p>A <code>secret</code> volume is used to pass sensitive information, such as passwords, to
Pods. You can store secrets in the Kubernetes API and mount them as files for
use by pods without coupling to Kubernetes directly. <code>secret</code> volumes are
backed by tmpfs (a RAM-backed filesystem) so they are never written to
non-volatile storage.</p><div class="alert alert-info note callout" role=alert><strong>Note:</strong> You must create a Secret in the Kubernetes API before you can use it.</div><div class="alert alert-info note callout" role=alert><strong>Note:</strong> A container using a Secret as a <a href=#using-subpath><code>subPath</code></a> volume mount will not
receive Secret updates.</div><p>For more details, see <a href=/docs/concepts/configuration/secret/>Configuring Secrets</a>.</p><h3 id=vspherevolume>vsphereVolume (deprecated)</h3><div class="alert alert-info note callout" role=alert><strong>Note:</strong> We recommend to use vSphere CSI out-of-tree driver instead.</div><p>A <code>vsphereVolume</code> is used to mount a vSphere VMDK volume into your Pod. The contents
of a volume are preserved when it is unmounted. It supports both VMFS and VSAN datastore.</p><p>For more information, see the <a href=https://github.com/kubernetes/examples/tree/master/staging/volumes/vsphere>vSphere volume</a> examples.</p><h4 id=vsphere-csi-migration>vSphere CSI migration</h4><div style=margin-top:10px;margin-bottom:10px><b>FEATURE STATE:</b> <code>Kubernetes v1.19 [beta]</code></div><p>The <code>CSIMigrationvSphere</code> feature for <code>vsphereVolume</code> is enabled by default as of Kubernetes v1.25.
All plugin operations from the in-tree <code>vspherevolume</code> will be redirected to the <code>csi.vsphere.vmware.com</code> <a class=glossary-tooltip title='The Container Storage Interface (CSI) defines a standard interface to expose storage systems to containers.' data-toggle=tooltip data-placement=top href=/docs/concepts/storage/volumes/#csi target=_blank aria-label=CSI>CSI</a> driver unless <code>CSIMigrationvSphere</code> feature gate is disabled.</p><p><a href=https://github.com/kubernetes-sigs/vsphere-csi-driver>vSphere CSI driver</a>
must be installed on the cluster. You can find additional advice on how to migrate in-tree <code>vsphereVolume</code> in VMware's documentation page
<a href=https://docs.vmware.com/en/VMware-vSphere-Container-Storage-Plug-in/2.0/vmware-vsphere-csp-getting-started/GUID-968D421F-D464-4E22-8127-6CB9FF54423F.html>Migrating In-Tree vSphere Volumes to vSphere Container Storage Plug-in</a>.</p><p>As of Kubernetes v1.25, vSphere releases less than 7.0u2 are not supported for the
(deprecated) in-tree vSphere storage driver. You must run vSphere 7.0u2 or later
in order to either continue using the deprecated driver, or to migrate to
the replacement CSI driver.</p><p>If you are running a version of Kubernetes other than v1.25, consult
the documentation for that version of Kubernetes.</p><div class="alert alert-info note callout" role=alert><strong>Note:</strong><p>The following StorageClass parameters from the built-in <code>vsphereVolume</code> plugin are not supported by the vSphere CSI driver:</p><ul><li><code>diskformat</code></li><li><code>hostfailurestotolerate</code></li><li><code>forceprovisioning</code></li><li><code>cachereservation</code></li><li><code>diskstripes</code></li><li><code>objectspacereservation</code></li><li><code>iopslimit</code></li></ul><p>Existing volumes created using these parameters will be migrated to the vSphere CSI driver,
but new volumes created by the vSphere CSI driver will not be honoring these parameters.</p></div><h4 id=vsphere-csi-migration-complete>vSphere CSI migration complete</h4><div style=margin-top:10px;margin-bottom:10px><b>FEATURE STATE:</b> <code>Kubernetes v1.19 [beta]</code></div><p>To turn off the <code>vsphereVolume</code> plugin from being loaded by the controller manager and the kubelet, you need to set <code>InTreePluginvSphereUnregister</code> feature flag to <code>true</code>. You must install a <code>csi.vsphere.vmware.com</code> <a class=glossary-tooltip title='The Container Storage Interface (CSI) defines a standard interface to expose storage systems to containers.' data-toggle=tooltip data-placement=top href=/docs/concepts/storage/volumes/#csi target=_blank aria-label=CSI>CSI</a> driver on all worker nodes.</p><h2 id=using-subpath>Using subPath</h2><p>Sometimes, it is useful to share one volume for multiple uses in a single pod.
The <code>volumeMounts.subPath</code> property specifies a sub-path inside the referenced volume
instead of its root.</p><p>The following example shows how to configure a Pod with a LAMP stack (Linux Apache MySQL PHP)
using a single, shared volume. This sample <code>subPath</code> configuration is not recommended
for production use.</p><p>The PHP application's code and assets map to the volume's <code>html</code> folder and
the MySQL database is stored in the volume's <code>mysql</code> folder. For example:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>my-lamp-site<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>mysql<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>mysql<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>env</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>MYSQL_ROOT_PASSWORD<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>value</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;rootpasswd&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>volumeMounts</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- <span style=color:green;font-weight:700>mountPath</span>:<span style=color:#bbb> </span>/var/lib/mysql<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>site-data<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>subPath</span>:<span style=color:#bbb> </span>mysql<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>php<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>php:7.0-apache<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>volumeMounts</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- <span style=color:green;font-weight:700>mountPath</span>:<span style=color:#bbb> </span>/var/www/html<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>site-data<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>subPath</span>:<span style=color:#bbb> </span>html<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>volumes</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>site-data<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>persistentVolumeClaim</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>claimName</span>:<span style=color:#bbb> </span>my-lamp-site-data<span style=color:#bbb>
</span></span></span></code></pre></div><h3 id=using-subpath-expanded-environment>Using subPath with expanded environment variables</h3><div style=margin-top:10px;margin-bottom:10px><b>FEATURE STATE:</b> <code>Kubernetes v1.17 [stable]</code></div><p>Use the <code>subPathExpr</code> field to construct <code>subPath</code> directory names from
downward API environment variables.
The <code>subPath</code> and <code>subPathExpr</code> properties are mutually exclusive.</p><p>In this example, a <code>Pod</code> uses <code>subPathExpr</code> to create a directory <code>pod1</code> within
the <code>hostPath</code> volume <code>/var/log/pods</code>.
The <code>hostPath</code> volume takes the <code>Pod</code> name from the <code>downwardAPI</code>.
The host directory <code>/var/log/pods/pod1</code> is mounted at <code>/logs</code> in the container.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>pod1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>container1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>env</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>POD_NAME<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>valueFrom</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>fieldRef</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>fieldPath</span>:<span style=color:#bbb> </span>metadata.name<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>busybox:1.28<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>command</span>:<span style=color:#bbb> </span>[<span style=color:#bbb> </span><span style=color:#b44>&#34;sh&#34;</span>,<span style=color:#bbb> </span><span style=color:#b44>&#34;-c&#34;</span>,<span style=color:#bbb> </span><span style=color:#b44>&#34;while [ true ]; do echo &#39;Hello&#39;; sleep 10; done | tee -a /logs/hello.txt&#34;</span><span style=color:#bbb> </span>]<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>volumeMounts</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>workdir1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>mountPath</span>:<span style=color:#bbb> </span>/logs<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:#080;font-style:italic># The variable expansion uses round brackets (not curly brackets).</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>subPathExpr</span>:<span style=color:#bbb> </span>$(POD_NAME)<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>restartPolicy</span>:<span style=color:#bbb> </span>Never<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>volumes</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>workdir1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>hostPath</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>path</span>:<span style=color:#bbb> </span>/var/log/pods<span style=color:#bbb>
</span></span></span></code></pre></div><h2 id=resources>Resources</h2><p>The storage media (such as Disk or SSD) of an <code>emptyDir</code> volume is determined by the
medium of the filesystem holding the kubelet root dir (typically
<code>/var/lib/kubelet</code>). There is no limit on how much space an <code>emptyDir</code> or
<code>hostPath</code> volume can consume, and no isolation between containers or between
pods.</p><p>To learn about requesting space using a resource specification, see
<a href=/docs/concepts/configuration/manage-resources-containers/>how to manage resources</a>.</p><h2 id=out-of-tree-volume-plugins>Out-of-tree volume plugins</h2><p>The out-of-tree volume plugins include
<a class=glossary-tooltip title='The Container Storage Interface (CSI) defines a standard interface to expose storage systems to containers.' data-toggle=tooltip data-placement=top href=/docs/concepts/storage/volumes/#csi target=_blank aria-label='Container Storage Interface'>Container Storage Interface</a> (CSI), and also FlexVolume (which is deprecated). These plugins enable storage vendors to create custom storage plugins
without adding their plugin source code to the Kubernetes repository.</p><p>Previously, all volume plugins were "in-tree". The "in-tree" plugins were built, linked, compiled,
and shipped with the core Kubernetes binaries. This meant that adding a new storage system to
Kubernetes (a volume plugin) required checking code into the core Kubernetes code repository.</p><p>Both CSI and FlexVolume allow volume plugins to be developed independent of
the Kubernetes code base, and deployed (installed) on Kubernetes clusters as
extensions.</p><p>For storage vendors looking to create an out-of-tree volume plugin, please refer
to the <a href=https://github.com/kubernetes/community/blob/master/sig-storage/volume-plugin-faq.md>volume plugin FAQ</a>.</p><h3 id=csi>csi</h3><p><a href=https://github.com/container-storage-interface/spec/blob/master/spec.md>Container Storage Interface</a>
(CSI) defines a standard interface for container orchestration systems (like
Kubernetes) to expose arbitrary storage systems to their container workloads.</p><p>Please read the <a href=https://git.k8s.io/design-proposals-archive/storage/container-storage-interface.md>CSI design proposal</a> for more information.</p><div class="alert alert-info note callout" role=alert><strong>Note:</strong> Support for CSI spec versions 0.2 and 0.3 are deprecated in Kubernetes
v1.13 and will be removed in a future release.</div><div class="alert alert-info note callout" role=alert><strong>Note:</strong> CSI drivers may not be compatible across all Kubernetes releases.
Please check the specific CSI driver's documentation for supported
deployments steps for each Kubernetes release and a compatibility matrix.</div><p>Once a CSI compatible volume driver is deployed on a Kubernetes cluster, users
may use the <code>csi</code> volume type to attach or mount the volumes exposed by the
CSI driver.</p><p>A <code>csi</code> volume can be used in a Pod in three different ways:</p><ul><li>through a reference to a <a href=#persistentvolumeclaim>PersistentVolumeClaim</a></li><li>with a <a href=/docs/concepts/storage/ephemeral-volumes/#generic-ephemeral-volumes>generic ephemeral volume</a></li><li>with a <a href=/docs/concepts/storage/ephemeral-volumes/#csi-ephemeral-volumes>CSI ephemeral volume</a> if the driver supports that</li></ul><p>The following fields are available to storage administrators to configure a CSI
persistent volume:</p><ul><li><code>driver</code>: A string value that specifies the name of the volume driver to use.
This value must correspond to the value returned in the <code>GetPluginInfoResponse</code>
by the CSI driver as defined in the <a href=https://github.com/container-storage-interface/spec/blob/master/spec.md#getplugininfo>CSI spec</a>.
It is used by Kubernetes to identify which CSI driver to call out to, and by
CSI driver components to identify which PV objects belong to the CSI driver.</li><li><code>volumeHandle</code>: A string value that uniquely identifies the volume. This value
must correspond to the value returned in the <code>volume.id</code> field of the
<code>CreateVolumeResponse</code> by the CSI driver as defined in the <a href=https://github.com/container-storage-interface/spec/blob/master/spec.md#createvolume>CSI spec</a>.
The value is passed as <code>volume_id</code> on all calls to the CSI volume driver when
referencing the volume.</li><li><code>readOnly</code>: An optional boolean value indicating whether the volume is to be
"ControllerPublished" (attached) as read only. Default is false. This value is
passed to the CSI driver via the <code>readonly</code> field in the
<code>ControllerPublishVolumeRequest</code>.</li><li><code>fsType</code>: If the PV's <code>VolumeMode</code> is <code>Filesystem</code> then this field may be used
to specify the filesystem that should be used to mount the volume. If the
volume has not been formatted and formatting is supported, this value will be
used to format the volume.
This value is passed to the CSI driver via the <code>VolumeCapability</code> field of
<code>ControllerPublishVolumeRequest</code>, <code>NodeStageVolumeRequest</code>, and
<code>NodePublishVolumeRequest</code>.</li><li><code>volumeAttributes</code>: A map of string to string that specifies static properties
of a volume. This map must correspond to the map returned in the
<code>volume.attributes</code> field of the <code>CreateVolumeResponse</code> by the CSI driver as
defined in the <a href=https://github.com/container-storage-interface/spec/blob/master/spec.md#createvolume>CSI spec</a>.
The map is passed to the CSI driver via the <code>volume_context</code> field in the
<code>ControllerPublishVolumeRequest</code>, <code>NodeStageVolumeRequest</code>, and
<code>NodePublishVolumeRequest</code>.</li><li><code>controllerPublishSecretRef</code>: A reference to the secret object containing
sensitive information to pass to the CSI driver to complete the CSI
<code>ControllerPublishVolume</code> and <code>ControllerUnpublishVolume</code> calls. This field is
optional, and may be empty if no secret is required. If the Secret
contains more than one secret, all secrets are passed.
<code>nodeExpandSecretRef</code>: A reference to the secret containing sensitive
information to pass to the CSI driver to complete the CSI
<code>NodeExpandVolume</code> call. This field is optional, and may be empty if no
secret is required. If the object contains more than one secret, all
secrets are passed. When you have configured secret data for node-initiated
volume expansion, the kubelet passes that data via the <code>NodeExpandVolume()</code>
call to the CSI driver. In order to use the <code>nodeExpandSecretRef</code> field, your
cluster should be running Kubernetes version 1.25 or later and you must enable
the <a href=https://kubernetes.io/docs/reference/command-line-tools-reference/feature-gates/>feature gate</a>
named <code>CSINodeExpandSecret</code> for each kube-apiserver and for the kubelet on every
node. You must also be using a CSI driver that supports or requires secret data during
node-initiated storage resize operations.</li><li><code>nodePublishSecretRef</code>: A reference to the secret object containing
sensitive information to pass to the CSI driver to complete the CSI
<code>NodePublishVolume</code> call. This field is optional, and may be empty if no
secret is required. If the secret object contains more than one secret, all
secrets are passed.</li><li><code>nodeStageSecretRef</code>: A reference to the secret object containing
sensitive information to pass to the CSI driver to complete the CSI
<code>NodeStageVolume</code> call. This field is optional, and may be empty if no secret
is required. If the Secret contains more than one secret, all secrets
are passed.</li></ul><h4 id=csi-raw-block-volume-support>CSI raw block volume support</h4><div style=margin-top:10px;margin-bottom:10px><b>FEATURE STATE:</b> <code>Kubernetes v1.18 [stable]</code></div><p>Vendors with external CSI drivers can implement raw block volume support
in Kubernetes workloads.</p><p>You can set up your
<a href=/docs/concepts/storage/persistent-volumes/#raw-block-volume-support>PersistentVolume/PersistentVolumeClaim with raw block volume support</a> as usual, without any CSI specific changes.</p><h4 id=csi-ephemeral-volumes>CSI ephemeral volumes</h4><div style=margin-top:10px;margin-bottom:10px><b>FEATURE STATE:</b> <code>Kubernetes v1.25 [stable]</code></div><p>You can directly configure CSI volumes within the Pod
specification. Volumes specified in this way are ephemeral and do not
persist across pod restarts. See <a href=/docs/concepts/storage/ephemeral-volumes/#csi-ephemeral-volumes>Ephemeral
Volumes</a>
for more information.</p><p>For more information on how to develop a CSI driver, refer to the
<a href=https://kubernetes-csi.github.io/docs/>kubernetes-csi documentation</a></p><h4 id=windows-csi-proxy>Windows CSI proxy</h4><div style=margin-top:10px;margin-bottom:10px><b>FEATURE STATE:</b> <code>Kubernetes v1.22 [stable]</code></div><p>CSI node plugins need to perform various privileged
operations like scanning of disk devices and mounting of file systems. These operations
differ for each host operating system. For Linux worker nodes, containerized CSI node
node plugins are typically deployed as privileged containers. For Windows worker nodes,
privileged operations for containerized CSI node plugins is supported using
<a href=https://github.com/kubernetes-csi/csi-proxy>csi-proxy</a>, a community-managed,
stand-alone binary that needs to be pre-installed on each Windows node.</p><p>For more details, refer to the deployment guide of the CSI plugin you wish to deploy.</p><h4 id=migrating-to-csi-drivers-from-in-tree-plugins>Migrating to CSI drivers from in-tree plugins</h4><div style=margin-top:10px;margin-bottom:10px><b>FEATURE STATE:</b> <code>Kubernetes v1.25 [stable]</code></div><p>The <code>CSIMigration</code> feature directs operations against existing in-tree
plugins to corresponding CSI plugins (which are expected to be installed and configured).
As a result, operators do not have to make any
configuration changes to existing Storage Classes, PersistentVolumes or PersistentVolumeClaims
(referring to in-tree plugins) when transitioning to a CSI driver that supersedes an in-tree plugin.</p><p>The operations and features that are supported include:
provisioning/delete, attach/detach, mount/unmount and resizing of volumes.</p><p>In-tree plugins that support <code>CSIMigration</code> and have a corresponding CSI driver implemented
are listed in <a href=#volume-types>Types of Volumes</a>.</p><p>The following in-tree plugins support persistent storage on Windows nodes:</p><ul><li><a href=#awselasticblockstore><code>awsElasticBlockStore</code></a></li><li><a href=#azuredisk><code>azureDisk</code></a></li><li><a href=#azurefile><code>azureFile</code></a></li><li><a href=#gcepersistentdisk><code>gcePersistentDisk</code></a></li><li><a href=#vspherevolume><code>vsphereVolume</code></a></li></ul><h3 id=flexvolume>flexVolume (deprecated)</h3><div style=margin-top:10px;margin-bottom:10px><b>FEATURE STATE:</b> <code>Kubernetes v1.23 [deprecated]</code></div><p>FlexVolume is an out-of-tree plugin interface that uses an exec-based model to interface
with storage drivers. The FlexVolume driver binaries must be installed in a pre-defined
volume plugin path on each node and in some cases the control plane nodes as well.</p><p>Pods interact with FlexVolume drivers through the <code>flexVolume</code> in-tree volume plugin.
For more details, see the FlexVolume <a href=https://github.com/kubernetes/community/blob/master/contributors/devel/sig-storage/flexvolume.md#readme>README</a> document.</p><p>The following FlexVolume <a href=https://github.com/Microsoft/K8s-Storage-Plugins/tree/master/flexvolume/windows>plugins</a>,
deployed as PowerShell scripts on the host, support Windows nodes:</p><ul><li><a href=https://github.com/microsoft/K8s-Storage-Plugins/tree/master/flexvolume/windows/plugins/microsoft.com~smb.cmd>SMB</a></li><li><a href=https://github.com/microsoft/K8s-Storage-Plugins/tree/master/flexvolume/windows/plugins/microsoft.com~iscsi.cmd>iSCSI</a></li></ul><div class="alert alert-info note callout" role=alert><strong>Note:</strong><p>FlexVolume is deprecated. Using an out-of-tree CSI driver is the recommended way to integrate external storage with Kubernetes.</p><p>Maintainers of FlexVolume driver should implement a CSI Driver and help to migrate users of FlexVolume drivers to CSI.
Users of FlexVolume should move their workloads to use the equivalent CSI Driver.</p></div><h2 id=mount-propagation>Mount propagation</h2><p>Mount propagation allows for sharing volumes mounted by a container to
other containers in the same pod, or even to other pods on the same node.</p><p>Mount propagation of a volume is controlled by the <code>mountPropagation</code> field
in <code>Container.volumeMounts</code>. Its values are:</p><ul><li><p><code>None</code> - This volume mount will not receive any subsequent mounts
that are mounted to this volume or any of its subdirectories by the host.
In similar fashion, no mounts created by the container will be visible on
the host. This is the default mode.</p><p>This mode is equal to <code>private</code> mount propagation as described in the
<a href=https://www.kernel.org/doc/Documentation/filesystems/sharedsubtree.txt>Linux kernel documentation</a></p></li><li><p><code>HostToContainer</code> - This volume mount will receive all subsequent mounts
that are mounted to this volume or any of its subdirectories.</p><p>In other words, if the host mounts anything inside the volume mount, the
container will see it mounted there.</p><p>Similarly, if any Pod with <code>Bidirectional</code> mount propagation to the same
volume mounts anything there, the container with <code>HostToContainer</code> mount
propagation will see it.</p><p>This mode is equal to <code>rslave</code> mount propagation as described in the
<a href=https://www.kernel.org/doc/Documentation/filesystems/sharedsubtree.txt>Linux kernel documentation</a></p></li><li><p><code>Bidirectional</code> - This volume mount behaves the same the <code>HostToContainer</code> mount.
In addition, all volume mounts created by the container will be propagated
back to the host and to all containers of all pods that use the same volume.</p><p>A typical use case for this mode is a Pod with a FlexVolume or CSI driver or
a Pod that needs to mount something on the host using a <code>hostPath</code> volume.</p><p>This mode is equal to <code>rshared</code> mount propagation as described in the
<a href=https://www.kernel.org/doc/Documentation/filesystems/sharedsubtree.txt>Linux kernel documentation</a></p><div class="alert alert-danger warning callout" role=alert><strong>Warning:</strong> <code>Bidirectional</code> mount propagation can be dangerous. It can damage
the host operating system and therefore it is allowed only in privileged
containers. Familiarity with Linux kernel behavior is strongly recommended.
In addition, any volume mounts created by containers in pods must be destroyed
(unmounted) by the containers on termination.</div></li></ul><h3 id=configuration>Configuration</h3><p>Before mount propagation can work properly on some deployments (CoreOS,
RedHat/Centos, Ubuntu) mount share must be configured correctly in
Docker as shown below.</p><p>Edit your Docker's <code>systemd</code> service file. Set <code>MountFlags</code> as follows:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span><span style=color:#b8860b>MountFlags</span><span style=color:#666>=</span>shared
</span></span></code></pre></div><p>Or, remove <code>MountFlags=slave</code> if present. Then restart the Docker daemon:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>sudo systemctl daemon-reload
</span></span><span style=display:flex><span>sudo systemctl restart docker
</span></span></code></pre></div><h2 id=what-s-next>What's next</h2><p>Follow an example of <a href=/docs/tutorials/stateful-application/mysql-wordpress-persistent-volume/>deploying WordPress and MySQL with Persistent Volumes</a>.</p></div><div class=td-content style=page-break-before:always><h1 id=pg-ffd12528a12882b282e1bd19e29f9e75>2 - Persistent Volumes</h1><p>This document describes <em>persistent volumes</em> in Kubernetes. Familiarity with <a href=/docs/concepts/storage/volumes/>volumes</a> is suggested.</p><h2 id=introduction>Introduction</h2><p>Managing storage is a distinct problem from managing compute instances. The PersistentVolume subsystem provides an API for users and administrators that abstracts details of how storage is provided from how it is consumed. To do this, we introduce two new API resources: PersistentVolume and PersistentVolumeClaim.</p><p>A <em>PersistentVolume</em> (PV) is a piece of storage in the cluster that has been provisioned by an administrator or dynamically provisioned using <a href=/docs/concepts/storage/storage-classes/>Storage Classes</a>. It is a resource in the cluster just like a node is a cluster resource. PVs are volume plugins like Volumes, but have a lifecycle independent of any individual Pod that uses the PV. This API object captures the details of the implementation of the storage, be that NFS, iSCSI, or a cloud-provider-specific storage system.</p><p>A <em>PersistentVolumeClaim</em> (PVC) is a request for storage by a user. It is similar to a Pod. Pods consume node resources and PVCs consume PV resources. Pods can request specific levels of resources (CPU and Memory). Claims can request specific size and access modes (e.g., they can be mounted ReadWriteOnce, ReadOnlyMany or ReadWriteMany, see <a href=#access-modes>AccessModes</a>).</p><p>While PersistentVolumeClaims allow a user to consume abstract storage resources, it is common that users need PersistentVolumes with varying properties, such as performance, for different problems. Cluster administrators need to be able to offer a variety of PersistentVolumes that differ in more ways than size and access modes, without exposing users to the details of how those volumes are implemented. For these needs, there is the <em>StorageClass</em> resource.</p><p>See the <a href=/docs/tasks/configure-pod-container/configure-persistent-volume-storage/>detailed walkthrough with working examples</a>.</p><h2 id=lifecycle-of-a-volume-and-claim>Lifecycle of a volume and claim</h2><p>PVs are resources in the cluster. PVCs are requests for those resources and also act as claim checks to the resource. The interaction between PVs and PVCs follows this lifecycle:</p><h3 id=provisioning>Provisioning</h3><p>There are two ways PVs may be provisioned: statically or dynamically.</p><h4 id=static>Static</h4><p>A cluster administrator creates a number of PVs. They carry the details of the real storage, which is available for use by cluster users. They exist in the Kubernetes API and are available for consumption.</p><h4 id=dynamic>Dynamic</h4><p>When none of the static PVs the administrator created match a user's PersistentVolumeClaim,
the cluster may try to dynamically provision a volume specially for the PVC.
This provisioning is based on StorageClasses: the PVC must request a
<a href=/docs/concepts/storage/storage-classes/>storage class</a> and
the administrator must have created and configured that class for dynamic
provisioning to occur. Claims that request the class <code>""</code> effectively disable
dynamic provisioning for themselves.</p><p>To enable dynamic storage provisioning based on storage class, the cluster administrator
needs to enable the <code>DefaultStorageClass</code> <a href=/docs/reference/access-authn-authz/admission-controllers/#defaultstorageclass>admission controller</a>
on the API server. This can be done, for example, by ensuring that <code>DefaultStorageClass</code> is
among the comma-delimited, ordered list of values for the <code>--enable-admission-plugins</code> flag of
the API server component. For more information on API server command-line flags,
check <a href=/docs/admin/kube-apiserver/>kube-apiserver</a> documentation.</p><h3 id=binding>Binding</h3><p>A user creates, or in the case of dynamic provisioning, has already created, a PersistentVolumeClaim with a specific amount of storage requested and with certain access modes. A control loop in the master watches for new PVCs, finds a matching PV (if possible), and binds them together. If a PV was dynamically provisioned for a new PVC, the loop will always bind that PV to the PVC. Otherwise, the user will always get at least what they asked for, but the volume may be in excess of what was requested. Once bound, PersistentVolumeClaim binds are exclusive, regardless of how they were bound. A PVC to PV binding is a one-to-one mapping, using a ClaimRef which is a bi-directional binding between the PersistentVolume and the PersistentVolumeClaim.</p><p>Claims will remain unbound indefinitely if a matching volume does not exist. Claims will be bound as matching volumes become available. For example, a cluster provisioned with many 50Gi PVs would not match a PVC requesting 100Gi. The PVC can be bound when a 100Gi PV is added to the cluster.</p><h3 id=using>Using</h3><p>Pods use claims as volumes. The cluster inspects the claim to find the bound volume and mounts that volume for a Pod. For volumes that support multiple access modes, the user specifies which mode is desired when using their claim as a volume in a Pod.</p><p>Once a user has a claim and that claim is bound, the bound PV belongs to the user for as long as they need it. Users schedule Pods and access their claimed PVs by including a <code>persistentVolumeClaim</code> section in a Pod's <code>volumes</code> block. See <a href=#claims-as-volumes>Claims As Volumes</a> for more details on this.</p><h3 id=storage-object-in-use-protection>Storage Object in Use Protection</h3><p>The purpose of the Storage Object in Use Protection feature is to ensure that PersistentVolumeClaims (PVCs) in active use by a Pod and PersistentVolume (PVs) that are bound to PVCs are not removed from the system, as this may result in data loss.</p><div class="alert alert-info note callout" role=alert><strong>Note:</strong> PVC is in active use by a Pod when a Pod object exists that is using the PVC.</div><p>If a user deletes a PVC in active use by a Pod, the PVC is not removed immediately. PVC removal is postponed until the PVC is no longer actively used by any Pods. Also, if an admin deletes a PV that is bound to a PVC, the PV is not removed immediately. PV removal is postponed until the PV is no longer bound to a PVC.</p><p>You can see that a PVC is protected when the PVC's status is <code>Terminating</code> and the <code>Finalizers</code> list includes <code>kubernetes.io/pvc-protection</code>:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl describe pvc hostpath
</span></span><span style=display:flex><span>Name:          hostpath
</span></span><span style=display:flex><span>Namespace:     default
</span></span><span style=display:flex><span>StorageClass:  example-hostpath
</span></span><span style=display:flex><span>Status:        Terminating
</span></span><span style=display:flex><span>Volume:
</span></span><span style=display:flex><span>Labels:        &lt;none&gt;
</span></span><span style=display:flex><span>Annotations:   volume.beta.kubernetes.io/storage-class<span style=color:#666>=</span>example-hostpath
</span></span><span style=display:flex><span>               volume.beta.kubernetes.io/storage-provisioner<span style=color:#666>=</span>example.com/hostpath
</span></span><span style=display:flex><span>Finalizers:    <span style=color:#666>[</span>kubernetes.io/pvc-protection<span style=color:#666>]</span>
</span></span><span style=display:flex><span>...
</span></span></code></pre></div><p>You can see that a PV is protected when the PV's status is <code>Terminating</code> and the <code>Finalizers</code> list includes <code>kubernetes.io/pv-protection</code> too:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl describe pv task-pv-volume
</span></span><span style=display:flex><span>Name:            task-pv-volume
</span></span><span style=display:flex><span>Labels:          <span style=color:#b8860b>type</span><span style=color:#666>=</span><span style=color:#a2f>local</span>
</span></span><span style=display:flex><span>Annotations:     &lt;none&gt;
</span></span><span style=display:flex><span>Finalizers:      <span style=color:#666>[</span>kubernetes.io/pv-protection<span style=color:#666>]</span>
</span></span><span style=display:flex><span>StorageClass:    standard
</span></span><span style=display:flex><span>Status:          Terminating
</span></span><span style=display:flex><span>Claim:
</span></span><span style=display:flex><span>Reclaim Policy:  Delete
</span></span><span style=display:flex><span>Access Modes:    RWO
</span></span><span style=display:flex><span>Capacity:        1Gi
</span></span><span style=display:flex><span>Message:
</span></span><span style=display:flex><span>Source:
</span></span><span style=display:flex><span>    Type:          HostPath <span style=color:#666>(</span>bare host directory volume<span style=color:#666>)</span>
</span></span><span style=display:flex><span>    Path:          /tmp/data
</span></span><span style=display:flex><span>    HostPathType:
</span></span><span style=display:flex><span>Events:            &lt;none&gt;
</span></span></code></pre></div><h3 id=reclaiming>Reclaiming</h3><p>When a user is done with their volume, they can delete the PVC objects from the API that allows reclamation of the resource. The reclaim policy for a PersistentVolume tells the cluster what to do with the volume after it has been released of its claim. Currently, volumes can either be Retained, Recycled, or Deleted.</p><h4 id=retain>Retain</h4><p>The <code>Retain</code> reclaim policy allows for manual reclamation of the resource. When the PersistentVolumeClaim is deleted, the PersistentVolume still exists and the volume is considered "released". But it is not yet available for another claim because the previous claimant's data remains on the volume. An administrator can manually reclaim the volume with the following steps.</p><ol><li>Delete the PersistentVolume. The associated storage asset in external infrastructure (such as an AWS EBS, GCE PD, Azure Disk, or Cinder volume) still exists after the PV is deleted.</li><li>Manually clean up the data on the associated storage asset accordingly.</li><li>Manually delete the associated storage asset.</li></ol><p>If you want to reuse the same storage asset, create a new PersistentVolume with the same storage asset definition.</p><h4 id=delete>Delete</h4><p>For volume plugins that support the <code>Delete</code> reclaim policy, deletion removes both the PersistentVolume object from Kubernetes, as well as the associated storage asset in the external infrastructure, such as an AWS EBS, GCE PD, Azure Disk, or Cinder volume. Volumes that were dynamically provisioned inherit the <a href=#reclaim-policy>reclaim policy of their StorageClass</a>, which defaults to <code>Delete</code>. The administrator should configure the StorageClass according to users' expectations; otherwise, the PV must be edited or patched after it is created. See <a href=/docs/tasks/administer-cluster/change-pv-reclaim-policy/>Change the Reclaim Policy of a PersistentVolume</a>.</p><h4 id=recycle>Recycle</h4><div class="alert alert-danger warning callout" role=alert><strong>Warning:</strong> The <code>Recycle</code> reclaim policy is deprecated. Instead, the recommended approach is to use dynamic provisioning.</div><p>If supported by the underlying volume plugin, the <code>Recycle</code> reclaim policy performs a basic scrub (<code>rm -rf /thevolume/*</code>) on the volume and makes it available again for a new claim.</p><p>However, an administrator can configure a custom recycler Pod template using
the Kubernetes controller manager command line arguments as described in the
<a href=/docs/reference/command-line-tools-reference/kube-controller-manager/>reference</a>.
The custom recycler Pod template must contain a <code>volumes</code> specification, as
shown in the example below:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>pv-recycler<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>namespace</span>:<span style=color:#bbb> </span>default<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>restartPolicy</span>:<span style=color:#bbb> </span>Never<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>volumes</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>vol<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>hostPath</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>path</span>:<span style=color:#bbb> </span>/any/path/it/will/be/replaced<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>pv-recycler<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;registry.k8s.io/busybox&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>command</span>:<span style=color:#bbb> </span>[<span style=color:#b44>&#34;/bin/sh&#34;</span>,<span style=color:#bbb> </span><span style=color:#b44>&#34;-c&#34;</span>,<span style=color:#bbb> </span><span style=color:#b44>&#34;test -e /scrub &amp;&amp; rm -rf /scrub/..?* /scrub/.[!.]* /scrub/*  &amp;&amp; test -z \&#34;$(ls -A /scrub)\&#34; || exit 1&#34;</span>]<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>volumeMounts</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>vol<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>mountPath</span>:<span style=color:#bbb> </span>/scrub<span style=color:#bbb>
</span></span></span></code></pre></div><p>However, the particular path specified in the custom recycler Pod template in the <code>volumes</code> part is replaced with the particular path of the volume that is being recycled.</p><h3 id=persistentvolume-deletion-protection-finalizer>PersistentVolume deletion protection finalizer</h3><div style=margin-top:10px;margin-bottom:10px><b>FEATURE STATE:</b> <code>Kubernetes v1.23 [alpha]</code></div><p>Finalizers can be added on a PersistentVolume to ensure that PersistentVolumes
having <code>Delete</code> reclaim policy are deleted only after the backing storage are deleted.</p><p>The newly introduced finalizers <code>kubernetes.io/pv-controller</code> and <code>external-provisioner.volume.kubernetes.io/finalizer</code>
are only added to dynamically provisioned volumes.</p><p>The finalizer <code>kubernetes.io/pv-controller</code> is added to in-tree plugin volumes. The following is an example</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl describe pv pvc-74a498d6-3929-47e8-8c02-078c1ece4d78
</span></span><span style=display:flex><span>Name:            pvc-74a498d6-3929-47e8-8c02-078c1ece4d78
</span></span><span style=display:flex><span>Labels:          &lt;none&gt;
</span></span><span style=display:flex><span>Annotations:     kubernetes.io/createdby: vsphere-volume-dynamic-provisioner
</span></span><span style=display:flex><span>                 pv.kubernetes.io/bound-by-controller: yes
</span></span><span style=display:flex><span>                 pv.kubernetes.io/provisioned-by: kubernetes.io/vsphere-volume
</span></span><span style=display:flex><span>Finalizers:      <span style=color:#666>[</span>kubernetes.io/pv-protection kubernetes.io/pv-controller<span style=color:#666>]</span>
</span></span><span style=display:flex><span>StorageClass:    vcp-sc
</span></span><span style=display:flex><span>Status:          Bound
</span></span><span style=display:flex><span>Claim:           default/vcp-pvc-1
</span></span><span style=display:flex><span>Reclaim Policy:  Delete
</span></span><span style=display:flex><span>Access Modes:    RWO
</span></span><span style=display:flex><span>VolumeMode:      Filesystem
</span></span><span style=display:flex><span>Capacity:        1Gi
</span></span><span style=display:flex><span>Node Affinity:   &lt;none&gt;
</span></span><span style=display:flex><span>Message:         
</span></span><span style=display:flex><span>Source:
</span></span><span style=display:flex><span>    Type:               vSphereVolume <span style=color:#666>(</span>a Persistent Disk resource in vSphere<span style=color:#666>)</span>
</span></span><span style=display:flex><span>    VolumePath:         <span style=color:#666>[</span>vsanDatastore<span style=color:#666>]</span> d49c4a62-166f-ce12-c464-020077ba5d46/kubernetes-dynamic-pvc-74a498d6-3929-47e8-8c02-078c1ece4d78.vmdk
</span></span><span style=display:flex><span>    FSType:             ext4
</span></span><span style=display:flex><span>    StoragePolicyName:  vSAN Default Storage Policy
</span></span><span style=display:flex><span>Events:                 &lt;none&gt;
</span></span></code></pre></div><p>The finalizer <code>external-provisioner.volume.kubernetes.io/finalizer</code> is added for CSI volumes.
The following is an example:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>Name:            pvc-2f0bab97-85a8-4552-8044-eb8be45cf48d
</span></span><span style=display:flex><span>Labels:          &lt;none&gt;
</span></span><span style=display:flex><span>Annotations:     pv.kubernetes.io/provisioned-by: csi.vsphere.vmware.com
</span></span><span style=display:flex><span>Finalizers:      <span style=color:#666>[</span>kubernetes.io/pv-protection external-provisioner.volume.kubernetes.io/finalizer<span style=color:#666>]</span>
</span></span><span style=display:flex><span>StorageClass:    fast
</span></span><span style=display:flex><span>Status:          Bound
</span></span><span style=display:flex><span>Claim:           demo-app/nginx-logs
</span></span><span style=display:flex><span>Reclaim Policy:  Delete
</span></span><span style=display:flex><span>Access Modes:    RWO
</span></span><span style=display:flex><span>VolumeMode:      Filesystem
</span></span><span style=display:flex><span>Capacity:        200Mi
</span></span><span style=display:flex><span>Node Affinity:   &lt;none&gt;
</span></span><span style=display:flex><span>Message:         
</span></span><span style=display:flex><span>Source:
</span></span><span style=display:flex><span>    Type:              CSI <span style=color:#666>(</span>a Container Storage Interface <span style=color:#666>(</span>CSI<span style=color:#666>)</span> volume <span style=color:#a2f>source</span><span style=color:#666>)</span>
</span></span><span style=display:flex><span>    Driver:            csi.vsphere.vmware.com
</span></span><span style=display:flex><span>    FSType:            ext4
</span></span><span style=display:flex><span>    VolumeHandle:      44830fa8-79b4-406b-8b58-621ba25353fd
</span></span><span style=display:flex><span>    ReadOnly:          <span style=color:#a2f>false</span>
</span></span><span style=display:flex><span>    VolumeAttributes:      storage.kubernetes.io/csiProvisionerIdentity<span style=color:#666>=</span>1648442357185-8081-csi.vsphere.vmware.com
</span></span><span style=display:flex><span>                           <span style=color:#b8860b>type</span><span style=color:#666>=</span>vSphere CNS Block Volume
</span></span><span style=display:flex><span>Events:                &lt;none&gt;
</span></span></code></pre></div><p>When the <code>CSIMigration{provider}</code> feature flag is enabled for a specific in-tree volume plugin,
the <code>kubernetes.io/pv-controller</code> finalizer is replaced by the
<code>external-provisioner.volume.kubernetes.io/finalizer</code> finalizer.</p><h3 id=reserving-a-persistentvolume>Reserving a PersistentVolume</h3><p>The control plane can <a href=#binding>bind PersistentVolumeClaims to matching PersistentVolumes</a> in the
cluster. However, if you want a PVC to bind to a specific PV, you need to pre-bind them.</p><p>By specifying a PersistentVolume in a PersistentVolumeClaim, you declare a binding between that specific PV and PVC.
If the PersistentVolume exists and has not reserved PersistentVolumeClaims through its <code>claimRef</code> field, then the PersistentVolume and PersistentVolumeClaim will be bound.</p><p>The binding happens regardless of some volume matching criteria, including node affinity.
The control plane still checks that <a href=/docs/concepts/storage/storage-classes/>storage class</a>, access modes, and requested storage size are valid.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>PersistentVolumeClaim<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>foo-pvc<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>namespace</span>:<span style=color:#bbb> </span>foo<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>storageClassName</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;&#34;</span><span style=color:#bbb> </span><span style=color:#080;font-style:italic># Empty string must be explicitly set otherwise default StorageClass will be set</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>volumeName</span>:<span style=color:#bbb> </span>foo-pv<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>...<span style=color:#bbb>
</span></span></span></code></pre></div><p>This method does not guarantee any binding privileges to the PersistentVolume. If other PersistentVolumeClaims could use the PV that you specify, you first need to reserve that storage volume. Specify the relevant PersistentVolumeClaim in the <code>claimRef</code> field of the PV so that other PVCs can not bind to it.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>PersistentVolume<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>foo-pv<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>storageClassName</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>claimRef</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>foo-pvc<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>namespace</span>:<span style=color:#bbb> </span>foo<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>...<span style=color:#bbb>
</span></span></span></code></pre></div><p>This is useful if you want to consume PersistentVolumes that have their <code>claimPolicy</code> set
to <code>Retain</code>, including cases where you are reusing an existing PV.</p><h3 id=expanding-persistent-volumes-claims>Expanding Persistent Volumes Claims</h3><div style=margin-top:10px;margin-bottom:10px><b>FEATURE STATE:</b> <code>Kubernetes v1.24 [stable]</code></div><p>Support for expanding PersistentVolumeClaims (PVCs) is enabled by default. You can expand
the following types of volumes:</p><ul><li>azureDisk</li><li>azureFile</li><li>awsElasticBlockStore</li><li>cinder (deprecated)</li><li><a class=glossary-tooltip title='The Container Storage Interface (CSI) defines a standard interface to expose storage systems to containers.' data-toggle=tooltip data-placement=top href=/docs/concepts/storage/volumes/#csi target=_blank aria-label=csi>csi</a></li><li>flexVolume (deprecated)</li><li>gcePersistentDisk</li><li>glusterfs (deprecated)</li><li>rbd</li><li>portworxVolume</li></ul><p>You can only expand a PVC if its storage class's <code>allowVolumeExpansion</code> field is set to true.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>storage.k8s.io/v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>StorageClass<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>example-vol-default<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>provisioner</span>:<span style=color:#bbb> </span>vendor-name.example/magicstorage<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>parameters</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>resturl</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;http://192.168.10.100:8080&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>restuser</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>secretNamespace</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>secretName</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>allowVolumeExpansion</span>:<span style=color:#bbb> </span><span style=color:#a2f;font-weight:700>true</span><span style=color:#bbb>
</span></span></span></code></pre></div><p>To request a larger volume for a PVC, edit the PVC object and specify a larger
size. This triggers expansion of the volume that backs the underlying PersistentVolume. A
new PersistentVolume is never created to satisfy the claim. Instead, an existing volume is resized.</p><div class="alert alert-danger warning callout" role=alert><strong>Warning:</strong> Directly editing the size of a PersistentVolume can prevent an automatic resize of that volume.
If you edit the capacity of a PersistentVolume, and then edit the <code>.spec</code> of a matching
PersistentVolumeClaim to make the size of the PersistentVolumeClaim match the PersistentVolume,
then no storage resize happens.
The Kubernetes control plane will see that the desired state of both resources matches,
conclude that the backing volume size has been manually
increased and that no resize is necessary.</div><h4 id=csi-volume-expansion>CSI Volume expansion</h4><div style=margin-top:10px;margin-bottom:10px><b>FEATURE STATE:</b> <code>Kubernetes v1.24 [stable]</code></div><p>Support for expanding CSI volumes is enabled by default but it also requires a specific CSI driver to support volume expansion. Refer to documentation of the specific CSI driver for more information.</p><h4 id=resizing-a-volume-containing-a-file-system>Resizing a volume containing a file system</h4><p>You can only resize volumes containing a file system if the file system is XFS, Ext3, or Ext4.</p><p>When a volume contains a file system, the file system is only resized when a new Pod is using
the PersistentVolumeClaim in <code>ReadWrite</code> mode. File system expansion is either done when a Pod is starting up
or when a Pod is running and the underlying file system supports online expansion.</p><p>FlexVolumes (deprecated since Kubernetes v1.23) allow resize if the driver is configured with the
<code>RequiresFSResize</code> capability to <code>true</code>. The FlexVolume can be resized on Pod restart.</p><h4 id=resizing-an-in-use-persistentvolumeclaim>Resizing an in-use PersistentVolumeClaim</h4><div style=margin-top:10px;margin-bottom:10px><b>FEATURE STATE:</b> <code>Kubernetes v1.24 [stable]</code></div><p>In this case, you don't need to delete and recreate a Pod or deployment that is using an existing PVC.
Any in-use PVC automatically becomes available to its Pod as soon as its file system has been expanded.
This feature has no effect on PVCs that are not in use by a Pod or deployment. You must create a Pod that
uses the PVC before the expansion can complete.</p><p>Similar to other volume types - FlexVolume volumes can also be expanded when in-use by a Pod.</p><div class="alert alert-info note callout" role=alert><strong>Note:</strong> FlexVolume resize is possible only when the underlying driver supports resize.</div><div class="alert alert-info note callout" role=alert><strong>Note:</strong> Expanding EBS volumes is a time-consuming operation. Also, there is a per-volume quota of one modification every 6 hours.</div><h4 id=recovering-from-failure-when-expanding-volumes>Recovering from Failure when Expanding Volumes</h4><p>If a user specifies a new size that is too big to be satisfied by underlying storage system, expansion of PVC will be continuously retried until user or cluster administrator takes some action. This can be undesirable and hence Kubernetes provides following methods of recovering from such failures.</p><ul class="nav nav-tabs" id=recovery-methods role=tablist><li class=nav-item><a data-toggle=tab class="nav-link active" href=#recovery-methods-0 role=tab aria-controls=recovery-methods-0 aria-selected=true>Manually with Cluster Administrator access</a></li><li class=nav-item><a data-toggle=tab class=nav-link href=#recovery-methods-1 role=tab aria-controls=recovery-methods-1>By requesting expansion to smaller size</a></li></ul><div class=tab-content id=recovery-methods><div id=recovery-methods-0 class="tab-pane show active" role=tabpanel aria-labelledby=recovery-methods-0><p><p>If expanding underlying storage fails, the cluster administrator can manually recover the Persistent Volume Claim (PVC) state and cancel the resize requests. Otherwise, the resize requests are continuously retried by the controller without administrator intervention.</p><ol><li>Mark the PersistentVolume(PV) that is bound to the PersistentVolumeClaim(PVC) with <code>Retain</code> reclaim policy.</li><li>Delete the PVC. Since PV has <code>Retain</code> reclaim policy - we will not lose any data when we recreate the PVC.</li><li>Delete the <code>claimRef</code> entry from PV specs, so as new PVC can bind to it. This should make the PV <code>Available</code>.</li><li>Re-create the PVC with smaller size than PV and set <code>volumeName</code> field of the PVC to the name of the PV. This should bind new PVC to existing PV.</li><li>Don't forget to restore the reclaim policy of the PV.</li></ol></div><div id=recovery-methods-1 class=tab-pane role=tabpanel aria-labelledby=recovery-methods-1><p><div style=margin-top:10px;margin-bottom:10px><b>FEATURE STATE:</b> <code>Kubernetes v1.23 [alpha]</code></div><div class="alert alert-info note callout" role=alert><strong>Note:</strong> Recovery from failing PVC expansion by users is available as an alpha feature since Kubernetes 1.23. The <code>RecoverVolumeExpansionFailure</code> feature must be enabled for this feature to work. Refer to the <a href=/docs/reference/command-line-tools-reference/feature-gates/>feature gate</a> documentation for more information.</div><p>If the feature gates <code>RecoverVolumeExpansionFailure</code> is
enabled in your cluster, and expansion has failed for a PVC, you can retry expansion with a
smaller size than the previously requested value. To request a new expansion attempt with a
smaller proposed size, edit <code>.spec.resources</code> for that PVC and choose a value that is less than the
value you previously tried.
This is useful if expansion to a higher value did not succeed because of capacity constraint.
If that has happened, or you suspect that it might have, you can retry expansion by specifying a
size that is within the capacity limits of underlying storage provider. You can monitor status of resize operation by watching <code>.status.resizeStatus</code> and events on the PVC.</p><p>Note that,
although you can specify a lower amount of storage than what was requested previously,
the new value must still be higher than <code>.status.capacity</code>.
Kubernetes does not support shrinking a PVC to less than its current size.</p></div></div><h2 id=types-of-persistent-volumes>Types of Persistent Volumes</h2><p>PersistentVolume types are implemented as plugins. Kubernetes currently supports the following plugins:</p><ul><li><a href=/docs/concepts/storage/volumes/#cephfs><code>cephfs</code></a> - CephFS volume</li><li><a href=/docs/concepts/storage/volumes/#csi><code>csi</code></a> - Container Storage Interface (CSI)</li><li><a href=/docs/concepts/storage/volumes/#fc><code>fc</code></a> - Fibre Channel (FC) storage</li><li><a href=/docs/concepts/storage/volumes/#hostpath><code>hostPath</code></a> - HostPath volume
(for single node testing only; WILL NOT WORK in a multi-node cluster;
consider using <code>local</code> volume instead)</li><li><a href=/docs/concepts/storage/volumes/#iscsi><code>iscsi</code></a> - iSCSI (SCSI over IP) storage</li><li><a href=/docs/concepts/storage/volumes/#local><code>local</code></a> - local storage devices
mounted on nodes.</li><li><a href=/docs/concepts/storage/volumes/#nfs><code>nfs</code></a> - Network File System (NFS) storage</li><li><a href=/docs/concepts/storage/volumes/#rbd><code>rbd</code></a> - Rados Block Device (RBD) volume</li></ul><p>The following types of PersistentVolume are deprecated. This means that support is still available but will be removed in a future Kubernetes release.</p><ul><li><a href=/docs/concepts/storage/volumes/#awselasticblockstore><code>awsElasticBlockStore</code></a> - AWS Elastic Block Store (EBS)
(<strong>deprecated</strong> in v1.17)</li><li><a href=/docs/concepts/storage/volumes/#azuredisk><code>azureDisk</code></a> - Azure Disk
(<strong>deprecated</strong> in v1.19)</li><li><a href=/docs/concepts/storage/volumes/#azurefile><code>azureFile</code></a> - Azure File
(<strong>deprecated</strong> in v1.21)</li><li><a href=/docs/concepts/storage/volumes/#cinder><code>cinder</code></a> - Cinder (OpenStack block storage)
(<strong>deprecated</strong> in v1.18)</li><li><a href=/docs/concepts/storage/volumes/#flexvolume><code>flexVolume</code></a> - FlexVolume
(<strong>deprecated</strong> in v1.23)</li><li><a href=/docs/concepts/storage/volumes/#gcepersistentdisk><code>gcePersistentDisk</code></a> - GCE Persistent Disk
(<strong>deprecated</strong> in v1.17)</li><li><a href=/docs/concepts/storage/volumes/#glusterfs><code>glusterfs</code></a> - Glusterfs volume
(<strong>deprecated</strong> in v1.25)</li><li><a href=/docs/concepts/storage/volumes/#portworxvolume><code>portworxVolume</code></a> - Portworx volume
(<strong>deprecated</strong> in v1.25)</li><li><a href=/docs/concepts/storage/volumes/#vspherevolume><code>vsphereVolume</code></a> - vSphere VMDK volume
(<strong>deprecated</strong> in v1.19)</li></ul><p>Older versions of Kubernetes also supported the following in-tree PersistentVolume types:</p><ul><li><code>photonPersistentDisk</code> - Photon controller persistent disk.
(<strong>not available</strong> starting v1.15)</li><li><a href=/docs/concepts/storage/volumes/#scaleio><code>scaleIO</code></a> - ScaleIO volume
(<strong>not available</strong> starting v1.21)</li><li><a href=/docs/concepts/storage/volumes/#flocker><code>flocker</code></a> - Flocker storage
(<strong>not available</strong> starting v1.25)</li><li><a href=/docs/concepts/storage/volumes/#quobyte><code>quobyte</code></a> - Quobyte volume
(<strong>not available</strong> starting v1.25)</li><li><a href=/docs/concepts/storage/volumes/#storageos><code>storageos</code></a> - StorageOS volume
(<strong>not available</strong> starting v1.25)</li></ul><h2 id=persistent-volumes>Persistent Volumes</h2><p>Each PV contains a spec and status, which is the specification and status of the volume.
The name of a PersistentVolume object must be a valid
<a href=/docs/concepts/overview/working-with-objects/names#dns-subdomain-names>DNS subdomain name</a>.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>PersistentVolume<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>pv0003<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>capacity</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>storage</span>:<span style=color:#bbb> </span>5Gi<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>volumeMode</span>:<span style=color:#bbb> </span>Filesystem<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>accessModes</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- ReadWriteOnce<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>persistentVolumeReclaimPolicy</span>:<span style=color:#bbb> </span>Recycle<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>storageClassName</span>:<span style=color:#bbb> </span>slow<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>mountOptions</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- hard<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- nfsvers=4.1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>nfs</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>path</span>:<span style=color:#bbb> </span>/tmp<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>server</span>:<span style=color:#bbb> </span><span style=color:#666>172.17.0.2</span><span style=color:#bbb>
</span></span></span></code></pre></div><div class="alert alert-info note callout" role=alert><strong>Note:</strong> Helper programs relating to the volume type may be required for consumption of a PersistentVolume within a cluster. In this example, the PersistentVolume is of type NFS and the helper program /sbin/mount.nfs is required to support the mounting of NFS filesystems.</div><h3 id=capacity>Capacity</h3><p>Generally, a PV will have a specific storage capacity. This is set using the PV's <code>capacity</code> attribute. Read the glossary term <a href="/docs/reference/glossary/?all=true#term-quantity">Quantity</a> to understand the units expected by <code>capacity</code>.</p><p>Currently, storage size is the only resource that can be set or requested. Future attributes may include IOPS, throughput, etc.</p><h3 id=volume-mode>Volume Mode</h3><div style=margin-top:10px;margin-bottom:10px><b>FEATURE STATE:</b> <code>Kubernetes v1.18 [stable]</code></div><p>Kubernetes supports two <code>volumeModes</code> of PersistentVolumes: <code>Filesystem</code> and <code>Block</code>.</p><p><code>volumeMode</code> is an optional API parameter.
<code>Filesystem</code> is the default mode used when <code>volumeMode</code> parameter is omitted.</p><p>A volume with <code>volumeMode: Filesystem</code> is <em>mounted</em> into Pods into a directory. If the volume
is backed by a block device and the device is empty, Kubernetes creates a filesystem
on the device before mounting it for the first time.</p><p>You can set the value of <code>volumeMode</code> to <code>Block</code> to use a volume as a raw block device.
Such volume is presented into a Pod as a block device, without any filesystem on it.
This mode is useful to provide a Pod the fastest possible way to access a volume, without
any filesystem layer between the Pod and the volume. On the other hand, the application
running in the Pod must know how to handle a raw block device.
See <a href=#raw-block-volume-support>Raw Block Volume Support</a>
for an example on how to use a volume with <code>volumeMode: Block</code> in a Pod.</p><h3 id=access-modes>Access Modes</h3><p>A PersistentVolume can be mounted on a host in any way supported by the resource provider. As shown in the table below, providers will have different capabilities and each PV's access modes are set to the specific modes supported by that particular volume. For example, NFS can support multiple read/write clients, but a specific NFS PV might be exported on the server as read-only. Each PV gets its own set of access modes describing that specific PV's capabilities.</p><p>The access modes are:</p><dl><dt><code>ReadWriteOnce</code></dt><dd>the volume can be mounted as read-write by a single node. ReadWriteOnce access mode still can allow multiple pods to access the volume when the pods are running on the same node.</dd><dt><code>ReadOnlyMany</code></dt><dd>the volume can be mounted as read-only by many nodes.</dd><dt><code>ReadWriteMany</code></dt><dd>the volume can be mounted as read-write by many nodes.</dd><dt><code>ReadWriteOncePod</code></dt><dd>the volume can be mounted as read-write by a single Pod. Use ReadWriteOncePod access mode if you want to ensure that only one pod across whole cluster can read that PVC or write to it. This is only supported for CSI volumes and Kubernetes version 1.22+.</dd></dl><p>The blog article <a href=/blog/2021/09/13/read-write-once-pod-access-mode-alpha/>Introducing Single Pod Access Mode for PersistentVolumes</a> covers this in more detail.</p><p>In the CLI, the access modes are abbreviated to:</p><ul><li>RWO - ReadWriteOnce</li><li>ROX - ReadOnlyMany</li><li>RWX - ReadWriteMany</li><li>RWOP - ReadWriteOncePod</li></ul><div class="alert alert-info note callout" role=alert><strong>Note:</strong> Kubernetes uses volume access modes to match PersistentVolumeClaims and PersistentVolumes.
In some cases, the volume access modes also constrain where the PersistentVolume can be mounted.
Volume access modes do <strong>not</strong> enforce write protection once the storage has been mounted.
Even if the access modes are specified as ReadWriteOnce, ReadOnlyMany, or ReadWriteMany, they don't set any constraints on the volume.
For example, even if a PersistentVolume is created as ReadOnlyMany, it is no guarantee that it will be read-only.
If the access modes are specified as ReadWriteOncePod, the volume is constrained and can be mounted on only a single Pod.</div><blockquote><p><strong>Important!</strong> A volume can only be mounted using one access mode at a time, even if it supports many. For example, a GCEPersistentDisk can be mounted as ReadWriteOnce by a single node or ReadOnlyMany by many nodes, but not at the same time.</p></blockquote><table><thead><tr><th style=text-align:left>Volume Plugin</th><th style=text-align:center>ReadWriteOnce</th><th style=text-align:center>ReadOnlyMany</th><th style=text-align:center>ReadWriteMany</th><th>ReadWriteOncePod</th></tr></thead><tbody><tr><td style=text-align:left>AWSElasticBlockStore</td><td style=text-align:center>✓</td><td style=text-align:center>-</td><td style=text-align:center>-</td><td>-</td></tr><tr><td style=text-align:left>AzureFile</td><td style=text-align:center>✓</td><td style=text-align:center>✓</td><td style=text-align:center>✓</td><td>-</td></tr><tr><td style=text-align:left>AzureDisk</td><td style=text-align:center>✓</td><td style=text-align:center>-</td><td style=text-align:center>-</td><td>-</td></tr><tr><td style=text-align:left>CephFS</td><td style=text-align:center>✓</td><td style=text-align:center>✓</td><td style=text-align:center>✓</td><td>-</td></tr><tr><td style=text-align:left>Cinder</td><td style=text-align:center>✓</td><td style=text-align:center>-</td><td style=text-align:center>(<a href=https://github.com/kubernetes/cloud-provider-openstack/blob/master/docs/cinder-csi-plugin/features.md#multi-attach-volumes>if multi-attach volumes are available</a>)</td><td>-</td></tr><tr><td style=text-align:left>CSI</td><td style=text-align:center>depends on the driver</td><td style=text-align:center>depends on the driver</td><td style=text-align:center>depends on the driver</td><td>depends on the driver</td></tr><tr><td style=text-align:left>FC</td><td style=text-align:center>✓</td><td style=text-align:center>✓</td><td style=text-align:center>-</td><td>-</td></tr><tr><td style=text-align:left>FlexVolume</td><td style=text-align:center>✓</td><td style=text-align:center>✓</td><td style=text-align:center>depends on the driver</td><td>-</td></tr><tr><td style=text-align:left>GCEPersistentDisk</td><td style=text-align:center>✓</td><td style=text-align:center>✓</td><td style=text-align:center>-</td><td>-</td></tr><tr><td style=text-align:left>Glusterfs</td><td style=text-align:center>✓</td><td style=text-align:center>✓</td><td style=text-align:center>✓</td><td>-</td></tr><tr><td style=text-align:left>HostPath</td><td style=text-align:center>✓</td><td style=text-align:center>-</td><td style=text-align:center>-</td><td>-</td></tr><tr><td style=text-align:left>iSCSI</td><td style=text-align:center>✓</td><td style=text-align:center>✓</td><td style=text-align:center>-</td><td>-</td></tr><tr><td style=text-align:left>NFS</td><td style=text-align:center>✓</td><td style=text-align:center>✓</td><td style=text-align:center>✓</td><td>-</td></tr><tr><td style=text-align:left>RBD</td><td style=text-align:center>✓</td><td style=text-align:center>✓</td><td style=text-align:center>-</td><td>-</td></tr><tr><td style=text-align:left>VsphereVolume</td><td style=text-align:center>✓</td><td style=text-align:center>-</td><td style=text-align:center>- (works when Pods are collocated)</td><td>-</td></tr><tr><td style=text-align:left>PortworxVolume</td><td style=text-align:center>✓</td><td style=text-align:center>-</td><td style=text-align:center>✓</td><td>-</td></tr></tbody></table><h3 id=class>Class</h3><p>A PV can have a class, which is specified by setting the
<code>storageClassName</code> attribute to the name of a
<a href=/docs/concepts/storage/storage-classes/>StorageClass</a>.
A PV of a particular class can only be bound to PVCs requesting
that class. A PV with no <code>storageClassName</code> has no class and can only be bound
to PVCs that request no particular class.</p><p>In the past, the annotation <code>volume.beta.kubernetes.io/storage-class</code> was used instead
of the <code>storageClassName</code> attribute. This annotation is still working; however,
it will become fully deprecated in a future Kubernetes release.</p><h3 id=reclaim-policy>Reclaim Policy</h3><p>Current reclaim policies are:</p><ul><li>Retain -- manual reclamation</li><li>Recycle -- basic scrub (<code>rm -rf /thevolume/*</code>)</li><li>Delete -- associated storage asset such as AWS EBS, GCE PD, Azure Disk, or OpenStack Cinder volume is deleted</li></ul><p>Currently, only NFS and HostPath support recycling. AWS EBS, GCE PD, Azure Disk, and Cinder volumes support deletion.</p><h3 id=mount-options>Mount Options</h3><p>A Kubernetes administrator can specify additional mount options for when a Persistent Volume is mounted on a node.</p><div class="alert alert-info note callout" role=alert><strong>Note:</strong> Not all Persistent Volume types support mount options.</div><p>The following volume types support mount options:</p><ul><li><code>awsElasticBlockStore</code></li><li><code>azureDisk</code></li><li><code>azureFile</code></li><li><code>cephfs</code></li><li><code>cinder</code> (<strong>deprecated</strong> in v1.18)</li><li><code>gcePersistentDisk</code></li><li><code>glusterfs</code> (<strong>deprecated</strong> in v1.25)</li><li><code>iscsi</code></li><li><code>nfs</code></li><li><code>rbd</code></li><li><code>vsphereVolume</code></li></ul><p>Mount options are not validated. If a mount option is invalid, the mount fails.</p><p>In the past, the annotation <code>volume.beta.kubernetes.io/mount-options</code> was used instead
of the <code>mountOptions</code> attribute. This annotation is still working; however,
it will become fully deprecated in a future Kubernetes release.</p><h3 id=node-affinity>Node Affinity</h3><div class="alert alert-info note callout" role=alert><strong>Note:</strong> For most volume types, you do not need to set this field. It is automatically populated for <a href=/docs/concepts/storage/volumes/#awselasticblockstore>AWS EBS</a>, <a href=/docs/concepts/storage/volumes/#gcepersistentdisk>GCE PD</a> and <a href=/docs/concepts/storage/volumes/#azuredisk>Azure Disk</a> volume block types. You need to explicitly set this for <a href=/docs/concepts/storage/volumes/#local>local</a> volumes.</div><p>A PV can specify node affinity to define constraints that limit what nodes this volume can be accessed from. Pods that use a PV will only be scheduled to nodes that are selected by the node affinity. To specify node affinity, set <code>nodeAffinity</code> in the <code>.spec</code> of a PV. The <a href=/docs/reference/kubernetes-api/config-and-storage-resources/persistent-volume-v1/#PersistentVolumeSpec>PersistentVolume</a> API reference has more details on this field.</p><h3 id=phase>Phase</h3><p>A volume will be in one of the following phases:</p><ul><li>Available -- a free resource that is not yet bound to a claim</li><li>Bound -- the volume is bound to a claim</li><li>Released -- the claim has been deleted, but the resource is not yet reclaimed by the cluster</li><li>Failed -- the volume has failed its automatic reclamation</li></ul><p>The CLI will show the name of the PVC bound to the PV.</p><h2 id=persistentvolumeclaims>PersistentVolumeClaims</h2><p>Each PVC contains a spec and status, which is the specification and status of the claim.
The name of a PersistentVolumeClaim object must be a valid
<a href=/docs/concepts/overview/working-with-objects/names#dns-subdomain-names>DNS subdomain name</a>.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>PersistentVolumeClaim<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>myclaim<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>accessModes</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- ReadWriteOnce<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>volumeMode</span>:<span style=color:#bbb> </span>Filesystem<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>resources</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>requests</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>storage</span>:<span style=color:#bbb> </span>8Gi<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>storageClassName</span>:<span style=color:#bbb> </span>slow<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>selector</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>matchLabels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>release</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;stable&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>matchExpressions</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- {<span style=color:green;font-weight:700>key: environment, operator: In, values</span>:<span style=color:#bbb> </span>[dev]}<span style=color:#bbb>
</span></span></span></code></pre></div><h3 id=access-modes-1>Access Modes</h3><p>Claims use <a href=#access-modes>the same conventions as volumes</a> when requesting storage with specific access modes.</p><h3 id=volume-modes>Volume Modes</h3><p>Claims use <a href=#volume-mode>the same convention as volumes</a> to indicate the consumption of the volume as either a filesystem or block device.</p><h3 id=resources>Resources</h3><p>Claims, like Pods, can request specific quantities of a resource. In this case, the request is for storage. The same <a href=https://git.k8s.io/design-proposals-archive/scheduling/resources.md>resource model</a> applies to both volumes and claims.</p><h3 id=selector>Selector</h3><p>Claims can specify a <a href=/docs/concepts/overview/working-with-objects/labels/#label-selectors>label selector</a> to further filter the set of volumes. Only the volumes whose labels match the selector can be bound to the claim. The selector can consist of two fields:</p><ul><li><code>matchLabels</code> - the volume must have a label with this value</li><li><code>matchExpressions</code> - a list of requirements made by specifying key, list of values, and operator that relates the key and values. Valid operators include In, NotIn, Exists, and DoesNotExist.</li></ul><p>All of the requirements, from both <code>matchLabels</code> and <code>matchExpressions</code>, are ANDed together – they must all be satisfied in order to match.</p><h3 id=class-1>Class</h3><p>A claim can request a particular class by specifying the name of a
<a href=/docs/concepts/storage/storage-classes/>StorageClass</a>
using the attribute <code>storageClassName</code>.
Only PVs of the requested class, ones with the same <code>storageClassName</code> as the PVC, can
be bound to the PVC.</p><p>PVCs don't necessarily have to request a class. A PVC with its <code>storageClassName</code> set
equal to <code>""</code> is always interpreted to be requesting a PV with no class, so it
can only be bound to PVs with no class (no annotation or one set equal to
<code>""</code>). A PVC with no <code>storageClassName</code> is not quite the same and is treated differently
by the cluster, depending on whether the
<a href=/docs/reference/access-authn-authz/admission-controllers/#defaultstorageclass><code>DefaultStorageClass</code> admission plugin</a>
is turned on.</p><ul><li>If the admission plugin is turned on, the administrator may specify a
default StorageClass. All PVCs that have no <code>storageClassName</code> can be bound only to
PVs of that default. Specifying a default StorageClass is done by setting the
annotation <code>storageclass.kubernetes.io/is-default-class</code> equal to <code>true</code> in
a StorageClass object. If the administrator does not specify a default, the
cluster responds to PVC creation as if the admission plugin were turned off. If
more than one default is specified, the admission plugin forbids the creation of
all PVCs.</li><li>If the admission plugin is turned off, there is no notion of a default
StorageClass. All PVCs that have <code>storageClassName</code> set to <code>""</code> can be
bound only to PVs that have <code>storageClassName</code> also set to <code>""</code>.
However, PVCs with missing <code>storageClassName</code> can be updated later once
default StorageClass becomes available. If the PVC gets updated it will no
longer bind to PVs that have <code>storageClassName</code> also set to <code>""</code>.</li></ul><p>See <a href=#retroactive-default-storageclass-assignment>retroactive default StorageClass assignment</a> for more details.</p><p>Depending on installation method, a default StorageClass may be deployed
to a Kubernetes cluster by addon manager during installation.</p><p>When a PVC specifies a <code>selector</code> in addition to requesting a StorageClass,
the requirements are ANDed together: only a PV of the requested class and with
the requested labels may be bound to the PVC.</p><div class="alert alert-info note callout" role=alert><strong>Note:</strong> Currently, a PVC with a non-empty <code>selector</code> can't have a PV dynamically provisioned for it.</div><p>In the past, the annotation <code>volume.beta.kubernetes.io/storage-class</code> was used instead
of <code>storageClassName</code> attribute. This annotation is still working; however,
it won't be supported in a future Kubernetes release.</p><h4 id=retroactive-default-storageclass-assignment>Retroactive default StorageClass assignment</h4><div style=margin-top:10px;margin-bottom:10px><b>FEATURE STATE:</b> <code>Kubernetes v1.25 [alpha]</code></div><p>You can create a PersistentVolumeClaim without specifying a <code>storageClassName</code> for the new PVC, and you can do so even when no default StorageClass exists in your cluster. In this case, the new PVC creates as you defined it, and the <code>storageClassName</code> of that PVC remains unset until default becomes available.
However, if you enable the <a href=/docs/reference/command-line-tools-reference/feature-gates/><code>RetroactiveDefaultStorageClass</code> feature gate</a> then Kubernetes behaves differently: existing PVCs without <code>storageClassName</code> update to use the new default StorageClass.</p><p>When a default StorageClass becomes available, the control plane identifies any existing PVCs without <code>storageClassName</code>. For the PVCs that either have an empty value for <code>storageClassName</code> or do not have this key, the control plane then updates those PVCs to set <code>storageClassName</code> to match the new default StorageClass. If you have an existing PVC where the <code>storageClassName</code> is <code>""</code>, and you configure a default StorageClass, then this PVC will not get updated.</p><p>In order to keep binding to PVs with <code>storageClassName</code> set to <code>""</code> (while a default StorageClass is present), you need to set the <code>storageClassName</code> of the associated PVC to <code>""</code>.</p><p>This behavior helps administrators change default StorageClass by removing the old one first and then creating or setting another one. This brief window while there is no default causes PVCs without <code>storageClassName</code> created at that time to not have any default, but due to the retroactive default StorageClass assignment this way of changing defaults is safe.</p><h2 id=claims-as-volumes>Claims As Volumes</h2><p>Pods access storage by using the claim as a volume. Claims must exist in the same namespace as the Pod using the claim. The cluster finds the claim in the Pod's namespace and uses it to get the PersistentVolume backing the claim. The volume is then mounted to the host and into the Pod.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>mypod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>myfrontend<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>nginx<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>volumeMounts</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- <span style=color:green;font-weight:700>mountPath</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;/var/www/html&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>mypd<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>volumes</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>mypd<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>persistentVolumeClaim</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>claimName</span>:<span style=color:#bbb> </span>myclaim<span style=color:#bbb>
</span></span></span></code></pre></div><h3 id=a-note-on-namespaces>A Note on Namespaces</h3><p>PersistentVolumes binds are exclusive, and since PersistentVolumeClaims are namespaced objects, mounting claims with "Many" modes (<code>ROX</code>, <code>RWX</code>) is only possible within one namespace.</p><h3 id=persistentvolumes-typed-hostpath>PersistentVolumes typed <code>hostPath</code></h3><p>A <code>hostPath</code> PersistentVolume uses a file or directory on the Node to emulate network-attached storage.
See <a href=/docs/tasks/configure-pod-container/configure-persistent-volume-storage/#create-a-persistentvolume>an example of <code>hostPath</code> typed volume</a>.</p><h2 id=raw-block-volume-support>Raw Block Volume Support</h2><div style=margin-top:10px;margin-bottom:10px><b>FEATURE STATE:</b> <code>Kubernetes v1.18 [stable]</code></div><p>The following volume plugins support raw block volumes, including dynamic provisioning where
applicable:</p><ul><li>AWSElasticBlockStore</li><li>AzureDisk</li><li>CSI</li><li>FC (Fibre Channel)</li><li>GCEPersistentDisk</li><li>iSCSI</li><li>Local volume</li><li>OpenStack Cinder</li><li>RBD (Ceph Block Device)</li><li>VsphereVolume</li></ul><h3 id=persistent-volume-using-a-raw-block-volume>PersistentVolume using a Raw Block Volume</h3><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>PersistentVolume<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>block-pv<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>capacity</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>storage</span>:<span style=color:#bbb> </span>10Gi<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>accessModes</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- ReadWriteOnce<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>volumeMode</span>:<span style=color:#bbb> </span>Block<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>persistentVolumeReclaimPolicy</span>:<span style=color:#bbb> </span>Retain<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>fc</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>targetWWNs</span>:<span style=color:#bbb> </span>[<span style=color:#b44>&#34;50060e801049cfd1&#34;</span>]<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>lun</span>:<span style=color:#bbb> </span><span style=color:#666>0</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>readOnly</span>:<span style=color:#bbb> </span><span style=color:#a2f;font-weight:700>false</span><span style=color:#bbb>
</span></span></span></code></pre></div><h3 id=persistent-volume-claim-requesting-a-raw-block-volume>PersistentVolumeClaim requesting a Raw Block Volume</h3><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>PersistentVolumeClaim<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>block-pvc<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>accessModes</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- ReadWriteOnce<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>volumeMode</span>:<span style=color:#bbb> </span>Block<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>resources</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>requests</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>storage</span>:<span style=color:#bbb> </span>10Gi<span style=color:#bbb>
</span></span></span></code></pre></div><h3 id=pod-specification-adding-raw-block-device-path-in-container>Pod specification adding Raw Block Device path in container</h3><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>pod-with-block-volume<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>fc-container<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>fedora:26<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>command</span>:<span style=color:#bbb> </span>[<span style=color:#b44>&#34;/bin/sh&#34;</span>,<span style=color:#bbb> </span><span style=color:#b44>&#34;-c&#34;</span>]<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>args</span>:<span style=color:#bbb> </span>[<span style=color:#bbb> </span><span style=color:#b44>&#34;tail -f /dev/null&#34;</span><span style=color:#bbb> </span>]<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>volumeDevices</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>data<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>devicePath</span>:<span style=color:#bbb> </span>/dev/xvda<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>volumes</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>data<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>persistentVolumeClaim</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>claimName</span>:<span style=color:#bbb> </span>block-pvc<span style=color:#bbb>
</span></span></span></code></pre></div><div class="alert alert-info note callout" role=alert><strong>Note:</strong> When adding a raw block device for a Pod, you specify the device path in the container instead of a mount path.</div><h3 id=binding-block-volumes>Binding Block Volumes</h3><p>If a user requests a raw block volume by indicating this using the <code>volumeMode</code> field in the PersistentVolumeClaim spec, the binding rules differ slightly from previous releases that didn't consider this mode as part of the spec.
Listed is a table of possible combinations the user and admin might specify for requesting a raw block device. The table indicates if the volume will be bound or not given the combinations:
Volume binding matrix for statically provisioned volumes:</p><table><thead><tr><th>PV volumeMode</th><th style=text-align:center>PVC volumeMode</th><th style=text-align:right>Result</th></tr></thead><tbody><tr><td>unspecified</td><td style=text-align:center>unspecified</td><td style=text-align:right>BIND</td></tr><tr><td>unspecified</td><td style=text-align:center>Block</td><td style=text-align:right>NO BIND</td></tr><tr><td>unspecified</td><td style=text-align:center>Filesystem</td><td style=text-align:right>BIND</td></tr><tr><td>Block</td><td style=text-align:center>unspecified</td><td style=text-align:right>NO BIND</td></tr><tr><td>Block</td><td style=text-align:center>Block</td><td style=text-align:right>BIND</td></tr><tr><td>Block</td><td style=text-align:center>Filesystem</td><td style=text-align:right>NO BIND</td></tr><tr><td>Filesystem</td><td style=text-align:center>Filesystem</td><td style=text-align:right>BIND</td></tr><tr><td>Filesystem</td><td style=text-align:center>Block</td><td style=text-align:right>NO BIND</td></tr><tr><td>Filesystem</td><td style=text-align:center>unspecified</td><td style=text-align:right>BIND</td></tr></tbody></table><div class="alert alert-info note callout" role=alert><strong>Note:</strong> Only statically provisioned volumes are supported for alpha release. Administrators should take care to consider these values when working with raw block devices.</div><h2 id=volume-snapshot-and-restore-volume-from-snapshot-support>Volume Snapshot and Restore Volume from Snapshot Support</h2><div style=margin-top:10px;margin-bottom:10px><b>FEATURE STATE:</b> <code>Kubernetes v1.20 [stable]</code></div><p>Volume snapshots only support the out-of-tree CSI volume plugins. For details, see <a href=/docs/concepts/storage/volume-snapshots/>Volume Snapshots</a>.
In-tree volume plugins are deprecated. You can read about the deprecated volume plugins in the <a href=https://github.com/kubernetes/community/blob/master/sig-storage/volume-plugin-faq.md>Volume Plugin FAQ</a>.</p><h3 id=create-persistent-volume-claim-from-volume-snapshot>Create a PersistentVolumeClaim from a Volume Snapshot</h3><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>PersistentVolumeClaim<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>restore-pvc<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>storageClassName</span>:<span style=color:#bbb> </span>csi-hostpath-sc<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>dataSource</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>new-snapshot-test<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>VolumeSnapshot<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>apiGroup</span>:<span style=color:#bbb> </span>snapshot.storage.k8s.io<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>accessModes</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- ReadWriteOnce<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>resources</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>requests</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>storage</span>:<span style=color:#bbb> </span>10Gi<span style=color:#bbb>
</span></span></span></code></pre></div><h2 id=volume-cloning>Volume Cloning</h2><p><a href=/docs/concepts/storage/volume-pvc-datasource/>Volume Cloning</a> only available for CSI volume plugins.</p><h3 id=create-persistent-volume-claim-from-an-existing-pvc>Create PersistentVolumeClaim from an existing PVC</h3><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>PersistentVolumeClaim<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>cloned-pvc<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>storageClassName</span>:<span style=color:#bbb> </span>my-csi-plugin<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>dataSource</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>existing-src-pvc-name<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>PersistentVolumeClaim<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>accessModes</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- ReadWriteOnce<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>resources</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>requests</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>storage</span>:<span style=color:#bbb> </span>10Gi<span style=color:#bbb>
</span></span></span></code></pre></div><h2 id=volume-populators-and-data-sources>Volume populators and data sources</h2><div style=margin-top:10px;margin-bottom:10px><b>FEATURE STATE:</b> <code>Kubernetes v1.24 [beta]</code></div><p>Kubernetes supports custom volume populators.
To use custom volume populators, you must enable the <code>AnyVolumeDataSource</code>
<a href=/docs/reference/command-line-tools-reference/feature-gates/>feature gate</a> for
the kube-apiserver and kube-controller-manager.</p><p>Volume populators take advantage of a PVC spec field called <code>dataSourceRef</code>. Unlike the
<code>dataSource</code> field, which can only contain either a reference to another PersistentVolumeClaim
or to a VolumeSnapshot, the <code>dataSourceRef</code> field can contain a reference to any object in the
same namespace, except for core objects other than PVCs. For clusters that have the feature
gate enabled, use of the <code>dataSourceRef</code> is preferred over <code>dataSource</code>.</p><h2 id=data-source-references>Data source references</h2><p>The <code>dataSourceRef</code> field behaves almost the same as the <code>dataSource</code> field. If either one is
specified while the other is not, the API server will give both fields the same value. Neither
field can be changed after creation, and attempting to specify different values for the two
fields will result in a validation error. Therefore the two fields will always have the same
contents.</p><p>There are two differences between the <code>dataSourceRef</code> field and the <code>dataSource</code> field that
users should be aware of:</p><ul><li>The <code>dataSource</code> field ignores invalid values (as if the field was blank) while the
<code>dataSourceRef</code> field never ignores values and will cause an error if an invalid value is
used. Invalid values are any core object (objects with no apiGroup) except for PVCs.</li><li>The <code>dataSourceRef</code> field may contain different types of objects, while the <code>dataSource</code> field
only allows PVCs and VolumeSnapshots.</li></ul><p>Users should always use <code>dataSourceRef</code> on clusters that have the feature gate enabled, and
fall back to <code>dataSource</code> on clusters that do not. It is not necessary to look at both fields
under any circumstance. The duplicated values with slightly different semantics exist only for
backwards compatibility. In particular, a mixture of older and newer controllers are able to
interoperate because the fields are the same.</p><h3 id=using-volume-populators>Using volume populators</h3><p>Volume populators are <a class=glossary-tooltip title='A control loop that watches the shared state of the cluster through the apiserver and makes changes attempting to move the current state towards the desired state.' data-toggle=tooltip data-placement=top href=/docs/concepts/architecture/controller/ target=_blank aria-label=controllers>controllers</a> that can
create non-empty volumes, where the contents of the volume are determined by a Custom Resource.
Users create a populated volume by referring to a Custom Resource using the <code>dataSourceRef</code> field:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>PersistentVolumeClaim<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>populated-pvc<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>dataSourceRef</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>example-name<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>ExampleDataSource<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>apiGroup</span>:<span style=color:#bbb> </span>example.storage.k8s.io<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>accessModes</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- ReadWriteOnce<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>resources</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>requests</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>storage</span>:<span style=color:#bbb> </span>10Gi<span style=color:#bbb>
</span></span></span></code></pre></div><p>Because volume populators are external components, attempts to create a PVC that uses one
can fail if not all the correct components are installed. External controllers should generate
events on the PVC to provide feedback on the status of the creation, including warnings if
the PVC cannot be created due to some missing component.</p><p>You can install the alpha <a href=https://github.com/kubernetes-csi/volume-data-source-validator>volume data source validator</a>
controller into your cluster. That controller generates warning Events on a PVC in the case that no populator
is registered to handle that kind of data source. When a suitable populator is installed for a PVC, it's the
responsibility of that populator controller to report Events that relate to volume creation and issues during
the process.</p><h2 id=writing-portable-configuration>Writing Portable Configuration</h2><p>If you're writing configuration templates or examples that run on a wide range of clusters
and need persistent storage, it is recommended that you use the following pattern:</p><ul><li>Include PersistentVolumeClaim objects in your bundle of config (alongside
Deployments, ConfigMaps, etc).</li><li>Do not include PersistentVolume objects in the config, since the user instantiating
the config may not have permission to create PersistentVolumes.</li><li>Give the user the option of providing a storage class name when instantiating
the template.<ul><li>If the user provides a storage class name, put that value into the
<code>persistentVolumeClaim.storageClassName</code> field.
This will cause the PVC to match the right storage
class if the cluster has StorageClasses enabled by the admin.</li><li>If the user does not provide a storage class name, leave the
<code>persistentVolumeClaim.storageClassName</code> field as nil. This will cause a
PV to be automatically provisioned for the user with the default StorageClass
in the cluster. Many cluster environments have a default StorageClass installed,
or administrators can create their own default StorageClass.</li></ul></li><li>In your tooling, watch for PVCs that are not getting bound after some time
and surface this to the user, as this may indicate that the cluster has no
dynamic storage support (in which case the user should create a matching PV)
or the cluster has no storage system (in which case the user cannot deploy
config requiring PVCs).</li></ul><h2 id=what-s-next>What's next</h2><ul><li>Learn more about <a href=/docs/tasks/configure-pod-container/configure-persistent-volume-storage/#create-a-persistentvolume>Creating a PersistentVolume</a>.</li><li>Learn more about <a href=/docs/tasks/configure-pod-container/configure-persistent-volume-storage/#create-a-persistentvolumeclaim>Creating a PersistentVolumeClaim</a>.</li><li>Read the <a href=https://git.k8s.io/design-proposals-archive/storage/persistent-storage.md>Persistent Storage design document</a>.</li></ul><h3 id=reference>API references</h3><p>Read about the APIs described in this page:</p><ul><li><a href=/docs/reference/kubernetes-api/config-and-storage-resources/persistent-volume-v1/><code>PersistentVolume</code></a></li><li><a href=/docs/reference/kubernetes-api/config-and-storage-resources/persistent-volume-claim-v1/><code>PersistentVolumeClaim</code></a></li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-2db414b26d4daec3ebed19dd837830c3>3 - Projected Volumes</h1><p>This document describes <em>projected volumes</em> in Kubernetes. Familiarity with <a href=/docs/concepts/storage/volumes/>volumes</a> is suggested.</p><h2 id=introduction>Introduction</h2><p>A <code>projected</code> volume maps several existing volume sources into the same directory.</p><p>Currently, the following types of volume sources can be projected:</p><ul><li><a href=/docs/concepts/storage/volumes/#secret><code>secret</code></a></li><li><a href=/docs/concepts/storage/volumes/#downwardapi><code>downwardAPI</code></a></li><li><a href=/docs/concepts/storage/volumes/#configmap><code>configMap</code></a></li><li><a href=#serviceaccounttoken><code>serviceAccountToken</code></a></li></ul><p>All sources are required to be in the same namespace as the Pod. For more details,
see the <a href=https://git.k8s.io/design-proposals-archive/node/all-in-one-volume.md>all-in-one volume</a> design document.</p><h3 id=example-configuration-secret-downwardapi-configmap>Example configuration with a secret, a downwardAPI, and a configMap</h3><div class=highlight><div class=copy-code-icon style=text-align:right><a href=https://raw.githubusercontent.com/kubernetes/website/main/content/en/examples/pods/storage/projected-secret-downwardapi-configmap.yaml download=pods/storage/projected-secret-downwardapi-configmap.yaml><code>pods/storage/projected-secret-downwardapi-configmap.yaml</code></a>
<img src=/images/copycode.svg style=max-height:24px;cursor:pointer onclick='copyCode("pods-storage-projected-secret-downwardapi-configmap-yaml")' title="Copy pods/storage/projected-secret-downwardapi-configmap.yaml to clipboard"></img></div><div class=includecode id=pods-storage-projected-secret-downwardapi-configmap-yaml><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>volume-test<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>container-test<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>busybox:1.28<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>volumeMounts</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>all-in-one<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>mountPath</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;/projected-volume&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>readOnly</span>:<span style=color:#bbb> </span><span style=color:#a2f;font-weight:700>true</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>volumes</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>all-in-one<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>projected</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>sources</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- <span style=color:green;font-weight:700>secret</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>mysecret<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>items</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>            </span>- <span style=color:green;font-weight:700>key</span>:<span style=color:#bbb> </span>username<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>              </span><span style=color:green;font-weight:700>path</span>:<span style=color:#bbb> </span>my-group/my-username<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- <span style=color:green;font-weight:700>downwardAPI</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>items</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>            </span>- <span style=color:green;font-weight:700>path</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;labels&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>              </span><span style=color:green;font-weight:700>fieldRef</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>                </span><span style=color:green;font-weight:700>fieldPath</span>:<span style=color:#bbb> </span>metadata.labels<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>            </span>- <span style=color:green;font-weight:700>path</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;cpu_limit&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>              </span><span style=color:green;font-weight:700>resourceFieldRef</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>                </span><span style=color:green;font-weight:700>containerName</span>:<span style=color:#bbb> </span>container-test<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>                </span><span style=color:green;font-weight:700>resource</span>:<span style=color:#bbb> </span>limits.cpu<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- <span style=color:green;font-weight:700>configMap</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>myconfigmap<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>items</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>            </span>- <span style=color:green;font-weight:700>key</span>:<span style=color:#bbb> </span>config<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>              </span><span style=color:green;font-weight:700>path</span>:<span style=color:#bbb> </span>my-group/my-config<span style=color:#bbb>
</span></span></span></code></pre></div></div></div><h3 id=example-configuration-secrets-nondefault-permission-mode>Example configuration: secrets with a non-default permission mode set</h3><div class=highlight><div class=copy-code-icon style=text-align:right><a href=https://raw.githubusercontent.com/kubernetes/website/main/content/en/examples/pods/storage/projected-secrets-nondefault-permission-mode.yaml download=pods/storage/projected-secrets-nondefault-permission-mode.yaml><code>pods/storage/projected-secrets-nondefault-permission-mode.yaml</code></a>
<img src=/images/copycode.svg style=max-height:24px;cursor:pointer onclick='copyCode("pods-storage-projected-secrets-nondefault-permission-mode-yaml")' title="Copy pods/storage/projected-secrets-nondefault-permission-mode.yaml to clipboard"></img></div><div class=includecode id=pods-storage-projected-secrets-nondefault-permission-mode-yaml><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>volume-test<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>container-test<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>busybox:1.28<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>volumeMounts</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>all-in-one<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>mountPath</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;/projected-volume&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>readOnly</span>:<span style=color:#bbb> </span><span style=color:#a2f;font-weight:700>true</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>volumes</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>all-in-one<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>projected</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>sources</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- <span style=color:green;font-weight:700>secret</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>mysecret<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>items</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>            </span>- <span style=color:green;font-weight:700>key</span>:<span style=color:#bbb> </span>username<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>              </span><span style=color:green;font-weight:700>path</span>:<span style=color:#bbb> </span>my-group/my-username<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- <span style=color:green;font-weight:700>secret</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>mysecret2<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>items</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>            </span>- <span style=color:green;font-weight:700>key</span>:<span style=color:#bbb> </span>password<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>              </span><span style=color:green;font-weight:700>path</span>:<span style=color:#bbb> </span>my-group/my-password<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>              </span><span style=color:green;font-weight:700>mode</span>:<span style=color:#bbb> </span><span style=color:#666>511</span><span style=color:#bbb>
</span></span></span></code></pre></div></div></div><p>Each projected volume source is listed in the spec under <code>sources</code>. The
parameters are nearly the same with two exceptions:</p><ul><li>For secrets, the <code>secretName</code> field has been changed to <code>name</code> to be consistent
with ConfigMap naming.</li><li>The <code>defaultMode</code> can only be specified at the projected level and not for each
volume source. However, as illustrated above, you can explicitly set the <code>mode</code>
for each individual projection.</li></ul><h2 id=serviceaccounttoken>serviceAccountToken projected volumes</h2><p>You can inject the token for the current <a href=/docs/reference/access-authn-authz/authentication/#service-account-tokens>service account</a>
into a Pod at a specified path. For example:</p><div class=highlight><div class=copy-code-icon style=text-align:right><a href=https://raw.githubusercontent.com/kubernetes/website/main/content/en/examples/pods/storage/projected-service-account-token.yaml download=pods/storage/projected-service-account-token.yaml><code>pods/storage/projected-service-account-token.yaml</code></a>
<img src=/images/copycode.svg style=max-height:24px;cursor:pointer onclick='copyCode("pods-storage-projected-service-account-token-yaml")' title="Copy pods/storage/projected-service-account-token.yaml to clipboard"></img></div><div class=includecode id=pods-storage-projected-service-account-token-yaml><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>sa-token-test<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>container-test<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>busybox:1.28<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>volumeMounts</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>token-vol<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>mountPath</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;/service-account&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>readOnly</span>:<span style=color:#bbb> </span><span style=color:#a2f;font-weight:700>true</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>serviceAccountName</span>:<span style=color:#bbb> </span>default<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>volumes</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>token-vol<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>projected</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>sources</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- <span style=color:green;font-weight:700>serviceAccountToken</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>audience</span>:<span style=color:#bbb> </span>api<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>expirationSeconds</span>:<span style=color:#bbb> </span><span style=color:#666>3600</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>path</span>:<span style=color:#bbb> </span>token<span style=color:#bbb>
</span></span></span></code></pre></div></div></div><p>The example Pod has a projected volume containing the injected service account
token. Containers in this Pod can use that token to access the Kubernetes API
server, authenticating with the identity of <a href=/docs/tasks/configure-pod-container/configure-service-account/>the pod's ServiceAccount</a>.
The <code>audience</code> field contains the intended audience of the
token. A recipient of the token must identify itself with an identifier specified
in the audience of the token, and otherwise should reject the token. This field
is optional and it defaults to the identifier of the API server.</p><p>The <code>expirationSeconds</code> is the expected duration of validity of the service account
token. It defaults to 1 hour and must be at least 10 minutes (600 seconds). An administrator
can also limit its maximum value by specifying the <code>--service-account-max-token-expiration</code>
option for the API server. The <code>path</code> field specifies a relative path to the mount point
of the projected volume.</p><div class="alert alert-info note callout" role=alert><strong>Note:</strong> A container using a projected volume source as a <a href=/docs/concepts/storage/volumes/#using-subpath><code>subPath</code></a>
volume mount will not receive updates for those volume sources.</div><h2 id=securitycontext-interactions>SecurityContext interactions</h2><p>The <a href=https://git.k8s.io/enhancements/keps/sig-storage/2451-service-account-token-volumes#proposal>proposal</a> for file permission handling in projected service account volume enhancement introduced the projected files having the correct owner permissions set.</p><h3 id=linux>Linux</h3><p>In Linux pods that have a projected volume and <code>RunAsUser</code> set in the Pod
<a href=/docs/reference/kubernetes-api/workload-resources/pod-v1/#security-context><code>SecurityContext</code></a>,
the projected files have the correct ownership set including container user
ownership.</p><p>When all containers in a pod have the same <code>runAsUser</code> set in their
<a href=/docs/reference/kubernetes-api/workload-resources/pod-v1/#security-context><code>PodSecurityContext</code></a>
or container
<a href=/docs/reference/kubernetes-api/workload-resources/pod-v1/#security-context-1><code>SecurityContext</code></a>,
then the kubelet ensures that the contents of the <code>serviceAccountToken</code> volume are owned by that user,
and the token file has its permission mode set to <code>0600</code>.</p><div class="alert alert-info note callout" role=alert><strong>Note:</strong><p><a class=glossary-tooltip title='A type of container type that you can temporarily run inside a Pod' data-toggle=tooltip data-placement=top href=/docs/concepts/workloads/pods/ephemeral-containers/ target=_blank aria-label='Ephemeral containers'>Ephemeral containers</a>
added to a Pod after it is created do <em>not</em> change volume permissions that were
set when the pod was created.</p><p>If a Pod's <code>serviceAccountToken</code> volume permissions were set to <code>0600</code> because
all other containers in the Pod have the same <code>runAsUser</code>, ephemeral
containers must use the same <code>runAsUser</code> to be able to read the token.</p></div><h3 id=windows>Windows</h3><p>In Windows pods that have a projected volume and <code>RunAsUsername</code> set in the
Pod <code>SecurityContext</code>, the ownership is not enforced due to the way user
accounts are managed in Windows. Windows stores and manages local user and group
accounts in a database file called Security Account Manager (SAM). Each
container maintains its own instance of the SAM database, to which the host has
no visibility into while the container is running. Windows containers are
designed to run the user mode portion of the OS in isolation from the host,
hence the maintenance of a virtual SAM database. As a result, the kubelet running
on the host does not have the ability to dynamically configure host file
ownership for virtualized container accounts. It is recommended that if files on
the host machine are to be shared with the container then they should be placed
into their own volume mount outside of <code>C:\</code>.</p><p>By default, the projected files will have the following ownership as shown for
an example projected volume file:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-powershell data-lang=powershell><span style=display:flex><span><span style=color:#a2f>PS </span>C:\&gt; <span style=color:#a2f>Get-Acl</span> C:\var\run\secrets\kubernetes.io\serviceaccount\..2021_08_31_22_22_18.<span style=color:#666>318230061</span>\ca.crt | <span style=color:#a2f>Format-List</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>Path   <span>:</span> Microsoft.PowerShell.Core\FileSystem::C:\var\run\secrets\kubernetes.io\serviceaccount\..2021_08_31_22_22_18.<span style=color:#666>318230061</span>\ca.crt
</span></span><span style=display:flex><span>Owner  <span>:</span> BUILTIN\Administrators
</span></span><span style=display:flex><span><span style=color:#a2f>Group </span> <span>:</span> NT AUTHORITY\SYSTEM
</span></span><span style=display:flex><span>Access <span>:</span> NT AUTHORITY\SYSTEM Allow  FullControl
</span></span><span style=display:flex><span>         BUILTIN\Administrators Allow  FullControl
</span></span><span style=display:flex><span>         BUILTIN\Users Allow  ReadAndExecute, Synchronize
</span></span><span style=display:flex><span>Audit  <span>:</span>
</span></span><span style=display:flex><span>Sddl   <span>:</span> O:BAG<span>:</span>SYD<span>:</span>AI(A;ID;FA;;;SY)(A;ID;FA;;;BA)(A;ID;0x1200a9;;;BU)
</span></span></code></pre></div><p>This implies all administrator users like <code>ContainerAdministrator</code> will have
read, write and execute access while, non-administrator users will have read and
execute access.</p><div class="alert alert-info note callout" role=alert><strong>Note:</strong><p>In general, granting the container access to the host is discouraged as it can
open the door for potential security exploits.</p><p>Creating a Windows Pod with <code>RunAsUser</code> in it's <code>SecurityContext</code> will result in
the Pod being stuck at <code>ContainerCreating</code> forever. So it is advised to not use
the Linux only <code>RunAsUser</code> option with Windows Pods.</p></div></div><div class=td-content style=page-break-before:always><h1 id=pg-df33eab51202c17bb0fe551d1d5cc5d2>4 - Ephemeral Volumes</h1><p>This document describes <em>ephemeral volumes</em> in Kubernetes. Familiarity
with <a href=/docs/concepts/storage/volumes/>volumes</a> is suggested, in
particular PersistentVolumeClaim and PersistentVolume.</p><p>Some application need additional storage but don't care whether that
data is stored persistently across restarts. For example, caching
services are often limited by memory size and can move infrequently
used data into storage that is slower than memory with little impact
on overall performance.</p><p>Other applications expect some read-only input data to be present in
files, like configuration data or secret keys.</p><p><em>Ephemeral volumes</em> are designed for these use cases. Because volumes
follow the Pod's lifetime and get created and deleted along with the
Pod, Pods can be stopped and restarted without being limited to where
some persistent volume is available.</p><p>Ephemeral volumes are specified <em>inline</em> in the Pod spec, which
simplifies application deployment and management.</p><h3 id=types-of-ephemeral-volumes>Types of ephemeral volumes</h3><p>Kubernetes supports several different kinds of ephemeral volumes for
different purposes:</p><ul><li><a href=/docs/concepts/storage/volumes/#emptydir>emptyDir</a>: empty at Pod startup,
with storage coming locally from the kubelet base directory (usually
the root disk) or RAM</li><li><a href=/docs/concepts/storage/volumes/#configmap>configMap</a>,
<a href=/docs/concepts/storage/volumes/#downwardapi>downwardAPI</a>,
<a href=/docs/concepts/storage/volumes/#secret>secret</a>: inject different
kinds of Kubernetes data into a Pod</li><li><a href=#csi-ephemeral-volumes>CSI ephemeral volumes</a>:
similar to the previous volume kinds, but provided by special
<a href=https://github.com/container-storage-interface/spec/blob/master/spec.md>CSI drivers</a>
which specifically <a href=https://kubernetes-csi.github.io/docs/drivers.html>support this feature</a></li><li><a href=#generic-ephemeral-volumes>generic ephemeral volumes</a>, which
can be provided by all storage drivers that also support persistent volumes</li></ul><p><code>emptyDir</code>, <code>configMap</code>, <code>downwardAPI</code>, <code>secret</code> are provided as
<a href=/docs/concepts/configuration/manage-resources-containers/#local-ephemeral-storage>local ephemeral
storage</a>.
They are managed by kubelet on each node.</p><p>CSI ephemeral volumes <em>must</em> be provided by third-party CSI storage
drivers.</p><p>Generic ephemeral volumes <em>can</em> be provided by third-party CSI storage
drivers, but also by any other storage driver that supports dynamic
provisioning. Some CSI drivers are written specifically for CSI
ephemeral volumes and do not support dynamic provisioning: those then
cannot be used for generic ephemeral volumes.</p><p>The advantage of using third-party drivers is that they can offer
functionality that Kubernetes itself does not support, for example
storage with different performance characteristics than the disk that
is managed by kubelet, or injecting different data.</p><h3 id=csi-ephemeral-volumes>CSI ephemeral volumes</h3><div style=margin-top:10px;margin-bottom:10px><b>FEATURE STATE:</b> <code>Kubernetes v1.25 [stable]</code></div><div class="alert alert-info note callout" role=alert><strong>Note:</strong> CSI ephemeral volumes are only supported by a subset of CSI drivers.
The Kubernetes CSI <a href=https://kubernetes-csi.github.io/docs/drivers.html>Drivers list</a>
shows which drivers support ephemeral volumes.</div><p>Conceptually, CSI ephemeral volumes are similar to <code>configMap</code>,
<code>downwardAPI</code> and <code>secret</code> volume types: the storage is managed locally on each
node and is created together with other local resources after a Pod has been
scheduled onto a node. Kubernetes has no concept of rescheduling Pods
anymore at this stage. Volume creation has to be unlikely to fail,
otherwise Pod startup gets stuck. In particular, <a href=/docs/concepts/storage/storage-capacity/>storage capacity
aware Pod scheduling</a> is <em>not</em>
supported for these volumes. They are currently also not covered by
the storage resource usage limits of a Pod, because that is something
that kubelet can only enforce for storage that it manages itself.</p><p>Here's an example manifest for a Pod that uses CSI ephemeral storage:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>my-csi-app<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>my-frontend<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>busybox:1.28<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>volumeMounts</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- <span style=color:green;font-weight:700>mountPath</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;/data&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>my-csi-inline-vol<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>command</span>:<span style=color:#bbb> </span>[<span style=color:#bbb> </span><span style=color:#b44>&#34;sleep&#34;</span>,<span style=color:#bbb> </span><span style=color:#b44>&#34;1000000&#34;</span><span style=color:#bbb> </span>]<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>volumes</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>my-csi-inline-vol<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>csi</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>driver</span>:<span style=color:#bbb> </span>inline.storage.kubernetes.io<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>volumeAttributes</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>foo</span>:<span style=color:#bbb> </span>bar<span style=color:#bbb>
</span></span></span></code></pre></div><p>The <code>volumeAttributes</code> determine what volume is prepared by the
driver. These attributes are specific to each driver and not
standardized. See the documentation of each CSI driver for further
instructions.</p><h3 id=csi-driver-restrictions>CSI driver restrictions</h3><p>CSI ephemeral volumes allow users to provide <code>volumeAttributes</code>
directly to the CSI driver as part of the Pod spec. A CSI driver
allowing <code>volumeAttributes</code> that are typically restricted to
administrators is NOT suitable for use in an inline ephemeral volume.
For example, parameters that are normally defined in the StorageClass
should not be exposed to users through the use of inline ephemeral volumes.</p><p>Cluster administrators who need to restrict the CSI drivers that are
allowed to be used as inline volumes within a Pod spec may do so by:</p><ul><li>Removing <code>Ephemeral</code> from <code>volumeLifecycleModes</code> in the CSIDriver spec, which prevents the
driver from being used as an inline ephemeral volume.</li><li>Using an <a href=/docs/reference/access-authn-authz/extensible-admission-controllers/>admission webhook</a>
to restrict how this driver is used.</li></ul><h3 id=generic-ephemeral-volumes>Generic ephemeral volumes</h3><div style=margin-top:10px;margin-bottom:10px><b>FEATURE STATE:</b> <code>Kubernetes v1.23 [stable]</code></div><p>Generic ephemeral volumes are similar to <code>emptyDir</code> volumes in the
sense that they provide a per-pod directory for scratch data that is
usually empty after provisioning. But they may also have additional
features:</p><ul><li>Storage can be local or network-attached.</li><li>Volumes can have a fixed size that Pods are not able to exceed.</li><li>Volumes may have some initial data, depending on the driver and
parameters.</li><li>Typical operations on volumes are supported assuming that the driver
supports them, including
<a href=/docs/concepts/storage/volume-snapshots/>snapshotting</a>,
<a href=/docs/concepts/storage/volume-pvc-datasource/>cloning</a>,
<a href=/docs/concepts/storage/persistent-volumes/#expanding-persistent-volumes-claims>resizing</a>,
and <a href=/docs/concepts/storage/storage-capacity/>storage capacity tracking</a>.</li></ul><p>Example:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>my-app<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>my-frontend<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>busybox:1.28<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>volumeMounts</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- <span style=color:green;font-weight:700>mountPath</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;/scratch&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>scratch-volume<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>command</span>:<span style=color:#bbb> </span>[<span style=color:#bbb> </span><span style=color:#b44>&#34;sleep&#34;</span>,<span style=color:#bbb> </span><span style=color:#b44>&#34;1000000&#34;</span><span style=color:#bbb> </span>]<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>volumes</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>scratch-volume<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>ephemeral</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>volumeClaimTemplate</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>            </span><span style=color:green;font-weight:700>labels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>              </span><span style=color:green;font-weight:700>type</span>:<span style=color:#bbb> </span>my-frontend-volume<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>            </span><span style=color:green;font-weight:700>accessModes</span>:<span style=color:#bbb> </span>[<span style=color:#bbb> </span><span style=color:#b44>&#34;ReadWriteOnce&#34;</span><span style=color:#bbb> </span>]<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>            </span><span style=color:green;font-weight:700>storageClassName</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;scratch-storage-class&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>            </span><span style=color:green;font-weight:700>resources</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>              </span><span style=color:green;font-weight:700>requests</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>                </span><span style=color:green;font-weight:700>storage</span>:<span style=color:#bbb> </span>1Gi<span style=color:#bbb>
</span></span></span></code></pre></div><h3 id=lifecycle-and-persistentvolumeclaim>Lifecycle and PersistentVolumeClaim</h3><p>The key design idea is that the
<a href=/docs/reference/generated/kubernetes-api/v1.25/#ephemeralvolumesource-v1alpha1-core>parameters for a volume claim</a>
are allowed inside a volume source of the Pod. Labels, annotations and
the whole set of fields for a PersistentVolumeClaim are supported. When such a Pod gets
created, the ephemeral volume controller then creates an actual PersistentVolumeClaim
object in the same namespace as the Pod and ensures that the PersistentVolumeClaim
gets deleted when the Pod gets deleted.</p><p>That triggers volume binding and/or provisioning, either immediately if
the <a class=glossary-tooltip title='A StorageClass provides a way for administrators to describe different available storage types.' data-toggle=tooltip data-placement=top href=/docs/concepts/storage/storage-classes target=_blank aria-label=StorageClass>StorageClass</a> uses immediate volume binding or when the Pod is
tentatively scheduled onto a node (<code>WaitForFirstConsumer</code> volume
binding mode). The latter is recommended for generic ephemeral volumes
because then the scheduler is free to choose a suitable node for
the Pod. With immediate binding, the scheduler is forced to select a node that has
access to the volume once it is available.</p><p>In terms of <a href=/docs/concepts/architecture/garbage-collection/#owners-dependents>resource ownership</a>,
a Pod that has generic ephemeral storage is the owner of the PersistentVolumeClaim(s)
that provide that ephemeral storage. When the Pod is deleted,
the Kubernetes garbage collector deletes the PVC, which then usually
triggers deletion of the volume because the default reclaim policy of
storage classes is to delete volumes. You can create quasi-ephemeral local storage
using a StorageClass with a reclaim policy of <code>retain</code>: the storage outlives the Pod,
and in this case you need to ensure that volume clean up happens separately.</p><p>While these PVCs exist, they can be used like any other PVC. In
particular, they can be referenced as data source in volume cloning or
snapshotting. The PVC object also holds the current status of the
volume.</p><h3 id=persistentvolumeclaim-naming>PersistentVolumeClaim naming</h3><p>Naming of the automatically created PVCs is deterministic: the name is
a combination of Pod name and volume name, with a hyphen (<code>-</code>) in the
middle. In the example above, the PVC name will be
<code>my-app-scratch-volume</code>. This deterministic naming makes it easier to
interact with the PVC because one does not have to search for it once
the Pod name and volume name are known.</p><p>The deterministic naming also introduces a potential conflict between different
Pods (a Pod "pod-a" with volume "scratch" and another Pod with name
"pod" and volume "a-scratch" both end up with the same PVC name
"pod-a-scratch") and between Pods and manually created PVCs.</p><p>Such conflicts are detected: a PVC is only used for an ephemeral
volume if it was created for the Pod. This check is based on the
ownership relationship. An existing PVC is not overwritten or
modified. But this does not resolve the conflict because without the
right PVC, the Pod cannot start.</p><div class="alert alert-warning caution callout" role=alert><strong>Caution:</strong> Take care when naming Pods and volumes inside the
same namespace, so that these conflicts can't occur.</div><h3 id=security>Security</h3><p>Enabling the GenericEphemeralVolume feature allows users to create
PVCs indirectly if they can create Pods, even if they do not have
permission to create PVCs directly. Cluster administrators must be
aware of this. If this does not fit their security model, they should
use an <a href=/docs/reference/access-authn-authz/extensible-admission-controllers/>admission webhook</a>
that rejects objects like Pods that have a generic ephemeral volume.</p><p>The normal <a href=/docs/concepts/policy/resource-quotas/#storage-resource-quota>namespace quota for PVCs</a>
still applies, so even if users are allowed to use this new mechanism, they cannot use
it to circumvent other policies.</p><h2 id=what-s-next>What's next</h2><h3 id=ephemeral-volumes-managed-by-kubelet>Ephemeral volumes managed by kubelet</h3><p>See <a href=/docs/concepts/configuration/manage-resources-containers/#local-ephemeral-storage>local ephemeral storage</a>.</p><h3 id=csi-ephemeral-volumes-1>CSI ephemeral volumes</h3><ul><li>For more information on the design, see the
<a href=https://github.com/kubernetes/enhancements/blob/ad6021b3d61a49040a3f835e12c8bb5424db2bbb/keps/sig-storage/20190122-csi-inline-volumes.md>Ephemeral Inline CSI volumes KEP</a>.</li><li>For more information on further development of this feature, see the
<a href=https://github.com/kubernetes/enhancements/issues/596>enhancement tracking issue #596</a>.</li></ul><h3 id=generic-ephemeral-volumes-1>Generic ephemeral volumes</h3><ul><li>For more information on the design, see the
<a href=https://github.com/kubernetes/enhancements/blob/master/keps/sig-storage/1698-generic-ephemeral-volumes/README.md>Generic ephemeral inline volumes KEP</a>.</li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-f0276d05eef111249272a1c932a91e2c>5 - Storage Classes</h1><p>This document describes the concept of a StorageClass in Kubernetes. Familiarity
with <a href=/docs/concepts/storage/volumes/>volumes</a> and
<a href=/docs/concepts/storage/persistent-volumes>persistent volumes</a> is suggested.</p><h2 id=introduction>Introduction</h2><p>A StorageClass provides a way for administrators to describe the "classes" of
storage they offer. Different classes might map to quality-of-service levels,
or to backup policies, or to arbitrary policies determined by the cluster
administrators. Kubernetes itself is unopinionated about what classes
represent. This concept is sometimes called "profiles" in other storage
systems.</p><h2 id=the-storageclass-resource>The StorageClass Resource</h2><p>Each StorageClass contains the fields <code>provisioner</code>, <code>parameters</code>, and
<code>reclaimPolicy</code>, which are used when a PersistentVolume belonging to the
class needs to be dynamically provisioned.</p><p>The name of a StorageClass object is significant, and is how users can
request a particular class. Administrators set the name and other parameters
of a class when first creating StorageClass objects, and the objects cannot
be updated once they are created.</p><p>Administrators can specify a default StorageClass only for PVCs that don't
request any particular class to bind to: see the
<a href=/docs/concepts/storage/persistent-volumes/#persistentvolumeclaims>PersistentVolumeClaim section</a>
for details.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>storage.k8s.io/v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>StorageClass<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>standard<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>provisioner</span>:<span style=color:#bbb> </span>kubernetes.io/aws-ebs<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>parameters</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>type</span>:<span style=color:#bbb> </span>gp2<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>reclaimPolicy</span>:<span style=color:#bbb> </span>Retain<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>allowVolumeExpansion</span>:<span style=color:#bbb> </span><span style=color:#a2f;font-weight:700>true</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>mountOptions</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- debug<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>volumeBindingMode</span>:<span style=color:#bbb> </span>Immediate<span style=color:#bbb>
</span></span></span></code></pre></div><h3 id=provisioner>Provisioner</h3><p>Each StorageClass has a provisioner that determines what volume plugin is used
for provisioning PVs. This field must be specified.</p><table><thead><tr><th style=text-align:left>Volume Plugin</th><th style=text-align:center>Internal Provisioner</th><th style=text-align:center>Config Example</th></tr></thead><tbody><tr><td style=text-align:left>AWSElasticBlockStore</td><td style=text-align:center>✓</td><td style=text-align:center><a href=#aws-ebs>AWS EBS</a></td></tr><tr><td style=text-align:left>AzureFile</td><td style=text-align:center>✓</td><td style=text-align:center><a href=#azure-file>Azure File</a></td></tr><tr><td style=text-align:left>AzureDisk</td><td style=text-align:center>✓</td><td style=text-align:center><a href=#azure-disk>Azure Disk</a></td></tr><tr><td style=text-align:left>CephFS</td><td style=text-align:center>-</td><td style=text-align:center>-</td></tr><tr><td style=text-align:left>Cinder</td><td style=text-align:center>✓</td><td style=text-align:center><a href=#openstack-cinder>OpenStack Cinder</a></td></tr><tr><td style=text-align:left>FC</td><td style=text-align:center>-</td><td style=text-align:center>-</td></tr><tr><td style=text-align:left>FlexVolume</td><td style=text-align:center>-</td><td style=text-align:center>-</td></tr><tr><td style=text-align:left>GCEPersistentDisk</td><td style=text-align:center>✓</td><td style=text-align:center><a href=#gce-pd>GCE PD</a></td></tr><tr><td style=text-align:left>Glusterfs</td><td style=text-align:center>✓</td><td style=text-align:center><a href=#glusterfs>Glusterfs</a></td></tr><tr><td style=text-align:left>iSCSI</td><td style=text-align:center>-</td><td style=text-align:center>-</td></tr><tr><td style=text-align:left>NFS</td><td style=text-align:center>-</td><td style=text-align:center><a href=#nfs>NFS</a></td></tr><tr><td style=text-align:left>RBD</td><td style=text-align:center>✓</td><td style=text-align:center><a href=#ceph-rbd>Ceph RBD</a></td></tr><tr><td style=text-align:left>VsphereVolume</td><td style=text-align:center>✓</td><td style=text-align:center><a href=#vsphere>vSphere</a></td></tr><tr><td style=text-align:left>PortworxVolume</td><td style=text-align:center>✓</td><td style=text-align:center><a href=#portworx-volume>Portworx Volume</a></td></tr><tr><td style=text-align:left>Local</td><td style=text-align:center>-</td><td style=text-align:center><a href=#local>Local</a></td></tr></tbody></table><p>You are not restricted to specifying the "internal" provisioners
listed here (whose names are prefixed with "kubernetes.io" and shipped
alongside Kubernetes). You can also run and specify external provisioners,
which are independent programs that follow a <a href=https://git.k8s.io/design-proposals-archive/storage/volume-provisioning.md>specification</a>
defined by Kubernetes. Authors of external provisioners have full discretion
over where their code lives, how the provisioner is shipped, how it needs to be
run, what volume plugin it uses (including Flex), etc. The repository
<a href=https://github.com/kubernetes-sigs/sig-storage-lib-external-provisioner>kubernetes-sigs/sig-storage-lib-external-provisioner</a>
houses a library for writing external provisioners that implements the bulk of
the specification. Some external provisioners are listed under the repository
<a href=https://github.com/kubernetes-sigs/sig-storage-lib-external-provisioner>kubernetes-sigs/sig-storage-lib-external-provisioner</a>.</p><p>For example, NFS doesn't provide an internal provisioner, but an external
provisioner can be used. There are also cases when 3rd party storage
vendors provide their own external provisioner.</p><h3 id=reclaim-policy>Reclaim Policy</h3><p>PersistentVolumes that are dynamically created by a StorageClass will have the
reclaim policy specified in the <code>reclaimPolicy</code> field of the class, which can be
either <code>Delete</code> or <code>Retain</code>. If no <code>reclaimPolicy</code> is specified when a
StorageClass object is created, it will default to <code>Delete</code>.</p><p>PersistentVolumes that are created manually and managed via a StorageClass will have
whatever reclaim policy they were assigned at creation.</p><h3 id=allow-volume-expansion>Allow Volume Expansion</h3><div style=margin-top:10px;margin-bottom:10px><b>FEATURE STATE:</b> <code>Kubernetes v1.11 [beta]</code></div><p>PersistentVolumes can be configured to be expandable. This feature when set to <code>true</code>,
allows the users to resize the volume by editing the corresponding PVC object.</p><p>The following types of volumes support volume expansion, when the underlying
StorageClass has the field <code>allowVolumeExpansion</code> set to true.</p><table><caption style=display:none>Table of Volume types and the version of Kubernetes they require</caption><thead><tr><th style=text-align:left>Volume type</th><th style=text-align:left>Required Kubernetes version</th></tr></thead><tbody><tr><td style=text-align:left>gcePersistentDisk</td><td style=text-align:left>1.11</td></tr><tr><td style=text-align:left>awsElasticBlockStore</td><td style=text-align:left>1.11</td></tr><tr><td style=text-align:left>Cinder</td><td style=text-align:left>1.11</td></tr><tr><td style=text-align:left>glusterfs</td><td style=text-align:left>1.11</td></tr><tr><td style=text-align:left>rbd</td><td style=text-align:left>1.11</td></tr><tr><td style=text-align:left>Azure File</td><td style=text-align:left>1.11</td></tr><tr><td style=text-align:left>Azure Disk</td><td style=text-align:left>1.11</td></tr><tr><td style=text-align:left>Portworx</td><td style=text-align:left>1.11</td></tr><tr><td style=text-align:left>FlexVolume</td><td style=text-align:left>1.13</td></tr><tr><td style=text-align:left>CSI</td><td style=text-align:left>1.14 (alpha), 1.16 (beta)</td></tr></tbody></table><div class="alert alert-info note callout" role=alert><strong>Note:</strong> You can only use the volume expansion feature to grow a Volume, not to shrink it.</div><h3 id=mount-options>Mount Options</h3><p>PersistentVolumes that are dynamically created by a StorageClass will have the
mount options specified in the <code>mountOptions</code> field of the class.</p><p>If the volume plugin does not support mount options but mount options are
specified, provisioning will fail. Mount options are not validated on either
the class or PV. If a mount option is invalid, the PV mount fails.</p><h3 id=volume-binding-mode>Volume Binding Mode</h3><p>The <code>volumeBindingMode</code> field controls when <a href=/docs/concepts/storage/persistent-volumes/#provisioning>volume binding and dynamic
provisioning</a> should occur. When unset, "Immediate" mode is used by default.</p><p>The <code>Immediate</code> mode indicates that volume binding and dynamic
provisioning occurs once the PersistentVolumeClaim is created. For storage
backends that are topology-constrained and not globally accessible from all Nodes
in the cluster, PersistentVolumes will be bound or provisioned without knowledge of the Pod's scheduling
requirements. This may result in unschedulable Pods.</p><p>A cluster administrator can address this issue by specifying the <code>WaitForFirstConsumer</code> mode which
will delay the binding and provisioning of a PersistentVolume until a Pod using the PersistentVolumeClaim is created.
PersistentVolumes will be selected or provisioned conforming to the topology that is
specified by the Pod's scheduling constraints. These include, but are not limited to, <a href=/docs/concepts/configuration/manage-resources-containers/>resource
requirements</a>,
<a href=/docs/concepts/scheduling-eviction/assign-pod-node/#nodeselector>node selectors</a>,
<a href=/docs/concepts/scheduling-eviction/assign-pod-node/#affinity-and-anti-affinity>pod affinity and
anti-affinity</a>,
and <a href=/docs/concepts/scheduling-eviction/taint-and-toleration>taints and tolerations</a>.</p><p>The following plugins support <code>WaitForFirstConsumer</code> with dynamic provisioning:</p><ul><li><a href=#aws-ebs>AWSElasticBlockStore</a></li><li><a href=#gce-pd>GCEPersistentDisk</a></li><li><a href=#azure-disk>AzureDisk</a></li></ul><p>The following plugins support <code>WaitForFirstConsumer</code> with pre-created PersistentVolume binding:</p><ul><li>All of the above</li><li><a href=#local>Local</a></li></ul><p><div style=margin-top:10px;margin-bottom:10px><b>FEATURE STATE:</b> <code>Kubernetes v1.17 [stable]</code></div><a href=/docs/concepts/storage/volumes/#csi>CSI volumes</a> are also supported with dynamic provisioning
and pre-created PVs, but you'll need to look at the documentation for a specific CSI driver
to see its supported topology keys and examples.</p><div class="alert alert-info note callout" role=alert><strong>Note:</strong><p>If you choose to use <code>WaitForFirstConsumer</code>, do not use <code>nodeName</code> in the Pod spec
to specify node affinity. If <code>nodeName</code> is used in this case, the scheduler will be bypassed and PVC will remain in <code>pending</code> state.</p><p>Instead, you can use node selector for hostname in this case as shown below.</p></div><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>task-pv-pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>nodeSelector</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>kubernetes.io/hostname</span>:<span style=color:#bbb> </span>kube-01<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>volumes</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>task-pv-storage<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>persistentVolumeClaim</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>claimName</span>:<span style=color:#bbb> </span>task-pv-claim<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>task-pv-container<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>nginx<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>ports</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span>- <span style=color:green;font-weight:700>containerPort</span>:<span style=color:#bbb> </span><span style=color:#666>80</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;http-server&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>volumeMounts</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span>- <span style=color:green;font-weight:700>mountPath</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;/usr/share/nginx/html&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>task-pv-storage<span style=color:#bbb>
</span></span></span></code></pre></div><h3 id=allowed-topologies>Allowed Topologies</h3><p>When a cluster operator specifies the <code>WaitForFirstConsumer</code> volume binding mode, it is no longer necessary
to restrict provisioning to specific topologies in most situations. However,
if still required, <code>allowedTopologies</code> can be specified.</p><p>This example demonstrates how to restrict the topology of provisioned volumes to specific
zones and should be used as a replacement for the <code>zone</code> and <code>zones</code> parameters for the
supported plugins.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>storage.k8s.io/v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>StorageClass<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>standard<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>provisioner</span>:<span style=color:#bbb> </span>kubernetes.io/gce-pd<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>parameters</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>type</span>:<span style=color:#bbb> </span>pd-standard<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>volumeBindingMode</span>:<span style=color:#bbb> </span>WaitForFirstConsumer<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>allowedTopologies</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span>- <span style=color:green;font-weight:700>matchLabelExpressions</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>key</span>:<span style=color:#bbb> </span>failure-domain.beta.kubernetes.io/zone<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>values</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- us-central-1a<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- us-central-1b<span style=color:#bbb>
</span></span></span></code></pre></div><h2 id=parameters>Parameters</h2><p>Storage Classes have parameters that describe volumes belonging to the storage
class. Different parameters may be accepted depending on the <code>provisioner</code>. For
example, the value <code>io1</code>, for the parameter <code>type</code>, and the parameter
<code>iopsPerGB</code> are specific to EBS. When a parameter is omitted, some default is
used.</p><p>There can be at most 512 parameters defined for a StorageClass.
The total length of the parameters object including its keys and values cannot
exceed 256 KiB.</p><h3 id=aws-ebs>AWS EBS</h3><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>storage.k8s.io/v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>StorageClass<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>slow<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>provisioner</span>:<span style=color:#bbb> </span>kubernetes.io/aws-ebs<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>parameters</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>type</span>:<span style=color:#bbb> </span>io1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>iopsPerGB</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;10&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>fsType</span>:<span style=color:#bbb> </span>ext4<span style=color:#bbb>
</span></span></span></code></pre></div><ul><li><code>type</code>: <code>io1</code>, <code>gp2</code>, <code>sc1</code>, <code>st1</code>. See
<a href=https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/EBSVolumeTypes.html>AWS docs</a>
for details. Default: <code>gp2</code>.</li><li><code>zone</code> (Deprecated): AWS zone. If neither <code>zone</code> nor <code>zones</code> is specified, volumes are
generally round-robin-ed across all active zones where Kubernetes cluster
has a node. <code>zone</code> and <code>zones</code> parameters must not be used at the same time.</li><li><code>zones</code> (Deprecated): A comma separated list of AWS zone(s). If neither <code>zone</code> nor <code>zones</code>
is specified, volumes are generally round-robin-ed across all active zones
where Kubernetes cluster has a node. <code>zone</code> and <code>zones</code> parameters must not
be used at the same time.</li><li><code>iopsPerGB</code>: only for <code>io1</code> volumes. I/O operations per second per GiB. AWS
volume plugin multiplies this with size of requested volume to compute IOPS
of the volume and caps it at 20 000 IOPS (maximum supported by AWS, see
<a href=https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/EBSVolumeTypes.html>AWS docs</a>).
A string is expected here, i.e. <code>"10"</code>, not <code>10</code>.</li><li><code>fsType</code>: fsType that is supported by kubernetes. Default: <code>"ext4"</code>.</li><li><code>encrypted</code>: denotes whether the EBS volume should be encrypted or not.
Valid values are <code>"true"</code> or <code>"false"</code>. A string is expected here,
i.e. <code>"true"</code>, not <code>true</code>.</li><li><code>kmsKeyId</code>: optional. The full Amazon Resource Name of the key to use when
encrypting the volume. If none is supplied but <code>encrypted</code> is true, a key is
generated by AWS. See AWS docs for valid ARN value.</li></ul><div class="alert alert-info note callout" role=alert><strong>Note:</strong> <code>zone</code> and <code>zones</code> parameters are deprecated and replaced with
<a href=#allowed-topologies>allowedTopologies</a></div><h3 id=gce-pd>GCE PD</h3><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>storage.k8s.io/v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>StorageClass<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>slow<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>provisioner</span>:<span style=color:#bbb> </span>kubernetes.io/gce-pd<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>parameters</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>type</span>:<span style=color:#bbb> </span>pd-standard<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>fstype</span>:<span style=color:#bbb> </span>ext4<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>replication-type</span>:<span style=color:#bbb> </span>none<span style=color:#bbb>
</span></span></span></code></pre></div><ul><li><p><code>type</code>: <code>pd-standard</code> or <code>pd-ssd</code>. Default: <code>pd-standard</code></p></li><li><p><code>zone</code> (Deprecated): GCE zone. If neither <code>zone</code> nor <code>zones</code> is specified, volumes are
generally round-robin-ed across all active zones where Kubernetes cluster has
a node. <code>zone</code> and <code>zones</code> parameters must not be used at the same time.</p></li><li><p><code>zones</code> (Deprecated): A comma separated list of GCE zone(s). If neither <code>zone</code> nor <code>zones</code>
is specified, volumes are generally round-robin-ed across all active zones
where Kubernetes cluster has a node. <code>zone</code> and <code>zones</code> parameters must not
be used at the same time.</p></li><li><p><code>fstype</code>: <code>ext4</code> or <code>xfs</code>. Default: <code>ext4</code>. The defined filesystem type must be supported by the host operating system.</p></li><li><p><code>replication-type</code>: <code>none</code> or <code>regional-pd</code>. Default: <code>none</code>.</p></li></ul><p>If <code>replication-type</code> is set to <code>none</code>, a regular (zonal) PD will be provisioned.</p><p>If <code>replication-type</code> is set to <code>regional-pd</code>, a
<a href=https://cloud.google.com/compute/docs/disks/#repds>Regional Persistent Disk</a>
will be provisioned. It's highly recommended to have
<code>volumeBindingMode: WaitForFirstConsumer</code> set, in which case when you create
a Pod that consumes a PersistentVolumeClaim which uses this StorageClass, a
Regional Persistent Disk is provisioned with two zones. One zone is the same
as the zone that the Pod is scheduled in. The other zone is randomly picked
from the zones available to the cluster. Disk zones can be further constrained
using <code>allowedTopologies</code>.</p><div class="alert alert-info note callout" role=alert><strong>Note:</strong> <code>zone</code> and <code>zones</code> parameters are deprecated and replaced with
<a href=#allowed-topologies>allowedTopologies</a></div><h3 id=glusterfs>Glusterfs (deprecated)</h3><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>storage.k8s.io/v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>StorageClass<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>slow<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>provisioner</span>:<span style=color:#bbb> </span>kubernetes.io/glusterfs<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>parameters</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>resturl</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;http://127.0.0.1:8081&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>clusterid</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;630372ccdc720a92c681fb928f27b53f&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>restauthenabled</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;true&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>restuser</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;admin&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>secretNamespace</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;default&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>secretName</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;heketi-secret&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>gidMin</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;40000&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>gidMax</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;50000&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>volumetype</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;replicate:3&#34;</span><span style=color:#bbb>
</span></span></span></code></pre></div><ul><li><p><code>resturl</code>: Gluster REST service/Heketi service url which provision gluster
volumes on demand. The general format should be <code>IPaddress:Port</code> and this is
a mandatory parameter for GlusterFS dynamic provisioner. If Heketi service is
exposed as a routable service in openshift/kubernetes setup, this can have a
format similar to <code>http://heketi-storage-project.cloudapps.mystorage.com</code>
where the fqdn is a resolvable Heketi service url.</p></li><li><p><code>restauthenabled</code> : Gluster REST service authentication boolean that enables
authentication to the REST server. If this value is <code>"true"</code>, <code>restuser</code> and
<code>restuserkey</code> or <code>secretNamespace</code> + <code>secretName</code> have to be filled. This
option is deprecated, authentication is enabled when any of <code>restuser</code>,
<code>restuserkey</code>, <code>secretName</code> or <code>secretNamespace</code> is specified.</p></li><li><p><code>restuser</code> : Gluster REST service/Heketi user who has access to create volumes
in the Gluster Trusted Pool.</p></li><li><p><code>restuserkey</code> : Gluster REST service/Heketi user's password which will be used
for authentication to the REST server. This parameter is deprecated in favor
of <code>secretNamespace</code> + <code>secretName</code>.</p></li><li><p><code>secretNamespace</code>, <code>secretName</code> : Identification of Secret instance that
contains user password to use when talking to Gluster REST service. These
parameters are optional, empty password will be used when both
<code>secretNamespace</code> and <code>secretName</code> are omitted. The provided secret must have
type <code>"kubernetes.io/glusterfs"</code>, for example created in this way:</p><pre tabindex=0><code>kubectl create secret generic heketi-secret \
  --type=&#34;kubernetes.io/glusterfs&#34; --from-literal=key=&#39;opensesame&#39; \
  --namespace=default
</code></pre><p>Example of a secret can be found in
<a href=https://github.com/kubernetes/examples/tree/master/staging/persistent-volume-provisioning/glusterfs/glusterfs-secret.yaml>glusterfs-provisioning-secret.yaml</a>.</p></li><li><p><code>clusterid</code>: <code>630372ccdc720a92c681fb928f27b53f</code> is the ID of the cluster
which will be used by Heketi when provisioning the volume. It can also be a
list of clusterids, for example:
<code>"8452344e2becec931ece4e33c4674e4e,42982310de6c63381718ccfa6d8cf397"</code>. This
is an optional parameter.</p></li><li><p><code>gidMin</code>, <code>gidMax</code> : The minimum and maximum value of GID range for the
StorageClass. A unique value (GID) in this range ( gidMin-gidMax ) will be
used for dynamically provisioned volumes. These are optional values. If not
specified, the volume will be provisioned with a value between 2000-2147483647
which are defaults for gidMin and gidMax respectively.</p></li><li><p><code>volumetype</code> : The volume type and its parameters can be configured with this
optional value. If the volume type is not mentioned, it's up to the provisioner
to decide the volume type.</p><p>For example:</p><ul><li>Replica volume: <code>volumetype: replicate:3</code> where '3' is replica count.</li><li>Disperse/EC volume: <code>volumetype: disperse:4:2</code> where '4' is data and '2' is the redundancy count.</li><li>Distribute volume: <code>volumetype: none</code></li></ul><p>For available volume types and administration options, refer to the
<a href=https://access.redhat.com/documentation/en-us/red_hat_gluster_storage/>Administration Guide</a>.</p><p>For further reference information, see
<a href=https://github.com/heketi/heketi/wiki/Setting-up-the-topology>How to configure Heketi</a>.</p><p>When persistent volumes are dynamically provisioned, the Gluster plugin
automatically creates an endpoint and a headless service in the name
<code>gluster-dynamic-&lt;claimname></code>. The dynamic endpoint and service are automatically
deleted when the persistent volume claim is deleted.</p></li></ul><h3 id=nfs>NFS</h3><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>storage.k8s.io/v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>StorageClass<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>example-nfs<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>provisioner</span>:<span style=color:#bbb> </span>example.com/external-nfs<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>parameters</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>server</span>:<span style=color:#bbb> </span>nfs-server.example.com<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>path</span>:<span style=color:#bbb> </span>/share<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>readOnly</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;false&#34;</span><span style=color:#bbb>
</span></span></span></code></pre></div><ul><li><code>server</code>: Server is the hostname or IP address of the NFS server.</li><li><code>path</code>: Path that is exported by the NFS server.</li><li><code>readOnly</code>: A flag indicating whether the storage will be mounted as read only (default false).</li></ul><p>Kubernetes doesn't include an internal NFS provisioner. You need to use an external provisioner to create a StorageClass for NFS.
Here are some examples:</p><ul><li><a href=https://github.com/kubernetes-sigs/nfs-ganesha-server-and-external-provisioner>NFS Ganesha server and external provisioner</a></li><li><a href=https://github.com/kubernetes-sigs/nfs-subdir-external-provisioner>NFS subdir external provisioner</a></li></ul><h3 id=openstack-cinder>OpenStack Cinder</h3><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>storage.k8s.io/v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>StorageClass<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>gold<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>provisioner</span>:<span style=color:#bbb> </span>kubernetes.io/cinder<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>parameters</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>availability</span>:<span style=color:#bbb> </span>nova<span style=color:#bbb>
</span></span></span></code></pre></div><ul><li><code>availability</code>: Availability Zone. If not specified, volumes are generally
round-robin-ed across all active zones where Kubernetes cluster has a node.</li></ul><div class="alert alert-info note callout" role=alert><strong>Note:</strong><div style=margin-top:10px;margin-bottom:10px><b>FEATURE STATE:</b> <code>Kubernetes v1.11 [deprecated]</code></div><p>This internal provisioner of OpenStack is deprecated. Please use <a href=https://github.com/kubernetes/cloud-provider-openstack>the external cloud provider for OpenStack</a>.</div><h3 id=vsphere>vSphere</h3><p>There are two types of provisioners for vSphere storage classes:</p><ul><li><a href=#vsphere-provisioner-csi>CSI provisioner</a>: <code>csi.vsphere.vmware.com</code></li><li><a href=#vcp-provisioner>vCP provisioner</a>: <code>kubernetes.io/vsphere-volume</code></li></ul><p>In-tree provisioners are <a href=/blog/2019/12/09/kubernetes-1-17-feature-csi-migration-beta/#why-are-we-migrating-in-tree-plugins-to-csi>deprecated</a>. For more information on the CSI provisioner, see <a href=https://vsphere-csi-driver.sigs.k8s.io/>Kubernetes vSphere CSI Driver</a> and <a href=/docs/concepts/storage/volumes/#vsphere-csi-migration>vSphereVolume CSI migration</a>.</p><h4 id=vsphere-provisioner-csi>CSI Provisioner</h4><p>The vSphere CSI StorageClass provisioner works with Tanzu Kubernetes clusters. For an example, refer to the <a href=https://github.com/kubernetes-sigs/vsphere-csi-driver/blob/master/example/vanilla-k8s-RWM-filesystem-volumes/example-sc.yaml>vSphere CSI repository</a>.</p><h4 id=vcp-provisioner>vCP Provisioner</h4><p>The following examples use the VMware Cloud Provider (vCP) StorageClass provisioner.</p><ol><li><p>Create a StorageClass with a user specified disk format.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>storage.k8s.io/v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>StorageClass<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>fast<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>provisioner</span>:<span style=color:#bbb> </span>kubernetes.io/vsphere-volume<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>parameters</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>diskformat</span>:<span style=color:#bbb> </span>zeroedthick<span style=color:#bbb>
</span></span></span></code></pre></div><p><code>diskformat</code>: <code>thin</code>, <code>zeroedthick</code> and <code>eagerzeroedthick</code>. Default: <code>"thin"</code>.</p></li><li><p>Create a StorageClass with a disk format on a user specified datastore.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>storage.k8s.io/v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>StorageClass<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>fast<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>provisioner</span>:<span style=color:#bbb> </span>kubernetes.io/vsphere-volume<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>parameters</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>diskformat</span>:<span style=color:#bbb> </span>zeroedthick<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>datastore</span>:<span style=color:#bbb> </span>VSANDatastore<span style=color:#bbb>
</span></span></span></code></pre></div><p><code>datastore</code>: The user can also specify the datastore in the StorageClass.
The volume will be created on the datastore specified in the StorageClass,
which in this case is <code>VSANDatastore</code>. This field is optional. If the
datastore is not specified, then the volume will be created on the datastore
specified in the vSphere config file used to initialize the vSphere Cloud
Provider.</p></li><li><p>Storage Policy Management inside kubernetes</p><ul><li><p>Using existing vCenter SPBM policy</p><p>One of the most important features of vSphere for Storage Management is
policy based Management. Storage Policy Based Management (SPBM) is a
storage policy framework that provides a single unified control plane
across a broad range of data services and storage solutions. SPBM enables
vSphere administrators to overcome upfront storage provisioning challenges,
such as capacity planning, differentiated service levels and managing
capacity headroom.</p><p>The SPBM policies can be specified in the StorageClass using the
<code>storagePolicyName</code> parameter.</p></li><li><p>Virtual SAN policy support inside Kubernetes</p><p>Vsphere Infrastructure (VI) Admins will have the ability to specify custom
Virtual SAN Storage Capabilities during dynamic volume provisioning. You
can now define storage requirements, such as performance and availability,
in the form of storage capabilities during dynamic volume provisioning.
The storage capability requirements are converted into a Virtual SAN
policy which are then pushed down to the Virtual SAN layer when a
persistent volume (virtual disk) is being created. The virtual disk is
distributed across the Virtual SAN datastore to meet the requirements.</p><p>You can see <a href=https://github.com/vmware-archive/vsphere-storage-for-kubernetes/blob/fa4c8b8ad46a85b6555d715dd9d27ff69839df53/documentation/policy-based-mgmt.md>Storage Policy Based Management for dynamic provisioning of volumes</a>
for more details on how to use storage policies for persistent volumes
management.</p></li></ul></li></ol><p>There are few
<a href=https://github.com/kubernetes/examples/tree/master/staging/volumes/vsphere>vSphere examples</a>
which you try out for persistent volume management inside Kubernetes for vSphere.</p><h3 id=ceph-rbd>Ceph RBD</h3><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>storage.k8s.io/v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>StorageClass<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>fast<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>provisioner</span>:<span style=color:#bbb> </span>kubernetes.io/rbd<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>parameters</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>monitors</span>:<span style=color:#bbb> </span><span style=color:#666>10.16.153.105</span>:<span style=color:#666>6789</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>adminId</span>:<span style=color:#bbb> </span>kube<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>adminSecretName</span>:<span style=color:#bbb> </span>ceph-secret<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>adminSecretNamespace</span>:<span style=color:#bbb> </span>kube-system<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>pool</span>:<span style=color:#bbb> </span>kube<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>userId</span>:<span style=color:#bbb> </span>kube<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>userSecretName</span>:<span style=color:#bbb> </span>ceph-secret-user<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>userSecretNamespace</span>:<span style=color:#bbb> </span>default<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>fsType</span>:<span style=color:#bbb> </span>ext4<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>imageFormat</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;2&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>imageFeatures</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;layering&#34;</span><span style=color:#bbb>
</span></span></span></code></pre></div><ul><li><p><code>monitors</code>: Ceph monitors, comma delimited. This parameter is required.</p></li><li><p><code>adminId</code>: Ceph client ID that is capable of creating images in the pool.
Default is "admin".</p></li><li><p><code>adminSecretName</code>: Secret Name for <code>adminId</code>. This parameter is required.
The provided secret must have type "kubernetes.io/rbd".</p></li><li><p><code>adminSecretNamespace</code>: The namespace for <code>adminSecretName</code>. Default is "default".</p></li><li><p><code>pool</code>: Ceph RBD pool. Default is "rbd".</p></li><li><p><code>userId</code>: Ceph client ID that is used to map the RBD image. Default is the
same as <code>adminId</code>.</p></li><li><p><code>userSecretName</code>: The name of Ceph Secret for <code>userId</code> to map RBD image. It
must exist in the same namespace as PVCs. This parameter is required.
The provided secret must have type "kubernetes.io/rbd", for example created in this
way:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl create secret generic ceph-secret --type<span style=color:#666>=</span><span style=color:#b44>&#34;kubernetes.io/rbd&#34;</span> <span style=color:#b62;font-weight:700>\
</span></span></span><span style=display:flex><span><span style=color:#b62;font-weight:700></span>  --from-literal<span style=color:#666>=</span><span style=color:#b8860b>key</span><span style=color:#666>=</span><span style=color:#b44>&#39;QVFEQ1pMdFhPUnQrSmhBQUFYaERWNHJsZ3BsMmNjcDR6RFZST0E9PQ==&#39;</span> <span style=color:#b62;font-weight:700>\
</span></span></span><span style=display:flex><span><span style=color:#b62;font-weight:700></span>  --namespace<span style=color:#666>=</span>kube-system
</span></span></code></pre></div></li><li><p><code>userSecretNamespace</code>: The namespace for <code>userSecretName</code>.</p></li><li><p><code>fsType</code>: fsType that is supported by kubernetes. Default: <code>"ext4"</code>.</p></li><li><p><code>imageFormat</code>: Ceph RBD image format, "1" or "2". Default is "2".</p></li><li><p><code>imageFeatures</code>: This parameter is optional and should only be used if you
set <code>imageFormat</code> to "2". Currently supported features are <code>layering</code> only.
Default is "", and no features are turned on.</p></li></ul><h3 id=azure-disk>Azure Disk</h3><h4 id=azure-unmanaged-disk-storage-class>Azure Unmanaged Disk storage class</h4><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>storage.k8s.io/v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>StorageClass<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>slow<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>provisioner</span>:<span style=color:#bbb> </span>kubernetes.io/azure-disk<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>parameters</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>skuName</span>:<span style=color:#bbb> </span>Standard_LRS<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>location</span>:<span style=color:#bbb> </span>eastus<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>storageAccount</span>:<span style=color:#bbb> </span>azure_storage_account_name<span style=color:#bbb>
</span></span></span></code></pre></div><ul><li><code>skuName</code>: Azure storage account Sku tier. Default is empty.</li><li><code>location</code>: Azure storage account location. Default is empty.</li><li><code>storageAccount</code>: Azure storage account name. If a storage account is provided,
it must reside in the same resource group as the cluster, and <code>location</code> is
ignored. If a storage account is not provided, a new storage account will be
created in the same resource group as the cluster.</li></ul><h4 id=azure-disk-storage-class>Azure Disk storage class (starting from v1.7.2)</h4><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>storage.k8s.io/v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>StorageClass<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>slow<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>provisioner</span>:<span style=color:#bbb> </span>kubernetes.io/azure-disk<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>parameters</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>storageaccounttype</span>:<span style=color:#bbb> </span>Standard_LRS<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>managed<span style=color:#bbb>
</span></span></span></code></pre></div><ul><li><code>storageaccounttype</code>: Azure storage account Sku tier. Default is empty.</li><li><code>kind</code>: Possible values are <code>shared</code>, <code>dedicated</code>, and <code>managed</code> (default).
When <code>kind</code> is <code>shared</code>, all unmanaged disks are created in a few shared
storage accounts in the same resource group as the cluster. When <code>kind</code> is
<code>dedicated</code>, a new dedicated storage account will be created for the new
unmanaged disk in the same resource group as the cluster. When <code>kind</code> is
<code>managed</code>, all managed disks are created in the same resource group as
the cluster.</li><li><code>resourceGroup</code>: Specify the resource group in which the Azure disk will be created.
It must be an existing resource group name. If it is unspecified, the disk will be
placed in the same resource group as the current Kubernetes cluster.</li></ul><ul><li>Premium VM can attach both Standard_LRS and Premium_LRS disks, while Standard
VM can only attach Standard_LRS disks.</li><li>Managed VM can only attach managed disks and unmanaged VM can only attach
unmanaged disks.</li></ul><h3 id=azure-file>Azure File</h3><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>storage.k8s.io/v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>StorageClass<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>azurefile<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>provisioner</span>:<span style=color:#bbb> </span>kubernetes.io/azure-file<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>parameters</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>skuName</span>:<span style=color:#bbb> </span>Standard_LRS<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>location</span>:<span style=color:#bbb> </span>eastus<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>storageAccount</span>:<span style=color:#bbb> </span>azure_storage_account_name<span style=color:#bbb>
</span></span></span></code></pre></div><ul><li><code>skuName</code>: Azure storage account Sku tier. Default is empty.</li><li><code>location</code>: Azure storage account location. Default is empty.</li><li><code>storageAccount</code>: Azure storage account name. Default is empty. If a storage
account is not provided, all storage accounts associated with the resource
group are searched to find one that matches <code>skuName</code> and <code>location</code>. If a
storage account is provided, it must reside in the same resource group as the
cluster, and <code>skuName</code> and <code>location</code> are ignored.</li><li><code>secretNamespace</code>: the namespace of the secret that contains the Azure Storage
Account Name and Key. Default is the same as the Pod.</li><li><code>secretName</code>: the name of the secret that contains the Azure Storage Account Name and
Key. Default is <code>azure-storage-account-&lt;accountName>-secret</code></li><li><code>readOnly</code>: a flag indicating whether the storage will be mounted as read only.
Defaults to false which means a read/write mount. This setting will impact the
<code>ReadOnly</code> setting in VolumeMounts as well.</li></ul><p>During storage provisioning, a secret named by <code>secretName</code> is created for the
mounting credentials. If the cluster has enabled both
<a href=/docs/reference/access-authn-authz/rbac/>RBAC</a> and
<a href=/docs/reference/access-authn-authz/rbac/#controller-roles>Controller Roles</a>,
add the <code>create</code> permission of resource <code>secret</code> for clusterrole
<code>system:controller:persistent-volume-binder</code>.</p><p>In a multi-tenancy context, it is strongly recommended to set the value for
<code>secretNamespace</code> explicitly, otherwise the storage account credentials may
be read by other users.</p><h3 id=portworx-volume>Portworx Volume</h3><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>storage.k8s.io/v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>StorageClass<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>portworx-io-priority-high<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>provisioner</span>:<span style=color:#bbb> </span>kubernetes.io/portworx-volume<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>parameters</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>repl</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;1&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>snap_interval</span>:<span style=color:#bbb>   </span><span style=color:#b44>&#34;70&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>priority_io</span>:<span style=color:#bbb>  </span><span style=color:#b44>&#34;high&#34;</span><span style=color:#bbb>
</span></span></span></code></pre></div><ul><li><code>fs</code>: filesystem to be laid out: <code>none/xfs/ext4</code> (default: <code>ext4</code>).</li><li><code>block_size</code>: block size in Kbytes (default: <code>32</code>).</li><li><code>repl</code>: number of synchronous replicas to be provided in the form of
replication factor <code>1..3</code> (default: <code>1</code>) A string is expected here i.e.
<code>"1"</code> and not <code>1</code>.</li><li><code>priority_io</code>: determines whether the volume will be created from higher
performance or a lower priority storage <code>high/medium/low</code> (default: <code>low</code>).</li><li><code>snap_interval</code>: clock/time interval in minutes for when to trigger snapshots.
Snapshots are incremental based on difference with the prior snapshot, 0
disables snaps (default: <code>0</code>). A string is expected here i.e.
<code>"70"</code> and not <code>70</code>.</li><li><code>aggregation_level</code>: specifies the number of chunks the volume would be
distributed into, 0 indicates a non-aggregated volume (default: <code>0</code>). A string
is expected here i.e. <code>"0"</code> and not <code>0</code></li><li><code>ephemeral</code>: specifies whether the volume should be cleaned-up after unmount
or should be persistent. <code>emptyDir</code> use case can set this value to true and
<code>persistent volumes</code> use case such as for databases like Cassandra should set
to false, <code>true/false</code> (default <code>false</code>). A string is expected here i.e.
<code>"true"</code> and not <code>true</code>.</li></ul><h3 id=local>Local</h3><div style=margin-top:10px;margin-bottom:10px><b>FEATURE STATE:</b> <code>Kubernetes v1.14 [stable]</code></div><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>storage.k8s.io/v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>StorageClass<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>local-storage<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>provisioner</span>:<span style=color:#bbb> </span>kubernetes.io/no-provisioner<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>volumeBindingMode</span>:<span style=color:#bbb> </span>WaitForFirstConsumer<span style=color:#bbb>
</span></span></span></code></pre></div><p>Local volumes do not currently support dynamic provisioning, however a StorageClass
should still be created to delay volume binding until Pod scheduling. This is
specified by the <code>WaitForFirstConsumer</code> volume binding mode.</p><p>Delaying volume binding allows the scheduler to consider all of a Pod's
scheduling constraints when choosing an appropriate PersistentVolume for a
PersistentVolumeClaim.</p></div><div class=td-content style=page-break-before:always><h1 id=pg-018f0a7fc6e2f6d16da37702fc39b4f3>6 - Dynamic Volume Provisioning</h1><p>Dynamic volume provisioning allows storage volumes to be created on-demand.
Without dynamic provisioning, cluster administrators have to manually make
calls to their cloud or storage provider to create new storage volumes, and
then create <a href=/docs/concepts/storage/persistent-volumes/><code>PersistentVolume</code> objects</a>
to represent them in Kubernetes. The dynamic provisioning feature eliminates
the need for cluster administrators to pre-provision storage. Instead, it
automatically provisions storage when it is requested by users.</p><h2 id=background>Background</h2><p>The implementation of dynamic volume provisioning is based on the API object <code>StorageClass</code>
from the API group <code>storage.k8s.io</code>. A cluster administrator can define as many
<code>StorageClass</code> objects as needed, each specifying a <em>volume plugin</em> (aka
<em>provisioner</em>) that provisions a volume and the set of parameters to pass to
that provisioner when provisioning.
A cluster administrator can define and expose multiple flavors of storage (from
the same or different storage systems) within a cluster, each with a custom set
of parameters. This design also ensures that end users don't have to worry
about the complexity and nuances of how storage is provisioned, but still
have the ability to select from multiple storage options.</p><p>More information on storage classes can be found
<a href=/docs/concepts/storage/storage-classes/>here</a>.</p><h2 id=enabling-dynamic-provisioning>Enabling Dynamic Provisioning</h2><p>To enable dynamic provisioning, a cluster administrator needs to pre-create
one or more StorageClass objects for users.
StorageClass objects define which provisioner should be used and what parameters
should be passed to that provisioner when dynamic provisioning is invoked.
The name of a StorageClass object must be a valid
<a href=/docs/concepts/overview/working-with-objects/names#dns-subdomain-names>DNS subdomain name</a>.</p><p>The following manifest creates a storage class "slow" which provisions standard
disk-like persistent disks.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>storage.k8s.io/v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>StorageClass<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>slow<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>provisioner</span>:<span style=color:#bbb> </span>kubernetes.io/gce-pd<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>parameters</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>type</span>:<span style=color:#bbb> </span>pd-standard<span style=color:#bbb>
</span></span></span></code></pre></div><p>The following manifest creates a storage class "fast" which provisions
SSD-like persistent disks.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>storage.k8s.io/v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>StorageClass<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>fast<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>provisioner</span>:<span style=color:#bbb> </span>kubernetes.io/gce-pd<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>parameters</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>type</span>:<span style=color:#bbb> </span>pd-ssd<span style=color:#bbb>
</span></span></span></code></pre></div><h2 id=using-dynamic-provisioning>Using Dynamic Provisioning</h2><p>Users request dynamically provisioned storage by including a storage class in
their <code>PersistentVolumeClaim</code>. Before Kubernetes v1.6, this was done via the
<code>volume.beta.kubernetes.io/storage-class</code> annotation. However, this annotation
is deprecated since v1.9. Users now can and should instead use the
<code>storageClassName</code> field of the <code>PersistentVolumeClaim</code> object. The value of
this field must match the name of a <code>StorageClass</code> configured by the
administrator (see <a href=#enabling-dynamic-provisioning>below</a>).</p><p>To select the "fast" storage class, for example, a user would create the
following PersistentVolumeClaim:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>PersistentVolumeClaim<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>claim1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>accessModes</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- ReadWriteOnce<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>storageClassName</span>:<span style=color:#bbb> </span>fast<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>resources</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>requests</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>storage</span>:<span style=color:#bbb> </span>30Gi<span style=color:#bbb>
</span></span></span></code></pre></div><p>This claim results in an SSD-like Persistent Disk being automatically
provisioned. When the claim is deleted, the volume is destroyed.</p><h2 id=defaulting-behavior>Defaulting Behavior</h2><p>Dynamic provisioning can be enabled on a cluster such that all claims are
dynamically provisioned if no storage class is specified. A cluster administrator
can enable this behavior by:</p><ul><li>Marking one <code>StorageClass</code> object as <em>default</em>;</li><li>Making sure that the <a href=/docs/reference/access-authn-authz/admission-controllers/#defaultstorageclass><code>DefaultStorageClass</code> admission controller</a>
is enabled on the API server.</li></ul><p>An administrator can mark a specific <code>StorageClass</code> as default by adding the
<a href=/docs/reference/labels-annotations-taints/#storageclass-kubernetes-io-is-default-class><code>storageclass.kubernetes.io/is-default-class</code> annotation</a> to it.
When a default <code>StorageClass</code> exists in a cluster and a user creates a
<code>PersistentVolumeClaim</code> with <code>storageClassName</code> unspecified, the
<code>DefaultStorageClass</code> admission controller automatically adds the
<code>storageClassName</code> field pointing to the default storage class.</p><p>Note that there can be at most one <em>default</em> storage class on a cluster, or
a <code>PersistentVolumeClaim</code> without <code>storageClassName</code> explicitly specified cannot
be created.</p><h2 id=topology-awareness>Topology Awareness</h2><p>In <a href=/docs/setup/best-practices/multiple-zones/>Multi-Zone</a> clusters, Pods can be spread across
Zones in a Region. Single-Zone storage backends should be provisioned in the Zones where
Pods are scheduled. This can be accomplished by setting the
<a href=/docs/concepts/storage/storage-classes/#volume-binding-mode>Volume Binding Mode</a>.</p></div><div class=td-content style=page-break-before:always><h1 id=pg-c262af210c6828dec445d2f55a1d877a>7 - Volume Snapshots</h1><p>In Kubernetes, a <em>VolumeSnapshot</em> represents a snapshot of a volume on a storage
system. This document assumes that you are already familiar with Kubernetes
<a href=/docs/concepts/storage/persistent-volumes/>persistent volumes</a>.</p><h2 id=introduction>Introduction</h2><p>Similar to how API resources <code>PersistentVolume</code> and <code>PersistentVolumeClaim</code> are
used to provision volumes for users and administrators, <code>VolumeSnapshotContent</code>
and <code>VolumeSnapshot</code> API resources are provided to create volume snapshots for
users and administrators.</p><p>A <code>VolumeSnapshotContent</code> is a snapshot taken from a volume in the cluster that
has been provisioned by an administrator. It is a resource in the cluster just
like a PersistentVolume is a cluster resource.</p><p>A <code>VolumeSnapshot</code> is a request for snapshot of a volume by a user. It is similar
to a PersistentVolumeClaim.</p><p><code>VolumeSnapshotClass</code> allows you to specify different attributes belonging to a
<code>VolumeSnapshot</code>. These attributes may differ among snapshots taken from the same
volume on the storage system and therefore cannot be expressed by using the same
<code>StorageClass</code> of a <code>PersistentVolumeClaim</code>.</p><p>Volume snapshots provide Kubernetes users with a standardized way to copy a volume's
contents at a particular point in time without creating an entirely new volume. This
functionality enables, for example, database administrators to backup databases before
performing edit or delete modifications.</p><p>Users need to be aware of the following when using this feature:</p><ul><li>API Objects <code>VolumeSnapshot</code>, <code>VolumeSnapshotContent</code>, and <code>VolumeSnapshotClass</code>
are <a class=glossary-tooltip title='Custom code that defines a resource to add to your Kubernetes API server without building a complete custom server.' data-toggle=tooltip data-placement=top href=/docs/tasks/extend-kubernetes/custom-resources/custom-resource-definitions/ target=_blank aria-label=CRDs>CRDs</a>, not
part of the core API.</li><li><code>VolumeSnapshot</code> support is only available for CSI drivers.</li><li>As part of the deployment process of <code>VolumeSnapshot</code>, the Kubernetes team provides
a snapshot controller to be deployed into the control plane, and a sidecar helper
container called csi-snapshotter to be deployed together with the CSI driver.
The snapshot controller watches <code>VolumeSnapshot</code> and <code>VolumeSnapshotContent</code> objects
and is responsible for the creation and deletion of <code>VolumeSnapshotContent</code> object.
The sidecar csi-snapshotter watches <code>VolumeSnapshotContent</code> objects and triggers
<code>CreateSnapshot</code> and <code>DeleteSnapshot</code> operations against a CSI endpoint.</li><li>There is also a validating webhook server which provides tightened validation on
snapshot objects. This should be installed by the Kubernetes distros along with
the snapshot controller and CRDs, not CSI drivers. It should be installed in all
Kubernetes clusters that has the snapshot feature enabled.</li><li>CSI drivers may or may not have implemented the volume snapshot functionality.
The CSI drivers that have provided support for volume snapshot will likely use
the csi-snapshotter. See <a href=https://kubernetes-csi.github.io/docs/>CSI Driver documentation</a> for details.</li><li>The CRDs and snapshot controller installations are the responsibility of the Kubernetes distribution.</li></ul><h2 id=lifecycle-of-a-volume-snapshot-and-volume-snapshot-content>Lifecycle of a volume snapshot and volume snapshot content</h2><p><code>VolumeSnapshotContents</code> are resources in the cluster. <code>VolumeSnapshots</code> are requests
for those resources. The interaction between <code>VolumeSnapshotContents</code> and <code>VolumeSnapshots</code>
follow this lifecycle:</p><h3 id=provisioning-volume-snapshot>Provisioning Volume Snapshot</h3><p>There are two ways snapshots may be provisioned: pre-provisioned or dynamically provisioned.</p><h4 id=static>Pre-provisioned</h4><p>A cluster administrator creates a number of <code>VolumeSnapshotContents</code>. They carry the details
of the real volume snapshot on the storage system which is available for use by cluster users.
They exist in the Kubernetes API and are available for consumption.</p><h4 id=dynamic>Dynamic</h4><p>Instead of using a pre-existing snapshot, you can request that a snapshot to be dynamically
taken from a PersistentVolumeClaim. The <a href=/docs/concepts/storage/volume-snapshot-classes/>VolumeSnapshotClass</a>
specifies storage provider-specific parameters to use when taking a snapshot.</p><h3 id=binding>Binding</h3><p>The snapshot controller handles the binding of a <code>VolumeSnapshot</code> object with an appropriate
<code>VolumeSnapshotContent</code> object, in both pre-provisioned and dynamically provisioned scenarios.
The binding is a one-to-one mapping.</p><p>In the case of pre-provisioned binding, the VolumeSnapshot will remain unbound until the
requested VolumeSnapshotContent object is created.</p><h3 id=persistent-volume-claim-as-snapshot-source-protection>Persistent Volume Claim as Snapshot Source Protection</h3><p>The purpose of this protection is to ensure that in-use
<a class=glossary-tooltip title='Claims storage resources defined in a PersistentVolume so that it can be mounted as a volume in a container.' data-toggle=tooltip data-placement=top href=/docs/concepts/storage/persistent-volumes/#persistentvolumeclaims target=_blank aria-label=PersistentVolumeClaim>PersistentVolumeClaim</a>
API objects are not removed from the system while a snapshot is being taken from it
(as this may result in data loss).</p><p>While a snapshot is being taken of a PersistentVolumeClaim, that PersistentVolumeClaim
is in-use. If you delete a PersistentVolumeClaim API object in active use as a snapshot
source, the PersistentVolumeClaim object is not removed immediately. Instead, removal of
the PersistentVolumeClaim object is postponed until the snapshot is readyToUse or aborted.</p><h3 id=delete>Delete</h3><p>Deletion is triggered by deleting the <code>VolumeSnapshot</code> object, and the <code>DeletionPolicy</code>
will be followed. If the <code>DeletionPolicy</code> is <code>Delete</code>, then the underlying storage snapshot
will be deleted along with the <code>VolumeSnapshotContent</code> object. If the <code>DeletionPolicy</code> is
<code>Retain</code>, then both the underlying snapshot and <code>VolumeSnapshotContent</code> remain.</p><h2 id=volumesnapshots>VolumeSnapshots</h2><p>Each VolumeSnapshot contains a spec and a status.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>snapshot.storage.k8s.io/v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>VolumeSnapshot<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>new-snapshot-test<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>volumeSnapshotClassName</span>:<span style=color:#bbb> </span>csi-hostpath-snapclass<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>source</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>persistentVolumeClaimName</span>:<span style=color:#bbb> </span>pvc-test<span style=color:#bbb>
</span></span></span></code></pre></div><p><code>persistentVolumeClaimName</code> is the name of the PersistentVolumeClaim data source
for the snapshot. This field is required for dynamically provisioning a snapshot.</p><p>A volume snapshot can request a particular class by specifying the name of a
<a href=/docs/concepts/storage/volume-snapshot-classes/>VolumeSnapshotClass</a>
using the attribute <code>volumeSnapshotClassName</code>. If nothing is set, then the
default class is used if available.</p><p>For pre-provisioned snapshots, you need to specify a <code>volumeSnapshotContentName</code>
as the source for the snapshot as shown in the following example. The
<code>volumeSnapshotContentName</code> source field is required for pre-provisioned snapshots.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>snapshot.storage.k8s.io/v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>VolumeSnapshot<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>test-snapshot<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>source</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>volumeSnapshotContentName</span>:<span style=color:#bbb> </span>test-content<span style=color:#bbb>
</span></span></span></code></pre></div><h2 id=volume-snapshot-contents>Volume Snapshot Contents</h2><p>Each VolumeSnapshotContent contains a spec and status. In dynamic provisioning,
the snapshot common controller creates <code>VolumeSnapshotContent</code> objects. Here is an example:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>snapshot.storage.k8s.io/v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>VolumeSnapshotContent<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>snapcontent-72d9a349-aacd-42d2-a240-d775650d2455<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>deletionPolicy</span>:<span style=color:#bbb> </span>Delete<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>driver</span>:<span style=color:#bbb> </span>hostpath.csi.k8s.io<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>source</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>volumeHandle</span>:<span style=color:#bbb> </span>ee0cfb94-f8d4-11e9-b2d8-0242ac110002<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>sourceVolumeMode</span>:<span style=color:#bbb> </span>Filesystem<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>volumeSnapshotClassName</span>:<span style=color:#bbb> </span>csi-hostpath-snapclass<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>volumeSnapshotRef</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>new-snapshot-test<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>namespace</span>:<span style=color:#bbb> </span>default<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>uid</span>:<span style=color:#bbb> </span>72d9a349-aacd-42d2-a240-d775650d2455<span style=color:#bbb>
</span></span></span></code></pre></div><p><code>volumeHandle</code> is the unique identifier of the volume created on the storage
backend and returned by the CSI driver during the volume creation. This field
is required for dynamically provisioning a snapshot.
It specifies the volume source of the snapshot.</p><p>For pre-provisioned snapshots, you (as cluster administrator) are responsible
for creating the <code>VolumeSnapshotContent</code> object as follows.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>snapshot.storage.k8s.io/v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>VolumeSnapshotContent<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>new-snapshot-content-test<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>deletionPolicy</span>:<span style=color:#bbb> </span>Delete<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>driver</span>:<span style=color:#bbb> </span>hostpath.csi.k8s.io<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>source</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>snapshotHandle</span>:<span style=color:#bbb> </span>7bdd0de3-aaeb-11e8-9aae-0242ac110002<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>sourceVolumeMode</span>:<span style=color:#bbb> </span>Filesystem<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>volumeSnapshotRef</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>new-snapshot-test<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>namespace</span>:<span style=color:#bbb> </span>default<span style=color:#bbb>
</span></span></span></code></pre></div><p><code>snapshotHandle</code> is the unique identifier of the volume snapshot created on
the storage backend. This field is required for the pre-provisioned snapshots.
It specifies the CSI snapshot id on the storage system that this
<code>VolumeSnapshotContent</code> represents.</p><p><code>sourceVolumeMode</code> is the mode of the volume whose snapshot is taken. The value
of the <code>sourceVolumeMode</code> field can be either <code>Filesystem</code> or <code>Block</code>. If the
source volume mode is not specified, Kubernetes treats the snapshot as if the
source volume's mode is unknown.</p><p><code>volumeSnapshotRef</code> is the reference of the corresponding <code>VolumeSnapshot</code>. Note that
when the <code>VolumeSnapshotContent</code> is being created as a pre-provisioned snapshot, the
<code>VolumeSnapshot</code> referenced in <code>volumeSnapshotRef</code> might not exist yet.</p><h2 id=convert-volume-mode>Converting the volume mode of a Snapshot</h2><p>If the <code>VolumeSnapshots</code> API installed on your cluster supports the <code>sourceVolumeMode</code>
field, then the API has the capability to prevent unauthorized users from converting
the mode of a volume.</p><p>To check if your cluster has capability for this feature, run the following command:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span>$ kubectl get crd volumesnapshotcontent -o yaml<span style=color:#bbb>
</span></span></span></code></pre></div><p>If you want to allow users to create a <code>PersistentVolumeClaim</code> from an existing
<code>VolumeSnapshot</code>, but with a different volume mode than the source, the annotation
<code>snapshot.storage.kubernetes.io/allowVolumeModeChange: "true"</code>needs to be added to
the <code>VolumeSnapshotContent</code> that corresponds to the <code>VolumeSnapshot</code>.</p><p>For pre-provisioned snapshots, <code>Spec.SourceVolumeMode</code> needs to be populated
by the cluster administrator.</p><p>An example <code>VolumeSnapshotContent</code> resource with this feature enabled would look like:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>snapshot.storage.k8s.io/v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>VolumeSnapshotContent<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>new-snapshot-content-test<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>annotations</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:green;font-weight:700>snapshot.storage.kubernetes.io/allowVolumeModeChange</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;true&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>deletionPolicy</span>:<span style=color:#bbb> </span>Delete<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>driver</span>:<span style=color:#bbb> </span>hostpath.csi.k8s.io<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>source</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>snapshotHandle</span>:<span style=color:#bbb> </span>7bdd0de3-aaeb-11e8-9aae-0242ac110002<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>sourceVolumeMode</span>:<span style=color:#bbb> </span>Filesystem<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>volumeSnapshotRef</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>new-snapshot-test<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>namespace</span>:<span style=color:#bbb> </span>default<span style=color:#bbb>
</span></span></span></code></pre></div><h2 id=provisioning-volumes-from-snapshots>Provisioning Volumes from Snapshots</h2><p>You can provision a new volume, pre-populated with data from a snapshot, by using
the <em>dataSource</em> field in the <code>PersistentVolumeClaim</code> object.</p><p>For more details, see
<a href=/docs/concepts/storage/persistent-volumes/#volume-snapshot-and-restore-volume-from-snapshot-support>Volume Snapshot and Restore Volume from Snapshot</a>.</p></div><div class=td-content style=page-break-before:always><h1 id=pg-4d00116c86dade62bdd5be7dc2afa1ca>8 - Volume Snapshot Classes</h1><p>This document describes the concept of VolumeSnapshotClass in Kubernetes. Familiarity
with <a href=/docs/concepts/storage/volume-snapshots/>volume snapshots</a> and
<a href=/docs/concepts/storage/storage-classes>storage classes</a> is suggested.</p><h2 id=introduction>Introduction</h2><p>Just like StorageClass provides a way for administrators to describe the "classes"
of storage they offer when provisioning a volume, VolumeSnapshotClass provides a
way to describe the "classes" of storage when provisioning a volume snapshot.</p><h2 id=the-volumesnapshotclass-resource>The VolumeSnapshotClass Resource</h2><p>Each VolumeSnapshotClass contains the fields <code>driver</code>, <code>deletionPolicy</code>, and <code>parameters</code>,
which are used when a VolumeSnapshot belonging to the class needs to be
dynamically provisioned.</p><p>The name of a VolumeSnapshotClass object is significant, and is how users can
request a particular class. Administrators set the name and other parameters
of a class when first creating VolumeSnapshotClass objects, and the objects cannot
be updated once they are created.</p><div class="alert alert-info note callout" role=alert><strong>Note:</strong> Installation of the CRDs is the responsibility of the Kubernetes distribution. Without the required CRDs present, the creation of a VolumeSnapshotClass fails.</div><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>snapshot.storage.k8s.io/v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>VolumeSnapshotClass<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>csi-hostpath-snapclass<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>driver</span>:<span style=color:#bbb> </span>hostpath.csi.k8s.io<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>deletionPolicy</span>:<span style=color:#bbb> </span>Delete<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>parameters</span>:<span style=color:#bbb>
</span></span></span></code></pre></div><p>Administrators can specify a default VolumeSnapshotClass for VolumeSnapshots
that don't request any particular class to bind to by adding the
<code>snapshot.storage.kubernetes.io/is-default-class: "true"</code> annotation:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>snapshot.storage.k8s.io/v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>VolumeSnapshotClass<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>csi-hostpath-snapclass<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>annotations</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>snapshot.storage.kubernetes.io/is-default-class</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;true&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>driver</span>:<span style=color:#bbb> </span>hostpath.csi.k8s.io<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>deletionPolicy</span>:<span style=color:#bbb> </span>Delete<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>parameters</span>:<span style=color:#bbb>
</span></span></span></code></pre></div><h3 id=driver>Driver</h3><p>Volume snapshot classes have a driver that determines what CSI volume plugin is
used for provisioning VolumeSnapshots. This field must be specified.</p><h3 id=deletionpolicy>DeletionPolicy</h3><p>Volume snapshot classes have a deletionPolicy. It enables you to configure what happens to a VolumeSnapshotContent when the VolumeSnapshot object it is bound to is to be deleted. The deletionPolicy of a volume snapshot class can either be <code>Retain</code> or <code>Delete</code>. This field must be specified.</p><p>If the deletionPolicy is <code>Delete</code>, then the underlying storage snapshot will be deleted along with the VolumeSnapshotContent object. If the deletionPolicy is <code>Retain</code>, then both the underlying snapshot and VolumeSnapshotContent remain.</p><h2 id=parameters>Parameters</h2><p>Volume snapshot classes have parameters that describe volume snapshots belonging to
the volume snapshot class. Different parameters may be accepted depending on the
<code>driver</code>.</p></div><div class=td-content style=page-break-before:always><h1 id=pg-707ca81a34eb1ca202f34692e9917d1e>9 - CSI Volume Cloning</h1><p>This document describes the concept of cloning existing CSI Volumes in Kubernetes. Familiarity with <a href=/docs/concepts/storage/volumes>Volumes</a> is suggested.</p><h2 id=introduction>Introduction</h2><p>The <a class=glossary-tooltip title='The Container Storage Interface (CSI) defines a standard interface to expose storage systems to containers.' data-toggle=tooltip data-placement=top href=/docs/concepts/storage/volumes/#csi target=_blank aria-label=CSI>CSI</a> Volume Cloning feature adds support for specifying existing <a class=glossary-tooltip title='Claims storage resources defined in a PersistentVolume so that it can be mounted as a volume in a container.' data-toggle=tooltip data-placement=top href=/docs/concepts/storage/persistent-volumes/#persistentvolumeclaims target=_blank aria-label=PVC>PVC</a>s in the <code>dataSource</code> field to indicate a user would like to clone a <a class=glossary-tooltip title='A directory containing data, accessible to the containers in a pod.' data-toggle=tooltip data-placement=top href=/docs/concepts/storage/volumes/ target=_blank aria-label=Volume>Volume</a>.</p><p>A Clone is defined as a duplicate of an existing Kubernetes Volume that can be consumed as any standard Volume would be. The only difference is that upon provisioning, rather than creating a "new" empty Volume, the back end device creates an exact duplicate of the specified Volume.</p><p>The implementation of cloning, from the perspective of the Kubernetes API, adds the ability to specify an existing PVC as a dataSource during new PVC creation. The source PVC must be bound and available (not in use).</p><p>Users need to be aware of the following when using this feature:</p><ul><li>Cloning support (<code>VolumePVCDataSource</code>) is only available for CSI drivers.</li><li>Cloning support is only available for dynamic provisioners.</li><li>CSI drivers may or may not have implemented the volume cloning functionality.</li><li>You can only clone a PVC when it exists in the same namespace as the destination PVC (source and destination must be in the same namespace).</li><li>Cloning is supported with a different Storage Class.<ul><li>Destination volume can be the same or a different storage class as the source.</li><li>Default storage class can be used and storageClassName omitted in the spec.</li></ul></li><li>Cloning can only be performed between two volumes that use the same VolumeMode setting (if you request a block mode volume, the source MUST also be block mode)</li></ul><h2 id=provisioning>Provisioning</h2><p>Clones are provisioned like any other PVC with the exception of adding a dataSource that references an existing PVC in the same namespace.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>PersistentVolumeClaim<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>clone-of-pvc-1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>namespace</span>:<span style=color:#bbb> </span>myns<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>accessModes</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- ReadWriteOnce<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>storageClassName</span>:<span style=color:#bbb> </span>cloning<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>resources</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>requests</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>storage</span>:<span style=color:#bbb> </span>5Gi<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>dataSource</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>PersistentVolumeClaim<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>pvc-1<span style=color:#bbb>
</span></span></span></code></pre></div><div class="alert alert-info note callout" role=alert><strong>Note:</strong> You must specify a capacity value for <code>spec.resources.requests.storage</code>, and the value you specify must be the same or larger than the capacity of the source volume.</div><p>The result is a new PVC with the name <code>clone-of-pvc-1</code> that has the exact same content as the specified source <code>pvc-1</code>.</p><h2 id=usage>Usage</h2><p>Upon availability of the new PVC, the cloned PVC is consumed the same as other PVC. It's also expected at this point that the newly created PVC is an independent object. It can be consumed, cloned, snapshotted, or deleted independently and without consideration for it's original dataSource PVC. This also implies that the source is not linked in any way to the newly created clone, it may also be modified or deleted without affecting the newly created clone.</p></div><div class=td-content style=page-break-before:always><h1 id=pg-00cd24f4570b7acaac75c2551c948bc7>10 - Storage Capacity</h1><p>Storage capacity is limited and may vary depending on the node on
which a pod runs: network-attached storage might not be accessible by
all nodes, or storage is local to a node to begin with.</p><div style=margin-top:10px;margin-bottom:10px><b>FEATURE STATE:</b> <code>Kubernetes v1.24 [stable]</code></div><p>This page describes how Kubernetes keeps track of storage capacity and
how the scheduler uses that information to <a href=/docs/concepts/scheduling-eviction/>schedule Pods</a> onto nodes
that have access to enough storage capacity for the remaining missing
volumes. Without storage capacity tracking, the scheduler may choose a
node that doesn't have enough capacity to provision a volume and
multiple scheduling retries will be needed.</p><h2 id=before-you-begin>Before you begin</h2><p>Kubernetes v1.25 includes cluster-level API support for
storage capacity tracking. To use this you must also be using a CSI driver that
supports capacity tracking. Consult the documentation for the CSI drivers that
you use to find out whether this support is available and, if so, how to use
it. If you are not running Kubernetes v1.25, check the
documentation for that version of Kubernetes.</p><h2 id=api>API</h2><p>There are two API extensions for this feature:</p><ul><li><a href=/docs/reference/kubernetes-api/config-and-storage-resources/csi-storage-capacity-v1/>CSIStorageCapacity</a> objects:
these get produced by a CSI driver in the namespace
where the driver is installed. Each object contains capacity
information for one storage class and defines which nodes have
access to that storage.</li><li><a href=/docs/reference/kubernetes-api/config-and-storage-resources/csi-driver-v1/#CSIDriverSpec>The <code>CSIDriverSpec.StorageCapacity</code> field</a>:
when set to <code>true</code>, the Kubernetes scheduler will consider storage
capacity for volumes that use the CSI driver.</li></ul><h2 id=scheduling>Scheduling</h2><p>Storage capacity information is used by the Kubernetes scheduler if:</p><ul><li>a Pod uses a volume that has not been created yet,</li><li>that volume uses a <a class=glossary-tooltip title='A StorageClass provides a way for administrators to describe different available storage types.' data-toggle=tooltip data-placement=top href=/docs/concepts/storage/storage-classes target=_blank aria-label=StorageClass>StorageClass</a> which references a CSI driver and
uses <code>WaitForFirstConsumer</code> <a href=/docs/concepts/storage/storage-classes/#volume-binding-mode>volume binding
mode</a>,
and</li><li>the <code>CSIDriver</code> object for the driver has <code>StorageCapacity</code> set to
true.</li></ul><p>In that case, the scheduler only considers nodes for the Pod which
have enough storage available to them. This check is very
simplistic and only compares the size of the volume against the
capacity listed in <code>CSIStorageCapacity</code> objects with a topology that
includes the node.</p><p>For volumes with <code>Immediate</code> volume binding mode, the storage driver
decides where to create the volume, independently of Pods that will
use the volume. The scheduler then schedules Pods onto nodes where the
volume is available after the volume has been created.</p><p>For <a href=/docs/concepts/storage/ephemeral-volumes/#csi-ephemeral-volumes>CSI ephemeral volumes</a>,
scheduling always happens without considering storage capacity. This
is based on the assumption that this volume type is only used by
special CSI drivers which are local to a node and do not need
significant resources there.</p><h2 id=rescheduling>Rescheduling</h2><p>When a node has been selected for a Pod with <code>WaitForFirstConsumer</code>
volumes, that decision is still tentative. The next step is that the
CSI storage driver gets asked to create the volume with a hint that the
volume is supposed to be available on the selected node.</p><p>Because Kubernetes might have chosen a node based on out-dated
capacity information, it is possible that the volume cannot really be
created. The node selection is then reset and the Kubernetes scheduler
tries again to find a node for the Pod.</p><h2 id=limitations>Limitations</h2><p>Storage capacity tracking increases the chance that scheduling works
on the first try, but cannot guarantee this because the scheduler has
to decide based on potentially out-dated information. Usually, the
same retry mechanism as for scheduling without any storage capacity
information handles scheduling failures.</p><p>One situation where scheduling can fail permanently is when a Pod uses
multiple volumes: one volume might have been created already in a
topology segment which then does not have enough capacity left for
another volume. Manual intervention is necessary to recover from this,
for example by increasing capacity or deleting the volume that was
already created.</p><h2 id=what-s-next>What's next</h2><ul><li>For more information on the design, see the
<a href=https://github.com/kubernetes/enhancements/blob/master/keps/sig-storage/1472-storage-capacity-tracking/README.md>Storage Capacity Constraints for Pod Scheduling KEP</a>.</li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-b2e4b16ac37988c678a3312a4a6639f8>11 - Node-specific Volume Limits</h1><p>This page describes the maximum number of volumes that can be attached
to a Node for various cloud providers.</p><p>Cloud providers like Google, Amazon, and Microsoft typically have a limit on
how many volumes can be attached to a Node. It is important for Kubernetes to
respect those limits. Otherwise, Pods scheduled on a Node could get stuck
waiting for volumes to attach.</p><h2 id=kubernetes-default-limits>Kubernetes default limits</h2><p>The Kubernetes scheduler has default limits on the number of volumes
that can be attached to a Node:</p><table><tr><th>Cloud service</th><th>Maximum volumes per Node</th></tr><tr><td><a href=https://aws.amazon.com/ebs/>Amazon Elastic Block Store (EBS)</a></td><td>39</td></tr><tr><td><a href=https://cloud.google.com/persistent-disk/>Google Persistent Disk</a></td><td>16</td></tr><tr><td><a href=https://azure.microsoft.com/en-us/services/storage/main-disks/>Microsoft Azure Disk Storage</a></td><td>16</td></tr></table><h2 id=custom-limits>Custom limits</h2><p>You can change these limits by setting the value of the
<code>KUBE_MAX_PD_VOLS</code> environment variable, and then starting the scheduler.
CSI drivers might have a different procedure, see their documentation
on how to customize their limits.</p><p>Use caution if you set a limit that is higher than the default limit. Consult
the cloud provider's documentation to make sure that Nodes can actually support
the limit you set.</p><p>The limit applies to the entire cluster, so it affects all Nodes.</p><h2 id=dynamic-volume-limits>Dynamic volume limits</h2><div style=margin-top:10px;margin-bottom:10px><b>FEATURE STATE:</b> <code>Kubernetes v1.17 [stable]</code></div><p>Dynamic volume limits are supported for following volume types.</p><ul><li>Amazon EBS</li><li>Google Persistent Disk</li><li>Azure Disk</li><li>CSI</li></ul><p>For volumes managed by in-tree volume plugins, Kubernetes automatically determines the Node
type and enforces the appropriate maximum number of volumes for the node. For example:</p><ul><li><p>On
<a href=https://cloud.google.com/compute/>Google Compute Engine</a>,
up to 127 volumes can be attached to a node, <a href=https://cloud.google.com/compute/docs/disks/#pdnumberlimits>depending on the node
type</a>.</p></li><li><p>For Amazon EBS disks on M5,C5,R5,T3 and Z1D instance types, Kubernetes allows only 25
volumes to be attached to a Node. For other instance types on
<a href=https://aws.amazon.com/ec2/>Amazon Elastic Compute Cloud (EC2)</a>,
Kubernetes allows 39 volumes to be attached to a Node.</p></li><li><p>On Azure, up to 64 disks can be attached to a node, depending on the node type. For more details, refer to <a href=https://docs.microsoft.com/en-us/azure/virtual-machines/windows/sizes>Sizes for virtual machines in Azure</a>.</p></li><li><p>If a CSI storage driver advertises a maximum number of volumes for a Node (using <code>NodeGetInfo</code>), the <a class=glossary-tooltip title='Control plane component that watches for newly created pods with no assigned node, and selects a node for them to run on.' data-toggle=tooltip data-placement=top href=/docs/reference/command-line-tools-reference/kube-scheduler/ target=_blank aria-label=kube-scheduler>kube-scheduler</a> honors that limit.
Refer to the <a href=https://github.com/container-storage-interface/spec/blob/master/spec.md#nodegetinfo>CSI specifications</a> for details.</p></li><li><p>For volumes managed by in-tree plugins that have been migrated to a CSI driver, the maximum number of volumes will be the one reported by the CSI driver.</p></li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-4f40cb95a671e51b4f0156a409d95c6d>12 - Volume Health Monitoring</h1><div style=margin-top:10px;margin-bottom:10px><b>FEATURE STATE:</b> <code>Kubernetes v1.21 [alpha]</code></div><p><a class=glossary-tooltip title='The Container Storage Interface (CSI) defines a standard interface to expose storage systems to containers.' data-toggle=tooltip data-placement=top href=/docs/concepts/storage/volumes/#csi target=_blank aria-label=CSI>CSI</a> volume health monitoring allows CSI Drivers to detect abnormal volume conditions from the underlying storage systems and report them as events on <a class=glossary-tooltip title='Claims storage resources defined in a PersistentVolume so that it can be mounted as a volume in a container.' data-toggle=tooltip data-placement=top href=/docs/concepts/storage/persistent-volumes/#persistentvolumeclaims target=_blank aria-label=PVCs>PVCs</a> or <a class=glossary-tooltip title='A Pod represents a set of running containers in your cluster.' data-toggle=tooltip data-placement=top href=/docs/concepts/workloads/pods/ target=_blank aria-label=Pods>Pods</a>.</p><h2 id=volume-health-monitoring>Volume health monitoring</h2><p>Kubernetes <em>volume health monitoring</em> is part of how Kubernetes implements the Container Storage Interface (CSI). Volume health monitoring feature is implemented in two components: an External Health Monitor controller, and the <a class=glossary-tooltip title='An agent that runs on each node in the cluster. It makes sure that containers are running in a pod.' data-toggle=tooltip data-placement=top href=/docs/reference/generated/kubelet target=_blank aria-label=kubelet>kubelet</a>.</p><p>If a CSI Driver supports Volume Health Monitoring feature from the controller side, an event will be reported on the related <a class=glossary-tooltip title='Claims storage resources defined in a PersistentVolume so that it can be mounted as a volume in a container.' data-toggle=tooltip data-placement=top href=/docs/concepts/storage/persistent-volumes/#persistentvolumeclaims target=_blank aria-label=PersistentVolumeClaim>PersistentVolumeClaim</a> (PVC) when an abnormal volume condition is detected on a CSI volume.</p><p>The External Health Monitor <a class=glossary-tooltip title='A control loop that watches the shared state of the cluster through the apiserver and makes changes attempting to move the current state towards the desired state.' data-toggle=tooltip data-placement=top href=/docs/concepts/architecture/controller/ target=_blank aria-label=controller>controller</a> also watches for node failure events. You can enable node failure monitoring by setting the <code>enable-node-watcher</code> flag to true. When the external health monitor detects a node failure event, the controller reports an Event will be reported on the PVC to indicate that pods using this PVC are on a failed node.</p><p>If a CSI Driver supports Volume Health Monitoring feature from the node side, an Event will be reported on every Pod using the PVC when an abnormal volume condition is detected on a CSI volume. In addition, Volume Health information is exposed as Kubelet VolumeStats metrics. A new metric kubelet_volume_stats_health_status_abnormal is added. This metric includes two labels: <code>namespace</code> and <code>persistentvolumeclaim</code>. The count is either 1 or 0. 1 indicates the volume is unhealthy, 0 indicates volume is healthy. For more information, please check <a href=https://github.com/kubernetes/enhancements/tree/master/keps/sig-storage/1432-volume-health-monitor#kubelet-metrics-changes>KEP</a>.</p><div class="alert alert-info note callout" role=alert><strong>Note:</strong> You need to enable the <code>CSIVolumeHealth</code> <a href=/docs/reference/command-line-tools-reference/feature-gates/>feature gate</a> to use this feature from the node side.</div><h2 id=what-s-next>What's next</h2><p>See the <a href=https://kubernetes-csi.github.io/docs/drivers.html>CSI driver documentation</a> to find out which CSI drivers have implemented this feature.</p></div><div class=td-content style=page-break-before:always><h1 id=pg-055a8df536f8ba8f3aa0217bd2db5437>13 - Windows Storage</h1><p>This page provides an storage overview specific to the Windows operating system.</p><h2 id=storage>Persistent storage</h2><p>Windows has a layered filesystem driver to mount container layers and create a copy
filesystem based on NTFS. All file paths in the container are resolved only within
the context of that container.</p><ul><li>With Docker, volume mounts can only target a directory in the container, and not
an individual file. This limitation does not apply to containerd.</li><li>Volume mounts cannot project files or directories back to the host filesystem.</li><li>Read-only filesystems are not supported because write access is always required
for the Windows registry and SAM database. However, read-only volumes are supported.</li><li>Volume user-masks and permissions are not available. Because the SAM is not shared
between the host & container, there's no mapping between them. All permissions are
resolved within the context of the container.</li></ul><p>As a result, the following storage functionality is not supported on Windows nodes:</p><ul><li>Volume subpath mounts: only the entire volume can be mounted in a Windows container</li><li>Subpath volume mounting for Secrets</li><li>Host mount projection</li><li>Read-only root filesystem (mapped volumes still support <code>readOnly</code>)</li><li>Block device mapping</li><li>Memory as the storage medium (for example, <code>emptyDir.medium</code> set to <code>Memory</code>)</li><li>File system features like uid/gid; per-user Linux filesystem permissions</li><li>Setting <a href=/docs/concepts/configuration/secret/#secret-files-permissions>secret permissions with DefaultMode</a> (due to UID/GID dependency)</li><li>NFS based storage/volume support</li><li>Expanding the mounted volume (resizefs)</li></ul><p>Kubernetes <a class=glossary-tooltip title='A directory containing data, accessible to the containers in a pod.' data-toggle=tooltip data-placement=top href=/docs/concepts/storage/volumes/ target=_blank aria-label=volumes>volumes</a> enable complex
applications, with data persistence and Pod volume sharing requirements, to be deployed
on Kubernetes. Management of persistent volumes associated with a specific storage
back-end or protocol includes actions such as provisioning/de-provisioning/resizing
of volumes, attaching/detaching a volume to/from a Kubernetes node and
mounting/dismounting a volume to/from individual containers in a pod that needs to
persist data.</p><p>Volume management components are shipped as Kubernetes volume
<a href=/docs/concepts/storage/volumes/#types-of-volumes>plugin</a>.
The following broad classes of Kubernetes volume plugins are supported on Windows:</p><ul><li><a href=/docs/concepts/storage/volumes/#flexvolume><code>FlexVolume plugins</code></a><ul><li>Please note that FlexVolumes have been deprecated as of 1.23</li></ul></li><li><a href=/docs/concepts/storage/volumes/#csi><code>CSI Plugins</code></a></li></ul><h5 id=in-tree-volume-plugins>In-tree volume plugins</h5><p>The following in-tree plugins support persistent storage on Windows nodes:</p><ul><li><a href=/docs/concepts/storage/volumes/#awselasticblockstore><code>awsElasticBlockStore</code></a></li><li><a href=/docs/concepts/storage/volumes/#azuredisk><code>azureDisk</code></a></li><li><a href=/docs/concepts/storage/volumes/#azurefile><code>azureFile</code></a></li><li><a href=/docs/concepts/storage/volumes/#gcepersistentdisk><code>gcePersistentDisk</code></a></li><li><a href=/docs/concepts/storage/volumes/#vspherevolume><code>vsphereVolume</code></a></li></ul></div></main></div></div><footer class=d-print-none><div class=footer__links><nav><a class=text-white href=/docs/home/>Home</a>
<a class=text-white href=/blog/>Blog</a>
<a class=text-white href=/training/>Training</a>
<a class=text-white href=/partners/>Partners</a>
<a class=text-white href=/community/>Community</a>
<a class=text-white href=/case-studies/>Case Studies</a></nav></div><div class=container-fluid><div class=row><div class="col-6 col-sm-2 text-xs-center order-sm-2"><ul class="list-inline mb-0"><li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title="User mailing list" aria-label="User mailing list"><a class=text-white target=_blank href=https://discuss.kubernetes.io><i class="fa fa-envelope"></i></a></li><li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title=Twitter aria-label=Twitter><a class=text-white target=_blank href=https://twitter.com/kubernetesio><i class="fab fa-twitter"></i></a></li><li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title=Calendar aria-label=Calendar><a class=text-white target=_blank href="https://calendar.google.com/calendar/embed?src=calendar%40kubernetes.io"><i class="fas fa-calendar-alt"></i></a></li><li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title=Youtube aria-label=Youtube><a class=text-white target=_blank href=https://youtube.com/kubernetescommunity><i class="fab fa-youtube"></i></a></li></ul></div><div class="col-6 col-sm-2 text-right text-xs-center order-sm-3"><ul class="list-inline mb-0"><li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title=GitHub aria-label=GitHub><a class=text-white target=_blank href=https://github.com/kubernetes/kubernetes><i class="fab fa-github"></i></a></li><li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title=Slack aria-label=Slack><a class=text-white target=_blank href=https://slack.k8s.io><i class="fab fa-slack"></i></a></li><li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title=Contribute aria-label=Contribute><a class=text-white target=_blank href=https://git.k8s.io/community/contributors/guide><i class="fas fa-edit"></i></a></li><li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title="Stack Overflow" aria-label="Stack Overflow"><a class=text-white target=_blank href=https://stackoverflow.com/questions/tagged/kubernetes><i class="fab fa-stack-overflow"></i></a></li></ul></div><div class="col-12 col-sm-8 text-center order-sm-2"><small class=text-white>&copy; 2023 The Kubernetes Authors | Documentation Distributed under <a href=https://git.k8s.io/website/LICENSE class=light-text>CC BY 4.0</a></small><br><small class=text-white>Copyright &copy; 2023 The Linux Foundation &reg;. All rights reserved. The Linux Foundation has registered trademarks and uses trademarks. For a list of trademarks of The Linux Foundation, please see our <a href=https://www.linuxfoundation.org/trademark-usage class=light-text>Trademark Usage page</a></small><br><small class=text-white>ICP license: 京ICP备17074266号-3</small></div></div></div></footer></div><script src=/js/jquery-3.6.0.min.js integrity=sha384-vtXRMe3mGCbOeY7l30aIg8H9p3GdeSe4IFlP6G8JMa7o7lXvnz3GFKzPxzJdPfGK crossorigin=anonymous></script>
<script src=/js/popper-1.16.1.min.js intregrity=sha384-9/reFTGAW83EW2RDu2S0VKaIzap3H66lZH81PoYlFhbGU+6BZp6G7niu735Sk7lN crossorigin=anonymous></script>
<script src=/js/bootstrap-4.6.1.min.js integrity=sha384-VHvPCCyXqtD5DqJeNxl2dtTyhF78xXNXdkwX1CZeRusQfRKp+tA7hAShOK/B/fQ2 crossorigin=anonymous></script>
<script src=/js/script.js></script>
<script async src=/js/mermaid-8.13.4.min.js integrity=sha384-5hHNvPeMrNH14oM3IcQofDoBhiclNK3g2+hnEinKzQ07C4AliMeVpnvxuiwEGpaO crossorigin=anonymous></script>
<script src=/js/main.min.5c0bf7f21dc4f66485f74efbbeeff28a7e4f8cddaac1bae47043159c922ff3a3.js integrity="sha256-XAv38h3E9mSF9077vu/yin5PjN2qwbrkcEMVnJIv86M=" crossorigin=anonymous></script></body></html>