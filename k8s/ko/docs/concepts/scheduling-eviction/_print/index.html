<!doctype html><html lang=ko class=no-js><head><meta name=robots content="noindex, nofollow"><link rel=alternate hreflang=en href=https://kubernetes.io/docs/concepts/scheduling-eviction/><link rel=alternate hreflang=zh-cn href=https://kubernetes.io/zh-cn/docs/concepts/scheduling-eviction/><link rel=alternate hreflang=ja href=https://kubernetes.io/ja/docs/concepts/scheduling-eviction/><link rel=alternate hreflang=pt-br href=https://kubernetes.io/pt-br/docs/concepts/scheduling-eviction/><link rel=alternate hreflang=id href=https://kubernetes.io/id/docs/concepts/scheduling-eviction/><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=generator content="Hugo 0.110.0"><link rel=canonical type=text/html href=https://kubernetes.io/ko/docs/concepts/scheduling-eviction/><link rel="shortcut icon" type=image/png href=/images/favicon.png><link rel=apple-touch-icon href=/favicons/apple-touch-icon-180x180.png sizes=180x180><link rel=manifest href=/manifest.webmanifest><link rel=apple-touch-icon href=/images/kubernetes-192x192.png><title>스케줄링, 선점(Preemption), 축출(Eviction) | Kubernetes</title><meta property="og:title" content="스케줄링, 선점(Preemption), 축출(Eviction)"><meta property="og:description" content="쿠버네티스에서, 스케줄링은 kubelet이 파드를 실행할 수 있도록  파드를 노드에 할당하는 것을 말한다. 선점은 우선순위가 높은 파드가 노드에 스케줄될 수 있도록  우선순위가 낮은 파드를 종료시키는 과정을 말한다. 축출은 리소스가 부족한 노드에서 하나 이상의 파드를 사전에 종료시키는 프로세스이다.
"><meta property="og:type" content="website"><meta property="og:url" content="https://kubernetes.io/ko/docs/concepts/scheduling-eviction/"><meta property="og:site_name" content="Kubernetes"><meta itemprop=name content="스케줄링, 선점(Preemption), 축출(Eviction)"><meta itemprop=description content="쿠버네티스에서, 스케줄링은 kubelet이 파드를 실행할 수 있도록  파드를 노드에 할당하는 것을 말한다. 선점은 우선순위가 높은 파드가 노드에 스케줄될 수 있도록  우선순위가 낮은 파드를 종료시키는 과정을 말한다. 축출은 리소스가 부족한 노드에서 하나 이상의 파드를 사전에 종료시키는 프로세스이다.
"><meta name=twitter:card content="summary"><meta name=twitter:title content="스케줄링, 선점(Preemption), 축출(Eviction)"><meta name=twitter:description content="쿠버네티스에서, 스케줄링은 kubelet이 파드를 실행할 수 있도록  파드를 노드에 할당하는 것을 말한다. 선점은 우선순위가 높은 파드가 노드에 스케줄될 수 있도록  우선순위가 낮은 파드를 종료시키는 과정을 말한다. 축출은 리소스가 부족한 노드에서 하나 이상의 파드를 사전에 종료시키는 프로세스이다.
"><link href=/scss/main.css rel=stylesheet><script type=application/ld+json>{"@context":"https://schema.org","@type":"Organization","url":"https://kubernetes.io","logo":"https://kubernetes.io/images/favicon.png","potentialAction":{"@type":"SearchAction","target":"https://kubernetes.io/search/?q={search_term_string}","query-input":"required name=search_term_string"}}</script><meta name=theme-color content="#326ce5"><link rel=stylesheet href=/css/feature-states.css><meta name=description content="쿠버네티스에서, 스케줄링은 kubelet이 파드를 실행할 수 있도록  파드를 노드에 할당하는 것을 말한다. 선점은 우선순위가 높은 파드가 노드에 스케줄될 수 있도록  우선순위가 낮은 파드를 종료시키는 과정을 말한다. 축출은 리소스가 부족한 노드에서 하나 이상의 파드를 사전에 종료시키는 프로세스이다.
"><meta property="og:description" content="쿠버네티스에서, 스케줄링은 kubelet이 파드를 실행할 수 있도록  파드를 노드에 할당하는 것을 말한다. 선점은 우선순위가 높은 파드가 노드에 스케줄될 수 있도록  우선순위가 낮은 파드를 종료시키는 과정을 말한다. 축출은 리소스가 부족한 노드에서 하나 이상의 파드를 사전에 종료시키는 프로세스이다.
"><meta name=twitter:description content="쿠버네티스에서, 스케줄링은 kubelet이 파드를 실행할 수 있도록  파드를 노드에 할당하는 것을 말한다. 선점은 우선순위가 높은 파드가 노드에 스케줄될 수 있도록  우선순위가 낮은 파드를 종료시키는 과정을 말한다. 축출은 리소스가 부족한 노드에서 하나 이상의 파드를 사전에 종료시키는 프로세스이다.
"><meta property="og:url" content="https://kubernetes.io/ko/docs/concepts/scheduling-eviction/"><meta property="og:title" content="스케줄링, 선점(Preemption), 축출(Eviction)"><meta name=twitter:title content="스케줄링, 선점(Preemption), 축출(Eviction)"><meta name=twitter:image content="https://kubernetes.io/images/favicon.png"><meta name=twitter:image:alt content="Kubernetes"><meta property="og:image" content="/images/kubernetes-horizontal-color.png"><meta property="og:type" content="article"><script src=/js/jquery-3.6.0.min.js intregrity=sha384-vtXRMe3mGCbOeY7l30aIg8H9p3GdeSe4IFlP6G8JMa7o7lXvnz3GFKzPxzJdPfGK crossorigin=anonymous></script></head><body class=td-section><header><nav class="js-navbar-scroll navbar navbar-expand navbar-dark flex-column flex-md-row td-navbar" data-auto-burger=primary><a class=navbar-brand href=/ko/></a><div class="td-navbar-nav-scroll ml-md-auto" id=main_navbar><ul class="navbar-nav mt-2 mt-lg-0"><li class="nav-item mr-2 mb-lg-0"><a class="nav-link active" href=/ko/docs/>문서</a></li><li class="nav-item mr-2 mb-lg-0"><a class=nav-link href=/ko/blog/>쿠버네티스 블로그</a></li><li class="nav-item mr-2 mb-lg-0"><a class=nav-link href=/ko/training/>교육</a></li><li class="nav-item mr-2 mb-lg-0"><a class=nav-link href=/ko/partners/>파트너</a></li><li class="nav-item mr-2 mb-lg-0"><a class=nav-link href=/ko/community/>Community</a></li><li class="nav-item mr-2 mb-lg-0"><a class=nav-link href=/ko/case-studies/>사례 연구</a></li><li class="nav-item dropdown"><a class="nav-link dropdown-toggle" href=# id=navbarDropdown role=button data-toggle=dropdown aria-haspopup=true aria-expanded=false>버전</a><div class="dropdown-menu dropdown-menu-right" aria-labelledby=navbarDropdownMenuLink><a class=dropdown-item href=/ko/releases>Release Information</a>
<a class=dropdown-item href=https://kubernetes.io/ko/docs/concepts/scheduling-eviction/>v1.25</a>
<a class=dropdown-item href=https://v1-24.docs.kubernetes.io/ko/docs/concepts/scheduling-eviction/>v1.24</a>
<a class=dropdown-item href=https://v1-23.docs.kubernetes.io/ko/docs/concepts/scheduling-eviction/>v1.23</a>
<a class=dropdown-item href=https://v1-22.docs.kubernetes.io/ko/docs/concepts/scheduling-eviction/>v1.22</a>
<a class=dropdown-item href=https://v1-21.docs.kubernetes.io/ko/docs/concepts/scheduling-eviction/>v1.21</a></div></li><li class="nav-item dropdown"><a class="nav-link dropdown-toggle" href=# id=navbarDropdownMenuLink role=button data-toggle=dropdown aria-haspopup=true aria-expanded=false>한국어 (Korean)</a><div class="dropdown-menu dropdown-menu-right" aria-labelledby=navbarDropdownMenuLink><a class=dropdown-item href=/docs/concepts/scheduling-eviction/>English</a>
<a class=dropdown-item href=/zh-cn/docs/concepts/scheduling-eviction/>中文 (Chinese)</a>
<a class=dropdown-item href=/ja/docs/concepts/scheduling-eviction/>日本語 (Japanese)</a>
<a class=dropdown-item href=/pt-br/docs/concepts/scheduling-eviction/>Português (Portuguese)</a>
<a class=dropdown-item href=/id/docs/concepts/scheduling-eviction/>Bahasa Indonesia</a></div></li></ul></div><button id=hamburger onclick=kub.toggleMenu() data-auto-burger-exclude><div></div></button></nav></header><div class="container-fluid td-outer"><div class=td-main><div class="row flex-xl-nowrap"><main class="col-12 col-md-9 col-xl-8 pl-md-5" role=main><div class=td-content><div class="pageinfo pageinfo-primary d-print-none"><p>이 섹션의 다중 페이지 출력 화면임.
<a href=# onclick="return print(),!1">여기를 클릭하여 프린트</a>.</p><p><a href=/ko/docs/concepts/scheduling-eviction/>이 페이지의 일반 화면으로 돌아가기</a>.</p></div><h1 class=title>스케줄링, 선점(Preemption), 축출(Eviction)</h1><div class=lead>쿠버네티스에서, 스케줄링은 kubelet이 파드를 실행할 수 있도록 파드를 노드에 할당하는 것을 말한다. 선점은 우선순위가 높은 파드가 노드에 스케줄될 수 있도록 우선순위가 낮은 파드를 종료시키는 과정을 말한다. 축출은 리소스가 부족한 노드에서 하나 이상의 파드를 사전에 종료시키는 프로세스이다.</div><ul><li>1: <a href=#pg-598f36d691ab197f9d995784574b0a12>쿠버네티스 스케줄러</a></li><li>2: <a href=#pg-21169f516071aea5d16734a4c27789a5>노드에 파드 할당하기</a></li><li>3: <a href=#pg-da22fe2278df236f71efbe672f392677>파드 오버헤드</a></li><li>4: <a href=#pg-ede4960b56a3529ee0bfe7c8fe2d09a5>테인트(Taints)와 톨러레이션(Tolerations)</a></li><li>5: <a href=#pg-6b8c85a6a88f4a81e6b79e197c293c31>파드 토폴로지 분배 제약 조건</a></li><li>6: <a href=#pg-78e0431b4b7516092662a7c289cbb304>노드-압박 축출</a></li><li>7: <a href=#pg-b87723bf81b079042860f0ebd37b0a64>API를 이용한 축출(API-initiated Eviction)</a></li><li>8: <a href=#pg-60e5a2861609e0848d58ce8bf99c4a31>파드 우선순위(priority)와 선점(preemption)</a></li><li>9: <a href=#pg-961126cd43559012893979e568396a49>리소스 빈 패킹(bin packing)</a></li><li>10: <a href=#pg-d9574a30fcbc631b0d2a57850e161e89>스케줄러 성능 튜닝</a></li></ul><div class=content><p>쿠버네티스에서, 스케줄링은 <a class=glossary-tooltip title='클러스터의 각 노드에서 실행되는 에이전트. Kubelet은 파드에서 컨테이너가 확실하게 동작하도록 관리한다.' data-toggle=tooltip data-placement=top href=/docs/reference/generated/kubelet target=_blank aria-label=kubelet>kubelet</a>이 파드를 실행할 수 있도록
<a class=glossary-tooltip title='파드는 클러스터에서 실행 중인 컨테이너의 집합을 나타낸다.' data-toggle=tooltip data-placement=top href=/ko/docs/concepts/workloads/pods/ target=_blank aria-label=파드>파드</a>를
<a class=glossary-tooltip title='노드는 쿠버네티스의 작업 장비(worker machine)이다.' data-toggle=tooltip data-placement=top href=/ko/docs/concepts/architecture/nodes/ target=_blank aria-label=노드>노드</a>에 할당하는 것을 말한다.
선점은 <a class=glossary-tooltip title='파드 프라이어리티는 다른 파드에 대한 상대적인 중요도를 나타낸다.' data-toggle=tooltip data-placement=top href=/ko/docs/concepts/scheduling-eviction/pod-priority-preemption/#%ed%8c%8c%eb%93%9c-%ec%9a%b0%ec%84%a0%ec%88%9c%ec%9c%84 target=_blank aria-label=우선순위>우선순위</a>가 높은 파드가 노드에 스케줄될 수 있도록
우선순위가 낮은 파드를 종료시키는 과정을 말한다.
축출은 리소스가 부족한 노드에서 하나 이상의 파드를 사전에 종료시키는 프로세스이다.</p><h2 id=스케줄링>스케줄링</h2><ul><li><a href=/ko/docs/concepts/scheduling-eviction/kube-scheduler/>쿠버네티스 스케줄러</a></li><li><a href=/ko/docs/concepts/scheduling-eviction/assign-pod-node/>노드에 파드 할당하기</a></li><li><a href=/ko/docs/concepts/scheduling-eviction/pod-overhead/>파드 오버헤드</a></li><li><a href=/ko/docs/concepts/scheduling-eviction/topology-spread-constraints/>파드 토폴로지 분배 제약 조건</a></li><li><a href=/ko/docs/concepts/scheduling-eviction/taint-and-toleration/>테인트(Taints)와 톨러레이션(Tolerations)</a></li><li><a href=/docs/concepts/scheduling-eviction/scheduling-framework/>스케줄링 프레임워크</a></li><li><a href=/ko/docs/concepts/scheduling-eviction/scheduler-perf-tuning/>스케줄러 성능 튜닝</a></li><li><a href=/ko/docs/concepts/scheduling-eviction/resource-bin-packing/>확장된 리소스를 위한 리소스 빈 패킹(bin packing)</a></li></ul><h2 id=파드-중단-disruption>파드 중단(disruption)</h2><p><a href=/ko/docs/concepts/workloads/pods/disruptions/>파드 중단</a>은
노드에 있는 파드가 자발적 또는 비자발적으로 종료되는 절차이다.</p><p>자발적 중단은 애플리케이션 소유자 또는 클러스터 관리자가 의도적으로 시작한다.
비자발적 중단은 의도하지 않은 것이며,
노드의 리소스 부족과 같은 피할 수 없는 문제 또는 우발적인 삭제로 인해 트리거가 될 수 있다.</p><ul><li><a href=/ko/docs/concepts/scheduling-eviction/pod-priority-preemption/>파드 우선순위와 선점</a></li><li><a href=/ko/docs/concepts/scheduling-eviction/node-pressure-eviction/>노드-압박 축출</a></li><li><a href=/ko/docs/concepts/scheduling-eviction/api-eviction/>API를 이용한 축출</a></li></ul></div></div><div class=td-content style=page-break-before:always><h1 id=pg-598f36d691ab197f9d995784574b0a12>1 - 쿠버네티스 스케줄러</h1><p>쿠버네티스에서 <em>스케줄링</em> 은 <a class=glossary-tooltip title='클러스터의 각 노드에서 실행되는 에이전트. Kubelet은 파드에서 컨테이너가 확실하게 동작하도록 관리한다.' data-toggle=tooltip data-placement=top href=/docs/reference/generated/kubelet target=_blank aria-label=Kubelet>Kubelet</a>이
파드를 실행할 수 있도록 <a class=glossary-tooltip title='파드는 클러스터에서 실행 중인 컨테이너의 집합을 나타낸다.' data-toggle=tooltip data-placement=top href=/ko/docs/concepts/workloads/pods/ target=_blank aria-label=파드>파드</a>가
<a class=glossary-tooltip title='노드는 쿠버네티스의 작업 장비(worker machine)이다.' data-toggle=tooltip data-placement=top href=/ko/docs/concepts/architecture/nodes/ target=_blank aria-label=노드>노드</a>에 적합한지 확인하는 것을 말한다.</p><h2 id=scheduling>스케줄링 개요</h2><p>스케줄러는 노드가 할당되지 않은 새로 생성된 파드를 감시한다.
스케줄러가 발견한 모든 파드에 대해 스케줄러는 해당 파드가 실행될
최상의 노드를 찾는 책임을 진다. 스케줄러는
아래 설명된 스케줄링 원칙을 고려하여 이 배치 결정을
하게 된다.</p><p>파드가 특정 노드에 배치되는 이유를 이해하려고 하거나
사용자 정의된 스케줄러를 직접 구현하려는 경우 이
페이지를 통해서 스케줄링에 대해 배울 수 있을 것이다.</p><h2 id=kube-scheduler>kube-scheduler</h2><p><a href=/docs/reference/command-line-tools-reference/kube-scheduler/>kube-scheduler</a>는
쿠버네티스의 기본 스케줄러이며 <a class=glossary-tooltip title='컨테이너의 라이프사이클을 정의, 배포, 관리하기 위한 API와 인터페이스들을 노출하는 컨테이너 오케스트레이션 레이어.' data-toggle=tooltip data-placement=top href='/ko/docs/reference/glossary/?all=true#term-control-plane' target=_blank aria-label='컨트롤 플레인'>컨트롤 플레인</a>의
일부로 실행된다.
kube-scheduler는 원하거나 필요에 따라 자체 스케줄링 컴포넌트를
만들고 대신 사용할 수 있도록 설계되었다.</p><p>새로 생성된 모든 파드 또는 예약되지 않은 다른 파드에 대해 kube-scheduler는
실행할 최적의 노드를 선택한다. 그러나 파드의 모든 컨테이너에는
리소스에 대한 요구사항이 다르며 모든 파드에도
요구사항이 다르다. 따라서 기존 노드들은
특정 스케줄링 요구사항에 따라 필터링 되어야 한다.</p><p>클러스터에서 파드에 대한 스케줄링 요구사항을 충족하는 노드를
<em>실행 가능한(feasible)</em> 노드라고 한다. 적합한 노드가 없으면 스케줄러가
배치할 수 있을 때까지 파드가 스케줄 되지 않은 상태로 유지된다.</p><p>스케줄러는 파드가 실행 가능한 노드를 찾은 다음 실행 가능한 노드의
점수를 측정하는 기능 셋을 수행하고 실행 가능한 노드 중에서 가장 높은 점수를
가진 노드를 선택하여 파드를 실행한다. 그런 다음 스케줄러는
<em>바인딩</em> 이라는 프로세스에서 이 결정에 대해 API 서버에 알린다.</p><p>스케줄링 결정을 위해 고려해야 할 요소에는
개별 및 집단 리소스 요구사항, 하드웨어 / 소프트웨어 /
정책 제한조건, 어피니티 및 안티-어피니티 명세, 데이터
지역성(data locality), 워크로드 간 간섭 등이 포함된다.</p><h3 id=kube-scheduler-implementation>kube-scheduler에서 노드 선택</h3><p>kube-scheduler는 2단계 작업에서 파드에 대한 노드를 선택한다.</p><ol><li>필터링</li><li>스코어링(scoring)</li></ol><p><em>필터링</em> 단계는 파드를 스케줄링 할 수 있는 노드 셋을
찾는다. 예를 들어 PodFitsResources 필터는
후보 노드가 파드의 특정 리소스 요청을 충족시키기에 충분한 가용 리소스가
있는지 확인한다. 이 단계 다음에 노드 목록에는 적합한 노드들이
포함된다. 하나 이상의 노드가 포함된 경우가 종종 있을 것이다. 목록이 비어 있으면
해당 파드는 (아직) 스케줄링 될 수 없다.</p><p><em>스코어링</em> 단계에서 스케줄러는 목록에 남아있는 노드의 순위를 지정하여
가장 적합한 파드 배치를 선택한다. 스케줄러는 사용 중인 스코어링 규칙에 따라
이 점수를 기준으로 필터링에서 통과된 각 노드에 대해 점수를 지정한다.</p><p>마지막으로 kube-scheduler는 파드를 순위가 가장 높은 노드에 할당한다.
점수가 같은 노드가 두 개 이상인 경우 kube-scheduler는
이들 중 하나를 임의로 선택한다.</p><p>스케줄러의 필터링 및 스코어링 동작을 구성하는 데 지원되는 두 가지
방법이 있다.</p><ol><li><a href=/ko/docs/reference/scheduling/config/#%ED%94%84%EB%A1%9C%ED%8C%8C%EC%9D%BC>스케줄링 정책</a>을 사용하면 필터링을 위한 <em>단정(Predicates)</em> 및 스코어링을 위한 <em>우선순위(Priorities)</em> 를 구성할 수 있다.</li><li><a href=/ko/docs/reference/scheduling/config/#%ED%94%84%EB%A1%9C%ED%8C%8C%EC%9D%BC>스케줄링 프로파일</a>을 사용하면 <code>QueueSort</code>, <code>Filter</code>, <code>Score</code>, <code>Bind</code>, <code>Reserve</code>, <code>Permit</code> 등의 다른 스케줄링 단계를 구현하는 플러그인을 구성할 수 있다. 다른 프로파일을 실행하도록 kube-scheduler를 구성할 수도 있다.</li></ol><h2 id=다음-내용>다음 내용</h2><ul><li><a href=/ko/docs/concepts/scheduling-eviction/scheduler-perf-tuning/>스케줄러 성능 튜닝</a>에 대해 읽기</li><li><a href=/ko/docs/concepts/scheduling-eviction/topology-spread-constraints/>파드 토폴로지 분배 제약 조건</a>에 대해 읽기</li><li>kube-scheduler의 <a href=/docs/reference/command-line-tools-reference/kube-scheduler/>레퍼런스 문서</a> 읽기</li><li><a href=/docs/reference/config-api/kube-scheduler-config.v1beta3/>kube-scheduler 구성(v1beta3)</a> 레퍼런스 읽기</li><li><a href=/ko/docs/tasks/extend-kubernetes/configure-multiple-schedulers/>멀티 스케줄러 구성하기</a>에 대해 배우기</li><li><a href=/docs/tasks/administer-cluster/topology-manager/>토폴로지 관리 정책</a>에 대해 배우기</li><li><a href=/ko/docs/concepts/scheduling-eviction/pod-overhead/>파드 오버헤드</a>에 대해 배우기</li><li>볼륨을 사용하는 파드의 스케줄링에 대해 배우기<ul><li><a href=/ko/docs/concepts/storage/storage-classes/#%EB%B3%BC%EB%A5%A8-%EB%B0%94%EC%9D%B8%EB%94%A9-%EB%AA%A8%EB%93%9C>볼륨 토폴리지 지원</a></li><li><a href=/ko/docs/concepts/storage/storage-capacity/>스토리지 용량 추적</a></li><li><a href=/ko/docs/concepts/storage/storage-limits/>노드별 볼륨 한도</a></li></ul></li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-21169f516071aea5d16734a4c27789a5>2 - 노드에 파드 할당하기</h1><p>특정한 <a class=glossary-tooltip title='노드는 쿠버네티스의 작업 장비(worker machine)이다.' data-toggle=tooltip data-placement=top href=/ko/docs/concepts/architecture/nodes/ target=_blank aria-label=노드(들)>노드(들)</a> 집합에서만
동작하거나 특정한 노드 집합에서 동작하는 것을 선호하도록 <a class=glossary-tooltip title='파드는 클러스터에서 실행 중인 컨테이너의 집합을 나타낸다.' data-toggle=tooltip data-placement=top href=/ko/docs/concepts/workloads/pods/ target=_blank aria-label=파드>파드</a>를
제한할 수 있다.
이를 수행하는 방법에는 여러 가지가 있으며 권장되는 접근 방식은 모두
<a href=/ko/docs/concepts/overview/working-with-objects/labels/>레이블 셀렉터</a>를 사용하여 선택을 용이하게 한다.
보통은 <a class=glossary-tooltip title='노드가 배정되지 않은 새로 생성된 파드를 감지하고, 실행할 노드를 선택하는 컨트롤 플레인 컴포넌트.' data-toggle=tooltip data-placement=top href=/docs/reference/command-line-tools-reference/kube-scheduler/ target=_blank aria-label=스케줄러>스케줄러</a>가
자동으로 합리적인 배치(예: 자원이 부족한 노드에 파드를 배치하지 않도록
노드 간에 파드를 분배)를 수행하기에 이러한 제약 조건을 설정할 필요는 없다.
그러나, 예를 들어 SSD가 장착된 머신에 파드가 배포되도록 하거나 또는
많은 통신을 하는 두 개의 서로 다른 서비스의 파드를 동일한 가용성 영역(availability zone)에 배치하는 경우와 같이,
파드가 어느 노드에 배포될지를 제어해야 하는 경우도 있다.</p><p>쿠버네티스가 특정 파드를 어느 노드에 스케줄링할지 고르는
다음의 방법 중 하나를 골라 사용할 수 있다.</p><ul><li><a href=#built-in-node-labels>노드 레이블</a>에 매칭되는 <a href=#nodeselector>nodeSelector</a> 필드</li><li><a href=#affinity-and-anti-affinity>어피니티 / 안티 어피니티</a></li><li><a href=#nodename>nodeName</a> 필드</li><li><a href=#pod-topology-spread-constraints>파드 토폴로지 분배 제약 조건</a></li></ul><h2 id=built-in-node-labels>노드 레이블</h2><p>다른 쿠버네티스 오브젝트와 마찬가지로, 노드도 <a href=/ko/docs/concepts/overview/working-with-objects/labels/>레이블</a>을 가진다.
<a href=/ko/docs/tasks/configure-pod-container/assign-pods-nodes/#%EB%85%B8%EB%93%9C%EC%97%90-%EB%A0%88%EC%9D%B4%EB%B8%94-%EC%B6%94%EA%B0%80>레이블을 수동으로 추가</a>할 수 있다.
또한 쿠버네티스도 클러스터의 모든 노드에 표준화된 레이블 집합을 적용한다.
<a href=/ko/docs/reference/labels-annotations-taints/>잘 알려진 레이블, 어노테이션, 테인트</a>에서 널리 사용되는 노드 레이블의 목록을 확인한다.</p><div class="alert alert-info note callout" role=alert><strong>참고:</strong> 이러한 레이블에 대한 값은 클라우드 제공자별로 다르며 정확하지 않을 수 있다.
예를 들어, <code>kubernetes.io/hostname</code>에 대한 값은 특정 환경에서는 노드 이름과 동일할 수 있지만
다른 환경에서는 다른 값일 수도 있다.</div><h3 id=node-isolation-restriction>노드 격리/제한</h3><p>노드에 레이블을 추가하여
파드를 특정 노드 또는 노드 그룹에 스케줄링되도록 지정할 수 있다.
이 기능을 사용하여 특정 파드가 특정 격리/보안/규제 속성을 만족하는 노드에서만
실행되도록 할 수 있다.</p><p>노드 격리를 위해 레이블을 사용할 때, <a class=glossary-tooltip title='클러스터의 각 노드에서 실행되는 에이전트. Kubelet은 파드에서 컨테이너가 확실하게 동작하도록 관리한다.' data-toggle=tooltip data-placement=top href=/docs/reference/generated/kubelet target=_blank aria-label=kubelet>kubelet</a>이 변경할 수 없는 레이블 키를 선택한다.
그렇지 않으면 kubelet이 해당 레이블을 변경하여 노드가 사용 불가능(compromised) 상태로 빠지고
스케줄러가 이 노드에 워크로드를 스케줄링하는 일이 발생할 수 있다.</p><p><a href=/docs/reference/access-authn-authz/admission-controllers/#noderestriction><code>NodeRestriction</code> 어드미션 플러그인</a>은
kubelet이 <code>node-restriction.kubernetes.io/</code> 접두사를 갖는 레이블을
설정하거나 변경하지 못하도록 한다.</p><p>노드 격리를 위해 레이블 접두사를 사용하려면,</p><ol><li><a href=/docs/reference/access-authn-authz/node/>노드 인가자(authorizer)</a>를 사용하고 있는지, 그리고 <code>NodeRestriction</code> 어드미션 플러그인을 <strong>활성화</strong> 했는지 확인한다.</li><li>노드에 <code>node-restriction.kubernetes.io/</code> 접두사를 갖는 레이블을 추가하고, <a href=#nodeselector>노드 셀렉터</a>에서 해당 레이블을 사용한다.
예: <code>example.com.node-restriction.kubernetes.io/fips=true</code> 또는 <code>example.com.node-restriction.kubernetes.io/pci-dss=true</code></li></ol><h2 id=nodeselector>노드셀렉터(nodeSelector)</h2><p><code>nodeSelector</code>는 노드 선택 제약사항의 가장 간단하면서도 추천하는 형태이다.
파드 스펙에 <code>nodeSelector</code> 필드를 추가하고,
타겟으로 삼고 싶은 노드가 갖고 있는 <a href=#built-in-node-labels>노드 레이블</a>을 명시한다.
쿠버네티스는 사용자가 명시한 레이블을 갖고 있는 노드에만
파드를 스케줄링한다.</p><p><a href=/ko/docs/tasks/configure-pod-container/assign-pods-nodes>노드에 파드 할당</a>에서
더 많은 정보를 확인한다.</p><h2 id=affinity-and-anti-affinity>어피니티(affinity)와 안티-어피니티(anti-affinity)</h2><p><code>nodeSelector</code> 는 파드를 특정 레이블이 있는 노드로 제한하는 가장 간단한 방법이다.
어피니티/안티-어피니티 기능은 표현할 수 있는 제약 종류를 크게 확장한다.
주요 개선 사항은 다음과 같다.</p><ul><li>어피니티/안티-어피니티 언어가 더 표현적이다.
<code>nodeSelector</code>로는 명시한 레이블이 있는 노드만 선택할 수 있다.
어피니티/안티-어피니티는 선택 로직에 대한 좀 더 많은 제어권을 제공한다.</li><li>규칙이 "소프트(soft)" 또는 "선호사항(preference)" 임을 나타낼 수 있으며,
이 덕분에 스케줄러는 매치되는 노드를 찾지 못한 경우에도 파드를 스케줄링할 수 있다.</li><li>다른 노드 (또는 다른 토폴로지 도메인)에서 실행 중인
다른 파드의 레이블을 사용하여 파드를 제한할 수 있으며,
이를 통해 어떤 파드들이 노드에 함께 위치할 수 있는지에 대한 규칙을 정의할 수 있다.</li></ul><p>어피니티 기능은 다음의 두 가지 종류로 구성된다.</p><ul><li><em>노드 어피니티</em> 기능은 <code>nodeSelector</code> 필드와 비슷하지만
더 표현적이고 소프트(soft) 규칙을 지정할 수 있게 해 준다.</li><li><em>파드 간 어피니티/안티-어피니티</em> 는 다른 파드의 레이블을 이용하여
해당 파드를 제한할 수 있게 해 준다.</li></ul><h3 id=node-affinity>노드 어피니티</h3><p>노드 어피니티는 개념적으로 <code>nodeSelector</code> 와 비슷하며,
노드의 레이블을 기반으로 파드가 스케줄링될 수 있는 노드를 제한할 수 있다.
노드 어피니티에는 다음의 두 종류가 있다.</p><ul><li><code>requiredDuringSchedulingIgnoredDuringExecution</code>:
규칙이 만족되지 않으면 스케줄러가 파드를 스케줄링할 수 없다.
이 기능은 <code>nodeSelector</code>와 유사하지만, 좀 더 표현적인 문법을 제공한다.</li><li><code>preferredDuringSchedulingIgnoredDuringExecution</code>:
스케줄러는 조건을 만족하는 노드를 찾으려고 노력한다.
해당되는 노드가 없더라도, 스케줄러는 여전히 파드를 스케줄링한다.</li></ul><div class="alert alert-info note callout" role=alert><strong>참고:</strong> 앞의 두 유형에서, <code>IgnoredDuringExecution</code>는
쿠버네티스가 파드를 스케줄링한 뒤에 노드 레이블이 변경되어도 파드는 계속 해당 노드에서 실행됨을 의미한다.</div><p>파드 스펙의 <code>.spec.affinity.nodeAffinity</code> 필드에
노드 어피니티를 명시할 수 있다.</p><p>예를 들어, 다음과 같은 파드 스펙이 있다고 하자.</p><div class=highlight><div class=copy-code-icon style=text-align:right><a href=https://raw.githubusercontent.com/kubernetes/website/main/content/ko/examples/pods/pod-with-node-affinity.yaml download=pods/pod-with-node-affinity.yaml><code>pods/pod-with-node-affinity.yaml</code></a>
<img src=/images/copycode.svg style=max-height:24px;cursor:pointer onclick='copyCode("pods-pod-with-node-affinity-yaml")' title="Copy pods/pod-with-node-affinity.yaml to clipboard"></img></div><div class=includecode id=pods-pod-with-node-affinity-yaml><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>with-node-affinity<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>affinity</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>nodeAffinity</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>requiredDuringSchedulingIgnoredDuringExecution</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>nodeSelectorTerms</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span>- <span style=color:green;font-weight:700>matchExpressions</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span>- <span style=color:green;font-weight:700>key</span>:<span style=color:#bbb> </span>topology.kubernetes.io/zone<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>            </span><span style=color:green;font-weight:700>operator</span>:<span style=color:#bbb> </span>In<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>            </span><span style=color:green;font-weight:700>values</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>            </span>- antarctica-east1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>            </span>- antarctica-west1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>preferredDuringSchedulingIgnoredDuringExecution</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- <span style=color:green;font-weight:700>weight</span>:<span style=color:#bbb> </span><span style=color:#666>1</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>preference</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>matchExpressions</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span>- <span style=color:green;font-weight:700>key</span>:<span style=color:#bbb> </span>another-node-label-key<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>            </span><span style=color:green;font-weight:700>operator</span>:<span style=color:#bbb> </span>In<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>            </span><span style=color:green;font-weight:700>values</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>            </span>- another-node-label-value<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>with-node-affinity<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>registry.k8s.io/pause:2.0</span></span></code></pre></div></div></div><p>이 예시에서는 다음의 규칙이 적용된다.</p><ul><li>노드는 키가 <code>topology.kubernetes.io/zone</code>인 레이블을 갖고 <em>있어야 하며</em>,
레이블의 값이 <code>antarctica-east1</code> 혹은 <code>antarctica-west1</code><em>여야 한다</em>.</li><li>키가 <code>another-node-label-key</code>이고 값이 <code>another-node-label-value</code>인 레이블을
갖고 있는 노드를 <em>선호한다</em> .</li></ul><p><code>operator</code> 필드를 사용하여
쿠버네티스가 규칙을 해석할 때 사용할 논리 연산자를 지정할 수 있다.
<code>In</code>, <code>NotIn</code>, <code>Exists</code>, <code>DoesNotExist</code>, <code>Gt</code> 및 <code>Lt</code> 연산자를 사용할 수 있다.</p><p><code>NotIn</code> 및 <code>DoesNotExist</code> 연산자를 사용하여 노드 안티-어피니티 규칙을 정의할 수 있다.
또는, 특정 노드에서 파드를 쫓아내는
<a href=/ko/docs/concepts/scheduling-eviction/taint-and-toleration/>노드 테인트(taint)</a>를 설정할 수 있다.</p><div class="alert alert-info note callout" role=alert><strong>참고:</strong><p><code>nodeSelector</code>와 <code>nodeAffinity</code>를 모두 사용하는 경우,
파드가 노드에 스케줄링되려면 두 조건 <em>모두</em> 만족되어야 한다.</p><p><code>nodeAffinity</code>에 연결된 <code>nodeSelectorTerms</code>를 여러 개 명시한 경우,
명시된 <code>nodeSelectorTerms</code> 중 하나를 만족하는 노드에도
파드가 스케줄링될 수 있다.</p><p>단일 <code>nodeSelectorTerms</code>와 연결된 <code>matchExpressions</code>를 여러 개 명시한 경우,
모든 <code>matchExpressions</code>를 만족하는 노드에만
파드가 스케줄링될 수 있다.</p></div><p><a href=/ko/docs/tasks/configure-pod-container/assign-pods-nodes-using-node-affinity/>노드 어피니티를 사용해 노드에 파드 할당</a>에서
더 많은 정보를 확인한다.</p><h4 id=node-affinity-weight>노드 어피니티 가중치(weight)</h4><p>각 <code>preferredDuringSchedulingIgnoredDuringExecution</code> 어피니티 타입 인스턴스에 대해
1-100 범위의 <code>weight</code>를 명시할 수 있다.
스케줄러가 다른 모든 파드 스케줄링 요구 사항을 만족하는 노드를 찾으면,
스케줄러는 노드가 만족한 모든 선호하는(preferred) 규칙에 대해
합계 계산을 위한 <code>weight</code> 값을 각각 추가한다.</p><p>최종 합계는 해당 노드에 대한 다른 우선 순위 함수 점수에 더해진다.
스케줄러가 파드에 대한 스케줄링 판단을 할 때,
총 점수가 가장 높은 노드가 우선 순위를 갖는다.</p><p>예를 들어, 다음과 같은 파드 스펙이 있다고 하자.</p><div class=highlight><div class=copy-code-icon style=text-align:right><a href=https://raw.githubusercontent.com/kubernetes/website/main/content/ko/examples/pods/pod-with-affinity-anti-affinity.yaml download=pods/pod-with-affinity-anti-affinity.yaml><code>pods/pod-with-affinity-anti-affinity.yaml</code></a>
<img src=/images/copycode.svg style=max-height:24px;cursor:pointer onclick='copyCode("pods-pod-with-affinity-anti-affinity-yaml")' title="Copy pods/pod-with-affinity-anti-affinity.yaml to clipboard"></img></div><div class=includecode id=pods-pod-with-affinity-anti-affinity-yaml><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>with-affinity-anti-affinity<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>affinity</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>nodeAffinity</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>requiredDuringSchedulingIgnoredDuringExecution</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>nodeSelectorTerms</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span>- <span style=color:green;font-weight:700>matchExpressions</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span>- <span style=color:green;font-weight:700>key</span>:<span style=color:#bbb> </span>kubernetes.io/os<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>            </span><span style=color:green;font-weight:700>operator</span>:<span style=color:#bbb> </span>In<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>            </span><span style=color:green;font-weight:700>values</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>            </span>- linux<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>preferredDuringSchedulingIgnoredDuringExecution</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- <span style=color:green;font-weight:700>weight</span>:<span style=color:#bbb> </span><span style=color:#666>1</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>preference</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>matchExpressions</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span>- <span style=color:green;font-weight:700>key</span>:<span style=color:#bbb> </span>label-1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>            </span><span style=color:green;font-weight:700>operator</span>:<span style=color:#bbb> </span>In<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>            </span><span style=color:green;font-weight:700>values</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>            </span>- key-1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- <span style=color:green;font-weight:700>weight</span>:<span style=color:#bbb> </span><span style=color:#666>50</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>preference</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>matchExpressions</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span>- <span style=color:green;font-weight:700>key</span>:<span style=color:#bbb> </span>label-2<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>            </span><span style=color:green;font-weight:700>operator</span>:<span style=color:#bbb> </span>In<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>            </span><span style=color:green;font-weight:700>values</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>            </span>- key-2<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>with-node-affinity<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>registry.k8s.io/pause:2.0<span style=color:#bbb>
</span></span></span></code></pre></div></div></div><p><code>preferredDuringSchedulingIgnoredDuringExecution</code> 규칙을 만족하는 노드가 2개 있고,
하나에는 <code>label-1:key-1</code> 레이블이 있고 다른 하나에는 <code>label-2:key-2</code> 레이블이 있으면,
스케줄러는 각 노드의 <code>weight</code>를 확인한 뒤
해당 노드에 대한 다른 점수에 가중치를 더하고,
최종 점수가 가장 높은 노드에 해당 파드를 스케줄링한다.</p><div class="alert alert-info note callout" role=alert><strong>참고:</strong> 이 예시에서 쿠버네티스가 정상적으로 파드를 스케줄링하려면,
보유하고 있는 노드에 <code>kubernetes.io/os=linux</code> 레이블이 있어야 한다.</div><h4 id=node-affinity-per-scheduling-profile>스케줄링 프로파일당 노드 어피니티</h4><div style=margin-top:10px;margin-bottom:10px><b>기능 상태:</b> <code>Kubernetes v1.20 [beta]</code></div><p>여러 <a href=/ko/docs/reference/scheduling/config/#%EC%97%AC%EB%9F%AC-%ED%94%84%EB%A1%9C%ED%8C%8C%EC%9D%BC>스케줄링 프로파일</a>을 구성할 때
노드 어피니티가 있는 프로파일을 연결할 수 있는데, 이는 프로파일이 특정 노드 집합에만 적용되는 경우 유용하다.
이렇게 하려면 다음과 같이 <a href=/ko/docs/reference/scheduling/config/>스케줄러 구성</a>에 있는
<a href=/ko/docs/reference/scheduling/config/#%EC%8A%A4%EC%BC%80%EC%A4%84%EB%A7%81-%ED%94%8C%EB%9F%AC%EA%B7%B8%EC%9D%B8-1><code>NodeAffinity</code> 플러그인</a>의 <code>args</code> 필드에 <code>addedAffinity</code>를 추가한다.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>kubescheduler.config.k8s.io/v1beta3<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>KubeSchedulerConfiguration<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>profiles</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>schedulerName</span>:<span style=color:#bbb> </span>default-scheduler<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>schedulerName</span>:<span style=color:#bbb> </span>foo-scheduler<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>pluginConfig</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>NodeAffinity<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>args</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>addedAffinity</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>            </span><span style=color:green;font-weight:700>requiredDuringSchedulingIgnoredDuringExecution</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>              </span><span style=color:green;font-weight:700>nodeSelectorTerms</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>              </span>- <span style=color:green;font-weight:700>matchExpressions</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>                </span>- <span style=color:green;font-weight:700>key</span>:<span style=color:#bbb> </span>scheduler-profile<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>                  </span><span style=color:green;font-weight:700>operator</span>:<span style=color:#bbb> </span>In<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>                  </span><span style=color:green;font-weight:700>values</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>                  </span>- foo<span style=color:#bbb>
</span></span></span></code></pre></div><p><code>addedAffinity</code>는 <code>.spec.schedulerName</code>을 <code>foo-scheduler</code>로 설정하는 모든 파드에 적용되며
PodSpec에 지정된 NodeAffinity도 적용된다.
즉, 파드를 매칭시키려면, 노드가 <code>addedAffinity</code>와
파드의 <code>.spec.NodeAffinity</code>를 충족해야 한다.</p><p><code>addedAffinity</code>는 엔드 유저에게 표시되지 않으므로,
예상치 못한 동작이 일어날 수 있다.
스케줄러 프로파일 이름과 명확한 상관 관계가 있는 노드 레이블을 사용한다.</p><div class="alert alert-info note callout" role=alert><strong>참고:</strong> <a href=/ko/docs/concepts/workloads/controllers/daemonset/#%EA%B8%B0%EB%B3%B8-%EC%8A%A4%EC%BC%80%EC%A4%84%EB%9F%AC%EB%A1%9C-%EC%8A%A4%EC%BC%80%EC%A4%84>데몬셋 파드를 생성</a>하는 데몬셋 컨트롤러는
스케줄링 프로파일을 지원하지 않는다.
데몬셋 컨트롤러가 파드를 생성할 때, 기본 쿠버네티스 스케줄러는 해당 파드를 배치하고
데몬셋 컨트롤러의 모든 <code>nodeAffinity</code> 규칙을 준수한다.</div><h3 id=inter-pod-affinity-and-anti-affinity>파드간 어피니티와 안티-어피니티</h3><p>파드간 어피니티와 안티-어피니티를 사용하여,
노드 레이블 대신, 각 노드에 이미 실행 중인 다른 <strong>파드</strong> 의 레이블을 기반으로
파드가 스케줄링될 노드를 제한할 수 있다.</p><p>파드간 어피니티와 안티-어피니티 규칙은
"X가 규칙 Y를 충족하는 하나 이상의 파드를 이미 실행중인 경우 이 파드는 X에서 실행해야 한다(또는
안티-어피니티의 경우에는 "실행하면 안 된다")"의 형태이며,
여기서 X는 노드, 랙, 클라우드 제공자 존 또는 리전 등이며
Y는 쿠버네티스가 충족할 규칙이다.</p><p>이러한 규칙(Y)은 <a href=/ko/docs/concepts/overview/working-with-objects/labels/#%EB%A0%88%EC%9D%B4%EB%B8%94-%EC%85%80%EB%A0%89%ED%84%B0>레이블 셀렉터</a> 형태로 작성하며,
연관된 네임스페이스 목록을 선택적으로 명시할 수도 있다.
쿠버네티스에서 파드는 네임스페이스에 속하는(namespaced) 오브젝트이므로,
파드 레이블도 암묵적으로 특정 네임스페이스에 속하게 된다.
파드 레이블에 대한 모든 레이블 셀렉터는 쿠버네티스가 해당 레이블을 어떤 네임스페이스에서 탐색할지를 명시해야 한다.</p><p><code>topologyKey</code>를 사용하여 토폴로지 도메인(X)를 나타낼 수 있으며,
이는 시스템이 도메인을 표시하기 위해 사용하는 노드 레이블의 키이다.
이에 대한 예시는 <a href=/ko/docs/reference/labels-annotations-taints/>잘 알려진 레이블, 어노테이션, 테인트</a>를 참고한다.</p><div class="alert alert-info note callout" role=alert><strong>참고:</strong> 파드간 어피니티와 안티-어피니티에는 상당한 양의 프로세싱이 필요하기에
대규모 클러스터에서는 스케줄링 속도가 크게 느려질 수 있다.
수백 개의 노드를 넘어가는 클러스터에서 이를 사용하는 것은 추천하지 않는다.</div><div class="alert alert-info note callout" role=alert><strong>참고:</strong> 파드 안티-어피니티에서는 노드에 일관된 레이블을 지정해야 한다.
즉, 클러스터의 모든 노드는 <code>topologyKey</code> 와 매칭되는 적절한 레이블을 가지고 있어야 한다.
일부 또는 모든 노드에 지정된 <code>topologyKey</code> 레이블이 없는 경우에는
의도하지 않은 동작이 발생할 수 있다.</div><h4 id=types-of-inter-pod-affinity-and-anti-affinity>파드간 어피니티 및 안티-어피니티 종류</h4><p>노드 어피니티와 마찬가지로
파드 어피니티 및 안티-어피니티에는 다음의 2 종류가 있다.</p><ul><li><code>requiredDuringSchedulingIgnoredDuringExecution</code></li><li><code>preferredDuringSchedulingIgnoredDuringExecution</code></li></ul><p>예를 들어, <code>requiredDuringSchedulingIgnoredDuringExecution</code> 어피니티를 사용하여
서로 통신을 많이 하는 두 서비스의 파드를
동일 클라우드 제공자 존에 배치하도록 스케줄러에게 지시할 수 있다.
비슷하게, <code>preferredDuringSchedulingIgnoredDuringExecution</code> 안티-어피니티를 사용하여
서비스의 파드를
여러 클라우드 제공자 존에 퍼뜨릴 수 있다.</p><p>파드간 어피니티를 사용하려면, 파드 스펙에 <code>affinity.podAffinity</code> 필드를 사용한다.
파드간 안티-어피니티를 사용하려면,
파드 스펙에 <code>affinity.podAntiAffinity</code> 필드를 사용한다.</p><h4 id=an-example-of-a-pod-that-uses-pod-affinity>파드 어피니티 예시</h4><p>다음과 같은 파드 스펙을 가정한다.</p><div class=highlight><div class=copy-code-icon style=text-align:right><a href=https://raw.githubusercontent.com/kubernetes/website/main/content/ko/examples/pods/pod-with-pod-affinity.yaml download=pods/pod-with-pod-affinity.yaml><code>pods/pod-with-pod-affinity.yaml</code></a>
<img src=/images/copycode.svg style=max-height:24px;cursor:pointer onclick='copyCode("pods-pod-with-pod-affinity-yaml")' title="Copy pods/pod-with-pod-affinity.yaml to clipboard"></img></div><div class=includecode id=pods-pod-with-pod-affinity-yaml><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>with-pod-affinity<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>affinity</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>podAffinity</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>requiredDuringSchedulingIgnoredDuringExecution</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- <span style=color:green;font-weight:700>labelSelector</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>matchExpressions</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span>- <span style=color:green;font-weight:700>key</span>:<span style=color:#bbb> </span>security<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>            </span><span style=color:green;font-weight:700>operator</span>:<span style=color:#bbb> </span>In<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>            </span><span style=color:green;font-weight:700>values</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>            </span>- S1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>topologyKey</span>:<span style=color:#bbb> </span>topology.kubernetes.io/zone<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>podAntiAffinity</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>preferredDuringSchedulingIgnoredDuringExecution</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- <span style=color:green;font-weight:700>weight</span>:<span style=color:#bbb> </span><span style=color:#666>100</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>podAffinityTerm</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>labelSelector</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>            </span><span style=color:green;font-weight:700>matchExpressions</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>            </span>- <span style=color:green;font-weight:700>key</span>:<span style=color:#bbb> </span>security<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>              </span><span style=color:green;font-weight:700>operator</span>:<span style=color:#bbb> </span>In<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>              </span><span style=color:green;font-weight:700>values</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>              </span>- S2<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>topologyKey</span>:<span style=color:#bbb> </span>topology.kubernetes.io/zone<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>with-pod-affinity<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>registry.k8s.io/pause:2.0<span style=color:#bbb>
</span></span></span></code></pre></div></div></div><p>이 예시는 하나의 파드 어피니티 규칙과
하나의 파드 안티-어피니티 규칙을 정의한다.
파드 어피니티 규칙은 "하드" <code>requiredDuringSchedulingIgnoredDuringExecution</code>을,
안티-어피니티 규칙은 "소프트" <code>preferredDuringSchedulingIgnoredDuringExecution</code>을 사용한다.</p><p>위의 어피니티 규칙은 <code>security=S1</code> 레이블이 있는 하나 이상의 기존 파드의 존와 동일한 존에 있는 노드에만
파드를 스케줄링하도록 스케줄러에 지시한다.
더 정확히 말하면, 만약 <code>security=S1</code> 파드 레이블이 있는 하나 이상의 기존 파드를 실행하고 있는 노드가
<code>zone=V</code>에 하나 이상 존재한다면,
스케줄러는 파드를 <code>topology.kubernetes.io/zone=V</code> 레이블이 있는 노드에 배치해야 한다.</p><p>위의 안티-어피니티 규칙은 <code>security=S2</code> 레이블이 있는 하나 이상의 기존 파드의 존와 동일한 존에 있는 노드에는
가급적 파드를 스케줄링하지 않도록 스케줄러에 지시한다.
더 정확히 말하면, 만약 <code>security=S2</code> 파드 레이블이 있는 파드가 실행되고 있는 <code>zone=R</code>에
다른 노드도 존재한다면,
스케줄러는 <code>topology.kubernetes.io/zone=R</code> 레이블이 있는 노드에는 가급적 해당 파드를 스케줄링하지 않야아 한다.</p><p>파드 어피니티와 안티-어피니티의 예시에 대해 익숙해지고 싶다면,
<a href=https://git.k8s.io/design-proposals-archive/scheduling/podaffinity.md>디자인 제안</a>을 참조한다.</p><p>파드 어피니티와 안티-어피니티의 <code>operator</code> 필드에
<code>In</code>, <code>NotIn</code>, <code>Exists</code> 및 <code>DoesNotExist</code> 값을 사용할 수 있다.</p><p>원칙적으로, <code>topologyKey</code> 에는 성능과 보안상의 이유로 다음의 예외를 제외하면
어느 레이블 키도 사용할 수 있다.</p><ul><li>파드 어피니티 및 안티-어피니티에 대해, 빈 <code>topologyKey</code> 필드는
<code>requiredDuringSchedulingIgnoredDuringExecution</code> 및 <code>preferredDuringSchedulingIgnoredDuringExecution</code> 내에 허용되지 않는다.</li><li><code>requiredDuringSchedulingIgnoredDuringExecution</code> 파드 안티-어피니티 규칙에 대해,
<code>LimitPodHardAntiAffinityTopology</code> 어드미션 컨트롤러는
<code>topologyKey</code>를 <code>kubernetes.io/hostname</code>으로 제한한다.
커스텀 토폴로지를 허용하고 싶다면 어드미션 컨트롤러를 수정하거나 비활성화할 수 있다.</li></ul><p><code>labelSelector</code>와 <code>topologyKey</code>에 더하여 선택적으로,
<code>labelSelector</code>가 비교해야 하는 네임스페이스의 목록을
<code>labelSelector</code> 및 <code>topologyKey</code> 필드와 동일한 계위의 <code>namespaces</code> 필드에 명시할 수 있다.
생략하거나 비워 두면,
해당 어피니티/안티-어피니티 정의가 있는 파드의 네임스페이스를 기본값으로 사용한다.</p><h4 id=namespace-selector>네임스페이스 셀렉터</h4><div style=margin-top:10px;margin-bottom:10px><b>기능 상태:</b> <code>Kubernetes v1.24 [stable]</code></div><p>네임스페이스 집합에 대한 레이블 쿼리인 <code>namespaceSelector</code> 를 사용하여 일치하는 네임스페이스를 선택할 수도 있다.
<code>namespaceSelector</code> 또는 <code>namespaces</code> 필드에 의해 선택된 네임스페이스 모두에 적용된다.
빈 <code>namespaceSelector</code> ({})는 모든 네임스페이스와 일치하는 반면,
null 또는 빈 <code>namespaces</code> 목록과 null <code>namespaceSelector</code> 는 규칙이 적용된 파드의 네임스페이스에 매치된다.</p><h4 id=more-practical-use-cases>더 실제적인 유스케이스</h4><p>파드간 어피니티와 안티-어피니티는 레플리카셋, 스테이트풀셋, 디플로이먼트 등과 같은
상위 레벨 모음과 함께 사용할 때 더욱 유용할 수 있다.
이러한 규칙을 사용하면, 워크로드 집합이 예를 들면
서로 연관된 두 개의 파드를 동일한 노드에 배치하는 것과 같이 동일하게 정의된 토폴로지와
같은 위치에 배치되도록 쉽게 구성할 수 있다.</p><p>세 개의 노드로 구성된 클러스터를 상상해 보자. 이 클러스터에서 redis와 같은 인-메모리 캐시를 이용하는 웹 애플리케이션을 실행한다.
또한 이 예에서 웹 애플리케이션과 메모리 캐시 사이의 대기 시간은 될 수 있는 대로 짧아야 한다고 가정하자.
이 때 웹 서버를 가능한 한 캐시와 같은 위치에서 실행되도록 하기 위해
파드간 어피니티/안티-어피니티를 사용할 수 있다.</p><p>다음의 redis 캐시 디플로이먼트 예시에서, 레플리카는 <code>app=store</code> 레이블을 갖는다.
<code>podAntiAffinity</code> 규칙은 스케줄러로 하여금
<code>app=store</code> 레이블을 가진 복수 개의 레플리카를 단일 노드에 배치하지 않게 한다.
이렇게 하여 캐시 파드를 각 노드에 분산하여 생성한다.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>apps/v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Deployment<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>redis-cache<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>selector</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>matchLabels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>app</span>:<span style=color:#bbb> </span>store<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>replicas</span>:<span style=color:#bbb> </span><span style=color:#666>3</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>template</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>labels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>app</span>:<span style=color:#bbb> </span>store<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>affinity</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>podAntiAffinity</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>requiredDuringSchedulingIgnoredDuringExecution</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span>- <span style=color:green;font-weight:700>labelSelector</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>              </span><span style=color:green;font-weight:700>matchExpressions</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>              </span>- <span style=color:green;font-weight:700>key</span>:<span style=color:#bbb> </span>app<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>                </span><span style=color:green;font-weight:700>operator</span>:<span style=color:#bbb> </span>In<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>                </span><span style=color:green;font-weight:700>values</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>                </span>- store<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>            </span><span style=color:green;font-weight:700>topologyKey</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;kubernetes.io/hostname&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>redis-server<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>redis:3.2-alpine<span style=color:#bbb>
</span></span></span></code></pre></div><p>웹 서버를 위한 다음의 디플로이먼트는 <code>app=web-store</code> 레이블을 갖는 레플리카를 생성한다.
파드 어피니티 규칙은 스케줄러로 하여금 <code>app=store</code> 레이블이 있는 파드를 실행 중인 노드에 각 레플리카를 배치하도록 한다.
파드 안티-어피니티 규칙은 스케줄러로 하여금 <code>app=web-store</code> 레이블이 있는 서버 파드를
한 노드에 여러 개 배치하지 못하도록 한다.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>apps/v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Deployment<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>web-server<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>selector</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>matchLabels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>app</span>:<span style=color:#bbb> </span>web-store<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>replicas</span>:<span style=color:#bbb> </span><span style=color:#666>3</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>template</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>labels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>app</span>:<span style=color:#bbb> </span>web-store<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>affinity</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>podAntiAffinity</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>requiredDuringSchedulingIgnoredDuringExecution</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span>- <span style=color:green;font-weight:700>labelSelector</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>              </span><span style=color:green;font-weight:700>matchExpressions</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>              </span>- <span style=color:green;font-weight:700>key</span>:<span style=color:#bbb> </span>app<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>                </span><span style=color:green;font-weight:700>operator</span>:<span style=color:#bbb> </span>In<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>                </span><span style=color:green;font-weight:700>values</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>                </span>- web-store<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>            </span><span style=color:green;font-weight:700>topologyKey</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;kubernetes.io/hostname&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>podAffinity</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>requiredDuringSchedulingIgnoredDuringExecution</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span>- <span style=color:green;font-weight:700>labelSelector</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>              </span><span style=color:green;font-weight:700>matchExpressions</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>              </span>- <span style=color:green;font-weight:700>key</span>:<span style=color:#bbb> </span>app<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>                </span><span style=color:green;font-weight:700>operator</span>:<span style=color:#bbb> </span>In<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>                </span><span style=color:green;font-weight:700>values</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>                </span>- store<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>            </span><span style=color:green;font-weight:700>topologyKey</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;kubernetes.io/hostname&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>web-app<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>nginx:1.16-alpine<span style=color:#bbb>
</span></span></span></code></pre></div><p>위의 두 디플로이먼트를 생성하면 다음과 같은 클러스터 형상이 나타나는데,
세 노드에 각 웹 서버가 캐시와 함께 있는 형상이다.</p><table><thead><tr><th style=text-align:center>node-1</th><th style=text-align:center>node-2</th><th style=text-align:center>node-3</th></tr></thead><tbody><tr><td style=text-align:center><em>webserver-1</em></td><td style=text-align:center><em>webserver-2</em></td><td style=text-align:center><em>webserver-3</em></td></tr><tr><td style=text-align:center><em>cache-1</em></td><td style=text-align:center><em>cache-2</em></td><td style=text-align:center><em>cache-3</em></td></tr></tbody></table><p>전체적인 효과는 각 캐시 인스턴스를 동일한 노드에서 실행 중인 단일 클라이언트가 액세스하게 될 것 같다는 것이다.
이 접근 방식은 차이(불균형 로드)와 대기 ​​시간을 모두 최소화하는 것을 목표로 한다.</p><p>파드간 안티-어피니티를 사용해야 하는 다른 이유가 있을 수 있다.
<a href=/ko/docs/tutorials/stateful-application/zookeeper/#%EB%85%B8%EB%93%9C-%EC%8B%A4%ED%8C%A8-%EB%B0%A9%EC%A7%80>ZooKeeper 튜토리얼</a>에서
위 예시와 동일한 기술을 사용해
고 가용성을 위한 안티-어피니티로 구성된 스테이트풀셋의 예시를 확인한다.</p><h2 id=nodename>nodeName</h2><p><code>nodeName</code>은 어피니티 또는 <code>nodeSelector</code>보다 더 직접적인 형태의 노드 선택 방법이다.
<code>nodeName</code>은 파드 스펙의 필드 중 하나이다.
<code>nodeName</code> 필드가 비어 있지 않으면, 스케줄러는 파드를 무시하고,
명명된 노드의 kubelet이 해당 파드를 자기 노드에 배치하려고 시도한다.
<code>nodeName</code>은 <code>nodeSelector</code> 또는 어피니티/안티-어피니티 규칙보다 우선적으로 적용(overrule)된다.</p><p><code>nodeName</code> 을 사용해서 노드를 선택할 때의 몇 가지 제한은 다음과 같다.</p><ul><li>만약 명명된 노드가 없으면, 파드가 실행되지 않고
따라서 자동으로 삭제될 수 있다.</li><li>만약 명명된 노드에 파드를 수용할 수 있는
리소스가 없는 경우 파드가 실패하고, 그 이유는 다음과 같이 표시된다.
예: OutOfmemory 또는 OutOfcpu.</li><li>클라우드 환경의 노드 이름은 항상 예측 가능하거나
안정적인 것은 아니다.</li></ul><p>다음은 <code>nodeName</code> 필드를 사용하는 파드 스펙 예시이다.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>nginx<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>nginx<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>nginx<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>nodeName</span>:<span style=color:#bbb> </span>kube-01<span style=color:#bbb>
</span></span></span></code></pre></div><p>위 파드는 <code>kube-01</code> 노드에서만 실행될 것이다.</p><h2 id=파드-토폴로지-분배-제약-조건>파드 토폴로지 분배 제약 조건</h2><p>_토폴로지 분배 제약 조건_을 사용하여 지역(regions), 영역(zones), 노드 또는 사용자가 정의한 다른 토폴로지 도메인과 같은 장애 도메인 사이에서 <a class=glossary-tooltip title='파드는 클러스터에서 실행 중인 컨테이너의 집합을 나타낸다.' data-toggle=tooltip data-placement=top href=/ko/docs/concepts/workloads/pods/ target=_blank aria-label=파드>파드</a>가 클러스터 전체에 분산되는 방식을 제어할 수 있다. 성능, 예상 가용성 또는 전체 활용도를 개선하기 위해 이 작업을 수행할 수 있다.</p><p><a href=/ko/docs/concepts/scheduling-eviction/topology-spread-constraints/>파드 토폴로지 분배 제약 조건</a>에서
작동 방식에 대해 더 자세히 알아볼 수 있다.</p><h2 id=다음-내용>다음 내용</h2><ul><li><a href=/ko/docs/concepts/scheduling-eviction/taint-and-toleration/>테인트 및 톨러레이션</a>에 대해 더 읽어본다.</li><li><a href=https://git.k8s.io/design-proposals-archive/scheduling/nodeaffinity.md>노드 어피니티</a>와
<a href=https://git.k8s.io/design-proposals-archive/scheduling/podaffinity.md>파드간 어피니티/안티-어피니티</a>에 대한 디자인 문서를 읽어본다.</li><li><a href=/docs/tasks/administer-cluster/topology-manager/>토폴로지 매니저</a>가
노드 수준 리소스 할당 결정에 어떻게 관여하는지 알아본다.</li><li><a href=/ko/docs/tasks/configure-pod-container/assign-pods-nodes/>노드셀렉터(nodeSelector)</a>를 어떻게 사용하는지 알아본다.</li><li><a href=/ko/docs/tasks/configure-pod-container/assign-pods-nodes-using-node-affinity/>어피니티/안티-어피니티</a>를 어떻게 사용하는지 알아본다.</li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-da22fe2278df236f71efbe672f392677>3 - 파드 오버헤드</h1><div style=margin-top:10px;margin-bottom:10px><b>기능 상태:</b> <code>Kubernetes v1.24 [stable]</code></div><p>노드 상에서 파드를 구동할 때, 파드는 그 자체적으로 많은 시스템 리소스를 사용한다.
이러한 리소스는 파드 내의 컨테이너들을 구동하기 위한 리소스 이외에 추가적으로 필요한 것이다.
쿠버네티스에서, <em>파드 오버헤드</em> 는 리소스 요청 및 상한 외에도
파드의 인프라에 의해 소비되는 리소스를 계산하는 방법 중 하나이다.</p><p>쿠버네티스에서 파드의 오버헤드는 파드의
<a href=/ko/docs/concepts/containers/runtime-class/>런타임클래스</a> 와 관련된 오버헤드에 따라
<a href=/docs/reference/access-authn-authz/extensible-admission-controllers/#what-are-admission-webhooks>어드미션</a>
이 수행될 때 지정된다.</p><p>파드를 노드에 스케줄링할 때, 컨테이너 리소스 요청의 합 뿐만 아니라 파드의 오버헤드도 함께 고려된다.
마찬가지로, kubelet은 파드의 cgroups 크기를 변경하거나 파드의 축출 등급을 부여할 때에도
파드의 오버헤드를 포함하여 고려한다.</p><h2 id=set-up>파드 오버헤드 환경 설정하기</h2><p><code>overhead</code> 필드를 정의하는 <code>RuntimeClass</code> 가 사용되고 있는지 확인해야 한다.</p><h2 id=사용-예제>사용 예제</h2><p>파드 오버헤드를 활용하려면, <code>overhead</code> 필드를 정의하는 런타임클래스가 필요하다.
예를 들어, 가상 머신 및 게스트 OS에 대하여 파드 당 120 MiB를 사용하는
가상화 컨테이너 런타임의 런타임클래스의 경우 다음과 같이 정의 할 수 있다.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>node.k8s.io/v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>RuntimeClass<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>kata-fc<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>handler</span>:<span style=color:#bbb> </span>kata-fc<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>overhead</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>podFixed</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>memory</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;120Mi&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>cpu</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;250m&#34;</span><span style=color:#bbb>
</span></span></span></code></pre></div><p><code>kata-fc</code> 런타임클래스 핸들러를 지정하는 워크로드는 리소스 쿼터 계산,
노드 스케줄링 및 파드 cgroup 크기 조정을 위하여 메모리와 CPU 오버헤드를 고려한다.</p><p>주어진 예제 워크로드 test-pod의 구동을 고려해보자.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>test-pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>runtimeClassName</span>:<span style=color:#bbb> </span>kata-fc<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>busybox-ctr<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>busybox:1.28<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>stdin</span>:<span style=color:#bbb> </span><span style=color:#a2f;font-weight:700>true</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>tty</span>:<span style=color:#bbb> </span><span style=color:#a2f;font-weight:700>true</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>resources</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>limits</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>cpu</span>:<span style=color:#bbb> </span>500m<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>memory</span>:<span style=color:#bbb> </span>100Mi<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>nginx-ctr<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>nginx<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>resources</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>limits</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>cpu</span>:<span style=color:#bbb> </span>1500m<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>memory</span>:<span style=color:#bbb> </span>100Mi<span style=color:#bbb>
</span></span></span></code></pre></div><p>어드미션 수행 시에, <a href=/docs/reference/access-authn-authz/admission-controllers/>어드미션 컨트롤러</a>는
런타임클래스에 기술된 <code>overhead</code> 를 포함하기 위하여 워크로드의 PodSpec 항목을 갱신한다. 만약 PodSpec이 이미 해당 필드에 정의되어 있으면,
파드는 거부된다. 주어진 예제에서, 오직 런타임클래스의 이름만이 정의되어 있기 때문에, 어드미션 컨트롤러는 파드가
<code>overhead</code> 를 포함하도록 변경한다.</p><p>런타임클래스 어드미션 컨트롤러가 변경을 완료하면,
다음의 명령어로 업데이트된 파드 오버헤드 값을 확인할 수 있다.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>kubectl get pod test-pod -o <span style=color:#b8860b>jsonpath</span><span style=color:#666>=</span><span style=color:#b44>&#39;{.spec.overhead}&#39;</span>
</span></span></code></pre></div><p>명령 실행 결과는 다음과 같다.</p><pre tabindex=0><code>map[cpu:250m memory:120Mi]
</code></pre><p>만약 <a href=/ko/docs/concepts/policy/resource-quotas/>리소스쿼터</a> 항목이 정의되어 있다면, 컨테이너의 리소스 요청의 합에는
<code>overhead</code> 필드도 추가된다.</p><p>kube-scheduler 는 어떤 노드에 파드가 기동 되어야 할지를 정할 때, 파드의 <code>overhead</code> 와
해당 파드에 대한 컨테이너의 리소스 요청의 합을 고려한다. 이 예제에서, 스케줄러는
리소스 요청과 파드의 오버헤드를 더하고, 2.25 CPU와 320 MiB 메모리가 사용 가능한 노드를 찾는다.</p><p>일단 파드가 특정 노드에 스케줄링 되면, 해당 노드에 있는 kubelet 은
파드에 대한 새로운 <a class=glossary-tooltip title='선택적으로 리소스를 격리, 관리, 제한하는 리눅스 프로세스의 그룹.' data-toggle=tooltip data-placement=top href='/ko/docs/reference/glossary/?all=true#term-cgroup' target=_blank aria-label=cgroup>cgroup</a>을 생성한다.
기본 컨테이너 런타임이 만들어내는 컨테이너들은 이 파드 안에 존재한다.</p><p>만약 각 컨테이너에 대하여 리소스 상한 제한이 걸려있으면
(제한이 걸려있는 보장된(Guaranteed) Qos 또는 향상 가능한(Burstable) QoS),
kubelet 은 해당 리소스(CPU의 경우 cpu.cfs_quota_us, 메모리의 경우 memory.limit_in_bytes)와 연관된 파드의 cgroup 의 상한선을 설정한다.
이 상한선은 컨테이너 리소스 상한과 PodSpec에 정의된 <code>overhead</code> 의 합에 기반한다.</p><p>CPU의 경우, 만약 파드가 보장형 또는 버스트형 QoS로 설정되었으면,
kubelet은 PodSpec에 정의된 <code>overhead</code> 에 컨테이너의 리소스 요청의 합을 더한 값을 <code>cpu.shares</code> 로 설정한다.</p><p>다음의 예제를 참고하여, 워크로드에 대하여 컨테이너의 리소스 요청을 확인하자.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>kubectl get pod test-pod -o <span style=color:#b8860b>jsonpath</span><span style=color:#666>=</span><span style=color:#b44>&#39;{.spec.containers[*].resources.limits}&#39;</span>
</span></span></code></pre></div><p>컨테이너 리소스 요청의 합은 각각 CPU 2000m 와 메모리 200MiB 이다.</p><pre tabindex=0><code>map[cpu: 500m memory:100Mi] map[cpu:1500m memory:100Mi]
</code></pre><p>노드에서 측정된 내용과 비교하여 확인해보자.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>kubectl describe node | grep test-pod -B2
</span></span></code></pre></div><p>결과를 보면 2250 m의 CPU와 320 MiB의 메모리가 리소스로 요청되었다. 여기에는 파드 오버헤드가 포함되어 있다.</p><pre tabindex=0><code>  Namespace    Name       CPU Requests  CPU Limits   Memory Requests  Memory Limits  AGE
  ---------    ----       ------------  ----------   ---------------  -------------  ---
  default      test-pod   2250m (56%)   2250m (56%)  320Mi (1%)       320Mi (1%)     36m
</code></pre><h2 id=파드-cgroup-상한-확인하기>파드 cgroup 상한 확인하기</h2><p>워크로드가 실행 중인 노드에서 파드의 메모리 cgroup들을 확인해 보자.
다음의 예제에서,
<a href=https://github.com/kubernetes-sigs/cri-tools/blob/master/docs/crictl.md><code>crictl</code></a>은 노드에서 사용되며,
CRI-호환 컨테이너 런타임을 위해서 노드에서 사용할 수 있는 CLI 를 제공한다.
파드 오버헤드 동작을 보여주는 좋은 예이며, 사용자가 노드에서 직접 cgroup들을 확인하지 않아도 된다.</p><p>먼저 특정 노드에서 파드의 식별자를 확인해 보자.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#080;font-style:italic># 파드가 스케줄 된 노드에서 이것을 실행</span>
</span></span><span style=display:flex><span><span style=color:#b8860b>POD_ID</span><span style=color:#666>=</span><span style=color:#b44>&#34;</span><span style=color:#a2f;font-weight:700>$(</span>sudo crictl pods --name test-pod -q<span style=color:#a2f;font-weight:700>)</span><span style=color:#b44>&#34;</span>
</span></span></code></pre></div><p>여기에서, 파드의 cgroup 경로를 확인할 수 있다.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#080;font-style:italic># 파드가 스케줄 된 노드에서 이것을 실행</span>
</span></span><span style=display:flex><span>sudo crictl inspectp -o<span style=color:#666>=</span>json <span style=color:#b8860b>$POD_ID</span> | grep cgroupsPath
</span></span></code></pre></div><p>명령의 결과로 나온 cgroup 경로는 파드의 <code>pause</code> 컨테이너를 포함한다. 파드 레벨의 cgroup은 하나의 디렉터리이다.</p><pre tabindex=0><code>  &#34;cgroupsPath&#34;: &#34;/kubepods/podd7f4b509-cf94-4951-9417-d1087c92a5b2/7ccf55aee35dd16aca4189c952d83487297f3cd760f1bbf09620e206e7d0c27a&#34;
</code></pre><p>아래의 특정한 경우에, 파드 cgroup 경로는 <code>kubepods/podd7f4b509-cf94-4951-9417-d1087c92a5b2</code> 이다.
메모리의 파드 레벨 cgroup 설정을 확인하자.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#080;font-style:italic># 파드가 스케줄 된 노드에서 이것을 실행.</span>
</span></span><span style=display:flex><span><span style=color:#080;font-style:italic># 또한 사용자의 파드에 할당된 cgroup 이름에 맞춰 해당 이름을 수정.</span>
</span></span><span style=display:flex><span> cat /sys/fs/cgroup/memory/kubepods/podd7f4b509-cf94-4951-9417-d1087c92a5b2/memory.limit_in_bytes
</span></span></code></pre></div><p>예상한 것과 같이 320 MiB 이다.</p><pre tabindex=0><code>335544320
</code></pre><h3 id=관찰성>관찰성</h3><p>몇몇 <code>kube_pod_overhead</code> 메트릭은
<a href=https://github.com/kubernetes/kube-state-metrics>kube-state-metrics</a> 에서 사용할 수 있어,
파드 오버헤드가 사용되는 시기를 식별하고, 정의된 오버헤드로 실행되는 워크로드의 안정성을 관찰할 수 있다.</p><h2 id=다음-내용>다음 내용</h2><ul><li><a href=/ko/docs/concepts/containers/runtime-class/>런타임클래스</a>에 대해 알아본다.</li><li>더 자세한 문맥은
<a href=https://github.com/kubernetes/enhancements/tree/master/keps/sig-node/688-pod-overhead>파드오버헤드 디자인</a> 향상 제안을 확인한다.</li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-ede4960b56a3529ee0bfe7c8fe2d09a5>4 - 테인트(Taints)와 톨러레이션(Tolerations)</h1><p><a href=/ko/docs/concepts/scheduling-eviction/assign-pod-node/#%EC%96%B4%ED%94%BC%EB%8B%88%ED%8B%B0-affinity-%EC%99%80-%EC%95%88%ED%8B%B0-%EC%96%B4%ED%94%BC%EB%8B%88%ED%8B%B0-anti-affinity><em>노드 어피니티</em></a>는
<a class=glossary-tooltip title='노드는 쿠버네티스의 작업 장비(worker machine)이다.' data-toggle=tooltip data-placement=top href=/ko/docs/concepts/architecture/nodes/ target=_blank aria-label=노드>노드</a> 셋을
(기본 설정 또는 어려운 요구 사항으로) <em>끌어들이는</em> <a class=glossary-tooltip title='파드는 클러스터에서 실행 중인 컨테이너의 집합을 나타낸다.' data-toggle=tooltip data-placement=top href=/ko/docs/concepts/workloads/pods/ target=_blank aria-label=파드>파드</a>의 속성이다.
<em>테인트</em> 는 그 반대로, 노드가 파드 셋을 제외시킬 수 있다.</p><p><em>톨러레이션</em> 은 파드에 적용된다. 톨러레이션을 통해 스케줄러는 그와 일치하는 테인트가 있는 파드를 스케줄할 수 있다.
톨러레이션은 스케줄을 허용하지만 보장하지는 않는다.
스케줄러는 그 기능의 일부로서
<a href=/ko/docs/concepts/scheduling-eviction/pod-priority-preemption/>다른 매개변수를</a> 고려한다.</p><p>테인트와 톨러레이션은 함께 작동하여 파드가 부적절한 노드에 스케줄되지
않게 한다. 하나 이상의 테인트가 노드에 적용되는데, 이것은
노드가 테인트를 용인하지 않는 파드를 수용해서는 안 된다는 것을 나타낸다.</p><h2 id=개요>개요</h2><p><a href=/docs/reference/generated/kubectl/kubectl-commands#taint>kubectl taint</a>를 사용하여 노드에 테인트을 추가한다.
예를 들면 다음과 같다.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl taint nodes node1 <span style=color:#b8860b>key1</span><span style=color:#666>=</span>value1:NoSchedule
</span></span></code></pre></div><p><code>node1</code> 노드에 테인트을 배치한다. 테인트에는 키 <code>key1</code>, 값 <code>value1</code> 및 테인트 이펙트(effect) <code>NoSchedule</code> 이 있다.
이는 일치하는 톨러레이션이 없으면 파드를 <code>node1</code> 에 스케줄할 수 없음을 의미한다.</p><p>위에서 추가했던 테인트를 제거하려면, 다음을 실행한다.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl taint nodes node1 <span style=color:#b8860b>key1</span><span style=color:#666>=</span>value1:NoSchedule-
</span></span></code></pre></div><p>PodSpec에서 파드에 대한 톨러레이션를 지정한다. 다음의 톨러레이션은
위의 <code>kubectl taint</code> 라인에 의해 생성된 테인트와 "일치"하므로, 어느 쪽 톨러레이션을 가진 파드이던
<code>node1</code> 에 스케줄 될 수 있다.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>tolerations</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span>- <span style=color:green;font-weight:700>key</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;key1&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>operator</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;Equal&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>value</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;value1&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>effect</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;NoSchedule&#34;</span><span style=color:#bbb>
</span></span></span></code></pre></div><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>tolerations</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span>- <span style=color:green;font-weight:700>key</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;key1&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>operator</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;Exists&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>effect</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;NoSchedule&#34;</span><span style=color:#bbb>
</span></span></span></code></pre></div><p>톨러레이션을 사용하는 파드의 예는 다음과 같다.</p><div class=highlight><div class=copy-code-icon style=text-align:right><a href=https://raw.githubusercontent.com/kubernetes/website/main/content/ko/examples/pods/pod-with-toleration.yaml download=pods/pod-with-toleration.yaml><code>pods/pod-with-toleration.yaml</code></a>
<img src=/images/copycode.svg style=max-height:24px;cursor:pointer onclick='copyCode("pods-pod-with-toleration-yaml")' title="Copy pods/pod-with-toleration.yaml to clipboard"></img></div><div class=includecode id=pods-pod-with-toleration-yaml><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>nginx<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>labels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>env</span>:<span style=color:#bbb> </span>test<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>nginx<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>nginx<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>imagePullPolicy</span>:<span style=color:#bbb> </span>IfNotPresent<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>tolerations</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>key</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;example-key&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>operator</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;Exists&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>effect</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;NoSchedule&#34;</span><span style=color:#bbb>
</span></span></span></code></pre></div></div></div><p>지정하지 않으면 <code>operator</code> 의 기본값은 <code>Equal</code> 이다.</p><p>톨러레이션은, 키와 이펙트가 동일한 경우에 테인트와 "일치"한다. 그리고 다음의 경우에도 마찬가지다.</p><ul><li><code>operator</code> 가 <code>Exists</code> 인 경우(이 경우 <code>value</code> 를 지정하지 않아야 함), 또는</li><li><code>operator</code> 는 <code>Equal</code> 이고 <code>value</code> 는 <code>value</code> 로 같다.</li></ul><div class="alert alert-info note callout" role=alert><strong>참고:</strong><p>두 가지 특별한 경우가 있다.</p><p>operator <code>Exists</code> 가 있는 비어있는 <code>key</code> 는 모든 키, 값 및 이펙트와 일치하므로
모든 것이 톨러레이션 된다.</p><p>비어있는 <code>effect</code> 는 모든 이펙트를 키 <code>key1</code> 와 일치시킨다.</p></div><p>위의 예는 <code>NoSchedule</code> 의 <code>effect</code> 를 사용했다. 또는, <code>PreferNoSchedule</code> 의 <code>effect</code> 를 사용할 수 있다.
이것은 <code>NoSchedule</code> 의 "기본 설정(preference)" 또는 "소프트(soft)" 버전이다. 시스템은 노드의 테인트를 허용하지 않는
파드를 배치하지 않으려고 <em>시도</em> 하지만, 필요하지는 않다. 세 번째 종류의 <code>effect</code> 는
나중에 설명할 <code>NoExecute</code> 이다.</p><p>동일한 노드에 여러 테인트를, 동일한 파드에 여러 톨러레이션을 둘 수 있다.
쿠버네티스가 여러 테인트 및 톨러레이션을 처리하는 방식은 필터와 같다.
모든 노드의 테인트로 시작한 다음, 파드에 일치하는 톨러레이션이 있는 것을 무시한다.
무시되지 않은 나머지 테인트는 파드에 표시된 이펙트를 가진다. 특히,</p><ul><li><code>NoSchedule</code> 이펙트가 있는 무시되지 않은 테인트가 하나 이상 있으면 쿠버네티스는 해당 노드에
파드를 스케줄하지 않는다.</li><li><code>NoSchedule</code> 이펙트가 있는 무시되지 않은 테인트가 없지만 <code>PreferNoSchedule</code> 이펙트가 있는
무시되지 않은 테인트가 하나 이상 있으면 쿠버네티스는 파드를 노드에 스케쥴하지 않으려고 <em>시도</em> 한다</li><li><code>NoExecute</code> 이펙트가 있는 무시되지 않은 테인트가 하나 이상 있으면
파드가 노드에서 축출되고(노드에서 이미 실행 중인 경우), 노드에서
스케줄되지 않는다(아직 실행되지 않은 경우).</li></ul><p>예를 들어, 이와 같은 노드를 테인트하는 경우는 다음과 같다.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl taint nodes node1 <span style=color:#b8860b>key1</span><span style=color:#666>=</span>value1:NoSchedule
</span></span><span style=display:flex><span>kubectl taint nodes node1 <span style=color:#b8860b>key1</span><span style=color:#666>=</span>value1:NoExecute
</span></span><span style=display:flex><span>kubectl taint nodes node1 <span style=color:#b8860b>key2</span><span style=color:#666>=</span>value2:NoSchedule
</span></span></code></pre></div><p>그리고 파드에는 두 가지 톨러레이션이 있다.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>tolerations</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span>- <span style=color:green;font-weight:700>key</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;key1&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>operator</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;Equal&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>value</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;value1&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>effect</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;NoSchedule&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span>- <span style=color:green;font-weight:700>key</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;key1&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>operator</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;Equal&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>value</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;value1&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>effect</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;NoExecute&#34;</span><span style=color:#bbb>
</span></span></span></code></pre></div><p>이 경우, 세 번째 테인트와 일치하는 톨러레이션이 없기 때문에, 파드는
노드에 스케줄 될 수 없다. 그러나 세 번째 테인트가 파드에서 용인되지 않는 세 가지 중
하나만 있기 때문에, 테인트가 추가될 때 노드에서 이미 실행 중인 경우,
파드는 계속 실행할 수 있다.</p><p>일반적으로, <code>NoExecute</code> 이펙트가 있는 테인트가 노드에 추가되면, 테인트를
용인하지 않는 파드는 즉시 축출되고, 테인트를 용인하는 파드는
축출되지 않는다. 그러나 <code>NoExecute</code> 이펙트가 있는 톨러레이션은
테인트가 추가된 후 파드가 노드에 바인딩된 시간을 지정하는
선택적 <code>tolerationSeconds</code> 필드를 지정할 수 있다. 예를 들어,</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>tolerations</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span>- <span style=color:green;font-weight:700>key</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;key1&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>operator</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;Equal&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>value</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;value1&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>effect</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;NoExecute&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>tolerationSeconds</span>:<span style=color:#bbb> </span><span style=color:#666>3600</span><span style=color:#bbb>
</span></span></span></code></pre></div><p>이것은 이 파드가 실행 중이고 일치하는 테인트가 노드에 추가되면,
파드는 3600초 동안 노드에 바인딩된 후, 축출된다는 것을 의미한다. 그 전에
테인트를 제거하면, 파드가 축출되지 않는다.</p><h2 id=유스케이스-예시>유스케이스 예시</h2><p>테인트 및 톨러레이션은 파드를 노드에서 <em>멀어지게</em> 하거나 실행되지 않아야 하는
파드를 축출할 수 있는 유연한 방법이다. 유스케이스 중 일부는 다음과 같다.</p><ul><li><p><strong>전용 노드</strong>: 특정 사용자들이 독점적으로 사용하도록
노드 셋을 전용하려면, 해당 노드에 테인트를 추가(예:
<code>kubectl taint nodes nodename dedicated=groupName:NoSchedule</code>)한 다음 해당
톨러레이션을 그들의 파드에 추가할 수 있다(사용자 정의 [어드미션 컨트롤러]
(/docs/reference/access-authn-authz/admission-controllers/)를 작성하면 가장 쉽게 수행할 수 있음).
그런 다음 톨러레이션이 있는 파드는 테인트된(전용) 노드와
클러스터의 다른 노드를 사용할 수 있다. 노드를 특정 사용자들에게 전용으로 지정하고 <em>그리고</em>
그 사용자들이 전용 노드 <em>만</em> 사용하려면, 동일한 노드 셋에
테인트와 유사한 레이블을 추가해야 하고(예: <code>dedicated=groupName</code>),
어드미션 컨트롤러는 추가로 파드가 <code>dedicated=groupName</code> 으로 레이블이 지정된 노드에만
스케줄될 수 있도록 노드 어피니티를 추가해야 한다.</p></li><li><p><strong>특별한 하드웨어가 있는 노드</strong>: 작은 서브셋의 노드에 특별한
하드웨어(예: GPU)가 있는 클러스터에서는, 특별한 하드웨어가 필요하지 않는 파드를
해당 노드에서 분리하여, 나중에 도착하는 특별한 하드웨어가 필요한 파드를 위한 공간을
남겨두는 것이 바람직하다. 이는 특별한 하드웨어가 있는
노드(예: <code>kubectl taint nodes nodename special=true:NoSchedule</code> 또는
<code>kubectl taint nodes nodename special=true:PreferNoSchedule</code>)에 테인트를 추가하고
특별한 하드웨어를 사용하는 파드에 해당 톨러레이션을 추가하여 수행할 수 있다. 전용 노드 유스케이스에서와 같이,
사용자 정의 <a href=/docs/reference/access-authn-authz/admission-controllers/>어드미션 컨트롤러</a>를
사용하여 톨러레이션를 적용하는 것이 가장 쉬운 방법이다.
예를 들어, <a href=/ko/docs/concepts/configuration/manage-resources-containers/#%ED%99%95%EC%9E%A5%EB%90%9C-%EB%A6%AC%EC%86%8C%EC%8A%A4>확장된
리소스</a>를
사용하여 특별한 하드웨어를 나타내고, 확장된 리소스 이름으로
특별한 하드웨어 노드를 테인트시키고
<a href=/docs/reference/access-authn-authz/admission-controllers/#extendedresourcetoleration>ExtendedResourceToleration</a>
어드미션 컨트롤러를 실행하는 것을 권장한다. 이제, 노드가 테인트되었으므로, 톨러레이션이 없는
파드는 스케줄되지 않는다. 그러나 확장된 리소스를 요청하는 파드를 제출하면,
<code>ExtendedResourceToleration</code> 어드미션 컨트롤러가
파드에 올바른 톨러레이션을 자동으로 추가하고 해당 파드는
특별한 하드웨어 노드에서 스케줄된다. 이렇게 하면 이러한 특별한 하드웨어 노드가
해당 하드웨어를 요청하는 파드가 전용으로 사용하며 파드에 톨러레이션을
수동으로 추가할 필요가 없다.</p></li><li><p><strong>테인트 기반 축출</strong>: 노드 문제가 있을 때 파드별로
구성 가능한 축출 동작은 다음 섹션에서 설명한다.</p></li></ul><h2 id=테인트-기반-축출>테인트 기반 축출</h2><div style=margin-top:10px;margin-bottom:10px><b>기능 상태:</b> <code>Kubernetes v1.18 [stable]</code></div><p>앞에서 우리는 노드에서 이미 실행 중인 파드에 영향을 주는 <code>NoExecute</code> 테인트 이펙트를
다음과 같이 언급했다.</p><ul><li>테인트를 용인하지 않는 파드는 즉시 축출된다.</li><li>톨러레이션 명세에 <code>tolerationSeconds</code> 를 지정하지 않고
테인트를 용인하는 파드는 계속 바인딩된다.</li><li><code>tolerationSeconds</code> 가 지정된 테인트를 용인하는 파드는 지정된
시간 동안 바인딩된 상태로 유지된다.</li></ul><p>노드 컨트롤러는 특정 컨디션이 참일 때 자동으로
노드를 테인트시킨다. 다음은 빌트인 테인트이다.</p><ul><li><code>node.kubernetes.io/not-ready</code>: 노드가 준비되지 않았다. 이는 NodeCondition
<code>Ready</code> 가 "<code>False</code>"로 됨에 해당한다.</li><li><code>node.kubernetes.io/unreachable</code>: 노드가 노드 컨트롤러에서 도달할 수 없다. 이는
NodeCondition <code>Ready</code> 가 "<code>Unknown</code>"로 됨에 해당한다.</li><li><code>node.kubernetes.io/memory-pressure</code>: 노드에 메모리 할당 압박이 있다.</li><li><code>node.kubernetes.io/disk-pressure</code>: 노드에 디스크 할당 압박이 있다.</li><li><code>node.kubernetes.io/pid-pressure</code>: 노드에 PID 할당 압박이 있다.</li><li><code>node.kubernetes.io/network-unavailable</code>: 노드의 네트워크를 사용할 수 없다.</li><li><code>node.kubernetes.io/unschedulable</code>: 노드를 스케줄할 수 없다.</li><li><code>node.cloudprovider.kubernetes.io/uninitialized</code>: "외부" 클라우드 공급자로
kubelet을 시작하면, 이 테인트가 노드에서 사용 불가능으로 표시되도록
설정된다. 클라우드-컨트롤러-관리자의 컨트롤러가 이 노드를 초기화하면,
kubelet이 이 테인트를 제거한다.</li></ul><p>노드가 축출될 경우, 노드 컨트롤러 또는 kubelet은 <code>NoExecute</code> 이펙트로 관련
테인트를 추가한다. 장애 상태가 정상으로 돌아오면 kubelet 또는 노드 컨트롤러가
관련 테인트를 제거할 수 있다.</p><div class="alert alert-info note callout" role=alert><strong>참고:</strong> 콘트롤 플레인은 노드에 새 테인트를 추가하는 비율을 제한한다.
이 비율-제한은 많은 노드가 동시에 도달할 수 없을 때(예를 들어, 네트워크 중단으로)
트리거될 축출 개수를 관리한다.</div><p>이 기능을 <code>tolerationSeconds</code> 와 함께 사용하면, 파드에서
이러한 문제 중 하나 또는 둘 다가 있는 노드에 바인딩된 기간을 지정할 수 있다.</p><p>예를 들어, 로컬 상태가 많은 애플리케이션은 네트워크 분할의 장애에서
네트워크가 복구된 후에 파드가 축출되는 것을 피하기 위해
오랫동안 노드에 바인딩된 상태를 유지하려고 할 수 있다.
이 경우 파드가 사용하는 톨러레이션은 다음과 같다.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>tolerations</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span>- <span style=color:green;font-weight:700>key</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;node.kubernetes.io/unreachable&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>operator</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;Exists&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>effect</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;NoExecute&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>tolerationSeconds</span>:<span style=color:#bbb> </span><span style=color:#666>6000</span><span style=color:#bbb>
</span></span></span></code></pre></div><div class="alert alert-info note callout" role=alert><strong>참고:</strong><p>쿠버네티스는 사용자나 컨트롤러에서 명시적으로 설정하지 않았다면, 자동으로
<code>node.kubernetes.io/not-ready</code> 와 <code>node.kubernetes.io/unreachable</code> 에 대해
<code>tolerationSeconds=300</code> 으로
톨러레이션을 추가한다.</p><p>자동으로 추가된 이 톨러레이션은 이러한 문제 중 하나가 감지된 후 5분 동안
파드가 노드에 바인딩된 상태를 유지함을 의미한다.</p></div><p><a href=/ko/docs/concepts/workloads/controllers/daemonset/>데몬셋</a> 파드는 <code>tolerationSeconds</code> 가 없는
다음 테인트에 대해 <code>NoExecute</code> 톨러레이션를 가지고 생성된다.</p><ul><li><code>node.kubernetes.io/unreachable</code></li><li><code>node.kubernetes.io/not-ready</code></li></ul><p>이렇게 하면 이러한 문제로 인해 데몬셋 파드가 축출되지 않는다.</p><h2 id=컨디션-condition-을-기준으로-노드-테인트하기>컨디션(condition)을 기준으로 노드 테인트하기</h2><p>컨트롤 플레인은 노드 <a class=glossary-tooltip title='API 서버를 통해 클러스터의 공유된 상태를 감시하고, 현재 상태를 원하는 상태로 이행시키는 컨트롤 루프.' data-toggle=tooltip data-placement=top href=/ko/docs/concepts/architecture/controller/ target=_blank aria-label=컨트롤러>컨트롤러</a>를 이용하여
<a href=/ko/docs/concepts/scheduling-eviction/node-pressure-eviction/#node-conditions>노드 컨디션</a>에 대한
<code>NoSchedule</code> 효과를 사용하여 자동으로 테인트를 생성한다.</p><p>스케줄러는 스케줄링 결정을 내릴 때 노드 컨디션을 확인하는 것이 아니라 테인트를 확인한다.
이렇게 하면 노드 컨디션이 스케줄링에 직접적인 영향을 주지 않는다.
예를 들어 <code>DiskPressure</code> 노드 컨디션이 활성화된 경우
컨트롤 플레인은 <code>node.kubernetes.io/disk-pressure</code> 테인트를 추가하고 영향을 받는 노드에 새 파드를 할당하지 않는다.
<code>MemoryPressure</code> 노드 컨디션이 활성화되면
컨트롤 플레인이 <code>node.kubernetes.io/memory-pressure</code> 테인트를 추가한다.</p><p>새로 생성된 파드에 파드 톨러레이션을 추가하여 노드 컨디션을 무시하도록 할 수 있다.
또한 컨트롤 플레인은 <code>BestEffort</code> 이외의
<a class=glossary-tooltip title='QoS 클래스(서비스 품질 클래스)는 쿠버네티스가 클러스터 안의 파드들을 여러 클래스로 구분하고, 스케줄링과 축출(eviction)에 대한 결정을 내리는 방법을 제공한다.' data-toggle=tooltip data-placement=top href='/ko/docs/reference/glossary/?all=true#term-qos-class' target=_blank aria-label='QoS 클래스'>QoS 클래스</a>를 가지는 파드에
<code>node.kubernetes.io/memory-pressure</code> 톨러레이션을 추가한다.
이는 쿠버네티스가 <code>Guaranteed</code> 또는 <code>Burstable</code> QoS 클래스를 갖는 파드(메모리 요청이 설정되지 않은 파드 포함)를
마치 그 파드들이 메모리 압박에 대처 가능한 것처럼 다루는 반면,
새로운 <code>BestEffort</code> 파드는 영향을 받는 노드에 할당하지 않기 때문이다.</p><p>데몬셋 컨트롤러는 다음의 <code>NoSchedule</code> 톨러레이션을
모든 데몬에 자동으로 추가하여, 데몬셋이 중단되는 것을 방지한다.</p><ul><li><code>node.kubernetes.io/memory-pressure</code></li><li><code>node.kubernetes.io/disk-pressure</code></li><li><code>node.kubernetes.io/pid-pressure</code> (1.14 이상)</li><li><code>node.kubernetes.io/unschedulable</code> (1.10 이상)</li><li><code>node.kubernetes.io/network-unavailable</code> (<em>호스트 네트워크만 해당</em>)</li></ul><p>이러한 톨러레이션을 추가하면 이전 버전과의 호환성이 보장된다. 데몬셋에
임의의 톨러레이션을 추가할 수도 있다.</p><h2 id=다음-내용>다음 내용</h2><ul><li><a href=/ko/docs/concepts/scheduling-eviction/node-pressure-eviction/>노드-압박(node-pressure) 축출</a>과
어떻게 구성하는지에 대해 알아보기</li><li><a href=/ko/docs/concepts/scheduling-eviction/pod-priority-preemption/>파드 우선순위</a>에 대해 알아보기</li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-6b8c85a6a88f4a81e6b79e197c293c31>5 - 파드 토폴로지 분배 제약 조건</h1><p>사용자는 <em>토폴로지 분배 제약 조건</em> 을 사용하여
지역(region), 존(zone), 노드 및 기타 사용자 정의 토폴로지 도메인과 같이
장애 도메인으로 설정된 클러스터에 걸쳐
<a class=glossary-tooltip title='파드는 클러스터에서 실행 중인 컨테이너의 집합을 나타낸다.' data-toggle=tooltip data-placement=top href=/ko/docs/concepts/workloads/pods/ target=_blank aria-label=파드>파드</a>가 분배되는 방식을 제어할 수 있다.
이를 통해 고가용성뿐만 아니라 효율적인 리소스 활용의 목적을 이루는 데에도 도움이 된다.</p><p><a href=#cluster-level-default-constraints>클러스터-수준 제약</a>을 기본값으로 설정하거나,
개별 워크로드마다 각각의 토폴로지 분배 제약 조건을 설정할 수 있다.</p><h2 id=동기-motivation>동기(motivation)</h2><p>최대 20 노드로 이루어진 클러스터가 있고, 레플리카 수를 자동으로 조절하는
<a class=glossary-tooltip title='워크로드는 클러스터의 컨테이너를 동작시키고 관리하기 위해 사용하는 오브젝트이다.' data-toggle=tooltip data-placement=top href=/ko/docs/concepts/workloads/ target=_blank aria-label=워크로드>워크로드</a>를
실행해야 하는 상황을 가정해 보자.
파드의 수는 2개 정도로 적을 수도 있고, 15개 정도로 많을 수도 있다.
파드가 2개만 있는 상황에서는, 해당 파드들이 동일 노드에서 실행되는 것은 원치 않을 것이다.
단일 노드 장애(single node failure)로 인해
전체 워크로드가 오프라인이 될 수 있기 때문이다.</p><p>이러한 기본적 사용 뿐만 아니라, 고가용성(high availability) 및
클러스터 활용(cluster utilization)으로부터 오는 장점을 워크로드가 누리도록 하는 고급 사용 예시도 존재한다.</p><p>워크로드를 스케일 업 하여 더 많은 파드를 실행함에 따라, 중요성이 부각되는 다른 요소도 존재한다.
3개의 노드가 각각 5개의 파드를 실행하는 경우를 가정하자.
각 노드는 5개의 레플리카를 실행하기에 충분한 성능을 갖고 있다.
하지만, 이 워크로드와 통신하는 클라이언트들은
3개의 서로 다른 데이터센터(또는 인프라스트럭처 존(zone))에 걸쳐 존재한다.
이제 단일 노드 장애에 대해서는 덜 걱정해도 되지만, 지연 시간(latency)이 증가하고,
서로 다른 존 간에 네트워크 트래픽을 전송하기 위해 네트워크 비용을 지불해야 한다.</p><p>정상적인 동작 중에는 각 인프라스트럭처 존에
비슷한 수의 레플리카가 <a href=/ko/docs/concepts/scheduling-eviction/>스케줄</a>되고,
클러스터에 문제가 있는 경우 스스로 치유하도록 설정할 수 있다.</p><p>파드 토폴로지 분배 제약 조건은 이러한 설정을 할 수 있도록 하는 선언적인 방법을 제공한다.</p><h2 id=topologyspreadconstraints-필드><code>topologySpreadConstraints</code> 필드</h2><p>파드 API에 <code>spec.topologySpreadConstraints</code> 필드가 있다. 이 필드는 다음과 같이
쓰인다.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#00f;font-weight:700>---</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>example-pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:#080;font-style:italic># 토폴로지 분배 제약 조건을 구성한다.</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>topologySpreadConstraints</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:green;font-weight:700>maxSkew</span>:<span style=color:#bbb> </span>&lt;integer&gt;<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>minDomains</span>:<span style=color:#bbb> </span>&lt;integer&gt;<span style=color:#bbb> </span><span style=color:#080;font-style:italic># 선택 사항이며, v1.25에서 베타 기능으로 도입되었다.</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>topologyKey</span>:<span style=color:#bbb> </span>&lt;string&gt;<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>whenUnsatisfiable</span>:<span style=color:#bbb> </span>&lt;string&gt;<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>labelSelector</span>:<span style=color:#bbb> </span>&lt;object&gt;<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>matchLabelKeys</span>:<span style=color:#bbb> </span>&lt;list&gt;<span style=color:#bbb> </span><span style=color:#080;font-style:italic># 선택 사항이며, v1.25에서 알파 기능으로 도입되었다.</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>nodeAffinityPolicy</span>:<span style=color:#bbb> </span>[Honor|Ignore]<span style=color:#bbb> </span><span style=color:#080;font-style:italic># 선택 사항이며, v1.25에서 알파 기능으로 도입되었다.</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>nodeTaintsPolicy</span>:<span style=color:#bbb> </span>[Honor|Ignore]<span style=color:#bbb> </span><span style=color:#080;font-style:italic># 선택 사항이며, v1.25에서 알파 기능으로 도입되었다.</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:#080;font-style:italic>### 파드의 다른 필드가 이 아래에 오게 된다.</span><span style=color:#bbb>
</span></span></span></code></pre></div><p><code>kubectl explain Pod.spec.topologySpreadConstraints</code> 명령을 실행하거나 파드에 관한 API 레퍼런스의
<a href=/docs/reference/kubernetes-api/workload-resources/pod-v1/#scheduling>스케줄링</a> 섹션을 참조해서 이 필드에 대해 좀 더 알아볼 수 있다.</p><h3 id=분배-제약-조건-정의>분배 제약 조건 정의</h3><p>하나 또는 다중 <code>topologySpreadConstraint</code> 를 정의하여,
kube-scheduler가 어떻게 클러스터 내에서 기존 파드와의 관계를 고려하며
새로운 파드를 배치할지를 지시할 수 있다. 각 필드는 다음과 같다.</p><ul><li><p><strong>maxSkew</strong> 는 파드가 균등하지 않게 분산될 수 있는 정도를 나타낸다.
이 필드는 필수이며, 0 보다는 커야 한다.
이 필드 값의 의미는 <code>whenUnsatisfiable</code> 의 값에 따라 다르다.</p><ul><li><code>whenUnsatisfiable: DoNotSchedule</code>을 선택했다면,
<code>maxSkew</code>는 대상 토폴로지에서 일치하는 파드 수와
<em>전역 최솟값(global minimum)</em> (적절한 도메인 내에서 일치하는 파드의 최소 수, 또는 적절한 도메인의 수가 <code>minDomains</code>보다 작은 경우에는 0)<br>사이의 최대 허용 차이를 나타낸다.
예를 들어, 3개의 존에 각각 2, 2, 1개의 일치하는 파드가 있으면,
<code>maxSkew</code>는 1로 설정되고 전역 최솟값은 1로 설정된다.</li><li><code>whenUnsatisfiable: ScheduleAnyway</code>를 선택하면,
스케줄러는 차이(skew)를 줄이는 데 도움이 되는 토폴로지에 더 높은 우선 순위를 부여한다.</li></ul></li><li><p><strong>minDomains</strong> 는 적합한(eligible) 도메인의 최소 수를 나타낸다. 이 필드는 선택 사항이다.
도메인은 토폴로지의 특정 인스턴스 중 하나이다.
도메인의 노드가 노드 셀렉터에 매치되면 그 도메인은 적합한 도메인이다.</p><div class="alert alert-info note callout" role=alert><strong>참고:</strong> <code>minDomains</code> 필드는 1.25에서 기본적으로 사용하도록 설정된 베타 필드이다. 사용을 원하지 않을 경우
<code>MinDomainsInPodToplogySpread</code> <a href=/ko/docs/reference/command-line-tools-reference/feature-gates/>기능 게이트</a>를 비활성화한다.</div><ul><li><code>minDomains</code> 값을 명시하는 경우, 이 값은 0보다 커야 한다.
<code>minDomains</code>는 <code>whenUnsatisfiable: DoNotSchedule</code>일 때에만 지정할 수 있다.</li><li>매치되는 토폴로지 키의 적합한 도메인 수가 <code>minDomains</code>보다 적으면,
파드 토폴로지 스프레드는 전역 최솟값을 0으로 간주한 뒤, <code>skew</code> 계산을 수행한다.
전역 최솟값은 적합한 도메인 내에 매치되는 파드의 최소 수이며,
적합한 도메인 수가 <code>minDomains</code>보다 적은 경우에는 0이다.</li><li>매치되는 토폴로지 키의 적합한 도메인 수가 <code>minDomains</code>보다 크거나 같으면,
이 값은 스케줄링에 영향을 미치지 않는다.</li><li><code>minDomains</code>를 명시하지 않으면, 분배 제약 조건은 <code>minDomains</code>가 1이라고 가정하고 동작한다.</li></ul></li><li><p><strong>topologyKey</strong> 는 <a href=#node-labels>노드 레이블</a>의 키(key)이다. 이 키와 동일한 값을 가진
레이블이 있는 노드는 동일한 토폴로지에 있는 것으로 간주된다.<br>토폴로지의 각 인스턴스(즉, &lt;키, 값> 쌍)를 도메인이라고 한다. 스케줄러는
각 도메인에 균형잡힌 수의 파드를 배치하려고 시도할 것이다.
또한, 노드가 nodeAffinityPolicy 및 nodeTaintsPolicy의 요구 사항을 충족하는 도메인을
적절한 도메인이라고 정의한다.</p></li><li><p><strong>whenUnsatisfiable</strong> 는 분산 제약 조건을 만족하지 않을 경우에 파드를 처리하는 방법을 나타낸다.</p><ul><li><code>DoNotSchedule</code>(기본값)은 스케줄러에 스케줄링을 하지 말라고 알려준다.</li><li><code>ScheduleAnyway</code>는 스케줄러에게 차이(skew)를 최소화하는 노드에 높은 우선 순위를 부여하면서, 스케줄링을 계속하도록 지시한다.</li></ul></li><li><p><strong>labelSelector</strong> 는 일치하는 파드를 찾는 데 사용된다.
이 레이블 셀렉터와 일치하는 파드의 수를 계산하여
해당 토폴로지 도메인에 속할 파드의 수를 결정한다.
자세한 내용은
<a href=/ko/docs/concepts/overview/working-with-objects/labels/#%EB%A0%88%EC%9D%B4%EB%B8%94-%EC%85%80%EB%A0%89%ED%84%B0>레이블 셀렉터</a>를 참조한다.</p></li><li><p><strong>matchLabelKeys</strong> 는 분배도(spreading)가 계산될 파드를 선택하기 위한 파드 레이블
키 목록이다. 키는 파드 레이블에서 값을 조회하는 데 사용되며, 이러한 키-값 레이블은 <code>labelSelector</code>와 AND 처리되어 들어오는 파드(incoming pod)에 대해 분배도가 계산될 기존 파드 그룹의 선택에 사용된다. 파드 레이블에 없는 키는 무시된다. null 또는 비어 있는 목록은 <code>labelSelector</code>와만 일치함을 의미한다.</p><p><code>matchLabelKeys</code>를 사용하면, 사용자는 다른 리비전 간에 <code>pod.spec</code>을 업데이트할 필요가 없다. 컨트롤러/오퍼레이터는 다른 리비전에 대해 동일한 <code>label</code>키에 다른 값을 설정하기만 하면 된다. 스케줄러는 <code>matchLabelKeys</code>를 기준으로 값을 자동으로 가정할 것이다. 예를 들어 사용자가 디플로이먼트를 사용하는 경우, 디플로이먼트 컨트롤러에 의해 자동으로 추가되는 <code>pod-template-hash</code>로 키가 지정된 레이블을 사용함으로써 단일 디플로이먼트에서 서로 다른 리비전을 구별할 수 있다.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>topologySpreadConstraints</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span>- <span style=color:green;font-weight:700>maxSkew</span>:<span style=color:#bbb> </span><span style=color:#666>1</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>topologyKey</span>:<span style=color:#bbb> </span>kubernetes.io/hostname<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>whenUnsatisfiable</span>:<span style=color:#bbb> </span>DoNotSchedule<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>matchLabelKeys</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>            </span>- app<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>            </span>- pod-template-hash<span style=color:#bbb>
</span></span></span></code></pre></div><div class="alert alert-info note callout" role=alert><strong>참고:</strong> <code>matchLabelKeys</code> 필드는 1.25에서 추가된 알파 필드이다. 이 필드를 사용하려면
<code>MatchLabelKeysInPodTopologySpread</code> <a href=/ko/docs/reference/command-line-tools-reference/feature-gates/>기능 게이트</a>
를 활성화시켜야 한다.</div></li><li><p><strong>nodeAffinityPolicy</strong>는 파드 토폴로지의 스프레드 스큐(spread skew)를 계산할 때
파드의 nodeAffinity/nodeSelector를 다루는 방법을 나타낸다. 옵션은 다음과 같다.</p><ul><li>Honor: nodeAffinity/nodeSelector와 일치하는 노드만 계산에 포함된다.</li><li>Ignore: nodeAffinity/nodeSelector는 무시된다. 모든 노드가 계산에 포함된다.</li></ul><p>옵션의 값이 null일 경우, Honor 정책과 동일하게 동작한다.</p><div class="alert alert-info note callout" role=alert><strong>참고:</strong> <code>nodeAffinityPolicy</code> 필드는 1.25에서 추가된 알파 필드이다. 이 필드를 사용하려면
<code>NodeInclusionPolicyInPodTopologySpread</code> <a href=/ko/docs/reference/command-line-tools-reference/feature-gates/>기능 게이트</a>
를 활성화시켜야 한다.</div></li><li><p><strong>nodeTaintsPolicy</strong>는 파드 토폴로지의 스프레드 스큐(spread skew)를 계산할 때 노드 테인트(taint)를
다루는 방법을 나타낸다. 옵션은 다음과 같다.</p><ul><li>Honor: 테인트가 없는 노드, 그리고 노드가 톨러레이션이 있는 들어오는 파드(incoming pod)를 위한 테인트가 설정된
노드가 포함된다.</li><li>Ignore: 노드 테인트는 무시된다. 모든 노드가 포함된다.</li></ul><p>옵션의 값이 null일 경우, Ignore 정책과 동일하게 동작한다.</p><div class="alert alert-info note callout" role=alert><strong>참고:</strong> <code>nodeTaintsPolicy</code> 필드는 1.25에서 추가된 알파 필드이다. 이 필드를 사용하려면
<code>NodeInclusionPolicyInPodTopologySpread</code> <a href=/ko/docs/reference/command-line-tools-reference/feature-gates/>기능 게이트</a>
를 활성화시켜야 한다.</div></li></ul><p>파드에 2개 이상의 <code>topologySpreadConstraint</code>가 정의되어 있으면,
각 제약 조건은 논리 AND 연산으로 조합되며,
kube-scheduler는 새로운 파드의 모든 제약 조건을 만족하는 노드를 찾는다.</p><h3 id=노드-레이블>노드 레이블</h3><p>토폴로지 분배 제약 조건은 노드 레이블을 이용하여
각 <a class=glossary-tooltip title='노드는 쿠버네티스의 작업 장비(worker machine)이다.' data-toggle=tooltip data-placement=top href=/ko/docs/concepts/architecture/nodes/ target=_blank aria-label=노드>노드</a>가 속한 토폴로지 도메인(들)을 인식한다.
예를 들어, 노드가 다음과 같은 레이블을 가질 수 있다.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>region</span>:<span style=color:#bbb> </span>us-east-1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>zone</span>:<span style=color:#bbb> </span>us-east-1a<span style=color:#bbb>
</span></span></span></code></pre></div><div class="alert alert-info note callout" role=alert><strong>참고:</strong><p>간결함을 위해, 이 예시에서는
<a href=/ko/docs/reference/labels-annotations-taints/>잘 알려진</a> 레이블 키인
<code>topology.kubernetes.io/zone</code> 및 <code>topology.kubernetes.io/region</code>을 사용하지 않는다.
그러나 그렇더라도, 아래에 등장하는 프라이빗(비공인된) 레이블 키인 <code>region</code> 및 <code>zone</code>보다는
위와 같은 공인된 레이블 키를 사용하는 것을 권장한다.</p><p>다양한 각 상황에 대해, 프라이빗 레이블 키의 의미가
모두 우리의 생각과 같을 것이라고 가정할 수는 없다.</p></div><p>각각 다음과 같은 레이블을 갖는 4개의 노드로 구성된 클러스터가 있다고 가정한다.</p><pre tabindex=0><code>NAME    STATUS   ROLES    AGE     VERSION   LABELS
node1   Ready    &lt;none&gt;   4m26s   v1.16.0   node=node1,zone=zoneA
node2   Ready    &lt;none&gt;   3m58s   v1.16.0   node=node2,zone=zoneA
node3   Ready    &lt;none&gt;   3m17s   v1.16.0   node=node3,zone=zoneB
node4   Ready    &lt;none&gt;   2m43s   v1.16.0   node=node4,zone=zoneB
</code></pre><p>그러면 클러스터는 논리적으로 다음과 같이 보이게 된다.</p><figure><div class=mermaid>graph TB
subgraph "zoneB"
n3(Node3)
n4(Node4)
end
subgraph "zoneA"
n1(Node1)
n2(Node2)
end
classDef plain fill:#ddd,stroke:#fff,stroke-width:4px,color:#000;
classDef k8s fill:#326ce5,stroke:#fff,stroke-width:4px,color:#fff;
classDef cluster fill:#fff,stroke:#bbb,stroke-width:2px,color:#326ce5;
class n1,n2,n3,n4 k8s;
class zoneA,zoneB cluster;</div></figure><noscript><div class="alert alert-secondary callout" role=alert><em class=javascript-required>이 컨텐츠를 보려면 자바스크립트가 <a href=https://www.enable-javascript.com/>활성화</a>되어 있어야 합니다.</em></div></noscript><h2 id=일관성-consistency>일관성(consistency)</h2><p>그룹 내의 모든 파드에는 동일한 파드 토폴로지 분배 제약 조건을 설정해야 한다.</p><p>일반적으로, 디플로이먼트와 같은 워크로드 컨트롤러를 사용하는 경우,
파드 템플릿이 이 사항을 담당한다.
여러 분배 제약 조건을 혼합하는 경우, 쿠버네티스는 해당 필드의 API 정의를 따르기는 하지만,
동작이 복잡해질 수 있고 트러블슈팅이 덜 직관적이게 된다.</p><p>동일한 토폴로지 도메인(예: 클라우드 공급자 리전)에 있는 모든 노드가
일관적으로 레이블되도록 하는 메카니즘이 필요하다.
각 노드를 수동으로 레이블하는 것을 피하기 위해,
대부분의 클러스터는 <code>topology.kubernetes.io/hostname</code>와 같은 잘 알려진 레이블을 자동으로 붙인다.
이용하려는 클러스터가 이를 지원하는지 확인해 본다.</p><h2 id=토폴로지-분배-제약-조건-예시>토폴로지 분배 제약 조건 예시</h2><h3 id=example-one-topologyspreadconstraint>예시: 단수 토폴로지 분배 제약 조건</h3><p><code>foo:bar</code> 가 레이블된 3개의 파드가 4개 노드를 가지는 클러스터의
node1, node2 및 node3에 각각 위치한다고 가정한다.</p><figure><div class=mermaid>graph BT
subgraph "zoneB"
p3(Pod) --> n3(Node3)
n4(Node4)
end
subgraph "zoneA"
p1(Pod) --> n1(Node1)
p2(Pod) --> n2(Node2)
end
classDef plain fill:#ddd,stroke:#fff,stroke-width:4px,color:#000;
classDef k8s fill:#326ce5,stroke:#fff,stroke-width:4px,color:#fff;
classDef cluster fill:#fff,stroke:#bbb,stroke-width:2px,color:#326ce5;
class n1,n2,n3,n4,p1,p2,p3 k8s;
class zoneA,zoneB cluster;</div></figure><noscript><div class="alert alert-secondary callout" role=alert><em class=javascript-required>이 컨텐츠를 보려면 자바스크립트가 <a href=https://www.enable-javascript.com/>활성화</a>되어 있어야 합니다.</em></div></noscript><p>신규 파드가 기존 파드와 함께 여러 존에 걸쳐 균등하게 분배되도록 하려면,
다음과 같은 매니페스트를 사용할 수 있다.</p><div class=highlight><div class=copy-code-icon style=text-align:right><a href=https://raw.githubusercontent.com/kubernetes/website/main/content/ko/examples/pods/topology-spread-constraints/one-constraint.yaml download=pods/topology-spread-constraints/one-constraint.yaml><code>pods/topology-spread-constraints/one-constraint.yaml</code></a>
<img src=/images/copycode.svg style=max-height:24px;cursor:pointer onclick='copyCode("pods-topology-spread-constraints-one-constraint-yaml")' title="Copy pods/topology-spread-constraints/one-constraint.yaml to clipboard"></img></div><div class=includecode id=pods-topology-spread-constraints-one-constraint-yaml><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>mypod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>labels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>foo</span>:<span style=color:#bbb> </span>bar<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>topologySpreadConstraints</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>maxSkew</span>:<span style=color:#bbb> </span><span style=color:#666>1</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>topologyKey</span>:<span style=color:#bbb> </span>zone<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>whenUnsatisfiable</span>:<span style=color:#bbb> </span>DoNotSchedule<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>labelSelector</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>matchLabels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>foo</span>:<span style=color:#bbb> </span>bar<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>pause<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>registry.k8s.io/pause:3.1</span></span></code></pre></div></div></div><p>위의 매니페스트에서, <code>topologyKey: zone</code>이 의미하는 것은 <code>zone: &lt;any value></code>로 레이블된
노드에 대해서만 균등한 분배를 적용한다는 뜻이다(<code>zone</code> 레이블이 없는 노드는 무시된다).
<code>whenUnsatisfiable: DoNotSchedule</code> 필드는 만약 스케줄러가 신규 파드에 대해 제약 조건을
만족하는 스케줄링 방법을 찾지 못하면 이 신규 파드를 pending 상태로 유지하도록 한다.</p><p>만약 스케줄러가 이 신규 파드를 <code>A</code> 존에 배치하면 파드 분포는 <code>[3, 1]</code>이 된다.
이는 곧 실제 차이(skew)가 2(<code>3-1</code>)임을 나타내는데, 이는 <code>maxSkew: 1</code>을 위반하게 된다.
이 예시에서 제약 조건과 상황을 만족하려면,
신규 파드는 <code>B</code> 존의 노드에만 배치될 수 있다.</p><figure><div class=mermaid>graph BT
subgraph "zoneB"
p3(Pod) --> n3(Node3)
p4(mypod) --> n4(Node4)
end
subgraph "zoneA"
p1(Pod) --> n1(Node1)
p2(Pod) --> n2(Node2)
end
classDef plain fill:#ddd,stroke:#fff,stroke-width:4px,color:#000;
classDef k8s fill:#326ce5,stroke:#fff,stroke-width:4px,color:#fff;
classDef cluster fill:#fff,stroke:#bbb,stroke-width:2px,color:#326ce5;
class n1,n2,n3,n4,p1,p2,p3 k8s;
class p4 plain;
class zoneA,zoneB cluster;</div></figure><noscript><div class="alert alert-secondary callout" role=alert><em class=javascript-required>이 컨텐츠를 보려면 자바스크립트가 <a href=https://www.enable-javascript.com/>활성화</a>되어 있어야 합니다.</em></div></noscript><p>또는</p><figure><div class=mermaid>graph BT
subgraph "zoneB"
p3(Pod) --> n3(Node3)
p4(mypod) --> n3
n4(Node4)
end
subgraph "zoneA"
p1(Pod) --> n1(Node1)
p2(Pod) --> n2(Node2)
end
classDef plain fill:#ddd,stroke:#fff,stroke-width:4px,color:#000;
classDef k8s fill:#326ce5,stroke:#fff,stroke-width:4px,color:#fff;
classDef cluster fill:#fff,stroke:#bbb,stroke-width:2px,color:#326ce5;
class n1,n2,n3,n4,p1,p2,p3 k8s;
class p4 plain;
class zoneA,zoneB cluster;</div></figure><noscript><div class="alert alert-secondary callout" role=alert><em class=javascript-required>이 컨텐츠를 보려면 자바스크립트가 <a href=https://www.enable-javascript.com/>활성화</a>되어 있어야 합니다.</em></div></noscript><p>사용자는 파드 스펙을 조정하여 다음과 같은 다양한 요구사항을 충족할 수 있다.</p><ul><li><code>maxSkew</code> 를 더 큰 값(예: <code>2</code>)으로 변경하여
신규 파드가 <code>A</code> 존에도 배치할 수 있도록 한다.</li><li><code>topologyKey</code>를 <code>node</code>로 변경하여 파드가 존이 아닌 노드에 걸쳐 고르게 분산되도록 한다.
위의 예시에서, 만약 <code>maxSkew</code>를 <code>1</code>로 유지한다면,
신규 파드는 오직 <code>node4</code>에만 배치될 수 있다.</li><li><code>whenUnsatisfiable: DoNotSchedule</code>를 <code>whenUnsatisfiable: ScheduleAnyway</code>로 변경하면
신규 파드가 항상 스케줄링되도록 보장할 수 있다(다른 스케줄링 API를 충족한다는 가정 하에).
그러나, 매칭되는 파드의 수가 적은 토폴로지 도메인에 배치되는 것이 선호된다.
(이 선호도는 리소스 사용 비율과 같은 다른 내부 스케줄링 우선순위와 함께 정규화된다는 것을
알아두자.)</li></ul><h3 id=example-multiple-topologyspreadconstraints>예시: 다중 토폴로지 분배 제약 조건</h3><p>이 예시는 위의 예시에 기반한다. <code>foo:bar</code> 가 레이블된 3개의 파드가
4개 노드를 가지는 클러스터의 node1, node2 그리고 node3에 각각 위치한다고 가정한다.</p><figure><div class=mermaid>graph BT
subgraph "zoneB"
p3(Pod) --> n3(Node3)
n4(Node4)
end
subgraph "zoneA"
p1(Pod) --> n1(Node1)
p2(Pod) --> n2(Node2)
end
classDef plain fill:#ddd,stroke:#fff,stroke-width:4px,color:#000;
classDef k8s fill:#326ce5,stroke:#fff,stroke-width:4px,color:#fff;
classDef cluster fill:#fff,stroke:#bbb,stroke-width:2px,color:#326ce5;
class n1,n2,n3,n4,p1,p2,p3 k8s;
class p4 plain;
class zoneA,zoneB cluster;</div></figure><noscript><div class="alert alert-secondary callout" role=alert><em class=javascript-required>이 컨텐츠를 보려면 자바스크립트가 <a href=https://www.enable-javascript.com/>활성화</a>되어 있어야 합니다.</em></div></noscript><p>사용자는 2개의 토폴로지 분배 제약 조건을 사용하여
노드 및 존 기반으로 파드가 분배되도록 제어할 수 있다.</p><div class=highlight><div class=copy-code-icon style=text-align:right><a href=https://raw.githubusercontent.com/kubernetes/website/main/content/ko/examples/pods/topology-spread-constraints/two-constraints.yaml download=pods/topology-spread-constraints/two-constraints.yaml><code>pods/topology-spread-constraints/two-constraints.yaml</code></a>
<img src=/images/copycode.svg style=max-height:24px;cursor:pointer onclick='copyCode("pods-topology-spread-constraints-two-constraints-yaml")' title="Copy pods/topology-spread-constraints/two-constraints.yaml to clipboard"></img></div><div class=includecode id=pods-topology-spread-constraints-two-constraints-yaml><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>mypod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>labels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>foo</span>:<span style=color:#bbb> </span>bar<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>topologySpreadConstraints</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>maxSkew</span>:<span style=color:#bbb> </span><span style=color:#666>1</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>topologyKey</span>:<span style=color:#bbb> </span>zone<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>whenUnsatisfiable</span>:<span style=color:#bbb> </span>DoNotSchedule<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>labelSelector</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>matchLabels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>foo</span>:<span style=color:#bbb> </span>bar<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>maxSkew</span>:<span style=color:#bbb> </span><span style=color:#666>1</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>topologyKey</span>:<span style=color:#bbb> </span>node<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>whenUnsatisfiable</span>:<span style=color:#bbb> </span>DoNotSchedule<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>labelSelector</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>matchLabels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>foo</span>:<span style=color:#bbb> </span>bar<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>pause<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>registry.k8s.io/pause:3.1</span></span></code></pre></div></div></div><p>이 경우에는, 첫 번째 제약 조건에 부합하려면, 신규 파드는 오직 <code>B</code> 존에만 배치될 수 있다.
한편 두 번째 제약 조건에 따르면 신규 파드는 오직 <code>node4</code> 노드에만 배치될 수 있다.
스케줄러는 모든 정의된 제약 조건을 만족하는 선택지만 고려하므로,
유효한 유일한 선택지는 신규 파드를 <code>node4</code>에 배치하는 것이다.</p><h3 id=example-conflicting-topologyspreadconstraints>예시: 상충하는 토폴로지 분배 제약 조건</h3><p>다중 제약 조건이 서로 충돌할 수 있다. 3개의 노드를 가지는 클러스터 하나가 2개의 존에 걸쳐 있다고 가정한다.</p><figure><div class=mermaid>graph BT
subgraph "zoneB"
p4(Pod) --> n3(Node3)
p5(Pod) --> n3
end
subgraph "zoneA"
p1(Pod) --> n1(Node1)
p2(Pod) --> n1
p3(Pod) --> n2(Node2)
end
classDef plain fill:#ddd,stroke:#fff,stroke-width:4px,color:#000;
classDef k8s fill:#326ce5,stroke:#fff,stroke-width:4px,color:#fff;
classDef cluster fill:#fff,stroke:#bbb,stroke-width:2px,color:#326ce5;
class n1,n2,n3,n4,p1,p2,p3,p4,p5 k8s;
class zoneA,zoneB cluster;</div></figure><noscript><div class="alert alert-secondary callout" role=alert><em class=javascript-required>이 컨텐츠를 보려면 자바스크립트가 <a href=https://www.enable-javascript.com/>활성화</a>되어 있어야 합니다.</em></div></noscript><p>만약
<a href=https://raw.githubusercontent.com/kubernetes/website/main/content/en/examples/pods/topology-spread-constraints/two-constraints.yaml><code>two-constraints.yaml</code></a>
(위 예시의 매니페스트)을
<strong>이</strong> 클러스터에 적용하면,
<code>mypod</code> 파드가 <code>Pending</code> 상태로 유지되는 것을 볼 수 있을 것이다.
이러한 이유는, 첫 번째 제약 조건을 충족하려면 <code>mypod</code> 파드는 <code>B</code> 존에만 배치될 수 있지만,
두 번째 제약 조건에 따르면 <code>mypod</code> 파드는 <code>node2</code> 노드에만 스케줄링될 수 있기 때문이다.
두 제약 조건의 교집합이 공집합이므로, 스케줄러는 파드를 배치할 수 없다.</p><p>이 상황을 극복하기 위해, <code>maxSkew</code> 값을 증가시키거나,
제약 조건 중 하나를 <code>whenUnsatisfiable: ScheduleAnyway</code> 를 사용하도록 수정할 수 있다.
상황에 따라, 기존 파드를 수동으로 삭제할 수도 있다.
예를 들어, 버그픽스 롤아웃이 왜 진행되지 않는지 트러블슈팅하는 상황에서 이 방법을 활용할 수 있다.</p><h4 id=노드-어피니티-affinity-및-노드-셀렉터-selector-와의-상호-작용>노드 어피니티(Affinity) 및 노드 셀렉터(Selector)와의 상호 작용</h4><p>스케줄러는 신규 파드에 <code>spec.nodeSelector</code> 또는 <code>spec.affinity.nodeAffinity</code>가 정의되어 있는 경우,
부합하지 않는 노드들을 차이(skew) 계산에서 생략한다.</p><h3 id=example-topologyspreadconstraints-with-nodeaffinity>예시: 토폴로지 분배 제약조건과 노드 어피니티</h3><p>5개의 노드를 가지는 클러스터가 A 존에서 C 존까지 걸쳐 있다고 가정한다.</p><figure><div class=mermaid>graph BT
subgraph "zoneB"
p3(Pod) --> n3(Node3)
n4(Node4)
end
subgraph "zoneA"
p1(Pod) --> n1(Node1)
p2(Pod) --> n2(Node2)
end
classDef plain fill:#ddd,stroke:#fff,stroke-width:4px,color:#000;
classDef k8s fill:#326ce5,stroke:#fff,stroke-width:4px,color:#fff;
classDef cluster fill:#fff,stroke:#bbb,stroke-width:2px,color:#326ce5;
class n1,n2,n3,n4,p1,p2,p3 k8s;
class p4 plain;
class zoneA,zoneB cluster;</div></figure><noscript><div class="alert alert-secondary callout" role=alert><em class=javascript-required>이 컨텐츠를 보려면 자바스크립트가 <a href=https://www.enable-javascript.com/>활성화</a>되어 있어야 합니다.</em></div></noscript><figure><div class=mermaid>graph BT
subgraph "zoneC"
n5(Node5)
end
classDef plain fill:#ddd,stroke:#fff,stroke-width:4px,color:#000;
classDef k8s fill:#326ce5,stroke:#fff,stroke-width:4px,color:#fff;
classDef cluster fill:#fff,stroke:#bbb,stroke-width:2px,color:#326ce5;
class n5 k8s;
class zoneC cluster;</div></figure><noscript><div class="alert alert-secondary callout" role=alert><em class=javascript-required>이 컨텐츠를 보려면 자바스크립트가 <a href=https://www.enable-javascript.com/>활성화</a>되어 있어야 합니다.</em></div></noscript><p>그리고 <code>C</code> 존은 파드 배포에서 제외해야 한다는 사실을 사용자가 알고 있다고 가정한다.
이 경우에, 다음과 같이 매니페스트를 작성하여, <code>mypod</code> 파드가 <code>C</code> 존 대신 <code>B</code> 존에 배치되도록 할 수 있다.
유사하게, 쿠버네티스는 <code>spec.nodeSelector</code> 필드도 고려한다.</p><div class=highlight><div class=copy-code-icon style=text-align:right><a href=https://raw.githubusercontent.com/kubernetes/website/main/content/ko/examples/pods/topology-spread-constraints/one-constraint-with-nodeaffinity.yaml download=pods/topology-spread-constraints/one-constraint-with-nodeaffinity.yaml><code>pods/topology-spread-constraints/one-constraint-with-nodeaffinity.yaml</code></a>
<img src=/images/copycode.svg style=max-height:24px;cursor:pointer onclick='copyCode("pods-topology-spread-constraints-one-constraint-with-nodeaffinity-yaml")' title="Copy pods/topology-spread-constraints/one-constraint-with-nodeaffinity.yaml to clipboard"></img></div><div class=includecode id=pods-topology-spread-constraints-one-constraint-with-nodeaffinity-yaml><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>mypod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>labels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>foo</span>:<span style=color:#bbb> </span>bar<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>topologySpreadConstraints</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>maxSkew</span>:<span style=color:#bbb> </span><span style=color:#666>1</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>topologyKey</span>:<span style=color:#bbb> </span>zone<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>whenUnsatisfiable</span>:<span style=color:#bbb> </span>DoNotSchedule<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>labelSelector</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>matchLabels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>foo</span>:<span style=color:#bbb> </span>bar<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>affinity</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>nodeAffinity</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>requiredDuringSchedulingIgnoredDuringExecution</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>nodeSelectorTerms</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span>- <span style=color:green;font-weight:700>matchExpressions</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span>- <span style=color:green;font-weight:700>key</span>:<span style=color:#bbb> </span>zone<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>            </span><span style=color:green;font-weight:700>operator</span>:<span style=color:#bbb> </span>NotIn<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>            </span><span style=color:green;font-weight:700>values</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>            </span>- zoneC<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>pause<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>registry.k8s.io/pause:3.1</span></span></code></pre></div></div></div><h2 id=암묵적-규칙>암묵적 규칙</h2><p>여기에 주목할만한 몇 가지 암묵적인 규칙이 있다.</p><ul><li><p>신규 파드와 동일한 네임스페이스를 갖는 파드만이 매칭의 후보가 된다.</p></li><li><p><code>topologySpreadConstraints[*].topologyKey</code> 가 없는 노드는 무시된다.
이것은 다음을 의미한다.</p><ol><li>이러한 노드에 위치한 파드는 <code>maxSkew</code> 계산에 영향을 미치지 않는다.
위의 예시에서, <code>node1</code> 노드는 "zone" 레이블을 가지고 있지 않다고 가정하면,
파드 2개는 무시될 것이고, 이런 이유로 신규 파드는 <code>A</code> 존으로 스케줄된다.</li><li>신규 파드는 이런 종류의 노드에 스케줄 될 기회가 없다.
위의 예시에서, <strong>잘못 타이핑된</strong> <code>zone-typo: zoneC</code> 레이블을 갖는 <code>node5</code> 노드가 있다고 가정하자(<code>zone</code> 레이블은 설정되지 않음).
<code>node5</code> 노드가 클러스터에 편입되면, 해당 노드는 무시되고
이 워크로드의 파드는 해당 노드에 스케줄링되지 않는다.</li></ol></li><li><p>신규 파드의 <code>topologySpreadConstraints[*].labelSelector</code>가 자체 레이블과 일치하지 않을 경우 어떻게 되는지 알고 있어야 한다.
위의 예시에서, 신규 파드의 레이블을 제거해도,
제약 조건이 여전히 충족되기 때문에 이 파드는 <code>B</code> 존의 노드에 배치될 수 있다.
그러나, 배치 이후에도 클러스터의 불균형 정도는 변경되지 않는다.
여전히 <code>A</code> 존은 <code>foo: bar</code> 레이블을 가지는 2개의 파드를 가지고 있고,
<code>B</code> 존도 <code>foo: bar</code> 레이블을 가지는 1개의 파드를 가지고 있다.
만약 결과가 예상과 다르다면,
워크로드의 <code>topologySpreadConstraints[*].labelSelector</code>를 파드 템플릿의 레이블과 일치하도록 업데이트한다.</p></li></ul><h2 id=클러스터-수준의-기본-제약-조건>클러스터 수준의 기본 제약 조건</h2><p>클러스터에 대한 기본 토폴로지 분배 제약 조건을 설정할 수 있다.
기본 토폴로지 분배 제약 조건은 다음과 같은 경우에만 파드에 적용된다.</p><ul><li><code>.spec.topologySpreadConstraints</code> 에 어떠한 제약 조건도 정의되어 있지 않는 경우.</li><li>서비스, 레플리카셋(ReplicaSet), 스테이트풀셋(StatefulSet), 또는 레플리케이션컨트롤러(ReplicationController)에 속해있는 경우.</li></ul><p>기본 제약 조건은
<a href=/ko/docs/reference/scheduling/config/#%ED%94%84%EB%A1%9C%ED%8C%8C%EC%9D%BC>스케줄링 프로파일</a>내의 플러그인 인자 중 하나로 설정할 수 있다.
제약 조건은 <a href=#api>위에서 설명한 것과 동일한 API</a>를 이용하여 정의되는데,
다만 <code>labelSelector</code>는 비워 두어야 한다.
셀렉터는 파드가 속한 서비스, 레플리카셋, 스테이트풀셋, 또는 레플리케이션 컨트롤러를 바탕으로 계산한다.</p><p>예시 구성은 다음과 같다.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>kubescheduler.config.k8s.io/v1beta3<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>KubeSchedulerConfiguration<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>profiles</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>schedulerName</span>:<span style=color:#bbb> </span>default-scheduler<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>pluginConfig</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>PodTopologySpread<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>args</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>defaultConstraints</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>            </span>- <span style=color:green;font-weight:700>maxSkew</span>:<span style=color:#bbb> </span><span style=color:#666>1</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>              </span><span style=color:green;font-weight:700>topologyKey</span>:<span style=color:#bbb> </span>topology.kubernetes.io/zone<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>              </span><span style=color:green;font-weight:700>whenUnsatisfiable</span>:<span style=color:#bbb> </span>ScheduleAnyway<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>defaultingType</span>:<span style=color:#bbb> </span>List<span style=color:#bbb>
</span></span></span></code></pre></div><div class="alert alert-info note callout" role=alert><strong>참고:</strong> <a href=/ko/docs/reference/scheduling/config/#%EC%8A%A4%EC%BC%80%EC%A4%84%EB%A7%81-%ED%94%8C%EB%9F%AC%EA%B7%B8%EC%9D%B8><code>SelectorSpread</code> 플러그인</a>은
기본적으로 비활성화되어 있다.
비슷한 효과를 얻기 위해 <code>PodTopologySpread</code>를 사용하는 것을 추천한다.</div><h3 id=internal-default-constraints>내장 기본 제약 조건</h3><div style=margin-top:10px;margin-bottom:10px><b>기능 상태:</b> <code>Kubernetes v1.24 [stable]</code></div><p>파드 토폴로지 분배에 대해 클러스터 수준의 기본 제약을 설정하지 않으면,
kube-scheduler는 다음과 같은 기본 토폴로지 제약이 설정되어 있는 것처럼 동작한다.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>defaultConstraints</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>maxSkew</span>:<span style=color:#bbb> </span><span style=color:#666>3</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>topologyKey</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;kubernetes.io/hostname&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>whenUnsatisfiable</span>:<span style=color:#bbb> </span>ScheduleAnyway<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>maxSkew</span>:<span style=color:#bbb> </span><span style=color:#666>5</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>topologyKey</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;topology.kubernetes.io/zone&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>whenUnsatisfiable</span>:<span style=color:#bbb> </span>ScheduleAnyway<span style=color:#bbb>
</span></span></span></code></pre></div><p>또한, 같은 동작을 제공하는 레거시 <code>SelectorSpread</code> 플러그인은
기본적으로 비활성화되어 있다.</p><div class="alert alert-info note callout" role=alert><strong>참고:</strong><p><code>PodTopologySpread</code> 플러그인은
분배 제약 조건에 지정된 토폴로지 키가 없는 노드에 점수를 매기지 않는다.
이로 인해 기본 토폴로지 제약을 사용하는 경우의
레거시 <code>SelectorSpread</code> 플러그인과는 기본 정책이 다를 수 있다.</p><p>노드에 <code>kubernetes.io/hostname</code> 및 <code>topology.kubernetes.io/zone</code>
레이블 세트가 <strong>둘 다</strong> 설정되지 않을 것으로 예상되는 경우,
쿠버네티스 기본값을 사용하는 대신 자체 제약 조건을 정의하자.</p></div><p>클러스터에 기본 파드 분배 제약 조건을 사용하지 않으려면,
<code>PodTopologySpread</code> 플러그인 구성에서 <code>defaultingType</code> 을 <code>List</code> 로 설정하고
<code>defaultConstraints</code> 를 비워두어 기본값을 비활성화할 수 있다.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>kubescheduler.config.k8s.io/v1beta3<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>KubeSchedulerConfiguration<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>profiles</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>schedulerName</span>:<span style=color:#bbb> </span>default-scheduler<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>pluginConfig</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>PodTopologySpread<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>args</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>defaultConstraints</span>:<span style=color:#bbb> </span>[]<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>defaultingType</span>:<span style=color:#bbb> </span>List<span style=color:#bbb>
</span></span></span></code></pre></div><h2 id=comparison-with-podaffinity-podantiaffinity>파드어피니티(PodAffinity) 및 파드안티어피니티(PodAntiAffinity)와의 비교</h2><p>쿠버네티스에서, <a href=/ko/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity>파드간 어피니티 및 안티 어피니티</a>는
파드가 다른 파드에 서로 어떤 연관 관계를 지니며 스케줄링되는지를 제어하며,
이는 파드들이 서로 더 밀집되도록 하거나 흩어지도록 하는 것을 의미한다.</p><dl><dt><code>podAffinity</code></dt><dd>파드를 끌어당긴다. 조건이 충족되는 토폴로지 도메인에는
원하는 수의 파드를 얼마든지 채울 수 있다.
<code>podAntiAffinity</code></dd><dd>파드를 밀어낸다.
이를 <code>requiredDuringSchedulingIgnoredDuringExecution</code> 모드로 설정하면
각 토폴로지 도메인에는 하나의 파드만 스케줄링될 수 있다.
반면 <code>preferredDuringSchedulingIgnoredDuringExecution</code>로 설정하면 제약 조건이 강제성을 잃게 된다.</dd></dl><p>더 세밀한 제어를 위해,
토폴로지 분배 제약 조건을 지정하여 다양한 토폴로지 도메인에 파드를 분배할 수 있고,
이를 통해 고 가용성 또는 비용 절감을 달성할 수 있다.
이는 또한 워크로드의 롤링 업데이트와 레플리카의 원활한 스케일링 아웃에 도움이 될 수 있다.</p><p>더 자세한 내용은
파드 토폴로지 분배 제약 조건에 대한 개선 제안의
<a href=https://github.com/kubernetes/enhancements/tree/master/keps/sig-scheduling/895-pod-topology-spread#motivation>동기(motivation)</a> 섹션을 참고한다.</p><h2 id=알려진-제한사항>알려진 제한사항</h2><ul><li><p>파드가 제거된 이후에도 제약 조건이 계속 충족된다는 보장은 없다.
예를 들어 디플로이먼트를 스케일링 다운하면 그 결과로 파드의 분포가 불균형해질 수 있다.</p><p><a href=https://github.com/kubernetes-sigs/descheduler>Descheduler</a>와 같은 도구를 사용하여
파드 분포를 다시 균형있게 만들 수 있다.</p></li><li><p>테인트된(tainted) 노드에 매치된 파드도 계산에 포함된다.
<a href=https://github.com/kubernetes/kubernetes/issues/80921>이슈 80921</a>을 본다.</p></li><li><p>스케줄러는 클러스터가 갖는 모든 존 또는 다른 토폴로지 도메인에 대한 사전 지식을 갖고 있지 않다.
이 정보들은 클러스터의 기존 노드로부터 획득된다.
이로 인해 오토스케일된 클러스터에서 문제가 발생할 수 있는데,
예를 들어 노드 풀(또는 노드 그룹)이 0으로 스케일 다운되고,
클러스터가 다시 스케일 업 되기를 기대하는 경우,
해당 토폴로지 도메인은 적어도 1개의 노드가 존재하기 전에는 고려가 되지 않을 것이다.</p><p>이를 극복하기 위해, 파드 토폴로지 분배 제약 조건과
전반적인 토폴로지 도메인 집합에 대한 정보를 인지하고 동작하는
클러스터 오토스케일링 도구를 이용할 수 있다.</p></li></ul><h2 id=다음-내용>다음 내용</h2><ul><li><a href=/blog/2020/05/introducing-podtopologyspread/>블로그: PodTopologySpread 소개</a>에서는
<code>maxSkew</code> 에 대해 자세히 설명하고, 몇 가지 고급 사용 예제를 제공한다.</li><li>파드 API 레퍼런스의
<a href=/docs/reference/kubernetes-api/workload-resources/pod-v1/#scheduling>스케줄링</a> 섹션을 읽어 본다.</li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-78e0431b4b7516092662a7c289cbb304>6 - 노드-압박 축출</h1><p>노드-압박 축출은 <a class=glossary-tooltip title='클러스터의 각 노드에서 실행되는 에이전트. Kubelet은 파드에서 컨테이너가 확실하게 동작하도록 관리한다.' data-toggle=tooltip data-placement=top href=/docs/reference/generated/kubelet target=_blank aria-label=kubelet>kubelet</a>이 노드의 자원을 회수하기 위해
파드를 능동적으로 중단시키는 절차이다.</br></p><p><a class=glossary-tooltip title='클러스터의 각 노드에서 실행되는 에이전트. Kubelet은 파드에서 컨테이너가 확실하게 동작하도록 관리한다.' data-toggle=tooltip data-placement=top href=/docs/reference/generated/kubelet target=_blank aria-label=kubelet>kubelet</a>은
클러스터 노드의 CPU, 메모리, 디스크 공간, 파일시스템 inode와 같은 자원을 모니터링한다.
이러한 자원 중 하나 이상이 특정 소모 수준에 도달하면,
kubelet은 하나 이상의 파드를 능동적으로 중단시켜
자원을 회수하고 고갈 상황을 방지할 수 있다.</p><p>노드-압박 축출 과정에서, kubelet은 축출할 파드의 <code>PodPhase</code>를
<code>Failed</code>로 설정함으로써 파드가 종료된다.</p><p>노드-압박 축출은
<a href=/ko/docs/concepts/scheduling-eviction/api-eviction/>API를 이용한 축출</a>과는 차이가 있다.</p><p>kubelet은 이전에 설정된 <code>PodDisruptionBudget</code> 값이나 파드의 <code>terminationGracePeriodSeconds</code> 값을 따르지 않는다.
<a href=#soft-eviction-thresholds>소프트 축출 임계값</a>을 사용하는 경우,
kubelet은 이전에 설정된 <code>eviction-max-pod-grace-period</code> 값을 따른다.
<a href=#hard-eviction-thresholds>하드 축출 임계값</a>을 사용하는 경우, 파드 종료 시 <code>0s</code> 만큼 기다린 후 종료한다(즉, 기다리지 않고 바로 종료한다).</p><p>실패한 파드를 새로운 파드로 교체하는
<a class=glossary-tooltip title='워크로드는 클러스터의 컨테이너를 동작시키고 관리하기 위해 사용하는 오브젝트이다.' data-toggle=tooltip data-placement=top href=/ko/docs/concepts/workloads/ target=_blank aria-label=워크로드>워크로드</a> 리소스(예:
<a class=glossary-tooltip title='내구성이 있는 스토리지와 파드별로 지속성 식별자를 사용해서 파드 집합의 디플로이먼트와 스케일링을 관리한다.' data-toggle=tooltip data-placement=top href=/ko/docs/concepts/workloads/controllers/statefulset/ target=_blank aria-label=스테이트풀셋(StatefulSet)>스테이트풀셋(StatefulSet)</a> 또는
<a class=glossary-tooltip title='클러스터에서 복제된 애플리케이션을 관리한다.' data-toggle=tooltip data-placement=top href=/ko/docs/concepts/workloads/controllers/deployment/ target=_blank aria-label=디플로이먼트(Deployment)>디플로이먼트(Deployment)</a>)가 파드를 관리하는 경우,
컨트롤 플레인이나 <code>kube-controller-manager</code>가 축출된 파드를 대신할 새 파드를 생성한다.</p><div class="alert alert-info note callout" role=alert><strong>참고:</strong> kubelet은 최종 사용자 파드를 종료하기 전에
먼저 <a href=#reclaim-node-resources>노드 수준 자원을 회수</a>하려고 시도한다.
예를 들어, 디스크 자원이 부족하면 사용하지 않는 컨테이너 이미지를 먼저 제거한다.</div><p>kubelet은 축출 결정을 내리기 위해 다음과 같은 다양한 파라미터를 사용한다.</p><ul><li>축출 신호</li><li>축출 임계값</li><li>모니터링 간격</li></ul><h3 id=eviction-signals>축출 신호</h3><p>축출 신호는 특정 시점에서 특정 자원의 현재 상태이다.
kubelet은 노드에서 사용할 수 있는 리소스의 최소량인
축출 임계값과 축출 신호를 비교하여
축출 결정을 내린다.</p><p>kubelet은 다음과 같은 축출 신호를 사용한다.</p><table><thead><tr><th>축출 신호</th><th>설명</th></tr></thead><tbody><tr><td><code>memory.available</code></td><td><code>memory.available</code> := <code>node.status.capacity[memory]</code> - <code>node.stats.memory.workingSet</code></td></tr><tr><td><code>nodefs.available</code></td><td><code>nodefs.available</code> := <code>node.stats.fs.available</code></td></tr><tr><td><code>nodefs.inodesFree</code></td><td><code>nodefs.inodesFree</code> := <code>node.stats.fs.inodesFree</code></td></tr><tr><td><code>imagefs.available</code></td><td><code>imagefs.available</code> := <code>node.stats.runtime.imagefs.available</code></td></tr><tr><td><code>imagefs.inodesFree</code></td><td><code>imagefs.inodesFree</code> := <code>node.stats.runtime.imagefs.inodesFree</code></td></tr><tr><td><code>pid.available</code></td><td><code>pid.available</code> := <code>node.stats.rlimit.maxpid</code> - <code>node.stats.rlimit.curproc</code></td></tr></tbody></table><p>이 표에서, <code>설명</code> 열은 kubelet이 축출 신호 값을 계산하는 방법을 나타낸다.
각 축출 신호는 백분율 또는 숫자값을 지원한다.
kubelet은 총 용량 대비 축출 신호의 백분율 값을
계산한다.</p><p><code>memory.available</code> 값은 <code>free -m</code>과 같은 도구가 아니라 cgroupfs로부터 도출된다.
이는 <code>free -m</code>이 컨테이너 안에서는 동작하지 않고, 또한 사용자가
<a href=/docs/tasks/administer-cluster/reserve-compute-resources/#node-allocatable>node allocatable</a>
기능을 사용하는 경우 자원 부족에 대한 결정은 루트 노드뿐만 아니라
cgroup 계층 구조의 최종 사용자 파드 부분에서도 지역적으로 이루어지기 때문에 중요하다.
이 <a href=/examples/admin/resource/memory-available.sh>스크립트</a>는
kubelet이 <code>memory.available</code>을 계산하기 위해 수행하는 동일한 단계들을 재현한다.
kubelet은 메모리 압박 상황에서 메모리가 회수 가능하다고 가정하므로,
inactive_file(즉, 비활성 LRU 목록의 파일 기반 메모리 바이트 수)을
계산에서 제외한다.</p><p>kubelet은 다음과 같은 파일시스템 파티션을 지원한다.</p><ol><li><code>nodefs</code>: 노드의 메인 파일시스템이며, 로컬 디스크 볼륨, emptyDir,
로그 스토리지 등에 사용된다. 예를 들어 <code>nodefs</code>는 <code>/var/lib/kubelet/</code>을 포함한다.</li><li><code>imagefs</code>: 컨테이너 런타임이 컨테이너 이미지 및
컨테이너 쓰기 가능 레이어를 저장하는 데 사용하는 선택적 파일시스템이다.</li></ol><p>kubelet은 이러한 파일시스템을 자동으로 검색하고 다른 파일시스템은 무시한다.
kubelet은 다른 구성은 지원하지 않는다.</p><p>아래의 kubelet 가비지 수집 기능은 더 이상 사용되지 않으며 축출로 대체되었다.</p><table><thead><tr><th>기존 플래그</th><th>새로운 플래그</th><th>이유</th></tr></thead><tbody><tr><td><code>--image-gc-high-threshold</code></td><td><code>--eviction-hard</code> 또는 <code>--eviction-soft</code></td><td>기존의 축출 신호가 이미지 가비지 수집을 트리거할 수 있음</td></tr><tr><td><code>--image-gc-low-threshold</code></td><td><code>--eviction-minimum-reclaim</code></td><td>축출 회수도 동일한 작업을 수행</td></tr><tr><td><code>--maximum-dead-containers</code></td><td>-</td><td>오래된 로그들이 컨테이너의 컨텍스트 외부에 저장된 이후로 사용되지 않음</td></tr><tr><td><code>--maximum-dead-containers-per-container</code></td><td>-</td><td>오래된 로그들이 컨테이너의 컨텍스트 외부에 저장된 이후로 사용되지 않음</td></tr><tr><td><code>--minimum-container-ttl-duration</code></td><td>-</td><td>오래된 로그들이 컨테이너의 컨텍스트 외부에 저장된 이후로 사용되지 않음</td></tr></tbody></table><h3 id=축출-임계값>축출 임계값</h3><p>kubelet이 축출 결정을 내릴 때 사용하는 축출 임계값을
사용자가 임의로 설정할 수 있다.</p><p>축출 임계값은 <code>[eviction-signal][operator][quantity]</code> 형태를 갖는다.</p><ul><li><code>eviction-signal</code>에는 사용할 <a href=#eviction-signals>축출 신호</a>를 적는다.</li><li><code>operator</code>에는 <a href=https://ko.wikipedia.org/wiki/%EA%B4%80%EA%B3%84%EC%97%B0%EC%82%B0%EC%9E%90#%ED%91%9C%EC%A4%80_%EA%B4%80%EA%B3%84%EC%97%B0%EC%82%B0%EC%9E%90>관계연산자</a>를
적는다(예: <code>&lt;</code> - 미만)</li><li><code>quantity</code>에는 <code>1Gi</code>와 같이 축출 임계값 수치를 적는다.
<code>quantity</code>에 들어가는 값은 쿠버네티스가 사용하는 수치 표현 방식과 맞아야 한다.
숫자값 또는 백분율(<code>%</code>)을 사용할 수 있다.</li></ul><p>예를 들어, 노드에 총 <code>10Gi</code>의 메모리가 있고
<code>1Gi</code> 아래로 내려갔을 때 축출이 시작되도록 만들고 싶으면, 축출 임계값을
<code>memory.available&lt;10%</code> 또는 <code>memory.available&lt;1Gi</code> 형태로 정할 수 있다. 둘을 동시에 사용할 수는 없다.</p><p>소프트 축출 임계값과 하드 축출 임계값을 설정할 수 있다.</p><h4 id=soft-eviction-thresholds>소프트 축출 임계값</h4><p>소프트 축출 임계값은 관리자가 설정하는 유예 시간(필수)과 함께 정의된다.
kubelet은 유예 시간이 초과될 때까지 파드를 제거하지 않는다.
유예 시간이 지정되지 않으면 kubelet 시작 시
오류가 반환된다.</p><p>kubelet이 축출 과정에서 사용할 수 있도록,
'소프트 축출 임계값'과 '최대 허용 파드 종료 유예 시간' 둘 다를 설정할 수 있다.
'최대 허용 파드 종료 유예 시간'이 설정되어 있는 상태에서 '소프트 축출 임계값'에 도달하면,
kubelet은 두 유예 시간 중 작은 쪽을 적용한다.
'최대 허용 파드 종료 유예 시간'을 설정하지 않으면,
kubelet은 축출된 파드를 유예 시간 없이 즉시 종료한다.</p><p>소프트 축출 임계값을 설정할 때 다음과 같은 플래그를 사용할 수 있다.</p><ul><li><code>eviction-soft</code>: 축출 임계값(예: <code>memory.available&lt;1.5Gi</code>)의 집합이며,
지정된 유예 시간동안 이 축출 임계값 조건이 충족되면 파드 축출이 트리거된다.</li><li><code>eviction-soft-grace-period</code>: 축출 유예 시간의 집합이며,
소프트 축출 임계값 조건이 이 유예 시간동안 충족되면 파드 축출이 트리거된다.</li><li><code>eviction-max-pod-grace-period</code>: '최대 허용 파드 종료 유예 시간(단위: 초)'이며,
소프트 축출 임계값 조건이 충족되어 파드를 종료할 때 사용한다.</li></ul><h4 id=hard-eviction-thresholds>하드 축출 임계값</h4><p>하드 축출 임계값에는 유예 시간이 없다. 하드 축출 임계값 조건이 충족되면,
kubelet은 고갈된 자원을 회수하기 위해 파드를 유예 시간 없이
즉시 종료한다.</p><p><code>eviction-hard</code> 플래그를 사용하여 하드 축출
임계값(예: <code>memory.available&lt;1Gi</code>)을 설정할 수 있다.</p><p>kubelet은 다음과 같은 하드 축출 임계값을 기본적으로 설정하고 있다.</p><ul><li><code>memory.available&lt;100Mi</code></li><li><code>nodefs.available&lt;10%</code></li><li><code>imagefs.available&lt;15%</code></li><li><code>nodefs.inodesFree&lt;5%</code> (리눅스 노드)</li></ul><h3 id=축출-모니터링-시간-간격>축출 모니터링 시간 간격</h3><p>kubelet은 <code>housekeeping-interval</code>에 설정된 시간 간격(기본값: <code>10s</code>)마다
축출 임계값을 확인한다.</p><h3 id=node-conditions>노드 컨디션</h3><p>kubelet은 하드/소프트 축출 임계값 조건이 충족되어
노드 압박이 발생했다는 것을 알리기 위해,
설정된 유예 시간과는 관계없이 노드 컨디션을 보고한다.</p><p>kubelet은 다음과 같이 노드 컨디션과 축출 신호를 매핑한다.</p><table><thead><tr><th>노드 컨디션</th><th>축출 신호</th><th>설명</th></tr></thead><tbody><tr><td><code>MemoryPressure</code></td><td><code>memory.available</code></td><td>노드의 가용 메모리 양이 축출 임계값에 도달함</td></tr><tr><td><code>DiskPressure</code></td><td><code>nodefs.available</code>, <code>nodefs.inodesFree</code>, <code>imagefs.available</code>, 또는 <code>imagefs.inodesFree</code></td><td>노드의 루트 파일시스템 또는 이미지 파일시스템의 가용 디스크 공간 또는 inode의 수가 축출 임계값에 도달함</td></tr><tr><td><code>PIDPressure</code></td><td><code>pid.available</code></td><td>(리눅스) 노드의 가용 프로세스 ID(PID)가 축출 임계값 이하로 내려옴</td></tr></tbody></table><p>kubelet은 <code>--node-status-update-frequency</code>에 설정된
시간 간격(기본값: <code>10s</code>)마다 노드 컨디션을 업데이트한다.</p><h4 id=노드-컨디션-진동-oscillation>노드 컨디션 진동(oscillation)</h4><p>경우에 따라, 노드의 축출 신호값이 사전에 설정된 유예 시간 동안 유지되지 않고
소프트 축출 임계값을 중심으로 진동할 수 있다. 이로 인해 노드 컨디션이 계속
<code>true</code>와 <code>false</code>로 바뀌며, 잘못된 축출 결정을 야기할 수 있다.</p><p>이러한 진동을 방지하기 위해, <code>eviction-pressure-transition-period</code> 플래그를
사용하여 kubelet이 노드 컨디션을 다른 상태로 바꾸기 위해 기다려야 하는 시간을
설정할 수 있다. 기본값은 <code>5m</code>이다.</p><h3 id=reclaim-node-resources>노드-수준 자원 회수하기</h3><p>kubelet은 최종 사용자 파드를 축출하기 전에 노드-수준 자원 회수를 시도한다.</p><p><code>DiskPressure</code> 노드 컨디션이 보고되면,
kubelet은 노드의 파일시스템을 기반으로 노드-수준 자원을 회수한다.</p><h4 id=imagefs-가-있는-경우><code>imagefs</code>가 있는 경우</h4><p>컨테이너 런타임이 사용할 전용 <code>imagefs</code> 파일시스템이 노드에 있으면,
kubelet은 다음 작업을 수행한다.</p><ul><li><code>nodefs</code> 파일시스템이 축출 임계값 조건을 충족하면,
kubelet은 종료된 파드와 컨테이너에 대해 가비지 수집을 수행한다.</li><li><code>imagefs</code> 파일시스템이 축출 임계값 조건을 충족하면,
kubelet은 모든 사용중이지 않은 이미지를 삭제한다.</li></ul><h4 id=imagefs-가-없는-경우><code>imagefs</code>가 없는 경우</h4><p>노드에 <code>nodefs</code> 파일시스템만 있고 이것이 축출 임계값 조건을 충족한 경우,
kubelet은 다음 순서로 디스크 공간을 확보한다.</p><ol><li>종료된 파드와 컨테이너에 대해 가비지 수집을 수행한다.</li><li>사용중이지 않은 이미지를 삭제한다.</li></ol><h3 id=kubelet-축출을-위한-파드-선택>kubelet 축출을 위한 파드 선택</h3><p>kubelet이 노드-수준 자원을 회수했음에도 축출 신호가 임계값 아래로 내려가지 않으면,
kubelet은 최종 사용자 파드 축출을 시작한다.</p><p>kubelet은 파드 축출 순서를 결정하기 위해 다음의 파라미터를 활용한다.</p><ol><li>파드의 자원 사용량이 요청량을 초과했는지 여부</li><li><a href=/ko/docs/concepts/scheduling-eviction/pod-priority-preemption/>파드 우선순위</a></li><li>파드의 자원 요청량 대비 자원 사용량</li></ol><p>결과적으로, kubelet은 다음과 같은 순서로 파드의 축출 순서를 정하고 축출을 수행한다.</p><ol><li><code>BestEffort</code> 또는 <code>Burstable</code> 파드 중 자원 사용량이 요청량을 초과한 파드.
이 파드들은 파드들의 우선순위, 그리고 자원 사용량이 요청량을
얼마나 초과했는지에 따라 축출된다.</li><li><code>Guaranteed</code>, <code>Burstable</code> 파드 중 자원 사용량이 요청량보다 낮은 파드는
우선순위에 따라 후순위로 축출된다.</li></ol><div class="alert alert-info note callout" role=alert><strong>참고:</strong> kubelet이 파드 축출 순서를 결정할 때 파드의 QoS 클래스는 이용하지 않는다.
메모리 등의 자원을 회수할 때, QoS 클래스를 이용하여 가장 가능성이 높은 파드 축출 순서를 예측할 수는 있다.
QoS는 EphemeralStorage 요청에 적용되지 않으므로,
노드가 예를 들어 <code>DiskPressure</code> 아래에 있는 경우 위의 시나리오가 적용되지 않는다.</div><p><code>Guaranteed</code> 파드는 모든 컨테이너에 대해 자원 요청량과 제한이 명시되고
그 둘이 동일할 때에만 보장(guaranteed)된다. 다른 파드의 자원 사용으로 인해
<code>Guaranteed</code> 파드가 축출되는 일은 발생하지 않는다. 만약 시스템 데몬(예:
<code>kubelet</code>, <code>journald</code>)이 <code>system-reserved</code> 또는 <code>kube-reserved</code>
할당을 통해 예약된 것보다 더 많은 자원을 소비하고, 노드에는 요청량보다 적은 양의
자원을 사용하고 있는 <code>Guaranteed</code> / <code>Burstable</code> 파드만 존재한다면,
kubelet은 노드 안정성을 유지하고 자원 고갈이 다른 파드에 미칠 영향을 통제하기 위해
이러한 파드 중 하나를 골라 축출해야 한다.
이 경우, 가장 낮은 <code>Priority</code>를 갖는 파드가 선택된다.</p><p><code>inodes</code>와 <code>PIDs</code>에 대한 요청량은 정의하고 있지 않기 때문에, kubelet이 <code>inode</code>
또는 <code>PID</code> 고갈 때문에 파드를 축출할 때에는 파드의 <code>Priority</code>를 이용하여 축출
순위를 정한다.</p><p>노드에 전용 <code>imagefs</code> 파일시스템이 있는지 여부에 따라 kubelet이 파드 축출 순서를
정하는 방식에 차이가 있다.</p><h4 id=imagefs-가-있는-경우-1><code>imagefs</code>가 있는 경우</h4><p><code>nodefs</code>로 인한 축출의 경우, kubelet은 <code>nodefs</code>
사용량(<code>모든 컨테이너의 로컬 볼륨 + 로그</code>)을 기준으로 축출 순서를 정한다.</p><p><code>imagefs</code>로 인한 축출의 경우, kubelet은 모든 컨테이너의
쓰기 가능한 레이어(writable layer) 사용량을 기준으로 축출 순서를 정한다.</p><h4 id=imagefs-가-없는-경우-1><code>imagefs</code>가 없는 경우</h4><p><code>nodefs</code>로 인한 축출의 경우, kubelet은 각 파드의 총
디스크 사용량(<code>모든 컨테이너의 로컬 볼륨 + 로그 + 쓰기 가능한 레이어</code>)을 기준으로 축출 순서를 정한다.</p><h3 id=최소-축출-회수량>최소 축출 회수량</h3><p>경우에 따라, 파드를 축출했음에도 적은 양의 자원만이 회수될 수 있다.
이로 인해 kubelet이 반복적으로 축출 임계값 도달을 감지하고
여러 번의 축출을 수행할 수 있다.</p><p><code>--eviction-minimum-reclaim</code> 플래그 또는
<a href=/docs/tasks/administer-cluster/kubelet-config-file/>kubelet 설정 파일</a>을 이용하여
각 자원에 대한 최소 회수량을 설정할 수 있다. kubelet이 자원 부족 상황을 감지하면,
앞서 설정한 최소 회수량에 도달할때까지 회수를 계속 진행한다.</p><p>예를 들어, 다음 YAML은 최소 회수량을 정의하고 있다.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>kubelet.config.k8s.io/v1beta1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>KubeletConfiguration<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>evictionHard</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>memory.available</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;500Mi&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>nodefs.available</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;1Gi&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>imagefs.available</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;100Gi&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>evictionMinimumReclaim</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>memory.available</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;0Mi&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>nodefs.available</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;500Mi&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>imagefs.available</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;2Gi&#34;</span><span style=color:#bbb>
</span></span></span></code></pre></div><p>이 예제에서, 만약 <code>nodefs.available</code> 축출 신호가 축출 임계값 조건에 도달하면,
kubelet은 축출 신호가 임계값인 <code>1Gi</code>에 도달할 때까지 자원을 회수하며,
이어서 축출 신호가 <code>1.5Gi</code>에 도달할 때까지 최소 <code>500Mi</code> 이상의 자원을
회수한다.</p><p>유사한 방식으로, kubelet은 <code>imagefs.available</code> 축출 신호가
<code>102Gi</code>에 도달할 때까지 <code>imagefs</code> 자원을 회수한다.</p><p>모든 자원에 대해 <code>eviction-minimum-reclaim</code>의 기본값은 <code>0</code>이다.</p><h3 id=노드-메모리-부족-시의-동작>노드 메모리 부족 시의 동작</h3><p>kubelet의 메모리 회수가 가능하기 이전에
노드에 메모리 부족(out of memory, 이하 OOM) 이벤트가 발생하면,
노드는 <a href=https://lwn.net/Articles/391222/>oom_killer</a>에 의존한다.</p><p>kubelet은 각 파드에 설정된 QoS를 기반으로 각 컨테이너에 <code>oom_score_adj</code> 값을 설정한다.</p><table><thead><tr><th>서비스 품질(Quality of Service)</th><th>oom_score_adj</th></tr></thead><tbody><tr><td><code>Guaranteed</code></td><td>-997</td></tr><tr><td><code>BestEffort</code></td><td>1000</td></tr><tr><td><code>Burstable</code></td><td>min(max(2, 1000 - (1000 * memoryRequestBytes) / machineMemoryCapacityBytes), 999)</td></tr></tbody></table><div class="alert alert-info note callout" role=alert><strong>참고:</strong> 또한, kubelet은 <code>system-node-critical</code> <a class=glossary-tooltip title='파드 프라이어리티는 다른 파드에 대한 상대적인 중요도를 나타낸다.' data-toggle=tooltip data-placement=top href=/ko/docs/concepts/scheduling-eviction/pod-priority-preemption/#%ed%8c%8c%eb%93%9c-%ec%9a%b0%ec%84%a0%ec%88%9c%ec%9c%84 target=_blank aria-label='파드 우선 순위(Priority)'>파드 우선 순위(Priority)</a>를 갖는 파드의 컨테이너에
<code>oom_score_adj</code> 값을 <code>-997</code>로 설정한다.</div><p>노드가 OOM을 겪기 전에 kubelet이 메모리를 회수하지 못하면, <code>oom_killer</code>가 노드의
메모리 사용률 백분율을 이용하여 <code>oom_score</code>를 계산하고, 각 컨테이너의 실질
<code>oom_score</code>를 구하기 위해 <code>oom_score_adj</code>를 더한다. 그 뒤 <code>oom_score</code>가 가장 높은
컨테이너부터 종료시킨다.</p><p>이는 곧, 스케줄링 요청에 비해 많은 양의 메모리를 사용하면서
QoS가 낮은 파드에 속한 컨테이너가 먼저 종료됨을 의미한다.</p><p>파드 축출과 달리, 컨테이너가 OOM으로 인해 종료되면,
<code>kubelet</code>이 컨테이너의 <code>RestartPolicy</code>를 기반으로 컨테이너를 다시 실행할 수 있다.</p><h3 id=node-pressure-eviction-good-practices>추천 예시</h3><p>아래 섹션에서 축출 설정에 대한 추천 예시를 소개한다.</p><h4 id=스케줄-가능한-자원과-축출-정책>스케줄 가능한 자원과 축출 정책</h4><p>kubelet에 축출 정책을 설정할 때, 만약 어떤 파드 배치가 즉시 메모리 압박을
야기하기 때문에 축출을 유발한다면 스케줄러가 그 파드 배치를 수행하지 않도록
설정해야 한다.</p><p>다음 시나리오를 가정한다.</p><ul><li>노드 메모리 용량: <code>10Gi</code></li><li>운영자는 시스템 데몬(커널, <code>kubelet</code> 등)을 위해 메모리 용량의 10%를 확보해 놓고 싶어 한다.</li><li>운영자는 시스템 OOM 발생을 줄이기 위해 메모리 사용률이 95%인 상황에서 파드를 축출하고 싶어한다.</li></ul><p>이것이 실현되도록, kubelet이 다음과 같이 실행된다.</p><pre tabindex=0><code>--eviction-hard=memory.available&lt;500Mi
--system-reserved=memory=1.5Gi
</code></pre><p>이 환경 설정에서, <code>--system-reserved</code> 플래그는 시스템 용으로 <code>1.5Gi</code> 메모리를
확보하는데, 이는 <code>총 메모리의 10% + 축출 임계값</code>에 해당된다.</p><p>파드가 요청량보다 많은 메모리를 사용하거나 시스템이 <code>1Gi</code> 이상의 메모리를
사용하여, <code>memory.available</code> 축출 신호가 <code>500Mi</code> 아래로 내려가면 노드가 축출
임계값에 도달할 수 있다.</p><h4 id=데몬셋-daemonset>데몬셋(DaemonSet)</h4><p>파드 우선 순위(Priority)는 파드 축출 결정을 내릴 때의 주요 요소이다.
kubelet이 <code>DaemonSet</code>에 속하는 파드를 축출하지 않도록 하려면
해당 파드의 파드 스펙에 충분히 높은 <code>priorityClass</code>를 지정한다.
또는 낮은 <code>priorityClass</code>나 기본값을 사용하여
리소스가 충분할 때만 <code>DaemonSet</code> 파드가 실행되도록 허용할 수도 있다.</p><h3 id=알려진-이슈>알려진 이슈</h3><p>다음 섹션에서는 리소스 부족 처리와 관련된 알려진 이슈에 대해 다룬다.</p><h4 id=kubelet이-메모리-압박을-즉시-감지하지-못할-수-있음>kubelet이 메모리 압박을 즉시 감지하지 못할 수 있음</h4><p>기본적으로 kubelet은 <code>cAdvisor</code>를 폴링하여
일정한 간격으로 메모리 사용량 통계를 수집한다.
해당 타임 윈도우 내에서 메모리 사용량이 빠르게 증가하면 kubelet이
<code>MemoryPressure</code>를 충분히 빠르게 감지하지 못해 <code>OOMKiller</code>가 계속 호출될 수 있다.</p><p><code>--kernel-memcg-notification</code> 플래그를 사용하여
kubelet의 <code>memcg</code> 알림 API가 임계값을 초과할 때 즉시 알림을 받도록
할 수 있다.</p><p>사용률(utilization)을 극단적으로 높이려는 것이 아니라 오버커밋(overcommit)에 대한 합리적인 조치만 원하는 경우,
이 문제에 대한 현실적인 해결 방법은 <code>--kube-reserved</code> 및
<code>--system-reserved</code> 플래그를 사용하여 시스템에 메모리를 할당하는 것이다.</p><h4 id=active-file-메모리가-사용-가능한-메모리로-간주되지-않음><code>active_file</code> 메모리가 사용 가능한 메모리로 간주되지 않음</h4><p>리눅스에서, 커널은 활성 LRU 목록의 파일 지원 메모리 바이트 수를 <code>active_file</code>
통계로 추적한다. kubelet은 <code>active_file</code> 메모리 영역을 회수할 수 없는 것으로
취급한다. 임시 로컬 스토리지를 포함하여 블록 지원 로컬 스토리지를 집중적으로
사용하는 워크로드의 경우 파일 및 블록 데이터의 커널 수준 캐시는 최근에 액세스한
많은 캐시 페이지가 <code>active_file</code>로 계산될 가능성이 있음을 의미한다. 활성 LRU
목록에 이러한 커널 블록 버퍼가 충분히 많으면, kubelet은 이를 높은 자원 사용
상태로 간주하고 노드가 메모리 압박을 겪고 있다고 테인트를 표시할 수 있으며, 이는
파드 축출을 유발한다.</p><p>자세한 사항은 <a href=https://github.com/kubernetes/kubernetes/issues/43916>https://github.com/kubernetes/kubernetes/issues/43916</a>를 참고한다.</p><p>집중적인 I/O 작업을 수행할 가능성이 있는 컨테이너에 대해 메모리 제한량 및 메모리
요청량을 동일하게 설정하여 이 문제를 해결할 수 있다. 해당 컨테이너에 대한 최적의
메모리 제한량을 추정하거나 측정해야 한다.</p><h2 id=다음-내용>다음 내용</h2><ul><li><a href=/ko/docs/concepts/scheduling-eviction/api-eviction/>API를 이용한 축출</a>에 대해 알아본다.</li><li><a href=/ko/docs/concepts/scheduling-eviction/pod-priority-preemption/>파드 우선순위와 선점</a>에 대해 알아본다.</li><li><a href=/docs/tasks/run-application/configure-pdb/>PodDisruptionBudgets</a>에 대해 알아본다.</li><li><a href=/ko/docs/tasks/configure-pod-container/quality-service-pod/>서비스 품질</a>(QoS)에 대해 알아본다.</li><li><a href=/docs/reference/generated/kubernetes-api/v1.25/#create-eviction-pod-v1-core>축출 API</a>를 확인한다.</li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-b87723bf81b079042860f0ebd37b0a64>7 - API를 이용한 축출(API-initiated Eviction)</h1><p>API를 이용한 축출은 <a href=/docs/reference/generated/kubernetes-api/v1.25/#create-eviction-pod-v1-core>축출 API</a>를 사용하여
생성된 <code>Eviction</code> 오브젝트로 파드를 정상 종료한다.</br></p><p>축출 API를 직접 호출하거나, 또는 <code>kubectl drain</code> 명령과 같이
<a class=glossary-tooltip title='쿠버네티스 API를 제공하는 컨트롤 플레인 컴포넌트.' data-toggle=tooltip data-placement=top href=/ko/docs/concepts/overview/components/#kube-apiserver target=_blank aria-label='API 서버'>API 서버</a>의 클라이언트를 사용하여 프로그램적인 방법으로 축출 요청을 할 수 있다.
이는 <code>Eviction</code> 오브젝트를 만들며, API 서버로 하여금 파드를 종료하도록 만든다.</p><p>API를 이용한 축출은 사용자가 설정한 <a href=/docs/tasks/run-application/configure-pdb/><code>PodDisruptionBudgets</code></a> 및
<a href=/ko/docs/concepts/workloads/pods/pod-lifecycle/#pod-termination><code>terminationGracePeriodSeconds</code></a> 값을 준수한다.</p><p>API를 사용하여 <code>Eviction</code> 오브젝트를 만드는 것은
정책 기반의 파드 <a href=/docs/reference/kubernetes-api/workload-resources/pod-v1/#delete-delete-a-pod><code>DELETE</code> 동작</a>을 수행하는 것과
비슷한 효과를 낸다.</p><h2 id=축출-api-호출하기>축출 API 호출하기</h2><p><a href=/ko/docs/tasks/administer-cluster/access-cluster-api/#api%EC%97%90-%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%98%EB%B0%8D-%EB%B0%A9%EC%8B%9D%EC%9C%BC%EB%A1%9C-%EC%A0%91%EA%B7%BC>각 언어 별 쿠버네티스 클라이언트</a>를 사용하여
쿠버네티스 API를 호출하고 <code>Eviction</code> 오브젝트를 생성할 수 있다.
이를 실행하려면, 아래의 예시를 참고하여 POST 호출을 수행한다.</p><ul class="nav nav-tabs" id=eviction-example role=tablist><li class=nav-item><a data-toggle=tab class="nav-link active" href=#eviction-example-0 role=tab aria-controls=eviction-example-0 aria-selected=true>policy/v1</a></li><li class=nav-item><a data-toggle=tab class=nav-link href=#eviction-example-1 role=tab aria-controls=eviction-example-1>policy/v1beta1</a></li></ul><div class=tab-content id=eviction-example><div id=eviction-example-0 class="tab-pane show active" role=tabpanel aria-labelledby=eviction-example-0><p><div class="alert alert-info note callout" role=alert><strong>참고:</strong> <code>policy/v1</code> 축출은 v1.22 이상에서 사용 가능하다. 이전 버전에서는 <code>policy/v1beta1</code>를 사용한다.</div><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-json data-lang=json><span style=display:flex><span>{
</span></span><span style=display:flex><span>  <span style=color:green;font-weight:700>&#34;apiVersion&#34;</span>: <span style=color:#b44>&#34;policy/v1&#34;</span>,
</span></span><span style=display:flex><span>  <span style=color:green;font-weight:700>&#34;kind&#34;</span>: <span style=color:#b44>&#34;Eviction&#34;</span>,
</span></span><span style=display:flex><span>  <span style=color:green;font-weight:700>&#34;metadata&#34;</span>: {
</span></span><span style=display:flex><span>    <span style=color:green;font-weight:700>&#34;name&#34;</span>: <span style=color:#b44>&#34;quux&#34;</span>,
</span></span><span style=display:flex><span>    <span style=color:green;font-weight:700>&#34;namespace&#34;</span>: <span style=color:#b44>&#34;default&#34;</span>
</span></span><span style=display:flex><span>  }
</span></span><span style=display:flex><span>}
</span></span></code></pre></div></div><div id=eviction-example-1 class=tab-pane role=tabpanel aria-labelledby=eviction-example-1><p><div class="alert alert-info note callout" role=alert><strong>참고:</strong> v1.22에서 사용 중단 및 <code>policy/v1</code>으로 대체되었다.</div><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-json data-lang=json><span style=display:flex><span>{
</span></span><span style=display:flex><span>  <span style=color:green;font-weight:700>&#34;apiVersion&#34;</span>: <span style=color:#b44>&#34;policy/v1beta1&#34;</span>,
</span></span><span style=display:flex><span>  <span style=color:green;font-weight:700>&#34;kind&#34;</span>: <span style=color:#b44>&#34;Eviction&#34;</span>,
</span></span><span style=display:flex><span>  <span style=color:green;font-weight:700>&#34;metadata&#34;</span>: {
</span></span><span style=display:flex><span>    <span style=color:green;font-weight:700>&#34;name&#34;</span>: <span style=color:#b44>&#34;quux&#34;</span>,
</span></span><span style=display:flex><span>    <span style=color:green;font-weight:700>&#34;namespace&#34;</span>: <span style=color:#b44>&#34;default&#34;</span>
</span></span><span style=display:flex><span>  }
</span></span><span style=display:flex><span>}
</span></span></code></pre></div></div></div><p>또는 다음 예시와 같이 <code>curl</code> 또는 <code>wget</code>으로 API에 접근하여
축출 동작을 시도할 수도 있다.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>curl -v -H <span style=color:#b44>&#39;Content-type: application/json&#39;</span> https://your-cluster-api-endpoint.example/api/v1/namespaces/default/pods/quux/eviction -d @eviction.json
</span></span></code></pre></div><h2 id=api를-이용한-축출의-동작>API를 이용한 축출의 동작</h2><p>API를 사용하여 축출을 요청하면,
API 서버는 인가 확인(admission checks)를 수행하고 다음 중 하나로 응답한다.</p><ul><li><code>200 OK</code>: 축출 요청이 허용되었고, <code>Eviction</code> 서브리소스가 생성되었고,
(마치 파드 URL에 <code>DELETE</code> 요청을 보낸 것처럼) 파드가 삭제되었다.</li><li><code>429 Too Many Requests</code>: 현재 설정된
<a class=glossary-tooltip title='An object that limits the number of  of a replicated application, that are down simultaneously from voluntary disruptions.' data-toggle=tooltip data-placement=top href='/ko/docs/reference/glossary/?all=true#term-pod-disruption-budget' target=_blank aria-label=PodDisruptionBudget>PodDisruptionBudget</a> 때문에
축출이 현재 허용되지 않는다.
또는 API 요청 속도 제한(rate limiting) 때문에 이 응답을 받았을 수도 있다.</li><li><code>500 Internal Server Error</code>: 잘못된 환경 설정(예:
여러 PodDisruptionBudget이 하나의 동일한 파드를 참조함)으로 인해 축출이 허용되지 않는다.</li></ul><p>축출하려는 파드가
PodDisruptionBudget이 설정된 워크로드에 속하지 않는다면,
API 서버는 항상 <code>200 OK</code>를 반환하고 축출을 허용한다.</p><p>API 서버가 축출을 허용하면, 파드는 다음과 같이 삭제된다.</p><ol><li>API 서버 내 <code>Pod</code> 리소스의 삭제 타임스탬프(deletion timestamp)가 업데이트되며,
이 타임스탬프에 명시된 시각이 경과하면 API 서버는 해당 <code>Pod</code> 리소스를 종료 대상으로 간주한다.
또한 설정된 그레이스 시간(grace period)이 <code>Pod</code> 리소스에 기록된다.</li><li>로컬 파드가 실행되고 있는 노드의 <a class=glossary-tooltip title='클러스터의 각 노드에서 실행되는 에이전트. Kubelet은 파드에서 컨테이너가 확실하게 동작하도록 관리한다.' data-toggle=tooltip data-placement=top href=/docs/reference/generated/kubelet target=_blank aria-label=kubelet>kubelet</a>이
<code>Pod</code>가 종료 대상으로 표시된 것을 감지하고
로컬 파드의 그레이스풀 셧다운을 시작한다.</li><li>kubelet이 파드를 종료하는 와중에, 컨트롤 플레인은
<a class=glossary-tooltip title='엔드포인트는 서비스(Service) 셀렉터에 매치되는 파드의 IP 주소를 추적한다.' data-toggle=tooltip data-placement=top href='/ko/docs/reference/glossary/?all=true#term-endpoint' target=_blank aria-label=엔드포인트>엔드포인트</a> 및
<a class=glossary-tooltip title='A way to group network endpoints together with Kubernetes resources.' data-toggle=tooltip data-placement=top href=/docs/concepts/services-networking/endpoint-slices/ target=_blank aria-label=엔드포인트슬라이스>엔드포인트슬라이스</a> 오브젝트에서 파드를 삭제한다.
이 결과, 컨트롤러는 파드를 더 이상 유효한 오브젝트로 간주하지 않는다.</li><li>파드의 그레이스 시간이 만료되면,
kubelet이 로컬 파드를 강제로 종료한다.</li><li>kubelet이 API 서버에 <code>Pod</code> 리소스를 삭제하도록 지시한다.</li><li>API 서버가 <code>Pod</code> 리소스를 삭제한다.</li></ol><h2 id=문제가-있어-중단된-축출-트러블슈팅하기>문제가 있어 중단된 축출 트러블슈팅하기</h2><p>일부 경우에, 애플리케이션이 잘못된 상태로 돌입하여,
직접 개입하기 전에는 축출 API가 <code>429</code> 또는 <code>500</code> 응답만 반환할 수 있다.
이러한 현상은, 예를 들면 레플리카셋이 애플리케이션을 서비스할 파드를 생성했지만
새 파드가 <code>Ready</code>로 바뀌지 못하는 경우에 발생할 수 있다.
또는 마지막으로 축출된 파드가 긴 종료 그레이스 시간을 가진 경우에 이러한 현상을 목격할 수도 있다.</p><p>문제가 있어 중단된 축출을 발견했다면, 다음 해결책 중 하나를 시도해 본다.</p><ul><li>이 문제를 발생시키는 자동 동작(automated operation)을 중단하거나 일시 중지한다.
해당 동작을 재시작하기 전에, 문제가 있어 중단된 애플리케이션을 조사한다.</li><li>잠시 기다린 뒤, 축출 API를 사용하는 것 대신
클러스터 컨트롤 플레인에서 파드를 직접 삭제한다.</li></ul><h2 id=다음-내용>다음 내용</h2><ul><li><a href=/docs/tasks/run-application/configure-pdb/>Pod Disruption Budget</a>을 사용하여 애플리케이션을 보호하는 방법에 대해 알아본다.</li><li><a href=/ko/docs/concepts/scheduling-eviction/node-pressure-eviction/>노드-압박 축출</a>에 대해 알아본다.</li><li><a href=/ko/docs/concepts/scheduling-eviction/pod-priority-preemption/>파드 우선순위와 선점</a>에 대해 알아본다.</li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-60e5a2861609e0848d58ce8bf99c4a31>8 - 파드 우선순위(priority)와 선점(preemption)</h1><div style=margin-top:10px;margin-bottom:10px><b>기능 상태:</b> <code>Kubernetes v1.14 [stable]</code></div><p><a href=/ko/docs/concepts/workloads/pods/>파드</a>는 <em>우선순위</em> 를 가질 수 있다. 우선순위는
다른 파드에 대한 상대적인 파드의 중요성을 나타낸다. 파드를 스케줄링할 수 없는 경우,
스케줄러는 우선순위가 낮은 파드를 선점(축출)하여 보류 중인 파드를
스케줄링할 수 있게 한다.</p><div class="alert alert-danger warning callout" role=alert><strong>경고:</strong><p>모든 사용자를 신뢰할 수 없는 클러스터에서, 악의적인 사용자가 우선순위가
가장 높은 파드를 생성하여 다른 파드가 축출되거나 스케줄링되지
않을 수 있다.
관리자는 리소스쿼터를 사용하여 사용자가 우선순위가 높은 파드를 생성하지
못하게 할 수 있다.</p><p>자세한 내용은 <a href=/ko/docs/concepts/policy/resource-quotas/#%EA%B8%B0%EB%B3%B8%EC%A0%81%EC%9C%BC%EB%A1%9C-%EC%9A%B0%EC%84%A0-%EC%88%9C%EC%9C%84-%ED%81%B4%EB%9E%98%EC%8A%A4-%EC%86%8C%EB%B9%84-%EC%A0%9C%ED%95%9C>기본적으로 프라이어리티클래스(Priority Class) 소비 제한</a>을
참고한다.</p></div><h2 id=우선순위와-선점을-사용하는-방법>우선순위와 선점을 사용하는 방법</h2><p>우선순위와 선점을 사용하려면 다음을 참고한다.</p><ol><li><p>하나 이상의 <a href=#%ED%94%84%EB%9D%BC%EC%9D%B4%EC%96%B4%EB%A6%AC%ED%8B%B0%ED%81%B4%EB%9E%98%EC%8A%A4>프라이어리티클래스</a>를 추가한다.</p></li><li><p>추가된 프라이어리티클래스 중 하나에 <a href=#%ED%8C%8C%EB%93%9C-%EC%9A%B0%EC%84%A0%EC%88%9C%EC%9C%84><code>priorityClassName</code></a>이 설정된
파드를 생성한다. 물론 파드를 직접 생성할 필요는 없다.
일반적으로 디플로이먼트와 같은 컬렉션 오브젝트의 파드 템플릿에 <code>priorityClassName</code>
을 추가한다.</p></li></ol><p>이 단계에 대한 자세한 내용은 계속 읽어보자.</p><div class="alert alert-info note callout" role=alert><strong>참고:</strong> 쿠버네티스는 이미 <code>system-cluster-critical</code> 과 <code>system-node-critical</code>,
두 개의 프라이어리티클래스를 제공한다.
이들은 일반적인 클래스이며 <a href=/ko/docs/tasks/administer-cluster/guaranteed-scheduling-critical-addon-pods/>중요한(critical) 컴포넌트가 항상 먼저 스케줄링이 되도록 하는 데</a> 사용된다.</div><h2 id=프라이어리티클래스>프라이어리티클래스</h2><p>프라이어리티클래스는 프라이어리티클래스 이름에서 우선순위의 정수 값으로의 매핑을
정의하는 네임스페이스가 아닌(non-namespaced) 오브젝트이다. 이름은
프라이어리티클래스 오브젝트의 메타데이터의 <code>name</code> 필드에 지정된다. 값은
필수 <code>value</code> 필드에 지정되어 있다. 값이 클수록, 우선순위가
높다.
프라이어리티클래스 오브젝트의 이름은 유효한
<a href=/ko/docs/concepts/overview/working-with-objects/names/#dns-%EC%84%9C%EB%B8%8C%EB%8F%84%EB%A9%94%EC%9D%B8-%EC%9D%B4%EB%A6%84>DNS 서브 도메인 이름</a>이어야 하며,
<code>system-</code> 접두사를 붙일 수 없다.</p><p>프라이어리티클래스 오브젝트는 10억 이하의 32비트 정수 값을 가질
수 있다. 일반적으로 선점하거나 축출해서는 안되는 중요한 시스템 파드에는 더 큰 숫자가
예약되어 있다. 클러스터 관리자는 원하는 각 매핑에 대해 프라이어리티클래스 오브젝트를
하나씩 생성해야 한다.</p><p>프라이어리티클래스에는 <code>globalDefault</code> 와 <code>description</code> 두 개의 선택적인 필드도 있다.
<code>globalDefault</code> 필드는 이 프라이어리티클래스의 값을 <code>priorityClassName</code> 이 없는
파드에 사용해야 함을 나타낸다. 시스템에서 <code>globalDefault</code> 가 <code>true</code> 로 설정된
프라이어리티클래스는 하나만 존재할 수 있다. <code>globalDefault</code> 가 설정된
프라이어리티클래스가 없을 경우, <code>priorityClassName</code> 이 없는 파드의
우선순위는 0이다.</p><p><code>description</code> 필드는 임의의 문자열이다. 이 필드는 이 프라이어리티클래스를 언제
사용해야 하는지를 클러스터 사용자에게 알려주기 위한 것이다.</p><h3 id=podpriority와-기존-클러스터에-대한-참고-사항>PodPriority와 기존 클러스터에 대한 참고 사항</h3><ul><li><p>이 기능없이 기존 클러스터를 업그레이드 하는 경우, 기존 파드의
우선순위는 사실상 0이다.</p></li><li><p><code>globalDefault</code> 가 <code>true</code> 로 설정된 프라이어리티클래스를 추가해도 기존 파드의
우선순위는 변경되지 않는다. 이러한 프라이어리티클래스의 값은
프라이어리티클래스를 추가한 후 생성된 파드에만 사용된다.</p></li><li><p>프라이어리티클래스를 삭제하면, 삭제된 프라이어리티클래스의 이름을 사용하는
기존 파드는 변경되지 않고 남아있지만, 삭제된 프라이어리티클래스의 이름을
사용하는 파드는 더 이상 생성할 수 없다.</p></li></ul><h3 id=프라이어리티클래스-예제>프라이어리티클래스 예제</h3><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>scheduling.k8s.io/v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>PriorityClass<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>high-priority<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>value</span>:<span style=color:#bbb> </span><span style=color:#666>1000000</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>globalDefault</span>:<span style=color:#bbb> </span><span style=color:#a2f;font-weight:700>false</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>description</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;이 프라이어리티클래스는 XYZ 서비스 파드에만 사용해야 한다.&#34;</span><span style=color:#bbb>
</span></span></span></code></pre></div><h2 id=non-preempting-priority-class>비-선점 프라이어리티클래스</h2><div style=margin-top:10px;margin-bottom:10px><b>기능 상태:</b> <code>Kubernetes v1.24 [stable]</code></div><p><code>preemptionPolicy: Never</code> 를 가진 파드는 낮은 우선순위 파드의 스케줄링 대기열의
앞쪽에 배치되지만,
그 파드는 다른 파드를 축출할 수 없다.
스케줄링 대기 중인 비-선점 파드는 충분한 리소스가 확보되고
스케줄링될 수 있을 때까지
스케줄링 대기열에 대기한다.
다른 파드와 마찬가지로,
비-선점 파드는
스케줄러 백오프(back-off)에 종속된다.
이는 스케줄러가 이러한 파드를 스케줄링하려고 시도하고 스케줄링할 수 없는 경우,
더 적은 횟수로 재시도하여,
우선순위가 낮은 다른 파드를 미리 스케줄링할 수 있음을 의미한다.</p><p>비-선점 파드는 다른 우선순위가 높은 파드에 의해
축출될 수 있다.</p><p><code>preemptionPolicy</code> 는 기본값으로 <code>PreemptLowerPriority</code> 로 설정되어,
해당 프라이어리티클래스의 파드가 우선순위가 낮은 파드를 축출할 수
있다(기존의 기본 동작과 동일).
<code>preemptionPolicy</code> 가 <code>Never</code> 로 설정된 경우,
해당 프라이어리티클래스의 파드는 비-선점될 것이다.</p><p>예제 유스케이스는 데이터 과학 관련 워크로드이다.
사용자는 다른 워크로드보다 우선순위가 높은 잡(job)을 제출할 수 있지만,
실행 중인 파드를 축출하여 기존의 작업을 삭제하지는 않을 것이다.
클러스터 리소스가 "자연스럽게" 충분히 사용할 수 있게 되면,
<code>preemptionPolicy: Never</code> 의 우선순위가 높은 잡이
다른 대기 중인 파드보다 먼저 스케줄링된다.</p><h3 id=비-선점-프라이어리티클래스-예제>비-선점 프라이어리티클래스 예제</h3><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>scheduling.k8s.io/v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>PriorityClass<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>high-priority-nonpreempting<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>value</span>:<span style=color:#bbb> </span><span style=color:#666>1000000</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>preemptionPolicy</span>:<span style=color:#bbb> </span>Never<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>globalDefault</span>:<span style=color:#bbb> </span><span style=color:#a2f;font-weight:700>false</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>description</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;이 프라이어리티클래스는 다른 파드를 축출하지 않는다.&#34;</span><span style=color:#bbb>
</span></span></span></code></pre></div><h2 id=파드-우선순위>파드 우선순위</h2><p>프라이어리티클래스가 하나 이상 있으면, 그것의 명세에서 이들 프라이어리티클래스 이름 중 하나를
지정하는 파드를 생성할 수 있다. 우선순위 어드미션
컨트롤러는 <code>priorityClassName</code> 필드를 사용하고 우선순위의 정수 값을
채운다. 프라이어리티클래스를 찾을 수 없으면, 파드가 거부된다.</p><p>다음의 YAML은 이전 예제에서 생성된 프라이어리티클래스를
사용하는 파드 구성의 예이다. 우선순위 어드미션 컨트롤러는
명세를 확인하고 파드의 우선순위를 1000000으로
해석한다.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>nginx<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>labels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>env</span>:<span style=color:#bbb> </span>test<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>nginx<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>nginx<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>imagePullPolicy</span>:<span style=color:#bbb> </span>IfNotPresent<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>priorityClassName</span>:<span style=color:#bbb> </span>high-priority<span style=color:#bbb>
</span></span></span></code></pre></div><h3 id=스케줄링-순서에-대한-파드-우선순위의-영향>스케줄링 순서에 대한 파드 우선순위의 영향</h3><p>파드 우선순위가 활성화되면, 스케줄러가 우선순위에 따라 보류 중인
파드를 주문하고 보류 중인 파드는 스케줄링 대기열에서
우선순위가 낮은 다른 보류 중인 파드보다 우선한다. 결과적으로, 스케줄링
요구 사항이 충족되는 경우 우선순위가 더 낮은 파드보다 우선순위가 높은 파드가
더 빨리 스케줄링될 수 있다. 이러한 파드를 스케줄링할 수 없는 경우,
스케줄러는 계속 진행하고 우선순위가 낮은 다른 파드를 스케줄링하려고 한다.</p><h2 id=선점>선점</h2><p>파드가 생성되면, 대기열로 이동하여 스케줄링을 기다린다.
스케줄러가 대기열에서 파드를 선택하여 노드에 스케줄링하려고 한다.
파드의 지정된 모든 요구 사항을 충족하는 노드가 없으면,
보류 중인 파드에 대해 선점 로직이 트리거된다. 보류 중인 파드를 P라 하자.
선점 로직은 P보다 우선순위가 낮은 하나 이상의 파드를 제거하면
해당 노드에서 P를 스케줄링할 수 있는 노드를 찾는다. 이러한
노드가 발견되면, 하나 이상의 우선순위가 낮은 파드가 노드에서 축출된다.
파드가 축출된 후, P는 노드에 스케줄링될 수 있다.</p><h3 id=사용자-노출-정보>사용자 노출 정보</h3><p>파드 P가 노드 N에서 하나 이상의 파드를 축출할 경우, 파드 P의 상태 <code>nominatedNodeName</code>
필드는 노드 N의 이름으로 설정된다. 이 필드는 스케줄러가 파드 P에
예약된 리소스를 추적하는 데 도움이 되고 사용자에게 클러스터의 선점에 대한
정보를 제공한다.</p><p>파드 P는 반드시 "지정된 노드"로 스케줄링되지는 않는다.
스케줄러는 다른 노드에 스케줄링을 시도하기 전에 항상 "지정된 노드"부터 시도한다.
피해자 파드가 축출된 후, 그것은 정상적(graceful)으로 종료되는 기간을 갖는다.
스케줄러가 종료될 피해자 파드를 기다리는 동안 다른 노드를 사용할 수
있게 되면, 스케줄러는 파드 P를 스케줄링하기 위해 다른 노드를 사용할 수 있다. 그 결과,
파드 스펙의 <code>nominatedNodeName</code> 과 <code>nodeName</code> 은 항상 동일하지 않다. 또한,
스케줄러가 노드 N에서 파드를 축출했지만, 파드 P보다 우선순위가 높은 파드가
도착하면, 스케줄러가 노드 N에 새로운 우선순위가 높은 파드를 제공할 수 있다. 이러한
경우, 스케줄러는 파드 P의 <code>nominatedNodeName</code> 을 지운다. 이렇게하면, 스케줄러는
파드 P가 다른 노드에서 파드를 축출할 수 있도록 한다.</p><h3 id=선점의-한계>선점의 한계</h3><h4 id=선점-피해자의-정상적인-종료>선점 피해자의 정상적인 종료</h4><p>파드가 축출되면, 축출된 피해자 파드는
<a href=/ko/docs/concepts/workloads/pods/pod-lifecycle/#%ED%8C%8C%EB%93%9C%EC%9D%98-%EC%A2%85%EB%A3%8C>정상적인 종료 기간</a>을 가진다.
피해자 파드는 작업을 종료하고 빠져나가는 데(exit) 많은 시간을 가진다. 그렇지 않으면,
파드는 강제종료(kill) 된다. 이 정상적인 종료 기간은 스케줄러가 파드를 축출하는
지점과 보류 중인 파드(P)를 노드(N)에서 스케줄링할 수 있는 시점 사이의
시간 간격을 만든다. 그 동안, 스케줄러는 보류 중인 다른 파드를
계속 스케줄링한다. 피해자 파드가 빠져나가거나 종료되면, 스케줄러는 보류 대기열에서
파드를 스케줄하려고 한다. 따라서, 일반적으로 스케줄러가 피해자 파드를 축출하는 시점과
파드 P가 스케줄링된 시점 사이에 시간 간격이 있다.
이러한 차이를 최소화하기 위해, 우선순위가 낮은 파드의 정상적인 종료 기간을 0 또는
작은 수로 설정할 수 있다.</p><h4 id=poddisruptionbudget을-지원하지만-보장하지-않음>PodDisruptionBudget을 지원하지만, 보장하지 않음</h4><p><a href=/ko/docs/concepts/workloads/pods/disruptions/>Pod Disruption Budget</a>(PDB)은
애플리케이션 소유자가 자발적 중단에서 동시에 다운된 복제된
애플리케이션의 파드 수를 제한할 수 있다. 쿠버네티스는 파드를
선점할 때 PDB를 지원하지만, PDB를 따르는 것이 최선의 노력이다. 스케줄러는
선점에 의해 PDB를 위반하지 않은 피해자 파드를 찾으려고 하지만, 그러한 피해자 파드가
발견되지 않으면, 선점은 여전히 발생하며, PDB를 위반하더라도 우선순위가
낮은 파드는 제거된다.</p><h4 id=우선순위가-낮은-파드에-대한-파드-간-어피니티>우선순위가 낮은 파드에 대한 파드-간 어피니티</h4><p>이 질문에 대한 답변이 '예'인 경우에만 노드가 선점 대상으로 간주된다.
"대기 중인 파드보다 우선순위가 낮은 모든 파드가 노드에서
제거되면, 보류 중인 파드를 노드에 스케줄링할 수 있습니까?"</p><div class="alert alert-info note callout" role=alert><strong>참고:</strong> 선점으로 우선순위가 낮은 모든 파드를 반드시 제거할 필요는
없다. 우선순위가 낮은 모든 파드보다 적은 수를 제거하여 보류 중인 파드를
스케줄링할 수 있는 경우, 우선순위가 낮은 파드의 일부만 제거된다.
그럼에도 불구하고, 앞의 질문에 대한 대답은 '예'여야 한다. 답변이 '아니오'인 경우,
노드가 선점 대상으로 간주되지 않는다.</div><p>보류 중인 파드가 노드에 있는 하나 이상의 우선순위가 낮은 파드에 대한 파드-간 어피니티를
가진 경우에, 우선순위가 낮은 파드가 없을 때 파드-간 어피니티 규칙을
충족할 수 없다. 이 경우, 스케줄러는 노드의 파드를 축출하지
않는다. 대신, 다른 노드를 찾는다. 스케줄러가
적합한 노드를 찾거나 찾지 못할 수 있다. 보류 중인 파드를 스케줄링할 수 있다는
보장은 없다.</p><p>이 문제에 대한 권장 솔루션은 우선순위가 같거나 높은 파드에 대해서만 파드-간 어피니티를
생성하는 것이다.</p><h4 id=교차-노드-선점>교차 노드 선점</h4><p>보류 중인 파드 P가 노드 N에 스케줄링될 수 있도록 노드 N이 선점 대상으로 고려되고
있다고 가정한다. 다른 노드의 파드가 축출된 경우에만 P가 N에서 실행 가능해질 수
있다. 예를 들면 다음과 같다.</p><ul><li>파드 P는 노드 N에 대해 고려된다.</li><li>파드 Q는 노드 N과 동일한 영역의 다른 노드에서 실행 중이다.</li><li>파드 P는 파드 Q(<code>topologyKey: topology.kubernetes.io/zone</code>)와 영역(zone) 전체의 안티-어피니티를 갖는다.</li><li>영역에서 파드 P와 다른 파드 간의 안티-어피니티에 대한 다른 경우는
없다.</li><li>노드 N에서 파드 P를 스케줄링하기 위해, 파드 Q를 축출할 수 있지만, 스케줄러는
교차-노드 선점을 수행하지 않는다. 따라서, 파드 P가 노드 N에서
스케줄링할 수 없는 것으로 간주된다.</li></ul><p>파드 Q가 노드에서 제거되면, 파드 안티-어피니티 위반이
사라지고, 파드 P는 노드 N에서 스케줄링될 수 있다.</p><p>수요가 충분하고 합리적인 성능의 알고리즘을 찾을 경우
향후 버전에서 교차 노드 선점의 추가를 고려할 수 있다.</p><h2 id=문제-해결>문제 해결</h2><p>파드 우선순위와 선점은 원하지 않는 부작용을 가질 수 있다. 다음은
잠재적 문제의 예시와 이를 해결하는 방법이다.</p><h3 id=파드가-불필요하게-선점-축출-됨>파드가 불필요하게 선점(축출)됨</h3><p>선점은 우선순위가 높은 보류 중인 파드를 위한 공간을 만들기 위해 리소스 압박을 받고 있는
클러스터에서 기존 파드를 제거한다. 실수로 특정 파드에 높은 우선순위를
부여하면, 의도하지 않은 높은 우선순위 파드가 클러스터에서
선점을 유발할 수 있다. 파드 우선순위는 파드 명세에서
<code>priorityClassName</code> 필드를 설정하여 지정한다. 그런 다음
우선순위의 정수 값이 분석되어 <code>podSpec</code> 의 <code>priority</code> 필드에 채워진다.</p><p>문제를 해결하기 위해, 해당 파드가 우선순위가 낮은 클래스를 사용하도록 <code>priorityClassName</code> 을
변경하거나, 해당 필드를 비워둘 수 있다. 빈
<code>priorityClassName</code> 은 기본값이 0으로 해석된다.</p><p>파드가 축출되면, 축출된 파드에 대한 이벤트가 기록된다.
선점은 클러스터가 파드에 대한 리소스를 충분히 가지지 못한 경우에만
발생한다. 이러한 경우, 선점은 보류 중인 파드(선점자)의 우선순위가
피해자 파드보다 높은 경우에만 발생한다. 보류 중인 파드가 없거나,
보류 중인 파드의 우선순위가 피해자 파드와 같거나 낮은 경우
선점이 발생하지 않아야 한다. 그러한 시나리오에서 선점이 발생하면, 이슈를 올리기 바란다.</p><h3 id=파드가-축출되었지만-선점자는-스케줄링되지-않음>파드가 축출되었지만, 선점자는 스케줄링되지 않음</h3><p>파드가 축출되면, 요청된 정상적인 종료
기간(기본적으로 30초)이 주어진다. 이 기간 내에 대상 파드가
종료되지 않으면, 강제 종료된다. 모든 피해자 파드가 사라지면,
선점자 파드를 스케줄링할 수 있다.</p><p>선점자 파드가 피해자 파드가 없어지기를 기다리는 동안, 동일한 노드에
적합한 우선순위가 높은 파드가 생성될 수 있다. 이 경우, 스케줄러는
선점자 대신 우선순위가 높은 파드를 스케줄링한다.</p><p>이것은 예상된 동작이다. 우선순위가 높은 파드는 우선순위가 낮은 파드를
대체해야 한다.</p><h3 id=우선순위가-높은-파드는-우선순위가-낮은-파드보다-우선함>우선순위가 높은 파드는 우선순위가 낮은 파드보다 우선함</h3><p>스케줄러가 보류 중인 파드를 실행할 수 있는 노드를 찾으려고 한다. 노드를 찾지
못하면, 스케줄러는 임의의 노드에서 우선순위가 낮은 파드를 제거하여
보류 중인 파드를 위한 공간을 만든다.
우선순위가 낮은 파드가 있는 노드가 보류 중인 파드를 실행할 수 없는 경우, 스케줄러는
선점을 위해 우선순위가 높은 다른 노드(다른 노드의 파드와 비교)를
선택할 수 있다. 피해자 파드는 여전히 선점자 파드보다 우선순위가
낮아야 한다.</p><p>선점할 수 있는 여러 노드가 있는 경우, 스케줄러는
우선순위가 가장 낮은 파드 세트를 가진 노드를 선택하려고 한다. 그러나,
이러한 파드가 위반될 PodDisruptionBudget을 가지고 있고 축출된 경우
스케줄러는 우선순위가 높은 파드를 가진 다른 노드를 선택할 수 있다.</p><p>선점을 위해 여러 개의 노드가 존재하고 위의 시나리오 중 어느 것도 적용되지 않는 경우,
스케줄러는 우선순위가 가장 낮은 노드를 선택한다.</p><h2 id=interactions-of-pod-priority-and-qos>파드 우선순위와 서비스 품질 간의 상호 작용</h2><p>파드 우선순위와 <a class=glossary-tooltip title='QoS 클래스(서비스 품질 클래스)는 쿠버네티스가 클러스터 안의 파드들을 여러 클래스로 구분하고, 스케줄링과 축출(eviction)에 대한 결정을 내리는 방법을 제공한다.' data-toggle=tooltip data-placement=top href='/ko/docs/reference/glossary/?all=true#term-qos-class' target=_blank aria-label='QoS 클래스'>QoS 클래스</a>는
상호 작용이 거의 없고 QoS 클래스를 기반으로 파드 우선순위를 설정하는 데 대한
기본 제한이 없는 두 개의 직교(orthogonal) 기능이다. 스케줄러의
선점 로직은 선점 대상을 선택할 때 QoS를 고려하지 않는다.
선점은 파드 우선순위를 고려하고 우선순위가 가장 낮은 대상 세트를
선택하려고 한다. 우선순위가 가장 높은 파드는 스케줄러가
선점자 파드를 스케줄링할 수 없거나 우선순위가 가장 낮은 파드가
<code>PodDisruptionBudget</code> 으로 보호되는 경우에만, 우선순위가 가장 낮은 파드를
축출 대상으로 고려한다.</p><p>kubelet은 우선순위를 사용하여 파드의 <a href=/ko/docs/concepts/scheduling-eviction/node-pressure-eviction/>노드-압박(node-pressure) 축출</a> 순서를 결정한다.
사용자는 QoS 클래스를 사용하여 어떤 파드가 축출될 것인지
예상할 수 있다. kubelet은 다음의 요소들을 통해서 파드의 축출 순위를 매긴다.</p><ol><li>기아(starved) 리소스 사용량이 요청을 초과하는지 여부</li><li>파드 우선순위</li><li>요청 대비 리소스 사용량</li></ol><p>더 자세한 내용은 <a href=/ko/docs/concepts/scheduling-eviction/node-pressure-eviction/#kubelet-%EC%B6%95%EC%B6%9C%EC%9D%84-%EC%9C%84%ED%95%9C-%ED%8C%8C%EB%93%9C-%EC%84%A0%ED%83%9D>kubelet 축출을 위한 파드 선택</a>을
참조한다.</p><p>kubelet 노드-압박 축출은 사용량이 요청을 초과하지 않는 경우
파드를 축출하지 않는다. 우선순위가 낮은 파드가 요청을
초과하지 않으면, 축출되지 않는다. 요청을 초과하는 우선순위가
더 높은 다른 파드가 축출될 수 있다.</p><h2 id=다음-내용>다음 내용</h2><ul><li>프라이어리티클래스와 함께 리소스쿼터 사용에 대해 읽기: <a href=/ko/docs/concepts/policy/resource-quotas/#%EA%B8%B0%EB%B3%B8%EC%A0%81%EC%9C%BC%EB%A1%9C-%EC%9A%B0%EC%84%A0-%EC%88%9C%EC%9C%84-%ED%81%B4%EB%9E%98%EC%8A%A4-%EC%86%8C%EB%B9%84-%EC%A0%9C%ED%95%9C>기본으로 프라이어리티 클래스 소비 제한</a></li><li><a href=/ko/docs/concepts/workloads/pods/disruptions/>파드 중단(disruption)</a>에 대해 학습한다.</li><li><a href=/ko/docs/concepts/scheduling-eviction/api-eviction/>API를 이용한 축출</a>에 대해 학습한다.</li><li><a href=/ko/docs/concepts/scheduling-eviction/node-pressure-eviction/>노드-압박(node-pressure) 축출</a>에 대해 학습한다.</li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-961126cd43559012893979e568396a49>9 - 리소스 빈 패킹(bin packing)</h1><p>kube-scheduler의 <a href=/ko/docs/reference/scheduling/config/#scheduling-plugins>스케줄링 플러그인</a> <code>NodeResourcesFit</code>에는,
리소스의 빈 패킹(bin packing)을 지원하는 <code>MostAllocated</code>과 <code>RequestedToCapacityRatio</code>라는 두 가지 점수 산정(scoring) 전략이 있다.</p><h2 id=mostallocated-전략을-사용하여-빈-패킹-활성화하기>MostAllocated 전략을 사용하여 빈 패킹 활성화하기</h2><p><code>MostAllocated</code> 전략은 리소스 사용량을 기반으로 할당량이 많은 노드를 높게 평가하여 노드에 점수를 매긴다.
각 리소스 유형별로 가중치를 설정하여 노드 점수에 미치는 영향을 조정할 수 있다.</p><p><code>NodeResourcesFit</code> 플러그인에 대한 <code>MostAllocated</code> 전략을 설정하려면,
다음과 유사한 <a href=/ko/docs/reference/scheduling/config>스케줄러 설정</a>을 사용한다.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>kubescheduler.config.k8s.io/v1beta3<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>KubeSchedulerConfiguration<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>profiles</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span>- <span style=color:green;font-weight:700>pluginConfig</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>args</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>scoringStrategy</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>resources</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>cpu<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>weight</span>:<span style=color:#bbb> </span><span style=color:#666>1</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>memory<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>weight</span>:<span style=color:#bbb> </span><span style=color:#666>1</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>intel.com/foo<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>weight</span>:<span style=color:#bbb> </span><span style=color:#666>3</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>intel.com/bar<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>weight</span>:<span style=color:#bbb> </span><span style=color:#666>3</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>type</span>:<span style=color:#bbb> </span>MostAllocated<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>NodeResourcesFit<span style=color:#bbb>
</span></span></span></code></pre></div><p>기타 파라미터와 기본 구성에 대한 자세한 내용은
<a href=/docs/reference/config-api/kube-scheduler-config.v1beta3/#kubescheduler-config-k8s-io-v1beta3-NodeResourcesFitArgs><code>NodeResourcesFitArgs</code></a>에 대한 API 문서를 참조한다.</p><h2 id=requestedtocapacityratio을-사용하여-빈-패킹-활성화하기>RequestedToCapacityRatio을 사용하여 빈 패킹 활성화하기</h2><p><code>RequestedToCapacityRatio</code> 전략은 사용자가 각 리소스에 대한 가중치와 함께 리소스를 지정하여
용량 대비 요청 비율을 기반으로 노드의 점수를 매길 수 있게 한다.
이를 통해 사용자는 적절한 파라미터를 사용하여 확장된 리소스를 빈 팩으로 만들 수 있어
대규모의 클러스터에서 부족한 리소스의 활용도를 향상시킬 수 있다. 이 전략은
할당된 리소스의 구성된 기능에 따라 노드를 선호하게 한다. <code>NodeResourcesFit</code>점수 기능의
<code>RequestedToCapacityRatio</code> 동작은 <a href=/docs/reference/config-api/kube-scheduler-config.v1beta3/#kubescheduler-config-k8s-io-v1beta3-ScoringStrategy>scoringStrategy</a>필드를
이용하여 제어할 수 있다.
<code>scoringStrategy</code> 필드에서 <code>requestedToCapacityRatio</code>와 <code>resources</code>라는 두 개의 파라미터를
구성할 수 있다. <code>requestedToCapacityRatio</code>파라미터의
<code>shape</code>를 사용하면 <code>utilization</code>과 <code>score</code> 값을 기반으로
최소 요청 혹은 최대 요청된 대로 기능을 조정할 수 있게 한다.
<code>resources</code> 파라미터는 점수를 매길 때 고려할 리소스의 <code>name</code> 과
각 리소스의 가중치를 지정하는 <code>weight</code> 로 구성된다.</p><p>다음은 <code>requestedToCapacityRatio</code> 를 이용해
확장된 리소스 <code>intel.com/foo</code> 와 <code>intel.com/bar</code> 에 대한 빈 패킹 동작을
설정하는 구성의 예시이다.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>kubescheduler.config.k8s.io/v1beta3<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>KubeSchedulerConfiguration<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>profiles</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span>- <span style=color:green;font-weight:700>pluginConfig</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>args</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>scoringStrategy</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>resources</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>intel.com/foo<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>weight</span>:<span style=color:#bbb> </span><span style=color:#666>3</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>intel.com/bar<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>weight</span>:<span style=color:#bbb> </span><span style=color:#666>3</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>requestedToCapacityRatio</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>shape</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span>- <span style=color:green;font-weight:700>utilization</span>:<span style=color:#bbb> </span><span style=color:#666>0</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>            </span><span style=color:green;font-weight:700>score</span>:<span style=color:#bbb> </span><span style=color:#666>0</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span>- <span style=color:green;font-weight:700>utilization</span>:<span style=color:#bbb> </span><span style=color:#666>100</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>            </span><span style=color:green;font-weight:700>score</span>:<span style=color:#bbb> </span><span style=color:#666>10</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>type</span>:<span style=color:#bbb> </span>RequestedToCapacityRatio<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>NodeResourcesFit<span style=color:#bbb>
</span></span></span></code></pre></div><p>kube-scheduler 플래그 <code>--config=/path/to/config/file</code> 을 사용하여
<code>KubeSchedulerConfiguration</code> 파일을 참조하면 구성이 스케줄러에
전달된다.</p><p>기타 파라미터와 기본 구성에 대한 자세한 내용은
<a href=/docs/reference/config-api/kube-scheduler-config.v1beta3/#kubescheduler-config-k8s-io-v1beta3-NodeResourcesFitArgs><code>NodeResourcesFitArgs</code></a>에 대한 API 문서를 참조한다.</p><h3 id=점수-기능-튜닝하기>점수 기능 튜닝하기</h3><p><code>shape</code> 는 <code>RequestedToCapacityRatio</code> 기능의 동작을 지정하는 데 사용된다.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>shape</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb> </span>- <span style=color:green;font-weight:700>utilization</span>:<span style=color:#bbb> </span><span style=color:#666>0</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>   </span><span style=color:green;font-weight:700>score</span>:<span style=color:#bbb> </span><span style=color:#666>0</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb> </span>- <span style=color:green;font-weight:700>utilization</span>:<span style=color:#bbb> </span><span style=color:#666>100</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>   </span><span style=color:green;font-weight:700>score</span>:<span style=color:#bbb> </span><span style=color:#666>10</span><span style=color:#bbb>
</span></span></span></code></pre></div><p>위의 인수는 <code>utilization</code> 이 0%인 경우 <code>score</code> 는 0, <code>utilization</code> 이
100%인 경우 10으로 하여, 빈 패킹 동작을 활성화한다. 최소 요청을
활성화하려면 점수 값을 다음과 같이 변경해야 한다.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>shape</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>utilization</span>:<span style=color:#bbb> </span><span style=color:#666>0</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>score</span>:<span style=color:#bbb> </span><span style=color:#666>10</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>utilization</span>:<span style=color:#bbb> </span><span style=color:#666>100</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>score</span>:<span style=color:#bbb> </span><span style=color:#666>0</span><span style=color:#bbb>
</span></span></span></code></pre></div><p><code>resources</code> 는 기본적으로 다음과 같이 설정되는 선택적인 파라미터이다.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>resources</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>cpu<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>weight</span>:<span style=color:#bbb> </span><span style=color:#666>1</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>memory<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>weight</span>:<span style=color:#bbb> </span><span style=color:#666>1</span><span style=color:#bbb>
</span></span></span></code></pre></div><p>다음과 같이 확장된 리소스를 추가하는 데 사용할 수 있다.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>resources</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>intel.com/foo<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>weight</span>:<span style=color:#bbb> </span><span style=color:#666>5</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>cpu<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>weight</span>:<span style=color:#bbb> </span><span style=color:#666>3</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>memory<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>weight</span>:<span style=color:#bbb> </span><span style=color:#666>1</span><span style=color:#bbb>
</span></span></span></code></pre></div><p><code>weight</code> 파라미터는 선택 사항이며 지정되지 않은 경우 1로 설정 된다. 또한,
<code>weight</code> 는 음수로 설정할 수 없다.</p><h3 id=용량-할당을-위해-노드에-점수-매기기>용량 할당을 위해 노드에 점수 매기기</h3><p>이 섹션은 이 기능 내부의 세부적인 사항을 이해하려는 사람들을
위한 것이다.
아래는 주어진 값의 집합에 대해 노드 점수가 계산되는 방법의 예시이다.</p><p>요청된 리소스는 다음과 같다.</p><pre tabindex=0><code>intel.com/foo : 2
memory: 256MB
cpu: 2
</code></pre><p>리소스의 가중치는 다음과 같다.</p><pre tabindex=0><code>intel.com/foo : 5
memory: 1
cpu: 3
</code></pre><p>FunctionShapePoint {{0, 0}, {100, 10}}</p><p>노드 1의 사양은 다음과 같다.</p><pre tabindex=0><code>Available:
  intel.com/foo: 4
  memory: 1 GB
  cpu: 8

Used:
  intel.com/foo: 1
  memory: 256MB
  cpu: 1
</code></pre><p>노드 점수는 다음과 같다.</p><pre tabindex=0><code>intel.com/foo  = resourceScoringFunction((2+1),4)
               = (100 - ((4-3)*100/4)
               = (100 - 25)
               = 75                       # requested + used = 75% * available
               = rawScoringFunction(75) 
               = 7                        # floor(75/10) 

memory         = resourceScoringFunction((256+256),1024)
               = (100 -((1024-512)*100/1024))
               = 50                       # requested + used = 50% * available
               = rawScoringFunction(50)
               = 5                        # floor(50/10)

cpu            = resourceScoringFunction((2+1),8)
               = (100 -((8-3)*100/8))
               = 37.5                     # requested + used = 37.5% * available
               = rawScoringFunction(37.5)
               = 3                        # floor(37.5/10)

NodeScore   =  (7 * 5) + (5 * 1) + (3 * 3) / (5 + 1 + 3)
            =  5
</code></pre><p>노드 2의 사양은 다음과 같다.</p><pre tabindex=0><code>Available:
  intel.com/foo: 8
  memory: 1GB
  cpu: 8
Used:
  intel.com/foo: 2
  memory: 512MB
  cpu: 6
</code></pre><p>노드 점수는 다음과 같다.</p><pre tabindex=0><code>intel.com/foo  = resourceScoringFunction((2+2),8)
               =  (100 - ((8-4)*100/8)
               =  (100 - 50)
               =  50
               =  rawScoringFunction(50)
               = 5

Memory         = resourceScoringFunction((256+512),1024)
               = (100 -((1024-768)*100/1024))
               = 75
               = rawScoringFunction(75)
               = 7

cpu            = resourceScoringFunction((2+6),8)
               = (100 -((8-8)*100/8))
               = 100
               = rawScoringFunction(100)
               = 10

NodeScore   =  (5 * 5) + (7 * 1) + (10 * 3) / (5 + 1 + 3)
            =  7
</code></pre><h2 id=다음-내용>다음 내용</h2><ul><li><a href=/docs/concepts/scheduling-eviction/scheduling-framework/>스케줄링 프레임워크</a>에 대해 더 읽어본다.</li><li><a href=/ko/docs/reference/scheduling/config/>스케줄러 구성</a>에 대해 더 읽어본다.</li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-d9574a30fcbc631b0d2a57850e161e89>10 - 스케줄러 성능 튜닝</h1><div style=margin-top:10px;margin-bottom:10px><b>기능 상태:</b> <code>Kubernetes 1.14 [beta]</code></div><p><a href=/ko/docs/concepts/scheduling-eviction/kube-scheduler/#kube-scheduler>kube-scheduler</a>는
쿠버네티스의 기본 스케줄러이다. 그것은 클러스터의
노드에 파드를 배치하는 역할을 한다.</p><p>파드의 스케줄링 요건을 충족하는
클러스터의 노드를 파드에 <em>적합한(feasible)</em> 노드라고 한다. 스케줄러는
파드에 대해 적합한 노드를 찾고 기능 셋을 실행하여 해당 노드의 점수를
측정한다. 그리고 스케줄러는 파드를 실행하는데 적합한 모든 노드 중 가장
높은 점수를 가진 노드를 선택한다. 이후 스케줄러는 <em>바인딩</em> 이라는 프로세스로
API 서버에 해당 결정을 통지한다.</p><p>본 페이지에서는 상대적으로 큰 규모의 쿠버네티스 클러스터에 대한 성능 튜닝
최적화에 대해 설명한다.</p><p>큰 규모의 클러스터에서는 스케줄러의 동작을 튜닝하여 응답 시간
(새 파드가 빠르게 배치됨)과 정확도(스케줄러가 배치 결정을 잘 못하는 경우가 드물게 됨)
사이에서의 스케줄링 결과를 균형 잡을 수 있다.</p><p>kube-scheduler 의 <code>percentageOfNodesToScore</code> 설정을 통해
이 튜닝을 구성 한다. 이 KubeSchedulerConfiguration 설정에 따라 클러스터의
노드를 스케줄링할 수 있는 임계값이 결정된다.</p><h3 id=임계값-설정하기>임계값 설정하기</h3><p><code>percentageOfNodesToScore</code> 옵션은 0과 100 사이의 값을
허용한다. 값 0은 kube-scheduler가 컴파일 된 기본값을
사용한다는 것을 나타내는 특별한 숫자이다.
<code>percentageOfNodesToScore</code> 를 100 보다 높게 설정해도 kube-scheduler는
마치 100을 설정한 것처럼 작동한다.</p><p>값을 변경하려면,
<a href=/docs/reference/config-api/kube-scheduler-config.v1beta3/>kube-scheduler 구성 파일</a>을
편집한 다음 스케줄러를 재시작한다.
대부분의 경우, 구성 파일은 <code>/etc/kubernetes/config/kube-scheduler.yaml</code> 에서 찾을 수 있다.</p><p>이를 변경한 후에 다음을 실행해서</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>kubectl get pods -n kube-system | grep kube-scheduler
</span></span></code></pre></div><p>kube-scheduler 컴포넌트가 정상인지 확인할 수 있다.</p><h2 id=percentage-of-nodes-to-score>노드 스코어링(scoring) 임계값</h2><p>스케줄링 성능을 향상시키기 위해 kube-scheduler는 실행 가능한
노드가 충분히 발견되면 이를 찾는 것을 중단할 수 있다. 큰 규모의 클러스터에서는
모든 노드를 고려하는 고지식한 접근 방식에 비해 시간이 절약된다.</p><p>클러스터에 있는 모든 노드의 정수 백분율로 충분한 노두의 수에
대한 임계값을 지정한다. kube-scheduler는 이 값을 노드의
정수 값(숫자)로 변환 한다. 스케줄링 중에 kube-scheduler가 구성된
비율을 초과 할만큼 충분히 실행 가능한 노드를 식별한 경우, kube-scheduler는
더 실행 가능한 노드를 찾는 검색을 중지하고
<a href=/ko/docs/concepts/scheduling-eviction/kube-scheduler/#kube-scheduler-implementation>스코어링 단계</a>를 진행한다.</p><p><a href=#%EC%8A%A4%EC%BC%80%EC%A4%84%EB%9F%AC%EA%B0%80-%EB%85%B8%EB%93%9C-%ED%83%90%EC%83%89%EC%9D%84-%EB%B0%98%EB%B3%B5-iterate-%ED%95%98%EB%8A%94-%EB%B0%A9%EB%B2%95>스케줄러가 노드 탐색을 반복(iterate)하는 방법</a>
은 이 프로세스를 자세히 설명한다.</p><h3 id=기본-임계값>기본 임계값</h3><p>임계값을 지정하지 않으면 쿠버네티스는 100 노드 클러스터인
경우 50%, 5000 노드 클러스터인 경우 10%를 산출하는
선형 공식을 사용하여 수치를 계산한다. 자동 값의 하한선은 5% 이다.</p><p>즉, <code>percentageOfNodesToScore</code> 를 명시적으로 5보다 작게 설정하지
않은 경우 클러스터가 아무리 크더라도 kube-scheduler는
항상 클러스터의 최소 5%를 스코어링을 한다.</p><p>스케줄러가 클러스터의 모든 노드에 스코어링을 하려면
<code>percentageOfNodesToScore</code> 를 100으로 설정 한다.</p><h2 id=예시>예시</h2><p>아래는 <code>percentageOfNodesToScore</code>를 50%로 설정하는 구성 예시이다.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>kubescheduler.config.k8s.io/v1alpha1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>KubeSchedulerConfiguration<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>algorithmSource</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>provider</span>:<span style=color:#bbb> </span>DefaultProvider<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:#00f;font-weight:700>...</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>percentageOfNodesToScore</span>:<span style=color:#bbb> </span><span style=color:#666>50</span><span style=color:#bbb>
</span></span></span></code></pre></div><h3 id=percentageofnodestoscore-튜닝>percentageOfNodesToScore 튜닝</h3><p><code>percentageOfNodesToScore</code>는 1과 100 사이의 값이어야 하며
기본값은 클러스터 크기에 따라 계산된다. 또한 50 노드로 하드 코딩된
최솟값도 있다.</p><div class="alert alert-info note callout" role=alert><strong>참고:</strong><p>클러스터에서 적합한 노드가 50 미만인 경우, 스케줄러는 여전히
모든 노드를 확인한다. 그 이유는 스케줄러가 탐색을 조기 중단하기에는 적합한
노드의 수가 충분하지 않기 때문이다.</p><p>규모가 작은 클러스터에서는 <code>percentageOfNodesToScore</code> 에 낮은 값을 설정하면,
비슷한 이유로 변경 사항이 거의 또는 전혀 영향을 미치지 않게 된다.</p><p>클러스터에 수백 개 이하의 노드가 있는 경우 이 구성 옵션을
기본값으로 둔다. 이는 변경사항을 적용하더라도 스케줄러의
성능이 크게 향상되지 않는다.</p></div><p>이 값을 세팅할 때 중요하고 자세한 사항은, 클러스터에서
적은 수의 노드에 대해서만 적합성을 확인하면, 주어진 파드에 대해서
일부 노드의 점수는 측정이되지 않는다는 것이다. 결과적으로, 주어진 파드를 실행하는데
가장 높은 점수를 가질 가능성이 있는 노드가 점수 측정 단계로 조차 넘어가지
않을 수 있다. 이것은 파드의 이상적인 배치보다 낮은 결과를 초래할 것이다.</p><p><code>percentageOfNodesToScore</code> 를 매우 낮게 설정해서 kube-scheduler가
파드 배치 결정을 잘못 내리지 않도록 해야 한다. 스케줄러의 처리량에
대해 애플리케이션이 중요하고 노드 점수가 중요하지 않은 경우가 아니라면
백분율을 10% 미만으로 설정하지 말아야 한다. 즉, 가능한 한
모든 노드에서 파드를 실행하는 것이 좋다.</p><h2 id=스케줄러가-노드-탐색을-반복-iterate-하는-방법>스케줄러가 노드 탐색을 반복(iterate)하는 방법</h2><p>이 섹션은 이 특징의 상세한 내부 방식을 이해하고 싶은 사람들을
위해 작성되었다.</p><p>클러스터의 모든 노드가 파드 실행 대상으로 고려되어 공정한 기회를
가지도록, 스케줄러는 라운드 로빈(round robin) 방식으로 모든 노드에 대해서 탐색을
반복한다. 모든 노드가 배열에 나열되어 있다고 생각해보자. 스케줄러는 배열의
시작부터 시작하여 <code>percentageOfNodesToScore</code>에 명시된 충분한 수의 노드를
찾을 때까지 적합성을 확인한다. 그 다음 파드에 대해서는, 스케줄러가
이전 파드를 위한 노드 적합성 확인이 마무리된 지점인 노드 배열의 마지막
포인트부터 확인을 재개한다.</p><p>만약 노드들이 다중의 영역(zone)에 있다면, 다른 영역에 있는 노드들이 적합성
확인의 대상이 되도록 스케줄러는 다양한 영역에 있는 노드에 대해서
탐색을 반복한다. 예제로, 2개의 영역에 있는 6개의 노드를 생각해보자.</p><pre tabindex=0><code>영역 1: 노드 1, 노드 2, 노드 3, 노드 4
영역 2: 노드 5, 노드 6
</code></pre><p>스케줄러는 노드의 적합성 평가를 다음의 순서로 실행한다.</p><pre tabindex=0><code>노드 1, 노드 5, 노드 2, 노드 6, 노드 3, 노드 4
</code></pre><p>모든 노드를 검토한 후, 노드 1로 돌아간다.</p><h2 id=다음-내용>다음 내용</h2><ul><li><a href=/docs/reference/config-api/kube-scheduler-config.v1beta3/>kube-scheduler 구성 레퍼런스(v1beta3)</a> 확인</li></ul></div></main></div></div><footer class=d-print-none><div class=footer__links><nav><a class=text-white href=/ko/docs/home/>홈</a>
<a class=text-white href=/ko/blog/>블로그</a>
<a class=text-white href=/ko/training/>교육</a>
<a class=text-white href=/ko/partners/>파트너</a>
<a class=text-white href=/ko/community/>Community</a>
<a class=text-white href=/ko/case-studies/>사례 연구</a></nav></div><div class=container-fluid><div class=row><div class="col-6 col-sm-2 text-xs-center order-sm-2"><ul class="list-inline mb-0"><li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title="User mailing list" aria-label="User mailing list"><a class=text-white target=_blank href=https://discuss.kubernetes.io><i class="fa fa-envelope"></i></a></li><li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title=Twitter aria-label=Twitter><a class=text-white target=_blank href=https://twitter.com/kubernetesio><i class="fab fa-twitter"></i></a></li><li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title=Calendar aria-label=Calendar><a class=text-white target=_blank href="https://calendar.google.com/calendar/embed?src=calendar%40kubernetes.io"><i class="fas fa-calendar-alt"></i></a></li><li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title=Youtube aria-label=Youtube><a class=text-white target=_blank href=https://youtube.com/kubernetescommunity><i class="fab fa-youtube"></i></a></li></ul></div><div class="col-6 col-sm-2 text-right text-xs-center order-sm-3"><ul class="list-inline mb-0"><li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title=GitHub aria-label=GitHub><a class=text-white target=_blank href=https://github.com/kubernetes/kubernetes><i class="fab fa-github"></i></a></li><li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title=Slack aria-label=Slack><a class=text-white target=_blank href=https://slack.k8s.io><i class="fab fa-slack"></i></a></li><li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title=Contribute aria-label=Contribute><a class=text-white target=_blank href=https://git.k8s.io/community/contributors/guide><i class="fas fa-edit"></i></a></li><li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title="Stack Overflow" aria-label="Stack Overflow"><a class=text-white target=_blank href=https://stackoverflow.com/questions/tagged/kubernetes><i class="fab fa-stack-overflow"></i></a></li></ul></div><div class="col-12 col-sm-8 text-center order-sm-2"><small class=text-white>&copy; 2023 The Kubernetes Authors | Documentation Distributed under <a href=https://git.k8s.io/website/LICENSE class=light-text>CC BY 4.0</a></small><br><small class=text-white>Copyright &copy; 2023 The Linux Foundation &reg;. All rights reserved. The Linux Foundation has registered trademarks and uses trademarks. For a list of trademarks of The Linux Foundation, please see our <a href=https://www.linuxfoundation.org/trademark-usage class=light-text>Trademark Usage page</a></small><br><small class=text-white>ICP license: 京ICP备17074266号-3</small></div></div></div></footer></div><script src=/js/jquery-3.6.0.min.js integrity=sha384-vtXRMe3mGCbOeY7l30aIg8H9p3GdeSe4IFlP6G8JMa7o7lXvnz3GFKzPxzJdPfGK crossorigin=anonymous></script>
<script src=/js/popper-1.16.1.min.js intregrity=sha384-9/reFTGAW83EW2RDu2S0VKaIzap3H66lZH81PoYlFhbGU+6BZp6G7niu735Sk7lN crossorigin=anonymous></script>
<script src=/js/bootstrap-4.6.1.min.js integrity=sha384-VHvPCCyXqtD5DqJeNxl2dtTyhF78xXNXdkwX1CZeRusQfRKp+tA7hAShOK/B/fQ2 crossorigin=anonymous></script>
<script src=/js/script.js></script>
<script async src=/js/mermaid-8.13.4.min.js integrity=sha384-5hHNvPeMrNH14oM3IcQofDoBhiclNK3g2+hnEinKzQ07C4AliMeVpnvxuiwEGpaO crossorigin=anonymous></script>
<script src=/js/main.min.5c0bf7f21dc4f66485f74efbbeeff28a7e4f8cddaac1bae47043159c922ff3a3.js integrity="sha256-XAv38h3E9mSF9077vu/yin5PjN2qwbrkcEMVnJIv86M=" crossorigin=anonymous></script></body></html>