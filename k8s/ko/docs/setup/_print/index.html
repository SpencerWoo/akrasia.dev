<!doctype html><html lang=ko class=no-js><head><meta name=robots content="noindex, nofollow"><link rel=alternate hreflang=en href=https://kubernetes.io/docs/setup/><link rel=alternate hreflang=zh-cn href=https://kubernetes.io/zh-cn/docs/setup/><link rel=alternate hreflang=ja href=https://kubernetes.io/ja/docs/setup/><link rel=alternate hreflang=fr href=https://kubernetes.io/fr/docs/setup/><link rel=alternate hreflang=de href=https://kubernetes.io/de/docs/setup/><link rel=alternate hreflang=es href=https://kubernetes.io/es/docs/setup/><link rel=alternate hreflang=pt-br href=https://kubernetes.io/pt-br/docs/setup/><link rel=alternate hreflang=id href=https://kubernetes.io/id/docs/setup/><link rel=alternate hreflang=hi href=https://kubernetes.io/hi/docs/setup/><link rel=alternate hreflang=ru href=https://kubernetes.io/ru/docs/setup/><link rel=alternate hreflang=pl href=https://kubernetes.io/pl/docs/setup/><link rel=alternate hreflang=uk href=https://kubernetes.io/uk/docs/setup/><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=generator content="Hugo 0.110.0"><link rel=canonical type=text/html href=https://kubernetes.io/ko/docs/setup/><link rel="shortcut icon" type=image/png href=/images/favicon.png><link rel=apple-touch-icon href=/favicons/apple-touch-icon-180x180.png sizes=180x180><link rel=manifest href=/manifest.webmanifest><link rel=apple-touch-icon href=/images/kubernetes-192x192.png><title>시작하기 | Kubernetes</title><meta property="og:title" content="시작하기"><meta property="og:description" content="운영 수준의 컨테이너 오케스트레이션"><meta property="og:type" content="website"><meta property="og:url" content="https://kubernetes.io/ko/docs/setup/"><meta property="og:site_name" content="Kubernetes"><meta itemprop=name content="시작하기"><meta itemprop=description content="운영 수준의 컨테이너 오케스트레이션"><meta name=twitter:card content="summary"><meta name=twitter:title content="시작하기"><meta name=twitter:description content="운영 수준의 컨테이너 오케스트레이션"><link href=/scss/main.css rel=stylesheet><script type=application/ld+json>{"@context":"https://schema.org","@type":"Organization","url":"https://kubernetes.io","logo":"https://kubernetes.io/images/favicon.png","potentialAction":{"@type":"SearchAction","target":"https://kubernetes.io/search/?q={search_term_string}","query-input":"required name=search_term_string"}}</script><meta name=theme-color content="#326ce5"><link rel=stylesheet href=/css/feature-states.css><meta name=description content="본 섹션에는 쿠버네티스를 설정하고 실행하는 다양한 방법이 나열되어 있다. 쿠버네티스를 설치할 때는 유지보수의 용이성, 보안, 제어, 사용 가능한 리소스, 그리고 클러스터를 운영하고 관리하기 위해 필요한 전문성을 기반으로 설치 유형을 선택한다.
쿠버네티스를 다운로드하여 로컬 머신에, 클라우드에, 데이터센터에 쿠버네티스 클러스터를 구축할 수 있다.
kube-apiserver나 kube-proxy와 같은 몇몇 쿠버네티스 컴포넌트들은 클러스터 내에서 컨테이너 이미지를 통해 배포할 수 있다.
쿠버네티스 컴포넌트들은 가급적 컨테이너 이미지로 실행하는 것을 추천하며, 이를 통해 쿠버네티스가 해당 컴포넌트들을 관리하도록 한다."><meta property="og:description" content="본 섹션에는 쿠버네티스를 설정하고 실행하는 다양한 방법이 나열되어 있다. 쿠버네티스를 설치할 때는 유지보수의 용이성, 보안, 제어, 사용 가능한 리소스, 그리고 클러스터를 운영하고 관리하기 위해 필요한 전문성을 기반으로 설치 유형을 선택한다.
쿠버네티스를 다운로드하여 로컬 머신에, 클라우드에, 데이터센터에 쿠버네티스 클러스터를 구축할 수 있다.
kube-apiserver나 kube-proxy와 같은 몇몇 쿠버네티스 컴포넌트들은 클러스터 내에서 컨테이너 이미지를 통해 배포할 수 있다.
쿠버네티스 컴포넌트들은 가급적 컨테이너 이미지로 실행하는 것을 추천하며, 이를 통해 쿠버네티스가 해당 컴포넌트들을 관리하도록 한다."><meta name=twitter:description content="본 섹션에는 쿠버네티스를 설정하고 실행하는 다양한 방법이 나열되어 있다. 쿠버네티스를 설치할 때는 유지보수의 용이성, 보안, 제어, 사용 가능한 리소스, 그리고 클러스터를 운영하고 관리하기 위해 필요한 전문성을 기반으로 설치 유형을 선택한다.
쿠버네티스를 다운로드하여 로컬 머신에, 클라우드에, 데이터센터에 쿠버네티스 클러스터를 구축할 수 있다.
kube-apiserver나 kube-proxy와 같은 몇몇 쿠버네티스 컴포넌트들은 클러스터 내에서 컨테이너 이미지를 통해 배포할 수 있다.
쿠버네티스 컴포넌트들은 가급적 컨테이너 이미지로 실행하는 것을 추천하며, 이를 통해 쿠버네티스가 해당 컴포넌트들을 관리하도록 한다."><meta property="og:url" content="https://kubernetes.io/ko/docs/setup/"><meta property="og:title" content="시작하기"><meta name=twitter:title content="시작하기"><meta name=twitter:image content="https://kubernetes.io/images/favicon.png"><meta name=twitter:image:alt content="Kubernetes"><meta property="og:image" content="/images/kubernetes-horizontal-color.png"><meta property="og:type" content="article"><script src=/js/jquery-3.6.0.min.js intregrity=sha384-vtXRMe3mGCbOeY7l30aIg8H9p3GdeSe4IFlP6G8JMa7o7lXvnz3GFKzPxzJdPfGK crossorigin=anonymous></script></head><body class=td-section><header><nav class="js-navbar-scroll navbar navbar-expand navbar-dark flex-column flex-md-row td-navbar" data-auto-burger=primary><a class=navbar-brand href=/ko/></a><div class="td-navbar-nav-scroll ml-md-auto" id=main_navbar><ul class="navbar-nav mt-2 mt-lg-0"><li class="nav-item mr-2 mb-lg-0"><a class="nav-link active" href=/ko/docs/>문서</a></li><li class="nav-item mr-2 mb-lg-0"><a class=nav-link href=/ko/blog/>쿠버네티스 블로그</a></li><li class="nav-item mr-2 mb-lg-0"><a class=nav-link href=/ko/training/>교육</a></li><li class="nav-item mr-2 mb-lg-0"><a class=nav-link href=/ko/partners/>파트너</a></li><li class="nav-item mr-2 mb-lg-0"><a class=nav-link href=/ko/community/>Community</a></li><li class="nav-item mr-2 mb-lg-0"><a class=nav-link href=/ko/case-studies/>사례 연구</a></li><li class="nav-item dropdown"><a class="nav-link dropdown-toggle" href=# id=navbarDropdown role=button data-toggle=dropdown aria-haspopup=true aria-expanded=false>버전</a><div class="dropdown-menu dropdown-menu-right" aria-labelledby=navbarDropdownMenuLink><a class=dropdown-item href=/ko/releases>Release Information</a>
<a class=dropdown-item href=https://kubernetes.io/ko/docs/setup/>v1.25</a>
<a class=dropdown-item href=https://v1-24.docs.kubernetes.io/ko/docs/setup/>v1.24</a>
<a class=dropdown-item href=https://v1-23.docs.kubernetes.io/ko/docs/setup/>v1.23</a>
<a class=dropdown-item href=https://v1-22.docs.kubernetes.io/ko/docs/setup/>v1.22</a>
<a class=dropdown-item href=https://v1-21.docs.kubernetes.io/ko/docs/setup/>v1.21</a></div></li><li class="nav-item dropdown"><a class="nav-link dropdown-toggle" href=# id=navbarDropdownMenuLink role=button data-toggle=dropdown aria-haspopup=true aria-expanded=false>한국어 (Korean)</a><div class="dropdown-menu dropdown-menu-right" aria-labelledby=navbarDropdownMenuLink><a class=dropdown-item href=/docs/setup/>English</a>
<a class=dropdown-item href=/zh-cn/docs/setup/>中文 (Chinese)</a>
<a class=dropdown-item href=/ja/docs/setup/>日本語 (Japanese)</a>
<a class=dropdown-item href=/fr/docs/setup/>Français (French)</a>
<a class=dropdown-item href=/de/docs/setup/>Deutsch (German)</a>
<a class=dropdown-item href=/es/docs/setup/>Español (Spanish)</a>
<a class=dropdown-item href=/pt-br/docs/setup/>Português (Portuguese)</a>
<a class=dropdown-item href=/id/docs/setup/>Bahasa Indonesia</a>
<a class=dropdown-item href=/hi/docs/setup/>हिन्दी (Hindi)</a>
<a class=dropdown-item href=/ru/docs/setup/>Русский (Russian)</a>
<a class=dropdown-item href=/pl/docs/setup/>Polski (Polish)</a>
<a class=dropdown-item href=/uk/docs/setup/>Українська (Ukrainian)</a></div></li></ul></div><button id=hamburger onclick=kub.toggleMenu() data-auto-burger-exclude><div></div></button></nav></header><div class="container-fluid td-outer"><div class=td-main><div class="row flex-xl-nowrap"><main class="col-12 col-md-9 col-xl-8 pl-md-5" role=main><div class=td-content><div class="pageinfo pageinfo-primary d-print-none"><p>이 섹션의 다중 페이지 출력 화면임.
<a href=# onclick="return print(),!1">여기를 클릭하여 프린트</a>.</p><p><a href=/ko/docs/setup/>이 페이지의 일반 화면으로 돌아가기</a>.</p></div><h1 class=title>시작하기</h1><ul><li>1: <a href=#pg-0b597086a9d1382f86abadcfeab657d6>학습 환경</a></li><ul></ul><li>2: <a href=#pg-4e14853fdaa3bd273f31a60112b9b5ac>프로덕션 환경</a></li><ul><li>2.1: <a href=#pg-a77d3feb6e6d9978f32fa14622642e9a>컨테이너 런타임</a></li><li>2.2: <a href=#pg-00e1646f68aeb89f9722cf6f6cfcad94>배포 도구로 쿠버네티스 설치하기</a></li><ul><li>2.2.1: <a href=#pg-a16f59f325a17cdeed324d5c889f7f73>kubeadm으로 클러스터 구성하기</a></li><ul><li>2.2.1.1: <a href=#pg-29e59491dd6118b23072dfe9ebb93323>kubeadm 설치하기</a></li><li>2.2.1.2: <a href=#pg-4c656c5eda3e1c06ad1aedebdc04a211>kubeadm API로 컴포넌트 사용자 정의하기</a></li><li>2.2.1.3: <a href=#pg-015edbc7cc688d31b1d1edce7c186135>고가용성 토폴로지 선택</a></li></ul><li>2.2.2: <a href=#pg-478acca1934b6d89a0bc00fb25bfe5b6>Kops로 쿠버네티스 설치하기</a></li><li>2.2.3: <a href=#pg-f8b4964187fe973644e06ee629eff1de>Kubespray로 쿠버네티스 설치하기</a></li></ul><li>2.3: <a href=#pg-d2f55eefe7222b7c637875af9c3ec199>턴키 클라우드 솔루션</a></li></ul><li>3: <a href=#pg-84b6491601d6a2b3da4cd5a105c866ba>모범 사례</a></li><ul><li>3.1: <a href=#pg-c797ee17120176c685455db89ae091a9>대형 클러스터에 대한 고려 사항</a></li><li>3.2: <a href=#pg-970615c97499e3651fd3a98e0387cefc>여러 영역에서 실행</a></li><li>3.3: <a href=#pg-f89867de1d34943f1524f67a241f5cc9>노드 구성 검증하기</a></li><li>3.4: <a href=#pg-0394f813094b7a35058dffe5b8bacd20>PKI 인증서 및 요구 사항</a></li><li>3.5: <a href=#pg-92a61cf5b0575aa3500f7665b68127d1>파드 시큐리티 스탠다드 강제하기</a></li></ul></ul><div class=content><p>본 섹션에는 쿠버네티스를 설정하고 실행하는 다양한 방법이 나열되어 있다.
쿠버네티스를 설치할 때는 유지보수의 용이성, 보안, 제어, 사용 가능한 리소스, 그리고
클러스터를 운영하고 관리하기 위해 필요한 전문성을 기반으로 설치 유형을 선택한다.</p><p><a href=/releases/download/>쿠버네티스를 다운로드</a>하여
로컬 머신에, 클라우드에, 데이터센터에 쿠버네티스 클러스터를 구축할 수 있다.</p><p><code>kube-apiserver</code>나 <code>kube-proxy</code>와 같은 몇몇 <a href=/releases/download/>쿠버네티스 컴포넌트</a>들은
클러스터 내에서 <a href=/releases/download/#container-images>컨테이너 이미지</a>를 통해 배포할 수 있다.</p><p>쿠버네티스 컴포넌트들은 가급적 컨테이너 이미지로 실행하는 것을 <strong>추천</strong>하며,
이를 통해 쿠버네티스가 해당 컴포넌트들을 관리하도록 한다.
컨테이너를 구동하는 컴포넌트(특히 kubelet)는 여기에 속하지 않는다.</p><p>쿠버네티스 클러스터를 직접 관리하고 싶지 않다면, <a href=/ko/docs/setup/production-environment/turnkey-solutions/>인증된 플랫폼</a>과
같은 매니지드 서비스를 선택할 수도 있다.
광범위한 클라우드 또는 베어 메탈 환경에 걸쳐 사용할 수 있는
표준화된/맞춤형 솔루션도 있다.</p><h2 id=학습-환경>학습 환경</h2><p>쿠버네티스를 배우고 있다면, 쿠버네티스 커뮤니티에서 지원하는 도구나,
로컬 머신에서 쿠버네티스를 설치하기 위한 생태계 내의 도구를 사용한다.
<a href=/ko/docs/tasks/tools/>도구 설치</a>를 살펴본다.</p><h2 id=프로덕션-환경>프로덕션 환경</h2><p><a href=/ko/docs/setup/production-environment/>프로덕션 환경</a>을 위한
솔루션을 평가할 때에는, 쿠버네티스 클러스터(또는 <em>추상화된 객체</em>)
운영에 대한 어떤 측면을 스스로 관리하기를 원하는지,
또는 제공자에게 넘기기를 원하는지 고려한다.</p><p>클러스터를 직접 관리하는 경우, 공식적으로 지원되는 쿠버네티스 구축 도구는
<a href=/ko/docs/setup/production-environment/tools/kubeadm/>kubeadm</a>이다.</p><h2 id=다음-내용>다음 내용</h2><ul><li><a href=/releases/download/>쿠버네티스를 다운로드</a>한다.</li><li><code>kubectl</code>을 포함한 <a href=/ko/docs/tasks/tools/>도구를 설치</a>한다.</li><li>새로운 클러스터에 사용할 <a href=/ko/docs/setup/production-environment/container-runtimes/>컨테이너 런타임</a>을 선택한다.</li><li>클러스터 구성의 <a href=/ko/docs/setup/best-practices/>모범 사례</a>를 확인한다.</li></ul><p>쿠버네티스의 <a class=glossary-tooltip title='컨테이너의 라이프사이클을 정의, 배포, 관리하기 위한 API와 인터페이스들을 노출하는 컨테이너 오케스트레이션 레이어.' data-toggle=tooltip data-placement=top href='/ko/docs/reference/glossary/?all=true#term-control-plane' target=_blank aria-label='컨트롤 플레인'>컨트롤 플레인</a>은
리눅스에서 실행되도록 설계되었다. 클러스터 내에서는 리눅스 또는
다른 운영 체제(예: 윈도우)에서 애플리케이션을 실행할 수 있다.</p><ul><li><a href=/ko/docs/concepts/windows/>윈도우 노드를 포함하는 클러스터 구성하기</a>를 살펴본다.</li></ul></div></div><div class=td-content style=page-break-before:always><h1 id=pg-0b597086a9d1382f86abadcfeab657d6>1 - 학습 환경</h1></div><div class=td-content style=page-break-before:always><h1 id=pg-4e14853fdaa3bd273f31a60112b9b5ac>2 - 프로덕션 환경</h1><div class=lead>프로덕션 수준의 쿠버네티스 클러스터 생성</div><p>프로덕션 수준의 쿠버네티스 클러스터에는 계획과 준비가 필요하다.
쿠버네티스 클러스터에 중요한 워크로드를 실행하려면 클러스터를 탄력적이도록 구성해야 한다.
이 페이지에서는 프로덕션용 클러스터를 설정하거나 기존 클러스터를 프로덕션용으로 업그레이드하기 위해
수행할 수 있는 단계를 설명한다.
이미 프로덕션 구성 내용에 익숙하여 단지 링크를 찾고 있다면,
<a href=#%EB%8B%A4%EC%9D%8C-%EB%82%B4%EC%9A%A9>다음 내용</a>을 참고한다.</p><h2 id=프로덕션-고려-사항>프로덕션 고려 사항</h2><p>일반적으로 프로덕션 쿠버네티스 클러스터 환경에는
개인 학습용, 개발용 또는 테스트 환경용 클러스터보다 더 많은 요구 사항이 있다.
프로덕션 환경에는 많은 사용자의 보안 액세스, 일관된 가용성 및
변화하는 요구를 충족하기 위한 리소스가 필요할 수 있다.</p><p>프로덕션 쿠버네티스 환경이 상주할 위치(온 프레미스 또는 클라우드)와
직접 처리하거나 다른 사람에게 맡길 관리의 양을 결정할 때,
쿠버네티스 클러스터에 대한 요구 사항이
다음 이슈에 의해 어떻게 영향을 받는지 고려해야 한다.</p><ul><li><p><em>가용성</em>: 단일 머신 쿠버네티스 <a href=/ko/docs/setup/#%ED%95%99%EC%8A%B5-%ED%99%98%EA%B2%BD>학습 환경</a>은 SPOF(Single Point of Failure, 단일 장애 지점) 이슈를 갖고 있다.
고가용성 클러스터를 만드는 것에는 다음과 같은 고려 사항이 있다.</p><ul><li>컨트롤 플레인과 워크 노드를 분리</li><li>컨트롤 플레인 구성요소를 여러 노드에 복제</li><li>클러스터의 <a class=glossary-tooltip title='쿠버네티스 API를 제공하는 컨트롤 플레인 컴포넌트.' data-toggle=tooltip data-placement=top href=/ko/docs/concepts/overview/components/#kube-apiserver target=_blank aria-label='API 서버'>API 서버</a>로 가는 트래픽을 로드밸런싱</li><li>워커 노드를 충분히 운영하거나, 워크로드 변경에 따라 빠르게 제공할 수 있도록 보장</li></ul></li><li><p><em>스케일링</em>: 프로덕션 쿠버네티스 환경에 들어오는 요청의 양의
일정할 것으로 예상된다면, 필요한 만큼의 용량(capacity)을 증설하고
마무리할 수도 있다. 하지만, 요청의 양이 시간에 따라 점점 증가하거나
계절, 이벤트 등에 의해 극적으로 변동할 것으로 예상된다면,
컨트롤 플레인과 워커 노드로의 요청 증가로 인한 압박을 해소하기 위해 스케일 업 하거나
잉여 자원을 줄이기 위해 스케일 다운 하는 것에 대해 고려해야 한다.</p></li><li><p><em>보안 및 접근 관리</em>: 학습을 위한 쿠버네티스 클러스터에는
완전한 관리 권한을 가질 수 있다. 하지만 중요한 워크로드를 실행하며
두 명 이상의 사용자가 있는 공유 클러스터에는 누가, 그리고 무엇이 클러스터 자원에
접근할 수 있는지에 대해서 보다 정교한 접근 방식이 필요하다.
역할 기반 접근 제어(<a href=/docs/reference/access-authn-authz/rbac/>RBAC</a>) 및
기타 보안 메커니즘을 사용하여, 사용자와 워크로드가 필요한 자원에
액세스할 수 있게 하면서도 워크로드와 클러스터를 안전하게 유지할 수 있다.
<a href=/ko/docs/concepts/policy/>정책</a>과
<a href=/ko/docs/concepts/configuration/manage-resources-containers/>컨테이너 리소스</a>를
관리하여, 사용자 및 워크로드가 접근할 수 있는 자원에 대한 제한을 설정할 수 있다.</p></li></ul><p>쿠버네티스 프로덕션 환경을 직접 구축하기 전에, 이 작업의 일부 또는 전체를
<a href=/ko/docs/setup/production-environment/turnkey-solutions/>턴키 클라우드 솔루션</a>
제공 업체 또는 기타 <a href=/ko/partners/>쿠버네티스 파트너</a>에게
넘기는 것을 고려할 수 있다.
다음과 같은 옵션이 있다.</p><ul><li><em>서버리스</em>: 클러스터를 전혀 관리하지 않고
타사 장비에서 워크로드를 실행하기만 하면 된다.
CPU 사용량, 메모리 및 디스크 요청과 같은 항목에 대한 요금이 부과된다.</li><li><em>관리형 컨트롤 플레인</em>: 쿠버네티스 서비스 공급자가
클러스터 컨트롤 플레인의 확장 및 가용성을 관리하고 패치 및 업그레이드를 처리하도록 한다.</li><li><em>관리형 워커 노드</em>: 필요에 맞는 노드 풀을 정의하면,
쿠버네티스 서비스 공급자는 해당 노드의 가용성 및
필요 시 업그레이드 제공을 보장한다.</li><li><em>통합</em>: 쿠버네티스를 스토리지, 컨테이너 레지스트리,
인증 방법 및 개발 도구와 같이
사용자가 필요로 하는 여러 서비스를 통합 제공하는 업체도 있다.</li></ul><p>프로덕션 쿠버네티스 클러스터를 직접 구축하든 파트너와 협력하든,
요구 사항이 <em>컨트롤 플레인</em>, <em>워커 노드</em>,
<em>사용자 접근</em>, <em>워크로드 자원</em>과 관련되기 때문에,
다음 섹션들을 검토하는 것이 바람직하다.</p><h2 id=프로덕션-클러스터-구성>프로덕션 클러스터 구성</h2><p>프로덕션 수준 쿠버네티스 클러스터에서,
컨트롤 플레인은 다양한 방식으로 여러 컴퓨터에 분산될 수 있는 서비스들을 통해
클러스터를 관리한다.
반면, 각 워커 노드는 쿠버네티스 파드를 실행하도록 구성된 단일 엔티티를 나타낸다.</p><h3 id=프로덕션-컨트롤-플레인>프로덕션 컨트롤 플레인</h3><p>가장 간단한 쿠버네티스 클러스터는 모든 컨트롤 플레인 및 워커 노드 서비스가
하나의 머신에 실행되는 클러스터이다.
<a href=/ko/docs/concepts/overview/components/>쿠버네티스 컴포넌트</a>
그림에 명시된 대로, 워커 노드를 추가하여 해당 환경을 확장할 수 있다.
클러스터를 단기간만 사용하거나,
심각한 문제가 발생한 경우 폐기하는 것이 가능하다면, 이 방식을 선택할 수 있다.</p><p>그러나 더 영구적이고 가용성이 높은 클러스터가 필요한 경우
컨트롤 플레인 확장을 고려해야 한다.
설계 상, 단일 시스템에서 실행되는 단일 시스템 컨트롤 플레인 서비스는
가용성이 높지 않다.
클러스터를 계속 유지하면서 문제가 발생한 경우 복구할 수 있는지 여부가 중요한 경우,
다음 사항들을 고려한다.</p><ul><li><em>배포 도구 선택</em>: kubeadm, kops, kubespray와 같은 도구를 이용해
컨트롤 플레인을 배포할 수 있다.
<a href=/ko/docs/setup/production-environment/tools/>배포 도구로 쿠버네티스 설치하기</a>에서
여러 배포 도구를 이용한 프로덕션 수준 배포에 대한 팁을 확인한다.
배포 시, 다양한
<a href=/ko/docs/setup/production-environment/container-runtimes/>컨테이너 런타임</a>을 사용할 수 있다.</li><li><em>인증서 관리</em>: 컨트롤 플레인 서비스 간의 보안 통신은 인증서를 사용하여 구현된다.
인증서는 배포 중에 자동으로 생성되거나, 또는 자체 인증 기관을 사용하여 생성할 수 있다.
<a href=/ko/docs/setup/best-practices/certificates/>PKI 인증서 및 요구 조건</a>에서
상세 사항을 확인한다.</li><li><em>apiserver를 위한 로드밸런서 구성</em>: 여러 노드에서 실행되는 apiserver 서비스 인스턴스에
외부 API 호출을 분산할 수 있도록 로드밸런서를 구성한다.
<a href=/ko/docs/tasks/access-application-cluster/create-external-load-balancer/>외부 로드밸런서 생성하기</a>에서
상세 사항을 확인한다.</li><li><em>etcd 서비스 분리 및 백업</em>: etcd 서비스는
다른 컨트롤 플레인 서비스와 동일한 시스템에서 실행되거나,
또는 추가 보안 및 가용성을 위해 별도의 시스템에서 실행될 수 있다.
etcd는 클러스터 구성 데이터를 저장하므로
필요한 경우 해당 데이터베이스를 복구할 수 있도록 etcd 데이터베이스를 정기적으로 백업해야 한다.
<a href=https://etcd.io/docs/v3.4/faq/>etcd FAQ</a>에서 etcd 구성 및 사용 상세를 확인한다.
<a href=/docs/tasks/administer-cluster/configure-upgrade-etcd/>쿠버네티스를 위한 etcd 클러스터 운영하기</a>와
<a href=/docs/setup/production-environment/tools/kubeadm/setup-ha-etcd-with-kubeadm/>kubeadm을 이용하여 고가용성 etcd 생성하기</a>에서
상세 사항을 확인한다.</li><li><em>다중 컨트롤 플레인 시스템 구성</em>: 고가용성을 위해,
컨트롤 플레인은 단일 머신으로 제한되지 않아야 한다.
컨트롤 플레인 서비스가 init 서비스(예: systemd)에 의해 실행되는 경우,
각 서비스는 최소 3대의 머신에서 실행되어야 한다.
그러나, 컨트롤 플레인 서비스를 쿠버네티스 상의 파드 형태로 실행하면
각 서비스 복제본 요청이 보장된다.
스케줄러는 내결함성이 있어야 하고, 고가용성은 필요하지 않다.
일부 배포 도구는 쿠버네티스 서비스의 리더 선출을 수행하기 위해
<a href=https://raft.github.io/>Raft</a> 합의 알고리즘을 설정한다.
리더를 맡은 서비스가 사라지면 다른 서비스가 스스로 리더가 되어 인계를 받는다.</li><li><em>다중 영역(zone)으로 확장</em>: 클러스터를 항상 사용 가능한 상태로 유지하는 것이 중요하다면
여러 데이터 센터(클라우드 환경에서는 '영역'이라고 함)에서 실행되는
클러스터를 만드는 것이 좋다.
영역의 그룹을 지역(region)이라고 한다.
동일한 지역의 여러 영역에 클러스터를 분산하면
하나의 영역을 사용할 수 없게 된 경우에도 클러스터가 계속 작동할 가능성을 높일 수 있다.
<a href=/ko/docs/setup/best-practices/multiple-zones/>여러 영역에서 실행</a>에서 상세 사항을 확인한다.</li><li><em>구동 중인 기능 관리</em>: 클러스터를 계속 유지하려면,
상태 및 보안을 유지하기 위해 수행해야 하는 작업이 있다.
예를 들어 kubeadm으로 클러스터를 생성한 경우,
<a href=/ko/docs/tasks/administer-cluster/kubeadm/kubeadm-certs/>인증서 관리</a>와
<a href=/ko/docs/tasks/administer-cluster/kubeadm/kubeadm-upgrade/>kubeadm 클러스터 업그레이드하기</a>에 대해 도움이 되는 가이드가 있다.
<a href=/ko/docs/tasks/administer-cluster/>클러스터 운영하기</a>에서
더 많은 쿠버네티스 관리 작업을 볼 수 있다.</li></ul><p>컨트롤 플레인 서비스를 실행할 때 사용 가능한 옵션에 대해 보려면,
<a href=/docs/reference/command-line-tools-reference/kube-apiserver/>kube-apiserver</a>,
<a href=/docs/reference/command-line-tools-reference/kube-controller-manager/>kube-controller-manager</a>,
<a href=/docs/reference/command-line-tools-reference/kube-scheduler/>kube-scheduler</a>를 참조한다.
고가용성 컨트롤 플레인 예제는
<a href=/ko/docs/setup/production-environment/tools/kubeadm/ha-topology/>고가용성 토폴로지를 위한 옵션</a>,
<a href=/docs/setup/production-environment/tools/kubeadm/high-availability/>kubeadm을 이용하여 고가용성 클러스터 생성하기</a>,
<a href=/docs/tasks/administer-cluster/configure-upgrade-etcd/>쿠버네티스를 위한 etcd 클러스터 운영하기</a>를 참조한다.
etcd 백업 계획을 세우려면
<a href=/docs/tasks/administer-cluster/configure-upgrade-etcd/#backing-up-an-etcd-cluster>etcd 클러스터 백업하기</a>를 참고한다.</p><h3 id=프로덕션-워커-노드>프로덕션 워커 노드</h3><p>프로덕션 수준 워크로드는 복원력이 있어야 하고,
이들이 의존하는 모든 것들(예: CoreDNS)도 복원력이 있어야 한다.
컨트롤 플레인을 자체적으로 관리하든
클라우드 공급자가 대신 수행하도록 하든 상관없이,
워커 노드(간단히 <em>노드</em>라고도 함)를 어떤 방법으로 관리할지 고려해야 한다.</p><ul><li><em>노드 구성하기</em>: 노드는 물리적 또는 가상 머신일 수 있다.
직접 노드를 만들고 관리하려면 지원되는 운영 체제를 설치한 다음
적절한 <a href=/ko/docs/concepts/overview/components/#%EB%85%B8%EB%93%9C-%EC%BB%B4%ED%8F%AC%EB%84%8C%ED%8A%B8>노드 서비스</a>를 추가하고 실행한다.
다음을 고려해야 한다.<ul><li>워크로드의 요구 사항 (노드가 적절한 메모리, CPU, 디스크 속도, 저장 용량을 갖도록 구성)</li><li>일반적인 컴퓨터 시스템이면 되는지, 아니면 GPU, 윈도우 노드, 또는 VM 격리를 필요로 하는 워크로드가 있는지</li></ul></li><li><em>노드 검증하기</em>: <a href=/ko/docs/setup/best-practices/node-conformance/>노드 구성 검증하기</a>에서
노드가 쿠버네티스 클러스터에 조인(join)에 필요한 요구 사항을
만족하는지 확인하는 방법을 알아본다.</li><li><em>클러스터에 노드 추가하기</em>: 클러스터를 자체적으로 관리하는 경우,
머신을 준비하고, 클러스터의 apiserver에 이를 수동으로 추가하거나
또는 머신이 스스로 등록하도록 하여 노드를 추가할 수 있다.
이러한 방식으로 노드를 추가하는 방법을 보려면 <a href=/ko/docs/concepts/architecture/nodes/>노드</a> 섹션을 확인한다.</li><li><em>노드 스케일링</em>: 클러스터가 최종적으로 필요로 하게 될 용량만큼
확장하는 것에 대한 계획이 있어야 한다.
실행해야 하는 파드 및 컨테이너 수에 따라 필요한 노드 수를 판별하려면
<a href=/ko/docs/setup/best-practices/cluster-large/>대형 클러스터에 대한 고려 사항</a>을 확인한다.
만약 노드를 직접 관리한다면, 직접 물리적 장비를 구입하고 설치해야 할 수도 있음을 의미한다.</li><li><em>노드 자동 스케일링</em>: 대부분의 클라우드 공급자는
비정상 노드를 교체하거나 수요에 따라 노드 수를 늘리거나 줄일 수 있도록
<a href=https://github.com/kubernetes/autoscaler/tree/master/cluster-autoscaler#readme>클러스터 오토스케일러</a>를 지원한다.
<a href=https://github.com/kubernetes/autoscaler/blob/master/cluster-autoscaler/FAQ.md>자주 묻는 질문</a>에서
오토스케일러가 어떻게 동작하는지,
<a href=https://github.com/kubernetes/autoscaler/tree/master/cluster-autoscaler#deployment>배치</a> 섹션에서
각 클라우드 공급자별로 어떻게 구현했는지를 확인한다.
온프레미스의 경우, 필요에 따라 새 노드를 가동하도록
스크립트를 구성할 수 있는 가상화 플랫폼이 있다.</li><li><em>노드 헬스 체크 구성</em>: 중요한 워크로드의 경우,
해당 노드에서 실행 중인 노드와 파드의 상태가 정상인지 확인하고 싶을 것이다.
<a href=/ko/docs/tasks/debug/debug-cluster/monitor-node-health/>Node Problem Detector</a>
데몬을 사용하면 노드가 정상인지 확인할 수 있다.</li></ul><h2 id=프로덕션-사용자-관리>프로덕션 사용자 관리</h2><p>프로덕션에서는, 클러스터를 한 명 또는 여러 명이 사용하던 모델에서
수십에서 수백 명이 사용하는 모델로 바꿔야 하는 경우가 발생할 수 있다.
학습 환경 또는 플랫폼 프로토타입에서는 모든 작업에 대한 단일 관리 계정으로도
충분할 수 있다. 프로덕션에서는 여러 네임스페이스에 대한, 액세스 수준이
각각 다른 더 많은 계정이 필요하다.</p><p>프로덕션 수준의 클러스터를 사용한다는 것은
다른 사용자의 액세스를 선택적으로 허용할 방법을 결정하는 것을 의미한다.
특히 클러스터에 액세스를 시도하는 사용자의 신원을 확인(인증, authentication)하고
요청한 작업을 수행할 권한이 있는지 결정(인가, authorization)하기 위한
다음과 같은 전략을 선택해야 한다.</p><ul><li><em>인증</em>: apiserver는 클라이언트 인증서, 전달자 토큰, 인증 프록시 또는
HTTP 기본 인증을 사용하여 사용자를 인증할 수 있다.
사용자는 인증 방법을 선택하여 사용할 수 있다.
apiserver는 또한 플러그인을 사용하여
LDAP 또는 Kerberos와 같은 조직의 기존 인증 방법을 활용할 수 있다.
쿠버네티스 사용자를 인증하는 다양한 방법에 대한 설명은
<a href=/docs/reference/access-authn-authz/authentication/>인증</a>을 참조한다.</li><li><em>인가</em>: 일반 사용자 인가를 위해,
RBAC 와 ABAC 중 하나를 선택하여 사용할 수 있다. <a href=/ko/docs/reference/access-authn-authz/authorization/>인가 개요</a>에서
사용자 계정과 서비스 어카운트 인가를 위한 여러 가지 모드를
확인할 수 있다.<ul><li><em>역할 기반 접근 제어</em> (<a href=/docs/reference/access-authn-authz/rbac/>RBAC</a>): 인증된 사용자에게
특정 권한 집합을 허용하여 클러스터에 대한 액세스를 할당할 수 있다.
특정 네임스페이스(Role) 또는 전체 클러스터(ClusterRole)에 권한을 할당할 수 있다.
그 뒤에 RoleBindings 및 ClusterRoleBindings를 사용하여 해당 권한을
특정 사용자에게 연결할 수 있다.</li><li><em>속성 기반 접근 제어</em> (<a href=/docs/reference/access-authn-authz/abac/>ABAC</a>): 클러스터의
리소스 속성을 기반으로 정책을 생성하고 이러한 속성을 기반으로 액세스를 허용하거나 거부할 수 있다.
정책 파일의 각 줄은 버전 관리 속성(apiVersion 및 종류),
그리고 '대상(사용자 또는 그룹)', '리소스 속성',
'비 리소스 속성(<code>/version</code> 또는 <code>/apis</code>)' 및 '읽기 전용'과 일치하는 사양 속성 맵을 식별한다.
자세한 내용은 <a href=/docs/reference/access-authn-authz/abac/#examples>예시</a>를 참조한다.</li></ul></li></ul><p>프로덕션 쿠버네티스 클러스터에 인증과 인가를 설정할 때, 다음의 사항을 고려해야 한다.</p><ul><li><em>인가 모드 설정</em>: 쿠버네티스 API 서버
(<a href=/docs/reference/command-line-tools-reference/kube-apiserver/>kube-apiserver</a>)를 실행할 때,
<em><code>--authorization-mode</code></em> 플래그를 사용하여 인증 모드를 설정해야 한다.
예를 들어, <em><code>kube-adminserver.yaml</code></em> 파일(*<code>/etc/kubernetes/manifests</code>*에 있는) 안의 플래그를 <code>Node,RBAC</code>으로 설정할 수 있다.
이렇게 하여 인증된 요청이 Node 인가와 RBAC 인가를 사용할 수 있게 된다.</li><li><em>사용자 인증서와 롤 바인딩 생성(RBAC을 사용하는 경우)</em>: RBAC 인증을 사용하는 경우,
사용자는 클러스터 CA가 서명한 CSR(CertificateSigningRequest)을 만들 수 있다.
그 뒤에 각 사용자에게 역할 및 ClusterRoles를 바인딩할 수 있다.
자세한 내용은
<a href=/docs/reference/access-authn-authz/certificate-signing-requests/>인증서 서명 요청</a>을 참조한다.</li><li><em>속성을 포함하는 정책 생성(ABAC을 사용하는 경우)</em>: ABAC 인증을 사용하는 경우,
속성의 집합으로 정책을 생성하여, 인증된 사용자 또는 그룹이
특정 리소스(예: 파드), 네임스페이스, 또는 apiGroup에 접근할 수 있도록 한다.
<a href=/docs/reference/access-authn-authz/abac/#examples>예시</a>에서
더 많은 정보를 확인한다.</li><li><em>어드미션 컨트롤러 도입 고려</em>:
<a href=/docs/reference/access-authn-authz/authentication/#webhook-token-authentication>웹훅 토큰 인증</a>은
API 서버를 통해 들어오는 요청의 인가에 사용할 수 있는 추가적인 방법이다.
웹훅 및 다른 인가 형식을 사용하려면 API 서버에
<a href=/docs/reference/access-authn-authz/admission-controllers/>어드미션 컨트롤러</a>를
추가해야 한다.</li></ul><h2 id=워크로드에-자원-제한-걸기>워크로드에 자원 제한 걸기</h2><p>프로덕션 워크로드의 요구 사항이
쿠버네티스 컨트롤 플레인 안팎의 압박을 초래할 수 있다.
워크로드의 요구 사항을 충족하도록 클러스터를 구성할 때 다음 항목을 고려한다.</p><ul><li><em>네임스페이스 제한 설정</em>: 메모리, CPU와 같은 자원의 네임스페이스 별 쿼터를 설정한다.
<a href=/ko/docs/tasks/administer-cluster/manage-resources/>메모리, CPU 와 API 리소스 관리</a>에서
상세 사항을 확인한다.
<a href=/blog/2020/08/14/introducing-hierarchical-namespaces/>계층적 네임스페이스</a>를 설정하여
제한을 상속할 수도 있다.</li><li><em>DNS 요청에 대한 대비</em>: 워크로드가 대규모로 확장될 것으로 예상된다면,
DNS 서비스도 확장할 준비가 되어 있어야 한다.
<a href=/docs/tasks/administer-cluster/dns-horizontal-autoscaling/>클러스터의 DNS 서비스 오토스케일링</a>을 확인한다.</li><li><em>추가적인 서비스 어카운트 생성</em>: 사용자 계정은 <em>클러스터</em>에서 사용자가 무엇을 할 수 있는지 결정하는 반면에,
서비스 어카운트는 특정 네임스페이스 내의 파드 접근 권한을 결정한다.
기본적으로, 파드는 자신의 네임스페이스의 기본 서비스 어카운트을 이용한다.
<a href=/ko/docs/reference/access-authn-authz/service-accounts-admin/>서비스 어카운트 관리하기</a>에서
새로운 서비스 어카운트을 생성하는 방법을 확인한다. 예를 들어, 다음의 작업을 할 수 있다.<ul><li>파드가 특정 컨테이너 레지스트리에서 이미지를 가져 오는 데 사용할 수 있는 시크릿을 추가한다.
<a href=/docs/tasks/configure-pod-container/configure-service-account/>파드를 위한 서비스 어카운트 구성하기</a>에서
예시를 확인한다.</li><li>서비스 어카운트에 RBAC 권한을 할당한다.
<a href=/docs/reference/access-authn-authz/rbac/#service-account-permissions>서비스어카운트 권한</a>에서
상세 사항을 확인한다.</li></ul></li></ul><h2 id=다음-내용>다음 내용</h2><ul><li>프로덕션 쿠버네티스를 직접 구축할지,
아니면 <a href=/ko/docs/setup/production-environment/turnkey-solutions/>턴키 클라우드 솔루션</a> 또는
<a href=/ko/partners/>쿠버네티스 파트너</a>가 제공하는 서비스를 이용할지 결정한다.</li><li>클러스터를 직접 구축한다면,
<a href=/ko/docs/setup/best-practices/certificates/>인증서</a>를 어떻게 관리할지,
<a href=/docs/setup/production-environment/tools/kubeadm/setup-ha-etcd-with-kubeadm/>etcd</a>와
<a href=/ko/docs/setup/production-environment/tools/kubeadm/ha-topology/>API 서버</a>
등의 기능에 대한 고가용성을
어떻게 보장할지를 계획한다.</li><li>배포 도구로 <a href=/ko/docs/setup/production-environment/tools/kubeadm/>kubeadm</a>,
<a href=/ko/docs/setup/production-environment/tools/kops/>kops</a>,
<a href=/ko/docs/setup/production-environment/tools/kubespray/>Kubespray</a> 중
하나를 선택한다.</li><li><a href=/docs/reference/access-authn-authz/authentication/>인증</a> 및
<a href=/ko/docs/reference/access-authn-authz/authorization/>인가</a> 방식을 선택하여
사용자 관리 방법을 구성한다.</li><li><a href=/ko/docs/tasks/administer-cluster/manage-resources/>자원 제한</a>,
<a href=/docs/tasks/administer-cluster/dns-horizontal-autoscaling/>DNS 오토스케일링</a>,
<a href=/ko/docs/reference/access-authn-authz/service-accounts-admin/>서비스 어카운트</a>를 설정하여
애플리케이션 워크로드의 실행에 대비한다.</li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-a77d3feb6e6d9978f32fa14622642e9a>2.1 - 컨테이너 런타임</h1><div class="alert alert-secondary callout note" role=alert><strong>참고:</strong> Dockershim은 쿠버네티스 릴리스 1.24부터 쿠버네티스 프로젝트에서 제거되었다. 더 자세한 내용은 <a href=/dockershim>Dockershim 제거 FAQ</a>를 참고한다.</div><p>파드가 노드에서 실행될 수 있도록 클러스터의 각 노드에
<a class=glossary-tooltip title='컨테이너 런타임은 컨테이너 실행을 담당하는 소프트웨어이다.' data-toggle=tooltip data-placement=top href=/ko/docs/setup/production-environment/container-runtimes/ target=_blank aria-label='컨테이너 런타임'>컨테이너 런타임</a>을
설치해야 한다. 이 페이지에서는 관련된 항목을 설명하고
노드 설정 관련 작업을 설명한다.</p><p>쿠버네티스 1.25에서는
<a class=glossary-tooltip title='Kubelet과 컨테이너 런타임을 통합시키기 위한 API' data-toggle=tooltip data-placement=top href=/ko/docs/concepts/overview/components/#%ec%bb%a8%ed%85%8c%ec%9d%b4%eb%84%88-%eb%9f%b0%ed%83%80%ec%9e%84 target=_blank aria-label='컨테이너 런타임 인터페이스'>컨테이너 런타임 인터페이스</a>(CRI) 요구사항을 만족하는
런타임을 사용해야 한다.</p><p>더 자세한 정보는 <a href=#cri-versions>CRI 버전 지원</a>을 참조한다.</p><p>이 페이지는 쿠버네티스에서
여러 공통 컨테이너 런타임을 사용하는 방법에 대한 개요를 제공한다.</p><ul><li><a href=#containerd>containerd</a></li><li><a href=#cri-o>CRI-O</a></li><li><a href=#docker>도커 엔진</a></li><li><a href=#mcr>미란티스 컨테이너 런타임</a></li></ul><div class="alert alert-info note callout" role=alert><strong>참고:</strong><p>쿠버네티스 v1.24 이전 릴리스는
<em>도커심</em> 이라는 구성 요소를 사용하여 도커 엔진과의 직접 통합을 지원했다.
이 특별한 직접 통합은
더 이상 쿠버네티스에 포함되지 않는다(이 제거는
v1.20 릴리스의 일부로 <a href=/blog/2020/12/08/kubernetes-1-20-release-announcement/#dockershim-deprecation>공지</a>되었다).
이 제거가 어떻게 영향을 미치는지 알아보려면
<a href=/docs/tasks/administer-cluster/migrating-from-dockershim/check-if-dockershim-removal-affects-you/>도커심 제거가 영향을 미치는지 확인하기</a> 문서를 확인한다.
도커심을 사용하던 환경에서 이전(migrating)하는 방법을 보려면,
<a href=/ko/docs/tasks/administer-cluster/migrating-from-dockershim/>도커심에서 이전하기</a>를 확인한다.</p><p>v1.25 이외의 쿠버네티스 버전을 사용하고 있다면,
해당 버전의 문서를 참고한다.</p></div><h2 id=필수-요소들-설치-및-구성하기>필수 요소들 설치 및 구성하기</h2><p>다음 단계에서는 리눅스의 쿠버네티스 노드를 위한 일반적인 설정들을 적용한다.</p><p>만약 필요하지 않다고 생각한다면 몇몇 설정들은 넘어가도 무방하다.</p><p>더 자세한 정보는, <a href=/ko/docs/concepts/extend-kubernetes/compute-storage-net/network-plugins/#network-plugin-requirements>네트워크 플러그인 요구사항</a>이나 각자 사용 중인 컨테이너 런타임에 해당하는 문서를 확인한다.</p><h3 id=ipv4를-포워딩하여-iptables가-브리지된-트래픽을-보게-하기>IPv4를 포워딩하여 iptables가 브리지된 트래픽을 보게 하기</h3><p><code>lsmod | grep br_netfilter</code>를 실행하여 <code>br_netfilter</code> 모듈이 로드되었는지 확인한다.</p><p>명시적으로 로드하려면, <code>sudo modprobe br_netfilter</code>를 실행한다.</p><p>리눅스 노드의 iptables가 브리지된 트래픽을 올바르게 보기 위한 요구 사항으로, <code>sysctl</code> 구성에서 <code>net.bridge.bridge-nf-call-iptables</code>가 1로 설정되어 있는지 확인한다. 예를 들어,</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>cat <span style=color:#b44>&lt;&lt;EOF | sudo tee /etc/modules-load.d/k8s.conf
</span></span></span><span style=display:flex><span><span style=color:#b44>overlay
</span></span></span><span style=display:flex><span><span style=color:#b44>br_netfilter
</span></span></span><span style=display:flex><span><span style=color:#b44>EOF</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>sudo modprobe overlay
</span></span><span style=display:flex><span>sudo modprobe br_netfilter
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#080;font-style:italic># 필요한 sysctl 파라미터를 설정하면, 재부팅 후에도 값이 유지된다.</span>
</span></span><span style=display:flex><span>cat <span style=color:#b44>&lt;&lt;EOF | sudo tee /etc/sysctl.d/k8s.conf
</span></span></span><span style=display:flex><span><span style=color:#b44>net.bridge.bridge-nf-call-iptables  = 1
</span></span></span><span style=display:flex><span><span style=color:#b44>net.bridge.bridge-nf-call-ip6tables = 1
</span></span></span><span style=display:flex><span><span style=color:#b44>net.ipv4.ip_forward                 = 1
</span></span></span><span style=display:flex><span><span style=color:#b44>EOF</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#080;font-style:italic># 재부팅하지 않고 sysctl 파라미터 적용하기</span>
</span></span><span style=display:flex><span>sudo sysctl --system
</span></span></code></pre></div><h2 id=cgroup-드라이버>cgroup 드라이버</h2><p>리눅스에서, <a class=glossary-tooltip title='선택적으로 리소스를 격리, 관리, 제한하는 리눅스 프로세스의 그룹.' data-toggle=tooltip data-placement=top href='/ko/docs/reference/glossary/?all=true#term-cgroup' target=_blank aria-label='control group'>control group</a>은
프로세스에 할당된 리소스를 제한하는데 사용된다.</p><p><a class=glossary-tooltip title='클러스터의 각 노드에서 실행되는 에이전트. Kubelet은 파드에서 컨테이너가 확실하게 동작하도록 관리한다.' data-toggle=tooltip data-placement=top href=/docs/reference/generated/kubelet target=_blank aria-label=kubelet>kubelet</a>과
그에 연계된 컨테이너 런타임 모두 컨트롤 그룹(control group)들과 상호작용 해야 하는데, 이는
<a href=/ko/docs/concepts/configuration/manage-resources-containers/>파드 및 컨테이너 자원 관리</a>가 수정될 수 있도록 하고
cpu 혹은 메모리와 같은 자원의 요청(request)과 상한(limit)을 설정하기 위함이다. 컨트롤
그룹과 상호작용하기 위해서는, kubelet과 컨테이너 런타임이 <em>cgroup 드라이버</em>를 사용해야 한다.
매우 중요한 점은, kubelet과 컨테이너 런타임이 같은 cgroup
group 드라이버를 사용해야 하며 구성도 동일해야 한다는 것이다.</p><p>두 가지의 cgroup 드라이버가 이용 가능하다.</p><ul><li><a href=#cgroupfs-cgroup-driver><code>cgroupfs</code></a></li><li><a href=#systemd-cgroup-driver><code>systemd</code></a></li></ul><h3 id=cgroupfs-cgroup-driver>cgroupfs 드라이버</h3><p><code>cgroupfs</code> 드라이버는 kubelet의 기본 cgroup 드라이버이다. <code>cgroupfs</code>
드라이버가 사용될 때, kubelet과 컨테이너 런타임은 직접적으로
cgroup 파일시스템과 상호작용하여 cgroup들을 설정한다.</p><p><code>cgroupfs</code> 드라이버가 권장되지 <strong>않는</strong> 때가 있는데,
<a href=https://www.freedesktop.org/wiki/Software/systemd/>systemd</a>가
init 시스템인 경우이다. 이것은 systemd가 시스템에 단 하나의 cgroup 관리자만 있을 것으로 기대하기 때문이다.
또한, <a href=/docs/concepts/architecture/cgroups>cgroup v2</a>를 사용할 경우에도
<code>cgroupfs</code> 대신 <code>systemd</code> cgroup 드라이버를
사용한다.</p><h3 id=systemd-cgroup-driver>systemd cgroup 드라이버</h3><p>리눅스 배포판의 init 시스템이 <a href=https://www.freedesktop.org/wiki/Software/systemd/>systemd</a>인
경우, init 프로세스는 root control group(<code>cgroup</code>)을
생성 및 사용하는 cgroup 관리자로 작동한다.</p><p>systemd는 cgroup과 긴밀하게 통합되어 있으며 매 systemd 단위로 cgroup을
할당한다. 결과적으로, <code>systemd</code>를 init 시스템으로 사용하고 <code>cgroupfs</code>
드라이버를 사용하면, 그 시스템은 두 개의 다른 cgroup 관리자를 갖게 된다.</p><p>두 개의 cgroup 관리자는 시스템 상 사용 가능한 자원과 사용 중인 자원들에 대하여 두 가지 관점을 가져 혼동을
초래한다. 예를 들어, kubelet과 컨테이너 런타임은 <code>cgroupfs</code>를 사용하고
나머지 프로세스는 <code>systemd</code>를 사용하도록 노드를 구성한 경우, 노드가
자원 압박으로 인해 불안정해질 수 있다.</p><p>이러한 불안정성을 줄이는 방법은, <code>systemd</code>가 init 시스템으로 선택되었을 때에는 <code>systemd</code>를
kubelet과 컨테이너 런타임의 cgroup 드라이버로 사용하는 것이다.</p><p><code>systemd</code>를 cgroup 드라이버로 사용하기 위해서는,
<a href=/docs/tasks/administer-cluster/kubelet-config-file/><code>KubeletConfiguration</code></a>를 수정하여
<code>cgroupDriver</code> 옵션을 <code>systemd</code>로 지정하는 것이다. 예를 들면 다음과 같다.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>kubelet.config.k8s.io/v1beta1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>KubeletConfiguration<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:#00f;font-weight:700>...</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>cgroupDriver</span>:<span style=color:#bbb> </span>systemd<span style=color:#bbb>
</span></span></span></code></pre></div><p><code>systemd</code>를 kubelet의 cgroup 드라이버로 구성했다면, 반드시
컨테이너 런타임의 cgroup 드라이버 또한 <code>systemd</code>로 설정해야 한다. 자세한 설명은
컨테이너 런타임 대한 문서를 참조한다. 예를 들면 다음과 같다.</p><ul><li><a href=#containerd-systemd>containerd</a></li><li><a href=#cri-o>CRI-O</a></li></ul><div class="alert alert-warning caution callout" role=alert><strong>주의:</strong><p>클러스터에 결합되어 있는 노드의 cgroup 관리자를 변경하는 것은 신중하게 수행해야 한다.
하나의 cgroup 드라이버의 의미를 사용하여 kubelet이 파드를 생성해왔다면,
컨테이너 런타임을 다른 cgroup 드라이버로 변경하는 것은 존재하는 기존 파드에 대해 파드 샌드박스 재생성을 시도할 때, 에러가 발생할 수 있다.
kubelet을 재시작하는 것은 에러를 해결할 수 없을 것이다.</p><p>자동화가 가능하다면, 업데이트된 구성을 사용하여 노드를 다른 노드로
교체하거나, 자동화를 사용하여 다시 설치한다.</p></div><h3 id=kubeadm으로-생성한-클러스터의-드라이버를-systemd-로-변경하기>kubeadm으로 생성한 클러스터의 드라이버를 <code>systemd</code>로 변경하기</h3><p>기존에 kubeadm으로 생성한 클러스터의 cgroup 드라이버를 <code>systemd</code>로 변경하려면,
<a href=/docs/tasks/administer-cluster/kubeadm/configure-cgroup-driver/>cgroup 드라이버 설정하기</a>를 참고한다.</p><h2 id=cri-versions>CRI 버전 지원</h2><p>사용할 컨테이너 런타임이 적어도 CRI의 v1alpha2 이상을 지원해야 한다.</p><p>쿠버네티스 1.25 버전에서는 기본적으로 CRI API 중 v1을 사용한다.
컨테이너 런타임이 v1 API를 지원하지 않으면,
kubelet은 대신 (사용 중단된) v1alpha2 API를 사용하도록 설정된다.</p><h2 id=컨테이너-런타임>컨테이너 런타임</h2><div class="alert alert-secondary callout third-party-content" role=alert><strong>참고:</strong>
이 섹션은 쿠버네티스에 필요한 기능을 제공하는 써드파티 프로젝트와 관련이 있다. 쿠버네티스 프로젝트 작성자는 써드파티 프로젝트에 책임이 없다. 이 페이지는 <a href=https://github.com/cncf/foundation/blob/master/website-guidelines.md target=_blank>CNCF 웹사이트 가이드라인</a>에 따라 프로젝트를 알파벳 순으로 나열한다. 이 목록에 프로젝트를 추가하려면 변경사항을 제출하기 전에 <a href=/contribute/style/content-guide/#third-party-content>콘텐츠 가이드</a>를 읽어본다.</div><h3 id=containerd>containerd</h3><p>이 섹션에는 containerd를 CRI 런타임으로 사용하는 데 필요한 단계를 간략하게 설명한다.</p><p>다음 명령을 사용하여 시스템에 containerd를 설치한다.</p><p><a href=https://github.com/containerd/containerd/blob/main/docs/getting-started.md>containerd 시작하기</a>의 지침에 따라, 유효한 환경 설정 파일(<code>config.toml</code>)을 생성한다.</p><ul class="nav nav-tabs" id=finding-your-config-toml-file role=tablist><li class=nav-item><a data-toggle=tab class="nav-link active" href=#finding-your-config-toml-file-0 role=tab aria-controls=finding-your-config-toml-file-0 aria-selected=true>Linux</a></li><li class=nav-item><a data-toggle=tab class=nav-link href=#finding-your-config-toml-file-1 role=tab aria-controls=finding-your-config-toml-file-1>Windows</a></li></ul><div class=tab-content id=finding-your-config-toml-file><div id=finding-your-config-toml-file-0 class="tab-pane show active" role=tabpanel aria-labelledby=finding-your-config-toml-file-0><p><p><code>/etc/containerd/config.toml</code> 경로에서 파일을 찾을 수 있음.</p></div><div id=finding-your-config-toml-file-1 class=tab-pane role=tabpanel aria-labelledby=finding-your-config-toml-file-1><p>`C:\Program Files\containerd\config.toml` 경로에서 파일을 찾을 수 있음.</div></div><p>리눅스에서, containerd를 위한 기본 CRI 소켓은 <code>/run/containerd/containerd.sock</code>이다.
윈도우에서, 기본 CRI 엔드포인트는 <code>npipe://./pipe/containerd-containerd</code>이다.</p><h4 id=containerd-systemd><code>systemd</code> cgroup 드라이버 환경 설정하기</h4><p><code>/etc/containerd/config.toml</code> 의 <code>systemd</code> cgroup 드라이버를 <code>runc</code> 에서 사용하려면, 다음과 같이 설정한다.</p><pre tabindex=0><code>[plugins.&#34;io.containerd.grpc.v1.cri&#34;.containerd.runtimes.runc]
  ...
  [plugins.&#34;io.containerd.grpc.v1.cri&#34;.containerd.runtimes.runc.options]
    SystemdCgroup = true
</code></pre><p><a href=/docs/concepts/architecture/cgroups>cgroup v2</a>을 사용할 경우 <code>systemd</code> cgroup 드라이버가 권장된다.</p><div class="alert alert-info note callout" role=alert><strong>참고:</strong><p>만약 containerd를 패키지(RPM, <code>.deb</code> 등)를 통해 설치하였다면,
CRI integration 플러그인은 기본적으로 비활성화되어 있다.</p><p>쿠버네티스에서 containerd를 사용하기 위해서는 CRI support가 활성화되어 있어야 한다.
<code>cri</code>가 <code>/etc/containerd/config.toml</code> 파일 안에 있는 <code>disabled_plugins</code> 목록에 포함되지 않도록 주의하자.
만약 해당 파일을 변경하였다면, <code>containerd</code>를 다시 시작한다.</p></div><p>이 변경 사항을 적용하려면, containerd를 재시작한다.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>sudo systemctl restart containerd
</span></span></code></pre></div><p>kubeadm을 사용하는 경우,
<a href=/docs/tasks/administer-cluster/kubeadm/configure-cgroup-driver/#configuring-the-kubelet-cgroup-driver>kubelet용 cgroup driver</a>를 수동으로 구성한다.</p><h4 id=override-pause-image-containerd>샌드박스(pause) 이미지 덮어쓰기</h4><p><a href=https://github.com/containerd/containerd/blob/main/docs/cri/config.md>containerd 설정</a>에서
아래와 같이 샌드박스 이미지를 덮어쓸 수 있다.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-toml data-lang=toml><span style=display:flex><span>[plugins.<span style=color:#b44>&#34;io.containerd.grpc.v1.cri&#34;</span>]
</span></span><span style=display:flex><span>  sandbox_image = <span style=color:#b44>&#34;registry.k8s.io/pause:3.2&#34;</span>
</span></span></code></pre></div><p>설정 파일을 변경하는 경우 역시 <code>systemctl restart containerd</code>를 통해 <code>containerd</code>를 재시작해야 한다.</p><h3 id=cri-o>CRI-O</h3><p>이 섹션은 CRI-O를 컨테이너 런타임으로 설치하는 필수적인 단계를 담고 있다.</p><p>CRI-O를 설치하려면, <a href=https://github.com/cri-o/cri-o/blob/main/install.md#readme>CRI-O 설치 방법</a>을 따른다.</p><h4 id=cgroup-드라이버-1>cgroup 드라이버</h4><p>CRI-O는 기본적으로 systemd cgroup 드라이버를 사용하며, 이는 대부분의 경우에 잘 동작할 것이다.
<code>cgroupfs</code> cgroup 드라이버로 전환하려면, <code>/etc/crio/crio.conf</code> 를 수정하거나
<code>/etc/crio/crio.conf.d/02-cgroup-manager.conf</code> 에 드롭-인(drop-in) 구성을 배치한다.
예를 들면 다음과 같다.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-toml data-lang=toml><span style=display:flex><span>[crio.runtime]
</span></span><span style=display:flex><span>conmon_cgroup = <span style=color:#b44>&#34;pod&#34;</span>
</span></span><span style=display:flex><span>cgroup_manager = <span style=color:#b44>&#34;cgroupfs&#34;</span>
</span></span></code></pre></div><p>또한 <code>cgroupfs</code> 와 함께 CRI-O를 사용할 때 <code>pod</code> 값으로 설정해야 하는
변경된 <code>conmon_cgroup</code> 에 유의해야 한다. 일반적으로 kubelet(일반적으로 kubeadm을 통해 수행됨)과
CRI-O의 cgroup 드라이버 구성을 동기화 상태로
유지해야 한다.</p><p>CRI-O의 경우, CRI 소켓은 기본적으로 <code>/var/run/crio/crio.sock</code>이다.</p><h4 id=override-pause-image-cri-o>샌드박스(pause) 이미지 덮어쓰기</h4><p><a href=https://github.com/cri-o/cri-o/blob/main/docs/crio.conf.5.md>CRI-O 설정</a>에서
아래와 같이 샌드박스 이미지를 덮어쓸 수 있다.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-toml data-lang=toml><span style=display:flex><span>[crio.image]
</span></span><span style=display:flex><span>pause_image=<span style=color:#b44>&#34;registry.k8s.io/pause:3.6&#34;</span>
</span></span></code></pre></div><p>이 옵션은 <code>systemctl reload crio</code> 혹은 <code>crio</code> 프로세스에 <code>SIGHUP</code>을 보내 변경사항을 적용하기 위한
live configuration reload 기능을 지원한다.</p><h3 id=docker>도커 엔진</h3><div class="alert alert-info note callout" role=alert><strong>참고:</strong> 아래의 지침은
당신이 도커 엔진과 쿠버네티스를 통합하는 데
<a href=https://github.com/Mirantis/cri-dockerd><code>cri-dockerd</code></a> 어댑터를 사용하고 있다고 가정한다.</div><ol><li><p>각 노드에서, <a href=https://docs.docker.com/engine/install/#server>도커 엔진 설치하기</a>에 따라
리눅스 배포판에 맞게 도커를 설치한다.</p></li><li><p><a href=https://github.com/Mirantis/cri-dockerd><code>cri-dockerd</code></a> 소스 코드 저장소의 지침대로
<code>cri-dockerd</code>를 설치한다.</p></li></ol><p><code>cri-dockerd</code>의 경우, CRI 소켓은 기본적으로 <code>/run/cri-dockerd.sock</code>이다.</p><h3 id=mcr>미란티스 컨테이너 런타임</h3><p><a href=https://docs.mirantis.com/mcr/20.10/overview.html>미란티스 컨테이너 런타임</a>(MCR)은 상용 컨테이너 런타임이며
이전에는 도커 엔터프라이즈 에디션으로 알려져 있었다.</p><p>오픈소스인 <a href=https://github.com/Mirantis/cri-dockerd><code>cri-dockerd</code></a> 컴포넌트를 이용하여 쿠버네티스에서 미란티스 컨테이너 런타임을 사용할 수 있으며,
이 컴포넌트는 MCR에 포함되어 있다.</p><p>미란티스 컨테이너 런타임을 설치하는 방법에 대해 더 알아보려면,
<a href=https://docs.mirantis.com/mcr/20.10/install.html>MCR 배포 가이드</a>를 참고한다.</p><p>CRI 소켓의 경로를 찾으려면
<code>cri-docker.socket</code>라는 이름의 systemd 유닛을 확인한다.</p><h4 id=override-pause-image-cri-dockerd-mcr>샌드박스(pause) 이미지 덮어쓰기</h4><p><code>cri-dockerd</code> 어댑터는,
파드 인프라 컨테이너("pause image")를 위해 어떤 컨테이너 이미지를 사용할지 명시하는 커맨드라인 인자를 받는다.
해당 커맨드라인 인자는 <code>--pod-infra-container-image</code>이다.</p><h2 id=다음-내용>다음 내용</h2><p>컨테이너 런타임과 더불어, 클러스터에는
동작하는 <a href=/ko/docs/concepts/cluster-administration/networking/#%EC%BF%A0%EB%B2%84%EB%84%A4%ED%8B%B0%EC%8A%A4-%EB%84%A4%ED%8A%B8%EC%9B%8C%ED%81%AC-%EB%AA%A8%EB%8D%B8%EC%9D%98-%EA%B5%AC%ED%98%84-%EB%B0%A9%EB%B2%95>네트워크 플러그인</a>도 필요하다.</p></div><div class=td-content style=page-break-before:always><h1 id=pg-00e1646f68aeb89f9722cf6f6cfcad94>2.2 - 배포 도구로 쿠버네티스 설치하기</h1></div><div class=td-content><h1 id=pg-a16f59f325a17cdeed324d5c889f7f73>2.2.1 - kubeadm으로 클러스터 구성하기</h1></div><div class=td-content><h1 id=pg-29e59491dd6118b23072dfe9ebb93323>2.2.1.1 - kubeadm 설치하기</h1><p><img src=/images/kubeadm-stacked-color.png align=right width=150px></img>
이 페이지에서는 <code>kubeadm</code> 툴박스 설치 방법을 보여준다.
이 설치 프로세스를 수행한 후 kubeadm으로 클러스터를 만드는 방법에 대한 자세한 내용은 <a href=/docs/setup/production-environment/tools/kubeadm/create-cluster-kubeadm/>kubeadm으로 클러스터 생성하기</a> 페이지를 참고한다.</p><h2 id=시작하기-전에>시작하기 전에</h2><ul><li>호환되는 리눅스 머신. 쿠버네티스 프로젝트는 데비안 기반 배포판, 레드햇 기반 배포판, 그리고 패키지 매니저를 사용하지 않는 경우에 대한 일반적인 가이드를 제공한다.</li><li>2 GB 이상의 램을 장착한 머신. (이 보다 작으면 사용자의 앱을 위한 공간이 거의 남지 않음)</li><li>2 이상의 CPU.</li><li>클러스터의 모든 머신에 걸친 전체 네트워크 연결. (공용 또는 사설 네트워크면 괜찮음)</li><li>모든 노드에 대해 고유한 호스트 이름, MAC 주소 및 product_uuid. 자세한 내용은 <a href=#verify-mac-address>여기</a>를 참고한다.</li><li>컴퓨터의 특정 포트들 개방. 자세한 내용은 <a href=#check-required-ports>여기</a>를 참고한다.</li><li>스왑의 비활성화. kubelet이 제대로 작동하게 하려면 <strong>반드시</strong> 스왑을 사용하지 않도록 설정한다.</li></ul><h2 id=verify-mac-address>MAC 주소 및 product_uuid가 모든 노드에 대해 고유한지 확인</h2><ul><li>사용자는 <code>ip link</code> 또는 <code>ifconfig -a</code> 명령을 사용하여 네트워크 인터페이스의 MAC 주소를 확인할 수 있다.</li><li>product_uuid는 <code>sudo cat /sys/class/dmi/id/product_uuid</code> 명령을 사용하여 확인할 수 있다.</li></ul><p>일부 가상 머신은 동일한 값을 가질 수 있지만 하드웨어 장치는 고유한 주소를 가질
가능성이 높다. 쿠버네티스는 이러한 값을 사용하여 클러스터의 노드를 고유하게 식별한다.
이러한 값이 각 노드에 고유하지 않으면 설치 프로세스가
<a href=https://github.com/kubernetes/kubeadm/issues/31>실패</a>할 수 있다.</p><h2 id=네트워크-어댑터-확인>네트워크 어댑터 확인</h2><p>네트워크 어댑터가 두 개 이상이고, 쿠버네티스 컴포넌트가 디폴트 라우트(default route)에서 도달할 수 없는
경우, 쿠버네티스 클러스터 주소가 적절한 어댑터를 통해 이동하도록 IP 경로를 추가하는 것이 좋다.</p><h2 id=check-required-ports>필수 포트 확인</h2><p><a href=/ko/docs/reference/ports-and-protocols/>필수 포트들</a>은
쿠버네티스 컴포넌트들이 서로 통신하기 위해서 열려 있어야
한다. 다음과 같이 netcat과 같은 도구를 이용하여 포트가 열려 있는지 확인해 볼 수 있다.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>nc 127.0.0.1 <span style=color:#666>6443</span>
</span></span></code></pre></div><p>사용자가 사용하는 파드 네트워크 플러그인은 특정 포트를 열어야 할 수도
있다. 이것은 각 파드 네트워크 플러그인마다 다르므로, 필요한 포트에 대한
플러그인 문서를 참고한다.</p><h2 id=installing-runtime>컨테이너 런타임 설치</h2><p>파드에서 컨테이너를 실행하기 위해, 쿠버네티스는
<a class=glossary-tooltip title='컨테이너 런타임은 컨테이너 실행을 담당하는 소프트웨어이다.' data-toggle=tooltip data-placement=top href=/ko/docs/setup/production-environment/container-runtimes/ target=_blank aria-label='컨테이너 런타임'>컨테이너 런타임</a>을 사용한다.</p><p>기본적으로, 쿠버네티스는
<a class=glossary-tooltip title='Kubelet과 컨테이너 런타임을 통합시키기 위한 API' data-toggle=tooltip data-placement=top href=/ko/docs/concepts/overview/components/#%ec%bb%a8%ed%85%8c%ec%9d%b4%eb%84%88-%eb%9f%b0%ed%83%80%ec%9e%84 target=_blank aria-label='컨테이너 런타임 인터페이스'>컨테이너 런타임 인터페이스</a>(CRI)를
사용하여 사용자가 선택한 컨테이너 런타임과 인터페이스한다.</p><p>런타임을 지정하지 않으면, kubeadm은 잘 알려진 엔드포인트를 스캐닝하여
설치된 컨테이너 런타임을 자동으로 감지하려고 한다.</p><p>컨테이너 런타임이 여러 개 감지되거나 하나도 감지되지 않은 경우,
kubeadm은 에러를 반환하고 사용자가 어떤 것을 사용할지를 명시하도록 요청할 것이다.</p><p>더 많은 정보는
<a href=/ko/docs/setup/production-environment/container-runtimes/>컨테이너 런타임</a>을 참고한다.</p><div class="alert alert-info note callout" role=alert><strong>참고:</strong> 도커 엔진은 컨테이너 런타임이 쿠버네티스와 호환되기 위한 요구 사항인
<a href=/ko/docs/concepts/architecture/cri/>CRI</a>를 만족하지 않는다.
이러한 이유로, 추가 서비스인 <a href=https://github.com/Mirantis/cri-dockerd>cri-dockerd</a>가 설치되어야 한다.
cri-dockerd는 쿠버네티스 버전 1.24부터 kubelet에서 <a href=/dockershim/>제거</a>된
기존 내장 도커 엔진 지원을 기반으로 한 프로젝트이다.</div><p>아래 표는 지원 운영 체제에 대한 알려진 엔드포인트를 담고 있다.</p><ul class="nav nav-tabs" id=container-runtime role=tablist><li class=nav-item><a data-toggle=tab class="nav-link active" href=#container-runtime-0 role=tab aria-controls=container-runtime-0 aria-selected=true>리눅스</a></li><li class=nav-item><a data-toggle=tab class=nav-link href=#container-runtime-1 role=tab aria-controls=container-runtime-1>윈도우</a></li></ul><div class=tab-content id=container-runtime><div id=container-runtime-0 class="tab-pane show active" role=tabpanel aria-labelledby=container-runtime-0><p><table><caption style=display:none>리눅스 컨테이너 런타임</caption><thead><tr><th>런타임</th><th>유닉스 도메인 소켓 경로</th></tr></thead><tbody><tr><td>containerd</td><td><code>unix:///var/run/containerd/containerd.sock</code></td></tr><tr><td>CRI-O</td><td><code>unix:///var/run/crio/crio.sock</code></td></tr><tr><td>도커 엔진 (cri-dockerd 사용)</td><td><code>unix:///var/run/cri-dockerd.sock</code></td></tr></tbody></table></div><div id=container-runtime-1 class=tab-pane role=tabpanel aria-labelledby=container-runtime-1><p><table><caption style=display:none>윈도우 컨테이너 런타임</caption><thead><tr><th>런타임</th><th>윈도우 네임드 파이프(named pipe) 경로</th></tr></thead><tbody><tr><td>containerd</td><td><code>npipe:////./pipe/containerd-containerd</code></td></tr><tr><td>도커 엔진 (cri-dockerd 사용)</td><td><code>npipe:////./pipe/cri-dockerd</code></td></tr></tbody></table></div></div><h2 id=kubeadm-kubelet-및-kubectl-설치>kubeadm, kubelet 및 kubectl 설치</h2><p>모든 머신에 다음 패키지들을 설치한다.</p><ul><li><p><code>kubeadm</code>: 클러스터를 부트스트랩하는 명령이다.</p></li><li><p><code>kubelet</code>: 클러스터의 모든 머신에서 실행되는 파드와 컨테이너 시작과
같은 작업을 수행하는 컴포넌트이다.</p></li><li><p><code>kubectl</code>: 클러스터와 통신하기 위한 커맨드 라인 유틸리티이다.</p></li></ul><p>kubeadm은 <code>kubelet</code> 또는 <code>kubectl</code> 을 설치하거나 관리하지 <strong>않으므로</strong>, kubeadm이
설치하려는 쿠버네티스 컨트롤 플레인의 버전과 일치하는지
확인해야 한다. 그렇지 않으면, 예상치 못한 버그 동작으로 이어질 수 있는
버전 차이(skew)가 발생할 위험이 있다. 그러나, kubelet과 컨트롤 플레인 사이에 <em>하나의</em>
마이너 버전 차이가 지원되지만, kubelet 버전은 API 서버 버전 보다
높을 수 없다. 예를 들어, 1.7.0 버전의 kubelet은 1.8.0 API 서버와 완전히 호환되어야 하지만,
그 반대의 경우는 아니다.</p><p><code>kubectl</code> 설치에 대한 정보는 <a href=/ko/docs/tasks/tools/>kubectl 설치 및 설정</a>을 참고한다.</p><div class="alert alert-danger warning callout" role=alert><strong>경고:</strong> 이 지침은 모든 시스템 업그레이드에서 모든 쿠버네티스 패키지를 제외한다.
이는 kubeadm 및 쿠버네티스를
<a href=/ko/docs/tasks/administer-cluster/kubeadm/kubeadm-upgrade/>업그레이드 하는 데 특별한 주의</a>가 필요하기 때문이다.</div><p>버전 차이에 대한 자세한 내용은 다음을 참고한다.</p><ul><li>쿠버네티스 <a href=/ko/releases/version-skew-policy/>버전 및 버전-차이 정책</a></li><li>Kubeadm 관련 <a href=/docs/setup/production-environment/tools/kubeadm/create-cluster-kubeadm/#version-skew-policy>버전 차이 정책</a></li></ul><ul class="nav nav-tabs" id=k8s-install role=tablist><li class=nav-item><a data-toggle=tab class="nav-link active" href=#k8s-install-0 role=tab aria-controls=k8s-install-0 aria-selected=true>데비안 기반 배포판</a></li><li class=nav-item><a data-toggle=tab class=nav-link href=#k8s-install-1 role=tab aria-controls=k8s-install-1>레드햇 기반 배포판</a></li><li class=nav-item><a data-toggle=tab class=nav-link href=#k8s-install-2 role=tab aria-controls=k8s-install-2>패키지 매니저를 사용하지 않는 경우</a></li></ul><div class=tab-content id=k8s-install><div id=k8s-install-0 class="tab-pane show active" role=tabpanel aria-labelledby=k8s-install-0><p><ol><li><p><code>apt</code> 패키지 색인을 업데이트하고, 쿠버네티스 <code>apt</code> 리포지터리를 사용하는 데 필요한 패키지를 설치한다.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>sudo apt-get update
</span></span><span style=display:flex><span>sudo apt-get install -y apt-transport-https ca-certificates curl
</span></span></code></pre></div></li><li><p>구글 클라우드의 공개 사이닝 키를 다운로드 한다.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>sudo curl -fsSLo /usr/share/keyrings/kubernetes-archive-keyring.gpg https://packages.cloud.google.com/apt/doc/apt-key.gpg
</span></span></code></pre></div></li><li><p>쿠버네티스 <code>apt</code> 리포지터리를 추가한다.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span><span style=color:#a2f>echo</span> <span style=color:#b44>&#34;deb [signed-by=/usr/share/keyrings/kubernetes-archive-keyring.gpg] https://apt.kubernetes.io/ kubernetes-xenial main&#34;</span> | sudo tee /etc/apt/sources.list.d/kubernetes.list
</span></span></code></pre></div></li><li><p><code>apt</code> 패키지 색인을 업데이트하고, kubelet, kubeadm, kubectl을 설치하고 해당 버전을 고정한다.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>sudo apt-get update
</span></span><span style=display:flex><span>sudo apt-get install -y kubelet kubeadm kubectl
</span></span><span style=display:flex><span>sudo apt-mark hold kubelet kubeadm kubectl
</span></span></code></pre></div></li></ol></div><div id=k8s-install-1 class=tab-pane role=tabpanel aria-labelledby=k8s-install-1><p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>cat <span style=color:#b44>&lt;&lt;EOF | sudo tee /etc/yum.repos.d/kubernetes.repo
</span></span></span><span style=display:flex><span><span style=color:#b44>[kubernetes]
</span></span></span><span style=display:flex><span><span style=color:#b44>name=Kubernetes
</span></span></span><span style=display:flex><span><span style=color:#b44>baseurl=https://packages.cloud.google.com/yum/repos/kubernetes-el7-\$basearch
</span></span></span><span style=display:flex><span><span style=color:#b44>enabled=1
</span></span></span><span style=display:flex><span><span style=color:#b44>gpgcheck=1
</span></span></span><span style=display:flex><span><span style=color:#b44>gpgkey=https://packages.cloud.google.com/yum/doc/yum-key.gpg https://packages.cloud.google.com/yum/doc/rpm-package-key.gpg
</span></span></span><span style=display:flex><span><span style=color:#b44>exclude=kubelet kubeadm kubectl
</span></span></span><span style=display:flex><span><span style=color:#b44>EOF</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#080;font-style:italic># permissive 모드로 SELinux 설정(효과적으로 비활성화)</span>
</span></span><span style=display:flex><span>sudo setenforce <span style=color:#666>0</span>
</span></span><span style=display:flex><span>sudo sed -i <span style=color:#b44>&#39;s/^SELINUX=enforcing$/SELINUX=permissive/&#39;</span> /etc/selinux/config
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>sudo yum install -y kubelet kubeadm kubectl --disableexcludes<span style=color:#666>=</span>kubernetes
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>sudo systemctl <span style=color:#a2f>enable</span> --now kubelet
</span></span></code></pre></div><p><strong>참고:</strong></p><ul><li><p><code>setenforce 0</code> 및 <code>sed ...</code> 를 실행하여 permissive 모드로 SELinux를 설정하면 효과적으로 비활성화된다.
컨테이너가 호스트 파일시스템(예를 들어, 파드 네트워크에 필요한)에 접근하도록 허용하는 데 필요하다.
kubelet에서 SELinux 지원이 개선될 때까지 이 작업을 수행해야 한다.</p></li><li><p>구성 방법을 알고 있는 경우 SELinux를 활성화된 상태로 둘 수 있지만 kubeadm에서 지원하지 않는 설정이 필요할 수 있다.</p></li><li><p>사용 중인 레드햇 배포판이 <code>basearch</code>를 해석하지 못하여 <code>baseurl</code>이 실패하면, <code>\$basearch</code>를 당신의 컴퓨터의 아키텍처로 치환한다.
<code>uname -m</code> 명령을 실행하여 해당 값을 확인한다.
예를 들어, <code>x86_64</code>에 대한 <code>baseurl</code> URL은 <code>https://packages.cloud.google.com/yum/repos/kubernetes-el7-x86_64</code> 이다.</p></li></ul></div><div id=k8s-install-2 class=tab-pane role=tabpanel aria-labelledby=k8s-install-2><p><p>CNI 플러그인 설치(대부분의 파드 네트워크에 필요)</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#b8860b>CNI_PLUGINS_VERSION</span><span style=color:#666>=</span><span style=color:#b44>&#34;v1.1.1&#34;</span>
</span></span><span style=display:flex><span><span style=color:#b8860b>ARCH</span><span style=color:#666>=</span><span style=color:#b44>&#34;amd64&#34;</span>
</span></span><span style=display:flex><span><span style=color:#b8860b>DEST</span><span style=color:#666>=</span><span style=color:#b44>&#34;/opt/cni/bin&#34;</span>
</span></span><span style=display:flex><span>sudo mkdir -p <span style=color:#b44>&#34;</span><span style=color:#b8860b>$DEST</span><span style=color:#b44>&#34;</span>
</span></span><span style=display:flex><span>curl -L <span style=color:#b44>&#34;https://github.com/containernetworking/plugins/releases/download/</span><span style=color:#b68;font-weight:700>${</span><span style=color:#b8860b>CNI_PLUGINS_VERSION</span><span style=color:#b68;font-weight:700>}</span><span style=color:#b44>/cni-plugins-linux-</span><span style=color:#b68;font-weight:700>${</span><span style=color:#b8860b>ARCH</span><span style=color:#b68;font-weight:700>}</span><span style=color:#b44>-</span><span style=color:#b68;font-weight:700>${</span><span style=color:#b8860b>CNI_PLUGINS_VERSION</span><span style=color:#b68;font-weight:700>}</span><span style=color:#b44>.tgz&#34;</span> | sudo tar -C <span style=color:#b44>&#34;</span><span style=color:#b8860b>$DEST</span><span style=color:#b44>&#34;</span> -xz
</span></span></code></pre></div><p>명령어 파일을 다운로드할 디렉터리 정의</p><div class="alert alert-info note callout" role=alert><strong>참고:</strong> <code>DOWNLOAD_DIR</code> 변수는 쓰기 가능한 디렉터리로 설정되어야 한다.
Flatcar Container Linux를 실행 중인 경우, <code>DOWNLOAD_DIR="/opt/bin"</code> 을 설정한다.</div><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#b8860b>DOWNLOAD_DIR</span><span style=color:#666>=</span><span style=color:#b44>&#34;/usr/local/bin&#34;</span>
</span></span><span style=display:flex><span>sudo mkdir -p <span style=color:#b44>&#34;</span><span style=color:#b8860b>$DOWNLOAD_DIR</span><span style=color:#b44>&#34;</span>
</span></span></code></pre></div><p>crictl 설치(kubeadm / Kubelet 컨테이너 런타임 인터페이스(CRI)에 필요)</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#b8860b>CRICTL_VERSION</span><span style=color:#666>=</span><span style=color:#b44>&#34;v1.25.0&#34;</span>
</span></span><span style=display:flex><span><span style=color:#b8860b>ARCH</span><span style=color:#666>=</span><span style=color:#b44>&#34;amd64&#34;</span>
</span></span><span style=display:flex><span>curl -L <span style=color:#b44>&#34;https://github.com/kubernetes-sigs/cri-tools/releases/download/</span><span style=color:#b68;font-weight:700>${</span><span style=color:#b8860b>CRICTL_VERSION</span><span style=color:#b68;font-weight:700>}</span><span style=color:#b44>/crictl-</span><span style=color:#b68;font-weight:700>${</span><span style=color:#b8860b>CRICTL_VERSION</span><span style=color:#b68;font-weight:700>}</span><span style=color:#b44>-linux-</span><span style=color:#b68;font-weight:700>${</span><span style=color:#b8860b>ARCH</span><span style=color:#b68;font-weight:700>}</span><span style=color:#b44>.tar.gz&#34;</span> | sudo tar -C <span style=color:#b8860b>$DOWNLOAD_DIR</span> -xz
</span></span></code></pre></div><p><code>kubeadm</code>, <code>kubelet</code>, <code>kubectl</code> 설치 및 <code>kubelet</code> systemd 서비스 추가</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#b8860b>RELEASE</span><span style=color:#666>=</span><span style=color:#b44>&#34;</span><span style=color:#a2f;font-weight:700>$(</span>curl -sSL https://dl.k8s.io/release/stable.txt<span style=color:#a2f;font-weight:700>)</span><span style=color:#b44>&#34;</span>
</span></span><span style=display:flex><span><span style=color:#b8860b>ARCH</span><span style=color:#666>=</span><span style=color:#b44>&#34;amd64&#34;</span>
</span></span><span style=display:flex><span><span style=color:#a2f>cd</span> <span style=color:#b8860b>$DOWNLOAD_DIR</span>
</span></span><span style=display:flex><span>sudo curl -L --remote-name-all https://storage.googleapis.com/kubernetes-release/release/<span style=color:#b68;font-weight:700>${</span><span style=color:#b8860b>RELEASE</span><span style=color:#b68;font-weight:700>}</span>/bin/linux/<span style=color:#b68;font-weight:700>${</span><span style=color:#b8860b>ARCH</span><span style=color:#b68;font-weight:700>}</span>/<span style=color:#666>{</span>kubeadm,kubelet,kubectl<span style=color:#666>}</span>
</span></span><span style=display:flex><span>sudo chmod +x <span style=color:#666>{</span>kubeadm,kubelet,kubectl<span style=color:#666>}</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#b8860b>RELEASE_VERSION</span><span style=color:#666>=</span><span style=color:#b44>&#34;v0.4.0&#34;</span>
</span></span><span style=display:flex><span>curl -sSL <span style=color:#b44>&#34;https://raw.githubusercontent.com/kubernetes/release/</span><span style=color:#b68;font-weight:700>${</span><span style=color:#b8860b>RELEASE_VERSION</span><span style=color:#b68;font-weight:700>}</span><span style=color:#b44>/cmd/kubepkg/templates/latest/deb/kubelet/lib/systemd/system/kubelet.service&#34;</span> | sed <span style=color:#b44>&#34;s:/usr/bin:</span><span style=color:#b68;font-weight:700>${</span><span style=color:#b8860b>DOWNLOAD_DIR</span><span style=color:#b68;font-weight:700>}</span><span style=color:#b44>:g&#34;</span> | sudo tee /etc/systemd/system/kubelet.service
</span></span><span style=display:flex><span>sudo mkdir -p /etc/systemd/system/kubelet.service.d
</span></span><span style=display:flex><span>curl -sSL <span style=color:#b44>&#34;https://raw.githubusercontent.com/kubernetes/release/</span><span style=color:#b68;font-weight:700>${</span><span style=color:#b8860b>RELEASE_VERSION</span><span style=color:#b68;font-weight:700>}</span><span style=color:#b44>/cmd/kubepkg/templates/latest/deb/kubeadm/10-kubeadm.conf&#34;</span> | sed <span style=color:#b44>&#34;s:/usr/bin:</span><span style=color:#b68;font-weight:700>${</span><span style=color:#b8860b>DOWNLOAD_DIR</span><span style=color:#b68;font-weight:700>}</span><span style=color:#b44>:g&#34;</span> | sudo tee /etc/systemd/system/kubelet.service.d/10-kubeadm.conf
</span></span></code></pre></div><p><code>kubelet</code> 활성화 및 시작</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>systemctl <span style=color:#a2f>enable</span> --now kubelet
</span></span></code></pre></div><div class="alert alert-info note callout" role=alert><strong>참고:</strong> Flatcar Container Linux 배포판은 <code>/usr</code> 디렉터리를 읽기 전용 파일시스템으로 마운트한다.
클러스터를 부트스트랩하기 전에, 쓰기 가능한 디렉터리를 구성하기 위한 추가 단계를 수행해야 한다.
쓰기 가능한 디렉터리를 설정하는 방법을 알아 보려면 <a href=/docs/setup/production-environment/tools/kubeadm/troubleshooting-kubeadm/#usr-mounted-read-only/>Kubeadm 문제 해결 가이드</a>를 참고한다.</div></div></div><p>kubelet은 이제 kubeadm이 수행할 작업을 알려 줄 때까지 크래시루프(crashloop) 상태로
기다려야 하므로 몇 초마다 다시 시작된다.</p><h2 id=cgroup-드라이버-구성>cgroup 드라이버 구성</h2><p>컨테이너 런타임과 kubelet은
<a href=/ko/docs/setup/production-environment/container-runtimes/>"cgroup 드라이버"</a>라는 속성을 갖고 있으며,
cgroup 드라이버는 리눅스 머신의 cgroup 관리 측면에 있어서 중요하다.</p><div class="alert alert-danger warning callout" role=alert><strong>경고:</strong><p>컨테이너 런타임과 kubelet의 cgroup 드라이버를 일치시켜야 하며, 그렇지 않으면 kubelet 프로세스에 오류가 발생한다.</p><p>더 자세한 사항은 <a href=/docs/tasks/administer-cluster/kubeadm/configure-cgroup-driver/>cgroup 드라이버 설정하기</a>를 참고한다.</p></div><h2 id=문제-해결>문제 해결</h2><p>kubeadm에 문제가 있는 경우, <a href=/docs/setup/production-environment/tools/kubeadm/troubleshooting-kubeadm/>문제 해결 문서</a>를 참고한다.</p><h2 id=다음-내용>다음 내용</h2><ul><li><a href=/docs/setup/production-environment/tools/kubeadm/create-cluster-kubeadm/>kubeadm을 사용하여 클러스터 생성</a></li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-4c656c5eda3e1c06ad1aedebdc04a211>2.2.1.2 - kubeadm API로 컴포넌트 사용자 정의하기</h1><p>이 페이지는 kubeadm이 배포하는 컴포넌트(component)들을 사용자 정의하는 방법을 다룬다. 컨트롤 플레인 컴포넌트에
대해서는 <code>Cluster Configuration</code> 구조에서 플래그를 사용하거나 노드당 패치를 사용할 수 있다. kubelet과
kube-proxy의 경우, <code>KubeletConfiguration</code>과 <code>KubeProxyConfiguration</code>을 각각 사용할 수 있다.</p><p>이 모든 옵션이 kubeadm 구성 API를 통해 가용하다.
구성의 각 필드 상세 사항은
<a href=/docs/reference/config-api/kubeadm-config.v1beta3/>API 참조 페이지</a>에서 찾아볼 수 있다.</p><div class="alert alert-info note callout" role=alert><strong>참고:</strong> kubeadm의 CoreDNS 디플로이먼트 사용자 정의는 현재 제공되지 않는다.
<code>kube-system/coredns</code> <a class=glossary-tooltip title='키-값 쌍으로 기밀이 아닌 데이터를 저장하는 데 사용하는 API 오브젝트이다. 볼륨에서 환경 변수, 커맨드-라인 인수 또는 구성 파일로 사용될 수 있다.' data-toggle=tooltip data-placement=top href=/ko/docs/concepts/configuration/configmap/ target=_blank aria-label=컨피그맵>컨피그맵</a>을 수동으로
패치하고, 그 이후에 CoreDNS <a class=glossary-tooltip title='파드는 클러스터에서 실행 중인 컨테이너의 집합을 나타낸다.' data-toggle=tooltip data-placement=top href=/ko/docs/concepts/workloads/pods/ target=_blank aria-label=파드>파드</a>를 다시 생성해야 한다. 또는,
기본 CoreDNS 디플로이먼트를 생략하고 자체 변형(variant)을 배포할 수 있다.
더 자세한 사항은 <a href=/docs/reference/setup-tools/kubeadm/kubeadm-init/#init-phases>kubeadm에서 초기화 단계 사용하기</a>을 참고한다.</div><div class="alert alert-info note callout" role=alert><strong>참고:</strong> 이미 생성된 클러스터를 다시 구성하려면
<a href=/docs/tasks/administer-cluster/kubeadm/kubeadm-reconfigure/>kubeadm 클러스터 다시 구성하기</a>를 참고한다.</div><h2 id=clusterconfiguration-의-플래그로-컨트롤-플레인-사용자-정의하기><code>ClusterConfiguration</code>의 플래그로 컨트롤 플레인 사용자 정의하기</h2><p>kubeadm의 <code>ClusterConfiguration</code> 오브젝트는 API 서버, 컨트롤러매니저, 스케줄러, Etcd와 같은 컨트롤 플레인 컴포넌트에 전달되는
기본 플래그를 사용자가 덮어쓸 수 있도록 노출한다.
이 컴포넌트는 다음 구조체를 사용하여 정의된다.</p><ul><li><code>apiServer</code></li><li><code>controllerManager</code></li><li><code>scheduler</code></li><li><code>etcd</code></li></ul><p>이 구조체들은 공통 필드인 <code>extraArgs</code>를 포함하며, 이 필드는 <code>키: 값</code> 쌍으로 구성된다.
컨트롤 플레인 컴포넌트를 위한 플래그를 덮어쓰려면 다음을 수행한다.</p><ol><li>사용자 구성에 적절한 <code>extraArgs</code> 필드를 추가한다.</li><li><code>extraArgs</code> 필드에 플래그를 추가한다.</li><li><code>kubeadm init</code>에 <code>--config &lt;CONFIG YAML 파일></code> 파라미터를 추가해서 실행한다.</li></ol><div class="alert alert-info note callout" role=alert><strong>참고:</strong> <code>kubeadm config print init-defaults</code>를 실행하고 원하는 파일에 출력을
저장하여 기본값들로 구성된 <code>ClusterConfiguration</code> 오브젝트를 생성할 수 있다.</div><div class="alert alert-info note callout" role=alert><strong>참고:</strong> <code>ClusterConfiguration</code> 오브젝트는 현재 kubeadm 클러스터에서 전역(global)으로 사용된다. 즉, 사용자가 추가하는 모든 플래그는
다른 노드에 있는 동일한 컴포넌트에도 모두 적용될 것이다. 다른 노드에서
컴포넌트별로 개별 구성을 적용하려면 <a href=#patches>패치</a>를 사용하면 된다.</div><div class="alert alert-info note callout" role=alert><strong>참고:</strong> 플래그(키)를 복제하거나 동일한 플래그 <code>--foo</code>를 여러 번 전달하는 것은 현재 지원하지 않는다.
이 문제를 해결하려면 <a href=#patches>패치</a>를 사용해야 한다.</div><h3 id=apiserver-플래그>APIServer 플래그</h3><p>자세한 내용은 <a href=/docs/reference/command-line-tools-reference/kube-apiserver/>kube-apiserver 레퍼런스 문서</a>를 확인한다.</p><p>사용 예시:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>kubeadm.k8s.io/v1beta3<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>ClusterConfiguration<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kubernetesVersion</span>:<span style=color:#bbb> </span>v1.16.0<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>apiServer</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>extraArgs</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>anonymous-auth</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;false&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>enable-admission-plugins</span>:<span style=color:#bbb> </span>AlwaysPullImages,DefaultStorageClass<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>audit-log-path</span>:<span style=color:#bbb> </span>/home/johndoe/audit.log<span style=color:#bbb>
</span></span></span></code></pre></div><h3 id=컨트롤러매니저-플래그>컨트롤러매니저 플래그</h3><p>자세한 내용은 <a href=/docs/reference/command-line-tools-reference/kube-controller-manager/>kube-controller-manager 레퍼런스 문서</a>를 확인한다.</p><p>사용 예시:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>kubeadm.k8s.io/v1beta3<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>ClusterConfiguration<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kubernetesVersion</span>:<span style=color:#bbb> </span>v1.16.0<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>controllerManager</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>extraArgs</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>cluster-signing-key-file</span>:<span style=color:#bbb> </span>/home/johndoe/keys/ca.key<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>deployment-controller-sync-period</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;50&#34;</span><span style=color:#bbb>
</span></span></span></code></pre></div><h3 id=스케줄러-플래그>스케줄러 플래그</h3><p>자세한 내용은 <a href=/docs/reference/command-line-tools-reference/kube-scheduler/>kube-scheduler 레퍼런스 문서</a>를 확인한다.</p><p>사용 예시:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>kubeadm.k8s.io/v1beta3<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>ClusterConfiguration<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kubernetesVersion</span>:<span style=color:#bbb> </span>v1.16.0<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>scheduler</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>extraArgs</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>config</span>:<span style=color:#bbb> </span>/etc/kubernetes/scheduler-config.yaml<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>extraVolumes</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>schedulerconfig<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>hostPath</span>:<span style=color:#bbb> </span>/home/johndoe/schedconfig.yaml<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>mountPath</span>:<span style=color:#bbb> </span>/etc/kubernetes/scheduler-config.yaml<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>readOnly</span>:<span style=color:#bbb> </span><span style=color:#a2f;font-weight:700>true</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>pathType</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;File&#34;</span><span style=color:#bbb>
</span></span></span></code></pre></div><h3 id=etcd-플래그>Etcd 플래그</h3><p>자세한 사항은 <a href=https://etcd.io/docs/>etcd 서버 문서</a>를 확인한다.</p><p>사용 예시:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>kubeadm.k8s.io/v1beta3<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>ClusterConfiguration<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>etcd</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>local</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>extraArgs</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>election-timeout</span>:<span style=color:#bbb> </span><span style=color:#666>1000</span><span style=color:#bbb>
</span></span></span></code></pre></div><h2 id=patches>패치를 통해 사용자 정의하기</h2><div style=margin-top:10px;margin-bottom:10px><b>기능 상태:</b> <code>Kubernetes v1.22 [beta]</code></div><p>Kubeadm을 사용하면 패치 파일이 있는 디렉토리를 개별 노드에 대한 <code>InitConfiguration</code>과 <code>JoinConfiguration</code>에
전달할 수 있다. 이 패치는 컴포넌트 구성이 디스크에 기록되기 전에 최종 사용자 정의 단계로
사용될 수 있다.</p><p><code>--config &lt;YOUR CONFIG YAML></code>을 사용하여 이 파일을 <code>kubeadm init</code>에 전달할 수 있다.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>kubeadm.k8s.io/v1beta3<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>InitConfiguration<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>patches</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>directory</span>:<span style=color:#bbb> </span>/home/user/somedir<span style=color:#bbb>
</span></span></span></code></pre></div><div class="alert alert-info note callout" role=alert><strong>참고:</strong> <code>kubeadm init</code>의 경우, <code>---</code>로 구분된 <code>ClusterConfiguration</code>과 <code>InitConfiguration</code>을 모두
포함하는 파일을 전달할 수 있다.</div><p><code>--config &lt;YOUR CONFIG YAML></code>을 사용하여 이 파일을 <code>kubeadm join</code>에 전달할 수 있다.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>kubeadm.k8s.io/v1beta3<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>JoinConfiguration<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>patches</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>directory</span>:<span style=color:#bbb> </span>/home/user/somedir<span style=color:#bbb>
</span></span></span></code></pre></div><p>디렉토리는 <code>target[suffix][+patchtype].extension</code> 형태의 파일을 포함해야 한다.
예를 들면, <code>kube-apiserver0+merge.yaml</code> 또는 단순히 <code>etcd.json</code>의 형태이다.</p><ul><li><code>target</code>은 <code>kube-apiserver</code>, <code>kube-controller-manager</code>, <code>kube-scheduler</code>, <code>etcd</code>
그리고 <code>kubeletconfiguration</code> 중 하나가 될 수 있다.</li><li><code>patchtype</code>은 <code>strategic</code>, <code>merge</code> 그리고 <code>json</code> 중 하나가 될 수 있으며
<a href=/docs/tasks/manage-kubernetes-objects/update-api-object-kubectl-patch>kubectl에서 지원하는</a> 패치 형식을 준수해야 한다.
<code>patchtype</code>의 기본값은 <code>strategic</code>이다.</li><li><code>extension</code>은 <code>json</code> 또는 <code>yaml</code> 중 하나여야 한다.</li><li><code>suffix</code>는 어떤 패치가 먼저 적용되는지를 결정하는 데 사용할 수 있는 영숫자 형태의
선택적 문자열이다.</li></ul><div class="alert alert-info note callout" role=alert><strong>참고:</strong> <code>kubeadm upgrade</code>를 사용하여 kubeadm 노드를 업그레이드하는 경우, 업그레이드 이후에도
사용자 정의를 유지하려면 동일한 패치를 다시 제공해야 한다. 이는 동일한 디렉토리로 지정된 <code>--patches</code>
플래그를 사용하여 처리할 수 있다. <code>kubeadm upgrade</code>는 동일 목적으로 재사용할 수 있는 구성
API 구조를 현재는 지원하지 않는다.</div><h2 id=kubelet>kubelet 사용자 정의하기</h2><p>kubelet을 사용자 정의하려면, <a href=/docs/reference/config-api/kubelet-config.v1beta1/><code>KubeletConfiguration</code></a>을
동일한 구성 파일 내에서 <code>---</code>로 구분된 <code>ClusterConfiguration</code>이나 <code>InitConfiguration</code> 다음에 추가하면 된다.
그런 다음 <code>kubeadm init</code>에 해당 파일을 전달하면, kubeadm은 동일한 기본 <code>KubeletConfiguration</code>을
클러스터의 모든 노드에 적용한다.</p><p>기본 <code>KubeletConfiguration</code>에 더하여 인스턴스별 구성을 적용하기 위해서는
<a href=#patches><code>kubeletconfiguration</code> 패치 target</a>을 이용할 수 있다.</p><p>다른 방법으로는, kubelet 플래그를 덮어쓰기(overrides)로 사용하여,
<code>InitConfiguration</code> 및 <code>JoinConfiguration</code> 모두에서 지원되는 <code>nodeRegistration.kubeletExtraArgs</code>에 전달할 수 있다.
일부 kubelet 플래그는 더 이상 사용되지 않는다(deprecated). 따라서 사용하기 전에
<a href=/docs/reference/command-line-tools-reference/kubelet>kubelet 참조 문서</a>를 통해 상태를 확인해야 한다.</p><p>이 외 더 자세한 사항은 <a href=/docs/setup/production-environment/tools/kubeadm/kubelet-integration>kubeadm을 통해 클러스터의 각 kubelet 구성하기</a>에서 살펴본다.</p><h2 id=kube-proxy-사용자-정의하기>kube-proxy 사용자 정의하기</h2><p>kube-proxy를 사용자 정의하려면, <code>KubeProxyConfiguration</code>을 <code>---</code>로 구분된 <code>ClusterConfiguration</code>이나 <code>InitConfiguration</code>
다음에 두고 <code>kubeadm init</code>에 전달하면 된다.</p><p>자세한 사항은 <a href=/docs/reference/config-api/kubeadm-config.v1beta3/>API 참조 페이지</a>에서 살펴볼 수 있다.</p><div class="alert alert-info note callout" role=alert><strong>참고:</strong> kubeadm은 kube-proxy를 <a class=glossary-tooltip title='파드의 복제본을 클러스터 노드 집합에서 동작하게 한다.' data-toggle=tooltip data-placement=top href=/ko/docs/concepts/workloads/controllers/daemonset target=_blank aria-label=데몬셋>데몬셋</a>으로 배포한다. 이것은
<code>KubeProxyConfiguration</code>이 클러스터의 모든 kube-proxy 인스턴스에 적용된다는 것을 의미한다.</div></div><div class=td-content style=page-break-before:always><h1 id=pg-015edbc7cc688d31b1d1edce7c186135>2.2.1.3 - 고가용성 토폴로지 선택</h1><p>이 페이지는 고가용성(HA) 쿠버네티스 클러스터의 토플로지를 구성하는 두 가지 선택 사항을 설명한다.</p><p>다음과 같이 HA 클러스터를 구성할 수 있다.</p><ul><li>etcd 노드와 컨트롤 플레인 노드를 함께 위치시키는 중첩된(stacked) 컨트롤 플레인 노드 방식</li><li>etcd와 컨트롤 플레인이 분리된 노드에서 운영되는 외부 etcd 노드 방식</li></ul><p>HA 클러스터를 구성하기 전에 각 토플로지의 장단점을 주의 깊게 고려해야 한다.</p><div class="alert alert-info note callout" role=alert><strong>참고:</strong> kubeadm은 etcd 클러스터를 정적으로 부트스트랩한다. 자세한 내용은 etcd <a href=https://github.com/etcd-io/etcd/blob/release-3.4/Documentation/op-guide/clustering.md#static>클러스터 구성 가이드</a>
를 읽는다.</div><h2 id=중첩된-etcd-토플로지>중첩된 etcd 토플로지</h2><p>중첩된 HA 클러스터는 etcd에서 제공하는 분산 데이터 저장소 클러스터를,
컨트롤 플레인 구성 요소를 실행하는 kubeadm으로 관리되는 노드에 의해서 형성된 클러스터 상단에
중첩하는 <a href=https://en.wikipedia.org/wiki/Network_topology>토플로지</a>이다.</p><p>각 컨트롤 플레인 노드는 <code>kube-apiserver</code>, <code>kube-scheduler</code>, <code>kube-controller-manager</code> 인스턴스를 운영한다.
<code>kube-apiserver</code>는 로드 밸런서를 이용하여 워커 노드에 노출되어 있다.</p><p>각 컨트롤 플레인 노드는 지역 etcd 맴버를 생성하고
이 etcd 맴버는 오직 해당 노드의 <code>kube-apiserver</code>와 통신한다.
비슷한 방식이 지역의 <code>kube-controller-manager</code>와 <code>kube-scheduler</code>에도 적용된다.</p><p>이 토플로지는 컨트롤 플레인과 etcd 맴버가 같은 노드에 묶여 있다.
이는 외부 etcd 노드의 클러스터를 구성하는 것보다는 단순하며 복제 관리도 간단하다.</p><p>그러나 중첩된 클러스터는 커플링에 실패할 위험이 있다. 한 노드가 다운되면 etcd 맴버와 컨트롤 플레인을 모두 잃어버리고,
중복성도 손상된다. 더 많은 컨트롤 플레인 노드를 추가하여 이 위험을 완화할 수 있다.</p><p>그러므로 HA 클러스터를 위해 최소 3개인 중첩된 컨트롤 플레인 노드를 운영해야 한다.</p><p>이는 kubeadm의 기본 토플로지이다. 지역 etcd 맴버는
<code>kubeadm init</code>와 <code>kubeadm join --control-plane</code> 을 이용할 때에 컨트롤 플레인 노드에 자동으로 생성된다.</p><p><img src=/images/kubeadm/kubeadm-ha-topology-stacked-etcd.svg alt="중첩된 etcd 토플로지"></p><h2 id=외부-etcd-토플로지>외부 etcd 토플로지</h2><p>외부 etcd를 이용하는 HA 클러스터는 etcd로 제공한 분산된 데이터 스토리지 클러스터가 컨트롤 플레인 구성 요소를 운영하는 노드로 형성하는 클러스터의 외부에 있는 <a href=https://en.wikipedia.org/wiki/Network_topology>토플로지</a>이다.</p><p>중첩된 etcd 토플로지와 유사하게, 외부 etcd 토플로지에 각 컨트롤 플레인 노드는 <code>kube-apiserver</code>, <code>kube-scheduler</code>, <code>kube-controller-manager</code>의 인스턴스를 운영한다. 그리고 <code>kube-apiserver</code>는 로드 밸런서를 이용하여 워커노드에 노출한다. 그러나 etcd 맴버는 분리된 호스트에서 운영되고, 각 etcd 호스트는 각 컨트롤 플레인 노드의 <code>kube-apiserver</code>와 통신한다.</p><p>이 토플로지는 컨트롤 플레인과 etcd 맴버를 분리한다. 이는 그러므로
컨트롤 플레인 인스턴스나 etcd 맴버를 잃는 충격이 덜하고,
클러스터 중복성에 있어 중첩된 HA 토플로지만큼 영향을 미치지 않는다.</p><p>그러나, 이 토플로지는 중첩된 토플로지에 비해 호스트 개수가 두배나 필요하다.
이 토플로지로 HA 클러스터를 구성하기 위해서는 최소한 3개의 컨트롤 플레인과 3개의 etcd 노드가 필요하다.</p><p><img src=/images/kubeadm/kubeadm-ha-topology-external-etcd.svg alt="외부 etcd 토플로지"></p><h2 id=다음-내용>다음 내용</h2><ul><li><a href=/docs/setup/production-environment/tools/kubeadm/high-availability/>kubeadm을 이용하여 고가용성 클러스터 구성하기</a></li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-478acca1934b6d89a0bc00fb25bfe5b6>2.2.2 - Kops로 쿠버네티스 설치하기</h1><p>이곳 빠른 시작에서는 사용자가 얼마나 쉽게 AWS에 쿠버네티스 클러스터를 설치할 수 있는지 보여준다.
<a href=https://github.com/kubernetes/kops><code>kops</code></a>라는 이름의 툴을 이용할 것이다.</p><p>kops는 자동화된 프로비저닝 시스템인데,</p><ul><li>완전 자동화된 설치</li><li>DNS를 통해 클러스터들의 신원 확인</li><li>자체 복구: 모든 자원이 Auto-Scaling Groups에서 실행</li><li>다양한 OS 지원(Debian, Ubuntu 16.04 supported, CentOS & RHEL, Amazon Linux and CoreOS) - <a href=https://github.com/kubernetes/kops/blob/master/docs/operations/images.md>images.md</a> 보기</li><li>고가용성 지원 - <a href=https://github.com/kubernetes/kops/blob/master/docs/operations/high_availability.md>high_availability.md</a> 보기</li><li>직접 프로비저닝 하거나 또는 할 수 있도록 terraform 매니페스트를 생성 - <a href=https://github.com/kubernetes/kops/blob/master/docs/terraform.md>terraform.md</a> 보기</li></ul><h2 id=시작하기-전에>시작하기 전에</h2><ul><li><p><a href=/ko/docs/tasks/tools/>kubectl</a>을 반드시 설치해야 한다.</p></li><li><p>반드시 64-bit (AMD64 그리고 Intel 64)디바이스 아키텍쳐 위에서 <code>kops</code> 를 <a href=https://github.com/kubernetes/kops#installing>설치</a> 한다.</p></li><li><p><a href=https://docs.aws.amazon.com/polly/latest/dg/setting-up.html>AWS 계정</a>이 있고 <a href=https://docs.aws.amazon.com/general/latest/gr/aws-sec-cred-types.html#access-keys-and-secret-access-keys>IAM 키</a>를 생성하고 <a href=https://docs.aws.amazon.com/cli/latest/userguide/cli-chap-configure.html#cli-quick-configuration>구성</a>해야 한다. IAM 사용자는 <a href=https://github.com/kubernetes/kops/blob/master/docs/getting_started/aws.md#setup-iam-user>적절한 권한</a>이 필요하다.</p></li></ul><h2 id=클러스터-구축>클러스터 구축</h2><h3 id=1-5-kops-설치>(1/5) kops 설치</h3><h4 id=설치>설치</h4><p><a href=https://github.com/kubernetes/kops/releases>releases page</a>에서 kops를 다운로드한다(소스 코드로부터 빌드하는 것도 역시 편리하다).</p><ul class="nav nav-tabs" id=kops-installation role=tablist><li class=nav-item><a data-toggle=tab class="nav-link active" href=#kops-installation-0 role=tab aria-controls=kops-installation-0 aria-selected=true>macOS</a></li><li class=nav-item><a data-toggle=tab class=nav-link href=#kops-installation-1 role=tab aria-controls=kops-installation-1>리눅스</a></li></ul><div class=tab-content id=kops-installation><div id=kops-installation-0 class="tab-pane show active" role=tabpanel aria-labelledby=kops-installation-0><p><p>최신 버전의 릴리스를 다운받는 명령어:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>curl -LO https://github.com/kubernetes/kops/releases/download/<span style=color:#a2f;font-weight:700>$(</span>curl -s https://api.github.com/repos/kubernetes/kops/releases/latest
</span></span><span style=display:flex><span>| grep tag_name | cut -d <span style=color:#b44>&#39;&#34;&#39;</span> -f 4<span style=color:#a2f;font-weight:700>)</span>/kops-darwin-amd64
</span></span></code></pre></div><p>특정 버전을 다운로드 받는다면 명령의 다음 부분을 특정 kops 버전으로 변경한다.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span><span style=color:#a2f;font-weight:700>$(</span>curl -s https://api.github.com/repos/kubernetes/kops/releases/latest | grep tag_name | cut -d <span style=color:#b44>&#39;&#34;&#39;</span> -f 4<span style=color:#a2f;font-weight:700>)</span>
</span></span></code></pre></div><p>예를 들어 kops 버전을 v1.20.0을 다운로드 하려면 다음을 입력한다.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>curl -LO https://github.com/kubernetes/kops/releases/download/v1.20.0/kops-darwin-amd64
</span></span></code></pre></div><p>kops 바이너리를 실행 가능하게 만든다.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>chmod +x kops-darwin-amd64
</span></span></code></pre></div><p>kops 바이너리를 사용자의 PATH로 이동한다.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>sudo mv kops-darwin-amd64 /usr/local/bin/kops
</span></span></code></pre></div><p>사용자는 <a href=https://brew.sh/>Homebrew</a>를 이용해서 kops를 설치할 수 있다.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>brew update <span style=color:#666>&amp;&amp;</span> brew install kops
</span></span></code></pre></div></div><div id=kops-installation-1 class=tab-pane role=tabpanel aria-labelledby=kops-installation-1><p><p>최신 릴리스를 다운로드 받는 명령어:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>curl -LO https://github.com/kubernetes/kops/releases/download/<span style=color:#a2f;font-weight:700>$(</span>curl -s https://api.github.com/repos/kubernetes/kops/releases/latest | grep tag_name | cut -d <span style=color:#b44>&#39;&#34;&#39;</span> -f 4<span style=color:#a2f;font-weight:700>)</span>/kops-linux-amd64
</span></span></code></pre></div><p>특정 버전의 kops를 다운로드하려면 명령의 다음 부분을 특정 kops 버전으로 변경한다.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span><span style=color:#a2f;font-weight:700>$(</span>curl -s https://api.github.com/repos/kubernetes/kops/releases/latest | grep tag_name | cut -d <span style=color:#b44>&#39;&#34;&#39;</span> -f 4<span style=color:#a2f;font-weight:700>)</span>
</span></span></code></pre></div><p>예를 들어 kops 버전을 v1.20.0을 다운로드 하려면 다음을 입력한다.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>curl -LO https://github.com/kubernetes/kops/releases/download/v1.20.0/kops-linux-amd64
</span></span></code></pre></div><p>kops 바이너리를 실행 가능하게 만든다.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>chmod +x kops-linux-amd64
</span></span></code></pre></div><p>kops 바이너리를 사용자의 PATH로 이동한다.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>sudo mv kops-linux-amd64 /usr/local/bin/kops
</span></span></code></pre></div><p>사용자는 <a href=https://docs.brew.sh/Homebrew-on-Linux>Homebrew</a>를 이용해서 kops를 설치할 수 있다.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>brew update <span style=color:#666>&amp;&amp;</span> brew install kops
</span></span></code></pre></div></div></div><h3 id=2-5-클러스터에-사용할-route53-domain-생성>(2/5) 클러스터에 사용할 route53 domain 생성</h3><p>kops는 클러스터 내부와 외부 모두에서 검색을 위해 DNS을 사용하기에 클라이언트에서 쿠버네티스 API 서버에 연결할
수 있다.</p><p>이런 클러스터 이름에 kops는 명확한 견해을 가지는데: 반드시 유효한 DNS 이름이어야 한다. 이렇게 함으로써
사용자는 클러스터를 헷갈리지 않을것이고, 동료들과 혼선없이 공유할 수 있으며,
IP를 기억할 필요없이 접근할 수 있다.</p><p>그렇게 하고 있겠지만, 클러스터를 구분하기 위해 서브도메인을 활용할 수 있다. 예를 들어
<code>useast1.dev.example.com</code>을 이용한다면, API 서버 엔드포인트는 <code>api.useast1.dev.example.com</code>가 될 것이다.</p><p>Route53 hosted zone은 서브도메인도 지원한다. 여러분의 hosted zone은 <code>useast1.dev.example.com</code>,
<code>dev.example.com</code> 그리고 <code>example.com</code> 같은 것도 될 수 있다. kops는 이것들 모두와 잘 동작하며,
사용자는 보통 조직적인 부분을 고려해 결정한다(예를 들어, 사용자가 <code>dev.example.com</code>하위에 레코드를 생성하는것은 허용되지만,
<code>example.com</code>하위에는 그렇지 않을 수 있다).</p><p><code>dev.example.com</code>을 hosted zone으로 사용하고 있다고 가정해보자.
보통 사용자는 <a href=https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/CreatingNewSubdomain.html>일반적인 방법</a> 에 따라 생성하거나
<code>aws route53 create-hosted-zone --name dev.example.com --caller-reference 1</code> 와 같은 커맨드를 이용한다.</p><p>그 후 도메인 내 레코드들을 확인할 수 있도록 상위 도메인내에 NS 레코드를 생성해야 한다. 여기서는,
<code>dev</code> NS 레코드를 <code>example.com</code>에 생성한다. 만약 이것이 루트 도메인 네임이라면 이 NS 레코드들은
도메인 등록기관을 통해서 생성해야 한다(예를 들어, <code>example.com</code>는 <code>example.com</code>를 구매한 곳에서 설정 할 수 있다).</p><p>route53 도메인 설정을 확인한다(문제를 만드는 가장 큰 이유이다!). dig 툴을 실행해서
클러스터 설정이 정확한지 한번 더 확인한다.</p><p><code>dig NS dev.example.com</code></p><p>당신의 hosted zone용으로 할당된 3~4개의 NS 레코드를 Route53에서 확인할 수 있어야 한다.</p><h3 id=3-5-클러스터-상태-저장용-s3-버킷-생성>(3/5) 클러스터 상태 저장용 S3 버킷 생성</h3><p>kops는 설치 이후에도 클러스터를 관리할 수 있다. 이를 위해 사용자가 생성한 클러스터의 상태나
사용하는 키 정보들을 지속적으로 추적해야 한다. 이 정보가 S3에 저장된다.
이 버킷의 접근은 S3 권한으로 제어한다.</p><p>다수의 클러스터는 동일한 S3 버킷을 이용할 수 있고, 사용자는 이 S3 버킷을 같은 클러스트를
운영하는 동료에게 공유할 수 있다. 하지만 이 S3 버킷에 접근 가능한 사람은 사용자의
모든 클러스터에 관리자 접근이 가능하게 되니, 운영팀 이외로
공유되지 않도록 해야 한다.</p><p>그래서 보통 한 운영팀 당 하나의 S3 버킷을 가지도록 하기도 한다.(그리고 종종 운영팀
이름은 위에서 언급한 hosted zone과 동일하게 짓기도 한다!)</p><p>우리 예제에서는, <code>dev.example.com</code>를 hosted zone으로 했으니 <code>clusters.dev.example.com</code>를
S3 버킷 이름으로 정하자.</p><ul><li><p><code>AWS_PROFILE</code>를 선언한다. (AWS CLI 동작을 위해 다른 profile을 선택해야 할 경우)</p></li><li><p><code>aws s3 mb s3://clusters.dev.example.com</code>를 이용해 S3 버킷을 생성한다.</p></li><li><p><code>export KOPS_STATE_STORE=s3://clusters.dev.example.com</code> 하면, kops는 이 위치를 기본값으로 인식할 것이다.
이 부분을 bash profile등에 넣어두는것을 권장한다.</p></li></ul><h3 id=4-5-클러스터-설정-구성>(4/5) 클러스터 설정 구성</h3><p>클러스터 설정하려면, <code>kops create cluster</code> 를 실행한다:</p><p><code>kops create cluster --zones=us-east-1c useast1.dev.example.com</code></p><p>kops는 클러스터에 사용될 설정을 생성할것이다. 여기서 주의할 점은 실제 클러스트 리소스가 아닌 <em>설정</em>
만을 생성한다는 것에 주의하자 - 이 부분은 다음 단계에서 <code>kops update cluster</code> 으로
구성해볼 것이다. 그 때 만들어진 설정을 점검하거나 변경할 수 있다.</p><p>더 자세한 내용을 알아보기 위한 커맨드가 출력된다.</p><ul><li>클러스터 조회: <code>kops get cluster</code></li><li>클러스트 수정: <code>kops edit cluster useast1.dev.example.com</code></li><li>인스턴스 그룹 수정: <code>kops edit ig --name=useast1.dev.example.com nodes</code></li><li>마스터 인스턴스 그룹 수정: <code>kops edit ig --name=useast1.dev.example.com master-us-east-1c</code></li></ul><p>만약 kops사용이 처음이라면, 얼마 걸리지 않으니 이들을 시험해 본다. 인스턴스 그룹은
쿠버네티스 노드로 등록된 인스턴스의 집합을 말한다. AWS상에서는 auto-scaling-groups를
통해 만들어진다. 사용자는 여러 개의 인스턴스 그룹을 관리할 수 있는데,
예를 들어, spot과 on-demand 인스턴스 조합 또는 GPU 와 non-GPU 인스턴스의 조합으로 구성할 수 있다.</p><h3 id=5-5-aws에-클러스터-생성>(5/5) AWS에 클러스터 생성</h3><p><code>kops update cluster</code>를 실행해 AWS에 클러스터를 생성한다.</p><p><code>kops update cluster useast1.dev.example.com --yes</code></p><p>실행은 수 초 만에 되지만, 실제로 클러스터가 준비되기 전까지 수 분이 걸릴 수 있다.
언제든 <code>kops update cluster</code>로 클러스터 설정을 변경할 수 있다. 사용자가
변경한 클러스터 설정을 그대로 반영해 줄 것이며, 필요다하면 AWS 나 쿠버네티스를 재설정 해 줄것이다.</p><p>예를 들면, <code>kops edit ig nodes</code> 뒤에 <code>kops update cluster --yes</code>를 실행해 설정을 반영한다.
그리고 <code>kops rolling-update cluster</code>로 설정을 즉시 원복시킬 수 있다.</p><p><code>--yes</code>를 명시하지 않으면 <code>kops update cluster</code> 커맨드 후 어떤 설정이 변경될지가 표시된다.
운영계 클러스터 관리할 때 사용하기 좋다!</p><h3 id=다른-애드온-탐험>다른 애드온 탐험</h3><p><a href=/ko/docs/concepts/cluster-administration/addons/>애드온 리스트</a> 에서 쿠버네티스 클러스터용 로깅, 모니터링, 네트워크 정책, 시각화 & 제어 등을 포함한 다른 애드온을 확인해본다.</p><h2 id=정리하기>정리하기</h2><ul><li><code>kops delete cluster useast1.dev.example.com --yes</code> 로 클러스터를 삭제한다.</li></ul><h2 id=다음-내용>다음 내용</h2><ul><li>쿠버네티스 <a href=/ko/docs/concepts/>개념</a> 과 <a href=/ko/docs/reference/kubectl/><code>kubectl</code></a>에 대해 더 알아보기.</li><li>튜토리얼, 모범사례 및 고급 구성 옵션에 대한 <code>kops</code> <a href=https://kops.sigs.k8s.io/>고급 사용법</a>에 대해 더 자세히 알아본다.</li><li>슬랙(Slack)에서 <code>kops</code> 커뮤니티 토론을 할 수 있다: <a href=https://github.com/kubernetes/kops#other-ways-to-communicate-with-the-contributors>커뮤니티 토론</a></li><li>문제를 해결하거나 이슈를 제기하여 <code>kops</code> 에 기여한다. <a href=https://github.com/kubernetes/kops/issues>깃헙 이슈</a></li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-f8b4964187fe973644e06ee629eff1de>2.2.3 - Kubespray로 쿠버네티스 설치하기</h1><p>이 가이드는 <a href=https://github.com/kubernetes-sigs/kubespray>Kubespray</a>를 이용하여 GCE, Azure, OpenStack, AWS, vSphere, Equinix Metal(전 Packet), Oracle Cloud infrastructure(실험적) 또는 베어메탈 등에서 운영되는 쿠버네티스 클러스터를 설치하는 과정을 보여준다.</p><p>Kubespray는 <a href=https://docs.ansible.com/>Ansible</a> 플레이북, <a href=https://github.com/kubernetes-sigs/kubespray/blob/master/docs/ansible.md#inventory>인벤토리</a>, 프로비저닝 도구와 일반적인 운영체제, 쿠버네티스 클러스터의 설정 관리 작업에 대한 도메인 지식의 결합으로 만들어졌다. Kubespray는 아래와 같은 기능을 제공한다.</p><p>Kubespray 지원 사항</p><ul><li>고가용성을 지닌 클러스터</li><li>구성 가능 (인스턴스를 위한 네트워크 플러그인 선택)</li><li>대부분의 인기있는 리눅스 배포판들에 대한 지원<ul><li>Flatcar Container Linux by Kinvolk</li><li>Debian Bullseye, Buster, Jessie, Stretch</li><li>Ubuntu 16.04, 18.04, 20.04, 22.04</li><li>CentOS/RHEL 7, 8</li><li>Fedora 34, 35</li><li>Fedora CoreOS</li><li>openSUSE Leap 15.x/Tumbleweed</li><li>Oracle Linux 7, 8</li><li>Alma Linux 8</li><li>Rocky Linux 8</li><li>Amazon Linux 2</li></ul></li><li>지속적인 통합 (CI) 테스트</li></ul><p>클러스터를 설치해 줄 도구로 유스케이스와 가장 잘 맞는 것을 고르고 싶다면, kubespray를 <a href=/ko/docs/reference/setup-tools/kubeadm/>kubeadm</a>, <a href=/ko/docs/setup/production-environment/tools/kops/>kops</a>와 <a href=https://github.com/kubernetes-sigs/kubespray/blob/master/docs/comparisons.md>비교한 글</a>을 읽어보자.</p><h2 id=클러스터-생성하기>클러스터 생성하기</h2><h3 id=1-5-아래의-요건-충족하기>(1/5) 아래의 요건 충족하기</h3><p>언더레이(underlay) <a href=https://github.com/kubernetes-sigs/kubespray#requirements>요건</a>을 만족하는 프로비전 한다.</p><ul><li><strong>쿠버네티스는 최소한 v1.22 이상의 버전이 필요하다.</strong></li><li><strong>Ansible의 명령어를 실행하기 위해 Ansible v2.11+, Jinja 2.11+와 Python netaddr 라이브러리가 머신에 설치되어 있어야 한다</strong>.</li><li>타겟 서버들은 docker 이미지를 풀(pull) 하기 위해 반드시 <strong>인터넷에 접속</strong>할 수 있어야 한다. 아니라면, 추가적인 설정을 해야 한다 (<a href=https://github.com/kubernetes-sigs/kubespray/blob/master/docs/offline-environment.md>오프라인 환경 확인하기</a>)</li><li>타겟 서버들의 <strong>IPv4 포워딩</strong>이 활성화되어야 한다.</li><li>파드와 서비스에서 IPv6를 이용한다면, 대상 서버도 <strong>IPv6 포워딩</strong>이 활성화되어야 한다.</li><li><strong>방화벽은 kubespray가 관리하지 않는다</strong>. 사용자는 기존 방식으로 자신의 규칙을 구현해야 한다. 배포 중에 만날 문제를 예방하려면 방화벽을 비활성화해야 한다.</li><li>만약 kubespray가 루트가 아닌 사용자 계정에서 실행되었다면, 타겟 서버에서 알맞은 권한 상승 방법이 설정되어야 한다. 그 후에 <code>ansible_become</code> 플래그나 커맨드 파라미터들, <code>--become</code> 또는 <code>-b</code> 가 명시되어야 한다</li></ul><p>Kubespray는 환경에 맞는 프로비저닝을 돕기 위해 아래와 같은 서비스를 제공한다:</p><ul><li>아래 클라우드 제공 업체를 위한 <a href=https://www.terraform.io/>Terraform</a> 스크립트:<ul><li><a href=https://github.com/kubernetes-sigs/kubespray/tree/master/contrib/terraform/aws>AWS</a></li><li><a href=https://github.com/kubernetes-sigs/kubespray/tree/master/contrib/terraform/openstack>OpenStack</a></li><li><a href=https://github.com/kubernetes-sigs/kubespray/tree/master/contrib/terraform/metal>Equinix Metal</a></li></ul></li></ul><h3 id=2-5-인벤토리-파일-구성하기>(2/5) 인벤토리 파일 구성하기</h3><p>서버들을 프로비저닝 한 후, <a href=https://docs.ansible.com/ansible/latest/network/getting_started/first_inventory.html>Ansible의 인벤토리 파일</a>을 만들어야 한다. 수동으로 만들 수도 있고, 동적인 인벤토리 스크립트를 통해 만들 수도 있다. 더 많이 알고싶다면 " <a href=https://github.com/kubernetes-sigs/kubespray/blob/master/docs/getting-started.md#building-your-own-inventory>나만의 인벤토리 만들기</a>" 글을 확인하자.</p><h3 id=3-5-클러스터-디플로이먼트-계획하기>(3/5) 클러스터 디플로이먼트 계획하기</h3><p>Kubespray에서는 디플로이먼트의 많은 속성들을 사용자가 정의(customize)할 수 있다:</p><ul><li>디플로이먼트 모드의 선택: kubeadm 또는 그 외</li><li>CNI(네트워킹) 플러그인</li><li>DNS 설정</li><li>컨트롤 플레인 선택: 네이티브/바이너리 또는 컨테이너화 된 것</li><li>컴포넌트 버전</li><li>Calico 라우터 리플렉터</li><li>컴포넌트 런타임 옵션<ul><li><a class=glossary-tooltip title='Docker는 운영 시스템 수준의 가상화를 제공하는 소프트웨어 기술이며, 컨테이너로도 알려져 있다.' data-toggle=tooltip data-placement=top href=https://docs.docker.com/engine/ target=_blank aria-label=도커(Docker)>도커(Docker)</a></li><li><a class=glossary-tooltip title='A container runtime with an emphasis on simplicity, robustness and portability' data-toggle=tooltip data-placement=top href=https://containerd.io/docs/ target=_blank aria-label=containerd>containerd</a></li><li><a class=glossary-tooltip title='A lightweight container runtime specifically for Kubernetes' data-toggle=tooltip data-placement=top href=https://cri-o.io/#what-is-cri-o target=_blank aria-label=CRI-O>CRI-O</a></li></ul></li><li>인증서 생성 방법</li></ul><p>Kubespray의 <a href=https://docs.ansible.com/ansible/latest/user_guide/playbooks_variables.html>변수 파일들</a>을 사용자가 정의할 수 있다. 만약 Kubespray를 처음 접하는 경우, kubespray의 기본 설정값을 이용해 클러스터를 배포하고 Kubernetes를 탐색하는 것이 좋다.</p><h3 id=4-5-클러스터-배포하기>(4/5) 클러스터 배포하기</h3><p>다음으로, 클러스터를 배포한다.</p><p><a href=https://github.com/kubernetes-sigs/kubespray/blob/master/docs/getting-started.md#starting-custom-deployment>Ansible-플레이북</a>을 이용한 클러스터 디플로이먼트</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>ansible-playbook -i your/inventory/inventory.ini cluster.yml -b -v <span style=color:#b62;font-weight:700>\
</span></span></span><span style=display:flex><span><span style=color:#b62;font-weight:700></span>  --private-key<span style=color:#666>=</span>~/.ssh/private_key
</span></span></code></pre></div><p>규모가 큰 디플로이먼트는 (100개 이상의 노드) 최적의 결과를 얻기 위해 <a href=https://github.com/kubernetes-sigs/kubespray/blob/master/docs/large-deployments.md>특정한 조정</a>을 필요로 할 수도 있다.</p><h3 id=5-5-디플로이먼트-검증하기>(5/5) 디플로이먼트 검증하기</h3><p>Kubespray는 Netchecker를 사용하여 파드 사이의 연결성과 DNS 해석을 검증할 방법을 제공한다. Netchecker는 netchecker-agents 파드들이 DNS 요청을 해석하고 기본(default) 네임스페이스 내부에서 서로에게 ping을 보낼 수 있도록 보장한다. 그 파드들은 나머지 워크로드의 유사한 동작을 모방하고 클러스터의 상태 표시기 역할을 한다.</p><h2 id=클러스터-동작>클러스터 동작</h2><p>Kubespray는 클러스터를 관리하기 위한 추가적인 플레이북, <em>scale</em> 과 <em>upgrade</em> 를 제공한다.</p><h3 id=클러스터-스케일링하기>클러스터 스케일링하기</h3><p>scale 플레이북을 실행해 클러스터에 워커 노드를 추가할 수 있다. 더 자세히 알고 싶다면, "<a href=https://github.com/kubernetes-sigs/kubespray/blob/master/docs/getting-started.md#adding-nodes>노드 추가하기</a>" 문서를 확인하자.
remove-node 플레이북을 실행하면 클러스터로부터 워커 노드를 제거할 수 있다. 더 알고 싶다면 "<a href=https://github.com/kubernetes-sigs/kubespray/blob/master/docs/getting-started.md#remove-nodes>노드 제거하기</a>" 문서를 확인하자.</p><h3 id=클러스터-업그레이드-하기>클러스터 업그레이드 하기</h3><p>upgrade-cluster 플레이북을 실행해 클러스터를 업그레이드 할 수 있다. 더 자세히 알고 싶다면 "<a href=https://github.com/kubernetes-sigs/kubespray/blob/master/docs/upgrades.md>업그레이드</a>" 문서를 확인하자.</p><h2 id=클린업>클린업</h2><p><a href=https://github.com/kubernetes-sigs/kubespray/blob/master/reset.yml>reset 플레이북</a>을 이용하여 노드들을 리셋하고 Kubespray로 설치된 모든 구성요소를 삭제할 수 있다.</p><div class="alert alert-warning caution callout" role=alert><strong>주의:</strong> reset 플레이북을 실행할 때, 실수로 프로덕션 클러스터를 타겟으로 삼지 않도록 해야 한다!</div><h2 id=피드백>피드백</h2><ul><li>Slack 채널: <a href=https://kubernetes.slack.com/messages/kubespray/>#kubespray</a> (<a href=https://slack.k8s.io/>이 곳</a>에서 초대를 받을 수 있다)</li><li><a href=https://github.com/kubernetes-sigs/kubespray/issues>GitHub Issues</a></li></ul><h2 id=다음-내용>다음 내용</h2><ul><li>Kubespray의 <a href=https://github.com/kubernetes-sigs/kubespray/blob/master/docs/roadmap.md>로드맵</a>에서 계획중인 작업을 확인해보자.</li><li><a href=https://github.com/kubernetes-sigs/kubespray>Kubespray</a>를 더 알아보자.</li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-d2f55eefe7222b7c637875af9c3ec199>2.3 - 턴키 클라우드 솔루션</h1><p>이 페이지는 인증된 쿠버네티스 솔루션 제공자 목록을 제공한다. 각 제공자
페이지를 통해서, 프로덕션에 준비된 클러스터를 설치 및 설정하는 방법을
학습할 수 있다.</p><script>function updateLandscapeSource(e,t){console.log({button:e,shouldUpdateFragment:t});try{if(t)window.location.hash="#"+e.id;else{var n=document.querySelectorAll("#landscape");let t=e.dataset.landscapeTypes,s="https://landscape.cncf.io/card-mode?category="+encodeURIComponent(t)+"&grouping=category&embed=yes";n[0].src=s}}catch(e){console.log({message:"error handling Landscape switch",error:e})}}document.addEventListener("DOMContentLoaded",function(){let t=()=>{if(window.location.hash){let e=document.querySelectorAll(".landscape-trigger"+window.location.hash);e.length==1&&(landscapeSource=e[0],console.log("Updating Landscape source based on fragment:",window.location.hash.substring(1)),updateLandscapeSource(landscapeSource,!1))}};var e,n=document.querySelectorAll(".landscape-trigger");if(n.forEach(e=>{e.onclick=function(){updateLandscapeSource(e,!0)}}),e=document.querySelectorAll(".landscape-trigger.landscape-default"),e.length==1){let t=e[0];updateLandscapeSource(t,!1)}window.addEventListener("hashchange",t,!1),t()})</script><div id=frameHolder><iframe frameborder=0 id=landscape scrolling=no src="https://landscape.cncf.io/card-mode?category=certified-kubernetes-hosted&grouping=category&embed=yes" style=width:1px;min-width:100%></iframe>
<script src=https://landscape.cncf.io/iframeResizer.js></script></div></div><div class=td-content style=page-break-before:always><h1 id=pg-84b6491601d6a2b3da4cd5a105c866ba>3 - 모범 사례</h1></div><div class=td-content><h1 id=pg-c797ee17120176c685455db89ae091a9>3.1 - 대형 클러스터에 대한 고려 사항</h1><p>클러스터는 <a class=glossary-tooltip title='컨테이너의 라이프사이클을 정의, 배포, 관리하기 위한 API와 인터페이스들을 노출하는 컨테이너 오케스트레이션 레이어.' data-toggle=tooltip data-placement=top href='/ko/docs/reference/glossary/?all=true#term-control-plane' target=_blank aria-label='컨트롤 플레인'>컨트롤 플레인</a>에서 관리하는
쿠버네티스 에이전트를 실행하는 <a class=glossary-tooltip title='노드는 쿠버네티스의 작업 장비(worker machine)이다.' data-toggle=tooltip data-placement=top href=/ko/docs/concepts/architecture/nodes/ target=_blank aria-label=노드>노드</a>(물리
또는 가상 머신)의 집합이다.
쿠버네티스 v1.25는 노드 5,000개까지의 클러스터를 지원한다. 보다 정확하게는,
쿠버네티스는 다음 기준을 <em>모두</em> 만족하는 설정을 수용하도록 설계되었다.</p><ul><li>노드 당 파드 110 개 이하</li><li>노드 5,000개 이하</li><li>전체 파드 150,000개 이하</li><li>전체 컨테이너 300,000개 이하</li></ul><p>노드를 추가하거나 제거하여 클러스터를 확장할 수 있다. 이를 수행하는 방법은
클러스터 배포 방법에 따라 다르다.</p><h2 id=quota-issues>클라우드 프로바이더 리소스 쿼터</h2><p>여러 노드를 가지는 클러스터를 만들 때, 클라우드 프로바이더 쿼터 이슈를 피하기 위해
고려할 점은 다음과 같다.</p><ul><li>다음과 같은 클라우드 리소스에 대한 쿼터 증가를 요청한다.<ul><li>컴퓨터 인스턴스</li><li>CPU</li><li>스토리지 볼륨</li><li>사용 중인 IP 주소</li><li>패킷 필터링 규칙 세트</li><li>로드밸런서 개수</li><li>로그 스트림</li></ul></li><li>일부 클라우드 프로바이더는 새로운 인스턴스 생성 속도에 상한이 있어, 클러스터 확장 작업 간 새로운 노드를 일괄적으로 배치하고, 배치 간에 일시 중지한다.</li></ul><h2 id=컨트롤-플레인-컴포넌트>컨트롤 플레인 컴포넌트</h2><p>대규모 클러스터의 경우, 충분한 컴퓨트 및 기타 리소스가 있는 컨트롤 플레인이
필요하다.</p><p>일반적으로 장애 영역 당 하나 또는 두 개의 컨트롤 플레인 인스턴스를
실행하고, 해당 인스턴스를 수직으로(vertically) 먼저 확장한 다음 (수직) 규모로 하락하는
지점에 도달한 후 수평으로(horizontally) 확장한다.</p><p>내결함성을 제공하려면 장애 영역 당 하나 이상의 인스턴스를 실행해야 한다. 쿠버네티스
노드는 동일한 장애 영역에 있는 컨트롤 플레인 엔드포인트로 트래픽을
자동으로 조정하지 않는다. 그러나, 클라우드 프로바이더는 이를 수행하기 위한 자체 메커니즘을 가지고 있을 수 있다.</p><p>예를 들어, 관리형 로드 밸런서를 사용하여 장애 영역 <em>A</em> 의
kubelet 및 파드에서 시작되는 트래픽을 전송하도록 로드 밸런서를 구성하고, 해당 트래픽을
<em>A</em> 영역에 있는 컨트롤 플레인 호스트로만 전달한다. 단일 컨트롤 플레인 호스트 또는
엔드포인트 장애 영역 <em>A</em> 이 오프라인이 되면, 영역 <em>A</em> 의 노드에 대한
모든 컨트롤 플레인 트래픽이 이제 영역간에 전송되고 있음을 의미한다. 각 영역에서 여러 컨트롤 플레인 호스트를
실행하면 가용성이 낮아진다.</p><h3 id=etcd-저장소>etcd 저장소</h3><p>큰 클러스터의 성능 향상을 위해, 사용자는 이벤트 오브젝트를 각각의
전용 etcd 인스턴스에 저장한다.</p><p>클러스터 생성시의 부가 스트립트이다.
클러스터 생성 시에 (사용자 도구를 사용하여) 다음을 수행할 수 있다.</p><ul><li>추가 etcd 인스턴스 시작 및 설정</li><li>이벤트를 저장하기 위한 <a class=glossary-tooltip title='쿠버네티스 API를 제공하는 컨트롤 플레인 컴포넌트.' data-toggle=tooltip data-placement=top href=/ko/docs/concepts/overview/components/#kube-apiserver target=_blank aria-label='API server'>API server</a> 설정</li></ul><p><a href=/docs/tasks/administer-cluster/configure-upgrade-etcd/>쿠버네티스를 위한 etcd 클러스터 운영하기</a>와
<a href=/docs/setup/production-environment/tools/kubeadm/setup-ha-etcd-with-kubeadm/>kubeadm을 이용하여 고가용성 etcd 생성하기</a>에서
큰 클러스터를 위한 etcd를 설정하고 관리하는 방법에 대한 상세 사항을 확인한다.</p><h2 id=애드온-리소스>애드온 리소스</h2><p>쿠버네티스 <a href=/ko/docs/concepts/configuration/manage-resources-containers/>리소스 제한</a>은
파드와 컨테이너가 다른 컴포넌트에 영향을 줄 수 있는 메모리 누수 및 기타 방식의 영향을
최소화하는 데 도움이 된다. 이러한 리소스 제한은 애플리케이션 워크로드에 적용될 수 있는 것처럼
<a class=glossary-tooltip title='쿠버네티스의 기능을 확장하는 리소스.' data-toggle=tooltip data-placement=top href=/ko/docs/concepts/cluster-administration/addons/ target=_blank aria-label=애드온>애드온</a> 리소스에도 적용될 수 있다.</p><p>예를 들어, 로깅 컴포넌트에 대한 CPU 및 메모리 제한을 설정할 수 있다.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#bbb>  </span>...<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>fluentd-cloud-logging<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>fluent/fluentd-kubernetes-daemonset:v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>resources</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>limits</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>cpu</span>:<span style=color:#bbb> </span>100m<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>memory</span>:<span style=color:#bbb> </span>200Mi<span style=color:#bbb>
</span></span></span></code></pre></div><p>애드온의 기본 제한은 일반적으로 중소형 쿠버네티스 클러스터에서
각 애드온을 실행한 경험에서 수집된 데이터를 기반으로 한다. 대규모 클러스터에서
실행할 때, 애드온은 종종 기본 제한보다 많은 리소스를 소비한다.
이러한 값을 조정하지 않고 대규모 클러스터를 배포하면, 애드온이
메모리 제한에 계속 도달하기 때문에 지속적으로 종료될 수 있다.
또는, 애드온이 실행될 수 있지만 CPU 시간 슬라이스 제한으로 인해
성능이 저하된다.</p><p>클러스터 애드온 리소스 문제가 발생하지 않도록, 노드가 많은 클러스터를
만들 때, 다음 사항을 고려한다.</p><ul><li>일부 애드온은 수직으로 확장된다. 클러스터 또는 전체 장애 영역을
제공하는 애드온 레플리카가 하나 있다. 이러한 애드온의 경우, 클러스터를 확장할 때
요청과 제한을 늘린다.</li><li>많은 애드온은 수평으로 확장된다. 더 많은 파드를 실행하여 용량을 추가하지만,
매우 큰 클러스터에서는 CPU 또는 메모리 제한을 약간 높여야 할 수도 있다.
VerticalPodAutoscaler는 <em>recommender</em> 모드에서 실행되어 요청 및 제한에 대한
제안 수치를 제공할 수 있다.</li><li>일부 애드온은 <a class=glossary-tooltip title='파드의 복제본을 클러스터 노드 집합에서 동작하게 한다.' data-toggle=tooltip data-placement=top href=/ko/docs/concepts/workloads/controllers/daemonset target=_blank aria-label=데몬셋(DaemonSet)>데몬셋(DaemonSet)</a>에 의해 제어되는 노드 당 하나의 복사본으로 실행된다(예: 노드 수준 로그 수집기). 수평
확장 애드온의 경우와 유사하게, CPU 또는 메모리 제한을 약간 높여야
할 수도 있다.</li></ul><h2 id=다음-내용>다음 내용</h2><p><code>VerticalPodAutoscaler</code> 는 리소스 요청 및 파드 제한을 관리하는 데 도움이 되도록
클러스터에 배포할 수 있는 사용자 정의 리소스이다.
클러스터에 중요한 애드온을 포함하여 클러스터 컴포넌트를 확장하는 방법에 대한
자세한 내용은 <a href=https://github.com/kubernetes/autoscaler/tree/master/vertical-pod-autoscaler#readme>Vertical Pod Autoscaler</a>를
방문하여 배워본다.</p><p><a href=https://github.com/kubernetes/autoscaler/tree/master/cluster-autoscaler#readme>클러스터 오토스케일러</a>는
여러 클라우드 프로바이더와 통합되어 클러스터의 리소스 요구 수준에 맞는
노드 수를 실행할 수 있도록 도와준다.</p><p><a href=https://github.com/kubernetes/autoscaler/tree/master/addon-resizer#readme>addon resizer</a>는
클러스터 스케일이 변경될 때 자동으로 애드온 크기를 조정할 수 있도록 도와준다.</p></div><div class=td-content style=page-break-before:always><h1 id=pg-970615c97499e3651fd3a98e0387cefc>3.2 - 여러 영역에서 실행</h1><p>이 페이지에서는 여러 영역에서 쿠버네티스를 실행하는 방법을 설명한다.</p><h2 id=배경>배경</h2><p>쿠버네티스는 단일 쿠버네티스 클러스터가 여러 장애 영역에서
실행될 수 있도록 설계되었다. 일반적으로 이러한 영역은 <em>지역(region)</em> 이라는
논리적 그룹 내에 적합하다. 주요 클라우드 제공자는 지역을 일관된 기능 집합을
제공하는 장애 영역 집합(<em>가용성 영역</em> 이라고도 함)으로
정의한다. 지역 내에서 각 영역은 동일한 API 및
서비스를 제공한다.</p><p>일반적인 클라우드 아키텍처는 한 영역의 장애가 다른 영역의 서비스도
손상시킬 가능성을 최소화하는 것을 목표로 한다.</p><h2 id=컨트롤-플레인-동작>컨트롤 플레인 동작</h2><p>모든 <a href=/ko/docs/concepts/overview/components/#%EC%BB%A8%ED%8A%B8%EB%A1%A4-%ED%94%8C%EB%A0%88%EC%9D%B8-%EC%BB%B4%ED%8F%AC%EB%84%8C%ED%8A%B8>컨트롤 플레인 컴포넌트</a>는
컴포넌트별로 복제되는 교환 가능한 리소스 풀로 실행을
지원한다.</p><p>클러스터 컨트롤 플레인을 배포할 때, 여러 장애 영역에
컨트롤 플레인 컴포넌트의 복제본을 배치한다. 가용성이
중요한 문제인 경우, 3개 이상의 장애 영역을 선택하고
각 개별 컨트롤 플레인 컴포넌트(API 서버, 스케줄러, etcd,
클러스터 컨트롤러 관리자)를 3개 이상의 장애 영역에 복제한다.
클라우드 컨트롤러 관리자를 실행 중인 경우 선택한
모든 장애 영역에 걸쳐 이를 복제해야 한다.</p><div class="alert alert-info note callout" role=alert><strong>참고:</strong> 쿠버네티스는 API 서버 엔드포인트에 대한 교차 영역 복원성을 제공하지
않는다. DNS 라운드-로빈, SRV 레코드 또는 상태 확인 기능이 있는
써드파티 로드 밸런싱 솔루션을 포함하여 다양한 기술을 사용하여
클러스터 API 서버의 가용성을 향상시킬 수 있다.</div><h2 id=노드-동작>노드 동작</h2><p>쿠버네티스는 클러스터의 여러 노드에 걸쳐
워크로드 리소스(예: <a class=glossary-tooltip title='클러스터에서 복제된 애플리케이션을 관리한다.' data-toggle=tooltip data-placement=top href=/ko/docs/concepts/workloads/controllers/deployment/ target=_blank aria-label=디플로이먼트(Deployment)>디플로이먼트(Deployment)</a>
또는 <a class=glossary-tooltip title='내구성이 있는 스토리지와 파드별로 지속성 식별자를 사용해서 파드 집합의 디플로이먼트와 스케일링을 관리한다.' data-toggle=tooltip data-placement=top href=/ko/docs/concepts/workloads/controllers/statefulset/ target=_blank aria-label=스테이트풀셋(StatefulSet)>스테이트풀셋(StatefulSet)</a>)에
대한 파드를 자동으로 분배한다. 이러한 분배는
실패에 대한 영향을 줄이는 데 도움이 된다.</p><p>노드가 시작되면, 각 노드의 kubelet이 쿠버네티스 API에서
특정 kubelet을 나타내는 노드 오브젝트에
<a class=glossary-tooltip title='사용자에게 의미 있고 관련성 높은 특징으로 식별할 수 있도록 오브젝트에 태그를 붙인다.' data-toggle=tooltip data-placement=top href=/ko/docs/concepts/overview/working-with-objects/labels target=_blank aria-label=레이블>레이블</a>을 자동으로 추가한다.
이러한 레이블에는
<a href=/ko/docs/reference/labels-annotations-taints/#topologykubernetesiozone>영역 정보</a>가 포함될 수 있다.</p><p>클러스터가 여러 영역 또는 지역에 걸쳐있는 경우,
<a href=/ko/docs/concepts/scheduling-eviction/topology-spread-constraints/>파드 토폴로지 분배 제약 조건</a>과
함께 노드 레이블을 사용하여
파드가 장애 도메인(지역, 영역, 특정 노드) 간 클러스터에
분산되는 방식을 제어할 수 있다.
이러한 힌트를 통해
<a class=glossary-tooltip title='노드가 배정되지 않은 새로 생성된 파드를 감지하고, 실행할 노드를 선택하는 컨트롤 플레인 컴포넌트.' data-toggle=tooltip data-placement=top href=/docs/reference/command-line-tools-reference/kube-scheduler/ target=_blank aria-label=스케줄러>스케줄러</a>는
더 나은 예상 가용성을 위해 파드를 배치할 수 있으므로, 상관 관계가 있는
오류가 전체 워크로드에 영향을 미칠 위험을 줄일 수 있다.</p><p>예를 들어, 가능할 때마다 스테이트풀셋의
3개 복제본이 모두 서로 다른 영역에서 실행되도록 제약 조건을
설정할 수 있다. 각 워크로드에 사용 중인
가용 영역을 명시적으로 정의하지 않고 이를 선언적으로
정의할 수 있다.</p><h3 id=여러-영역에-노드-분배>여러 영역에 노드 분배</h3><p>쿠버네티스의 코어는 사용자를 위해 노드를 생성하지 않는다. 사용자가 직접 수행하거나,
<a href=https://cluster-api.sigs.k8s.io/>클러스터 API</a>와 같은 도구를 사용하여
사용자 대신 노드를 관리해야 한다.</p><p>클러스터 API와 같은 도구를 사용하면 여러 장애 도메인에서
클러스터의 워커 노드로 실행할 머신 집합과 전체 영역 서비스 중단 시
클러스터를 자동으로 복구하는 규칙을 정의할 수 있다.</p><h2 id=파드에-대한-수동-영역-할당>파드에 대한 수동 영역 할당</h2><p>생성한 파드와 디플로이먼트, 스테이트풀셋, 잡(Job)과
같은 워크로드 리소스의 파드 템플릿에 <a href=/ko/docs/concepts/scheduling-eviction/assign-pod-node/#%EB%85%B8%EB%93%9C-%EC%85%80%EB%A0%89%ED%84%B0-nodeselector>노드 셀렉터 제약 조건</a>을
적용할 수 있다.</p><h2 id=영역에-대한-스토리지-접근>영역에 대한 스토리지 접근</h2><p>퍼시스턴트 볼륨이 생성되면, <code>PersistentVolumeLabel</code>
<a href=/docs/reference/access-authn-authz/admission-controllers/>어드미션 컨트롤러</a>는
특정 영역에 연결된 모든 퍼시스턴트볼륨(PersistentVolume)에 영역 레이블을 자동으로
추가한다. 그런 다음 <a class=glossary-tooltip title='노드가 배정되지 않은 새로 생성된 파드를 감지하고, 실행할 노드를 선택하는 컨트롤 플레인 컴포넌트.' data-toggle=tooltip data-placement=top href=/docs/reference/command-line-tools-reference/kube-scheduler/ target=_blank aria-label=스케줄러>스케줄러</a>는
<code>NoVolumeZoneConflict</code> 프레디케이트(predicate)를 통해 주어진 퍼시스턴트볼륨을 요구하는 파드가
해당 볼륨과 동일한 영역에만 배치되도록 한다.</p><p>해당 클래스의 스토리지가 사용할 수 있는 장애 도메인(영역)을 지정하는
퍼시스턴트볼륨클레임(PersistentVolumeClaims)에 대한
<a class=glossary-tooltip title='스토리지클래스는 관리자가 사용 가능한 다양한 스토리지 유형을 설명할 수 있는 방법을 제공한다.' data-toggle=tooltip data-placement=top href=/ko/docs/concepts/storage/storage-classes target=_blank aria-label=스토리지클래스(StorageClass)>스토리지클래스(StorageClass)</a>를 지정할 수 있다.
장애 도메인 또는 영역을 인식하는 스토리지클래스 구성에 대한 자세한 내용은
<a href=/ko/docs/concepts/storage/storage-classes/#%ED%97%88%EC%9A%A9%EB%90%9C-%ED%86%A0%ED%8F%B4%EB%A1%9C%EC%A7%80>허용된 토폴로지</a>를 참고한다.</p><h2 id=네트워킹>네트워킹</h2><p>쿠버네티스가 스스로 영역-인지(zone-aware) 네트워킹을 포함하지는 않는다.
<a href=/ko/docs/concepts/extend-kubernetes/compute-storage-net/network-plugins/>네트워크 플러그인</a>을
사용하여 클러스터 네트워킹을 구성할 수 있으며, 해당 네트워크 솔루션에는 영역별 요소가
있을 수 있다. 예를 들어, 클라우드 제공자가
<code>type=LoadBalancer</code> 를 사용하여 서비스를 지원하는 경우, 로드 밸런서는 지정된 연결을 처리하는
로드 밸런서 요소와 동일한 영역에서 실행 중인 파드로만 트래픽을 보낼 수 있다.
자세한 내용은 클라우드 제공자의 문서를 확인한다.</p><p>사용자 정의 또는 온-프레미스 배포의 경우, 비슷한 고려 사항이 적용된다.
다른 장애 영역 처리를 포함한 <a class=glossary-tooltip title='네트워크 서비스로 파드 집합에서 실행 중인 애플리케이션을 노출하는 방법' data-toggle=tooltip data-placement=top href=/ko/docs/concepts/services-networking/service/ target=_blank aria-label=서비스>서비스</a>와
<a class=glossary-tooltip title='클러스터 내의 서비스에 대한 외부 접근을 관리하는 API 오브젝트이며, 일반적으로 HTTP를 관리함.' data-toggle=tooltip data-placement=top href=/ko/docs/concepts/services-networking/ingress/ target=_blank aria-label=인그레스(Ingress)>인그레스(Ingress)</a> 동작은
클러스터가 설정된 방식에 명확히 의존한다.</p><h2 id=장애-복구>장애 복구</h2><p>클러스터를 설정할 때, 한 지역의 모든 장애 영역이 동시에
오프라인 상태가 되는 경우 설정에서 서비스를 복원할 수 있는지
여부와 방법을 고려해야 할 수도 있다. 예를 들어, 영역에서 파드를 실행할 수 있는
노드가 적어도 하나 이상 있어야 하는가?
클러스터에 중요한 복구 작업이 클러스터에
적어도 하나 이상의 정상 노드에 의존하지 않는지 확인한다. 예를 들어, 모든 노드가
비정상인 경우, 하나 이상의 노드를 서비스할 수 있을 만큼 복구를 완료할 수 있도록 특별한
<a class=glossary-tooltip title='세 가지 필수 속성: 키(key), 값(value), 효과(effect)로 구성된 코어 오브젝트. 톨러레이션은 매칭되는 테인트(taint)를 가진 노드나 노드 그룹에 파드가 스케줄링되는 것을 활성화한다.' data-toggle=tooltip data-placement=top href=/ko/docs/concepts/scheduling-eviction/taint-and-toleration/ target=_blank aria-label=톨러레이션(toleration)>톨러레이션(toleration)</a>으로
복구 작업을 실행해야 할 수 있다.</p><p>쿠버네티스는 이 문제에 대한 답을 제공하지 않는다. 그러나,
고려해야 할 사항이다.</p><h2 id=다음-내용>다음 내용</h2><p>스케줄러가 구성된 제약 조건을 준수하면서, 클러스터에 파드를 배치하는 방법을 알아보려면,
<a href=/ko/docs/concepts/scheduling-eviction/>스케줄링과 축출(eviction)</a>을 참고한다.</p></div><div class=td-content style=page-break-before:always><h1 id=pg-f89867de1d34943f1524f67a241f5cc9>3.3 - 노드 구성 검증하기</h1><h2 id=노드-적합성-테스트>노드 적합성 테스트</h2><p><em>노드 적합성 테스트</em> 는 노드의 시스템 검증과 기능 테스트를 제공하기 위해 컨테이너화된
테스트 프레임워크이다.
테스트는 노드가 쿠버네티스를 위한 최소 요구조건을 만족하는지를 검증한다.
그리고 테스트를 통과한 노드는 쿠버네티스 클러스터에 참여할 자격이 주어진다.</p><h2 id=노드-필수-구성-요소>노드 필수 구성 요소</h2><p>노드 적합성 테스트를 실행하기 위해서는,
해당 노드는 표준 쿠버네티스 노드로서 동일한 전제조건을 만족해야 한다.
노드는 최소한 아래 데몬들이 설치되어 있어야 한다.</p><ul><li>컨테이너 런타임 (Docker)</li><li>Kubelet</li></ul><h2 id=노드-적합성-테스트-실행>노드 적합성 테스트 실행</h2><p>노드 적합성 테스트는 다음 순서로 진행된다.</p><ol><li>kubelet에 대한 <code>--kubeconfig</code> 옵션의 값을 계산한다. 예를 들면, 다음과 같다.
<code>--kubeconfig = / var / lib / kubelet / config.yaml</code>.
테스트 프레임워크는 kubelet을 테스트하기 위해 로컬 컨트롤 플레인을 시작하기 때문에,
<code>http://localhost:8080</code> 을 API 서버의 URL로 사용한다.
사용할 수 있는 kubelet 커맨드 라인 파라미터가 몇 개 있다.</li></ol><ul><li><code>--cloud-provider</code>: <code>--cloud-provider=gce</code>를 사용 중이라면,
테스트 실행 시에는 제거해야 한다.</li></ul><ol start=2><li>다음 커맨드로 노드 적합성 테스트를 실행한다.</li></ol><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span><span style=color:#080;font-style:italic># $CONFIG_DIR는 Kublet의 파드 매니페스트 경로이다.</span>
</span></span><span style=display:flex><span><span style=color:#080;font-style:italic># $LOG_DIR는 테스트 출력 경로이다.</span>
</span></span><span style=display:flex><span>sudo docker run -it --rm --privileged --net<span style=color:#666>=</span>host <span style=color:#b62;font-weight:700>\
</span></span></span><span style=display:flex><span><span style=color:#b62;font-weight:700></span>  -v /:/rootfs -v <span style=color:#b8860b>$CONFIG_DIR</span>:<span style=color:#b8860b>$CONFIG_DIR</span> -v <span style=color:#b8860b>$LOG_DIR</span>:/var/result <span style=color:#b62;font-weight:700>\
</span></span></span><span style=display:flex><span><span style=color:#b62;font-weight:700></span>  registry.k8s.io/node-test:0.2
</span></span></code></pre></div><h2 id=다른-아키텍처에서-노드-적합성-테스트-실행>다른 아키텍처에서 노드 적합성 테스트 실행</h2><p>쿠버네티스는 다른 아키텍쳐용 노드 적합성 테스트 Docker 이미지도 제공한다.</p><table><thead><tr><th>Arch</th><th style=text-align:center>Image</th></tr></thead><tbody><tr><td>amd64</td><td style=text-align:center>node-test-amd64</td></tr><tr><td>arm</td><td style=text-align:center>node-test-arm</td></tr><tr><td>arm64</td><td style=text-align:center>node-test-arm64</td></tr></tbody></table><h2 id=선택된-테스트-실행>선택된 테스트 실행</h2><p>특정 테스트만 실행하기 위해서는 환경 변수 <code>FOCUS</code>에 테스트하고자 하는 테스트를 정규식으로 지정한다.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>sudo docker run -it --rm --privileged --net<span style=color:#666>=</span>host <span style=color:#b62;font-weight:700>\
</span></span></span><span style=display:flex><span><span style=color:#b62;font-weight:700></span>  -v /:/rootfs:ro -v <span style=color:#b8860b>$CONFIG_DIR</span>:<span style=color:#b8860b>$CONFIG_DIR</span> -v <span style=color:#b8860b>$LOG_DIR</span>:/var/result <span style=color:#b62;font-weight:700>\
</span></span></span><span style=display:flex><span><span style=color:#b62;font-weight:700></span>  -e <span style=color:#b8860b>FOCUS</span><span style=color:#666>=</span>MirrorPod <span style=color:#b62;font-weight:700>\ </span><span style=color:#080;font-style:italic># MirrorPod 테스트만 실행</span>
</span></span><span style=display:flex><span>  registry.k8s.io/node-test:0.2
</span></span></code></pre></div><p>특정 테스트를 건너뛰기 위해서는, 환경 변수 <code>SKIP</code>에 건너뛰고자 하는 테스트를 정규식으로 지정한다.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>sudo docker run -it --rm --privileged --net<span style=color:#666>=</span>host <span style=color:#b62;font-weight:700>\
</span></span></span><span style=display:flex><span><span style=color:#b62;font-weight:700></span>  -v /:/rootfs:ro -v <span style=color:#b8860b>$CONFIG_DIR</span>:<span style=color:#b8860b>$CONFIG_DIR</span> -v <span style=color:#b8860b>$LOG_DIR</span>:/var/result <span style=color:#b62;font-weight:700>\
</span></span></span><span style=display:flex><span><span style=color:#b62;font-weight:700></span>  -e <span style=color:#b8860b>SKIP</span><span style=color:#666>=</span>MirrorPod <span style=color:#b62;font-weight:700>\ </span><span style=color:#080;font-style:italic># MirrorPod 테스트만 건너뛰고 모든 적합성 테스트를 실행한다</span>
</span></span><span style=display:flex><span>  registry.k8s.io/node-test:0.2
</span></span></code></pre></div><p>노드 적합성 테스트는 <a href=https://github.com/kubernetes/community/blob/master/contributors/devel/sig-node/e2e-node-tests.md>노드 e2e 테스트</a>를 컨테이너화한 버전이다.
기본적으로, 모든 적합성 테스트를 실행한다.</p><p>이론적으로, 컨테이너와 필요한 볼륨을 적절히 설정했다면 어떤 노드 e2e 테스트도 수행할 수 있다.
하지만, 적합성 테스트가 아닌 테스트들은 훨씬 복잡한 설정이 필요하기 때문에 <strong>적합성 테스트만 실행하기를 강하게 추천한다.</strong></p><h2 id=주의-사항>주의 사항</h2><ul><li>테스트 후, 노드 적합성 테스트 이미지 및 기능 테스트에 사용된 이미지들을 포함하여 몇 개의 Docker 이미지들이 노드에 남는다.</li><li>테스트 후, 노드에 죽은 컨테이너가 남는다. 기능 테스트 도중에 생성된 컨테이너들이다.</li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-0394f813094b7a35058dffe5b8bacd20>3.4 - PKI 인증서 및 요구 사항</h1><p>쿠버네티스는 TLS를 통한 인증을 위해서 PKI 인증서가 필요하다.
만약 <a href=/ko/docs/reference/setup-tools/kubeadm/>kubeadm</a>으로 쿠버네티스를 설치한다면, 클러스터에 필요한 인증서는 자동으로 생성된다.
또한 더 안전하게 자신이 소유한 인증서를 생성할 수 있다. 이를 테면, 개인키를 API 서버에 저장하지 않으므로 더 안전하게 보관할 수 있다.
이 페이지는 클러스터가 필요로 하는 인증서에 대해서 설명한다.</p><h2 id=클러스터에서-인증서가-이용되는-방식>클러스터에서 인증서가 이용되는 방식</h2><p>쿠버네티스는 다음 작업에서 PKI를 필요로 한다.</p><ul><li>kubelet에서 API 서버 인증서를 인증시 사용하는 클라이언트 인증서</li><li>API 서버가 kubelet과 통신하기 위한
kubelet <a href=/docs/reference/access-authn-authz/kubelet-tls-bootstrapping/#client-and-serving-certificates>서버 인증서</a></li><li>API 서버 엔드포인트를 위한 서버 인증서</li><li>API 서버에 클러스터 관리자 인증을 위한 클라이언트 인증서</li><li>API 서버에서 kubelet과 통신을 위한 클라이언트 인증서</li><li>API 서버에서 etcd 간의 통신을 위한 클라이언트 인증서</li><li>컨트롤러 매니저와 API 서버 간의 통신을 위한 클라이언트 인증서/kubeconfig</li><li>스케줄러와 API 서버간 통신을 위한 클라이언트 인증서/kubeconfig</li><li><a href=/docs/tasks/extend-kubernetes/configure-aggregation-layer/>front-proxy</a>를 위한 클라이언트와 서버 인증서</li></ul><div class="alert alert-info note callout" role=alert><strong>참고:</strong> <code>front-proxy</code> 인증서는 kube-proxy에서 <a href=/ko/docs/tasks/extend-kubernetes/setup-extension-api-server/>API 서버 확장</a>을 지원할 때만 kube-proxy에서 필요하다.</div><p>etcd 역시 클라이언트와 피어 간에 상호 TLS 인증을 구현한다.</p><h2 id=인증서를-저장하는-위치>인증서를 저장하는 위치</h2><p>만약 쿠버네티스를 kubeadm으로 설치했다면, 대부분의 인증서는 <code>/etc/kubernetes/pki</code>에 저장된다. 이 문서에 언급된 모든 파일 경로는 그 디렉터리에 상대적이나, kubeadm이 <code>/etc/kubernetes</code>에 저장하는 사용자 어카운트 인증서는 예외이다.</p><h2 id=인증서-수동-설정>인증서 수동 설정</h2><p>필요한 인증서를 kubeadm으로 생성하기 싫다면, 단일 루트 CA를 이용하거나 모든 인증서를 제공하여 생성할 수 있다. 소유한 인증기관을 이용해서 생성하는 방법에 대해서는 <a href=/ko/docs/tasks/administer-cluster/certificates/>인증서</a>를 살펴본다.
인증서를 관리하는 방법에 대해서는 <a href=/ko/docs/tasks/administer-cluster/kubeadm/kubeadm-certs/>kubeadm을 사용한 인증서 관리</a>를 살펴본다.</p><h3 id=단일-루트-ca>단일 루트 CA</h3><p>관리자에 의해 제어되는 단일 루트 CA를 만들 수 있다. 이 루트 CA는 여러 중간 CA를 생성할 수 있고, 모든 추가 생성에 관해서도 쿠버네티스 자체에 위임할 수 있다.</p><p>필요 CA:</p><table><thead><tr><th>경로</th><th>기본 CN</th><th>설명</th></tr></thead><tbody><tr><td>ca.crt,key</td><td>kubernetes-ca</td><td>쿠버네티스 일반 CA</td></tr><tr><td>etcd/ca.crt,key</td><td>etcd-ca</td><td>모든 etcd 관련 기능을 위해서</td></tr><tr><td>front-proxy-ca.crt,key</td><td>kubernetes-front-proxy-ca</td><td><a href=/docs/tasks/extend-kubernetes/configure-aggregation-layer/>front-end proxy</a> 위해서</td></tr></tbody></table><p>위의 CA외에도, 서비스 계정 관리를 위한 공개/개인 키 쌍인 <code>sa.key</code> 와 <code>sa.pub</code> 을 얻는 것이 필요하다.
다음은 이전 표에 나온 CA 키와 인증서 파일을 보여준다.</p><pre tabindex=0><code>/etc/kubernetes/pki/ca.crt
/etc/kubernetes/pki/ca.key
/etc/kubernetes/pki/etcd/ca.crt
/etc/kubernetes/pki/etcd/ca.key
/etc/kubernetes/pki/front-proxy-ca.crt
/etc/kubernetes/pki/front-proxy-ca.key
</code></pre><h3 id=모든-인증서>모든 인증서</h3><p>이런 개인키를 API 서버에 복사하기 원치 않는다면, 모든 인증서를 스스로 생성할 수 있다.</p><p>필요한 인증서:</p><table><thead><tr><th>기본 CN</th><th>부모 CA</th><th>O (주체에서)</th><th>종류</th><th>호스트 (SAN)</th></tr></thead><tbody><tr><td>kube-etcd</td><td>etcd-ca</td><td></td><td>server, client</td><td><code>&lt;hostname></code>, <code>&lt;Host_IP></code>, <code>localhost</code>, <code>127.0.0.1</code></td></tr><tr><td>kube-etcd-peer</td><td>etcd-ca</td><td></td><td>server, client</td><td><code>&lt;hostname></code>, <code>&lt;Host_IP></code>, <code>localhost</code>, <code>127.0.0.1</code></td></tr><tr><td>kube-etcd-healthcheck-client</td><td>etcd-ca</td><td></td><td>client</td><td></td></tr><tr><td>kube-apiserver-etcd-client</td><td>etcd-ca</td><td>system:masters</td><td>client</td><td></td></tr><tr><td>kube-apiserver</td><td>kubernetes-ca</td><td></td><td>server</td><td><code>&lt;hostname></code>, <code>&lt;Host_IP></code>, <code>&lt;advertise_IP></code>, <code>[1]</code></td></tr><tr><td>kube-apiserver-kubelet-client</td><td>kubernetes-ca</td><td>system:masters</td><td>client</td><td></td></tr><tr><td>front-proxy-client</td><td>kubernetes-front-proxy-ca</td><td></td><td>client</td><td></td></tr></tbody></table><p>[1]: 클러스터에 접속한 다른 IP 또는 DNS 이름(<a href=/ko/docs/reference/setup-tools/kubeadm/>kubeadm</a>이 사용하는
로드 밸런서 안정 IP 또는 DNS 이름, <code>kubernetes</code>, <code>kubernetes.default</code>, <code>kubernetes.default.svc</code>,
<code>kubernetes.default.svc.cluster</code>, <code>kubernetes.default.svc.cluster.local</code>)</p><p><code>kind</code>는 하나 이상의 <a href=https://pkg.go.dev/k8s.io/api/certificates/v1beta1#KeyUsage>x509 키 사용</a> 종류를 가진다.</p><table><thead><tr><th>종류</th><th>키 사용</th></tr></thead><tbody><tr><td>server</td><td>digital signature, key encipherment, server auth</td></tr><tr><td>client</td><td>digital signature, key encipherment, client auth</td></tr></tbody></table><div class="alert alert-info note callout" role=alert><strong>참고:</strong> 위에 나열된 호스트/SAN은 작업 중인 클러스터를 획득하는데 권장된다. 특정 설정이 필요한 경우, 모든 서버 인증서에 SAN을 추가할 수 있다.</div><div class="alert alert-info note callout" role=alert><strong>참고:</strong><p>kubeadm 사용자만 해당:</p><ul><li>개인 키 없이 클러스터 CA 인증서에 복사하는 시나리오는 kubeadm 문서에서 외부 CA라고 한다.</li><li>위 목록을 kubeadm이 생성한 PKI와 비교하는 경우, <code>kube-etcd</code>, <code>kube-etcd-peer</code> 와 <code>kube-etcd-healthcheck-client</code> 인증서는
외부 etcd 케이스에서는 생성하지 않는 것을 알고 있어야 한다.</li></ul></div><h3 id=certificate-paths>인증서 파일 경로</h3><p>인증서는 권고하는 파일 경로에 존재해야 한다(<a href=/ko/docs/reference/setup-tools/kubeadm/>kubeadm</a>에서 사용되는 것처럼).
경로는 위치에 관계없이 주어진 파라미터를 사용하여 지정해야 한다.</p><table><thead><tr><th>기본 CN</th><th>권고되는 키 파일 경로</th><th>권고하는 인증서 파일 경로</th><th>명령어</th><th>키 파라미터</th><th>인증서 파라미터</th></tr></thead><tbody><tr><td>etcd-ca</td><td>etcd/ca.key</td><td>etcd/ca.crt</td><td>kube-apiserver</td><td></td><td>--etcd-cafile</td></tr><tr><td>kube-apiserver-etcd-client</td><td>apiserver-etcd-client.key</td><td>apiserver-etcd-client.crt</td><td>kube-apiserver</td><td>--etcd-keyfile</td><td>--etcd-certfile</td></tr><tr><td>kubernetes-ca</td><td>ca.key</td><td>ca.crt</td><td>kube-apiserver</td><td></td><td>--client-ca-file</td></tr><tr><td>kubernetes-ca</td><td>ca.key</td><td>ca.crt</td><td>kube-controller-manager</td><td>--cluster-signing-key-file</td><td>--client-ca-file, --root-ca-file, --cluster-signing-cert-file</td></tr><tr><td>kube-apiserver</td><td>apiserver.key</td><td>apiserver.crt</td><td>kube-apiserver</td><td>--tls-private-key-file</td><td>--tls-cert-file</td></tr><tr><td>kube-apiserver-kubelet-client</td><td>apiserver-kubelet-client.key</td><td>apiserver-kubelet-client.crt</td><td>kube-apiserver</td><td>--kubelet-client-key</td><td>--kubelet-client-certificate</td></tr><tr><td>front-proxy-ca</td><td>front-proxy-ca.key</td><td>front-proxy-ca.crt</td><td>kube-apiserver</td><td></td><td>--requestheader-client-ca-file</td></tr><tr><td>front-proxy-ca</td><td>front-proxy-ca.key</td><td>front-proxy-ca.crt</td><td>kube-controller-manager</td><td></td><td>--requestheader-client-ca-file</td></tr><tr><td>front-proxy-client</td><td>front-proxy-client.key</td><td>front-proxy-client.crt</td><td>kube-apiserver</td><td>--proxy-client-key-file</td><td>--proxy-client-cert-file</td></tr><tr><td>etcd-ca</td><td>etcd/ca.key</td><td>etcd/ca.crt</td><td>etcd</td><td></td><td>--trusted-ca-file, --peer-trusted-ca-file</td></tr><tr><td>kube-etcd</td><td>etcd/server.key</td><td>etcd/server.crt</td><td>etcd</td><td>--key-file</td><td>--cert-file</td></tr><tr><td>kube-etcd-peer</td><td>etcd/peer.key</td><td>etcd/peer.crt</td><td>etcd</td><td>--peer-key-file</td><td>--peer-cert-file</td></tr><tr><td>etcd-ca</td><td></td><td>etcd/ca.crt</td><td>etcdctl</td><td></td><td>--cacert</td></tr><tr><td>kube-etcd-healthcheck-client</td><td>etcd/healthcheck-client.key</td><td>etcd/healthcheck-client.crt</td><td>etcdctl</td><td>--key</td><td>--cert</td></tr></tbody></table><p>서비스 계정 키 쌍에도 동일한 고려 사항이 적용된다.</p><table><thead><tr><th>개인키 경로</th><th>공개 키 경로</th><th>명령어</th><th>파라미터</th></tr></thead><tbody><tr><td>sa.key</td><td></td><td>kube-controller-manager</td><td>--service-account-private-key-file</td></tr><tr><td></td><td>sa.pub</td><td>kube-apiserver</td><td>--service-account-key-file</td></tr></tbody></table><p>다음은 키와 인증서를 모두 생성할 때에 제공해야 하는 <a href=#certificate-paths>이전 표에 있는</a> 파일의 경로를 보여준다.</p><pre tabindex=0><code>/etc/kubernetes/pki/etcd/ca.key
/etc/kubernetes/pki/etcd/ca.crt
/etc/kubernetes/pki/apiserver-etcd-client.key
/etc/kubernetes/pki/apiserver-etcd-client.crt
/etc/kubernetes/pki/ca.key
/etc/kubernetes/pki/ca.crt
/etc/kubernetes/pki/apiserver.key
/etc/kubernetes/pki/apiserver.crt
/etc/kubernetes/pki/apiserver-kubelet-client.key
/etc/kubernetes/pki/apiserver-kubelet-client.crt
/etc/kubernetes/pki/front-proxy-ca.key
/etc/kubernetes/pki/front-proxy-ca.crt
/etc/kubernetes/pki/front-proxy-client.key
/etc/kubernetes/pki/front-proxy-client.crt
/etc/kubernetes/pki/etcd/server.key
/etc/kubernetes/pki/etcd/server.crt
/etc/kubernetes/pki/etcd/peer.key
/etc/kubernetes/pki/etcd/peer.crt
/etc/kubernetes/pki/etcd/healthcheck-client.key
/etc/kubernetes/pki/etcd/healthcheck-client.crt
/etc/kubernetes/pki/sa.key
/etc/kubernetes/pki/sa.pub
</code></pre><h2 id=각-사용자-계정을-위한-인증서-설정하기>각 사용자 계정을 위한 인증서 설정하기</h2><p>반드시 이런 관리자 계정과 서비스 계정을 설정해야 한다.</p><table><thead><tr><th>파일명</th><th>자격증명 이름</th><th>기본 CN</th><th>O (주체에서)</th></tr></thead><tbody><tr><td>admin.conf</td><td>default-admin</td><td>kubernetes-admin</td><td>system:masters</td></tr><tr><td>kubelet.conf</td><td>default-auth</td><td>system:node:<code>&lt;nodeName></code> (note를 보자)</td><td>system:nodes</td></tr><tr><td>controller-manager.conf</td><td>default-controller-manager</td><td>system:kube-controller-manager</td><td></td></tr><tr><td>scheduler.conf</td><td>default-scheduler</td><td>system:kube-scheduler</td><td></td></tr></tbody></table><div class="alert alert-info note callout" role=alert><strong>참고:</strong> <code>kubelet.conf</code>을 위한 <code>&lt;nodeName></code>값은 API 서버에 등록된 것처럼 kubelet에 제공되는 노드 이름 값과 <strong>반드시</strong> 정확히 일치해야 한다. 더 자세한 내용은 <a href=/docs/reference/access-authn-authz/node/>노드 인증</a>을 살펴보자.</div><ol><li><p>각 환경 설정에 대해 주어진 CN과 O를 이용하여 x509 인증서와 키쌍을 생성한다.</p></li><li><p>각 환경 설정에 대해 다음과 같이 <code>kubectl</code>를 실행한다.</p></li></ol><pre tabindex=0><code>KUBECONFIG=&lt;filename&gt; kubectl config set-cluster default-cluster --server=https://&lt;host ip&gt;:6443 --certificate-authority &lt;path-to-kubernetes-ca&gt; --embed-certs
KUBECONFIG=&lt;filename&gt; kubectl config set-credentials &lt;credential-name&gt; --client-key &lt;path-to-key&gt;.pem --client-certificate &lt;path-to-cert&gt;.pem --embed-certs
KUBECONFIG=&lt;filename&gt; kubectl config set-context default-system --cluster default-cluster --user &lt;credential-name&gt;
KUBECONFIG=&lt;filename&gt; kubectl config use-context default-system
</code></pre><p>이 파일들은 다음과 같이 사용된다.</p><table><thead><tr><th>파일명</th><th>명령어</th><th>설명</th></tr></thead><tbody><tr><td>admin.conf</td><td>kubectl</td><td>클러스터 관리자를 설정한다.</td></tr><tr><td>kubelet.conf</td><td>kubelet</td><td>클러스터 각 노드를 위해 필요하다.</td></tr><tr><td>controller-manager.conf</td><td>kube-controller-manager</td><td>반드시 매니페스트를 <code>manifests/kube-controller-manager.yaml</code>에 추가해야 한다.</td></tr><tr><td>scheduler.conf</td><td>kube-scheduler</td><td>반드시 매니페스트를 <code>manifests/kube-scheduler.yaml</code>에 추가해야 한다.</td></tr></tbody></table><p>다음의 파일은 이전 표에 나열된 파일의 전체 경로를 보여준다.</p><pre tabindex=0><code>/etc/kubernetes/admin.conf
/etc/kubernetes/kubelet.conf
/etc/kubernetes/controller-manager.conf
/etc/kubernetes/scheduler.conf
</code></pre></div><div class=td-content style=page-break-before:always><h1 id=pg-92a61cf5b0575aa3500f7665b68127d1>3.5 - 파드 시큐리티 스탠다드 강제하기</h1><p>이 페이지는 <a href=/docs/concepts/security/pod-security-standards>파드 시큐리티 스탠다드(Pod Security Standards)</a>를
강제(enforce)하는 모범 사례에 대한 개요를 제공한다.</p><h2 id=내장된-파드-시큐리티-어드미션-컨트롤러-사용>내장된 파드 시큐리티 어드미션 컨트롤러 사용</h2><div style=margin-top:10px;margin-bottom:10px><b>기능 상태:</b> <code>Kubernetes v1.23 [beta]</code></div><p><a href=/docs/reference/access-authn-authz/admission-controllers/#podsecurity>파드 시큐리티 어드미션 컨트롤러(Pod Security Admission Controller)</a>는
더 이상 사용되지 않는 파드시큐리티폴리시(PodSecurityPolicy)를 대체한다.</p><h3 id=모든-클러스터-네임스페이스-구성>모든 클러스터 네임스페이스 구성</h3><p>구성이 전혀 없는 네임스페이스는 클러스터 시큐리티 모델에서 심각한 틈으로 간주해야
한다. 시간을 들여 각 네임스페이스에서 발생하는 워크로드 유형을 분석하고,
파드 시큐리티 폴리시를 참조하여 각각에 적합한 수준을 결정하는 것을 권장한다.
레이블이 없는 네임스페이스는 아직 평가되지 않았음을 표시해야 한다.</p><p>모든 네임스페이스의 모든 워크로드에 동일한 보안 요구 사항이 있는 시나리오에서,
파드 시큐리티 레이블을 대량으로 적용할 수 있는 방법을 보여주는 <a href=/docs/concepts/security/pod-security-admission/#applying-to-all-namespaces>예시</a>를
제공한다.</p><h3 id=최소-권한-원칙-수용>최소 권한 원칙 수용</h3><p>이상적인 경우 모든 네임스페이스의 모든 파드가 <code>제한된</code> 정책의 요구 사항을 충족할
것이다. 그러나 일부 워크로드는 정당한 이유로 승격된 권한(elevated privilege)이 필요하므로 이는
불가능하거나 실용적이지 않다.</p><ul><li><code>권한 있는(privileged)</code> 워크로드를 허용하는 네임스페이스는 적절한 액세스 제어를 설정하고 시행해야 한다.</li><li>허용되는 네임스페이스에서 실행되는 워크로드의 경우, 고유한 보안 요구 사항에
대한 문서를 유지 관리한다. 가능하다면 이러한 요구 사항을 어떻게 더 제한할 수
있는지 고려해야 한다.</li></ul><h3 id=다중-모드-multi-mode-전략-채택>다중 모드(multi-mode) 전략 채택</h3><p>파드 시큐리티 스탠다드 어드미션 컨트롤러의 <code>감사(audit)</code> 및 <code>경고(warn)</code> 모드를 사용하면 기존 워크로드를
중단하지 않고 파드에 대한 중요한 보안 현황을 쉽게 이해할 수 있다.</p><p>이러한 모드들을 모든 네임스페이스에 <code>강제(enforce)</code>하려는 <em>원하는</em> 수준 및 버전으로
설정하는 것이 좋다. 이 단계에서 생성된 경고 및 감사 어노테이션은 해당 상태로
안내할 수 있다. 워크로드 작성자가 원하는 수준에 맞게 변경을 수행할 것으로 예상되는 경우
<code>경고</code> 모드를 활성화한다. 감사 로그를 사용하여 원하는 수준에 맞게 변경 사항을
모니터링/구동하려는 경우 <code>감사</code> 모드를 활성화한다.</p><p><code>강제</code> 모드를 원하는 값으로 설정한 경우 이러한 모드는 몇 가지 다른 방식으로도
유용할 수 있다.</p><ul><li><code>경고</code>를 <code>강제</code>와 같은 수준으로 설정하면 클라이언트가 유효성 검사를
통과하지 못한 파드(또는 파드 템플릿이 있는 리소스)를 만들려고 할 때 경고를 받게 된다.
이렇게 하면 규정을 준수하도록 해당 리소스를 업데이트하는 데 도움이 된다.</li><li><code>강제</code>를 최신이 아닌 특정 버전에 고정하는 네임스페이스에서는 <code>감사</code> 및 <code>경고</code> 모드가
<code>강제</code>와 동일한 수준으로 설정되지만, <code>최신</code> 버전으로 고정하면 설정(setting) 정보를 볼 수 있다.
이는 이전 버전에서는 허용되지만 현재 모범 사례에서는 허용되지 않는다.</li></ul><h2 id=타사-third-party-대안>타사(third-party) 대안</h2><div class="alert alert-secondary callout third-party-content" role=alert><strong>참고:</strong>
이 섹션은 쿠버네티스에 필요한 기능을 제공하는 써드파티 프로젝트와 관련이 있다. 쿠버네티스 프로젝트 작성자는 써드파티 프로젝트에 책임이 없다. 이 페이지는 <a href=https://github.com/cncf/foundation/blob/master/website-guidelines.md target=_blank>CNCF 웹사이트 가이드라인</a>에 따라 프로젝트를 알파벳 순으로 나열한다. 이 목록에 프로젝트를 추가하려면 변경사항을 제출하기 전에 <a href=/contribute/style/content-guide/#third-party-content>콘텐츠 가이드</a>를 읽어본다.</div><p>쿠버네티스 에코시스템에서 보안 프로필을 적용하기 위한 다른 대안이
개발되고 있다.</p><ul><li><a href=https://github.com/kubewarden>Kubewarden</a>.</li><li><a href=https://kyverno.io/policies/>Kyverno</a>.</li><li><a href=https://github.com/open-policy-agent/gatekeeper>OPA Gatekeeper</a>.</li></ul><p><em>내장</em> 솔루션(예: 파드 시큐리티 어드미션 컨트롤러)과 타사 도구를
사용할지 여부는 전적으로 사용자의 상황에 달려 있다. 솔루션을 평가할 때
공급망의 신뢰가 중요하다. 궁극적으로 앞서 언급한 접근 방식 중
하나를 사용하는 것이 아무것도 하지 않는 것보다 낫다.</p></div></main></div></div><footer class=d-print-none><div class=footer__links><nav><a class=text-white href=/ko/docs/home/>홈</a>
<a class=text-white href=/ko/blog/>블로그</a>
<a class=text-white href=/ko/training/>교육</a>
<a class=text-white href=/ko/partners/>파트너</a>
<a class=text-white href=/ko/community/>Community</a>
<a class=text-white href=/ko/case-studies/>사례 연구</a></nav></div><div class=container-fluid><div class=row><div class="col-6 col-sm-2 text-xs-center order-sm-2"><ul class="list-inline mb-0"><li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title="User mailing list" aria-label="User mailing list"><a class=text-white target=_blank href=https://discuss.kubernetes.io><i class="fa fa-envelope"></i></a></li><li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title=Twitter aria-label=Twitter><a class=text-white target=_blank href=https://twitter.com/kubernetesio><i class="fab fa-twitter"></i></a></li><li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title=Calendar aria-label=Calendar><a class=text-white target=_blank href="https://calendar.google.com/calendar/embed?src=calendar%40kubernetes.io"><i class="fas fa-calendar-alt"></i></a></li><li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title=Youtube aria-label=Youtube><a class=text-white target=_blank href=https://youtube.com/kubernetescommunity><i class="fab fa-youtube"></i></a></li></ul></div><div class="col-6 col-sm-2 text-right text-xs-center order-sm-3"><ul class="list-inline mb-0"><li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title=GitHub aria-label=GitHub><a class=text-white target=_blank href=https://github.com/kubernetes/kubernetes><i class="fab fa-github"></i></a></li><li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title=Slack aria-label=Slack><a class=text-white target=_blank href=https://slack.k8s.io><i class="fab fa-slack"></i></a></li><li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title=Contribute aria-label=Contribute><a class=text-white target=_blank href=https://git.k8s.io/community/contributors/guide><i class="fas fa-edit"></i></a></li><li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title="Stack Overflow" aria-label="Stack Overflow"><a class=text-white target=_blank href=https://stackoverflow.com/questions/tagged/kubernetes><i class="fab fa-stack-overflow"></i></a></li></ul></div><div class="col-12 col-sm-8 text-center order-sm-2"><small class=text-white>&copy; 2023 The Kubernetes Authors | Documentation Distributed under <a href=https://git.k8s.io/website/LICENSE class=light-text>CC BY 4.0</a></small><br><small class=text-white>Copyright &copy; 2023 The Linux Foundation &reg;. All rights reserved. The Linux Foundation has registered trademarks and uses trademarks. For a list of trademarks of The Linux Foundation, please see our <a href=https://www.linuxfoundation.org/trademark-usage class=light-text>Trademark Usage page</a></small><br><small class=text-white>ICP license: 京ICP备17074266号-3</small></div></div></div></footer></div><script src=/js/jquery-3.6.0.min.js integrity=sha384-vtXRMe3mGCbOeY7l30aIg8H9p3GdeSe4IFlP6G8JMa7o7lXvnz3GFKzPxzJdPfGK crossorigin=anonymous></script>
<script src=/js/popper-1.16.1.min.js intregrity=sha384-9/reFTGAW83EW2RDu2S0VKaIzap3H66lZH81PoYlFhbGU+6BZp6G7niu735Sk7lN crossorigin=anonymous></script>
<script src=/js/bootstrap-4.6.1.min.js integrity=sha384-VHvPCCyXqtD5DqJeNxl2dtTyhF78xXNXdkwX1CZeRusQfRKp+tA7hAShOK/B/fQ2 crossorigin=anonymous></script>
<script src=/js/script.js></script>
<script async src=/js/mermaid-8.13.4.min.js integrity=sha384-5hHNvPeMrNH14oM3IcQofDoBhiclNK3g2+hnEinKzQ07C4AliMeVpnvxuiwEGpaO crossorigin=anonymous></script>
<script src=/js/main.min.5c0bf7f21dc4f66485f74efbbeeff28a7e4f8cddaac1bae47043159c922ff3a3.js integrity="sha256-XAv38h3E9mSF9077vu/yin5PjN2qwbrkcEMVnJIv86M=" crossorigin=anonymous></script></body></html>