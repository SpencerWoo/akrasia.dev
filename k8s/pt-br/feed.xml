<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Kubernetes ‚Äì Orquestra√ß√£o de cont√™ineres prontos para produ√ß√£o</title><link>https://kubernetes.io/pt-br/</link><description>The Kubernetes project blog</description><generator>Hugo -- gohugo.io</generator><image><url>https://raw.githubusercontent.com/kubernetes/kubernetes/master/logo/logo.png</url><title>Kubernetes.io</title><link>https://kubernetes.io/pt-br/</link></image><atom:link href="https://kubernetes.io/pt-br/feed.xml" rel="self" type="application/rss+xml"/><item><title>Blog: Atualizado: Perguntas frequentes (FAQ) sobre a remo√ß√£o do Dockershim</title><link>https://kubernetes.io/pt-br/blog/2022/02/17/dockershim-faq/</link><pubDate>Thu, 17 Feb 2022 00:00:00 +0000</pubDate><guid>https://kubernetes.io/pt-br/blog/2022/02/17/dockershim-faq/</guid><description>
&lt;p>&lt;strong>Esta √© uma atualiza√ß√£o do artigo original &lt;a href="https://kubernetes.io/blog/2020/12/02/dockershim-faq/">FAQ sobre a deprecia√ß√£o do Dockershim&lt;/a>,
publicado no final de 2020.&lt;/strong>&lt;/p>
&lt;p>Este documento aborda algumas perguntas frequentes sobre a
descontinua√ß√£o e remo√ß√£o do &lt;em>dockershim&lt;/em>, que foi
&lt;a href="https://kubernetes.io/blog/2020/12/08/kubernetes-1-20-release-announcement/">anunciado&lt;/a>
como parte do lan√ßamento do Kubernetes v1.20. Para obter mais detalhes sobre
o que isso significa, confira a postagem do blog
&lt;a href="https://kubernetes.io/pt-br/blog/2020/12/02/dont-panic-kubernetes-and-docker/">N√£o entre em p√¢nico: Kubernetes e Docker&lt;/a>.&lt;/p>
&lt;p>Al√©m disso, voc√™ pode ler &lt;a href="https://kubernetes.io/docs/tasks/administer-cluster/migrating-from-dockershim/check-if-dockershim-removal-affects-you/">verifique se a remo√ß√£o do dockershim afeta voc√™&lt;/a>
para determinar qual impacto a remo√ß√£o do &lt;em>dockershim&lt;/em> teria para voc√™
ou para sua organiza√ß√£o.&lt;/p>
&lt;p>Como o lan√ßamento do Kubernetes 1.24 se tornou iminente, estamos trabalhando bastante para tentar fazer uma transi√ß√£o suave.&lt;/p>
&lt;ul>
&lt;li>Escrevemos uma postagem no blog detalhando nosso &lt;a href="https://kubernetes.io/blog/2022/01/07/kubernetes-is-moving-on-from-dockershim/">compromisso e os pr√≥ximos passos&lt;/a>.&lt;/li>
&lt;li>Acreditamos que n√£o h√° grandes obst√°culos para a migra√ß√£o para &lt;a href="https://kubernetes.io/docs/setup/production-environment/container-runtimes/#container-runtimes">outros agentes de execu√ß√£o de cont√™iner&lt;/a>.&lt;/li>
&lt;li>H√° tamb√©m um guia &lt;a href="https://kubernetes.io/docs/tasks/administer-cluster/migrating-from-dockershim/">Migrando do dockershim&lt;/a> dispon√≠vel.&lt;/li>
&lt;li>Tamb√©m criamos uma p√°gina para listar
&lt;a href="https://kubernetes.io/docs/reference/node/topics-on-dockershim-and-cri-compatible-runtimes/">artigos sobre a remo√ß√£o do dockershim e sobre o uso de agentes de execu√ß√£o compat√≠veis com CRI&lt;/a>. Essa lista inclui alguns dos documentos j√° mencionados e tamb√©m
abrange fontes externas selecionadas (incluindo guias de fornecedores).&lt;/li>
&lt;/ul>
&lt;h3 id="por-que-o-dockershim-est√°-sendo-removido-do-kubernetes">Por que o &lt;em>dockershim&lt;/em> est√° sendo removido do Kubernetes?&lt;/h3>
&lt;p>As primeiras vers√µes do Kubernetes funcionavam apenas com um ambiente de execu√ß√£o de cont√™iner espec√≠fico:
Docker Engine. Mais tarde, o Kubernetes adicionou suporte para trabalhar com outros agentes de execu√ß√£o de cont√™iner.
O padr√£o CRI (&lt;em>Container Runtime Interface&lt;/em> ou Interface de Agente de Execu√ß√£o de Containers) foi &lt;a href="https://kubernetes.io/blog/2016/12/container-runtime-interface-cri-in-kubernetes/">criado&lt;/a> para
habilitar a interoperabilidade entre orquestradores (como Kubernetes) e diferentes agentes
de execu√ß√£o de cont√™iner.
O Docker Engine n√£o implementa essa interface (CRI), ent√£o o projeto Kubernetes criou um
c√≥digo especial para ajudar na transi√ß√£o, e tornou esse c√≥digo &lt;em>dockershim&lt;/em> parte do projeto
Kubernetes.&lt;/p>
&lt;p>O c√≥digo &lt;em>dockershim&lt;/em> sempre foi destinado a ser uma solu√ß√£o tempor√°ria (da√≠ o nome: &lt;em>shim&lt;/em>).
Voc√™ pode ler mais sobre a discuss√£o e o planejamento da comunidade na
&lt;a href="https://github.com/kubernetes/enhancements/tree/master/keps/sig-node/2221-remove-dockershim">Proposta de remo√ß√£o do Dockershim para aprimoramento do Kubernetes&lt;/a>.
Na verdade, manter o &lt;em>dockershim&lt;/em> se tornou um fardo pesado para os mantenedores do Kubernetes.&lt;/p>
&lt;p>Al√©m disso, recursos que s√£o amplamente incompat√≠veis com o &lt;em>dockershim&lt;/em>, como
&lt;em>cgroups v2&lt;/em> e &lt;em>namespaces&lt;/em> de usu√°rio est√£o sendo implementados nos agentes de execu√ß√£o de CRI
mais recentes. A remo√ß√£o do suporte para o &lt;em>dockershim&lt;/em> permitir√° um maior
desenvolvimento nessas √°reas.&lt;/p>
&lt;h3 id="ainda-posso-usar-o-docker-engine-no-kubernetes-1-23">Ainda posso usar o Docker Engine no Kubernetes 1.23?&lt;/h3>
&lt;p>Sim, a √∫nica coisa que mudou na vers√£o 1.20 √© a presen√ßa de um aviso no log de inicializa√ß√£o
do &lt;a href="https://kubernetes.io/docs/reference/command-line-tools-reference/kubelet/">kubelet&lt;/a> se estiver usando o Docker Engine como agente de execu√ß√£o de cont√™iner.
Voc√™ ver√° este aviso em todas as vers√µes at√© 1.23. A remo√ß√£o do &lt;em>dockershim&lt;/em> ocorre no Kubernetes 1.24.&lt;/p>
&lt;h3 id="quando-o-dockershim-ser√°-removido">Quando o &lt;em>dockershim&lt;/em> ser√° removido?&lt;/h3>
&lt;p>Dado o impacto dessa mudan√ßa, estamos definindo um cronograma de deprecia√ß√£o mais longo.
A remo√ß√£o do &lt;em>dockershim&lt;/em> est√° agendada para o Kubernetes v1.24, consulte a
&lt;a href="https://github.com/kubernetes/enhancements/tree/master/keps/sig-node/2221-remove-dockershim">Proposta de remo√ß√£o do Dockershim para aprimoramento do Kubernetes&lt;/a>.
O projeto Kubernetes trabalhar√° em estreita colabora√ß√£o com fornecedores e outros ecossistemas para garantir
uma transi√ß√£o suave e avaliar√° os acontecimentos √† medida que a situa√ß√£o for evoluindo.&lt;/p>
&lt;h3 id="ainda-posso-usar-o-docker-engine-como-meu-agente-de-execu√ß√£o-do-cont√™iner">Ainda posso usar o Docker Engine como meu agente de execu√ß√£o do cont√™iner?&lt;/h3>
&lt;p>Primeiro, se voc√™ usa o Docker em seu pr√≥prio PC para desenvolver ou testar cont√™ineres: nada muda.
Voc√™ ainda pode usar o Docker localmente, independentemente dos agentes de execu√ß√£o de cont√™iner que
voc√™ usa em seus Clusters Kubernetes. Os cont√™ineres tornam esse tipo de interoperabilidade poss√≠vel.&lt;/p>
&lt;p>Mirantis e Docker &lt;a href="https://www.mirantis.com/blog/mirantis-to-take-over-support-of-kubernetes-dockershim-2/">comprometeram-se&lt;/a> a manter um adaptador substituto para o
Docker Engine, e a manter este adaptador mesmo ap√≥s o &lt;em>dockershim&lt;/em> ser removido
do Kubernetes. O adaptador substituto √© chamado &lt;a href="https://github.com/Mirantis/cri-dockerd">&lt;code>cri-dockerd&lt;/code>&lt;/a>.&lt;/p>
&lt;h3 id="minhas-imagens-de-cont√™iner-existentes-ainda-funcionar√£o">Minhas imagens de cont√™iner existentes ainda funcionar√£o?&lt;/h3>
&lt;p>Sim, as imagens produzidas a partir do &lt;code>docker build&lt;/code> funcionar√£o com todas as implementa√ß√µes do CRI.
Todas as suas imagens existentes ainda funcionar√£o exatamente da mesma forma.&lt;/p>
&lt;h4 id="e-as-imagens-privadas">E as imagens privadas?&lt;/h4>
&lt;p>Sim. Todos os agentes de execu√ß√£o de CRI s√£o compat√≠veis com as mesmas configura√ß√µes de segredos usadas no
Kubernetes, seja por meio do PodSpec ou ServiceAccount.&lt;/p>
&lt;h3 id="docker-e-cont√™ineres-s√£o-a-mesma-coisa">Docker e cont√™ineres s√£o a mesma coisa?&lt;/h3>
&lt;p>Docker popularizou o padr√£o de cont√™ineres Linux e tem sido fundamental no
desenvolvimento desta tecnologia. No entanto, os cont√™ineres j√° existiam
no Linux h√° muito tempo. O ecossistema de cont√™ineres cresceu para ser muito
mais abrangente do que apenas Docker. Padr√µes como o OCI e o CRI ajudaram muitas
ferramentas a crescer e prosperar no nosso ecossistema, alguns substituindo
aspectos do Docker, enquanto outros aprimoram funcionalidades j√° existentes.&lt;/p>
&lt;h3 id="existem-exemplos-de-pessoas-que-usam-outros-agentes-de-execu√ß√£o-de-cont√™ineres-em-produ√ß√£o-hoje">Existem exemplos de pessoas que usam outros agentes de execu√ß√£o de cont√™ineres em produ√ß√£o hoje?&lt;/h3>
&lt;p>Todos os artefatos produzidos pelo projeto Kubernetes (bin√°rios Kubernetes) s√£o validados
a cada lan√ßamento de vers√£o.&lt;/p>
&lt;p>Al√©m disso, o projeto &lt;a href="https://kind.sigs.k8s.io/">kind&lt;/a> vem usando containerd h√° algum tempo e tem
visto uma melhoria na estabilidade para seu caso de uso. Kind e containerd s√£o executados
v√°rias vezes todos os dias para validar quaisquer altera√ß√µes na base de c√≥digo do Kubernetes.
Outros projetos relacionados seguem um padr√£o semelhante, demonstrando a estabilidade e
usabilidade de outros agentes de execu√ß√£o de cont√™iner. Como exemplo, o OpenShift 4.x utiliza
o agente de execu√ß√£o &lt;a href="https://cri-o.io/">CRI-O&lt;/a> em produ√ß√£o desde junho de 2019.&lt;/p>
&lt;p>Para outros exemplos e refer√™ncias, d√™ uma olhada em projetos adeptos do containerd e
CRI-O, dois agentes de execu√ß√£o de cont√™ineres sob o controle da &lt;em>Cloud Native Computing Foundation&lt;/em>
(&lt;a href="https://cncf.io">CNCF&lt;/a>).&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://github.com/containerd/containerd/blob/master/ADOPTERS.md">containerd&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://github.com/cri-o/cri-o/blob/master/ADOPTERS.md">CRI-O&lt;/a>&lt;/li>
&lt;/ul>
&lt;h3 id="as-pessoas-continuam-referenciando-oci-o-que-√©-isso">As pessoas continuam referenciando OCI, o que √© isso?&lt;/h3>
&lt;p>OCI significa &lt;em>&lt;a href="https://opencontainers.org/about/overview/">Open Container Initiative&lt;/a>&lt;/em> (ou Iniciativa Open Source de Cont√™ineres), que padronizou muitas das
interfaces entre ferramentas e tecnologias de cont√™iner. Eles mant√™m uma
especifica√ß√£o padr√£o para imagens de cont√™iner (OCI image-spec) e para
cont√™ineres em execu√ß√£o (OCI runtime-spec). Eles tamb√©m mant√™m uma implementa√ß√£o real
da especifica√ß√£o do agente de execu√ß√£o na forma de &lt;a href="https://github.com/opencontainers/runc">runc&lt;/a>, que √© o agente de execu√ß√£o padr√£o
para ambos &lt;a href="https://containerd.io/">containerd&lt;/a> e &lt;a href="https://cri-o.io/">CRI-O&lt;/a>. O CRI baseia-se nessas especifica√ß√µes de baixo n√≠vel para
fornecer um padr√£o de ponta a ponta para gerenciar cont√™ineres.&lt;/p>
&lt;h3 id="qual-implementa√ß√£o-de-cri-devo-usar">Qual implementa√ß√£o de CRI devo usar?&lt;/h3>
&lt;p>Essa √© uma pergunta complexa e depende de muitos fatores. Se voc√™ estiver
trabalhando com Docker, mudar para containerd deve ser uma troca relativamente f√°cil e
ter√° um desempenho estritamente melhor e menos sobrecarga. No entanto, n√≥s encorajamos voc√™ a
explorar todas as op√ß√µes do &lt;a href="https://landscape.cncf.io/card-mode?category=container-runtime&amp;amp;grouping=category">cen√°rio CNCF&lt;/a>, pois outro agente de execu√ß√£o de cont√™iner
pode funcionar ainda melhor para o seu ambiente.&lt;/p>
&lt;h3 id="o-que-devo-ficar-atento-ao-mudar-a-minha-implementa√ß√£o-de-cri-utilizada">O que devo ficar atento ao mudar a minha implementa√ß√£o de CRI utilizada?&lt;/h3>
&lt;p>Embora o c√≥digo de conteineriza√ß√£o base seja o mesmo entre o Docker e a maioria dos
CRIs (incluindo containerd), existem algumas poucas diferen√ßas. Alguns
pontos a se considerar ao migrar s√£o:&lt;/p>
&lt;ul>
&lt;li>Configura√ß√£o de &lt;em>log&lt;/em>&lt;/li>
&lt;li>Limita√ß√µes de recursos de agentes de execu√ß√£o&lt;/li>
&lt;li>Scripts de provisionamento que chamam o docker ou usam o docker por meio de seu soquete de controle&lt;/li>
&lt;li>Plugins kubectl que exigem CLI do docker ou o soquete de controle&lt;/li>
&lt;li>Ferramentas do projeto Kubernetes que requerem acesso direto ao Docker Engine
(por exemplo: a ferramenta depreciada &lt;code>kube-imagepuller&lt;/code>)&lt;/li>
&lt;li>Configura√ß√£o de funcionalidades como &lt;code>registry-mirrors&lt;/code> e &lt;em>registries&lt;/em> inseguros&lt;/li>
&lt;li>Outros scripts de suporte ou &lt;em>daemons&lt;/em> que esperam que o Docker Engine esteja dispon√≠vel e seja executado
fora do Kubernetes (por exemplo, agentes de monitoramento ou seguran√ßa)&lt;/li>
&lt;li>GPUs ou hardware especial e como eles se integram ao seu agente de execu√ß√£o e ao Kubernetes&lt;/li>
&lt;/ul>
&lt;p>Se voc√™ usa solicita√ß√µes ou limites de recursos do Kubernetes ou usa DaemonSets para coleta de logs
em arquivos, eles continuar√£o a funcionar da mesma forma. Mas se voc√™ personalizou
sua configura√ß√£o &lt;code>dockerd&lt;/code>, voc√™ precisar√° adapt√°-la para seu novo agente de execu√ß√£o de
cont√™iner assim que poss√≠vel.&lt;/p>
&lt;p>Outro aspecto a ser observado √© que ferramentas para manuten√ß√£o do sistema ou execu√ß√µes dentro de um
cont√™iner no momento da cria√ß√£o de imagens podem n√£o funcionar mais. Para o primeiro, a ferramenta
&lt;a href="https://github.com/kubernetes-sigs/cri-tools">&lt;code>crictl&lt;/code>&lt;/a> pode ser utilizada como um substituto natural (veja
&lt;a href="https://kubernetes.io/docs/tasks/debug/debug-cluster/crictl/#mapping-from-docker-cli-to-crictl">migrando do docker cli para o crictl&lt;/a>)
e para o √∫ltimo, voc√™ pode usar novas op√ß√µes de constru√ß√µes de cont√™iner, como &lt;a href="https://github.com/genuinetools/img">img&lt;/a>, &lt;a href="https://github.com/containers/buildah">buildah&lt;/a>,
&lt;a href="https://github.com/GoogleContainerTools/kaniko">kaniko&lt;/a>, ou &lt;a href="https://github.com/vmware-tanzu/buildkit-cli-for-kubectl">buildkit-cli-for-kubectl&lt;/a> que n√£o requerem Docker.&lt;/p>
&lt;p>Para containerd, voc√™ pode come√ßar com sua &lt;a href="https://github.com/containerd/cri/blob/master/docs/registry.md">documenta√ß√£o&lt;/a> para ver quais op√ß√µes de configura√ß√£o
est√£o dispon√≠veis √† medida que voc√™ v√° realizando a migra√ß√£o.&lt;/p>
&lt;p>Para obter instru√ß√µes sobre como usar containerd e CRI-O com Kubernetes, consulte o
documenta√ß√£o do Kubernetes em &lt;a href="https://kubernetes.io/docs/setup/production-environment/container-runtimes/">Agentes de execu√ß√£o de cont√™ineres&lt;/a>&lt;/p>
&lt;h3 id="e-se-eu-tiver-mais-perguntas">E se eu tiver mais perguntas?&lt;/h3>
&lt;p>Se voc√™ usa uma distribui√ß√£o do Kubernetes com suporte do fornecedor, pode perguntar a eles sobre
planos de atualiza√ß√£o para seus produtos. Para perguntas de usu√°rio final, poste-as
no nosso f√≥rum da comunidade de usu√°rios: &lt;a href="https://discuss.kubernetes.io/">https://discuss.kubernetes.io/&lt;/a>.&lt;/p>
&lt;p>Voc√™ tamb√©m pode conferir a excelente postagem do blog
&lt;a href="https://dev.to/inductor/wait-docker-is-deprecated-in-kubernetes-now-what-do-i-do-e4m">Espere, o Docker est√° depreciado no Kubernetes agora?&lt;/a>, uma discuss√£o t√©cnica mais aprofundada
sobre as mudan√ßas.&lt;/p>
&lt;h3 id="posso-ganhar-um-abra√ßo">Posso ganhar um abra√ßo?&lt;/h3>
&lt;p>Sim, ainda estamos dando abra√ßos se solicitado. ü§óü§óü§ó&lt;/p></description></item><item><title>Blog: N√£o entre em p√¢nico: Kubernetes e Docker</title><link>https://kubernetes.io/pt-br/blog/2020/12/02/dont-panic-kubernetes-and-docker/</link><pubDate>Wed, 02 Dec 2020 00:00:00 +0000</pubDate><guid>https://kubernetes.io/pt-br/blog/2020/12/02/dont-panic-kubernetes-and-docker/</guid><description>
&lt;p>&lt;strong>Autores / Autoras&lt;/strong>: Jorge Castro, Duffie Cooley, Kat Cosgrove, Justin Garrison, Noah Kantrowitz, Bob Killen, Rey Lejano, Dan ‚ÄúPOP‚Äù Papandrea, Jeffrey Sica, Davanum ‚ÄúDims‚Äù Srinivas&lt;/p>
&lt;p>&lt;strong>Tradu√ß√£o:&lt;/strong> Jo√£o Brito&lt;/p>
&lt;p>Kubernetes est√° &lt;a href="https://github.com/kubernetes/kubernetes/blob/master/CHANGELOG/CHANGELOG-1.20.md#deprecation">deixando de usar Docker&lt;/a> como seu agente de execu√ß√£o ap√≥s a vers√£o v1.20.&lt;/p>
&lt;p>&lt;strong>N√£o entre em p√¢nico. N√£o √© t√£o dram√°tico quanto parece.&lt;/strong>&lt;/p>
&lt;p>TL;DR Docker como um agente de execu√ß√£o prim√°rio est√° sendo deixado de lado em favor de agentes de execu√ß√£o que utilizam a Interface de Agente de Execu√ß√£o de Containers (Container Runtime Interface &amp;quot;CRI&amp;quot;) criada para o Kubernetes. As imagens criadas com o Docker continuar√£o a funcionar em seu cluster com os agentes atuais, como sempre estiveram.&lt;/p>
&lt;p>Se voc√™ √© um usu√°rio final de Kubernetes, quase nada mudar√° para voc√™. Isso n√£o significa a morte do Docker, e isso n√£o significa que voc√™ n√£o pode, ou n√£o deva, usar ferramentas Docker em desenvolvimento mais. Docker ainda √© uma ferramenta √∫til para a constru√ß√£o de containers, e as imagens resultantes de executar &lt;code>docker build&lt;/code> ainda rodar√£o em seu cluster Kubernetes.&lt;/p>
&lt;p>Se voc√™ est√° usando um Kubernetes gerenciado como GKE, EKS, ou AKS (que usa como &lt;a href="https://github.com/Azure/AKS/releases/tag/2020-11-16">padr√£o containerd&lt;/a>) voc√™ precisar√° ter certeza que seus n√≥s est√£o usando um agente de execu√ß√£o de container suportado antes que o suporte ao Docker seja removido nas vers√µes futuras do Kubernetes. Se voc√™ tem mudan√ßas em seus n√≥s, talvez voc√™ precise atualiz√°-los baseado em seu ambiente e necessidades do agente de execu√ß√£o.&lt;/p>
&lt;p>Se voc√™ est√° rodando seus pr√≥prios clusters, voc√™ tamb√©m precisa fazer mudan√ßas para evitar quebras em seu cluster. Na vers√£o v1.20, voc√™ ter√° o aviso de alerta da perda de suporte ao Docker. Quando o suporte ao agente de execu√ß√£o do Docker for removido em uma vers√£o futura (atualmente planejado para a vers√£o 1.22 no final de 2021) do Kubernetes ele n√£o ser√° mais suportado e voc√™ precisar√° trocar para um dos outros agentes de execu√ß√£o de container compat√≠vel, como o containerd ou CRI-O. Mas tenha certeza que esse agente de execu√ß√£o escolhido tenha suporte √†s configura√ß√µes do daemon do Docker usadas atualmente (Ex.: logs)&lt;/p>
&lt;h2 id="ent√£o-porque-a-confus√£o-e-toda-essa-turma-surtando">Ent√£o porque a confus√£o e toda essa turma surtando?&lt;/h2>
&lt;p>Estamos falando aqui de dois ambientes diferentes, e isso est√° criando essa confus√£o. Dentro do seu cluster Kubernetes, existe uma coisa chamada de agente de execu√ß√£o de container que √© respons√°vel por baixar e executar as imagens de seu container. Docker √© a escolha popular para esse agente de execu√ß√£o (outras escolhas comuns incluem containerd e CRI-O), mas Docker n√£o foi projetado para ser embutido no Kubernetes, e isso causa problemas.&lt;/p>
&lt;p>Se liga, o que chamamos de &amp;quot;Docker&amp;quot; n√£o √© exatamente uma coisa - √© uma stack tecnol√≥gica inteira, e uma parte disso √© chamado de &amp;quot;containerd&amp;quot;, que √© o agente de execu√ß√£o de container de alto-n√≠vel por si s√≥. Docker √© legal e √∫til porque ele possui muitas melhorias de experi√™ncia do usu√°rio e isso o torna realmente f√°cil para humanos interagirem com ele enquanto est√£o desenvolvendo, mas essas melhorias para o usu√°rio n√£o s√£o necess√°rias para o Kubernetes, pois ele n√£o √© humano.&lt;/p>
&lt;p>Como resultado dessa camada de abstra√ß√£o amig√°vel aos humanos, seu cluster Kubernetes precisa usar outra ferramenta chamada Dockershim para ter o que ele realmente precisa, que √© o containerd. Isso n√£o √© muito bom, porque adiciona outra coisa a ser mantida e que pode quebrar. O que est√° atualmente acontecendo aqui √© que o Dockershim est√° sendo removido do Kubelet assim que que a vers√£o v1.23 for lan√ßada, que remove o suporte ao Docker como agente de execu√ß√£o de container como resultado. Voc√™ deve estar pensando, mas se o containerd est√° incluso na stack do Docker, porque o Kubernetes precisa do Dockershim?&lt;/p>
&lt;p>Docker n√£o √© compat√≠vel com CRI, a &lt;a href="https://kubernetes.io/blog/2016/12/container-runtime-interface-cri-in-kubernetes/">Container Runtime Interface&lt;/a> (interface do agente de execu√ß√£o de container). Se fosse, n√≥s n√£o precisar√≠amos do shim, e isso n√£o seria nenhum problema. Mas isso n√£o √© o fim do mundo, e voc√™ n√£o precisa entrar em p√¢nico - voc√™ s√≥ precisa mudar seu agente de execu√ß√£o de container do Docker para um outro suportado.&lt;/p>
&lt;p>Uma coisa a ser notada: Se voc√™ est√° contando com o socket do Docker (&lt;code>/var/run/docker.sock&lt;/code>) como parte do seu fluxo de trabalho em seu cluster hoje, mover para um agente de execu√ß√£o diferente acaba com sua habilidade de us√°-lo. Esse modelo √© conhecido como Docker em Docker. Existem diversas op√ß√µes por a√≠ para esse caso espec√≠fico como o &lt;a href="https://github.com/GoogleContainerTools/kaniko">kaniko&lt;/a>, &lt;a href="https://github.com/genuinetools/img">img&lt;/a>, e &lt;a href="https://github.com/containers/buildah">buildah&lt;/a>.&lt;/p>
&lt;h2 id="o-que-essa-mudan√ßa-representa-para-os-desenvolvedores-ainda-escrevemos-dockerfiles-ainda-vamos-fazer-build-com-docker">O que essa mudan√ßa representa para os desenvolvedores? Ainda escrevemos Dockerfiles? Ainda vamos fazer build com Docker?&lt;/h2>
&lt;p>Essa mudan√ßa aborda um ambiente diferente do que a maioria das pessoas usa para interagir com Docker. A instala√ß√£o do Docker que voc√™ est√° usando em desenvolvimento n√£o tem rela√ß√£o com o agente de execu√ß√£o de Docker dentro de seu cluster Kubernetes. √â confuso, d√° pra entender.
Como desenvolvedor, Docker ainda √© √∫til para voc√™ em todas as formas que era antes dessa mudan√ßa ser anunciada. A imagem que o Docker cria n√£o √© uma imagem espec√≠fica para Docker e sim uma imagem que segue o padr√£o OCI (&lt;a href="https://opencontainers.org/">Open Container Initiative&lt;/a>).&lt;/p>
&lt;p>Qualquer imagem compat√≠vel com OCI, independente da ferramenta usada para constru√≠-la ser√° vista da mesma forma pelo Kubernetes. Ambos &lt;a href="https://containerd.io/">containerd&lt;/a> e &lt;a href="https://cri-o.io/">CRI-O&lt;/a> sabem como baixar e execut√°-las. Esse √© o porque temos um padr√£o para containers.&lt;/p>
&lt;p>Ent√£o, essa mudan√ßa est√° chegando. Isso ir√° causar problemas para alguns, mas nada catastr√≥fico, no geral √© uma boa coisa. Dependendo de como voc√™ interage com o Kubernetes, isso tornar√° as coisas mais f√°ceis. Se isso ainda √© confuso para voc√™, tudo bem, tem muita coisa rolando aqui; Kubernetes tem um monte de partes m√≥veis, e ningu√©m √© 100% especialista nisso. N√≥s encorajamos toda e qualquer tipo de quest√£o independente do n√≠vel de experi√™ncia ou de complexidade! Nosso objetivo √© ter certeza que todos est√£o entendendo o m√°ximo poss√≠vel as mudan√ßas que est√£o chegando. Esperamos que isso tenha respondido a maioria de suas quest√µes e acalmado algumas ansiedades! ‚ù§Ô∏è&lt;/p>
&lt;p>Procurando mais respostas? D√™ uma olhada em nosso apanhado de &lt;a href="https://kubernetes.io/blog/2020/12/02/dockershim-faq/">quest√µes quanto ao desuso do Dockershim&lt;/a>.&lt;/p></description></item><item><title>Blog: Escalando a rede do Kubernetes com EndpointSlices</title><link>https://kubernetes.io/pt-br/blog/2020/09/02/scaling-kubernetes-networking-with-endpointslices/</link><pubDate>Wed, 02 Sep 2020 00:00:00 +0000</pubDate><guid>https://kubernetes.io/pt-br/blog/2020/09/02/scaling-kubernetes-networking-with-endpointslices/</guid><description>
&lt;p>&lt;strong>Autor:&lt;/strong> Rob Scott (Google)&lt;/p>
&lt;p>EndpointSlices √© um novo tipo de API que prov√™ uma alternativa escal√°vel e extens√≠vel √† API de Endpoints. EndpointSlices mant√©m o rastreio dos endere√ßos IP, portas, informa√ß√µes de topologia e prontid√£o de Pods que comp√µem um servi√ßo.&lt;/p>
&lt;p>No Kubernetes 1.19 essa funcionalidade est√° habilitada por padr√£o, com o kube-proxy lendo os &lt;a href="https://kubernetes.io/docs/concepts/services-networking/endpoint-slices/">EndpointSlices&lt;/a> ao inv√©s de Endpoints. Apesar de isso ser uma mudan√ßa praticamente transparente, resulta numa melhoria not√°vel de escalabilidade em grandes clusters. Tamb√©m permite a adi√ß√£o de novas funcionalidades em releases futuras do Kubernetes, como o &lt;a href="https://kubernetes.io/docs/concepts/services-networking/service-topology/">Roteamento baseado em topologia.&lt;/a>.&lt;/p>
&lt;h2 id="limita√ß√µes-de-escalabilidade-da-api-de-endpoints">Limita√ß√µes de escalabilidade da API de Endpoints&lt;/h2>
&lt;p>Na API de Endpoints, existia apenas um recurso de Endpoint por servi√ßo (Service). Isso significa que
era necess√°rio ser poss√≠vel armazenar endere√ßos IPs e portas para cada Pod que compunha o servi√ßo correspondente. Isso resultava em recursos imensos de API. Para piorar, o kube-proxy rodava em cada um dos n√≥s e observava qualquer altera√ß√£o nos recursos de Endpoint. Mesmo que fosse uma simples mudan√ßa em um Endpoint, todo o objeto precisava ser enviado para cada uma das inst√¢ncias do kube-proxy.&lt;/p>
&lt;p>Outra limita√ß√£o da API de Endpoints era que ela limitava o n√∫mero de objetos que podiam ser associados a um &lt;em>Service&lt;/em>. O tamanho padr√£o de um objeto armazenado no etcd √© 1.5MB. Em alguns casos, isso poderia limitar um Endpoint a 5,000 IPs de Pod. Isso n√£o chega a ser um problema para a maioria dos usu√°rios, mas torna-se um problema significativo para servi√ßos que se aproximem desse tamanho.&lt;/p>
&lt;p>Para demonstrar o qu√£o significante se torna esse problema em grande escala, vamos usar de um simples exemplo: Imagine um &lt;em>Service&lt;/em> que possua 5,000 Pods, e que possa causar o Endpoint a ter 1.5Mb . Se apenas um Endpoint nessa lista sofra uma altera√ß√£o, todo o objeto de Endpoint precisar√° ser redistribu√≠do para cada um dos n√≥s do cluster. Em um cluster com 3.000 n√≥s, essa atualiza√ß√£o causar√° o envio de 4.5Gb de dados (1.5Mb de Endpoints * 3,000 n√≥s) para todo o cluster. Isso √© quase que o suficiente para encher um DVD, e acontecer√° para cada mudan√ßa de Endpoint. Agora imagine uma atualiza√ß√£o gradual em um &lt;em>Deployment&lt;/em> que resulte nos 5,000 Pods serem substitu√≠dos - isso √© mais que 22Tb (ou 5,000 DVDs) de dados transferidos.&lt;/p>
&lt;h2 id="dividindo-os-endpoints-com-a-api-de-endpointslice">Dividindo os endpoints com a API de EndpointSlice&lt;/h2>
&lt;p>A API de EndpointSlice foi desenhada para resolver esse problema com um modelo similar de &lt;em>sharding&lt;/em>. Ao inv√©s de rastrar todos os IPs dos Pods para um &lt;em>Service&lt;/em>, com um √∫nico recurso de Endpoint, n√≥s dividimos eles em m√∫ltiplos EndpointSlices menores.&lt;/p>
&lt;p>Usemos por exemplo um servi√ßo com 15 pods. N√≥s ter√≠amos um √∫nico recurso de Endpoints referente a todos eles. Se o EndpointSlices for configurado para armazenar 5 &lt;em>endpoints&lt;/em> cada, n√≥s ter√≠amos 3 EndpointSlices diferentes:
&lt;img src="https://kubernetes.io/images/blog/2020-09-02-scaling-kubernetes-networking-endpointslices/endpoint-slices.png" alt="EndpointSlices">&lt;/p>
&lt;p>Por padr√£o, o EndpointSlices armazena um m√°ximo de 100 &lt;em>endpoints&lt;/em> cada, podendo isso ser configurado com a flag &lt;code>--max-endpoints-per-slice&lt;/code> no kube-controller-manager.&lt;/p>
&lt;h2 id="endpointslices-prov√™-uma-melhoria-de-escalabilidade-em-10x">EndpointSlices prov√™ uma melhoria de escalabilidade em 10x&lt;/h2>
&lt;p>Essa API melhora dramaticamente a escalabilidade da rede. Agora quando um Pod √© adicionado ou removido, apenas 1 pequeno EndpointSlice necessita ser atualizado. Essa diferen√ßa come√ßa a ser notada quando centenas ou milhares de Pods comp√µem um √∫nico &lt;em>Service&lt;/em>.&lt;/p>
&lt;p>Mais significativo, agora que todos os IPs de Pods para um &lt;em>Service&lt;/em> n√£o precisam ser armazenados em um √∫nico recurso, n√≥s n√£o precisamos nos preocupar com o limite de tamanho para objetos armazendos no etcd. EndpointSlices j√° foram utilizados para escalar um servi√ßo al√©m de 100,000 endpoints de rede.&lt;/p>
&lt;p>Tudo isso √© poss√≠vel com uma melhoria significativa de performance feita no kube-proxy. Quando o EndpointSlices √© usado em grande escala, muito menos dados ser√£o transferidos para as atualiza√ß√µes de endpoints e o kube-proxy torna-se mais r√°pido para atualizar regras do iptables ou do ipvs. Al√©m disso, os &lt;em>Services&lt;/em> podem escalar agora para pelo menos 10x mais al√©m dos limites anteriores.&lt;/p>
&lt;h2 id="endpointslices-permitem-novas-funcionalidades">EndpointSlices permitem novas funcionalidades&lt;/h2>
&lt;p>Introduzido como uma funcionalidade alpha no Kubernetes v1.16, os EndpointSlices foram constru√≠dos para permitir algumas novas funcionalidades arrebatadoras em futuras vers√µes do Kubernetes. Isso inclui servi√ßos dual-stack, roteamento baseado em topologia e subconjuntos de &lt;em>endpoints&lt;/em>.&lt;/p>
&lt;p>Servi√ßos Dual-stack s√£o uma nova funcionalidade que foi desenvolvida juntamente com o EndpointSlices. Eles ir√£o utilizar simult√¢neamente endere√ßos IPv4 e IPv6 para servi√ßos, e dependem do campo addressType do Endpointslices para conter esses novos tipos de endere√ßo por fam√≠lia de IP.&lt;/p>
&lt;p>O roteamento baseado por topologia ir√° atualizar o kube-proxy para dar prefer√™ncia no roteamento de requisi√ß√µes para a mesma regi√£o ou zona, utilizando-se de campos de topologia armazenados em cada endpoint dentro de um EndpointSlice. Como uma melhoria futura disso, estamos explorando o potencial de subconjuntos de endpoint. Isso ir√° permitir o kube-proxy apenas observar um subconjunto de EndpointSlices. Por exemplo, isso pode ser combinado com o roteamento baseado em topologia e assim, o kube-proxy precisar√° observar apenas EndpointSlices contendo &lt;em>endpoints&lt;/em> na mesma zona. Isso ir√° permitir uma outra melhoria significativa de escalabilidade.&lt;/p>
&lt;h2 id="o-que-isso-significa-para-a-api-de-endpoints">O que isso significa para a API de Endpoints?&lt;/h2>
&lt;p>Apesar da API de EndpointSlice prover uma alternativa nova e escal√°vel √† API de Endpoints, a API de Endpoints continuar√° a ser considerada uma funcionalidade est√°vel. A mudan√ßa mais significativa para a API de Endpoints envolve come√ßar a truncar Endpoints que podem causar problemas de escalabilidade.&lt;/p>
&lt;p>A API de Endpoints n√£o ser√° removida, mas muitas novas funcionalidades ir√£o depender da nova API EndpointSlice. Para obter vant√°gem da funcionalidade e escalabilidade que os EndpointSlices prov√©m, aplica√ß√µes que hoje consomem a API de Endpoints devem considerar suportar EndpointSlices no futuro.&lt;/p></description></item></channel></rss>