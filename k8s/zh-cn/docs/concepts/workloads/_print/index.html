<!doctype html><html lang=zh-cn class=no-js><head><meta name=robots content="noindex, nofollow"><link rel=alternate hreflang=en href=https://kubernetes.io/docs/concepts/workloads/><link rel=alternate hreflang=ko href=https://kubernetes.io/ko/docs/concepts/workloads/><link rel=alternate hreflang=ja href=https://kubernetes.io/ja/docs/concepts/workloads/><link rel=alternate hreflang=fr href=https://kubernetes.io/fr/docs/concepts/workloads/><link rel=alternate hreflang=de href=https://kubernetes.io/de/docs/concepts/workloads/><link rel=alternate hreflang=es href=https://kubernetes.io/es/docs/concepts/workloads/><link rel=alternate hreflang=id href=https://kubernetes.io/id/docs/concepts/workloads/><link rel=alternate hreflang=uk href=https://kubernetes.io/uk/docs/concepts/workloads/><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=generator content="Hugo 0.110.0"><link rel=canonical type=text/html href=https://kubernetes.io/zh-cn/docs/concepts/workloads/><link rel="shortcut icon" type=image/png href=/images/favicon.png><link rel=apple-touch-icon href=/favicons/apple-touch-icon-180x180.png sizes=180x180><link rel=manifest href=/manifest.webmanifest><link rel=apple-touch-icon href=/images/kubernetes-192x192.png><title>工作负载 | Kubernetes</title><meta property="og:title" content="工作负载"><meta property="og:description" content="理解 Pods，Kubernetes 中可部署的最小计算对象，以及辅助它运行它们的高层抽象对象。"><meta property="og:type" content="website"><meta property="og:url" content="https://kubernetes.io/zh-cn/docs/concepts/workloads/"><meta property="og:site_name" content="Kubernetes"><meta itemprop=name content="工作负载"><meta itemprop=description content="理解 Pods，Kubernetes 中可部署的最小计算对象，以及辅助它运行它们的高层抽象对象。"><meta name=twitter:card content="summary"><meta name=twitter:title content="工作负载"><meta name=twitter:description content="理解 Pods，Kubernetes 中可部署的最小计算对象，以及辅助它运行它们的高层抽象对象。"><link href=/scss/main.css rel=stylesheet><script type=application/ld+json>{"@context":"https://schema.org","@type":"Organization","url":"https://kubernetes.io","logo":"https://kubernetes.io/images/favicon.png","potentialAction":{"@type":"SearchAction","target":"https://kubernetes.io/search/?q={search_term_string}","query-input":"required name=search_term_string"}}</script><meta name=theme-color content="#326ce5"><link rel=stylesheet href=/css/feature-states.css><meta name=description content="理解 Pods，Kubernetes 中可部署的最小计算对象，以及辅助它运行它们的高层抽象对象。"><meta property="og:description" content="理解 Pods，Kubernetes 中可部署的最小计算对象，以及辅助它运行它们的高层抽象对象。"><meta name=twitter:description content="理解 Pods，Kubernetes 中可部署的最小计算对象，以及辅助它运行它们的高层抽象对象。"><meta property="og:url" content="https://kubernetes.io/zh-cn/docs/concepts/workloads/"><meta property="og:title" content="工作负载"><meta name=twitter:title content="工作负载"><meta name=twitter:image content="https://kubernetes.io/images/favicon.png"><meta name=twitter:image:alt content="Kubernetes"><meta property="og:image" content="/images/kubernetes-horizontal-color.png"><meta property="og:type" content="article"><script src=/js/jquery-3.6.0.min.js intregrity=sha384-vtXRMe3mGCbOeY7l30aIg8H9p3GdeSe4IFlP6G8JMa7o7lXvnz3GFKzPxzJdPfGK crossorigin=anonymous></script></head><body class=td-section><header><nav class="js-navbar-scroll navbar navbar-expand navbar-dark flex-column flex-md-row td-navbar" data-auto-burger=primary><a class=navbar-brand href=/zh-cn/></a><div class="td-navbar-nav-scroll ml-md-auto" id=main_navbar><ul class="navbar-nav mt-2 mt-lg-0"><li class="nav-item mr-2 mb-lg-0"><a class="nav-link active" href=/zh-cn/docs/>文档</a></li><li class="nav-item mr-2 mb-lg-0"><a class=nav-link href=/zh-cn/blog/>Kubernetes 博客</a></li><li class="nav-item mr-2 mb-lg-0"><a class=nav-link href=/zh-cn/training/>培训</a></li><li class="nav-item mr-2 mb-lg-0"><a class=nav-link href=/zh-cn/partners/>合作伙伴</a></li><li class="nav-item mr-2 mb-lg-0"><a class=nav-link href=/zh-cn/community/>社区</a></li><li class="nav-item mr-2 mb-lg-0"><a class=nav-link href=/zh-cn/case-studies/>案例分析</a></li><li class="nav-item dropdown"><a class="nav-link dropdown-toggle" href=# id=navbarDropdown role=button data-toggle=dropdown aria-haspopup=true aria-expanded=false>版本列表</a><div class="dropdown-menu dropdown-menu-right" aria-labelledby=navbarDropdownMenuLink><a class=dropdown-item href=/zh-cn/releases>Release Information</a>
<a class=dropdown-item href=https://kubernetes.io/zh-cn/docs/concepts/workloads/>v1.25</a>
<a class=dropdown-item href=https://v1-24.docs.kubernetes.io/zh-cn/docs/concepts/workloads/>v1.24</a>
<a class=dropdown-item href=https://v1-23.docs.kubernetes.io/zh-cn/docs/concepts/workloads/>v1.23</a>
<a class=dropdown-item href=https://v1-22.docs.kubernetes.io/zh-cn/docs/concepts/workloads/>v1.22</a>
<a class=dropdown-item href=https://v1-21.docs.kubernetes.io/zh-cn/docs/concepts/workloads/>v1.21</a></div></li><li class="nav-item dropdown"><a class="nav-link dropdown-toggle" href=# id=navbarDropdownMenuLink role=button data-toggle=dropdown aria-haspopup=true aria-expanded=false>中文 (Chinese)</a><div class="dropdown-menu dropdown-menu-right" aria-labelledby=navbarDropdownMenuLink><a class=dropdown-item href=/docs/concepts/workloads/>English</a>
<a class=dropdown-item href=/ko/docs/concepts/workloads/>한국어 (Korean)</a>
<a class=dropdown-item href=/ja/docs/concepts/workloads/>日本語 (Japanese)</a>
<a class=dropdown-item href=/fr/docs/concepts/workloads/>Français (French)</a>
<a class=dropdown-item href=/de/docs/concepts/workloads/>Deutsch (German)</a>
<a class=dropdown-item href=/es/docs/concepts/workloads/>Español (Spanish)</a>
<a class=dropdown-item href=/id/docs/concepts/workloads/>Bahasa Indonesia</a>
<a class=dropdown-item href=/uk/docs/concepts/workloads/>Українська (Ukrainian)</a></div></li></ul></div><button id=hamburger onclick=kub.toggleMenu() data-auto-burger-exclude><div></div></button></nav></header><div class="container-fluid td-outer"><div class=td-main><div class="row flex-xl-nowrap"><main class="col-12 col-md-9 col-xl-8 pl-md-5" role=main><div class=td-content><div class="pageinfo pageinfo-primary d-print-none"><p>这是本节的多页打印视图。
<a href=# onclick="return print(),!1">点击此处打印</a>.</p><p><a href=/zh-cn/docs/concepts/workloads/>返回本页常规视图</a>.</p></div><h1 class=title>工作负载</h1><div class=lead>理解 Pods，Kubernetes 中可部署的最小计算对象，以及辅助它运行它们的高层抽象对象。</div><ul><li>1: <a href=#pg-4d68b0ccf9c683e6368ffdcc40c838d4>Pod</a></li><ul><li>1.1: <a href=#pg-c3c2b9cf30915ec9d46c147201da3332>Pod 的生命周期</a></li><li>1.2: <a href=#pg-1ccbd4eeded6ab138d98b59175bd557e>Init 容器</a></li><li>1.3: <a href=#pg-4aaf43c715cd764bc8ed4436f3537e68>干扰（Disruptions）</a></li><li>1.4: <a href=#pg-53a1005011e1bda2ce81819aad7c8b32>临时容器</a></li><li>1.5: <a href=#pg-420713565efe2f940e277f6b4824ad9a>Downward API</a></li></ul><li>2: <a href=#pg-89637410cacae45a36ab1cc278c482eb>工作负载资源</a></li><ul><li>2.1: <a href=#pg-a2dc0393e0c4079e1c504b6429844e86>Deployments</a></li><li>2.2: <a href=#pg-d459b930218774655fa7fd1620625539>ReplicaSet</a></li><li>2.3: <a href=#pg-6d72299952c37ca8cc61b416e5bdbcd4>StatefulSet</a></li><li>2.4: <a href=#pg-41600eb8b6631c88848156f381e9d588>DaemonSet</a></li><li>2.5: <a href=#pg-cc7cc3c4907039d9f863162e20bfbbef>Job</a></li><li>2.6: <a href=#pg-4de50a37ebb6f2340484192126cb7a04>已完成 Job 的自动清理</a></li><li>2.7: <a href=#pg-2e4cec01c525b45eccd6010e21cc76d9>CronJob</a></li><li>2.8: <a href=#pg-27f1331d515d95f76aa1156088b4ad91>ReplicationController</a></li></ul></ul><div class=content>工作负载是在 Kubernetes 上运行的应用程序。<p>在 Kubernetes 中，无论你的负载是由单个组件还是由多个一同工作的组件构成，
你都可以在一组 <a href=/zh-cn/docs/concepts/workloads/pods><strong>Pod</strong></a> 中运行它。
在 Kubernetes 中，<code>Pod</code> 代表的是集群上处于运行状态的一组
<a class=glossary-tooltip title=容器是可移植、可执行的轻量级的镜像，镜像中包含软件及其相关依赖。 data-toggle=tooltip data-placement=top href=/zh-cn/docs/concepts/overview/what-is-kubernetes/#why-containers target=_blank aria-label=容器>容器</a> 的集合。</p><p>Kubernetes Pod 遵循<a href=/zh-cn/docs/concepts/workloads/pods/pod-lifecycle/>预定义的生命周期</a>。
例如，当在你的集群中运行了某个 Pod，但是 Pod 所在的
<a class=glossary-tooltip title='Kubernetes 中的工作机器称作节点。' data-toggle=tooltip data-placement=top href=/zh-cn/docs/concepts/architecture/nodes/ target=_blank aria-label=节点>节点</a> 出现致命错误时，
所有该节点上的 Pod 的状态都会变成失败。Kubernetes 将这类失败视为最终状态：
即使该节点后来恢复正常运行，你也需要创建新的 <code>Pod</code> 以恢复应用。</p><p>不过，为了减轻用户的使用负担，通常不需要用户直接管理每个 <code>Pod</code>。
而是使用<strong>负载资源</strong>来替用户管理一组 Pod。
这些负载资源通过配置 <a class=glossary-tooltip title='控制器通过 API 服务器监控集群的公共状态，并致力于将当前状态转变为期望的状态。' data-toggle=tooltip data-placement=top href=/zh-cn/docs/concepts/architecture/controller/ target=_blank aria-label=控制器>控制器</a>
来确保正确类型的、处于运行状态的 Pod 个数是正确的，与用户所指定的状态相一致。</p><p>Kubernetes 提供若干种内置的工作负载资源：</p><ul><li><a href=/zh-cn/docs/concepts/workloads/controllers/deployment/><code>Deployment</code></a> 和
<a href=/zh-cn/docs/concepts/workloads/controllers/replicaset/><code>ReplicaSet</code></a>
（替换原来的资源 <a class=glossary-tooltip title='一种管理多副本应用的（已启用）的 API 对象。' data-toggle=tooltip data-placement=top href='/zh-cn/docs/reference/glossary/?all=true#term-replication-controller' target=_blank aria-label=ReplicationController>ReplicationController</a>）。
<code>Deployment</code> 很适合用来管理你的集群上的无状态应用，<code>Deployment</code> 中的所有
<code>Pod</code> 都是相互等价的，并且在需要的时候被替换。</li><li><a href=/zh-cn/docs/concepts/workloads/controllers/statefulset/>StatefulSet</a>
让你能够运行一个或者多个以某种方式跟踪应用状态的 Pod。
例如，如果你的负载会将数据作持久存储，你可以运行一个 <code>StatefulSet</code>，将每个
<code>Pod</code> 与某个 <a href=/zh-cn/docs/concepts/storage/persistent-volumes/><code>PersistentVolume</code></a>
对应起来。你在 <code>StatefulSet</code> 中各个 <code>Pod</code> 内运行的代码可以将数据复制到同一
<code>StatefulSet</code> 中的其它 <code>Pod</code> 中以提高整体的服务可靠性。</li></ul><ul><li><a href=/zh-cn/docs/concepts/workloads/controllers/daemonset/>DaemonSet</a>
定义提供节点本地支撑设施的 <code>Pod</code>。这些 Pod 可能对于你的集群的运维是
非常重要的，例如作为网络链接的辅助工具或者作为网络
<a class=glossary-tooltip title='扩展 Kubernetes 功能的资源。' data-toggle=tooltip data-placement=top href=/zh-cn/docs/concepts/cluster-administration/addons/ target=_blank aria-label=插件>插件</a>
的一部分等等。每次你向集群中添加一个新节点时，如果该节点与某 <code>DaemonSet</code>
的规约匹配，则控制平面会为该 <code>DaemonSet</code> 调度一个 <code>Pod</code> 到该新节点上运行。</li><li><a href=/zh-cn/docs/concepts/workloads/controllers/job/>Job</a> 和
<a href=/zh-cn/docs/concepts/workloads/controllers/cron-jobs/>CronJob</a>。
定义一些一直运行到结束并停止的任务。<code>Job</code> 用来执行一次性任务，而
<code>CronJob</code> 用来执行的根据时间规划反复运行的任务。</li></ul><p>在庞大的 Kubernetes 生态系统中，你还可以找到一些提供额外操作的第三方工作负载相关的资源。
通过使用<a href=/zh-cn/docs/concepts/extend-kubernetes/api-extension/custom-resources/>定制资源定义（CRD）</a>，
你可以添加第三方工作负载资源，以完成原本不是 Kubernetes 核心功能的工作。
例如，如果你希望运行一组 <code>Pod</code>，但要求<strong>所有</strong> Pod 都可用时才执行操作
（比如针对某种高吞吐量的分布式任务），你可以基于定制资源实现一个能够满足这一需求的扩展，
并将其安装到集群中运行。</p><h2 id=接下来>接下来</h2><p>除了阅读了解每类资源外，你还可以了解与这些资源相关的任务：</p><ul><li><a href=/zh-cn/docs/tasks/run-application/run-stateless-application-deployment/>使用 <code>Deployment</code> 运行一个无状态的应用</a></li><li>以<a href=/zh-cn/docs/tasks/run-application/run-single-instance-stateful-application/>单实例</a>或者<a href=/zh-cn/docs/tasks/run-application/run-replicated-stateful-application/>多副本集合</a>
的形式运行有状态的应用；</li><li><a href=/zh-cn/docs/tasks/job/automated-tasks-with-cron-jobs/>使用 <code>CronJob</code> 运行自动化的任务</a></li></ul><p>要了解 Kubernetes 将代码与配置分离的实现机制，可参阅<a href=/zh-cn/docs/concepts/configuration/>配置部分</a>。</p><p>关于 Kubernetes 如何为应用管理 Pod，还有两个支撑概念能够提供相关背景信息：</p><ul><li><a href=/zh-cn/docs/concepts/architecture/garbage-collection/>垃圾收集</a>机制负责在
对象的<strong>属主资源</strong>被删除时在集群中清理这些对象。</li><li><a href=/zh-cn/docs/concepts/workloads/controllers/ttlafterfinished/><strong>Time-to-Live</strong> 控制器</a>会在 Job
结束之后的指定时间间隔之后删除它们。</li></ul><p>一旦你的应用处于运行状态，你就可能想要以
<a href=/zh-cn/docs/concepts/services-networking/service/><code>Service</code></a>
的形式使之可在互联网上访问；或者对于 Web 应用而言，使用
<a href=/zh-cn/docs/concepts/services-networking/ingress><code>Ingress</code></a> 资源将其暴露到互联网上。</p></div></div><div class=td-content style=page-break-before:always><h1 id=pg-4d68b0ccf9c683e6368ffdcc40c838d4>1 - Pod</h1><p><strong>Pod</strong> 是可以在 Kubernetes 中创建和管理的、最小的可部署的计算单元。</p><p><strong>Pod</strong>（就像在鲸鱼荚或者豌豆荚中）是一组（一个或多个）
<a class=glossary-tooltip title=容器是可移植、可执行的轻量级的镜像，镜像中包含软件及其相关依赖。 data-toggle=tooltip data-placement=top href=/zh-cn/docs/concepts/overview/what-is-kubernetes/#why-containers target=_blank aria-label=容器>容器</a>；
这些容器共享存储、网络、以及怎样运行这些容器的声明。
Pod 中的内容总是并置（colocated）的并且一同调度，在共享的上下文中运行。
Pod 所建模的是特定于应用的 “逻辑主机”，其中包含一个或多个应用容器，
这些容器相对紧密地耦合在一起。
在非云环境中，在相同的物理机或虚拟机上运行的应用类似于在同一逻辑主机上运行的云应用。</p><p>除了应用容器，Pod 还可以包含在 Pod 启动期间运行的
<a href=/zh-cn/docs/concepts/workloads/pods/init-containers/>Init 容器</a>。
你也可以在集群支持<a href=/zh-cn/docs/concepts/workloads/pods/ephemeral-containers/>临时性容器</a>的情况下，
为调试的目的注入临时性容器。</p><h2 id=what-is-a-pod>什么是 Pod？</h2><div class="alert alert-info note callout" role=alert><strong>说明：</strong> 除了 Docker 之外，Kubernetes 支持很多其他<a class=glossary-tooltip title=容器运行时是负责运行容器的软件。 data-toggle=tooltip data-placement=top href=/zh-cn/docs/setup/production-environment/container-runtimes target=_blank aria-label=容器运行时>容器运行时</a>，
<a href=https://www.docker.com/>Docker</a> 是最有名的运行时，
使用 Docker 的术语来描述 Pod 会很有帮助。</div><p>Pod 的共享上下文包括一组 Linux 名字空间、控制组（cgroup）和可能一些其他的隔离方面，
即用来隔离<a class=glossary-tooltip title=容器是可移植、可执行的轻量级的镜像，镜像中包含软件及其相关依赖。 data-toggle=tooltip data-placement=top href=/zh-cn/docs/concepts/overview/what-is-kubernetes/#why-containers target=_blank aria-label=容器>容器</a>的技术。
在 Pod 的上下文中，每个独立的应用可能会进一步实施隔离。</p><p>Pod 类似于共享名字空间并共享文件系统卷的一组容器。</p><h2 id=using-pods>使用 Pod</h2><p>下面是一个 Pod 示例，它由一个运行镜像 <code>nginx:1.14.2</code> 的容器组成。</p><div class=highlight><div class=copy-code-icon style=text-align:right><a href=https://raw.githubusercontent.com/kubernetes/website/main/content/zh-cn/examples/pods/simple-pod.yaml download=pods/simple-pod.yaml><code>pods/simple-pod.yaml</code></a>
<img src=/images/copycode.svg style=max-height:24px;cursor:pointer onclick='copyCode("pods-simple-pod-yaml")' title="Copy pods/simple-pod.yaml to clipboard"></img></div><div class=includecode id=pods-simple-pod-yaml><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>nginx<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>nginx<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>nginx:1.14.2<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>ports</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:green;font-weight:700>containerPort</span>:<span style=color:#bbb> </span><span style=color:#666>80</span><span style=color:#bbb>
</span></span></span></code></pre></div></div></div><p>要创建上面显示的 Pod，请运行以下命令：</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl apply -f https://k8s.io/examples/pods/simple-pod.yaml
</span></span></code></pre></div><p>Pod 通常不是直接创建的，而是使用工作负载资源创建的。
有关如何将 Pod 用于工作负载资源的更多信息，请参阅<a href=#working-with-pods>使用 Pod</a>。</p><h3 id=workload-resources-for-managing-pods>用于管理 pod 的工作负载资源</h3><p>通常你不需要直接创建 Pod，甚至单实例 Pod。
相反，你会使用诸如
<a class=glossary-tooltip title=管理集群上的多副本应用。 data-toggle=tooltip data-placement=top href=/zh-cn/docs/concepts/workloads/controllers/deployment/ target=_blank aria-label=Deployment>Deployment</a> 或
<a class=glossary-tooltip title='Job 是需要运行完成的确定性的或批量的任务。' data-toggle=tooltip data-placement=top href=/zh-cn/docs/concepts/workloads/controllers/job/ target=_blank aria-label=Job>Job</a> 这类工作负载资源来创建 Pod。
如果 Pod 需要跟踪状态，可以考虑
<a class=glossary-tooltip title='StatefulSet 用来管理某 Pod 集合的部署和扩缩，并为这些 Pod 提供持久存储和持久标识符。' data-toggle=tooltip data-placement=top href=/zh-cn/docs/concepts/workloads/controllers/statefulset/ target=_blank aria-label=StatefulSet>StatefulSet</a> 资源。</p><p>Kubernetes 集群中的 Pod 主要有两种用法：</p><ul><li><p><strong>运行单个容器的 Pod</strong>。"每个 Pod 一个容器" 模型是最常见的 Kubernetes 用例；
在这种情况下，可以将 Pod 看作单个容器的包装器，并且 Kubernetes 直接管理 Pod，而不是容器。</p></li><li><p><strong>运行多个协同工作的容器的 Pod</strong>。
Pod 可能封装由多个紧密耦合且需要共享资源的共处容器组成的应用程序。
这些位于同一位置的容器可能形成单个内聚的服务单元 —— 一个容器将文件从共享卷提供给公众，
而另一个单独的 “边车”（sidecar）容器则刷新或更新这些文件。
Pod 将这些容器和存储资源打包为一个可管理的实体。</p><div class="alert alert-info note callout" role=alert><strong>说明：</strong><p>将多个并置、同管的容器组织到一个 Pod 中是一种相对高级的使用场景。
只有在一些场景中，容器之间紧密关联时你才应该使用这种模式。</div></li></ul><p>每个 Pod 都旨在运行给定应用程序的单个实例。如果希望横向扩展应用程序
（例如，运行多个实例以提供更多的资源），则应该使用多个 Pod，每个实例使用一个 Pod。
在 Kubernetes 中，这通常被称为<strong>副本（Replication）</strong>。
通常使用一种工作负载资源及其<a class=glossary-tooltip title='控制器通过 API 服务器监控集群的公共状态，并致力于将当前状态转变为期望的状态。' data-toggle=tooltip data-placement=top href=/zh-cn/docs/concepts/architecture/controller/ target=_blank aria-label=控制器>控制器</a>来创建和管理一组 Pod 副本。</p><p>参见 <a href=#pods-and-controllers>Pod 和控制器</a>以了解 Kubernetes
如何使用工作负载资源及其控制器以实现应用的扩缩和自动修复。</p><h3 id=how-pods-manage-multiple-containers>Pod 怎样管理多个容器</h3><p>Pod 被设计成支持形成内聚服务单元的多个协作过程（形式为容器）。
Pod 中的容器被自动安排到集群中的同一物理机或虚拟机上，并可以一起进行调度。
容器之间可以共享资源和依赖、彼此通信、协调何时以及何种方式终止自身。</p><p>例如，你可能有一个容器，为共享卷中的文件提供 Web 服务器支持，以及一个单独的
"边车 (sidercar)" 容器负责从远端更新这些文件，如下图所示：</p><figure class=diagram-medium><img src=/images/docs/pod.svg alt="Pod 创建示意图"></figure><p>有些 Pod 具有 <a class=glossary-tooltip title='应用容器运行前必须先运行完成的一个或多个 Init 容器（Init Container）。' data-toggle=tooltip data-placement=top href='/zh-cn/docs/reference/glossary/?all=true#term-init-container' target=_blank aria-label='Init 容器'>Init 容器</a>和
<a class=glossary-tooltip title='用于运行部分工作负载的容器。与 Init 容器比较而言。' data-toggle=tooltip data-placement=top href='/zh-cn/docs/reference/glossary/?all=true#term-app-container' target=_blank aria-label=应用容器>应用容器</a>。
Init 容器会在启动应用容器之前运行并完成。</p><p>Pod 天生地为其成员容器提供了两种共享资源：<a href=#pod-networking>网络</a>和<a href=#pod-storage>存储</a>。</p><h2 id=working-with-pods>使用 Pod</h2><p>你很少在 Kubernetes 中直接创建一个个的 Pod，甚至是单实例（Singleton）的 Pod。
这是因为 Pod 被设计成了相对临时性的、用后即抛的一次性实体。
当 Pod 由你或者间接地由<a class=glossary-tooltip title='控制器通过 API 服务器监控集群的公共状态，并致力于将当前状态转变为期望的状态。' data-toggle=tooltip data-placement=top href=/zh-cn/docs/concepts/architecture/controller/ target=_blank aria-label=控制器>控制器</a>
创建时，它被调度在集群中的<a class=glossary-tooltip title='Kubernetes 中的工作机器称作节点。' data-toggle=tooltip data-placement=top href=/zh-cn/docs/concepts/architecture/nodes/ target=_blank aria-label=节点>节点</a>上运行。
Pod 会保持在该节点上运行，直到 Pod 结束执行、Pod 对象被删除、Pod 因资源不足而被<strong>驱逐</strong>或者节点失效为止。</p><div class="alert alert-info note callout" role=alert><strong>说明：</strong> 重启 Pod 中的容器不应与重启 Pod 混淆。
Pod 不是进程，而是容器运行的环境。
在被删除之前，Pod 会一直存在。</div><p>当你为 Pod 对象创建清单时，要确保所指定的 Pod 名称是合法的
<a href=/zh-cn/docs/concepts/overview/working-with-objects/names#dns-subdomain-names>DNS 子域名</a>。</p><h3 id=pod-os>Pod 操作系统</h3><div style=margin-top:10px;margin-bottom:10px><b>特性状态：</b> <code>Kubernetes v1.25 [stable]</code></div><p>你应该将 <code>.spec.os.name</code> 字段设置为 <code>windows</code> 或 <code>linux</code> 以表示你希望 Pod 运行在哪个操作系统之上。
这两个是 Kubernetes 目前支持的操作系统。将来，这个列表可能会被扩充。</p><p>在 Kubernetes v1.25 中，为此字段设置的值对 Pod
的<a class=glossary-tooltip title='控制平面组件，负责监视新创建的、未指定运行节点的 Pod，选择节点让 Pod 在上面运行。' data-toggle=tooltip data-placement=top href=/zh-cn/docs/reference/command-line-tools-reference/kube-scheduler/ target=_blank aria-label=调度>调度</a>没有影响。
设置 <code>. spec.os.name</code> 有助于确定性地标识 Pod 的操作系统并用于验证。
如果你指定的 Pod 操作系统与运行 kubelet 所在节点的操作系统不同，
那么 kubelet 将会拒绝运行该 Pod。
<a href=/zh-cn/docs/concepts/security/pod-security-standards/>Pod 安全标准</a>也使用这个字段来避免强制执行与该操作系统无关的策略。</p><h3 id=pods-and-controllers>Pod 和控制器</h3><p>你可以使用工作负载资源来创建和管理多个 Pod。
资源的控制器能够处理副本的管理、上线，并在 Pod 失效时提供自愈能力。
例如，如果一个节点失败，控制器注意到该节点上的 Pod 已经停止工作，
就可以创建替换性的 Pod。调度器会将替身 Pod 调度到一个健康的节点执行。</p><p>下面是一些管理一个或者多个 Pod 的工作负载资源的示例：</p><ul><li><a class=glossary-tooltip title=管理集群上的多副本应用。 data-toggle=tooltip data-placement=top href=/zh-cn/docs/concepts/workloads/controllers/deployment/ target=_blank aria-label=Deployment>Deployment</a></li><li><a class=glossary-tooltip title='StatefulSet 用来管理某 Pod 集合的部署和扩缩，并为这些 Pod 提供持久存储和持久标识符。' data-toggle=tooltip data-placement=top href=/zh-cn/docs/concepts/workloads/controllers/statefulset/ target=_blank aria-label=StatefulSet>StatefulSet</a></li><li><a class=glossary-tooltip title='确保 Pod 的副本在集群中的一组节点上运行。' data-toggle=tooltip data-placement=top href=/zh-cn/docs/concepts/workloads/controllers/daemonset/ target=_blank aria-label=DaemonSet>DaemonSet</a></li></ul><h3 id=pod-templates>Pod 模板</h3><p><a class=glossary-tooltip title='工作负载是在 Kubernetes 上运行的应用程序。' data-toggle=tooltip data-placement=top href=/zh-cn/docs/concepts/workloads/ target=_blank aria-label=工作负载>工作负载</a>资源的控制器通常使用
<strong>Pod 模板（Pod Template）</strong> 来替你创建 Pod 并管理它们。</p><p>Pod 模板是包含在工作负载对象中的规范，用来创建 Pod。这类负载资源包括
<a href=/zh-cn/docs/concepts/workloads/controllers/deployment/>Deployment</a>、
<a href=/zh-cn/docs/concepts/workloads/controllers/job/>Job</a> 和
<a href=/zh-cn/docs/concepts/workloads/controllers/daemonset/>DaemonSet</a> 等。</p><p>工作负载的控制器会使用负载对象中的 <code>PodTemplate</code> 来生成实际的 Pod。
<code>PodTemplate</code> 是你用来运行应用时指定的负载资源的目标状态的一部分。</p><p>下面的示例是一个简单的 Job 的清单，其中的 <code>template</code> 指示启动一个容器。
该 Pod 中的容器会打印一条消息之后暂停。</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>batch/v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Job<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>hello<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>template</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:#080;font-style:italic># 这里是 Pod 模板</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>hello<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>busybox:1.28<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>command</span>:<span style=color:#bbb> </span>[<span style=color:#b44>&#39;sh&#39;</span>,<span style=color:#bbb> </span><span style=color:#b44>&#39;-c&#39;</span>,<span style=color:#bbb> </span><span style=color:#b44>&#39;echo &#34;Hello, Kubernetes!&#34; &amp;&amp; sleep 3600&#39;</span>]<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>restartPolicy</span>:<span style=color:#bbb> </span>OnFailure<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:#080;font-style:italic># 以上为 Pod 模板</span><span style=color:#bbb>
</span></span></span></code></pre></div><p>修改 Pod 模板或者切换到新的 Pod 模板都不会对已经存在的 Pod 直接起作用。
如果改变工作负载资源的 Pod 模板，工作负载资源需要使用更新后的模板来创建 Pod，
并使用新创建的 Pod 替换旧的 Pod。</p><p>例如，StatefulSet 控制器针对每个 StatefulSet 对象确保运行中的 Pod 与当前的 Pod
模板匹配。如果编辑 StatefulSet 以更改其 Pod 模板，
StatefulSet 将开始基于更新后的模板创建新的 Pod。</p><p>每个工作负载资源都实现了自己的规则，用来处理对 Pod 模板的更新。
如果你想了解更多关于 StatefulSet 的具体信息，
请阅读 StatefulSet 基础教程中的<a href=/zh-cn/docs/tutorials/stateful-application/basic-stateful-set/#updating-statefulsets>更新策略</a>。</p><p>在节点上，<a class=glossary-tooltip title='一个在集群中每个节点上运行的代理。它保证容器都运行在 Pod 中。' data-toggle=tooltip data-placement=top href=/docs/reference/generated/kubelet target=_blank aria-label=kubelet>kubelet</a> 并不直接监测或管理与
Pod 模板相关的细节或模板的更新，这些细节都被抽象出来。
这种抽象和关注点分离简化了整个系统的语义，
并且使得用户可以在不改变现有代码的前提下就能扩展集群的行为。</p><h2 id=pod-update-and-replacement>Pod 更新与替换</h2><p>正如前面章节所述，当某工作负载的 Pod 模板被改变时，
控制器会基于更新的模板创建新的 Pod 对象而不是对现有 Pod 执行更新或者修补操作。</p><p>Kubernetes 并不禁止你直接管理 Pod。对运行中的 Pod 的某些字段执行就地更新操作还是可能的。不过，类似
<a href=/docs/reference/generated/kubernetes-api/v1.25/#patch-pod-v1-core><code>patch</code></a> 和
<a href=/docs/reference/generated/kubernetes-api/v1.25/#replace-pod-v1-core><code>replace</code></a>
这类更新操作有一些限制：</p><ul><li><p>Pod 的绝大多数元数据都是不可变的。例如，你不可以改变其 <code>namespace</code>、<code>name</code>、
<code>uid</code> 或者 <code>creationTimestamp</code> 字段；<code>generation</code> 字段是比较特别的，
如果更新该字段，只能增加字段取值而不能减少。</p></li><li><p>如果 <code>metadata.deletionTimestamp</code> 已经被设置，则不可以向 <code>metadata.finalizers</code>
列表中添加新的条目。</p></li><li><p>Pod 更新不可以改变除 <code>spec.containers[*].image</code>、<code>spec.initContainers[*].image</code>、
<code>spec.activeDeadlineSeconds</code> 或 <code>spec.tolerations</code> 之外的字段。
对于 <code>spec.tolerations</code>，你只被允许添加新的条目到其中。</p></li><li><p>在更新 <code>spec.activeDeadlineSeconds</code> 字段时，以下两种更新操作是被允许的：</p><ol><li>如果该字段尚未设置，可以将其设置为一个正数；</li><li>如果该字段已经设置为一个正数，可以将其设置为一个更小的、非负的整数。</li></ol></li></ul><h3 id=resource-sharing-and-communication>资源共享和通信</h3><p>Pod 使它的成员容器间能够进行数据共享和通信。</p><h3 id=pod-storage>Pod 中的存储</h3><p>一个 Pod 可以设置一组共享的存储<a class=glossary-tooltip title='包含可被 Pod 中容器访问的数据的目录。' data-toggle=tooltip data-placement=top href=/zh-cn/docs/concepts/storage/volumes/ target=_blank aria-label=卷>卷</a>。
Pod 中的所有容器都可以访问该共享卷，从而允许这些容器共享数据。
卷还允许 Pod 中的持久数据保留下来，即使其中的容器需要重新启动。
有关 Kubernetes 如何在 Pod 中实现共享存储并将其提供给 Pod 的更多信息，
请参考<a href=/zh-cn/docs/concepts/storage/>存储</a>。</p><h3 id=pod-networking>Pod 联网</h3><p>每个 Pod 都在每个地址族中获得一个唯一的 IP 地址。
Pod 中的每个容器共享网络名字空间，包括 IP 地址和网络端口。
<strong>Pod 内</strong>的容器可以使用 <code>localhost</code> 互相通信。
当 Pod 中的容器与 <strong>Pod 之外</strong>的实体通信时，它们必须协调如何使用共享的网络资源（例如端口）。</p><p>在同一个 Pod 内，所有容器共享一个 IP 地址和端口空间，并且可以通过 <code>localhost</code> 发现对方。
他们也能通过如 SystemV 信号量或 POSIX 共享内存这类标准的进程间通信方式互相通信。
不同 Pod 中的容器的 IP 地址互不相同，如果没有特殊配置，就无法通过 OS 级 IPC 进行通信。
如果某容器希望与运行于其他 Pod 中的容器通信，可以通过 IP 联网的方式实现。</p><p>Pod 中的容器所看到的系统主机名与为 Pod 配置的 <code>name</code> 属性值相同。
<a href=/zh-cn/docs/concepts/cluster-administration/networking/>网络</a>部分提供了更多有关此内容的信息。</p><h2 id=privileged-mode-for-containers>容器的特权模式</h2><p>在 Linux 中，Pod 中的任何容器都可以使用容器规约中的
<a href=/zh-cn/docs/tasks/configure-pod-container/security-context/>安全性上下文</a>中的
<code>privileged</code>（Linux）参数启用特权模式。
这对于想要使用操作系统管理权能（Capabilities，如操纵网络堆栈和访问设备）的容器很有用。</p><p>如果你的集群启用了 <code>WindowsHostProcessContainers</code> 特性，你可以使用 Pod 规约中安全上下文的
<code>windowsOptions.hostProcess</code> 参数来创建
<a href=/zh-cn/docs/tasks/configure-pod-container/create-hostprocess-pod/>Windows HostProcess Pod</a>。
这些 Pod 中的所有容器都必须以 Windows HostProcess 容器方式运行。
HostProcess Pod 可以直接运行在主机上，它也能像 Linux 特权容器一样，用于执行管理任务。</p><div class="alert alert-info note callout" role=alert><strong>说明：</strong><p>你的<a class=glossary-tooltip title=容器运行时是负责运行容器的软件。 data-toggle=tooltip data-placement=top href=/zh-cn/docs/setup/production-environment/container-runtimes target=_blank aria-label=容器运行时>容器运行时</a>必须支持特权容器的概念才能使用这一配置。</div><h2 id=static-pods>静态 Pod</h2><p><strong>静态 Pod（Static Pod）</strong> 直接由特定节点上的 <code>kubelet</code> 守护进程管理，
不需要 <a class=glossary-tooltip title='提供 Kubernetes API 服务的控制面组件。' data-toggle=tooltip data-placement=top href=/zh-cn/docs/concepts/overview/components/#kube-apiserver target=_blank aria-label='API 服务器'>API 服务器</a>看到它们。
尽管大多数 Pod 都是通过控制面（例如，<a class=glossary-tooltip title=管理集群上的多副本应用。 data-toggle=tooltip data-placement=top href=/zh-cn/docs/concepts/workloads/controllers/deployment/ target=_blank aria-label=Deployment>Deployment</a>）
来管理的，对于静态 Pod 而言，<code>kubelet</code> 直接监控每个 Pod，并在其失效时重启之。</p><p>静态 Pod 通常绑定到某个节点上的 <a class=glossary-tooltip title='一个在集群中每个节点上运行的代理。它保证容器都运行在 Pod 中。' data-toggle=tooltip data-placement=top href=/docs/reference/generated/kubelet target=_blank aria-label=kubelet>kubelet</a>。
其主要用途是运行自托管的控制面。
在自托管场景中，使用 <code>kubelet</code>
来管理各个独立的<a href=/zh-cn/docs/concepts/overview/components/#control-plane-components>控制面组件</a>。</p><p><code>kubelet</code> 自动尝试为每个静态 Pod 在 Kubernetes API
服务器上创建一个<a class=glossary-tooltip title='API 服务器中的一个对象，用于跟踪 kubelet 上的静态 pod。' data-toggle=tooltip data-placement=top href='/zh-cn/docs/reference/glossary/?all=true#term-mirror-pod' target=_blank aria-label='镜像 Pod'>镜像 Pod</a>。
这意味着在节点上运行的 Pod 在 API 服务器上是可见的，但不可以通过 API 服务器来控制。</p><div class="alert alert-info note callout" role=alert><strong>说明：</strong><p>静态 Pod 的 <code>spec</code> 不能引用其他的 API 对象（例如：
<a class=glossary-tooltip title='为在 Pod 中运行的进程提供标识。' data-toggle=tooltip data-placement=top href=/zh-cn/docs/tasks/configure-pod-container/configure-service-account/ target=_blank aria-label=ServiceAccount>ServiceAccount</a>、
<a class=glossary-tooltip title='ConfigMap 是一种 API 对象，用来将非机密性的数据保存到键值对中。使用时可以用作环境变量、命令行参数或者存储卷中的配置文件。' data-toggle=tooltip data-placement=top href=/zh-cn/docs/tasks/configure-pod-container/configure-pod-configmap/ target=_blank aria-label=ConfigMap>ConfigMap</a>、
<a class=glossary-tooltip title='Secret 用于存储敏感信息，如密码、 OAuth 令牌和 SSH 密钥。' data-toggle=tooltip data-placement=top href=/zh-cn/docs/concepts/configuration/secret/ target=_blank aria-label=Secret>Secret</a> 等）。</div><h2 id=container-probes>容器探针</h2><p><strong>Probe</strong> 是由 kubelet 对容器执行的定期诊断。要执行诊断，kubelet 可以执行三种动作：</p><ul><li><code>ExecAction</code>（借助容器运行时执行）</li><li><code>TCPSocketAction</code>（由 kubelet 直接检测）</li><li><code>HTTPGetAction</code>（由 kubelet 直接检测）</li></ul><p>你可以参阅 Pod 的生命周期文档中的<a href=/zh-cn/docs/concepts/workloads/pods/pod-lifecycle/#container-probes>探针</a>部分。</p><h2 id=接下来>接下来</h2><ul><li>了解 <a href=/zh-cn/docs/concepts/workloads/pods/pod-lifecycle/>Pod 生命周期</a>。</li><li>了解 <a href=/zh-cn/docs/concepts/containers/runtime-class/>RuntimeClass</a>，
以及如何使用它来配置不同的 Pod 使用不同的容器运行时配置。</li><li>了解 <a href=/zh-cn/docs/concepts/workloads/pods/disruptions/>PodDisruptionBudget</a>，
以及你可以如何利用它在出现干扰因素时管理应用的可用性。</li><li>Pod 在 Kubernetes REST API 中是一个顶层资源。
<a href=/zh-cn/docs/reference/kubernetes-api/workload-resources/pod-v1/>Pod</a>
对象的定义中包含了更多的细节信息。</li><li>博客<a href=/blog/2015/06/the-distributed-system-toolkit-patterns/>分布式系统工具箱：复合容器模式</a>中解释了在同一
Pod 中包含多个容器时的几种常见布局。</li><li>了解 <a href=/zh-cn/docs/concepts/scheduling-eviction/topology-spread-constraints/>Pod 拓扑分布约束</a>。</li></ul><p>要了解为什么 Kubernetes 会在其他资源
（如 <a class=glossary-tooltip title='StatefulSet 用来管理某 Pod 集合的部署和扩缩，并为这些 Pod 提供持久存储和持久标识符。' data-toggle=tooltip data-placement=top href=/zh-cn/docs/concepts/workloads/controllers/statefulset/ target=_blank aria-label=StatefulSet>StatefulSet</a>
或 <a class=glossary-tooltip title=管理集群上的多副本应用。 data-toggle=tooltip data-placement=top href=/zh-cn/docs/concepts/workloads/controllers/deployment/ target=_blank aria-label=Deployment>Deployment</a>）
封装通用的 Pod API，相关的背景信息可以在前人的研究中找到。具体包括：</p><ul><li><a href=https://aurora.apache.org/documentation/latest/reference/configuration/#job-schema>Aurora</a></li><li><a href=https://research.google.com/pubs/pub43438.html>Borg</a></li><li><a href=https://mesosphere.github.io/marathon/docs/rest-api.html>Marathon</a></li><li><a href=https://research.google/pubs/pub41684/>Omega</a></li><li><a href=https://engineering.fb.com/data-center-engineering/tupperware/>Tupperware</a>.</li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-c3c2b9cf30915ec9d46c147201da3332>1.1 - Pod 的生命周期</h1><p>本页面讲述 Pod 的生命周期。
Pod 遵循预定义的生命周期，起始于 <code>Pending</code> <a href=#pod-phase>阶段</a>，
如果至少其中有一个主要容器正常启动，则进入 <code>Running</code>，之后取决于 Pod
中是否有容器以失败状态结束而进入 <code>Succeeded</code> 或者 <code>Failed</code> 阶段。</p><p>在 Pod 运行期间，<code>kubelet</code> 能够重启容器以处理一些失效场景。
在 Pod 内部，Kubernetes 跟踪不同容器的<a href=#container-states>状态</a>并确定使
Pod 重新变得健康所需要采取的动作。</p><p>在 Kubernetes API 中，Pod 包含规约部分和实际状态部分。
Pod 对象的状态包含了一组 <a href=#pod-conditions>Pod 状况（Conditions）</a>。
如果应用需要的话，你也可以向其中注入<a href=#pod-readiness-gate>自定义的就绪态信息</a>。</p><p>Pod 在其生命周期中只会被<a href=/zh-cn/docs/concepts/scheduling-eviction/>调度</a>一次。
一旦 Pod 被调度（分派）到某个节点，Pod 会一直在该节点运行，直到 Pod
停止或者被<a href=#pod-termination>终止</a>。</p><h2 id=pod-lifetime>Pod 生命期</h2><p>和一个个独立的应用容器一样，Pod 也被认为是相对临时性（而不是长期存在）的实体。
Pod 会被创建、赋予一个唯一的
ID（<a href=/zh-cn/docs/concepts/overview/working-with-objects/names/#uids>UID</a>），
并被调度到节点，并在终止（根据重启策略）或删除之前一直运行在该节点。</p><p>如果一个<a class=glossary-tooltip title='Kubernetes 中的工作机器称作节点。' data-toggle=tooltip data-placement=top href=/zh-cn/docs/concepts/architecture/nodes/ target=_blank aria-label=节点>节点</a>死掉了，调度到该节点的
Pod 也被计划在给定超时期限结束后<a href=#pod-garbage-collection>删除</a>。</p><p>Pod 自身不具有自愈能力。如果 Pod
被调度到某<a class=glossary-tooltip title='Kubernetes 中的工作机器称作节点。' data-toggle=tooltip data-placement=top href=/zh-cn/docs/concepts/architecture/nodes/ target=_blank aria-label=节点>节点</a>而该节点之后失效，
Pod 会被删除；类似地，Pod 无法在因节点资源耗尽或者节点维护而被驱逐期间继续存活。
Kubernetes 使用一种高级抽象来管理这些相对而言可随时丢弃的 Pod 实例，
称作<a class=glossary-tooltip title='控制器通过 API 服务器监控集群的公共状态，并致力于将当前状态转变为期望的状态。' data-toggle=tooltip data-placement=top href=/zh-cn/docs/concepts/architecture/controller/ target=_blank aria-label=控制器>控制器</a>。</p><p>任何给定的 Pod （由 UID 定义）从不会被“重新调度（rescheduled）”到不同的节点；
相反，这一 Pod 可以被一个新的、几乎完全相同的 Pod 替换掉。
如果需要，新 Pod 的名字可以不变，但是其 UID 会不同。</p><p>如果某物声称其生命期与某 Pod 相同，例如存储<a class=glossary-tooltip title='包含可被 Pod 中容器访问的数据的目录。' data-toggle=tooltip data-placement=top href=/zh-cn/docs/concepts/storage/volumes/ target=_blank aria-label=卷>卷</a>，
这就意味着该对象在此 Pod （UID 亦相同）存在期间也一直存在。
如果 Pod 因为任何原因被删除，甚至某完全相同的替代 Pod 被创建时，
这个相关的对象（例如这里的卷）也会被删除并重建。</p><figure class=diagram-medium><img src=/images/docs/pod.svg><figcaption><h4>Pod 结构图例</h4></figcaption></figure><p><em>一个包含多个容器的 Pod 中包含一个用来拉取文件的程序和一个 Web 服务器，
均使用持久卷作为容器间共享的存储。</em></p><h2 id=pod-phase>Pod 阶段</h2><p>Pod 的 <code>status</code> 字段是一个
<a href=/docs/reference/generated/kubernetes-api/v1.25/#podstatus-v1-core>PodStatus</a>
对象，其中包含一个 <code>phase</code> 字段。</p><p>Pod 的阶段（Phase）是 Pod 在其生命周期中所处位置的简单宏观概述。
该阶段并不是对容器或 Pod 状态的综合汇总，也不是为了成为完整的状态机。</p><p>Pod 阶段的数量和含义是严格定义的。
除了本文档中列举的内容外，不应该再假定 Pod 有其他的 <code>phase</code> 值。</p><p>下面是 <code>phase</code> 可能的值：</p><table><thead><tr><th style=text-align:left>取值</th><th style=text-align:left>描述</th></tr></thead><tbody><tr><td style=text-align:left><code>Pending</code>（悬决）</td><td style=text-align:left>Pod 已被 Kubernetes 系统接受，但有一个或者多个容器尚未创建亦未运行。此阶段包括等待 Pod 被调度的时间和通过网络下载镜像的时间。</td></tr><tr><td style=text-align:left><code>Running</code>（运行中）</td><td style=text-align:left>Pod 已经绑定到了某个节点，Pod 中所有的容器都已被创建。至少有一个容器仍在运行，或者正处于启动或重启状态。</td></tr><tr><td style=text-align:left><code>Succeeded</code>（成功）</td><td style=text-align:left>Pod 中的所有容器都已成功终止，并且不会再重启。</td></tr><tr><td style=text-align:left><code>Failed</code>（失败）</td><td style=text-align:left>Pod 中的所有容器都已终止，并且至少有一个容器是因为失败终止。也就是说，容器以非 0 状态退出或者被系统终止。</td></tr><tr><td style=text-align:left><code>Unknown</code>（未知）</td><td style=text-align:left>因为某些原因无法取得 Pod 的状态。这种情况通常是因为与 Pod 所在主机通信失败。</td></tr></tbody></table><div class="alert alert-info note callout" role=alert><strong>说明：</strong><p>当一个 Pod 被删除时，执行一些 kubectl 命令会展示这个 Pod 的状态为 <code>Terminating</code>（终止）。
这个 <code>Terminating</code> 状态并不是 Pod 阶段之一。
Pod 被赋予一个可以体面终止的期限，默认为 30 秒。
你可以使用 <code>--force</code> 参数来<a href=/zh-cn/docs/concepts/workloads/pods/pod-lifecycle/#pod-termination-forced>强制终止 Pod</a>。</div><p>如果某节点死掉或者与集群中其他节点失联，Kubernetes
会实施一种策略，将失去的节点上运行的所有 Pod 的 <code>phase</code> 设置为 <code>Failed</code>。</p><h2 id=container-states>容器状态</h2><p>Kubernetes 会跟踪 Pod 中每个容器的状态，就像它跟踪 Pod 总体上的<a href=#pod-phase>阶段</a>一样。
你可以使用<a href=/zh-cn/docs/concepts/containers/container-lifecycle-hooks/>容器生命周期回调</a>
来在容器生命周期中的特定时间点触发事件。</p><p>一旦<a class=glossary-tooltip title='控制平面组件，负责监视新创建的、未指定运行节点的 Pod，选择节点让 Pod 在上面运行。' data-toggle=tooltip data-placement=top href=/zh-cn/docs/reference/command-line-tools-reference/kube-scheduler/ target=_blank aria-label=调度器>调度器</a>将 Pod
分派给某个节点，<code>kubelet</code>
就通过<a class=glossary-tooltip title=容器运行时是负责运行容器的软件。 data-toggle=tooltip data-placement=top href=/zh-cn/docs/setup/production-environment/container-runtimes target=_blank aria-label=容器运行时>容器运行时</a>开始为
Pod 创建容器。容器的状态有三种：<code>Waiting</code>（等待）、<code>Running</code>（运行中）和
<code>Terminated</code>（已终止）。</p><p>要检查 Pod 中容器的状态，你可以使用 <code>kubectl describe pod &lt;pod 名称></code>。
其输出中包含 Pod 中每个容器的状态。</p><p>每种状态都有特定的含义：</p><h3 id=container-state-waiting><code>Waiting</code> （等待）</h3><p>如果容器并不处在 <code>Running</code> 或 <code>Terminated</code> 状态之一，它就处在 <code>Waiting</code> 状态。
处于 <code>Waiting</code> 状态的容器仍在运行它完成启动所需要的操作：例如，
从某个容器镜像仓库拉取容器镜像，或者向容器应用 <a class=glossary-tooltip title='Secret 用于存储敏感信息，如密码、 OAuth 令牌和 SSH 密钥。' data-toggle=tooltip data-placement=top href=/zh-cn/docs/concepts/configuration/secret/ target=_blank aria-label=Secret>Secret</a>
数据等等。
当你使用 <code>kubectl</code> 来查询包含 <code>Waiting</code> 状态的容器的 Pod 时，你也会看到一个
Reason 字段，其中给出了容器处于等待状态的原因。</p><h3 id=container-state-running><code>Running</code>（运行中）</h3><p><code>Running</code> 状态表明容器正在执行状态并且没有问题发生。
如果配置了 <code>postStart</code> 回调，那么该回调已经执行且已完成。
如果你使用 <code>kubectl</code> 来查询包含 <code>Running</code> 状态的容器的 Pod 时，
你也会看到关于容器进入 <code>Running</code> 状态的信息。</p><h3 id=container-state-terminated><code>Terminated</code>（已终止）</h3><p>处于 <code>Terminated</code> 状态的容器已经开始执行并且或者正常结束或者因为某些原因失败。
如果你使用 <code>kubectl</code> 来查询包含 <code>Terminated</code> 状态的容器的 Pod 时，
你会看到容器进入此状态的原因、退出代码以及容器执行期间的起止时间。</p><p>如果容器配置了 <code>preStop</code> 回调，则该回调会在容器进入 <code>Terminated</code>
状态之前执行。</p><h2 id=restart-policy>容器重启策略</h2><p>Pod 的 <code>spec</code> 中包含一个 <code>restartPolicy</code> 字段，其可能取值包括
Always、OnFailure 和 Never。默认值是 Always。</p><p><code>restartPolicy</code> 适用于 Pod 中的所有容器。<code>restartPolicy</code> 仅针对同一节点上
<code>kubelet</code> 的容器重启动作。当 Pod 中的容器退出时，<code>kubelet</code>
会按指数回退方式计算重启的延迟（10s、20s、40s、...），其最长延迟为 5 分钟。
一旦某容器执行了 10 分钟并且没有出现问题，<code>kubelet</code> 对该容器的重启回退计时器执行重置操作。</p><h2 id=pod-conditions>Pod 状况</h2><p>Pod 有一个 PodStatus 对象，其中包含一个
<a href=/docs/reference/generated/kubernetes-api/v1.25/#podcondition-v1-core>PodConditions</a>
数组。Pod 可能通过也可能未通过其中的一些状况测试。
Kubelet 管理以下 PodCondition：</p><ul><li><code>PodScheduled</code>：Pod 已经被调度到某节点；</li><li><code>PodHasNetwork</code>：Pod 沙箱被成功创建并且配置了网络（Alpha 特性，必须被<a href=#pod-has-network>显式启用</a>）；</li><li><code>ContainersReady</code>：Pod 中所有容器都已就绪；</li><li><code>Initialized</code>：所有的 <a href=/zh-cn/docs/concepts/workloads/pods/init-containers/>Init 容器</a>都已成功完成；</li><li><code>Ready</code>：Pod 可以为请求提供服务，并且应该被添加到对应服务的负载均衡池中。</li></ul><table><thead><tr><th style=text-align:left>字段名称</th><th style=text-align:left>描述</th></tr></thead><tbody><tr><td style=text-align:left><code>type</code></td><td style=text-align:left>Pod 状况的名称</td></tr><tr><td style=text-align:left><code>status</code></td><td style=text-align:left>表明该状况是否适用，可能的取值有 "<code>True</code>"、"<code>False</code>" 或 "<code>Unknown</code>"</td></tr><tr><td style=text-align:left><code>lastProbeTime</code></td><td style=text-align:left>上次探测 Pod 状况时的时间戳</td></tr><tr><td style=text-align:left><code>lastTransitionTime</code></td><td style=text-align:left>Pod 上次从一种状态转换到另一种状态时的时间戳</td></tr><tr><td style=text-align:left><code>reason</code></td><td style=text-align:left>机器可读的、驼峰编码（UpperCamelCase）的文字，表述上次状况变化的原因</td></tr><tr><td style=text-align:left><code>message</code></td><td style=text-align:left>人类可读的消息，给出上次状态转换的详细信息</td></tr></tbody></table><h3 id=pod-readiness-gate>Pod 就绪态</h3><div style=margin-top:10px;margin-bottom:10px><b>特性状态：</b> <code>Kubernetes v1.14 [stable]</code></div><p>你的应用可以向 PodStatus 中注入额外的反馈或者信号：<strong>Pod Readiness（Pod 就绪态）</strong>。
要使用这一特性，可以设置 Pod 规约中的 <code>readinessGates</code> 列表，为 kubelet
提供一组额外的状况供其评估 Pod 就绪态时使用。</p><p>就绪态门控基于 Pod 的 <code>status.conditions</code> 字段的当前值来做决定。
如果 Kubernetes 无法在 <code>status.conditions</code> 字段中找到某状况，
则该状况的状态值默认为 "<code>False</code>"。</p><p>这里是一个例子：</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:#00f;font-weight:700>...</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>readinessGates</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:green;font-weight:700>conditionType</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;www.example.com/feature-1&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>status</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>conditions</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:green;font-weight:700>type</span>:<span style=color:#bbb> </span>Ready                             <span style=color:#bbb> </span><span style=color:#080;font-style:italic># 内置的 Pod 状况</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>status</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;False&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>lastProbeTime</span>:<span style=color:#bbb> </span><span style=color:#a2f;font-weight:700>null</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>lastTransitionTime</span>:<span style=color:#bbb> </span>2018-01-01T00:00:00Z<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:green;font-weight:700>type</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;www.example.com/feature-1&#34;</span><span style=color:#bbb>        </span><span style=color:#080;font-style:italic># 额外的 Pod 状况</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>status</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;False&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>lastProbeTime</span>:<span style=color:#bbb> </span><span style=color:#a2f;font-weight:700>null</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>lastTransitionTime</span>:<span style=color:#bbb> </span>2018-01-01T00:00:00Z<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>containerStatuses</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:green;font-weight:700>containerID</span>:<span style=color:#bbb> </span>docker://abcd...<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>ready</span>:<span style=color:#bbb> </span><span style=color:#a2f;font-weight:700>true</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:#00f;font-weight:700>...</span><span style=color:#bbb>
</span></span></span></code></pre></div><p>你所添加的 Pod 状况名称必须满足 Kubernetes
<a href=/zh-cn/docs/concepts/overview/working-with-objects/labels/#syntax-and-character-set>标签键名格式</a>。</p><h3 id=pod-readiness-status>Pod 就绪态的状态</h3><p>命令 <code>kubectl patch</code> 不支持修改对象的状态。
如果需要设置 Pod 的 <code>status.conditions</code>，应用或者
<a class=glossary-tooltip title=一种用于管理自定义资源的专用控制器 data-toggle=tooltip data-placement=top href=/zh-cn/docs/concepts/extend-kubernetes/operator/ target=_blank aria-label=Operators>Operators</a>
需要使用 <code>PATCH</code> 操作。你可以使用
<a href=/zh-cn/docs/reference/using-api/client-libraries/>Kubernetes 客户端库</a>之一来编写代码，
针对 Pod 就绪态设置定制的 Pod 状况。</p><p>对于使用定制状况的 Pod 而言，只有当下面的陈述都适用时，该 Pod 才会被评估为就绪：</p><ul><li>Pod 中所有容器都已就绪；</li><li><code>readinessGates</code> 中的所有状况都为 <code>True</code> 值。</li></ul><p>当 Pod 的容器都已就绪，但至少一个定制状况没有取值或者取值为 <code>False</code>，
<code>kubelet</code> 将 Pod 的<a href=#pod-conditions>状况</a>设置为 <code>ContainersReady</code>。</p><h3 id=pod-has-network>Pod 网络就绪</h3><div style=margin-top:10px;margin-bottom:10px><b>特性状态：</b> <code>Kubernetes v1.25 [alpha]</code></div><p>在 Pod 被调度到某节点后，它需要被 Kubelet 接受并且挂载所需的卷。
一旦这些阶段完成，Kubelet 将与容器运行时（使用<a class=glossary-tooltip title='一组与 kubelet 集成的容器运行时 API' data-toggle=tooltip data-placement=top href=/zh-cn/docs/concepts/overview/components/#container-runtime target=_blank aria-label='容器运行时接口（Container Runtime Interface；CRI）'>容器运行时接口（Container Runtime Interface；CRI）</a>）
一起为 Pod 生成运行时沙箱并配置网络。
如果启用了 <code>PodHasNetworkCondition</code> <a href=/zh-cn/docs/reference/command-line-tools-reference/feature-gates/>特性门控</a>，
kubelet 会通过 Pod 的 <code>status.conditions</code> 字段中的 <code>PodHasNetwork</code> 状况来报告
Pod 是否达到了初始化里程碑。</p><p>当 kubelet 检测到 Pod 不具备配置了网络的运行时沙箱时，<code>PodHasNetwork</code> 状况将被设置为 <code>False</code>。
以下场景中将会发生这种状况：</p><ul><li>在 Pod 生命周期的早期阶段，kubelet 还没有开始使用容器运行时为 Pod 设置沙箱时。</li><li>在 Pod 生命周期的末期阶段，Pod 的沙箱由于以下原因被销毁时：<ul><li>节点重启时 Pod 没有被驱逐</li><li>对于使用虚拟机进行隔离的容器运行时，Pod 沙箱虚拟机重启时，需要创建一个新的沙箱和全新的容器网络配置。</li></ul></li></ul><p>在运行时插件成功完成 Pod 的沙箱创建和网络配置后，
kubelet 会将 <code>PodHasNetwork</code> 状况设置为 <code>True</code>。
当 <code>PodHasNetwork</code> 状况设置为 <code>True</code> 后，
Kubelet 可以开始拉取容器镜像和创建容器。</p><p>对于带有 Init 容器的 Pod，kubelet 会在 Init 容器成功完成后将 <code>Initialized</code> 状况设置为 <code>True</code>
（这发生在运行时成功创建沙箱和配置网络之后），
对于没有 Init 容器的 Pod，kubelet 会在创建沙箱和网络配置开始之前将
<code>Initialized</code> 状况设置为 <code>True</code>。</p><h2 id=container-probes>容器探针</h2><p>probe 是由 <a href=/zh-cn/docs/reference/command-line-tools-reference/kubelet/>kubelet</a> 对容器执行的定期诊断。
要执行诊断，kubelet 既可以在容器内执行代码，也可以发出一个网络请求。</p><h3 id=probe-check-methods>检查机制</h3><p>使用探针来检查容器有四种不同的方法。
每个探针都必须准确定义为这四种机制中的一种：</p><dl><dt><code>exec</code></dt><dd>在容器内执行指定命令。如果命令退出时返回码为 0 则认为诊断成功。</dd><dt><code>grpc</code></dt><dd>使用 <a href=https://grpc.io/>gRPC</a> 执行一个远程过程调用。
目标应该实现
<a href=https://grpc.io/grpc/core/md_doc_health-checking.html>gRPC健康检查</a>。
如果响应的状态是 "SERVING"，则认为诊断成功。
gRPC 探针是一个 Alpha 特性，只有在你启用了
"GRPCContainerProbe" <a href=/zh-cn/docs/reference/command-line-tools-reference/feature-gates/>特性门控</a>时才能使用。</dd><dt><code>httpGet</code></dt><dd>对容器的 IP 地址上指定端口和路径执行 HTTP <code>GET</code> 请求。如果响应的状态码大于等于 200
且小于 400，则诊断被认为是成功的。</dd><dt><code>tcpSocket</code></dt><dd>对容器的 IP 地址上的指定端口执行 TCP 检查。如果端口打开，则诊断被认为是成功的。
如果远程系统（容器）在打开连接后立即将其关闭，这算作是健康的。</dd></dl><h3 id=probe-outcome>探测结果</h3><p>每次探测都将获得以下三种结果之一：</p><dl><dt><code>Success</code>（成功）</dt><dd>容器通过了诊断。</dd><dt><code>Failure</code>（失败）</dt><dd>容器未通过诊断。</dd><dt><code>Unknown</code>（未知）</dt><dd>诊断失败，因此不会采取任何行动。</dd></dl><h3 id=types-of-probe>探测类型</h3><p>针对运行中的容器，<code>kubelet</code> 可以选择是否执行以下三种探针，以及如何针对探测结果作出反应：</p><dl><dt><code>livenessProbe</code></dt><dd>指示容器是否正在运行。如果存活态探测失败，则 kubelet 会杀死容器，
并且容器将根据其<a href=#restart-policy>重启策略</a>决定未来。如果容器不提供存活探针，
则默认状态为 <code>Success</code>。</dd><dt><code>readinessProbe</code></dt><dd>指示容器是否准备好为请求提供服务。如果就绪态探测失败，
端点控制器将从与 Pod 匹配的所有服务的端点列表中删除该 Pod 的 IP 地址。
初始延迟之前的就绪态的状态值默认为 <code>Failure</code>。
如果容器不提供就绪态探针，则默认状态为 <code>Success</code>。</dd><dt><code>startupProbe</code></dt><dd>指示容器中的应用是否已经启动。如果提供了启动探针，则所有其他探针都会被
禁用，直到此探针成功为止。如果启动探测失败，<code>kubelet</code> 将杀死容器，
而容器依其<a href=#restart-policy>重启策略</a>进行重启。
如果容器没有提供启动探测，则默认状态为 <code>Success</code>。</dd></dl><p>如欲了解如何设置存活态、就绪态和启动探针的进一步细节，
可以参阅<a href=/zh-cn/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/>配置存活态、就绪态和启动探针</a>。</p><h4 id=when-should-you-use-a-liveness-probe>何时该使用存活态探针?</h4><div style=margin-top:10px;margin-bottom:10px><b>特性状态：</b> <code>Kubernetes v1.0 [stable]</code></div><p>如果容器中的进程能够在遇到问题或不健康的情况下自行崩溃，则不一定需要存活态探针；
<code>kubelet</code> 将根据 Pod 的 <code>restartPolicy</code> 自动执行修复操作。</p><p>如果你希望容器在探测失败时被杀死并重新启动，那么请指定一个存活态探针，
并指定 <code>restartPolicy</code> 为 "<code>Always</code>" 或 "<code>OnFailure</code>"。</p><h4 id=when-should-you-use-a-readiness-probe>何时该使用就绪态探针?</h4><div style=margin-top:10px;margin-bottom:10px><b>特性状态：</b> <code>Kubernetes v1.0 [stable]</code></div><p>如果要仅在探测成功时才开始向 Pod 发送请求流量，请指定就绪态探针。
在这种情况下，就绪态探针可能与存活态探针相同，但是规约中的就绪态探针的存在意味着
Pod 将在启动阶段不接收任何数据，并且只有在探针探测成功后才开始接收数据。</p><p>如果你希望容器能够自行进入维护状态，也可以指定一个就绪态探针，
检查某个特定于就绪态的因此不同于存活态探测的端点。</p><p>如果你的应用程序对后端服务有严格的依赖性，你可以同时实现存活态和就绪态探针。
当应用程序本身是健康的，存活态探针检测通过后，就绪态探针会额外检查每个所需的后端服务是否可用。
这可以帮助你避免将流量导向只能返回错误信息的 Pod。</p><p>如果你的容器需要在启动期间加载大型数据、配置文件或执行迁移，
你可以使用<a href=#when-should-you-use-a-startup-probe>启动探针</a>。
然而，如果你想区分已经失败的应用和仍在处理其启动数据的应用，你可能更倾向于使用就绪探针。</p><div class="alert alert-info note callout" role=alert><strong>说明：</strong><p>请注意，如果你只是想在 Pod 被删除时能够排空请求，则不一定需要使用就绪态探针；
在删除 Pod 时，Pod 会自动将自身置于未就绪状态，无论就绪态探针是否存在。
等待 Pod 中的容器停止期间，Pod 会一直处于未就绪状态。</div><h4 id=when-should-you-use-a-startup-probe>何时该使用启动探针？</h4><div style=margin-top:10px;margin-bottom:10px><b>特性状态：</b> <code>Kubernetes v1.20 [stable]</code></div><p>对于所包含的容器需要较长时间才能启动就绪的 Pod 而言，启动探针是有用的。
你不再需要配置一个较长的存活态探测时间间隔，只需要设置另一个独立的配置选定，
对启动期间的容器执行探测，从而允许使用远远超出存活态时间间隔所允许的时长。</p><p>如果你的容器启动时间通常超出 <code>initialDelaySeconds + failureThreshold × periodSeconds</code>
总值，你应该设置一个启动探测，对存活态探针所使用的同一端点执行检查。
<code>periodSeconds</code> 的默认值是 10 秒。你应该将其 <code>failureThreshold</code> 设置得足够高，
以便容器有充足的时间完成启动，并且避免更改存活态探针所使用的默认值。
这一设置有助于减少死锁状况的发生。</p><h2 id=pod-termination>Pod 的终止</h2><p>由于 Pod 所代表的是在集群中节点上运行的进程，当不再需要这些进程时允许其体面地终止是很重要的。
一般不应武断地使用 <code>KILL</code> 信号终止它们，导致这些进程没有机会完成清理操作。</p><p>设计的目标是令你能够请求删除进程，并且知道进程何时被终止，同时也能够确保删除操作终将完成。
当你请求删除某个 Pod 时，集群会记录并跟踪 Pod 的体面终止周期，
而不是直接强制地杀死 Pod。在存在强制关闭设施的前提下，
<a class=glossary-tooltip title='一个在集群中每个节点上运行的代理。它保证容器都运行在 Pod 中。' data-toggle=tooltip data-placement=top href=/docs/reference/generated/kubelet target=_blank aria-label=kubelet>kubelet</a> 会尝试体面地终止
Pod。</p><p>通常情况下，容器运行时会发送一个 TERM 信号到每个容器中的主进程。
很多容器运行时都能够注意到容器镜像中 <code>STOPSIGNAL</code> 的值，并发送该信号而不是 TERM。
一旦超出了体面终止限期，容器运行时会向所有剩余进程发送 KILL 信号，之后
Pod 就会被从 <a class=glossary-tooltip title='提供 Kubernetes API 服务的控制面组件。' data-toggle=tooltip data-placement=top href=/zh-cn/docs/concepts/overview/components/#kube-apiserver target=_blank aria-label='API 服务器'>API 服务器</a>上移除。
如果 <code>kubelet</code> 或者容器运行时的管理服务在等待进程终止期间被重启，
集群会从头开始重试，赋予 Pod 完整的体面终止限期。</p><p>下面是一个例子：</p><ol><li><p>你使用 <code>kubectl</code> 工具手动删除某个特定的 Pod，而该 Pod 的体面终止限期是默认值（30 秒）。</p></li><li><p>API 服务器中的 Pod 对象被更新，记录涵盖体面终止限期在内 Pod
的最终死期，超出所计算时间点则认为 Pod 已死（dead）。
如果你使用 <code>kubectl describe</code> 来查验你正在删除的 Pod，该 Pod 会显示为
"Terminating" （正在终止）。
在 Pod 运行所在的节点上：<code>kubelet</code> 一旦看到 Pod
被标记为正在终止（已经设置了体面终止限期），<code>kubelet</code> 即开始本地的 Pod 关闭过程。</p><ol><li><p>如果 Pod 中的容器之一定义了 <code>preStop</code>
<a href=/zh-cn/docs/concepts/containers/container-lifecycle-hooks>回调</a>，
<code>kubelet</code> 开始在容器内运行该回调逻辑。如果超出体面终止限期时，
<code>preStop</code> 回调逻辑仍在运行，<code>kubelet</code> 会请求给予该 Pod 的宽限期一次性增加 2 秒钟。</p><div class="alert alert-info note callout" role=alert><strong>说明：</strong><pre><code>  如果 `preStop` 回调所需要的时间长于默认的体面终止限期，你必须修改
  `terminationGracePeriodSeconds` 属性值来使其正常工作。</code></pre></div></li></ol><ol start=2><li><p><code>kubelet</code> 接下来触发容器运行时发送 TERM 信号给每个容器中的进程 1。</p><div class="alert alert-info note callout" role=alert><strong>说明：</strong><pre><code>  Pod 中的容器会在不同时刻收到 TERM 信号，接收顺序也是不确定的。
  如果关闭的顺序很重要，可以考虑使用 `preStop` 回调逻辑来协调。</code></pre></div></li></ol></li></ol><ol start=3><li>在 <code>kubelet</code> 启动体面关闭逻辑的同时，控制面会将关闭的 Pod 从对应的
EndpointSlice（和 Endpoints）对象中移除，过滤条件是 Pod
被对应的<a class=glossary-tooltip title='将运行在一组 Pods 上的应用程序公开为网络服务的抽象方法。' data-toggle=tooltip data-placement=top href=/zh-cn/docs/concepts/services-networking/service/ target=_blank aria-label=服务>服务</a>以某
<a class=glossary-tooltip title=选择算符允许用户通过标签对一组资源对象进行筛选过滤。 data-toggle=tooltip data-placement=top href=/zh-cn/docs/concepts/overview/working-with-objects/labels/ target=_blank aria-label=选择算符>选择算符</a>选定。
<a class=glossary-tooltip title='ReplicaSet 是下一代副本控制器。' data-toggle=tooltip data-placement=top href=/zh-cn/docs/concepts/workloads/controllers/replicaset/ target=_blank aria-label=ReplicaSet>ReplicaSet</a>
和其他工作负载资源不再将关闭进程中的 Pod 视为合法的、能够提供服务的副本。
关闭动作很慢的 Pod 也无法继续处理请求数据，
因为负载均衡器（例如服务代理）已经在终止宽限期开始的时候将其从端点列表中移除。</li></ol><ol start=4><li><p>超出终止宽限期限时，<code>kubelet</code> 会触发强制关闭过程。容器运行时会向 Pod
中所有容器内仍在运行的进程发送 <code>SIGKILL</code> 信号。
<code>kubelet</code> 也会清理隐藏的 <code>pause</code> 容器，如果容器运行时使用了这种容器的话。</p></li><li><p><code>kubelet</code> 触发强制从 API 服务器上删除 Pod 对象的逻辑，并将体面终止限期设置为 0
（这意味着马上删除）。</p></li><li><p>API 服务器删除 Pod 的 API 对象，从任何客户端都无法再看到该对象。</p></li></ol><h3 id=pod-termination-forced>强制终止 Pod</h3><div class="alert alert-warning caution callout" role=alert><strong>注意：</strong><p>对于某些工作负载及其 Pod 而言，强制删除很可能会带来某种破坏。</div><p>默认情况下，所有的删除操作都会附有 30 秒钟的宽限期限。
<code>kubectl delete</code> 命令支持 <code>--grace-period=&lt;seconds></code> 选项，允许你重载默认值，
设定自己希望的期限值。</p><p>将宽限期限强制设置为 <code>0</code> 意味着立即从 API 服务器删除 Pod。
如果 Pod 仍然运行于某节点上，强制删除操作会触发 <code>kubelet</code> 立即执行清理操作。</p><div class="alert alert-info note callout" role=alert><strong>说明：</strong><p>你必须在设置 <code>--grace-period=0</code> 的同时额外设置 <code>--force</code> 参数才能发起强制删除请求。</div><p>执行强制删除操作时，API 服务器不再等待来自 <code>kubelet</code> 的、关于 Pod
已经在原来运行的节点上终止执行的确认消息。
API 服务器直接删除 Pod 对象，这样新的与之同名的 Pod 即可以被创建。
在节点侧，被设置为立即终止的 Pod 仍然会在被强行杀死之前获得一点点的宽限时间。</p><div class="alert alert-warning caution callout" role=alert><strong>注意：</strong><p>马上删除时不等待确认正在运行的资源已被终止。这些资源可能会无限期地继续在集群上运行。</div><p>如果你需要强制删除 StatefulSet 的 Pod，
请参阅<a href=/zh-cn/docs/tasks/run-application/force-delete-stateful-set-pod/>从 StatefulSet 中删除 Pod</a> 的任务文档。</p><h3 id=pod-garbage-collection>已终止 Pod 的垃圾收集</h3><p>对于已失败的 Pod 而言，对应的 API 对象仍然会保留在集群的 API 服务器上，
直到用户或者<a class=glossary-tooltip title='控制器通过 API 服务器监控集群的公共状态，并致力于将当前状态转变为期望的状态。' data-toggle=tooltip data-placement=top href=/zh-cn/docs/concepts/architecture/controller/ target=_blank aria-label=控制器>控制器</a>进程显式地将其删除。</p><p>控制面组件会在 Pod 个数超出所配置的阈值
（根据 <code>kube-controller-manager</code> 的 <code>terminated-pod-gc-threshold</code> 设置）时删除已终止的
Pod（阶段值为 <code>Succeeded</code> 或 <code>Failed</code>）。
这一行为会避免随着时间演进不断创建和终止 Pod 而引起的资源泄露问题。</p><h2 id=接下来>接下来</h2><ul><li>动手实践<a href=/zh-cn/docs/tasks/configure-pod-container/attach-handler-lifecycle-event/>为容器生命周期时间关联处理程序</a>。</li><li>动手实践<a href=/zh-cn/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/>配置存活态、就绪态和启动探针</a>。</li><li>进一步了解<a href=/zh-cn/docs/concepts/containers/container-lifecycle-hooks/>容器生命周期回调</a>。</li><li>关于 API 中定义的有关 Pod 和容器状态的详细规范信息，
可参阅 API 参考文档中 Pod 的 <a href=/docs/reference/kubernetes-api/workload-resources/pod-v1/#PodStatus><code>.status</code></a> 字段。</li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-1ccbd4eeded6ab138d98b59175bd557e>1.2 - Init 容器</h1><p>本页提供了 Init 容器的概览。Init 容器是一种特殊容器，在 <a class=glossary-tooltip title='Pod 表示你的集群上一组正在运行的容器。' data-toggle=tooltip data-placement=top href=/zh-cn/docs/concepts/workloads/pods/ target=_blank aria-label=Pod>Pod</a>
内的应用容器启动之前运行。Init 容器可以包括一些应用镜像中不存在的实用工具和安装脚本。</p><p>你可以在 Pod 的规约中与用来描述应用容器的 <code>containers</code> 数组平行的位置指定
Init 容器。</p><h2 id=understanding-init-containers>理解 Init 容器</h2><p>每个 <a class=glossary-tooltip title='Pod 表示你的集群上一组正在运行的容器。' data-toggle=tooltip data-placement=top href=/zh-cn/docs/concepts/workloads/pods/ target=_blank aria-label=Pod>Pod</a> 中可以包含多个容器，
应用运行在这些容器里面，同时 Pod 也可以有一个或多个先于应用容器启动的 Init 容器。</p><p>Init 容器与普通的容器非常像，除了如下两点：</p><ul><li>它们总是运行到完成。</li><li>每个都必须在下一个启动之前成功完成。</li></ul><p>如果 Pod 的 Init 容器失败，kubelet 会不断地重启该 Init 容器直到该容器成功为止。
然而，如果 Pod 对应的 <code>restartPolicy</code> 值为 "Never"，并且 Pod 的 Init 容器失败，
则 Kubernetes 会将整个 Pod 状态设置为失败。</p><p>为 Pod 设置 Init 容器需要在
<a href=/zh-cn/docs/reference/kubernetes-api/workload-resources/pod-v1/#PodSpec>Pod 规约</a>中添加 <code>initContainers</code> 字段，
该字段以 <a href=/docs/reference/generated/kubernetes-api/v1.25/#container-v1-core>Container</a>
类型对象数组的形式组织，和应用的 <code>containers</code> 数组同级相邻。
参阅 API 参考的<a href=/zh-cn/docs/reference/kubernetes-api/workload-resources/pod-v1/#Container>容器</a>章节了解详情。</p><p>Init 容器的状态在 <code>status.initContainerStatuses</code> 字段中以容器状态数组的格式返回
（类似 <code>status.containerStatuses</code> 字段）。</p><h3 id=differences-from-regular-containers>与普通容器的不同之处</h3><p>Init 容器支持应用容器的全部字段和特性，包括资源限制、数据卷和安全设置。
然而，Init 容器对资源请求和限制的处理稍有不同，在下面<a href=#resources>资源</a>节有说明。</p><p>同时 Init 容器不支持 <code>lifecycle</code>、<code>livenessProbe</code>、<code>readinessProbe</code> 和 <code>startupProbe</code>，
因为它们必须在 Pod 就绪之前运行完成。</p><p>如果为一个 Pod 指定了多个 Init 容器，这些容器会按顺序逐个运行。
每个 Init 容器必须运行成功，下一个才能够运行。当所有的 Init 容器运行完成时，
Kubernetes 才会为 Pod 初始化应用容器并像平常一样运行。</p><h2 id=using-init-containers>使用 Init 容器</h2><p>因为 Init 容器具有与应用容器分离的单独镜像，其启动相关代码具有如下优势：</p><ul><li><p>Init 容器可以包含一些安装过程中应用容器中不存在的实用工具或个性化代码。
例如，没有必要仅为了在安装过程中使用类似 <code>sed</code>、<code>awk</code>、<code>python</code> 或 <code>dig</code>
这样的工具而去 <code>FROM</code> 一个镜像来生成一个新的镜像。</p></li><li><p>应用镜像的创建者和部署者可以各自独立工作，而没有必要联合构建一个单独的应用镜像。</p></li></ul><ul><li><p>与同一 Pod 中的多个应用容器相比，Init 容器能以不同的文件系统视图运行。因此，Init
容器可以被赋予访问应用容器不能访问的 <a class=glossary-tooltip title='Secret 用于存储敏感信息，如密码、 OAuth 令牌和 SSH 密钥。' data-toggle=tooltip data-placement=top href=/zh-cn/docs/concepts/configuration/secret/ target=_blank aria-label=Secret>Secret</a> 的权限。</p></li><li><p>由于 Init 容器必须在应用容器启动之前运行完成，因此 Init
容器提供了一种机制来阻塞或延迟应用容器的启动，直到满足了一组先决条件。
一旦前置条件满足，Pod 内的所有的应用容器会并行启动。</p></li><li><p>Init 容器可以安全地运行实用程序或自定义代码，而在其他方式下运行这些实用程序或自定义代码可能会降低应用容器镜像的安全性。
通过将不必要的工具分开，你可以限制应用容器镜像的被攻击范围。</p></li></ul><h3 id=examples>示例</h3><p>下面是一些如何使用 Init 容器的想法：</p><ul><li><p>等待一个 Service 完成创建，通过类似如下 Shell 命令：</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span><span style=color:#a2f;font-weight:700>for</span> i in <span style=color:#666>{</span>1..100<span style=color:#666>}</span>; <span style=color:#a2f;font-weight:700>do</span> sleep 1; <span style=color:#a2f;font-weight:700>if</span> dig myservice; <span style=color:#a2f;font-weight:700>then</span> <span style=color:#a2f>exit</span> 0; <span style=color:#a2f;font-weight:700>fi</span>; <span style=color:#a2f;font-weight:700>done</span>; <span style=color:#a2f>exit</span> <span style=color:#666>1</span>
</span></span></code></pre></div></li></ul><ul><li><p>注册这个 Pod 到远程服务器，通过在命令中调用 API，类似如下：</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>curl -X POST http://<span style=color:#b8860b>$MANAGEMENT_SERVICE_HOST</span>:<span style=color:#b8860b>$MANAGEMENT_SERVICE_PORT</span>/register -d <span style=color:#b44>&#39;instance=$(&lt;POD_NAME&gt;)&amp;ip=$(&lt;POD_IP&gt;)&#39;</span>
</span></span></code></pre></div></li></ul><ul><li><p>在启动应用容器之前等一段时间，使用类似命令：</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>sleep <span style=color:#666>60</span>
</span></span></code></pre></div></li></ul><ul><li><p>克隆 Git 仓库到<a class=glossary-tooltip title='包含可被 Pod 中容器访问的数据的目录。' data-toggle=tooltip data-placement=top href=/zh-cn/docs/concepts/storage/volumes/ target=_blank aria-label=卷>卷</a>中。</p></li><li><p>将配置值放到配置文件中，运行模板工具为主应用容器动态地生成配置文件。
例如，在配置文件中存放 <code>POD_IP</code> 值，并使用 Jinja 生成主应用配置文件。</p></li></ul><h3 id=init-containers-in-use>使用 Init 容器的情况</h3><p>下面的例子定义了一个具有 2 个 Init 容器的简单 Pod。 第一个等待 <code>myservice</code> 启动，
第二个等待 <code>mydb</code> 启动。 一旦这两个 Init 容器都启动完成，Pod 将启动 <code>spec</code> 节中的应用容器。</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>myapp-pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>labels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>app.kubernetes.io/name</span>:<span style=color:#bbb> </span>MyApp<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>myapp-container<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>busybox:1.28<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>command</span>:<span style=color:#bbb> </span>[<span style=color:#b44>&#39;sh&#39;</span>,<span style=color:#bbb> </span><span style=color:#b44>&#39;-c&#39;</span>,<span style=color:#bbb> </span><span style=color:#b44>&#39;echo The app is running! &amp;&amp; sleep 3600&#39;</span>]<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>initContainers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>init-myservice<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>busybox:1.28<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>command</span>:<span style=color:#bbb> </span>[<span style=color:#b44>&#39;sh&#39;</span>,<span style=color:#bbb> </span><span style=color:#b44>&#39;-c&#39;</span>,<span style=color:#bbb> </span><span style=color:#b44>&#34;until nslookup myservice.$(cat /var/run/secrets/kubernetes.io/serviceaccount/namespace).svc.cluster.local; do echo waiting for myservice; sleep 2; done&#34;</span>]<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>init-mydb<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>busybox:1.28<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>command</span>:<span style=color:#bbb> </span>[<span style=color:#b44>&#39;sh&#39;</span>,<span style=color:#bbb> </span><span style=color:#b44>&#39;-c&#39;</span>,<span style=color:#bbb> </span><span style=color:#b44>&#34;until nslookup mydb.$(cat /var/run/secrets/kubernetes.io/serviceaccount/namespace).svc.cluster.local; do echo waiting for mydb; sleep 2; done&#34;</span>]<span style=color:#bbb>
</span></span></span></code></pre></div><p>你通过运行下面的命令启动 Pod：</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl apply -f myapp.yaml
</span></span></code></pre></div><p>输出类似于：</p><pre tabindex=0><code>pod/myapp-pod created
</code></pre><p>使用下面的命令检查其状态：</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get -f myapp.yaml
</span></span></code></pre></div><p>输出类似于：</p><pre tabindex=0><code>NAME        READY     STATUS     RESTARTS   AGE
myapp-pod   0/1       Init:0/2   0          6m
</code></pre><p>或者查看更多详细信息：</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl describe -f myapp.yaml
</span></span></code></pre></div><p>输出类似于：</p><pre tabindex=0><code>Name:          myapp-pod
Namespace:     default
[...]
Labels:        app.kubernetes.io/name=MyApp
Status:        Pending
[...]
Init Containers:
  init-myservice:
[...]
    State:         Running
[...]
  init-mydb:
[...]
    State:         Waiting
      Reason:      PodInitializing
    Ready:         False
[...]
Containers:
  myapp-container:
[...]
    State:         Waiting
      Reason:      PodInitializing
    Ready:         False
[...]
Events:
  FirstSeen    LastSeen    Count    From                      SubObjectPath                           Type          Reason        Message
  ---------    --------    -----    ----                      -------------                           --------      ------        -------
  16s          16s         1        {default-scheduler }                                              Normal        Scheduled     Successfully assigned myapp-pod to 172.17.4.201
  16s          16s         1        {kubelet 172.17.4.201}    spec.initContainers{init-myservice}     Normal        Pulling       pulling image &#34;busybox&#34;
  13s          13s         1        {kubelet 172.17.4.201}    spec.initContainers{init-myservice}     Normal        Pulled        Successfully pulled image &#34;busybox&#34;
  13s          13s         1        {kubelet 172.17.4.201}    spec.initContainers{init-myservice}     Normal        Created       Created container init-myservice
  13s          13s         1        {kubelet 172.17.4.201}    spec.initContainers{init-myservice}     Normal        Started       Started container init-myservice
</code></pre><p>如需查看 Pod 内 Init 容器的日志，请执行：</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl logs myapp-pod -c init-myservice <span style=color:#080;font-style:italic># 查看第一个 Init 容器</span>
</span></span><span style=display:flex><span>kubectl logs myapp-pod -c init-mydb      <span style=color:#080;font-style:italic># 查看第二个 Init 容器</span>
</span></span></code></pre></div><p>在这一刻，Init 容器将会等待至发现名称为 <code>mydb</code> 和 <code>myservice</code> 的 Service。</p><p>如下为创建这些 Service 的配置文件：</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#00f;font-weight:700>---</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Service<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>myservice<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>ports</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>protocol</span>:<span style=color:#bbb> </span>TCP<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>port</span>:<span style=color:#bbb> </span><span style=color:#666>80</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>targetPort</span>:<span style=color:#bbb> </span><span style=color:#666>9376</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:#00f;font-weight:700>---</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Service<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>mydb<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>ports</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>protocol</span>:<span style=color:#bbb> </span>TCP<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>port</span>:<span style=color:#bbb> </span><span style=color:#666>80</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>targetPort</span>:<span style=color:#bbb> </span><span style=color:#666>9377</span><span style=color:#bbb>
</span></span></span></code></pre></div><p>创建 <code>mydb</code> 和 <code>myservice</code> 服务的命令：</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl apply -f services.yaml
</span></span></code></pre></div><p>输出类似于：</p><pre tabindex=0><code>service/myservice created
service/mydb created
</code></pre><p>这样你将能看到这些 Init 容器执行完毕，随后 <code>my-app</code> 的 Pod 进入 <code>Running</code> 状态：</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get -f myapp.yaml
</span></span></code></pre></div><p>输出类似于：</p><pre tabindex=0><code>NAME        READY     STATUS    RESTARTS   AGE
myapp-pod   1/1       Running   0          9m
</code></pre><p>这个简单例子应该能为你创建自己的 Init 容器提供一些启发。
<a href=#what-s-next>接下来</a>节提供了更详细例子的链接。</p><h2 id=detailed-behavior>具体行为</h2><p>在 Pod 启动过程中，每个 Init 容器会在网络和数据卷初始化之后按顺序启动。
kubelet 运行依据 Init 容器在 Pod 规约中的出现顺序依次运行之。</p><p>每个 Init 容器成功退出后才会启动下一个 Init 容器。
如果某容器因为容器运行时的原因无法启动，或以错误状态退出，kubelet 会根据
Pod 的 <code>restartPolicy</code> 策略进行重试。
然而，如果 Pod 的 <code>restartPolicy</code> 设置为 "Always"，Init 容器失败时会使用
<code>restartPolicy</code> 的 "OnFailure" 策略。</p><p>在所有的 Init 容器没有成功之前，Pod 将不会变成 <code>Ready</code> 状态。
Init 容器的端口将不会在 Service 中进行聚集。正在初始化中的 Pod 处于 <code>Pending</code> 状态，
但会将状况 <code>Initializing</code> 设置为 false。</p><p>如果 Pod <a href=#pod-restart-reasons>重启</a>，所有 Init 容器必须重新执行。</p><p>对 Init 容器规约的修改仅限于容器的 <code>image</code> 字段。
更改 Init 容器的 <code>image</code> 字段，等同于重启该 Pod。</p><p>因为 Init 容器可能会被重启、重试或者重新执行，所以 Init 容器的代码应该是幂等的。
特别地，基于 <code>emptyDirs</code> 写文件的代码，应该对输出文件可能已经存在做好准备。</p><p>Init 容器具有应用容器的所有字段。然而 Kubernetes 禁止使用 <code>readinessProbe</code>，
因为 Init 容器不能定义不同于完成态（Completion）的就绪态（Readiness）。
Kubernetes 会在校验时强制执行此检查。</p><p>在 Pod 上使用 <code>activeDeadlineSeconds</code> 和在容器上使用 <code>livenessProbe</code> 可以避免
Init 容器一直重复失败。
<code>activeDeadlineSeconds</code> 时间包含了 Init 容器启动的时间。
但建议仅在团队将其应用程序部署为 Job 时才使用 <code>activeDeadlineSeconds</code>，
因为 <code>activeDeadlineSeconds</code> 在 Init 容器结束后仍有效果。
如果你设置了 <code>activeDeadlineSeconds</code>，已经在正常运行的 Pod 会被杀死。</p><p>在 Pod 中的每个应用容器和 Init 容器的名称必须唯一；
与任何其它容器共享同一个名称，会在校验时抛出错误。</p><h3 id=resources>资源</h3><p>在给定的 Init 容器执行顺序下，资源使用适用于如下规则：</p><ul><li>所有 Init 容器上定义的任何特定资源的 limit 或 request 的最大值，作为
Pod <strong>有效初始 request/limit</strong>。
如果任何资源没有指定资源限制，这被视为最高限制。</li><li>Pod 对资源的 <strong>有效 limit/request</strong> 是如下两者中的较大者：<ul><li>所有应用容器对某个资源的 limit/request 之和</li><li>对某个资源的有效初始 limit/request</li></ul></li><li>基于有效 limit/request 完成调度，这意味着 Init 容器能够为初始化过程预留资源，
这些资源在 Pod 生命周期过程中并没有被使用。</li><li>Pod 的 <strong>有效 QoS 层</strong>，与 Init 容器和应用容器的一样。</li></ul><p>配额和限制适用于有效 Pod 的请求和限制值。
Pod 级别的 cgroups 是基于有效 Pod 的请求和限制值，和调度器相同。</p><h3 id=pod-restart-reasons>Pod 重启的原因</h3><p>Pod 重启会导致 Init 容器重新执行，主要有如下几个原因：</p><ul><li><p>Pod 的基础设施容器 (译者注：如 <code>pause</code> 容器) 被重启。这种情况不多见，
必须由具备 root 权限访问节点的人员来完成。</p></li><li><p>当 <code>restartPolicy</code> 设置为 <code>Always</code>，Pod 中所有容器会终止而强制重启。
由于垃圾收集机制的原因，Init 容器的完成记录将会丢失。</p></li></ul><p>当 Init 容器的镜像发生改变或者 Init 容器的完成记录因为垃圾收集等原因被丢失时，
Pod 不会被重启。这一行为适用于 Kubernetes v1.20 及更新版本。
如果你在使用较早版本的 Kubernetes，可查阅你所使用的版本对应的文档。</p><h2 id=接下来>接下来</h2><ul><li>阅读<a href=/zh-cn/docs/tasks/configure-pod-container/configure-pod-initialization/#create-a-pod-that-has-an-init-container>创建包含 Init 容器的 Pod</a></li><li>学习如何<a href=/zh-cn/docs/tasks/debug/debug-application/debug-init-containers/>调试 Init 容器</a></li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-4aaf43c715cd764bc8ed4436f3537e68>1.3 - 干扰（Disruptions）</h1><p>本指南针对的是希望构建高可用性应用的应用所有者，他们有必要了解可能发生在 Pod 上的干扰类型。</p><p>文档同样适用于想要执行自动化集群操作（例如升级和自动扩展集群）的集群管理员。</p><h2 id=voluntary-and-involuntary-disruptions>自愿干扰和非自愿干扰</h2><p>Pod 不会消失，除非有人（用户或控制器）将其销毁，或者出现了不可避免的硬件或软件系统错误。</p><p>我们把这些不可避免的情况称为应用的<strong>非自愿干扰（Involuntary Disruptions）</strong>。例如：</p><ul><li>节点下层物理机的硬件故障</li><li>集群管理员错误地删除虚拟机（实例）</li><li>云提供商或虚拟机管理程序中的故障导致的虚拟机消失</li><li>内核错误</li><li>节点由于集群网络隔离从集群中消失</li><li>由于节点<a href=/zh-cn/docs/concepts/scheduling-eviction/node-pressure-eviction/>资源不足</a>导致 pod 被驱逐。</li></ul><p>除了资源不足的情况，大多数用户应该都熟悉这些情况；它们不是特定于 Kubernetes 的。</p><p>我们称其他情况为<strong>自愿干扰（Voluntary Disruptions）</strong>。
包括由应用所有者发起的操作和由集群管理员发起的操作。
典型的应用所有者的操作包括：</p><ul><li>删除 Deployment 或其他管理 Pod 的控制器</li><li>更新了 Deployment 的 Pod 模板导致 Pod 重启</li><li>直接删除 Pod（例如，因为误操作）</li></ul><p>集群管理员操作包括：</p><ul><li><a href=/zh-cn/docs/tasks/administer-cluster/safely-drain-node/>排空（drain）节点</a>进行修复或升级。</li><li>从集群中排空节点以缩小集群（了解<a href=https://github.com/kubernetes/autoscaler/#readme>集群自动扩缩</a>）。</li><li>从节点中移除一个 Pod，以允许其他 Pod 使用该节点。</li></ul><p>这些操作可能由集群管理员直接执行，也可能由集群管理员所使用的自动化工具执行，或者由集群托管提供商自动执行。</p><p>咨询集群管理员或联系云提供商，或者查询发布文档，以确定是否为集群启用了任何资源干扰源。
如果没有启用，可以不用创建 Pod Disruption Budgets（Pod 干扰预算）</p><div class="alert alert-warning caution callout" role=alert><strong>注意：</strong> 并非所有的自愿干扰都会受到 Pod 干扰预算的限制。
例如，删除 Deployment 或 Pod 的删除操作就会跳过 Pod 干扰预算检查。</div><h2 id=处理干扰>处理干扰</h2><p>以下是减轻非自愿干扰的一些方法：</p><ul><li>确保 Pod 在请求中给出<a href=/zh-cn/docs/tasks/configure-pod-container/assign-memory-resource/>所需资源</a>。</li><li>如果需要更高的可用性，请复制应用。
（了解有关运行多副本的<a href=/zh-cn/docs/tasks/run-application/run-stateless-application-deployment/>无状态</a>
和<a href=/zh-cn/docs/tasks/run-application/run-replicated-stateful-application/>有状态</a>应用的信息。）</li><li>为了在运行复制应用时获得更高的可用性，请跨机架（使用
<a href=/zh-cn/docs/concepts/scheduling-eviction/assign-pod-node/#affinity-and-anti-affinity>反亲和性</a>
或跨区域（如果使用<a href=/zh-cn/docs/setup/best-practices/multiple-zones/>多区域集群</a>）扩展应用。</li></ul><p>自愿干扰的频率各不相同。在一个基本的 Kubernetes 集群中，没有自愿干扰（只有用户触发的干扰）。
然而，集群管理员或托管提供商可能运行一些可能导致自愿干扰的额外服务。例如，节点软
更新可能导致自愿干扰。另外，集群（节点）自动缩放的某些
实现可能导致碎片整理和紧缩节点的自愿干扰。集群
管理员或托管提供商应该已经记录了各级别的自愿干扰（如果有的话）。
有些配置选项，例如在 pod spec 中
<a href=/zh-cn/docs/concepts/scheduling-eviction/pod-priority-preemption/>使用 PriorityClasses</a>
也会产生自愿（和非自愿）的干扰。</p><h2 id=pod-disruption-budgets>干扰预算</h2><div style=margin-top:10px;margin-bottom:10px><b>特性状态：</b> <code>Kubernetes v1.21 [stable]</code></div><p>即使你会经常引入自愿性干扰，Kubernetes 提供的功能也能够支持你运行高度可用的应用。</p><p>作为一个应用的所有者，你可以为每个应用创建一个 <code>PodDisruptionBudget</code>（PDB）。
PDB 将限制在同一时间因自愿干扰导致的多副本应用中发生宕机的 Pod 数量。
例如，基于票选机制的应用希望确保运行中的副本数永远不会低于票选所需的数量。
Web 前端可能希望确保提供负载的副本数量永远不会低于总数的某个百分比。</p><p>集群管理员和托管提供商应该使用遵循 PodDisruptionBudgets 的接口
（通过调用<a href=/zh-cn/docs/tasks/administer-cluster/safely-drain-node/#the-eviction-api>Eviction API</a>），
而不是直接删除 Pod 或 Deployment。</p><p>例如，<code>kubectl drain</code> 命令可以用来标记某个节点即将停止服务。
运行 <code>kubectl drain</code> 命令时，工具会尝试驱逐你所停服的节点上的所有 Pod。
<code>kubectl</code> 代表你所提交的驱逐请求可能会暂时被拒绝，
所以该工具会周期性地重试所有失败的请求，
直到目标节点上的所有的 Pod 都被终止，或者达到配置的超时时间。</p><p>PDB 指定应用可以容忍的副本数量（相当于应该有多少副本）。
例如，具有 <code>.spec.replicas: 5</code> 的 Deployment 在任何时间都应该有 5 个 Pod。
如果 PDB 允许其在某一时刻有 4 个副本，那么驱逐 API 将允许同一时刻仅有一个（而不是两个）Pod 自愿干扰。</p><p>使用标签选择器来指定构成应用的一组 Pod，这与应用的控制器（Deployment，StatefulSet 等）
选择 Pod 的逻辑一样。</p><p>Pod 的“预期”数量由管理这些 Pod 的工作负载资源的 <code>.spec.replicas</code> 参数计算出来的。
控制平面通过检查 Pod 的
<code>.metadata.ownerReferences</code> 来发现关联的工作负载资源。</p><p>PDB 无法防止<a href=#voluntary-and-involuntary-disruptions>非自愿干扰</a>；
但它们确实计入预算。</p><p>由于应用的滚动升级而被删除或不可用的 Pod 确实会计入干扰预算，
但是工作负载资源（如 Deployment 和 StatefulSet）
在进行滚动升级时不受 PDB 的限制。
应用更新期间的故障处理方式是在对应的工作负载资源的 <code>spec</code> 中配置的。</p><p>当使用驱逐 API 驱逐 Pod 时，Pod 会被体面地
<a href=/zh-cn/docs/concepts/workloads/pods/pod-lifecycle/#pod-termination>终止</a>，期间会
参考 <a href=/docs/reference/generated/kubernetes-api/v1.25/#podspec-v1-core>PodSpec</a>
中的 <code>terminationGracePeriodSeconds</code> 配置值。</p><h2 id=pdb-example>PodDisruptionBudget 例子</h2><p>假设集群有 3 个节点，<code>node-1</code> 到 <code>node-3</code>。集群上运行了一些应用。
其中一个应用有 3 个副本，分别是 <code>pod-a</code>，<code>pod-b</code> 和 <code>pod-c</code>。
另外，还有一个不带 PDB 的无关 pod <code>pod-x</code> 也同样显示出来。
最初，所有的 Pod 分布如下：</p><table><thead><tr><th style=text-align:center>node-1</th><th style=text-align:center>node-2</th><th style=text-align:center>node-3</th></tr></thead><tbody><tr><td style=text-align:center>pod-a <em>available</em></td><td style=text-align:center>pod-b <em>available</em></td><td style=text-align:center>pod-c <em>available</em></td></tr><tr><td style=text-align:center>pod-x <em>available</em></td><td style=text-align:center></td><td style=text-align:center></td></tr></tbody></table><p>3 个 Pod 都是 deployment 的一部分，并且共同拥有同一个 PDB，要求 3 个 Pod 中至少有 2 个 Pod 始终处于可用状态。</p><p>例如，假设集群管理员想要重启系统，升级内核版本来修复内核中的缺陷。
集群管理员首先使用 <code>kubectl drain</code> 命令尝试腾空 <code>node-1</code> 节点。
命令尝试驱逐 <code>pod-a</code> 和 <code>pod-x</code>。操作立即就成功了。
两个 Pod 同时进入 <code>terminating</code> 状态。这时的集群处于下面的状态：</p><table><thead><tr><th style=text-align:center>node-1 <em>draining</em></th><th style=text-align:center>node-2</th><th style=text-align:center>node-3</th></tr></thead><tbody><tr><td style=text-align:center>pod-a <em>terminating</em></td><td style=text-align:center>pod-b <em>available</em></td><td style=text-align:center>pod-c <em>available</em></td></tr><tr><td style=text-align:center>pod-x <em>terminating</em></td><td style=text-align:center></td><td style=text-align:center></td></tr></tbody></table><p>Deployment 控制器观察到其中一个 Pod 正在终止，因此它创建了一个替代 Pod <code>pod-d</code>。
由于 <code>node-1</code> 被封锁（cordon），<code>pod-d</code> 落在另一个节点上。
同样其他控制器也创建了 <code>pod-y</code> 作为 <code>pod-x</code> 的替代品。</p><p>（注意：对于 StatefulSet 来说，<code>pod-a</code>（也称为 <code>pod-0</code>）需要在替换 Pod 创建之前完全终止，
替代它的也称为 <code>pod-0</code>，但是具有不同的 UID。除此之外，此示例也适用于 StatefulSet。）</p><p>当前集群的状态如下：</p><table><thead><tr><th style=text-align:center>node-1 <em>draining</em></th><th style=text-align:center>node-2</th><th style=text-align:center>node-3</th></tr></thead><tbody><tr><td style=text-align:center>pod-a <em>terminating</em></td><td style=text-align:center>pod-b <em>available</em></td><td style=text-align:center>pod-c <em>available</em></td></tr><tr><td style=text-align:center>pod-x <em>terminating</em></td><td style=text-align:center>pod-d <em>starting</em></td><td style=text-align:center>pod-y</td></tr></tbody></table><p>在某一时刻，Pod 被终止，集群如下所示：</p><table><thead><tr><th style=text-align:center>node-1 <em>drained</em></th><th style=text-align:center>node-2</th><th style=text-align:center>node-3</th></tr></thead><tbody><tr><td style=text-align:center></td><td style=text-align:center>pod-b <em>available</em></td><td style=text-align:center>pod-c <em>available</em></td></tr><tr><td style=text-align:center></td><td style=text-align:center>pod-d <em>starting</em></td><td style=text-align:center>pod-y</td></tr></tbody></table><p>此时，如果一个急躁的集群管理员试图排空（drain）<code>node-2</code> 或 <code>node-3</code>，drain 命令将被阻塞，
因为对于 Deployment 来说只有 2 个可用的 Pod，并且它的 PDB 至少需要 2 个。
经过一段时间，<code>pod-d</code> 变得可用。</p><p>集群状态如下所示：</p><table><thead><tr><th style=text-align:center>node-1 <em>drained</em></th><th style=text-align:center>node-2</th><th style=text-align:center>node-3</th></tr></thead><tbody><tr><td style=text-align:center></td><td style=text-align:center>pod-b <em>available</em></td><td style=text-align:center>pod-c <em>available</em></td></tr><tr><td style=text-align:center></td><td style=text-align:center>pod-d <em>available</em></td><td style=text-align:center>pod-y</td></tr></tbody></table><p>现在，集群管理员试图排空（drain）<code>node-2</code>。
drain 命令将尝试按照某种顺序驱逐两个 Pod，假设先是 <code>pod-b</code>，然后是 <code>pod-d</code>。
命令成功驱逐 <code>pod-b</code>，但是当它尝试驱逐 <code>pod-d</code>时将被拒绝，因为对于
Deployment 来说只剩一个可用的 Pod 了。</p><p>Deployment 创建 <code>pod-b</code> 的替代 Pod <code>pod-e</code>。
因为集群中没有足够的资源来调度 <code>pod-e</code>，drain 命令再次阻塞。集群最终将是下面这种状态：</p><table><thead><tr><th style=text-align:center>node-1 <em>drained</em></th><th style=text-align:center>node-2</th><th style=text-align:center>node-3</th><th style=text-align:center><em>no node</em></th></tr></thead><tbody><tr><td style=text-align:center></td><td style=text-align:center>pod-b <em>terminating</em></td><td style=text-align:center>pod-c <em>available</em></td><td style=text-align:center>pod-e <em>pending</em></td></tr><tr><td style=text-align:center></td><td style=text-align:center>pod-d <em>available</em></td><td style=text-align:center>pod-y</td><td style=text-align:center></td></tr></tbody></table><p>此时，集群管理员需要增加一个节点到集群中以继续升级操作。</p><p>可以看到 Kubernetes 如何改变干扰发生的速率，根据：</p><ul><li>应用需要多少个副本</li><li>优雅关闭应用实例需要多长时间</li><li>启动应用新实例需要多长时间</li><li>控制器的类型</li><li>集群的资源能力</li></ul><h2 id=pod-disruption-conditions>Pod 干扰状况</h2><div style=margin-top:10px;margin-bottom:10px><b>特性状态：</b> <code>Kubernetes v1.25 [alpha]</code></div><div class="alert alert-info note callout" role=alert><strong>说明：</strong><p>要使用此行为，你必须在集群中启用 <code>PodDisruptionCondition</code>
<a href=/zh-cn/docs/reference/command-line-tools-reference/feature-gates/>特性门控</a>。</div><p>启用后，会给 Pod 添加一个 <code>DisruptionTarget</code>
<a href=/zh-cn/docs/concepts/workloads/pods/pod-lifecycle/#pod-conditions>状况</a>，
用来表明该 Pod 因为发生<a class=glossary-tooltip title='导致 Pod 服务停止的事件。' data-toggle=tooltip data-placement=top href=/zh-cn/docs/concepts/workloads/pods/disruptions/ target=_blank aria-label=干扰>干扰</a>而被删除。
状况中的 <code>reason</code> 字段进一步给出 Pod 终止的原因，如下：</p><dl><dt><code>PreemptionByKubeScheduler</code></dt><dd>Pod 将被调度器<a class=glossary-tooltip title='Kubernetes 中的抢占逻辑通过驱逐节点上的低优先级 Pod 来帮助悬决的 Pod 找到合适的节点。' data-toggle=tooltip data-placement=top href=/zh-cn/docs/concepts/scheduling-eviction/pod-priority-preemption/#preemption target=_blank aria-label=抢占>抢占</a>，
目的是接受优先级更高的新 Pod。
要了解更多的相关信息，请参阅 <a href=/zh-cn/docs/concepts/scheduling-eviction/pod-priority-preemption/>Pod 优先级和抢占</a>。</dd></dl><dl><dt><code>DeletionByTaintManager</code></dt><dd>由于 Pod 不能容忍 <code>NoExecute</code> 污点，Pod 将被
Taint Manager（<code>kube-controller-manager</code> 中节点生命周期控制器的一部分）删除；
请参阅基于<a class=glossary-tooltip title='污点是一种一个核心对象，包含三个必需的属性：key、value 和 effect。 污点会阻止在节点或节点组上调度 Pod。' data-toggle=tooltip data-placement=top href=/zh-cn/docs/concepts/scheduling-eviction/taint-and-toleration/ target=_blank aria-label=污点>污点</a>的驱逐。</dd></dl><dl><dt><code>EvictionByEvictionAPI</code></dt><dd>Pod 已被标记为<a class=glossary-tooltip title='API 发起的驱逐是一个先调用 Eviction API 创建驱逐对象，再由该对象体面地中止 Pod 的过程。' data-toggle=tooltip data-placement=top href=/zh-cn/docs/concepts/scheduling-eviction/api-eviction/ target=_blank aria-label='通过 Kubernetes API 驱逐'>通过 Kubernetes API 驱逐</a>。</dd></dl><dl><dt><code>DeletionByPodGC</code></dt><dd>绑定到一个不再存在的 Node 上的 Pod 将被
<a href=/zh-cn/docs/concepts/workloads/pods/pod-lifecycle/#pod-garbage-collection>Pod 垃圾收集</a>删除。</dd></dl><div class="alert alert-info note callout" role=alert><strong>说明：</strong><p>Pod 的干扰可能会被中断。控制平面可能会重新尝试继续干扰同一个 Pod，但这没办法保证。
因此，<code>DisruptionTarget</code> 条件可能会添被加到 Pod 上，
但该 Pod 实际上可能不会被删除。
在这种情况下，一段时间后，Pod 干扰状况将被清除。</div><p>使用 Job（或 CronJob）时，你可能希望将这些 Pod 干扰状况作为 Job
<a href=/zh-cn/docs/concepts/workloads/controllers/job#pod-failure-policy>Pod 失效策略</a>的一部分。</p><h2 id=分离集群所有者和应用所有者角色>分离集群所有者和应用所有者角色</h2><p>通常，将集群管理者和应用所有者视为彼此了解有限的独立角色是很有用的。这种责任分离在下面这些场景下是有意义的：</p><ul><li>当有许多应用团队共用一个 Kubernetes 集群，并且有自然的专业角色</li><li>当第三方工具或服务用于集群自动化管理</li></ul><p>Pod 干扰预算通过在角色之间提供接口来支持这种分离。</p><p>如果你的组织中没有这样的责任分离，则可能不需要使用 Pod 干扰预算。</p><h2 id=如何在集群上执行干扰性操作>如何在集群上执行干扰性操作</h2><p>如果你是集群管理员，并且需要对集群中的所有节点执行干扰操作，例如节点或系统软件升级，则可以使用以下选项</p><ul><li>接受升级期间的停机时间。</li><li>故障转移到另一个完整的副本集群。<ul><li>没有停机时间，但是对于重复的节点和人工协调成本可能是昂贵的。</li></ul></li><li>编写可容忍干扰的应用和使用 PDB。<ul><li>不停机。</li><li>最小的资源重复。</li><li>允许更多的集群管理自动化。</li><li>编写可容忍干扰的应用是棘手的，但对于支持容忍自愿干扰所做的工作，和支持自动扩缩和容忍非
自愿干扰所做工作相比，有大量的重叠</li></ul></li></ul><h2 id=接下来>接下来</h2><ul><li><p>参考<a href=/zh-cn/docs/tasks/run-application/configure-pdb/>配置 Pod 干扰预算</a>中的方法来保护你的应用。</p></li><li><p>进一步了解<a href=/zh-cn/docs/tasks/administer-cluster/safely-drain-node/>排空节点</a>的信息。</p></li><li><p>了解<a href=/zh-cn/docs/concepts/workloads/controllers/deployment/#updating-a-deployment>更新 Deployment</a>
的过程，包括如何在其进程中维持应用的可用性</p></li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-53a1005011e1bda2ce81819aad7c8b32>1.4 - 临时容器</h1><div style=margin-top:10px;margin-bottom:10px><b>特性状态：</b> <code>Kubernetes v1.25 [stable]</code></div><p>本页面概述了临时容器：一种特殊的容器，该容器在现有
<a class=glossary-tooltip title='Pod 表示你的集群上一组正在运行的容器。' data-toggle=tooltip data-placement=top href=/zh-cn/docs/concepts/workloads/pods/ target=_blank aria-label=Pod>Pod</a>
中临时运行，以便完成用户发起的操作，例如故障排查。
你会使用临时容器来检查服务，而不是用它来构建应用程序。</p><h2 id=understanding-ephemeral-containers>了解临时容器</h2><p><a class=glossary-tooltip title='Pod 表示你的集群上一组正在运行的容器。' data-toggle=tooltip data-placement=top href=/zh-cn/docs/concepts/workloads/pods/ target=_blank aria-label=Pod>Pod</a> 是 Kubernetes 应用程序的基本构建块。
由于 Pod 是一次性且可替换的，因此一旦 Pod 创建，就无法将容器加入到 Pod 中。
取而代之的是，通常使用 <a class=glossary-tooltip title=管理集群上的多副本应用。 data-toggle=tooltip data-placement=top href=/zh-cn/docs/concepts/workloads/controllers/deployment/ target=_blank aria-label=Deployment>Deployment</a>
以受控的方式来删除并替换 Pod。</p><p>有时有必要检查现有 Pod 的状态。例如，对于难以复现的故障进行排查。
在这些场景中，可以在现有 Pod 中运行临时容器来检查其状态并运行任意命令。</p><h3 id=what-is-an-ephemeral-container>什么是临时容器？</h3><p>临时容器与其他容器的不同之处在于，它们缺少对资源或执行的保证，并且永远不会自动重启，
因此不适用于构建应用程序。
临时容器使用与常规容器相同的 <code>ContainerSpec</code> 节来描述，但许多字段是不兼容和不允许的。</p><ul><li>临时容器没有端口配置，因此像 <code>ports</code>，<code>livenessProbe</code>，<code>readinessProbe</code>
这样的字段是不允许的。</li><li>Pod 资源分配是不可变的，因此 <code>resources</code> 配置是不允许的。</li><li>有关允许字段的完整列表，请参见
<a href=/docs/reference/generated/kubernetes-api/v1.25/#ephemeralcontainer-v1-core>EphemeralContainer 参考文档</a>。</li></ul><p>临时容器是使用 API 中的一种特殊的 <code>ephemeralcontainers</code> 处理器进行创建的，
而不是直接添加到 <code>pod.spec</code> 段，因此无法使用 <code>kubectl edit</code> 来添加一个临时容器。</p><p>与常规容器一样，将临时容器添加到 Pod 后，将不能更改或删除临时容器。</p><h2 id=uses-for-ephemeral-containers>临时容器的用途</h2><p>当由于容器崩溃或容器镜像不包含调试工具而导致 <code>kubectl exec</code> 无用时，
临时容器对于交互式故障排查很有用。</p><p>尤其是，<a href=https://github.com/GoogleContainerTools/distroless>Distroless 镜像</a>
允许用户部署最小的容器镜像，从而减少攻击面并减少故障和漏洞的暴露。
由于 distroless 镜像不包含 Shell 或任何的调试工具，因此很难单独使用
<code>kubectl exec</code> 命令进行故障排查。</p><p>使用临时容器时，启用
<a href=/zh-cn/docs/tasks/configure-pod-container/share-process-namespace/>进程名字空间共享</a>
很有帮助，可以查看其他容器中的进程。</p><p>接下来</p><ul><li>了解如何<a href=/zh-cn/docs/tasks/debug/debug-application/debug-running-pod/#ephemeral-container>使用临时调试容器来进行调试</a></li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-420713565efe2f940e277f6b4824ad9a>1.5 - Downward API</h1><div class=lead>有两种方法可以将 Pod 和容器字段暴露给运行中的容器：环境变量和由特殊卷类型承载的文件。 这两种暴露 Pod 和容器字段的方法统称为 Downward API。</div><p>对于容器来说，在不与 Kubernetes 过度耦合的情况下，拥有关于自身的信息有时是很有用的。
<strong>Downward API</strong> 允许容器在不使用 Kubernetes 客户端或 API 服务器的情况下获得自己或集群的信息。</p><p>例如，现有应用程序假设某特定的周知的环境变量是存在的，其中包含唯一标识符。
一种方法是对应用程序进行封装，但这很繁琐且容易出错，并且违背了低耦合的目标。
更好的选择是使用 Pod 名称作为标识符，并将 Pod 名称注入到周知的环境变量中。</p><p>在 Kubernetes 中，有两种方法可以将 Pod 和容器字段暴露给运行中的容器：</p><ul><li>作为<a href=/zh-cn/docs/tasks/inject-data-application/environment-variable-expose-pod-information/>环境变量</a></li><li>作为 <a href=/zh-cn/docs/tasks/inject-data-application/downward-api-volume-expose-pod-information/><code>downwardAPI</code> 卷中的文件</a></li></ul><p>这两种暴露 Pod 和容器字段的方式统称为 <strong>Downward API</strong>。</p><h2 id=available-fields>可用字段</h2><p>只有部分 Kubernetes API 字段可以通过 Downward API 使用。本节列出了你可以使用的字段。</p><p>你可以使用 <code>fieldRef</code> 传递来自可用的 Pod 级字段的信息。在 API 层面，一个 Pod 的
<code>spec</code> 总是定义了至少一个 <a href=/zh-cn/docs/reference/kubernetes-api/workload-resources/pod-v1/#Container>Container</a>。
你可以使用 <code>resourceFieldRef</code> 传递来自可用的 Container 级字段的信息。</p><h3 id=downwardapi-fieldRef>可通过 <code>fieldRef</code> 获得的信息</h3><p>对于大多数 Pod 级别的字段，你可以将它们作为环境变量或使用 <code>downwardAPI</code> 卷提供给容器。
通过这两种机制可用的字段有：</p><dl><dt><code>metadata.name</code></dt><dd>Pod 的名称</dd></dl><dl><dt><code>metadata.namespace</code></dt><dd>Pod 的<a class=glossary-tooltip title='名字空间是 Kubernetes 用来支持隔离单个集群中的资源组的一种抽象。' data-toggle=tooltip data-placement=top href=/zh-cn/docs/concepts/overview/working-with-objects/namespaces/ target=_blank aria-label=命名空间>命名空间</a></dd></dl><dl><dt><code>metadata.uid</code></dt><dd>Pod 的唯一 ID</dd></dl><dl><dt><code>metadata.annotations['&lt;KEY>']</code></dt><dd>Pod 的<a class=glossary-tooltip title=注解是以键值对的形式给资源对象附加随机的无法标识的元数据。 data-toggle=tooltip data-placement=top href=/zh-cn/docs/concepts/overview/working-with-objects/annotations/ target=_blank aria-label=注解>注解</a> <code>&lt;KEY></code> 的值（例如：<code>metadata.annotations['myannotation']</code>）</dd></dl><dl><dt><code>metadata.labels['&lt;KEY>']</code></dt><dd>Pod 的<a class=glossary-tooltip title=用来为对象设置可标识的属性标记；这些标记对用户而言是有意义且重要的。 data-toggle=tooltip data-placement=top href=/zh-cn/docs/concepts/overview/working-with-objects/labels/ target=_blank aria-label=标签>标签</a> <code>&lt;KEY></code> 的值（例如：<code>metadata.labels['mylabel']</code>）</dd></dl><dl><dt><code>spec.serviceAccountName</code></dt><dd>Pod 的<a class=glossary-tooltip title='为在 Pod 中运行的进程提供标识。' data-toggle=tooltip data-placement=top href=/zh-cn/docs/tasks/configure-pod-container/configure-service-account/ target=_blank aria-label=服务账号>服务账号</a>名称</dd></dl><dl><dt><code>spec.nodeName</code></dt><dd>Pod 运行时所处的<a class=glossary-tooltip title='Kubernetes 中的工作机器称作节点。' data-toggle=tooltip data-placement=top href=/zh-cn/docs/concepts/architecture/nodes/ target=_blank aria-label=节点>节点</a>名称</dd></dl><dl><dt><code>status.hostIP</code></dt><dd>Pod 所在节点的主 IP 地址</dd></dl><dl><dt><code>status.podIP</code></dt><dd>Pod 的主 IP 地址（通常是其 IPv4 地址）</dd></dl><p>此外，以下信息可以通过 <code>downwardAPI</code> 卷 <code>fieldRef</code> 获得，但<strong>不能作为环境变量</strong>获得：</p><dl><dt><code>metadata.labels</code></dt><dd>Pod 的所有标签，格式为 <code>标签键名="转义后的标签值"</code>，每行一个标签</dd></dl><dl><dt><code>metadata.annotations</code></dt><dd>Pod 的全部注解，格式为 <code>注解键名="转义后的注解值"</code>，每行一个注解</dd></dl><h3 id=downwardapi-resourceFieldRef>可通过 <code>resourceFieldRef</code> 获得的信息</h3><dl><dt><code>resource: limits.cpu</code></dt><dd>容器的 CPU 限制值</dd></dl><dl><dt><code>resource: requests.cpu</code></dt><dd>容器的 CPU 请求值</dd></dl><dl><dt><code>resource: limits.memory</code></dt><dd>容器的内存限制值</dd></dl><dl><dt><code>resource: requests.memory</code></dt><dd>容器的内存请求值</dd></dl><dl><dt><code>resource: limits.hugepages-*</code></dt><dd>容器的巨页限制值（前提是启用了 <code>DownwardAPIHugePages</code>
<a href=/zh-cn/docs/reference/command-line-tools-reference/feature-gates/>特性门控</a>）</dd></dl><dl><dt><code>resource: requests.hugepages-*</code></dt><dd>容器的巨页请求值（前提是启用了 <code>DownwardAPIHugePages</code>
<a href=/zh-cn/docs/reference/command-line-tools-reference/feature-gates/>特性门控</a>）</dd></dl><dl><dt><code>resource: limits.ephemeral-storage</code></dt><dd>容器的临时存储的限制值</dd></dl><dl><dt><code>resource: requests.ephemeral-storage</code></dt><dd>容器的临时存储的请求值</dd></dl><h4 id=fallback-information-for-resource-limits>资源限制的后备信息</h4><p>如果没有为容器指定 CPU 和内存限制时尝试使用 Downward API 暴露该信息，那么 kubelet 默认会根据
<a href=/zh-cn/docs/tasks/administer-cluster/reserve-compute-resources/#node-allocatable>节点可分配资源</a>
计算并暴露 CPU 和内存的最大可分配值。</p><h2 id=接下来>接下来</h2><p>你可以阅读有关 <a href=/zh-cn/docs/concepts/storage/volumes/#downwardapi><code>downwardAPI</code> 卷</a>的内容。</p><p>你可以尝试使用 Downward API 暴露容器或 Pod 级别的信息：</p><ul><li>作为<a href=/zh-cn/docs/tasks/inject-data-application/environment-variable-expose-pod-information/>环境变量</a></li><li>作为 <a href=/zh-cn/docs/tasks/inject-data-application/downward-api-volume-expose-pod-information/><code>downwardAPI</code> 卷中的文件</a></li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-89637410cacae45a36ab1cc278c482eb>2 - 工作负载资源</h1></div><div class=td-content><h1 id=pg-a2dc0393e0c4079e1c504b6429844e86>2.1 - Deployments</h1><p>一个 Deployment 为 <a class=glossary-tooltip title='Pod 表示你的集群上一组正在运行的容器。' data-toggle=tooltip data-placement=top href=/zh-cn/docs/concepts/workloads/pods/ target=_blank aria-label=Pod>Pod</a>
和 <a class=glossary-tooltip title='ReplicaSet 是下一代副本控制器。' data-toggle=tooltip data-placement=top href=/zh-cn/docs/concepts/workloads/controllers/replicaset/ target=_blank aria-label=ReplicaSet>ReplicaSet</a>
提供声明式的更新能力。</p><p>你负责描述 Deployment 中的 <strong>目标状态</strong>，而 Deployment <a class=glossary-tooltip title='控制器通过 API 服务器监控集群的公共状态，并致力于将当前状态转变为期望的状态。' data-toggle=tooltip data-placement=top href=/zh-cn/docs/concepts/architecture/controller/ target=_blank aria-label=控制器（Controller）>控制器（Controller）</a>
以受控速率更改实际状态，
使其变为期望状态。你可以定义 Deployment 以创建新的 ReplicaSet，或删除现有 Deployment，
并通过新的 Deployment 收养其资源。</p><div class="alert alert-info note callout" role=alert><strong>说明：</strong><p>不要管理 Deployment 所拥有的 ReplicaSet 。
如果存在下面未覆盖的使用场景，请考虑在 Kubernetes 仓库中提出 Issue。</div><h2 id=用例>用例</h2><p>以下是 Deployments 的典型用例：</p><ul><li><a href=#creating-a-deployment>创建 Deployment 以将 ReplicaSet 上线</a>。ReplicaSet 在后台创建 Pod。
检查 ReplicaSet 的上线状态，查看其是否成功。</li><li>通过更新 Deployment 的 PodTemplateSpec，<a href=#updating-a-deployment>声明 Pod 的新状态</a> 。
新的 ReplicaSet 会被创建，Deployment 以受控速率将 Pod 从旧 ReplicaSet 迁移到新 ReplicaSet。
每个新的 ReplicaSet 都会更新 Deployment 的修订版本。</li></ul><ul><li>如果 Deployment 的当前状态不稳定，<a href=#rolling-back-a-deployment>回滚到较早的 Deployment 版本</a>。
每次回滚都会更新 Deployment 的修订版本。</li><li><a href=#scaling-a-deployment>扩大 Deployment 规模以承担更多负载</a>。</li><li><a href=#pausing-and-resuming-a-deployment>暂停 Deployment 的上线</a> 以应用对 PodTemplateSpec 所作的多项修改，
然后恢复其执行以启动新的上线版本。</li><li><a href=#deployment-status>使用 Deployment 状态</a>来判定上线过程是否出现停滞。</li><li><a href=#clean-up-policy>清理较旧的不再需要的 ReplicaSet</a> 。</li></ul><h2 id=creating-a-deployment>创建 Deployment</h2><p>下面是一个 Deployment 示例。其中创建了一个 ReplicaSet，负责启动三个 <code>nginx</code> Pod：</p><div class=highlight><div class=copy-code-icon style=text-align:right><a href=https://raw.githubusercontent.com/kubernetes/website/main/content/zh-cn/examples/controllers/nginx-deployment.yaml download=controllers/nginx-deployment.yaml><code>controllers/nginx-deployment.yaml</code></a>
<img src=/images/copycode.svg style=max-height:24px;cursor:pointer onclick='copyCode("controllers-nginx-deployment-yaml")' title="Copy controllers/nginx-deployment.yaml to clipboard"></img></div><div class=includecode id=controllers-nginx-deployment-yaml><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>apps/v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Deployment<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>nginx-deployment<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>labels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>app</span>:<span style=color:#bbb> </span>nginx<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>replicas</span>:<span style=color:#bbb> </span><span style=color:#666>3</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>selector</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>matchLabels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>app</span>:<span style=color:#bbb> </span>nginx<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>template</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>labels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>app</span>:<span style=color:#bbb> </span>nginx<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>nginx<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>nginx:1.14.2<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>ports</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span>- <span style=color:green;font-weight:700>containerPort</span>:<span style=color:#bbb> </span><span style=color:#666>80</span><span style=color:#bbb>
</span></span></span></code></pre></div></div></div><p>在该例中：</p><ul><li>创建名为 <code>nginx-deployment</code>（由 <code>.metadata.name</code> 字段标明）的 Deployment。</li><li>该 Deployment 创建三个（由 <code>.spec.replicas</code> 字段标明）Pod 副本。</li></ul><ul><li><p><code>selector</code> 字段定义 Deployment 如何查找要管理的 Pod。
在这里，你选择在 Pod 模板中定义的标签（<code>app: nginx</code>）。
不过，更复杂的选择规则是也可能的，只要 Pod 模板本身满足所给规则即可。</p><div class="alert alert-info note callout" role=alert><strong>说明：</strong><p><code>spec.selector.matchLabels</code> 字段是 <code>{key,value}</code> 键值对映射。
在 <code>matchLabels</code> 映射中的每个 <code>{key,value}</code> 映射等效于 <code>matchExpressions</code> 中的一个元素，
即其 <code>key</code> 字段是 “key”，<code>operator</code> 为 “In”，<code>values</code> 数组仅包含 “value”。
在 <code>matchLabels</code> 和 <code>matchExpressions</code> 中给出的所有条件都必须满足才能匹配。</div></li></ul><ul><li><code>template</code> 字段包含以下子字段：<ul><li>Pod 被使用 <code>.metadata.labels</code> 字段打上 <code>app: nginx</code> 标签。</li><li>Pod 模板规约（即 <code>.template.spec</code> 字段）指示 Pod 运行一个 <code>nginx</code> 容器，
该容器运行版本为 1.14.2 的 <code>nginx</code> <a href=https://hub.docker.com/>Docker Hub</a> 镜像。</li><li>创建一个容器并使用 <code>.spec.template.spec.containers[0].name</code> 字段将其命名为 <code>nginx</code>。</li></ul></li></ul><p>开始之前，请确保的 Kubernetes 集群已启动并运行。
按照以下步骤创建上述 Deployment ：</p><ol><li><p>通过运行以下命令创建 Deployment ：</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl apply -f https://k8s.io/examples/controllers/nginx-deployment.yaml
</span></span></code></pre></div></li></ol><ol start=2><li><p>运行 <code>kubectl get deployments</code> 检查 Deployment 是否已创建。
如果仍在创建 Deployment，则输出类似于：</p><pre tabindex=0><code>NAME               READY   UP-TO-DATE   AVAILABLE   AGE
nginx-deployment   0/3     0            0           1s
</code></pre><p>在检查集群中的 Deployment 时，所显示的字段有：</p><ul><li><code>NAME</code> 列出了名字空间中 Deployment 的名称。</li><li><code>READY</code> 显示应用程序的可用的“副本”数。显示的模式是“就绪个数/期望个数”。</li><li><code>UP-TO-DATE</code> 显示为了达到期望状态已经更新的副本数。</li><li><code>AVAILABLE</code> 显示应用可供用户使用的副本数。</li><li><code>AGE</code> 显示应用程序运行的时间。</li></ul><p>请注意期望副本数是根据 <code>.spec.replicas</code> 字段设置 3。</p></li></ol><ol start=3><li><p>要查看 Deployment 上线状态，运行 <code>kubectl rollout status deployment/nginx-deployment</code>。</p><p>输出类似于：</p><pre tabindex=0><code>Waiting for rollout to finish: 2 out of 3 new replicas have been updated...
deployment &#34;nginx-deployment&#34; successfully rolled out
</code></pre></li></ol><ol start=4><li><p>几秒钟后再次运行 <code>kubectl get deployments</code>。输出类似于：</p><pre tabindex=0><code>NAME               READY   UP-TO-DATE   AVAILABLE   AGE
nginx-deployment   3/3     3            3           18s
</code></pre><p>注意 Deployment 已创建全部三个副本，并且所有副本都是最新的（它们包含最新的 Pod 模板）
并且可用。</p></li></ol><ol start=5><li><p>要查看 Deployment 创建的 ReplicaSet（<code>rs</code>），运行 <code>kubectl get rs</code>。
输出类似于：</p><pre tabindex=0><code>NAME                          DESIRED   CURRENT   READY   AGE
nginx-deployment-75675f5897   3         3         3       18s
</code></pre><p>ReplicaSet 输出中包含以下字段：</p><ul><li><code>NAME</code> 列出名字空间中 ReplicaSet 的名称；</li><li><code>DESIRED</code> 显示应用的期望副本个数，即在创建 Deployment 时所定义的值。
此为期望状态；</li><li><code>CURRENT</code> 显示当前运行状态中的副本个数；</li><li><code>READY</code> 显示应用中有多少副本可以为用户提供服务；</li><li><code>AGE</code> 显示应用已经运行的时间长度。</li></ul><p>注意 ReplicaSet 的名称始终被格式化为<code>[Deployment名称]-[哈希]</code>。
其中的<code>哈希</code>字符串与 ReplicaSet 上的 <code>pod-template-hash</code> 标签一致。</p></li></ol><ol start=6><li><p>要查看每个 Pod 自动生成的标签，运行 <code>kubectl get pods --show-labels</code>。
输出类似于：</p><pre tabindex=0><code>NAME                                READY     STATUS    RESTARTS   AGE       LABELS
nginx-deployment-75675f5897-7ci7o   1/1       Running   0          18s       app=nginx,pod-template-hash=3123191453
nginx-deployment-75675f5897-kzszj   1/1       Running   0          18s       app=nginx,pod-template-hash=3123191453
nginx-deployment-75675f5897-qqcnn   1/1       Running   0          18s       app=nginx,pod-template-hash=3123191453
</code></pre><p>所创建的 ReplicaSet 确保总是存在三个 <code>nginx</code> Pod。</p></li></ol><div class="alert alert-info note callout" role=alert><strong>说明：</strong><p>你必须在 Deployment 中指定适当的选择算符和 Pod 模板标签（在本例中为 <code>app: nginx</code>）。
标签或者选择算符不要与其他控制器（包括其他 Deployment 和 StatefulSet）重叠。
Kubernetes 不会阻止你这样做，但是如果多个控制器具有重叠的选择算符，
它们可能会发生冲突执行难以预料的操作。</div><h3 id=pod-template-hash-标签>Pod-template-hash 标签</h3><div class="alert alert-warning caution callout" role=alert><strong>注意：</strong><p>不要更改此标签。</div><p>Deployment 控制器将 <code>pod-template-hash</code> 标签添加到 Deployment
所创建或收留的每个 ReplicaSet 。</p><p>此标签可确保 Deployment 的子 ReplicaSets 不重叠。
标签是通过对 ReplicaSet 的 <code>PodTemplate</code> 进行哈希处理。
所生成的哈希值被添加到 ReplicaSet 选择算符、Pod 模板标签，并存在于在 ReplicaSet
可能拥有的任何现有 Pod 中。</p><h2 id=updating-a-deployment>更新 Deployment</h2><div class="alert alert-info note callout" role=alert><strong>说明：</strong><p>仅当 Deployment Pod 模板（即 <code>.spec.template</code>）发生改变时，例如模板的标签或容器镜像被更新，
才会触发 Deployment 上线。其他更新（如对 Deployment 执行扩缩容的操作）不会触发上线动作。</div><p>按照以下步骤更新 Deployment：</p><ol><li><p>先来更新 nginx Pod 以使用 <code>nginx:1.16.1</code> 镜像，而不是 <code>nginx:1.14.2</code> 镜像。</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl <span style=color:#a2f>set</span> image deployment.v1.apps/nginx-deployment <span style=color:#b8860b>nginx</span><span style=color:#666>=</span>nginx:1.16.1
</span></span></code></pre></div><p>或者使用下面的命令：</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl <span style=color:#a2f>set</span> image deployment/nginx-deployment <span style=color:#b8860b>nginx</span><span style=color:#666>=</span>nginx:1.16.1
</span></span></code></pre></div><p>输出类似于：</p><pre tabindex=0><code>deployment.apps/nginx-deployment image updated
</code></pre><p>或者，可以对 Deployment 执行 <code>edit</code> 操作并将 <code>.spec.template.spec.containers[0].image</code> 从
<code>nginx:1.14.2</code> 更改至 <code>nginx:1.16.1</code>。</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl edit deployment/nginx-deployment
</span></span></code></pre></div><p>输出类似于：</p><pre tabindex=0><code>deployment.apps/nginx-deployment edited
</code></pre></li></ol><ol start=2><li><p>要查看上线状态，运行：</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl rollout status deployment/nginx-deployment
</span></span></code></pre></div><p>输出类似于：</p><pre tabindex=0><code>Waiting for rollout to finish: 2 out of 3 new replicas have been updated...
</code></pre><p>或者</p><pre tabindex=0><code>deployment &#34;nginx-deployment&#34; successfully rolled out
</code></pre></li></ol><p>获取关于已更新的 Deployment 的更多信息：</p><ul><li><p>在上线成功后，可以通过运行 <code>kubectl get deployments</code> 来查看 Deployment：
输出类似于：</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-ini data-lang=ini><span style=display:flex><span><span style=color:#b44>NAME               READY   UP-TO-DATE   AVAILABLE   AGE</span>
</span></span><span style=display:flex><span><span style=color:#b44>nginx-deployment   3/3     3            3           36s</span>
</span></span></code></pre></div></li></ul><ul><li><p>运行 <code>kubectl get rs</code> 以查看 Deployment 通过创建新的 ReplicaSet 并将其扩容到
3 个副本并将旧 ReplicaSet 缩容到 0 个副本完成了 Pod 的更新操作：</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get rs
</span></span></code></pre></div><p>输出类似于：</p><pre tabindex=0><code>NAME                          DESIRED   CURRENT   READY   AGE
nginx-deployment-1564180365   3         3         3       6s
nginx-deployment-2035384211   0         0         0       36s
</code></pre></li></ul><ul><li><p>现在运行 <code>get pods</code> 应仅显示新的 Pod：</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get pods
</span></span></code></pre></div><p>输出类似于：</p><pre tabindex=0><code>NAME                                READY     STATUS    RESTARTS   AGE
nginx-deployment-1564180365-khku8   1/1       Running   0          14s
nginx-deployment-1564180365-nacti   1/1       Running   0          14s
nginx-deployment-1564180365-z9gth   1/1       Running   0          14s
</code></pre><p>下次要更新这些 Pod 时，只需再次更新 Deployment Pod 模板即可。</p><p>Deployment 可确保在更新时仅关闭一定数量的 Pod。默认情况下，它确保至少所需 Pod 的 75% 处于运行状态（最大不可用比例为 25%）。</p><p>Deployment 还确保仅所创建 Pod 数量只可能比期望 Pod 数高一点点。
默认情况下，它可确保启动的 Pod 个数比期望个数最多多出 125%（最大峰值 25%）。</p><p>例如，如果仔细查看上述 Deployment ，将看到它首先创建了一个新的 Pod，然后删除旧的 Pod，
并创建了新的 Pod。它不会杀死旧 Pod，直到有足够数量的新 Pod 已经出现。
在足够数量的旧 Pod 被杀死前并没有创建新 Pod。它确保至少 3 个 Pod 可用，
同时最多总共 4 个 Pod 可用。
当 Deployment 设置为 4 个副本时，Pod 的个数会介于 3 和 5 之间。</p></li></ul><ul><li><p>获取 Deployment 的更多信息</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl describe deployments
</span></span></code></pre></div><p>输出类似于：</p><pre tabindex=0><code>Name:                   nginx-deployment
Namespace:              default
CreationTimestamp:      Thu, 30 Nov 2017 10:56:25 +0000
Labels:                 app=nginx
Annotations:            deployment.kubernetes.io/revision=2
Selector:               app=nginx
Replicas:               3 desired | 3 updated | 3 total | 3 available | 0 unavailable
StrategyType:           RollingUpdate
MinReadySeconds:        0
RollingUpdateStrategy:  25% max unavailable, 25% max surge
Pod Template:
  Labels:  app=nginx
   Containers:
    nginx:
      Image:        nginx:1.16.1
      Port:         80/TCP
      Environment:  &lt;none&gt;
      Mounts:       &lt;none&gt;
    Volumes:        &lt;none&gt;
  Conditions:
    Type           Status  Reason
    ----           ------  ------
    Available      True    MinimumReplicasAvailable
    Progressing    True    NewReplicaSetAvailable
  OldReplicaSets:  &lt;none&gt;
  NewReplicaSet:   nginx-deployment-1564180365 (3/3 replicas created)
  Events:
    Type    Reason             Age   From                   Message
    ----    ------             ----  ----                   -------
    Normal  ScalingReplicaSet  2m    deployment-controller  Scaled up replica set nginx-deployment-2035384211 to 3
    Normal  ScalingReplicaSet  24s   deployment-controller  Scaled up replica set nginx-deployment-1564180365 to 1
    Normal  ScalingReplicaSet  22s   deployment-controller  Scaled down replica set nginx-deployment-2035384211 to 2
    Normal  ScalingReplicaSet  22s   deployment-controller  Scaled up replica set nginx-deployment-1564180365 to 2
    Normal  ScalingReplicaSet  19s   deployment-controller  Scaled down replica set nginx-deployment-2035384211 to 1
    Normal  ScalingReplicaSet  19s   deployment-controller  Scaled up replica set nginx-deployment-1564180365 to 3
    Normal  ScalingReplicaSet  14s   deployment-controller  Scaled down replica set nginx-deployment-2035384211 to 0
</code></pre><p>可以看到，当第一次创建 Deployment 时，它创建了一个 ReplicaSet（<code>nginx-deployment-2035384211</code>）
并将其直接扩容至 3 个副本。更新 Deployment 时，它创建了一个新的 ReplicaSet
（nginx-deployment-1564180365），并将其扩容为 1，等待其就绪；然后将旧 ReplicaSet 缩容到 2，
将新的 ReplicaSet 扩容到 2 以便至少有 3 个 Pod 可用且最多创建 4 个 Pod。
然后，它使用相同的滚动更新策略继续对新的 ReplicaSet 扩容并对旧的 ReplicaSet 缩容。
最后，你将有 3 个可用的副本在新的 ReplicaSet 中，旧 ReplicaSet 将缩容到 0。</p></li></ul><div class="alert alert-info note callout" role=alert><strong>说明：</strong><p>Kubernetes 在计算 <code>availableReplicas</code> 数值时不考虑终止过程中的 Pod，
<code>availableReplicas</code> 的值一定介于 <code>replicas - maxUnavailable</code> 和 <code>replicas + maxSurge</code> 之间。
因此，你可能在上线期间看到 Pod 个数比预期的多，Deployment 所消耗的总的资源也大于
<code>replicas + maxSurge</code> 个 Pod 所用的资源，直到被终止的 Pod 所设置的
<code>terminationGracePeriodSeconds</code> 到期为止。</div><h3 id=翻转-多-deployment-动态更新>翻转（多 Deployment 动态更新）</h3><p>Deployment 控制器每次注意到新的 Deployment 时，都会创建一个 ReplicaSet 以启动所需的 Pod。
如果更新了 Deployment，则控制标签匹配 <code>.spec.selector</code> 但模板不匹配 <code>.spec.template</code> 的 Pod 的现有 ReplicaSet 被缩容。
最终，新的 ReplicaSet 缩放为 <code>.spec.replicas</code> 个副本，
所有旧 ReplicaSets 缩放为 0 个副本。</p><p>当 Deployment 正在上线时被更新，Deployment 会针对更新创建一个新的 ReplicaSet
并开始对其扩容，之前正在被扩容的 ReplicaSet 会被翻转，添加到旧 ReplicaSets 列表
并开始缩容。</p><p>例如，假定你在创建一个 Deployment 以生成 <code>nginx:1.14.2</code> 的 5 个副本，但接下来
更新 Deployment 以创建 5 个 <code>nginx:1.16.1</code> 的副本，而此时只有 3 个 <code>nginx:1.14.2</code>
副本已创建。在这种情况下，Deployment 会立即开始杀死 3 个 <code>nginx:1.14.2</code> Pod，
并开始创建 <code>nginx:1.16.1</code> Pod。它不会等待 <code>nginx:1.14.2</code> 的 5
个副本都创建完成后才开始执行变更动作。</p><h3 id=label-selector-updates>更改标签选择算符</h3><p>通常不鼓励更新标签选择算符。建议你提前规划选择算符。
在任何情况下，如果需要更新标签选择算符，请格外小心，
并确保自己了解这背后可能发生的所有事情。</p><div class="alert alert-info note callout" role=alert><strong>说明：</strong><p>在 API 版本 <code>apps/v1</code> 中，Deployment 标签选择算符在创建后是不可变的。</div><ul><li>添加选择算符时要求使用新标签更新 Deployment 规约中的 Pod 模板标签，否则将返回验证错误。
此更改是非重叠的，也就是说新的选择算符不会选择使用旧选择算符所创建的 ReplicaSet 和 Pod，
这会导致创建新的 ReplicaSet 时所有旧 ReplicaSet 都会被孤立。</li><li>选择算符的更新如果更改了某个算符的键名，这会导致与添加算符时相同的行为。</li><li>删除选择算符的操作会删除从 Deployment 选择算符中删除现有算符。
此操作不需要更改 Pod 模板标签。现有 ReplicaSet 不会被孤立，也不会因此创建新的 ReplicaSet，
但请注意已删除的标签仍然存在于现有的 Pod 和 ReplicaSet 中。</li></ul><h2 id=rolling-back-a-deployment>回滚 Deployment</h2><p>有时，你可能想要回滚 Deployment；例如，当 Deployment 不稳定时（例如进入反复崩溃状态）。
默认情况下，Deployment 的所有上线记录都保留在系统中，以便可以随时回滚
（你可以通过修改修订历史记录限制来更改这一约束）。</p><div class="alert alert-info note callout" role=alert><strong>说明：</strong><p>Deployment 被触发上线时，系统就会创建 Deployment 的新的修订版本。
这意味着仅当 Deployment 的 Pod 模板（<code>.spec.template</code>）发生更改时，才会创建新修订版本
-- 例如，模板的标签或容器镜像发生变化。
其他更新，如 Deployment 的扩缩容操作不会创建 Deployment 修订版本。
这是为了方便同时执行手动缩放或自动缩放。
换言之，当你回滚到较早的修订版本时，只有 Deployment 的 Pod 模板部分会被回滚。</div><ul><li><p>假设你在更新 Deployment 时犯了一个拼写错误，将镜像名称命名设置为
<code>nginx:1.161</code> 而不是 <code>nginx:1.16.1</code>：</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl <span style=color:#a2f>set</span> image deployment/nginx-deployment <span style=color:#b8860b>nginx</span><span style=color:#666>=</span>nginx:1.161 
</span></span></code></pre></div><p>输出类似于：</p><pre tabindex=0><code>deployment.apps/nginx-deployment image updated
</code></pre></li></ul><ul><li><p>此上线进程会出现停滞。你可以通过检查上线状态来验证：</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl rollout status deployment/nginx-deployment
</span></span></code></pre></div><p>输出类似于：</p><pre tabindex=0><code>Waiting for rollout to finish: 1 out of 3 new replicas have been updated...
</code></pre></li></ul><ul><li>按 Ctrl-C 停止上述上线状态观测。有关上线停滞的详细信息，<a href=#deployment-status>参考这里</a>。</li></ul><ul><li><p>你可以看到旧的副本有两个（<code>nginx-deployment-1564180365</code> 和 <code>nginx-deployment-2035384211</code>），
新的副本有 1 个（<code>nginx-deployment-3066724191</code>）：</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get rs
</span></span></code></pre></div><p>输出类似于：</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>NAME                          DESIRED   CURRENT   READY   AGE
</span></span><span style=display:flex><span>nginx-deployment-1564180365   <span style=color:#666>3</span>         <span style=color:#666>3</span>         <span style=color:#666>3</span>       25s
</span></span><span style=display:flex><span>nginx-deployment-2035384211   <span style=color:#666>0</span>         <span style=color:#666>0</span>         <span style=color:#666>0</span>       36s
</span></span><span style=display:flex><span>nginx-deployment-3066724191   <span style=color:#666>1</span>         <span style=color:#666>1</span>         <span style=color:#666>0</span>       6s
</span></span></code></pre></div></li></ul><ul><li><p>查看所创建的 Pod，你会注意到新 ReplicaSet 所创建的 1 个 Pod 卡顿在镜像拉取循环中。</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get pods
</span></span></code></pre></div><p>输出类似于：</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>NAME                                READY     STATUS             RESTARTS   AGE
</span></span><span style=display:flex><span>nginx-deployment-1564180365-70iae   1/1       Running            <span style=color:#666>0</span>          25s
</span></span><span style=display:flex><span>nginx-deployment-1564180365-jbqqo   1/1       Running            <span style=color:#666>0</span>          25s
</span></span><span style=display:flex><span>nginx-deployment-1564180365-hysrc   1/1       Running            <span style=color:#666>0</span>          25s
</span></span><span style=display:flex><span>nginx-deployment-3066724191-08mng   0/1       ImagePullBackOff   <span style=color:#666>0</span>          6s
</span></span></code></pre></div><div class="alert alert-info note callout" role=alert><strong>说明：</strong><p>Deployment 控制器自动停止有问题的上线过程，并停止对新的 ReplicaSet 扩容。
这行为取决于所指定的 rollingUpdate 参数（具体为 <code>maxUnavailable</code>）。
默认情况下，Kubernetes 将此值设置为 25%。</div></li></ul><ul><li><p>获取 Deployment 描述信息：</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl describe deployment
</span></span></code></pre></div><p>输出类似于：</p><pre tabindex=0><code>Name:           nginx-deployment
Namespace:      default
CreationTimestamp:  Tue, 15 Mar 2016 14:48:04 -0700
Labels:         app=nginx
Selector:       app=nginx
Replicas:       3 desired | 1 updated | 4 total | 3 available | 1 unavailable
StrategyType:       RollingUpdate
MinReadySeconds:    0
RollingUpdateStrategy:  25% max unavailable, 25% max surge
Pod Template:
  Labels:  app=nginx
  Containers:
   nginx:
    Image:        nginx:1.161
    Port:         80/TCP
    Host Port:    0/TCP
    Environment:  &lt;none&gt;
    Mounts:       &lt;none&gt;
  Volumes:        &lt;none&gt;
Conditions:
  Type           Status  Reason
  ----           ------  ------
  Available      True    MinimumReplicasAvailable
  Progressing    True    ReplicaSetUpdated
OldReplicaSets:     nginx-deployment-1564180365 (3/3 replicas created)
NewReplicaSet:      nginx-deployment-3066724191 (1/1 replicas created)
Events:
  FirstSeen LastSeen    Count   From                    SubobjectPath   Type        Reason              Message
  --------- --------    -----   ----                    -------------   --------    ------              -------
  1m        1m          1       {deployment-controller }                Normal      ScalingReplicaSet   Scaled up replica set nginx-deployment-2035384211 to 3
  22s       22s         1       {deployment-controller }                Normal      ScalingReplicaSet   Scaled up replica set nginx-deployment-1564180365 to 1
  22s       22s         1       {deployment-controller }                Normal      ScalingReplicaSet   Scaled down replica set nginx-deployment-2035384211 to 2
  22s       22s         1       {deployment-controller }                Normal      ScalingReplicaSet   Scaled up replica set nginx-deployment-1564180365 to 2
  21s       21s         1       {deployment-controller }                Normal      ScalingReplicaSet   Scaled down replica set nginx-deployment-2035384211 to 1
  21s       21s         1       {deployment-controller }                Normal      ScalingReplicaSet   Scaled up replica set nginx-deployment-1564180365 to 3
  13s       13s         1       {deployment-controller }                Normal      ScalingReplicaSet   Scaled down replica set nginx-deployment-2035384211 to 0
  13s       13s         1       {deployment-controller }                Normal      ScalingReplicaSet   Scaled up replica set nginx-deployment-3066724191 to 1
</code></pre><p>要解决此问题，需要回滚到以前稳定的 Deployment 版本。</p></li></ul><h3 id=检查-deployment-上线历史>检查 Deployment 上线历史</h3><p>按照如下步骤检查回滚历史：</p><ol><li><p>首先，检查 Deployment 修订历史：</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl rollout <span style=color:#a2f>history</span> deployment/nginx-deployment
</span></span></code></pre></div><p>输出类似于：</p><pre tabindex=0><code>deployments &#34;nginx-deployment&#34;
REVISION    CHANGE-CAUSE
1           kubectl apply --filename=https://k8s.io/examples/controllers/nginx-deployment.yaml
2           kubectl set image deployment/nginx-deployment nginx=nginx:1.16.1
3           kubectl set image deployment/nginx-deployment nginx=nginx:1.161
</code></pre><p><code>CHANGE-CAUSE</code> 的内容是从 Deployment 的 <code>kubernetes.io/change-cause</code> 注解复制过来的。
复制动作发生在修订版本创建时。你可以通过以下方式设置 <code>CHANGE-CAUSE</code> 消息：</p><ul><li>使用 <code>kubectl annotate deployment/nginx-deployment kubernetes.io/change-cause="image updated to 1.16.1"</code>
为 Deployment 添加注解。</li><li>手动编辑资源的清单。</li></ul></li></ol><ol start=2><li><p>要查看修订历史的详细信息，运行：</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl rollout <span style=color:#a2f>history</span> deployment/nginx-deployment --revision<span style=color:#666>=</span><span style=color:#666>2</span>
</span></span></code></pre></div><p>输出类似于：</p><pre tabindex=0><code>deployments &#34;nginx-deployment&#34; revision 2
  Labels:       app=nginx
          pod-template-hash=1159050644
  Annotations:  kubernetes.io/change-cause=kubectl set image deployment/nginx-deployment nginx=nginx:1.16.1
  Containers:
   nginx:
    Image:      nginx:1.16.1
    Port:       80/TCP
     QoS Tier:
        cpu:      BestEffort
        memory:   BestEffort
    Environment Variables:      &lt;none&gt;
  No volumes.
</code></pre></li></ol><h3 id=rolling-back-to-a-previous-revision>回滚到之前的修订版本</h3><p>按照下面给出的步骤将 Deployment 从当前版本回滚到以前的版本（即版本 2）。</p><ol><li><p>假定现在你已决定撤消当前上线并回滚到以前的修订版本：</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl rollout undo deployment/nginx-deployment
</span></span></code></pre></div><p>输出类似于：</p><pre tabindex=0><code>deployment.apps/nginx-deployment rolled back
</code></pre><p>或者，你也可以通过使用 <code>--to-revision</code> 来回滚到特定修订版本：</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl rollout undo deployment/nginx-deployment --to-revision<span style=color:#666>=</span><span style=color:#666>2</span>
</span></span></code></pre></div><p>输出类似于：</p><pre tabindex=0><code>deployment.apps/nginx-deployment rolled back
</code></pre><p>与回滚相关的指令的更详细信息，请参考
<a href=/docs/reference/generated/kubectl/kubectl-commands#rollout><code>kubectl rollout</code></a>。</p><p>现在，Deployment 正在回滚到以前的稳定版本。正如你所看到的，Deployment
控制器生成了回滚到修订版本 2 的 <code>DeploymentRollback</code> 事件。</p></li></ol><ol start=2><li><p>检查回滚是否成功以及 Deployment 是否正在运行，运行：</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get deployment nginx-deployment
</span></span></code></pre></div><p>输出类似于：</p><pre tabindex=0><code>NAME               READY   UP-TO-DATE   AVAILABLE   AGE
nginx-deployment   3/3     3            3           30m
</code></pre></li></ol><ol start=3><li><p>获取 Deployment 描述信息：</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl describe deployment nginx-deployment
</span></span></code></pre></div><p>输出类似于：</p><pre tabindex=0><code>Name:                   nginx-deployment
Namespace:              default
CreationTimestamp:      Sun, 02 Sep 2018 18:17:55 -0500
Labels:                 app=nginx
Annotations:            deployment.kubernetes.io/revision=4
                        kubernetes.io/change-cause=kubectl set image deployment/nginx-deployment nginx=nginx:1.16.1
Selector:               app=nginx
Replicas:               3 desired | 3 updated | 3 total | 3 available | 0 unavailable
StrategyType:           RollingUpdate
MinReadySeconds:        0
RollingUpdateStrategy:  25% max unavailable, 25% max surge
Pod Template:
  Labels:  app=nginx
  Containers:
   nginx:
    Image:        nginx:1.16.1
    Port:         80/TCP
    Host Port:    0/TCP
    Environment:  &lt;none&gt;
    Mounts:       &lt;none&gt;
  Volumes:        &lt;none&gt;
Conditions:
  Type           Status  Reason
  ----           ------  ------
  Available      True    MinimumReplicasAvailable
  Progressing    True    NewReplicaSetAvailable
OldReplicaSets:  &lt;none&gt;
NewReplicaSet:   nginx-deployment-c4747d96c (3/3 replicas created)
Events:
  Type    Reason              Age   From                   Message
  ----    ------              ----  ----                   -------
  Normal  ScalingReplicaSet   12m   deployment-controller  Scaled up replica set nginx-deployment-75675f5897 to 3
  Normal  ScalingReplicaSet   11m   deployment-controller  Scaled up replica set nginx-deployment-c4747d96c to 1
  Normal  ScalingReplicaSet   11m   deployment-controller  Scaled down replica set nginx-deployment-75675f5897 to 2
  Normal  ScalingReplicaSet   11m   deployment-controller  Scaled up replica set nginx-deployment-c4747d96c to 2
  Normal  ScalingReplicaSet   11m   deployment-controller  Scaled down replica set nginx-deployment-75675f5897 to 1
  Normal  ScalingReplicaSet   11m   deployment-controller  Scaled up replica set nginx-deployment-c4747d96c to 3
  Normal  ScalingReplicaSet   11m   deployment-controller  Scaled down replica set nginx-deployment-75675f5897 to 0
  Normal  ScalingReplicaSet   11m   deployment-controller  Scaled up replica set nginx-deployment-595696685f to 1
  Normal  DeploymentRollback  15s   deployment-controller  Rolled back deployment &#34;nginx-deployment&#34; to revision 2
  Normal  ScalingReplicaSet   15s   deployment-controller  Scaled down replica set nginx-deployment-595696685f to 0
</code></pre></li></ol><h2 id=scaling-a-deployment>缩放 Deployment</h2><p>你可以使用如下指令缩放 Deployment：</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl scale deployment/nginx-deployment --replicas<span style=color:#666>=</span><span style=color:#666>10</span>
</span></span></code></pre></div><p>输出类似于：</p><pre tabindex=0><code>deployment.apps/nginx-deployment scaled
</code></pre><p>假设集群启用了<a href=/zh-cn/docs/tasks/run-application/horizontal-pod-autoscale-walkthrough/>Pod 的水平自动缩放</a>，
你可以为 Deployment 设置自动缩放器，并基于现有 Pod 的 CPU 利用率选择要运行的
Pod 个数下限和上限。</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl autoscale deployment/nginx-deployment --min<span style=color:#666>=</span><span style=color:#666>10</span> --max<span style=color:#666>=</span><span style=color:#666>15</span> --cpu-percent<span style=color:#666>=</span><span style=color:#666>80</span>
</span></span></code></pre></div><p>输出类似于：</p><pre tabindex=0><code>deployment.apps/nginx-deployment scaled
</code></pre><h3 id=proportional-scaling>比例缩放</h3><p>RollingUpdate 的 Deployment 支持同时运行应用程序的多个版本。
当自动缩放器缩放处于上线进程（仍在进行中或暂停）中的 RollingUpdate Deployment 时，
Deployment 控制器会平衡现有的活跃状态的 ReplicaSets（含 Pod 的 ReplicaSets）中的额外副本，
以降低风险。这称为 <em>比例缩放（Proportional Scaling）</em>。</p><p>例如，你正在运行一个 10 个副本的 Deployment，其
<a href=#max-surge>maxSurge</a>=3，<a href=#max-unavailable>maxUnavailable</a>=2。</p><ul><li><p>确保 Deployment 的这 10 个副本都在运行。</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get deploy
</span></span></code></pre></div><p>输出类似于：</p><pre tabindex=0><code>NAME                 DESIRED   CURRENT   UP-TO-DATE   AVAILABLE   AGE
nginx-deployment     10        10        10           10          50s
</code></pre></li></ul><ul><li><p>更新 Deployment 使用新镜像，碰巧该镜像无法从集群内部解析。</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl <span style=color:#a2f>set</span> image deployment/nginx-deployment <span style=color:#b8860b>nginx</span><span style=color:#666>=</span>nginx:sometag
</span></span></code></pre></div><p>输出类似于：</p><pre tabindex=0><code>deployment.apps/nginx-deployment image updated
</code></pre></li></ul><ul><li><p>镜像更新使用 ReplicaSet <code>nginx-deployment-1989198191</code> 启动新的上线过程，
但由于上面提到的 <code>maxUnavailable</code> 要求，该进程被阻塞了。检查上线状态：</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get rs
</span></span></code></pre></div><p>输出类似于：</p><pre tabindex=0><code>NAME                          DESIRED   CURRENT   READY     AGE
nginx-deployment-1989198191   5         5         0         9s
nginx-deployment-618515232    8         8         8         1m
</code></pre></li></ul><ul><li>然后，出现了新的 Deployment 扩缩请求。自动缩放器将 Deployment 副本增加到 15。
Deployment 控制器需要决定在何处添加 5 个新副本。如果未使用比例缩放，所有 5 个副本
都将添加到新的 ReplicaSet 中。使用比例缩放时，可以将额外的副本分布到所有 ReplicaSet。
较大比例的副本会被添加到拥有最多副本的 ReplicaSet，而较低比例的副本会进入到
副本较少的 ReplicaSet。所有剩下的副本都会添加到副本最多的 ReplicaSet。
具有零副本的 ReplicaSets 不会被扩容。</li></ul><p>在上面的示例中，3 个副本被添加到旧 ReplicaSet 中，2 个副本被添加到新 ReplicaSet。
假定新的副本都很健康，上线过程最终应将所有副本迁移到新的 ReplicaSet 中。
要确认这一点，请运行：</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get deploy
</span></span></code></pre></div><p>输出类似于：</p><pre tabindex=0><code>NAME                 DESIRED   CURRENT   UP-TO-DATE   AVAILABLE   AGE
nginx-deployment     15        18        7            8           7m
</code></pre><p>上线状态确认了副本是如何被添加到每个 ReplicaSet 的。</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get rs
</span></span></code></pre></div><p>输出类似于：</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>NAME                          DESIRED   CURRENT   READY     AGE
</span></span><span style=display:flex><span>nginx-deployment-1989198191   <span style=color:#666>7</span>         <span style=color:#666>7</span>         <span style=color:#666>0</span>         7m
</span></span><span style=display:flex><span>nginx-deployment-618515232    <span style=color:#666>11</span>        <span style=color:#666>11</span>        <span style=color:#666>11</span>        7m
</span></span></code></pre></div><h2 id=pausing-and-resuming-a-deployment>暂停、恢复 Deployment 的上线过程</h2><p>在你更新一个 Deployment 的时候，或者计划更新它的时候，
你可以在触发一个或多个更新之前暂停 Deployment 的上线过程。
当你准备应用这些变更时，你可以重新恢复 Deployment 上线过程。
这样做使得你能够在暂停和恢复执行之间应用多个修补程序，而不会触发不必要的上线操作。</p><ul><li><p>例如，对于一个刚刚创建的 Deployment：</p><p>获取该 Deployment 信息：</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get deploy
</span></span></code></pre></div><p>输出类似于：</p><pre tabindex=0><code>NAME      DESIRED   CURRENT   UP-TO-DATE   AVAILABLE   AGE
nginx     3         3         3            3           1m
</code></pre><p>获取上线状态：</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get rs
</span></span></code></pre></div><p>输出类似于：</p><pre tabindex=0><code>NAME               DESIRED   CURRENT   READY     AGE
nginx-2142116321   3         3         3         1m
</code></pre></li></ul><ul><li><p>使用如下指令暂停上线：</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl rollout pause deployment/nginx-deployment
</span></span></code></pre></div><p>输出类似于：</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>deployment.apps/nginx-deployment paused
</span></span></code></pre></div></li></ul><ul><li><p>接下来更新 Deployment 镜像：</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl <span style=color:#a2f>set</span> image deployment/nginx-deployment <span style=color:#b8860b>nginx</span><span style=color:#666>=</span>nginx:1.16.1
</span></span></code></pre></div><p>输出类似于：</p><pre tabindex=0><code>deployment.apps/nginx-deployment image updated
</code></pre></li></ul><ul><li><p>注意没有新的上线被触发：</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl rollout <span style=color:#a2f>history</span> deployment/nginx-deployment
</span></span></code></pre></div><p>输出类似于：</p><pre tabindex=0><code>deployments &#34;nginx&#34;
REVISION  CHANGE-CAUSE
1   &lt;none&gt;
</code></pre></li></ul><ul><li><p>获取上线状态验证现有的 ReplicaSet 没有被更改：</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get rs
</span></span></code></pre></div><p>输出类似于：</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>NAME               DESIRED   CURRENT   READY     AGE
</span></span><span style=display:flex><span>nginx-2142116321   <span style=color:#666>3</span>         <span style=color:#666>3</span>         <span style=color:#666>3</span>         2m
</span></span></code></pre></div></li></ul><ul><li><p>你可以根据需要执行很多更新操作，例如，可以要使用的资源：</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl <span style=color:#a2f>set</span> resources deployment/nginx-deployment -c<span style=color:#666>=</span>nginx --limits<span style=color:#666>=</span><span style=color:#b8860b>cpu</span><span style=color:#666>=</span>200m,memory<span style=color:#666>=</span>512Mi
</span></span></code></pre></div><p>输出类似于：</p><pre tabindex=0><code>deployment.apps/nginx-deployment resource requirements updated
</code></pre><p>暂停 Deployment 上线之前的初始状态将继续发挥作用，但新的更新在 Deployment
上线被暂停期间不会产生任何效果。</p></li></ul><ul><li><p>最终，恢复 Deployment 上线并观察新的 ReplicaSet 的创建过程，其中包含了所应用的所有更新：</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl rollout resume deployment/nginx-deployment
</span></span></code></pre></div><p>输出类似于这样：</p><pre tabindex=0><code>deployment.apps/nginx-deployment resumed
</code></pre></li></ul><ul><li><p>观察上线的状态，直到完成。</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get rs -w
</span></span></code></pre></div><p>输出类似于：</p><pre tabindex=0><code>NAME               DESIRED   CURRENT   READY     AGE
nginx-2142116321   2         2         2         2m
nginx-3926361531   2         2         0         6s
nginx-3926361531   2         2         1         18s
nginx-2142116321   1         2         2         2m
nginx-2142116321   1         2         2         2m
nginx-3926361531   3         2         1         18s
nginx-3926361531   3         2         1         18s
nginx-2142116321   1         1         1         2m
nginx-3926361531   3         3         1         18s
nginx-3926361531   3         3         2         19s
nginx-2142116321   0         1         1         2m
nginx-2142116321   0         1         1         2m
nginx-2142116321   0         0         0         2m
nginx-3926361531   3         3         3         20s
</code></pre></li></ul><ul><li><p>获取最近上线的状态：</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get rs
</span></span></code></pre></div><p>输出类似于：</p><pre tabindex=0><code>NAME               DESIRED   CURRENT   READY     AGE
nginx-2142116321   0         0         0         2m
nginx-3926361531   3         3         3         28s
</code></pre></li></ul><div class="alert alert-info note callout" role=alert><strong>说明：</strong><p>你不可以回滚处于暂停状态的 Deployment，除非先恢复其执行状态。</div><h2 id=deployment-status>Deployment 状态</h2><p>Deployment 的生命周期中会有许多状态。上线新的 ReplicaSet 期间可能处于
<a href=#progressing-deployment>Progressing（进行中）</a>，可能是
<a href=#complete-deployment>Complete（已完成）</a>，也可能是
<a href=#failed-deployment>Failed（失败）</a>以至于无法继续进行。</p><h3 id=progressing-deployment>进行中的 Deployment</h3><p>执行下面的任务期间，Kubernetes 标记 Deployment 为<strong>进行中</strong>（Progressing）_：</p><ul><li>Deployment 创建新的 ReplicaSet</li><li>Deployment 正在为其最新的 ReplicaSet 扩容</li><li>Deployment 正在为其旧有的 ReplicaSet(s) 缩容</li><li>新的 Pod 已经就绪或者可用（就绪至少持续了 <a href=#min-ready-seconds>MinReadySeconds</a> 秒）。</li></ul><p>当上线过程进入“Progressing”状态时，Deployment 控制器会向 Deployment 的
<code>.status.conditions</code> 中添加包含下面属性的状况条目：</p><ul><li><code>type: Progressing</code></li><li><code>status: "True"</code></li><li><code>reason: NewReplicaSetCreated</code> | <code>reason: FoundNewReplicaSet</code> | <code>reason: ReplicaSetUpdated</code></li></ul><p>你可以使用 <code>kubectl rollout status</code> 监视 Deployment 的进度。</p><h3 id=complete-deployment>完成的 Deployment</h3><p>当 Deployment 具有以下特征时，Kubernetes 将其标记为<strong>完成（Complete）</strong>;</p><ul><li>与 Deployment 关联的所有副本都已更新到指定的最新版本，这意味着之前请求的所有更新都已完成。</li><li>与 Deployment 关联的所有副本都可用。</li><li>未运行 Deployment 的旧副本。</li></ul><p>当上线过程进入“Complete”状态时，Deployment 控制器会向 Deployment 的
<code>.status.conditions</code> 中添加包含下面属性的状况条目：</p><ul><li><code>type: Progressing</code></li><li><code>status: "True"</code></li><li><code>reason: NewReplicaSetAvailable</code></li></ul><p>这一 <code>Progressing</code> 状况的状态值会持续为 <code>"True"</code>，直至新的上线动作被触发。
即使副本的可用状态发生变化（进而影响 <code>Available</code> 状况），<code>Progressing</code> 状况的值也不会变化。</p><p>你可以使用 <code>kubectl rollout status</code> 检查 Deployment 是否已完成。
如果上线成功完成，<code>kubectl rollout status</code> 返回退出代码 0。</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl rollout status deployment/nginx-deployment
</span></span></code></pre></div><p>输出类似于：</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>Waiting <span style=color:#a2f;font-weight:700>for</span> rollout to finish: <span style=color:#666>2</span> of <span style=color:#666>3</span> updated replicas are available...
</span></span><span style=display:flex><span>deployment <span style=color:#b44>&#34;nginx-deployment&#34;</span> successfully rolled out
</span></span></code></pre></div><p>从 <code>kubectl rollout</code> 命令获得的返回状态为 0（成功）：</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>$ <span style=color:#a2f>echo</span> <span style=color:#b8860b>$?</span>
</span></span></code></pre></div><pre tabindex=0><code>0
</code></pre><h3 id=failed-deployment>失败的 Deployment</h3><p>你的 Deployment 可能会在尝试部署其最新的 ReplicaSet 受挫，一直处于未完成状态。
造成此情况一些可能因素如下：</p><ul><li>配额（Quota）不足</li><li>就绪探测（Readiness Probe）失败</li><li>镜像拉取错误</li><li>权限不足</li><li>限制范围（Limit Ranges）问题</li><li>应用程序运行时的配置错误</li></ul><p>检测此状况的一种方法是在 Deployment 规约中指定截止时间参数：
（<a href=#progress-deadline-seconds><code>.spec.progressDeadlineSeconds</code></a>）。
<code>.spec.progressDeadlineSeconds</code> 给出的是一个秒数值，Deployment 控制器在（通过 Deployment 状态）
标示 Deployment 进展停滞之前，需要等待所给的时长。</p><p>以下 <code>kubectl</code> 命令设置规约中的 <code>progressDeadlineSeconds</code>，从而告知控制器
在 10 分钟后报告 Deployment 的上线没有进展：</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl patch deployment/nginx-deployment -p <span style=color:#b44>&#39;{&#34;spec&#34;:{&#34;progressDeadlineSeconds&#34;:600}}&#39;</span>
</span></span></code></pre></div><p>输出类似于：</p><pre tabindex=0><code>deployment.apps/nginx-deployment patched
</code></pre><p>超过截止时间后，Deployment 控制器将添加具有以下属性的 Deployment 状况到
Deployment 的 <code>.status.conditions</code> 中：</p><ul><li><code>type: Progressing</code></li><li><code>status: "False"</code></li><li><code>reason: ProgressDeadlineExceeded</code></li></ul><p>这一状况也可能会比较早地失败，因而其状态值被设置为 <code>"False"</code>，
其原因为 <code>ReplicaSetCreateError</code>。
一旦 Deployment 上线完成，就不再考虑其期限。</p><p>参考
<a href=https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#typical-status-properties>Kubernetes API Conventions</a>
获取更多状态状况相关的信息。</p><div class="alert alert-info note callout" role=alert><strong>说明：</strong><p>除了报告 <code>Reason=ProgressDeadlineExceeded</code> 状态之外，Kubernetes 对已停止的
Deployment 不执行任何操作。更高级别的编排器可以利用这一设计并相应地采取行动。
例如，将 Deployment 回滚到其以前的版本。</div><div class="alert alert-info note callout" role=alert><strong>说明：</strong><p>如果你暂停了某个 Deployment 上线，Kubernetes 不再根据指定的截止时间检查 Deployment 上线的进展。
你可以在上线过程中间安全地暂停 Deployment 再恢复其执行，这样做不会导致超出最后时限的问题。</div><p>Deployment 可能会出现瞬时性的错误，可能因为设置的超时时间过短，
也可能因为其他可认为是临时性的问题。例如，假定所遇到的问题是配额不足。
如果描述 Deployment，你将会注意到以下部分：</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl describe deployment nginx-deployment
</span></span></code></pre></div><p>输出类似于：</p><pre tabindex=0><code>&lt;...&gt;
Conditions:
  Type            Status  Reason
  ----            ------  ------
  Available       True    MinimumReplicasAvailable
  Progressing     True    ReplicaSetUpdated
  ReplicaFailure  True    FailedCreate
&lt;...&gt;
</code></pre><p>如果运行 <code>kubectl get deployment nginx-deployment -o yaml</code>，Deployment 状态输出
将类似于这样：</p><pre tabindex=0><code>status:
  availableReplicas: 2
  conditions:
  - lastTransitionTime: 2016-10-04T12:25:39Z
    lastUpdateTime: 2016-10-04T12:25:39Z
    message: Replica set &#34;nginx-deployment-4262182780&#34; is progressing.
    reason: ReplicaSetUpdated
    status: &#34;True&#34;
    type: Progressing
  - lastTransitionTime: 2016-10-04T12:25:42Z
    lastUpdateTime: 2016-10-04T12:25:42Z
    message: Deployment has minimum availability.
    reason: MinimumReplicasAvailable
    status: &#34;True&#34;
    type: Available
  - lastTransitionTime: 2016-10-04T12:25:39Z
    lastUpdateTime: 2016-10-04T12:25:39Z
    message: &#39;Error creating: pods &#34;nginx-deployment-4262182780-&#34; is forbidden: exceeded quota:
      object-counts, requested: pods=1, used: pods=3, limited: pods=2&#39;
    reason: FailedCreate
    status: &#34;True&#34;
    type: ReplicaFailure
  observedGeneration: 3
  replicas: 2
  unavailableReplicas: 2
</code></pre><p>最终，一旦超过 Deployment 进度限期，Kubernetes 将更新状态和进度状况的原因：</p><pre tabindex=0><code>Conditions:
  Type            Status  Reason
  ----            ------  ------
  Available       True    MinimumReplicasAvailable
  Progressing     False   ProgressDeadlineExceeded
  ReplicaFailure  True    FailedCreate
</code></pre><p>可以通过缩容 Deployment 或者缩容其他运行状态的控制器，或者直接在命名空间中增加配额
来解决配额不足的问题。如果配额条件满足，Deployment 控制器完成了 Deployment 上线操作，
Deployment 状态会更新为成功状况（<code>Status=True</code> 和 <code>Reason=NewReplicaSetAvailable</code>）。</p><pre tabindex=0><code>Conditions:
  Type          Status  Reason
  ----          ------  ------
  Available     True    MinimumReplicasAvailable
  Progressing   True    NewReplicaSetAvailable
</code></pre><p><code>type: Available</code> 加上 <code>status: True</code> 意味着 Deployment 具有最低可用性。
最低可用性由 Deployment 策略中的参数指定。
<code>type: Progressing</code> 加上 <code>status: True</code> 表示 Deployment 处于上线过程中，并且正在运行，
或者已成功完成进度，最小所需新副本处于可用。
请参阅对应状况的 Reason 了解相关细节。
在我们的案例中 <code>reason: NewReplicaSetAvailable</code> 表示 Deployment 已完成。</p><p>你可以使用 <code>kubectl rollout status</code> 检查 Deployment 是否未能取得进展。
如果 Deployment 已超过进度限期，<code>kubectl rollout status</code> 返回非零退出代码。</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl rollout status deployment/nginx-deployment
</span></span></code></pre></div><p>输出类似于：</p><pre tabindex=0><code>Waiting for rollout to finish: 2 out of 3 new replicas have been updated...
error: deployment &#34;nginx&#34; exceeded its progress deadline
</code></pre><p><code>kubectl rollout</code> 命令的退出状态为 1（表明发生了错误）：</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>$ <span style=color:#a2f>echo</span> <span style=color:#b8860b>$?</span>
</span></span></code></pre></div><pre tabindex=0><code>1
</code></pre><h3 id=operating-on-a-failed-deployment>对失败 Deployment 的操作</h3><p>可应用于已完成的 Deployment 的所有操作也适用于失败的 Deployment。
你可以对其执行扩缩容、回滚到以前的修订版本等操作，或者在需要对 Deployment 的
Pod 模板应用多项调整时，将 Deployment 暂停。</p><h2 id=clean-up-policy>清理策略</h2><p>你可以在 Deployment 中设置 <code>.spec.revisionHistoryLimit</code> 字段以指定保留此
Deployment 的多少个旧有 ReplicaSet。其余的 ReplicaSet 将在后台被垃圾回收。
默认情况下，此值为 10。</p><div class="alert alert-info note callout" role=alert><strong>说明：</strong><p>显式将此字段设置为 0 将导致 Deployment 的所有历史记录被清空，因此 Deployment 将无法回滚。</div><h2 id=canary-deployment>金丝雀部署</h2><p>如果要使用 Deployment 向用户子集或服务器子集上线版本，
则可以遵循<a href=/zh-cn/docs/concepts/cluster-administration/manage-deployment/#canary-deployments>资源管理</a>所描述的金丝雀模式，
创建多个 Deployment，每个版本一个。</p><h2 id=writing-a-deployment-spec>编写 Deployment 规约</h2><p>同其他 Kubernetes 配置一样， Deployment 需要 <code>.apiVersion</code>，<code>.kind</code> 和 <code>.metadata</code> 字段。
有关配置文件的其他信息，请参考<a href=/zh-cn/docs/tasks/run-application/run-stateless-application-deployment/>部署 Deployment</a>、
配置容器和<a href=/zh-cn/docs/concepts/overview/working-with-objects/object-management/>使用 kubectl 管理资源</a>等相关文档。</p><p>Deployment 对象的名称必须是合法的
<a href=/zh-cn/docs/concepts/overview/working-with-objects/names#dns-subdomain-names>DNS 子域名</a>。
Deployment 还需要 <a href=https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#spec-and-status><code>.spec</code> 部分</a>。</p><h3 id=pod-template>Pod 模板</h3><p><code>.spec</code> 中只有 <code>.spec.template</code> 和 <code>.spec.selector</code> 是必需的字段。</p><p><code>.spec.template</code> 是一个 <a href=/zh-cn/docs/concepts/workloads/pods/#pod-templates>Pod 模板</a>。
它和 <a class=glossary-tooltip title='Pod 表示你的集群上一组正在运行的容器。' data-toggle=tooltip data-placement=top href=/zh-cn/docs/concepts/workloads/pods/ target=_blank aria-label=Pod>Pod</a> 的语法规则完全相同。
只是这里它是嵌套的，因此不需要 <code>apiVersion</code> 或 <code>kind</code>。</p><p>除了 Pod 的必填字段外，Deployment 中的 Pod 模板必须指定适当的标签和适当的重新启动策略。
对于标签，请确保不要与其他控制器重叠。请参考<a href=#selector>选择算符</a>。</p><p>只有 <a href=/zh-cn/docs/concepts/workloads/pods/pod-lifecycle/#restart-policy><code>.spec.template.spec.restartPolicy</code></a>
等于 <code>Always</code> 才是被允许的，这也是在没有指定时的默认设置。</p><h3 id=replicas>副本</h3><p><code>.spec.replicas</code> 是指定所需 Pod 的可选字段。它的默认值是1。</p><p>如果你对某个 Deployment 执行了手动扩缩操作（例如，通过
<code>kubectl scale deployment deployment --replicas=X</code>），
之后基于清单对 Deployment 执行了更新操作（例如通过运行
<code>kubectl apply -f deployment.yaml</code>），那么通过应用清单而完成的更新会覆盖之前手动扩缩所作的变更。</p><p>如果一个 <a href=/zh-cn/docs/tasks/run-application/horizontal-pod-autoscale/>HorizontalPodAutoscaler</a>
（或者其他执行水平扩缩操作的类似 API）在管理 Deployment 的扩缩，
则不要设置 <code>.spec.replicas</code>。</p><p>恰恰相反，应该允许 Kubernetes
<a class=glossary-tooltip title='控制平面是指容器编排层，它暴露 API 和接口来定义、部署容器和管理容器的生命周期。' data-toggle=tooltip data-placement=top href='/zh-cn/docs/reference/glossary/?all=true#term-control-plane' target=_blank aria-label=控制面>控制面</a>来自动管理
<code>.spec.replicas</code> 字段。</p><h3 id=selector>选择算符</h3><p><code>.spec.selector</code> 是指定本 Deployment 的 Pod
<a href=/zh-cn/docs/concepts/overview/working-with-objects/labels/>标签选择算符</a>的必需字段。</p><p><code>.spec.selector</code> 必须匹配 <code>.spec.template.metadata.labels</code>，否则请求会被 API 拒绝。</p><p>在 API <code>apps/v1</code>版本中，<code>.spec.selector</code> 和 <code>.metadata.labels</code> 如果没有设置的话，
不会被默认设置为 <code>.spec.template.metadata.labels</code>，所以需要明确进行设置。
同时在 <code>apps/v1</code>版本中，Deployment 创建后 <code>.spec.selector</code> 是不可变的。</p><p>当 Pod 的标签和选择算符匹配，但其模板和 <code>.spec.template</code> 不同时，或者此类 Pod
的总数超过 <code>.spec.replicas</code> 的设置时，Deployment 会终结之。
如果 Pod 总数未达到期望值，Deployment 会基于 <code>.spec.template</code> 创建新的 Pod。</p><div class="alert alert-info note callout" role=alert><strong>说明：</strong><p>你不应直接创建与此选择算符匹配的 Pod，也不应通过创建另一个 Deployment 或者类似于
ReplicaSet 或 ReplicationController 这类控制器来创建标签与此选择算符匹配的 Pod。
如果这样做，第一个 Deployment 会认为它创建了这些 Pod。
Kubernetes 不会阻止你这么做。</div><p>如果有多个控制器的选择算符发生重叠，则控制器之间会因冲突而无法正常工作。</p><h3 id=strategy>策略</h3><p><code>.spec.strategy</code> 策略指定用于用新 Pod 替换旧 Pod 的策略。
<code>.spec.strategy.type</code> 可以是 “Recreate” 或 “RollingUpdate”。“RollingUpdate” 是默认值。</p><h4 id=recreate-deployment>重新创建 Deployment</h4><p>如果 <code>.spec.strategy.type==Recreate</code>，在创建新 Pod 之前，所有现有的 Pod 会被杀死。</p><div class="alert alert-info note callout" role=alert><strong>说明：</strong><p>这只会确保为了升级而创建新 Pod 之前其他 Pod 都已终止。如果你升级一个 Deployment，
所有旧版本的 Pod 都会立即被终止。控制器等待这些 Pod 被成功移除之后，
才会创建新版本的 Pod。如果你手动删除一个 Pod，其生命周期是由 ReplicaSet 来控制的，
后者会立即创建一个替换 Pod（即使旧的 Pod 仍然处于 Terminating 状态）。
如果你需要一种“最多 n 个”的 Pod 个数保证，你需要考虑使用
<a href=/zh-cn/docs/concepts/workloads/controllers/statefulset/>StatefulSet</a>。</div><h4 id=rolling-update-deployment>滚动更新 Deployment</h4><p>Deployment 会在 <code>.spec.strategy.type==RollingUpdate</code>时，采取
滚动更新的方式更新 Pod。你可以指定 <code>maxUnavailable</code> 和 <code>maxSurge</code> 来控制滚动更新
过程。</p><h5 id=max-unavailable>最大不可用</h5><p><code>.spec.strategy.rollingUpdate.maxUnavailable</code> 是一个可选字段，用来指定
更新过程中不可用的 Pod 的个数上限。该值可以是绝对数字（例如，5），也可以是所需
Pod 的百分比（例如，10%）。百分比值会转换成绝对数并去除小数部分。
如果 <code>.spec.strategy.rollingUpdate.maxSurge</code> 为 0，则此值不能为 0。
默认值为 25%。</p><p>例如，当此值设置为 30% 时，滚动更新开始时会立即将旧 ReplicaSet 缩容到期望 Pod 个数的70%。
新 Pod 准备就绪后，可以继续缩容旧有的 ReplicaSet，然后对新的 ReplicaSet 扩容，
确保在更新期间可用的 Pod 总数在任何时候都至少为所需的 Pod 个数的 70%。</p><h5 id=max-surge>最大峰值</h5><p><code>.spec.strategy.rollingUpdate.maxSurge</code> 是一个可选字段，用来指定可以创建的超出期望
Pod 个数的 Pod 数量。此值可以是绝对数（例如，5）或所需 Pod 的百分比（例如，10%）。
如果 <code>MaxUnavailable</code> 为 0，则此值不能为 0。百分比值会通过向上取整转换为绝对数。
此字段的默认值为 25%。</p><p>例如，当此值为 30% 时，启动滚动更新后，会立即对新的 ReplicaSet 扩容，同时保证新旧 Pod
的总数不超过所需 Pod 总数的 130%。一旦旧 Pod 被杀死，新的 ReplicaSet 可以进一步扩容，
同时确保更新期间的任何时候运行中的 Pod 总数最多为所需 Pod 总数的 130%。</p><h3 id=progress-deadline-seconds>进度期限秒数</h3><p><code>.spec.progressDeadlineSeconds</code> 是一个可选字段，用于指定系统在报告 Deployment
<a href=#failed-deployment>进展失败</a> 之前等待 Deployment 取得进展的秒数。
这类报告会在资源状态中体现为 <code>type: Progressing</code>、<code>status: False</code>、
<code>reason: ProgressDeadlineExceeded</code>。Deployment 控制器将在默认 600 毫秒内持续重试 Deployment。
将来，一旦实现了自动回滚，Deployment 控制器将在探测到这样的条件时立即回滚 Deployment。</p><p>如果指定，则此字段值需要大于 <code>.spec.minReadySeconds</code> 取值。</p><h3 id=min-ready-seconds>最短就绪时间</h3><p><code>.spec.minReadySeconds</code> 是一个可选字段，用于指定新创建的 Pod
在没有任意容器崩溃情况下的最小就绪时间，
只有超出这个时间 Pod 才被视为可用。默认值为 0（Pod 在准备就绪后立即将被视为可用）。
要了解何时 Pod 被视为就绪，
可参考<a href=/zh-cn/docs/concepts/workloads/pods/pod-lifecycle/#container-probes>容器探针</a>。</p><h3 id=修订历史限制>修订历史限制</h3><p>Deployment 的修订历史记录存储在它所控制的 ReplicaSets 中。</p><p><code>.spec.revisionHistoryLimit</code> 是一个可选字段，用来设定出于回滚目的所要保留的旧 ReplicaSet 数量。
这些旧 ReplicaSet 会消耗 etcd 中的资源，并占用 <code>kubectl get rs</code> 的输出。
每个 Deployment 修订版本的配置都存储在其 ReplicaSets 中；因此，一旦删除了旧的 ReplicaSet，
将失去回滚到 Deployment 的对应修订版本的能力。
默认情况下，系统保留 10 个旧 ReplicaSet，但其理想值取决于新 Deployment 的频率和稳定性。</p><p>更具体地说，将此字段设置为 0 意味着将清理所有具有 0 个副本的旧 ReplicaSet。
在这种情况下，无法撤消新的 Deployment 上线，因为它的修订历史被清除了。</p><h3 id=paused>paused（暂停的）</h3><p><code>.spec.paused</code> 是用于暂停和恢复 Deployment 的可选布尔字段。
暂停的 Deployment 和未暂停的 Deployment 的唯一区别是，Deployment 处于暂停状态时，
PodTemplateSpec 的任何修改都不会触发新的上线。
Deployment 在创建时是默认不会处于暂停状态。</p><h2 id=接下来>接下来</h2><ul><li>了解 <a href=/zh-cn/docs/concepts/workloads/pods>Pod</a>。</li><li><a href=/zh-cn/docs/tasks/run-application/run-stateless-application-deployment/>使用 Deployment 运行一个无状态应用</a>。</li><li><code>Deployment</code> 是 Kubernetes REST API 中的一个顶层资源。
阅读
<a href=/zh-cn/docs/reference/kubernetes-api/workload-resources/deployment-v1/>Deployment</a>
对象定义，以了解 Deployment 的 API 细节。</li><li>阅读 <a href=/zh-cn/docs/concepts/workloads/pods/disruptions/>PodDisruptionBudget</a>
了解如何使用它来在可能出现干扰的情况下管理应用的可用性。</li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-d459b930218774655fa7fd1620625539>2.2 - ReplicaSet</h1><p>ReplicaSet 的目的是维护一组在任何时候都处于运行状态的 Pod 副本的稳定集合。
因此，它通常用来保证给定数量的、完全相同的 Pod 的可用性。</p><h2 id=how-a-replicaset-works>ReplicaSet 的工作原理</h2><p>ReplicaSet 是通过一组字段来定义的，包括一个用来识别可获得的 Pod
的集合的选择算符、一个用来标明应该维护的副本个数的数值、一个用来指定应该创建新 Pod
以满足副本个数条件时要使用的 Pod 模板等等。
每个 ReplicaSet 都通过根据需要创建和删除 Pod 以使得副本个数达到期望值，
进而实现其存在价值。当 ReplicaSet 需要创建新的 Pod 时，会使用所提供的 Pod 模板。</p><p>ReplicaSet 通过 Pod 上的
<a href=/zh-cn/docs/concepts/architecture/garbage-collection/#owners-and-dependents>metadata.ownerReferences</a>
字段连接到附属 Pod，该字段给出当前对象的属主资源。
ReplicaSet 所获得的 Pod 都在其 ownerReferences 字段中包含了属主 ReplicaSet
的标识信息。正是通过这一连接，ReplicaSet 知道它所维护的 Pod 集合的状态，
并据此计划其操作行为。</p><p>ReplicaSet 使用其选择算符来辨识要获得的 Pod 集合。如果某个 Pod 没有
OwnerReference 或者其 OwnerReference 不是一个<a class=glossary-tooltip title='控制器通过 API 服务器监控集群的公共状态，并致力于将当前状态转变为期望的状态。' data-toggle=tooltip data-placement=top href=/zh-cn/docs/concepts/architecture/controller/ target=_blank aria-label=控制器>控制器</a>，
且其匹配到某 ReplicaSet 的选择算符，则该 Pod 立即被此 ReplicaSet 获得。</p><h2 id=when-to-use-a-replicaset>何时使用 ReplicaSet</h2><p>ReplicaSet 确保任何时间都有指定数量的 Pod 副本在运行。
然而，Deployment 是一个更高级的概念，它管理 ReplicaSet，并向 Pod
提供声明式的更新以及许多其他有用的功能。
因此，我们建议使用 Deployment 而不是直接使用 ReplicaSet，
除非你需要自定义更新业务流程或根本不需要更新。</p><p>这实际上意味着，你可能永远不需要操作 ReplicaSet 对象：而是使用
Deployment，并在 spec 部分定义你的应用。</p><h2 id=example>示例</h2><div class=highlight><div class=copy-code-icon style=text-align:right><a href=https://raw.githubusercontent.com/kubernetes/website/main/content/zh-cn/examples/controllers/frontend.yaml download=controllers/frontend.yaml><code>controllers/frontend.yaml</code></a>
<img src=/images/copycode.svg style=max-height:24px;cursor:pointer onclick='copyCode("controllers-frontend-yaml")' title="Copy controllers/frontend.yaml to clipboard"></img></div><div class=includecode id=controllers-frontend-yaml><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>apps/v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>ReplicaSet<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>frontend<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>labels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>app</span>:<span style=color:#bbb> </span>guestbook<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>tier</span>:<span style=color:#bbb> </span>frontend<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:#080;font-style:italic># 按你的实际情况修改副本数</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>replicas</span>:<span style=color:#bbb> </span><span style=color:#666>3</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>selector</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>matchLabels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>tier</span>:<span style=color:#bbb> </span>frontend<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>template</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>labels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>tier</span>:<span style=color:#bbb> </span>frontend<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>php-redis<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>gcr.io/google_samples/gb-frontend:v3<span style=color:#bbb>
</span></span></span></code></pre></div></div></div><p>将此清单保存到 <code>frontend.yaml</code> 中，并将其提交到 Kubernetes 集群，
就能创建 yaml 文件所定义的 ReplicaSet 及其管理的 Pod。</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl apply -f https://kubernetes.io/examples/controllers/frontend.yaml
</span></span></code></pre></div><p>你可以看到当前被部署的 ReplicaSet：</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get rs
</span></span></code></pre></div><p>并看到你所创建的前端：</p><pre tabindex=0><code>NAME       DESIRED   CURRENT   READY   AGE
frontend   3         3         3       6s
</code></pre><p>你也可以查看 ReplicaSet 的状态：</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl describe rs/frontend
</span></span></code></pre></div><p>你会看到类似如下的输出：</p><pre tabindex=0><code>Name:         frontend
Namespace:    default
Selector:     tier=frontend
Labels:       app=guestbook
              tier=frontend
Annotations:  kubectl.kubernetes.io/last-applied-configuration:
                {&#34;apiVersion&#34;:&#34;apps/v1&#34;,&#34;kind&#34;:&#34;ReplicaSet&#34;,&#34;metadata&#34;:{&#34;annotations&#34;:{},&#34;labels&#34;:{&#34;app&#34;:&#34;guestbook&#34;,&#34;tier&#34;:&#34;frontend&#34;},&#34;name&#34;:&#34;frontend&#34;,...
Replicas:     3 current / 3 desired
Pods Status:  3 Running / 0 Waiting / 0 Succeeded / 0 Failed
Pod Template:
  Labels:  tier=frontend
  Containers:
   php-redis:
    Image:        gcr.io/google_samples/gb-frontend:v3
    Port:         &lt;none&gt;
    Host Port:    &lt;none&gt;
    Environment:  &lt;none&gt;
    Mounts:       &lt;none&gt;
  Volumes:        &lt;none&gt;
Events:
  Type    Reason            Age   From                   Message
  ----    ------            ----  ----                   -------
  Normal  SuccessfulCreate  117s  replicaset-controller  Created pod: frontend-wtsmm
  Normal  SuccessfulCreate  116s  replicaset-controller  Created pod: frontend-b2zdv
  Normal  SuccessfulCreate  116s  replicaset-controller  Created pod: frontend-vcmts
</code></pre><p>最后可以查看启动了的 Pod 集合：</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get pods
</span></span></code></pre></div><p>你会看到类似如下的 Pod 信息：</p><pre tabindex=0><code>NAME             READY   STATUS    RESTARTS   AGE
frontend-b2zdv   1/1     Running   0          6m36s
frontend-vcmts   1/1     Running   0          6m36s
frontend-wtsmm   1/1     Running   0          6m36s
</code></pre><p>你也可以查看 Pod 的属主引用被设置为前端的 ReplicaSet。
要实现这点，可取回运行中的某个 Pod 的 YAML：</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get pods frontend-b2zdv -o yaml
</span></span></code></pre></div><p>输出将类似这样，frontend ReplicaSet 的信息被设置在 metadata 的
<code>ownerReferences</code> 字段中：</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>creationTimestamp</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;2020-02-12T07:06:16Z&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>generateName</span>:<span style=color:#bbb> </span>frontend-<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>labels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>tier</span>:<span style=color:#bbb> </span>frontend<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>frontend-b2zdv<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>namespace</span>:<span style=color:#bbb> </span>default<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>ownerReferences</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>apps/v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>blockOwnerDeletion</span>:<span style=color:#bbb> </span><span style=color:#a2f;font-weight:700>true</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>controller</span>:<span style=color:#bbb> </span><span style=color:#a2f;font-weight:700>true</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>ReplicaSet<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>frontend<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>uid</span>:<span style=color:#bbb> </span>f391f6db-bb9b-4c09-ae74-6a1f77f3d5cf<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:#00f;font-weight:700>...</span><span style=color:#bbb>
</span></span></span></code></pre></div><h2 id=non-template-pod-acquisitions>非模板 Pod 的获得</h2><p>尽管你完全可以直接创建裸的 Pod，强烈建议你确保这些裸的 Pod 并不包含可能与你的某个
ReplicaSet 的选择算符相匹配的标签。原因在于 ReplicaSet 并不仅限于拥有在其模板中设置的
Pod，它还可以像前面小节中所描述的那样获得其他 Pod。</p><p>以前面的 frontend ReplicaSet 为例，并在以下清单中指定这些 Pod：</p><div class=highlight><div class=copy-code-icon style=text-align:right><a href=https://raw.githubusercontent.com/kubernetes/website/main/content/zh-cn/examples/pods/pod-rs.yaml download=pods/pod-rs.yaml><code>pods/pod-rs.yaml</code></a>
<img src=/images/copycode.svg style=max-height:24px;cursor:pointer onclick='copyCode("pods-pod-rs-yaml")' title="Copy pods/pod-rs.yaml to clipboard"></img></div><div class=includecode id=pods-pod-rs-yaml><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>pod1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>labels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>tier</span>:<span style=color:#bbb> </span>frontend<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>hello1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>gcr.io/google-samples/hello-app:2.0<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:#00f;font-weight:700>---</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>pod2<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>labels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>tier</span>:<span style=color:#bbb> </span>frontend<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>hello2<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>gcr.io/google-samples/hello-app:1.0<span style=color:#bbb>
</span></span></span></code></pre></div></div></div><p>由于这些 Pod 没有控制器（Controller，或其他对象）作为其属主引用，
并且其标签与 frontend ReplicaSet 的选择算符匹配，它们会立即被该 ReplicaSet 获取。</p><p>假定你在 frontend ReplicaSet 已经被部署之后创建 Pod，并且你已经在 ReplicaSet
中设置了其初始的 Pod 副本数以满足其副本计数需要：</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl apply -f https://kubernetes.io/examples/pods/pod-rs.yaml
</span></span></code></pre></div><p>新的 Pod 会被该 ReplicaSet 获取，并立即被 ReplicaSet 终止，
因为它们的存在会使得 ReplicaSet 中 Pod 个数超出其期望值。</p><p>取回 Pod：</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get pods
</span></span></code></pre></div><p>输出显示新的 Pod 或者已经被终止，或者处于终止过程中：</p><pre tabindex=0><code>NAME             READY   STATUS        RESTARTS   AGE
frontend-b2zdv   1/1     Running       0          10m
frontend-vcmts   1/1     Running       0          10m
frontend-wtsmm   1/1     Running       0          10m
pod1             0/1     Terminating   0          1s
pod2             0/1     Terminating   0          1s
</code></pre><p>如果你先行创建 Pod：</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl apply -f https://kubernetes.io/examples/pods/pod-rs.yaml
</span></span></code></pre></div><p>之后再创建 ReplicaSet：</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl apply -f https://kubernetes.io/examples/controllers/frontend.yaml
</span></span></code></pre></div><p>你会看到 ReplicaSet 已经获得了该 Pod，并仅根据其规约创建新的 Pod，
直到新的 Pod 和原来的 Pod 的总数达到其预期个数。
这时取回 Pod 列表：</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get pods
</span></span></code></pre></div><p>将会生成下面的输出：</p><pre tabindex=0><code>NAME             READY   STATUS    RESTARTS   AGE
frontend-hmmj2   1/1     Running   0          9s
pod1             1/1     Running   0          36s
pod2             1/1     Running   0          36s
</code></pre><p>采用这种方式，一个 ReplicaSet 中可以包含异质的 Pod 集合。</p><h2 id=writing-a-replicaset-manifest>编写 ReplicaSet 的清单</h2><p>与所有其他 Kubernetes API 对象一样，ReplicaSet 也需要 <code>apiVersion</code>、<code>kind</code>、和 <code>metadata</code> 字段。
对于 ReplicaSet 而言，其 <code>kind</code> 始终是 ReplicaSet。</p><p>ReplicaSet 对象的名称必须是合法的
<a href=/zh-cn/docs/concepts/overview/working-with-objects/names#dns-subdomain-names>DNS 子域名</a>。</p><p>ReplicaSet 也需要
<a href=https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#spec-and-status><code>.spec</code></a>
部分。</p><h3 id=pod-template>Pod 模板</h3><p><code>.spec.template</code> 是一个 <a href=/zh-cn/docs/concepts/workloads/pods/#pod-templates>Pod 模板</a>，
要求设置标签。在 <code>frontend.yaml</code> 示例中，我们指定了标签 <code>tier: frontend</code>。
注意不要将标签与其他控制器的选择算符重叠，否则那些控制器会尝试收养此 Pod。</p><p>对于模板的<a href=/zh-cn/docs/concepts/workloads/pods/pod-lifecycle/#restart-policy>重启策略</a>
字段，<code>.spec.template.spec.restartPolicy</code>，唯一允许的取值是 <code>Always</code>，这也是默认值.</p><h3 id=pod-selector>Pod 选择算符</h3><p><code>.spec.selector</code> 字段是一个<a href=/zh-cn/docs/concepts/overview/working-with-objects/labels/>标签选择算符</a>。
如前文中<a href=#how-a-replicaset-works>所讨论的</a>，这些是用来标识要被获取的 Pod
的标签。在签名的 <code>frontend.yaml</code> 示例中，选择算符为：</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>matchLabels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>tier</span>:<span style=color:#bbb> </span>frontend<span style=color:#bbb>
</span></span></span></code></pre></div><p>在 ReplicaSet 中，<code>.spec.template.metadata.labels</code> 的值必须与 <code>spec.selector</code>
值相匹配，否则该配置会被 API 拒绝。</p><div class="alert alert-info note callout" role=alert><strong>说明：</strong><p>对于设置了相同的 <code>.spec.selector</code>，但
<code>.spec.template.metadata.labels</code> 和 <code>.spec.template.spec</code> 字段不同的两个
ReplicaSet 而言，每个 ReplicaSet 都会忽略被另一个 ReplicaSet 所创建的 Pod。</div><h3 id=replicas>Replicas</h3><p>你可以通过设置 <code>.spec.replicas</code> 来指定要同时运行的 Pod 个数。
ReplicaSet 创建、删除 Pod 以与此值匹配。</p><p>如果你没有指定 <code>.spec.replicas</code>，那么默认值为 1。</p><h2 id=working-with-replicasets>使用 ReplicaSet</h2><h3 id=deleting-a-replicaset-and-its-pods>删除 ReplicaSet 和它的 Pod</h3><p>要删除 ReplicaSet 和它的所有 Pod，使用
<a href=/docs/reference/generated/kubectl/kubectl-commands#delete><code>kubectl delete</code></a> 命令。
默认情况下，<a href=/zh-cn/docs/concepts/architecture/garbage-collection/>垃圾收集器</a>
自动删除所有依赖的 Pod。</p><p>当使用 REST API 或 <code>client-go</code> 库时，你必须在 <code>-d</code> 选项中将 <code>propagationPolicy</code>
设置为 <code>Background</code> 或 <code>Foreground</code>。例如：</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl proxy --port<span style=color:#666>=</span><span style=color:#666>8080</span>
</span></span><span style=display:flex><span>curl -X DELETE  <span style=color:#b44>&#39;localhost:8080/apis/apps/v1/namespaces/default/replicasets/frontend&#39;</span> <span style=color:#b62;font-weight:700>\
</span></span></span><span style=display:flex><span><span style=color:#b62;font-weight:700></span>  -d <span style=color:#b44>&#39;{&#34;kind&#34;:&#34;DeleteOptions&#34;,&#34;apiVersion&#34;:&#34;v1&#34;,&#34;propagationPolicy&#34;:&#34;Foreground&#34;}&#39;</span> <span style=color:#b62;font-weight:700>\
</span></span></span><span style=display:flex><span><span style=color:#b62;font-weight:700></span>  -H <span style=color:#b44>&#34;Content-Type: application/json&#34;</span>
</span></span></code></pre></div><h3 id=deleting-just-a-replicaset>只删除 ReplicaSet</h3><p>你可以只删除 ReplicaSet 而不影响它的各个 Pod，方法是使用
<a href=/docs/reference/generated/kubectl/kubectl-commands#delete><code>kubectl delete</code></a>
命令并设置 <code>--cascade=orphan</code> 选项。</p><p>当使用 REST API 或 <code>client-go</code> 库时，你必须将 <code>propagationPolicy</code> 设置为 <code>Orphan</code>。
例如：</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl proxy --port<span style=color:#666>=</span><span style=color:#666>8080</span>
</span></span><span style=display:flex><span>curl -X DELETE  <span style=color:#b44>&#39;localhost:8080/apis/apps/v1/namespaces/default/replicasets/frontend&#39;</span> <span style=color:#b62;font-weight:700>\
</span></span></span><span style=display:flex><span><span style=color:#b62;font-weight:700></span>  -d <span style=color:#b44>&#39;{&#34;kind&#34;:&#34;DeleteOptions&#34;,&#34;apiVersion&#34;:&#34;v1&#34;,&#34;propagationPolicy&#34;:&#34;Orphan&#34;}&#39;</span> <span style=color:#b62;font-weight:700>\
</span></span></span><span style=display:flex><span><span style=color:#b62;font-weight:700></span>  -H <span style=color:#b44>&#34;Content-Type: application/json&#34;</span>
</span></span></code></pre></div><p>一旦删除了原来的 ReplicaSet，就可以创建一个新的来替换它。
由于新旧 ReplicaSet 的 <code>.spec.selector</code> 是相同的，新的 ReplicaSet 将接管老的 Pod。
但是，它不会努力使现有的 Pod 与新的、不同的 Pod 模板匹配。
若想要以可控的方式更新 Pod 的规约，可以使用
<a href=/zh-cn/docs/concepts/workloads/controllers/deployment/#creating-a-deployment>Deployment</a>
资源，因为 ReplicaSet 并不直接支持滚动更新。</p><h3 id=isolating-pods-from-a-replicaset>将 Pod 从 ReplicaSet 中隔离</h3><p>可以通过改变标签来从 ReplicaSet 中移除 Pod。
这种技术可以用来从服务中去除 Pod，以便进行排错、数据恢复等。
以这种方式移除的 Pod 将被自动替换（假设副本的数量没有改变）。</p><h3 id=scaling-a-replicaset>扩缩 ReplicaSet</h3><p>通过更新 <code>.spec.replicas</code> 字段，ReplicaSet 可以被轻松地进行扩缩。ReplicaSet
控制器能确保匹配标签选择器的数量的 Pod 是可用的和可操作的。</p><p>在降低集合规模时，ReplicaSet 控制器通过对可用的所有 Pod 进行排序来优先选择要被删除的那些 Pod。
其一般性算法如下：</p><ol><li>首先选择剔除悬决（Pending，且不可调度）的各个 Pod</li><li>如果设置了 <code>controller.kubernetes.io/pod-deletion-cost</code> 注解，则注解值较小的优先被裁减掉</li><li>所处节点上副本个数较多的 Pod 优先于所处节点上副本较少者</li><li>如果 Pod 的创建时间不同，最近创建的 Pod 优先于早前创建的 Pod 被裁减。
（当 <code>LogarithmicScaleDown</code> 这一<a href=/zh-cn/docs/reference/command-line-tools-reference/feature-gates/>特性门控</a>
被启用时，创建时间是按整数幂级来分组的）。</li></ol><p>如果以上比较结果都相同，则随机选择。</p><h3 id=pod-deletion-cost>Pod 删除开销</h3><div style=margin-top:10px;margin-bottom:10px><b>特性状态：</b> <code>Kubernetes v1.22 [beta]</code></div><p>通过使用 <a href=/zh-cn/docs/reference/labels-annotations-taints/#pod-deletion-cost><code>controller.kubernetes.io/pod-deletion-cost</code></a>
注解，用户可以对 ReplicaSet 缩容时要先删除哪些 Pod 设置偏好。</p><p>此注解要设置到 Pod 上，取值范围为 [-2147483647, 2147483647]。
所代表的是删除同一 ReplicaSet 中其他 Pod 相比较而言的开销。
删除开销较小的 Pod 比删除开销较高的 Pod 更容易被删除。</p><p>Pod 如果未设置此注解，则隐含的设置值为 0。负值也是可接受的。
如果注解值非法，API 服务器会拒绝对应的 Pod。</p><p>此功能特性处于 Beta 阶段，默认被启用。你可以通过为 kube-apiserver 和
kube-controller-manager 设置<a href=/zh-cn/docs/reference/command-line-tools-reference/feature-gates/>特性门控</a>
<code>PodDeletionCost</code> 来禁用此功能。</p><div class="alert alert-info note callout" role=alert><strong>说明：</strong><ul><li>此机制实施时仅是尽力而为，并不能对 Pod 的删除顺序作出任何保证；</li><li>用户应避免频繁更新注解值，例如根据某观测度量值来更新此注解值是应该避免的。
这样做会在 API 服务器上产生大量的 Pod 更新操作。</li></ul></div><h4 id=example-use-case>使用场景示例</h4><p>同一应用的不同 Pod 可能其利用率是不同的。在对应用执行缩容操作时，
可能希望移除利用率较低的 Pod。为了避免频繁更新 Pod，应用应该在执行缩容操作之前更新一次
<code>controller.kubernetes.io/pod-deletion-cost</code> 注解值
（将注解值设置为一个与其 Pod 利用率对应的值）。
如果应用自身控制器缩容操作时（例如 Spark 部署的驱动 Pod），这种机制是可以起作用的。</p><h3 id=replicaset-as-a-horizontal-pod-autoscaler-target>ReplicaSet 作为水平的 Pod 自动扩缩器目标</h3><p>ReplicaSet 也可以作为<a href=/zh-cn/docs/tasks/run-application/horizontal-pod-autoscale/>水平的 Pod 扩缩器 (HPA)</a>
的目标。也就是说，ReplicaSet 可以被 HPA 自动扩缩。
以下是 HPA 以我们在前一个示例中创建的副本集为目标的示例。</p><div class=highlight><div class=copy-code-icon style=text-align:right><a href=https://raw.githubusercontent.com/kubernetes/website/main/content/zh-cn/examples/controllers/hpa-rs.yaml download=controllers/hpa-rs.yaml><code>controllers/hpa-rs.yaml</code></a>
<img src=/images/copycode.svg style=max-height:24px;cursor:pointer onclick='copyCode("controllers-hpa-rs-yaml")' title="Copy controllers/hpa-rs.yaml to clipboard"></img></div><div class=includecode id=controllers-hpa-rs-yaml><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>autoscaling/v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>HorizontalPodAutoscaler<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>frontend-scaler<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>scaleTargetRef</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>ReplicaSet<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>frontend<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>minReplicas</span>:<span style=color:#bbb> </span><span style=color:#666>3</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>maxReplicas</span>:<span style=color:#bbb> </span><span style=color:#666>10</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>targetCPUUtilizationPercentage</span>:<span style=color:#bbb> </span><span style=color:#666>50</span><span style=color:#bbb>
</span></span></span></code></pre></div></div></div><p>将这个列表保存到 <code>hpa-rs.yaml</code> 并提交到 Kubernetes 集群，就能创建它所定义的
HPA，进而就能根据复制的 Pod 的 CPU 利用率对目标 ReplicaSet 进行自动扩缩。</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl apply -f https://k8s.io/examples/controllers/hpa-rs.yaml
</span></span></code></pre></div><p>或者，可以使用 <code>kubectl autoscale</code> 命令完成相同的操作（而且它更简单！）</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl autoscale rs frontend --max<span style=color:#666>=</span><span style=color:#666>10</span> --min<span style=color:#666>=</span><span style=color:#666>3</span> --cpu-percent<span style=color:#666>=</span><span style=color:#666>50</span>
</span></span></code></pre></div><h2 id=alternatives-to-replicaset>ReplicaSet 的替代方案</h2><h3 id=deployment-recommended>Deployment（推荐）</h3><p><a href=/zh-cn/docs/concepts/workloads/controllers/deployment/><code>Deployment</code></a> 是一个可以拥有
ReplicaSet 并使用声明式方式在服务器端完成对 Pod 滚动更新的对象。
尽管 ReplicaSet 可以独立使用，目前它们的主要用途是提供给 Deployment 作为编排
Pod 创建、删除和更新的一种机制。当使用 Deployment 时，你不必关心如何管理它所创建的
ReplicaSet，Deployment 拥有并管理其 ReplicaSet。
因此，建议你在需要 ReplicaSet 时使用 Deployment。</p><h3 id=bare-pods>裸 Pod</h3><p>与用户直接创建 Pod 的情况不同，ReplicaSet 会替换那些由于某些原因被删除或被终止的
Pod，例如在节点故障或破坏性的节点维护（如内核升级）的情况下。
因为这个原因，我们建议你使用 ReplicaSet，即使应用程序只需要一个 Pod。
想像一下，ReplicaSet 类似于进程监视器，只不过它在多个节点上监视多个 Pod，
而不是在单个节点上监视单个进程。
ReplicaSet 将本地容器重启的任务委托给了节点上的某个代理（例如，Kubelet）去完成。</p><h3 id=job>Job</h3><p>使用<a href=/zh-cn/docs/concepts/workloads/controllers/job/><code>Job</code></a> 代替 ReplicaSet，
可以用于那些期望自行终止的 Pod。</p><h3 id=daemonset>DaemonSet</h3><p>对于管理那些提供主机级别功能（如主机监控和主机日志）的容器，
就要用 <a href=/zh-cn/docs/concepts/workloads/controllers/daemonset/><code>DaemonSet</code></a>
而不用 ReplicaSet。
这些 Pod 的寿命与主机寿命有关：这些 Pod 需要先于主机上的其他 Pod 运行，
并且在机器准备重新启动/关闭时安全地终止。</p><h3 id=replicationcontroller>ReplicationController</h3><p>ReplicaSet 是 <a href=/zh-cn/docs/concepts/workloads/controllers/replicationcontroller/>ReplicationController</a>
的后继者。二者目的相同且行为类似，只是 ReplicationController 不支持
<a href=/zh-cn/docs/concepts/overview/working-with-objects/labels/#label-selectors>标签用户指南</a>
中讨论的基于集合的选择算符需求。
因此，相比于 ReplicationController，应优先考虑 ReplicaSet。</p><h2 id=接下来>接下来</h2><ul><li>了解 <a href=/zh-cn/docs/concepts/workloads/pods>Pod</a>。</li><li>了解 <a href=/zh-cn/docs/concepts/workloads/controllers/deployment/>Deployment</a>。</li><li><a href=/zh-cn/docs/tasks/run-application/run-stateless-application-deployment/>使用 Deployment 运行一个无状态应用</a>，
它依赖于 ReplicaSet。</li><li><code>ReplicaSet</code> 是 Kubernetes REST API 中的顶级资源。阅读
<a href=/zh-cn/docs/reference/kubernetes-api/workload-resources/replica-set-v1/>ReplicaSet</a>
对象定义理解关于该资源的 API。</li><li>阅读 <a href=/zh-cn/docs/concepts/workloads/pods/disruptions/>Pod 干扰预算（Disruption Budget）</a>，
了解如何在干扰下运行高度可用的应用。</li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-6d72299952c37ca8cc61b416e5bdbcd4>2.3 - StatefulSet</h1><p>StatefulSet 是用来管理有状态应用的工作负载 API 对象。</p><p>StatefulSet 用来管理某 <a class=glossary-tooltip title='Pod 表示你的集群上一组正在运行的容器。' data-toggle=tooltip data-placement=top href=/zh-cn/docs/concepts/workloads/pods/ target=_blank aria-label=Pod>Pod</a> 集合的部署和扩缩，
并为这些 Pod 提供持久存储和持久标识符。</p><p>和 <a class=glossary-tooltip title=管理集群上的多副本应用。 data-toggle=tooltip data-placement=top href=/zh-cn/docs/concepts/workloads/controllers/deployment/ target=_blank aria-label=Deployment>Deployment</a> 类似，
StatefulSet 管理基于相同容器规约的一组 Pod。但和 Deployment 不同的是，
StatefulSet 为它们的每个 Pod 维护了一个有粘性的 ID。这些 Pod 是基于相同的规约来创建的，
但是不能相互替换：无论怎么调度，每个 Pod 都有一个永久不变的 ID。</p><p>如果希望使用存储卷为工作负载提供持久存储，可以使用 StatefulSet 作为解决方案的一部分。
尽管 StatefulSet 中的单个 Pod 仍可能出现故障，
但持久的 Pod 标识符使得将现有卷与替换已失败 Pod 的新 Pod 相匹配变得更加容易。</p><h2 id=using-statefulsets>使用 StatefulSet</h2><p>StatefulSet 对于需要满足以下一个或多个需求的应用程序很有价值：</p><ul><li>稳定的、唯一的网络标识符。</li><li>稳定的、持久的存储。</li><li>有序的、优雅的部署和扩缩。</li><li>有序的、自动的滚动更新。</li></ul><p>在上面描述中，“稳定的”意味着 Pod 调度或重调度的整个过程是有持久性的。
如果应用程序不需要任何稳定的标识符或有序的部署、删除或扩缩，
则应该使用由一组无状态的副本控制器提供的工作负载来部署应用程序，比如
<a href=/zh-cn/docs/concepts/workloads/controllers/deployment/>Deployment</a> 或者
<a href=/zh-cn/docs/concepts/workloads/controllers/replicaset/>ReplicaSet</a>
可能更适用于你的无状态应用部署需要。</p><h2 id=limitations>限制</h2><ul><li>给定 Pod 的存储必须由
<a href=https://github.com/kubernetes/examples/tree/master/staging/persistent-volume-provisioning/README.md>PersistentVolume Provisioner</a>
基于所请求的 <code>storage class</code> 来制备，或者由管理员预先制备。</li><li>删除或者扩缩 StatefulSet 并<strong>不会</strong>删除它关联的存储卷。
这样做是为了保证数据安全，它通常比自动清除 StatefulSet 所有相关的资源更有价值。</li><li>StatefulSet 当前需要<a href=/zh-cn/docs/concepts/services-networking/service/#headless-services>无头服务</a>来负责 Pod
的网络标识。你需要负责创建此服务。</li><li>当删除一个 StatefulSet 时，该 StatefulSet 不提供任何终止 Pod 的保证。
为了实现 StatefulSet 中的 Pod 可以有序且体面地终止，可以在删除之前将 StatefulSet
缩容到 0。</li><li>在默认 <a href=#pod-management-policies>Pod 管理策略</a>(<code>OrderedReady</code>) 时使用<a href=#rolling-updates>滚动更新</a>，
可能进入需要<a href=#forced-rollback>人工干预</a>才能修复的损坏状态。</li></ul><h2 id=components>组件</h2><p>下面的示例演示了 StatefulSet 的组件。</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Service<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>nginx<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>labels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>app</span>:<span style=color:#bbb> </span>nginx<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>ports</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>port</span>:<span style=color:#bbb> </span><span style=color:#666>80</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>web<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>clusterIP</span>:<span style=color:#bbb> </span>None<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>selector</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>app</span>:<span style=color:#bbb> </span>nginx<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:#00f;font-weight:700>---</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>apps/v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>StatefulSet<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>web<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>selector</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>matchLabels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>app</span>:<span style=color:#bbb> </span>nginx<span style=color:#bbb> </span><span style=color:#080;font-style:italic># 必须匹配 .spec.template.metadata.labels</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>serviceName</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;nginx&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>replicas</span>:<span style=color:#bbb> </span><span style=color:#666>3</span><span style=color:#bbb> </span><span style=color:#080;font-style:italic># 默认值是 1</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>minReadySeconds</span>:<span style=color:#bbb> </span><span style=color:#666>10</span><span style=color:#bbb> </span><span style=color:#080;font-style:italic># 默认值是 0</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>template</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>labels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>app</span>:<span style=color:#bbb> </span>nginx<span style=color:#bbb> </span><span style=color:#080;font-style:italic># 必须匹配 .spec.selector.matchLabels</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>terminationGracePeriodSeconds</span>:<span style=color:#bbb> </span><span style=color:#666>10</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>nginx<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>registry.k8s.io/nginx-slim:0.8<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>ports</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span>- <span style=color:green;font-weight:700>containerPort</span>:<span style=color:#bbb> </span><span style=color:#666>80</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>web<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>volumeMounts</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>www<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>mountPath</span>:<span style=color:#bbb> </span>/usr/share/nginx/html<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>volumeClaimTemplates</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>www<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>accessModes</span>:<span style=color:#bbb> </span>[<span style=color:#bbb> </span><span style=color:#b44>&#34;ReadWriteOnce&#34;</span><span style=color:#bbb> </span>]<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>storageClassName</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;my-storage-class&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>resources</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>requests</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>storage</span>:<span style=color:#bbb> </span>1Gi<span style=color:#bbb>
</span></span></span></code></pre></div><p>上述例子中：</p><ul><li>名为 <code>nginx</code> 的 Headless Service 用来控制网络域名。</li><li>名为 <code>web</code> 的 StatefulSet 有一个 Spec，它表明将在独立的 3 个 Pod 副本中启动 nginx 容器。</li><li><code>volumeClaimTemplates</code> 将通过 PersistentVolume 制备程序所准备的
<a href=/zh-cn/docs/concepts/storage/persistent-volumes/>PersistentVolumes</a> 来提供稳定的存储。</li></ul><p>StatefulSet 的命名需要遵循
<a href=/zh-cn/docs/concepts/overview/working-with-objects/names#dns-subdomain-names>DNS 子域名</a>规范。</p><h3 id=pod-selector>Pod 选择算符</h3><p>你必须设置 StatefulSet 的 <code>.spec.selector</code> 字段，使之匹配其在
<code>.spec.template.metadata.labels</code> 中设置的标签。
未指定匹配的 Pod 选择算符将在创建 StatefulSet 期间导致验证错误。</p><h3 id=volume-claim-templates>卷申领模板</h3><p>你可以设置 <code>.spec.volumeClaimTemplates</code>，
它可以使用 PersistentVolume 制备程序所准备的
<a href=/zh-cn/docs/concepts/storage/persistent-volumes/>PersistentVolumes</a> 来提供稳定的存储。</p><h3 id=minimum-ready-seconds>最短就绪秒数</h3><div style=margin-top:10px;margin-bottom:10px><b>特性状态：</b> <code>Kubernetes v1.25 [stable]</code></div><p><code>.spec.minReadySeconds</code> 是一个可选字段。
它指定新创建的 Pod 应该在没有任何容器崩溃的情况下运行并准备就绪，才能被认为是可用的。
这用于在使用<a href=#rolling-updates>滚动更新</a>策略时检查滚动的进度。
该字段默认为 0（Pod 准备就绪后将被视为可用）。
要了解有关何时认为 Pod 准备就绪的更多信息，
请参阅<a href=/zh-cn/docs/concepts/workloads/pods/pod-lifecycle/#container-probes>容器探针</a>。</p><h2 id=pod-identity>Pod 标识</h2><p>StatefulSet Pod 具有唯一的标识，该标识包括顺序标识、稳定的网络标识和稳定的存储。
该标识和 Pod 是绑定的，与该 Pod 调度到哪个节点上无关。</p><h3 id=ordinal-index>有序索引</h3><p>对于具有 N 个副本的 StatefulSet，该 StatefulSet 中的每个 Pod 将被分配一个从 0 到 N-1
的整数序号，该序号在此 StatefulSet 上是唯一的。</p><h3 id=stable-network-id>稳定的网络 ID</h3><p>StatefulSet 中的每个 Pod 根据 StatefulSet 的名称和 Pod 的序号派生出它的主机名。
组合主机名的格式为<code>$(StatefulSet 名称)-$(序号)</code>。
上例将会创建三个名称分别为 <code>web-0、web-1、web-2</code> 的 Pod。
StatefulSet 可以使用<a href=/zh-cn/docs/concepts/services-networking/service/#headless-services>无头服务</a>控制它的
Pod 的网络域。管理域的这个服务的格式为：
<code>$(服务名称).$(名字空间).svc.cluster.local</code>，其中 <code>cluster.local</code> 是集群域。
一旦每个 Pod 创建成功，就会得到一个匹配的 DNS 子域，格式为：
<code>$(pod 名称).$(所属服务的 DNS 域名)</code>，其中所属服务由 StatefulSet 的 <code>serviceName</code> 域来设定。</p><p>取决于集群域内部 DNS 的配置，有可能无法查询一个刚刚启动的 Pod 的 DNS 命名。
当集群内其他客户端在 Pod 创建完成前发出 Pod 主机名查询时，就会发生这种情况。
负缓存 (在 DNS 中较为常见) 意味着之前失败的查询结果会被记录和重用至少若干秒钟，
即使 Pod 已经正常运行了也是如此。</p><p>如果需要在 Pod 被创建之后及时发现它们，可使用以下选项：</p><ul><li>直接查询 Kubernetes API（比如，利用 watch 机制）而不是依赖于 DNS 查询</li><li>缩短 Kubernetes DNS 驱动的缓存时长（通常这意味着修改 CoreDNS 的 ConfigMap，目前缓存时长为 30 秒）</li></ul><p>正如<a href=#limitations>限制</a>中所述，
你需要负责创建<a href=/zh-cn/docs/concepts/services-networking/service/#headless-services>无头服务</a>以便为 Pod 提供网络标识。</p><p>下面给出一些选择集群域、服务名、StatefulSet 名、及其怎样影响 StatefulSet 的 Pod 上的 DNS 名称的示例：</p><table><thead><tr><th>集群域名</th><th>服务（名字空间/名字）</th><th>StatefulSet（名字空间/名字）</th><th>StatefulSet 域名</th><th>Pod DNS</th><th>Pod 主机名</th></tr></thead><tbody><tr><td>cluster.local</td><td>default/nginx</td><td>default/web</td><td>nginx.default.svc.cluster.local</td><td>web-{0..N-1}.nginx.default.svc.cluster.local</td><td>web-{0..N-1}</td></tr><tr><td>cluster.local</td><td>foo/nginx</td><td>foo/web</td><td>nginx.foo.svc.cluster.local</td><td>web-{0..N-1}.nginx.foo.svc.cluster.local</td><td>web-{0..N-1}</td></tr><tr><td>kube.local</td><td>foo/nginx</td><td>foo/web</td><td>nginx.foo.svc.kube.local</td><td>web-{0..N-1}.nginx.foo.svc.kube.local</td><td>web-{0..N-1}</td></tr></tbody></table><div class="alert alert-info note callout" role=alert><strong>说明：</strong><p>集群域会被设置为 <code>cluster.local</code>，除非有<a href=/zh-cn/docs/concepts/services-networking/dns-pod-service/>其他配置</a>。</div><h3 id=stable-storage>稳定的存储</h3><p>对于 StatefulSet 中定义的每个 VolumeClaimTemplate，每个 Pod 接收到一个 PersistentVolumeClaim。
在上面的 nginx 示例中，每个 Pod 将会得到基于 StorageClass <code>my-storage-class</code> 制备的
1 Gib 的 PersistentVolume。
如果没有声明 StorageClass，就会使用默认的 StorageClass。
当一个 Pod 被调度（重新调度）到节点上时，它的 <code>volumeMounts</code> 会挂载与其
PersistentVolumeClaims 相关联的 PersistentVolume。
请注意，当 Pod 或者 StatefulSet 被删除时，与 PersistentVolumeClaims 相关联的
PersistentVolume 并不会被删除。要删除它必须通过手动方式来完成。</p><h3 id=pod-name-label>Pod 名称标签</h3><p>当 StatefulSet <a class=glossary-tooltip title='控制器通过 API 服务器监控集群的公共状态，并致力于将当前状态转变为期望的状态。' data-toggle=tooltip data-placement=top href=/zh-cn/docs/concepts/architecture/controller/ target=_blank aria-label=控制器>控制器</a>创建 Pod 时，
它会添加一个标签 <code>statefulset.kubernetes.io/pod-name</code>，该标签值设置为 Pod 名称。
这个标签允许你给 StatefulSet 中的特定 Pod 绑定一个 Service。</p><h2 id=deployment-and-scaling-guarantees>部署和扩缩保证</h2><ul><li>对于包含 N 个 副本的 StatefulSet，当部署 Pod 时，它们是依次创建的，顺序为 <code>0..N-1</code>。</li><li>当删除 Pod 时，它们是逆序终止的，顺序为 <code>N-1..0</code>。</li><li>在将扩缩操作应用到 Pod 之前，它前面的所有 Pod 必须是 Running 和 Ready 状态。</li><li>在一个 Pod 终止之前，所有的继任者必须完全关闭。</li></ul><p>StatefulSet 不应将 <code>pod.Spec.TerminationGracePeriodSeconds</code> 设置为 0。
这种做法是不安全的，要强烈阻止。
更多的解释请参考<a href=/zh-cn/docs/tasks/run-application/force-delete-stateful-set-pod/>强制删除 StatefulSet Pod</a>。</p><p>在上面的 nginx 示例被创建后，会按照 web-0、web-1、web-2 的顺序部署三个 Pod。
在 web-0 进入 <a href=/zh-cn/docs/concepts/workloads/pods/pod-lifecycle/>Running 和 Ready</a>
状态前不会部署 web-1。在 web-1 进入 Running 和 Ready 状态前不会部署 web-2。
如果 web-1 已经处于 Running 和 Ready 状态，而 web-2 尚未部署，在此期间发生了
web-0 运行失败，那么 web-2 将不会被部署，要等到 web-0 部署完成并进入 Running 和
Ready 状态后，才会部署 web-2。</p><p>如果用户想将示例中的 StatefulSet 扩缩为 <code>replicas=1</code>，首先被终止的是 web-2。
在 web-2 没有被完全停止和删除前，web-1 不会被终止。
当 web-2 已被终止和删除、web-1 尚未被终止，如果在此期间发生 web-0 运行失败，
那么就不会终止 web-1，必须等到 web-0 进入 Running 和 Ready 状态后才会终止 web-1。</p><h3 id=pod-management-policies>Pod 管理策略</h3><p>StatefulSet 允许你放宽其排序保证，
同时通过它的 <code>.spec.podManagementPolicy</code> 域保持其唯一性和身份保证。</p><h4 id=orderedready-pod-management>OrderedReady Pod 管理</h4><p><code>OrderedReady</code> Pod 管理是 StatefulSet 的默认设置。
它实现了<a href=#deployment-and-scaling-guarantees>上面</a>描述的功能。</p><h4 id=parallel-pod-management>并行 Pod 管理</h4><p><code>Parallel</code> Pod 管理让 StatefulSet 控制器并行的启动或终止所有的 Pod，
启动或者终止其他 Pod 前，无需等待 Pod 进入 Running 和 Ready 或者完全停止状态。
这个选项只会影响扩缩操作的行为，更新则不会被影响。</p><h2 id=update-strategies>更新策略</h2><p>StatefulSet 的 <code>.spec.updateStrategy</code> 字段让你可以配置和禁用掉自动滚动更新 Pod
的容器、标签、资源请求或限制、以及注解。有两个允许的值：</p><dl><dt><code>OnDelete</code></dt><dd>当 StatefulSet 的 <code>.spec.updateStrategy.type</code> 设置为 <code>OnDelete</code> 时，
它的控制器将不会自动更新 StatefulSet 中的 Pod。
用户必须手动删除 Pod 以便让控制器创建新的 Pod，以此来对 StatefulSet 的
<code>.spec.template</code> 的变动作出反应。</dd><dt><code>RollingUpdate</code></dt><dd><code>RollingUpdate</code> 更新策略对 StatefulSet 中的 Pod 执行自动的滚动更新。这是默认的更新策略。</dd></dl><h2 id=rolling-updates>滚动更新</h2><p>当 StatefulSet 的 <code>.spec.updateStrategy.type</code> 被设置为 <code>RollingUpdate</code> 时，
StatefulSet 控制器会删除和重建 StatefulSet 中的每个 Pod。
它将按照与 Pod 终止相同的顺序（从最大序号到最小序号）进行，每次更新一个 Pod。</p><p>Kubernetes 控制平面会等到被更新的 Pod 进入 Running 和 Ready 状态，然后再更新其前身。
如果你设置了 <code>.spec.minReadySeconds</code>（查看<a href=#minimum-ready-seconds>最短就绪秒数</a>），
控制平面在 Pod 就绪后会额外等待一定的时间再执行下一步。</p><h3 id=partitions>分区滚动更新</h3><p>通过声明 <code>.spec.updateStrategy.rollingUpdate.partition</code> 的方式，<code>RollingUpdate</code>
更新策略可以实现分区。
如果声明了一个分区，当 StatefulSet 的 <code>.spec.template</code> 被更新时，
所有序号大于等于该分区序号的 Pod 都会被更新。
所有序号小于该分区序号的 Pod 都不会被更新，并且，即使它们被删除也会依据之前的版本进行重建。
如果 StatefulSet 的 <code>.spec.updateStrategy.rollingUpdate.partition</code> 大于它的
<code>.spec.replicas</code>，则对它的 <code>.spec.template</code> 的更新将不会传递到它的 Pod。
在大多数情况下，你不需要使用分区，但如果你希望进行阶段更新、执行金丝雀或执行分阶段上线，则这些分区会非常有用。</p><h3 id=maximum-unavailable-pods>最大不可用 Pod</h3><div style=margin-top:10px;margin-bottom:10px><b>特性状态：</b> <code>Kubernetes v1.24 [alpha]</code></div><p>你可以通过指定 <code>.spec.updateStrategy.rollingUpdate.maxUnavailable</code>
字段来控制更新期间不可用的 Pod 的最大数量。
该值可以是绝对值（例如，“5”）或者是期望 Pod 个数的百分比（例如，<code>10%</code>）。
绝对值是根据百分比值四舍五入计算的。
该字段不能为 0。默认设置为 1。</p><p>该字段适用于 <code>0</code> 到 <code>replicas - 1</code> 范围内的所有 Pod。
如果在 <code>0</code> 到 <code>replicas - 1</code> 范围内存在不可用 Pod，这类 Pod 将被计入 <code>maxUnavailable</code> 值。</p><div class="alert alert-info note callout" role=alert><strong>说明：</strong><p><code>maxUnavailable</code> 字段处于 Alpha 阶段，仅当 API 服务器启用了 <code>MaxUnavailableStatefulSet</code>
<a href=/zh-cn/docs/reference/command-line-tools-reference/feature-gates/>特性门控</a>时才起作用。</div><h3 id=forced-rollback>强制回滚</h3><p>在默认 <a href=#pod-management-policies>Pod 管理策略</a>(<code>OrderedReady</code>) 下使用<a href=#rolling-updates>滚动更新</a>，
可能进入需要人工干预才能修复的损坏状态。</p><p>如果更新后 Pod 模板配置进入无法运行或就绪的状态（例如，
由于错误的二进制文件或应用程序级配置错误），StatefulSet 将停止回滚并等待。</p><p>在这种状态下，仅将 Pod 模板还原为正确的配置是不够的。
由于<a href=https://github.com/kubernetes/kubernetes/issues/67250>已知问题</a>，StatefulSet
将继续等待损坏状态的 Pod 准备就绪（永远不会发生），然后再尝试将其恢复为正常工作配置。</p><p>恢复模板后，还必须删除 StatefulSet 尝试使用错误的配置来运行的 Pod。这样，
StatefulSet 才会开始使用被还原的模板来重新创建 Pod。</p><h2 id=persistentvolumeclaim-retention>PersistentVolumeClaim 保留</h2><div style=margin-top:10px;margin-bottom:10px><b>特性状态：</b> <code>Kubernetes v1.23 [alpha]</code></div><p>在 StatefulSet 的生命周期中，可选字段
<code>.spec.persistentVolumeClaimRetentionPolicy</code> 控制是否删除以及如何删除 PVC。
使用该字段，你必须在 API 服务器和控制器管理器启用 <code>StatefulSetAutoDeletePVC</code>
<a href=/zh-cn/docs/reference/command-line-tools-reference/feature-gates/>特性门控</a>。
启用后，你可以为每个 StatefulSet 配置两个策略：</p><dl><dt><code>whenDeleted</code></dt><dd>配置删除 StatefulSet 时应用的卷保留行为。</dd><dt><code>whenScaled</code></dt><dd>配置当 StatefulSet 的副本数减少时应用的卷保留行为；例如，缩小集合时。</dd></dl><p>对于你可以配置的每个策略，你可以将值设置为 <code>Delete</code> 或 <code>Retain</code>。</p><dl><dt><code>Delete</code></dt><dd>对于受策略影响的每个 Pod，基于 StatefulSet 的 <code>volumeClaimTemplate</code> 字段创建的 PVC 都会被删除。
使用 <code>whenDeleted</code> 策略，所有来自 <code>volumeClaimTemplate</code> 的 PVC 在其 Pod 被删除后都会被删除。
使用 <code>whenScaled</code> 策略，只有与被缩减的 Pod 副本对应的 PVC 在其 Pod 被删除后才会被删除。</dd></dl><dl><dt><code>Retain</code>（默认）</dt><dd>来自 <code>volumeClaimTemplate</code> 的 PVC 在 Pod 被删除时不受影响。这是此新功能之前的行为。</dd></dl><p>请记住，这些策略<strong>仅</strong>适用于由于 StatefulSet 被删除或被缩小而被删除的 Pod。
例如，如果与 StatefulSet 关联的 Pod 由于节点故障而失败，
并且控制平面创建了替换 Pod，则 StatefulSet 保留现有的 PVC。
现有卷不受影响，集群会将其附加到新 Pod 即将启动的节点上。</p><p>策略的默认值为 <code>Retain</code>，与此新功能之前的 StatefulSet 行为相匹配。</p><p>这是一个示例策略。</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>apps/v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>StatefulSet<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:#00f;font-weight:700>...</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>persistentVolumeClaimRetentionPolicy</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>whenDeleted</span>:<span style=color:#bbb> </span>Retain<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>whenScaled</span>:<span style=color:#bbb> </span>Delete<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:#00f;font-weight:700>...</span><span style=color:#bbb>
</span></span></span></code></pre></div><p>StatefulSet <a class=glossary-tooltip title='控制器通过 API 服务器监控集群的公共状态，并致力于将当前状态转变为期望的状态。' data-toggle=tooltip data-placement=top href=/zh-cn/docs/concepts/architecture/controller/ target=_blank aria-label=控制器>控制器</a>为其 PVC
添加了<a href=/zh-cn/docs/concepts/overview/working-with-objects/owners-dependents/#owner-references-in-object-specifications>属主引用</a>，
这些 PVC 在 Pod 终止后被<a class=glossary-tooltip title='Kubernetes 用于清理集群资源的各种机制的统称。' data-toggle=tooltip data-placement=top href=/zh-cn/docs/concepts/architecture/garbage-collection/ target=_blank aria-label=垃圾回收器>垃圾回收器</a>删除。
这使 Pod 能够在删除 PVC 之前（以及在删除后备 PV 和卷之前，取决于保留策略）干净地卸载所有卷。
当你设置 <code>whenDeleted</code> 删除策略，对 StatefulSet 实例的属主引用放置在与该 StatefulSet 关联的所有 PVC 上。</p><p><code>whenScaled</code> 策略必须仅在 Pod 缩减时删除 PVC，而不是在 Pod 因其他原因被删除时删除。
执行协调操作时，StatefulSet 控制器将其所需的副本数与集群上实际存在的 Pod 进行比较。
对于 StatefulSet 中的所有 Pod 而言，如果其 ID 大于副本数，则将被废弃并标记为需要删除。
如果 <code>whenScaled</code> 策略是 <code>Delete</code>，则在删除 Pod 之前，
首先将已销毁的 Pod 设置为与 StatefulSet 模板对应的 PVC 的属主。
这会导致 PVC 仅在已废弃的 Pod 终止后被垃圾收集。</p><p>这意味着如果控制器崩溃并重新启动，在其属主引用更新到适合策略的 Pod 之前，不会删除任何 Pod。
如果在控制器关闭时强制删除了已废弃的 Pod，则属主引用可能已被设置，也可能未被设置，具体取决于控制器何时崩溃。
更新属主引用可能需要几个协调循环，因此一些已废弃的 Pod 可能已经被设置了属主引用，而其他可能没有。
出于这个原因，我们建议等待控制器恢复，控制器将在终止 Pod 之前验证属主引用。
如果这不可行，则操作员应验证 PVC 上的属主引用，以确保在强制删除 Pod 时删除预期的对象。</p><h3 id=replicas>副本数</h3><p><code>.spec.replicas</code> 是一个可选字段，用于指定所需 Pod 的数量。它的默认值为 1。</p><p>如果你手动扩缩已部署的负载，例如通过 <code>kubectl scale statefulset statefulset --replicas=X</code>，
然后根据清单更新 StatefulSet（例如：通过运行 <code>kubectl apply -f statefulset.yaml</code>），
那么应用该清单的操作会覆盖你之前所做的手动扩缩。</p><p>如果 <a href=/zh-cn/docs/tasks/run-application/horizontal-pod-autoscale/>HorizontalPodAutoscaler</a>
（或任何类似的水平扩缩 API）正在管理 StatefulSet 的扩缩，
请不要设置 <code>.spec.replicas</code>。
相反，允许 Kubernetes 控制平面自动管理 <code>.spec.replicas</code> 字段。</p><h2 id=接下来>接下来</h2><ul><li>了解 <a href=/zh-cn/docs/concepts/workloads/pods>Pod</a>。</li><li>了解如何使用 StatefulSet<ul><li>跟随示例<a href=/zh-cn/docs/tutorials/stateful-application/basic-stateful-set/>部署有状态应用</a>。</li><li>跟随示例<a href=/zh-cn/docs/tutorials/stateful-application/cassandra/>使用 StatefulSet 部署 Cassandra</a>。</li><li>跟随示例<a href=/zh-cn/docs/tasks/run-application/run-replicated-stateful-application/>运行多副本的有状态应用程序</a>。</li><li>了解如何<a href=/zh-cn/docs/tasks/run-application/scale-stateful-set/>扩缩 StatefulSet</a>。</li><li>了解<a href=/zh-cn/docs/tasks/run-application/delete-stateful-set/>删除 StatefulSet</a>涉及到的操作。</li><li>了解如何<a href=/zh-cn/docs/tasks/configure-pod-container/configure-volume-storage/>配置 Pod 以使用卷进行存储</a>。</li><li>了解如何<a href=/zh-cn/docs/tasks/configure-pod-container/configure-persistent-volume-storage/>配置 Pod 以使用 PersistentVolume 作为存储</a>。</li></ul></li><li><code>StatefulSet</code> 是 Kubernetes REST API 中的顶级资源。阅读
<a href=/zh-cn/docs/reference/kubernetes-api/workload-resources/stateful-set-v1/>StatefulSet</a>
对象定义理解关于该资源的 API。</li><li>阅读 <a href=/zh-cn/docs/concepts/workloads/pods/disruptions/>Pod 干扰预算（Disruption Budget）</a>，了解如何在干扰下运行高度可用的应用。</li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-41600eb8b6631c88848156f381e9d588>2.4 - DaemonSet</h1><p><strong>DaemonSet</strong> 确保全部（或者某些）节点上运行一个 Pod 的副本。
当有节点加入集群时， 也会为他们新增一个 Pod 。
当有节点从集群移除时，这些 Pod 也会被回收。删除 DaemonSet 将会删除它创建的所有 Pod。</p><p>DaemonSet 的一些典型用法：</p><ul><li>在每个节点上运行集群守护进程</li><li>在每个节点上运行日志收集守护进程</li><li>在每个节点上运行监控守护进程</li></ul><p>一种简单的用法是为每种类型的守护进程在所有的节点上都启动一个 DaemonSet。
一个稍微复杂的用法是为同一种守护进程部署多个 DaemonSet；每个具有不同的标志，
并且对不同硬件类型具有不同的内存、CPU 要求。</p><h2 id=writing-a-daemon-set-spec>编写 DaemonSet Spec</h2><h3 id=create-a-daemon-set>创建 DaemonSet</h3><p>你可以在 YAML 文件中描述 DaemonSet。
例如，下面的 daemonset.yaml 文件描述了一个运行 fluentd-elasticsearch Docker 镜像的 DaemonSet：</p><div class=highlight><div class=copy-code-icon style=text-align:right><a href=https://raw.githubusercontent.com/kubernetes/website/main/content/zh-cn/examples/controllers/daemonset.yaml download=controllers/daemonset.yaml><code>controllers/daemonset.yaml</code></a>
<img src=/images/copycode.svg style=max-height:24px;cursor:pointer onclick='copyCode("controllers-daemonset-yaml")' title="Copy controllers/daemonset.yaml to clipboard"></img></div><div class=includecode id=controllers-daemonset-yaml><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>apps/v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>DaemonSet<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>fluentd-elasticsearch<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>namespace</span>:<span style=color:#bbb> </span>kube-system<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>labels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>k8s-app</span>:<span style=color:#bbb> </span>fluentd-logging<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>selector</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>matchLabels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>fluentd-elasticsearch<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>template</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>labels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>fluentd-elasticsearch<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>tolerations</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:#080;font-style:italic># 这些容忍度设置是为了让该守护进程集在控制平面节点上运行</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:#080;font-style:italic># 如果你不希望自己的控制平面节点运行 Pod，可以删除它们</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- <span style=color:green;font-weight:700>key</span>:<span style=color:#bbb> </span>node-role.kubernetes.io/control-plane<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>operator</span>:<span style=color:#bbb> </span>Exists<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>effect</span>:<span style=color:#bbb> </span>NoSchedule<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- <span style=color:green;font-weight:700>key</span>:<span style=color:#bbb> </span>node-role.kubernetes.io/master<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>operator</span>:<span style=color:#bbb> </span>Exists<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>effect</span>:<span style=color:#bbb> </span>NoSchedule<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>fluentd-elasticsearch<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>quay.io/fluentd_elasticsearch/fluentd:v2.5.2<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>resources</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>limits</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>            </span><span style=color:green;font-weight:700>memory</span>:<span style=color:#bbb> </span>200Mi<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>requests</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>            </span><span style=color:green;font-weight:700>cpu</span>:<span style=color:#bbb> </span>100m<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>            </span><span style=color:green;font-weight:700>memory</span>:<span style=color:#bbb> </span>200Mi<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>volumeMounts</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>varlog<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>mountPath</span>:<span style=color:#bbb> </span>/var/log<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>terminationGracePeriodSeconds</span>:<span style=color:#bbb> </span><span style=color:#666>30</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>volumes</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>varlog<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>hostPath</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>path</span>:<span style=color:#bbb> </span>/var/log<span style=color:#bbb>
</span></span></span></code></pre></div></div></div><p>基于 YAML 文件创建 DaemonSet：</p><pre tabindex=0><code>kubectl apply -f https://k8s.io/examples/controllers/daemonset.yaml
</code></pre><h3 id=required-fields>必需字段</h3><p>与所有其他 Kubernetes 配置一样，DaemonSet 也需要 <code>apiVersion</code>、<code>kind</code> 和 <code>metadata</code> 字段。
有关使用这些配置文件的通用信息，
参见<a href=/zh-cn/docs/tasks/run-application/run-stateless-application-deployment/>运行无状态应用</a>和<a href=/zh-cn/docs/concepts/overview/working-with-objects/object-management/>使用 kubectl 管理对象</a>。</p><p>DaemonSet 对象的名称必须是一个合法的
<a href=/zh-cn/docs/concepts/overview/working-with-objects/names#dns-subdomain-names>DNS 子域名</a>。</p><p>DaemonSet 也需要 <a href=https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#spec-and-status><code>.spec</code></a> 节区。</p><h3 id=pod-template>Pod 模板</h3><p><code>.spec</code> 中唯一必需的字段是 <code>.spec.template</code>。</p><p><code>.spec.template</code> 是一个 <a href=/zh-cn/docs/concepts/workloads/pods/#pod-templates>Pod 模板</a>。
除了它是嵌套的，因而不具有 <code>apiVersion</code> 或 <code>kind</code> 字段之外，它与
<a class=glossary-tooltip title='Pod 表示你的集群上一组正在运行的容器。' data-toggle=tooltip data-placement=top href=/zh-cn/docs/concepts/workloads/pods/ target=_blank aria-label=Pod>Pod</a> 具有相同的 schema。</p><p>除了 Pod 必需字段外，在 DaemonSet 中的 Pod 模板必须指定合理的标签（查看 <a href=#pod-selector>Pod 选择算符</a>）。</p><p>在 DaemonSet 中的 Pod 模板必须具有一个值为 <code>Always</code> 的
<a href=/zh-cn/docs/concepts/workloads/pods/pod-lifecycle/#restart-policy><code>RestartPolicy</code></a>。
当该值未指定时，默认是 <code>Always</code>。</p><h3 id=pod-selector>Pod 选择算符</h3><p><code>.spec.selector</code> 字段表示 Pod 选择算符，它与
<a href=/zh-cn/docs/concepts/workloads/controllers/job/>Job</a> 的 <code>.spec.selector</code> 的作用是相同的。</p><p>你必须指定与 <code>.spec.template</code> 的标签匹配的 Pod 选择算符。
此外，一旦创建了 DaemonSet，它的 <code>.spec.selector</code> 就不能修改。
修改 Pod 选择算符可能导致 Pod 意外悬浮，并且这对用户来说是费解的。</p><p><code>spec.selector</code> 是一个对象，如下两个字段组成：</p><ul><li><code>matchLabels</code> - 与 <a href=/zh-cn/docs/concepts/workloads/controllers/replicationcontroller/>ReplicationController</a>
的 <code>.spec.selector</code> 的作用相同。</li><li><code>matchExpressions</code> - 允许构建更加复杂的选择器，可以通过指定 key、value
列表以及将 key 和 value 列表关联起来的 Operator。</li></ul><p>当上述两个字段都指定时，结果会按逻辑与（AND）操作处理。</p><p><code>.spec.selector</code> 必须与 <code>.spec.template.metadata.labels</code> 相匹配。
如果配置中这两个字段不匹配，则会被 API 拒绝。</p><h3 id=running-pods-on-only-some-nodes>仅在某些节点上运行 Pod</h3><p>如果指定了 <code>.spec.template.spec.nodeSelector</code>，DaemonSet 控制器将在能够与
<a href=/zh-cn/docs/concepts/scheduling-eviction/assign-pod-node/>Node 选择算符</a>匹配的节点上创建 Pod。
类似这种情况，可以指定 <code>.spec.template.spec.affinity</code>，之后 DaemonSet
控制器将在能够与<a href=/zh-cn/docs/concepts/scheduling-eviction/assign-pod-node/>节点亲和性</a>匹配的节点上创建 Pod。
如果根本就没有指定，则 DaemonSet Controller 将在所有节点上创建 Pod。</p><h2 id=how-daemon-pods-are-scheduled>Daemon Pods 是如何被调度的</h2><h3 id=scheduled-by-default-scheduler>通过默认调度器调度</h3><div style=margin-top:10px;margin-bottom:10px><b>特性状态：</b> <code>Kubernetes 1.17 [stable]</code></div><p>DaemonSet 确保所有符合条件的节点都运行该 Pod 的一个副本。
通常，运行 Pod 的节点由 Kubernetes 调度器选择。
不过，DaemonSet Pods 由 DaemonSet 控制器创建和调度。这就带来了以下问题：</p><ul><li>Pod 行为的不一致性：正常 Pod 在被创建后等待调度时处于 <code>Pending</code> 状态，
DaemonSet Pods 创建后不会处于 <code>Pending</code> 状态下。这使用户感到困惑。</li><li><a href=/zh-cn/docs/concepts/scheduling-eviction/pod-priority-preemption/>Pod 抢占</a>由默认调度器处理。
启用抢占后，DaemonSet 控制器将在不考虑 Pod 优先级和抢占的情况下制定调度决策。</li></ul><p><code>ScheduleDaemonSetPods</code> 允许你使用默认调度器而不是 DaemonSet 控制器来调度这些 DaemonSet，
方法是将 <code>NodeAffinity</code> 条件而不是 <code>.spec.nodeName</code> 条件添加到这些 DaemonSet Pod。
默认调度器接下来将 Pod 绑定到目标主机。
如果 DaemonSet Pod 的节点亲和性配置已存在，则被替换
（原始的节点亲和性配置在选择目标主机之前被考虑）。
DaemonSet 控制器仅在创建或修改 DaemonSet Pod 时执行这些操作，
并且不会更改 DaemonSet 的 <code>spec.template</code>。</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>nodeAffinity</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>requiredDuringSchedulingIgnoredDuringExecution</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>nodeSelectorTerms</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:green;font-weight:700>matchFields</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- <span style=color:green;font-weight:700>key</span>:<span style=color:#bbb> </span>metadata.name<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>operator</span>:<span style=color:#bbb> </span>In<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>values</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span>- target-host-name<span style=color:#bbb>
</span></span></span></code></pre></div><p>此外，系统会自动添加 <code>node.kubernetes.io/unschedulable：NoSchedule</code> 容忍度到这些
DaemonSet Pod。在调度 DaemonSet Pod 时，默认调度器会忽略 <code>unschedulable</code> 节点。</p><h3 id=taint-and-toleration>污点和容忍度</h3><p>尽管 Daemon Pod 遵循<a href=/zh-cn/docs/concepts/scheduling-eviction/taint-and-toleration>污点和容忍度</a>规则，
根据相关特性，控制器会自动将以下容忍度添加到 DaemonSet Pod：</p><table><thead><tr><th>容忍度键名</th><th>效果</th><th>版本</th><th>描述</th></tr></thead><tbody><tr><td><code>node.kubernetes.io/not-ready</code></td><td>NoExecute</td><td>1.13+</td><td>当出现类似网络断开的情况导致节点问题时，DaemonSet Pod 不会被逐出。</td></tr><tr><td><code>node.kubernetes.io/unreachable</code></td><td>NoExecute</td><td>1.13+</td><td>当出现类似于网络断开的情况导致节点问题时，DaemonSet Pod 不会被逐出。</td></tr><tr><td><code>node.kubernetes.io/disk-pressure</code></td><td>NoSchedule</td><td>1.8+</td><td>DaemonSet Pod 被默认调度器调度时能够容忍磁盘压力属性。</td></tr><tr><td><code>node.kubernetes.io/memory-pressure</code></td><td>NoSchedule</td><td>1.8+</td><td>DaemonSet Pod 被默认调度器调度时能够容忍内存压力属性。</td></tr><tr><td><code>node.kubernetes.io/unschedulable</code></td><td>NoSchedule</td><td>1.12+</td><td>DaemonSet Pod 能够容忍默认调度器所设置的 <code>unschedulable</code> 属性.</td></tr><tr><td><code>node.kubernetes.io/network-unavailable</code></td><td>NoSchedule</td><td>1.12+</td><td>DaemonSet 在使用宿主网络时，能够容忍默认调度器所设置的 <code>network-unavailable</code> 属性。</td></tr></tbody></table><h2 id=communicating-with-daemon-pods>与 Daemon Pods 通信</h2><p>与 DaemonSet 中的 Pod 进行通信的几种可能模式如下：</p><ul><li><p><strong>推送（Push）</strong>：配置 DaemonSet 中的 Pod，将更新发送到另一个服务，例如统计数据库。
这些服务没有客户端。</p></li><li><p><strong>NodeIP 和已知端口</strong>：DaemonSet 中的 Pod 可以使用 <code>hostPort</code>，从而可以通过节点 IP
访问到 Pod。客户端能通过某种方法获取节点 IP 列表，并且基于此也可以获取到相应的端口。</p></li><li><p><strong>DNS</strong>：创建具有相同 Pod 选择算符的<a href=/zh-cn/docs/concepts/services-networking/service/#headless-services>无头服务</a>，
通过使用 <code>endpoints</code> 资源或从 DNS 中检索到多个 A 记录来发现 DaemonSet。</p></li><li><p><strong>Service</strong>：创建具有相同 Pod 选择算符的服务，并使用该服务随机访问到某个节点上的守护进程（没有办法访问到特定节点）。</p></li></ul><h2 id=updating-a-daemon-set>更新 DaemonSet</h2><p>如果节点的标签被修改，DaemonSet 将立刻向新匹配上的节点添加 Pod，
同时删除不匹配的节点上的 Pod。</p><p>你可以修改 DaemonSet 创建的 Pod。不过并非 Pod 的所有字段都可更新。
下次当某节点（即使具有相同的名称）被创建时，DaemonSet 控制器还会使用最初的模板。</p><p>你可以删除一个 DaemonSet。如果使用 <code>kubectl</code> 并指定 <code>--cascade=orphan</code> 选项，
则 Pod 将被保留在节点上。接下来如果创建使用相同选择算符的新 DaemonSet，
新的 DaemonSet 会收养已有的 Pod。
如果有 Pod 需要被替换，DaemonSet 会根据其 <code>updateStrategy</code> 来替换。</p><p>你可以对 DaemonSet <a href=/zh-cn/docs/tasks/manage-daemon/update-daemon-set/>执行滚动更新</a>操作。</p><h2 id=alternatives-to-daemon-set>DaemonSet 的替代方案</h2><h3 id=init-scripts>init 脚本</h3><p>直接在节点上启动守护进程（例如使用 <code>init</code>、<code>upstartd</code> 或 <code>systemd</code>）的做法当然是可行的。
不过，基于 DaemonSet 来运行这些进程有如下一些好处：</p><ul><li><p>像所运行的其他应用一样，DaemonSet 具备为守护进程提供监控和日志管理的能力。</p></li><li><p>为守护进程和应用所使用的配置语言和工具（如 Pod 模板、<code>kubectl</code>）是相同的。</p></li><li><p>在资源受限的容器中运行守护进程能够增加守护进程和应用容器的隔离性。
然而，这一点也可以通过在容器中运行守护进程但却不在 Pod 中运行之来实现。</p></li></ul><h3 id=bare-pods>裸 Pod</h3><p>直接创建 Pod并指定其运行在特定的节点上也是可以的。
然而，DaemonSet 能够替换由于任何原因（例如节点失败、例行节点维护、内核升级）
而被删除或终止的 Pod。
由于这个原因，你应该使用 DaemonSet 而不是单独创建 Pod。</p><h3 id=static-pods>静态 Pod</h3><p>通过在一个指定的、受 <code>kubelet</code> 监视的目录下编写文件来创建 Pod 也是可行的。
这类 Pod 被称为<a href=/zh-cn/docs/tasks/configure-pod-container/static-pod/>静态 Pod</a>。
不像 DaemonSet，静态 Pod 不受 <code>kubectl</code> 和其它 Kubernetes API 客户端管理。
静态 Pod 不依赖于 API 服务器，这使得它们在启动引导新集群的情况下非常有用。
此外，静态 Pod 在将来可能会被废弃。</p><h3 id=deployment>Deployment</h3><p>DaemonSet 与 <a href=/zh-cn/docs/concepts/workloads/controllers/deployment/>Deployment</a> 非常类似，
它们都能创建 Pod，并且 Pod 中的进程都不希望被终止（例如，Web 服务器、存储服务器）。</p><p>建议为无状态的服务使用 Deployment，比如前端服务。
对这些服务而言，对副本的数量进行扩缩容、平滑升级，比精确控制 Pod 运行在某个主机上要重要得多。
当需要 Pod 副本总是运行在全部或特定主机上，并且当该 DaemonSet 提供了节点级别的功能（允许其他 Pod 在该特定节点上正确运行）时，
应该使用 DaemonSet。</p><p>例如，<a href=/zh-cn/docs/concepts/extend-kubernetes/compute-storage-net/network-plugins/>网络插件</a>通常包含一个以 DaemonSet 运行的组件。
这个 DaemonSet 组件确保它所在的节点的集群网络正常工作。</p><h2 id=接下来>接下来</h2><ul><li>了解 <a href=/zh-cn/docs/concepts/workloads/pods>Pod</a>。<ul><li>了解<a href=#static-pods>静态 Pod</a>，这对运行 Kubernetes <a class=glossary-tooltip title='控制平面是指容器编排层，它暴露 API 和接口来定义、部署容器和管理容器的生命周期。' data-toggle=tooltip data-placement=top href='/zh-cn/docs/reference/glossary/?all=true#term-control-plane' target=_blank aria-label=控制面>控制面</a>组件有帮助。</li></ul></li><li>了解如何使用 DaemonSet<ul><li><a href=/zh-cn/docs/tasks/manage-daemon/update-daemon-set/>对 DaemonSet 执行滚动更新</a></li><li><a href=/zh-cn/docs/tasks/manage-daemon/rollback-daemon-set/>对 DaemonSet 执行回滚</a>（例如：新的版本没有达到你的预期）</li></ul></li><li>理解<a href=/zh-cn/docs/concepts/scheduling-eviction/assign-pod-node/>Kubernetes 如何将 Pod 分配给节点</a>。</li><li>了解<a href=/zh-cn/docs/concepts/extend-kubernetes/compute-storage-net/device-plugins/>设备插件</a>和
<a href=/zh-cn/docs/concepts/cluster-administration/addons/>扩展（Addons）</a>，它们常以 DaemonSet 运行。</li><li><code>DaemonSet</code> 是 Kubernetes REST API 中的顶级资源。阅读
<a href=/zh-cn/docs/reference/kubernetes-api/workload-resources/daemon-set-v1/>DaemonSet</a>
对象定义理解关于该资源的 API。</li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-cc7cc3c4907039d9f863162e20bfbbef>2.5 - Job</h1><p>Job 会创建一个或者多个 Pod，并将继续重试 Pod 的执行，直到指定数量的 Pod 成功终止。
随着 Pod 成功结束，Job 跟踪记录成功完成的 Pod 个数。
当数量达到指定的成功个数阈值时，任务（即 Job）结束。
删除 Job 的操作会清除所创建的全部 Pod。
挂起 Job 的操作会删除 Job 的所有活跃 Pod，直到 Job 被再次恢复执行。</p><p>一种简单的使用场景下，你会创建一个 Job 对象以便以一种可靠的方式运行某 Pod 直到完成。
当第一个 Pod 失败或者被删除（比如因为节点硬件失效或者重启）时，Job
对象会启动一个新的 Pod。</p><p>你也可以使用 Job 以并行的方式运行多个 Pod。</p><p>如果你想按某种排期表（Schedule）运行 Job（单个任务或多个并行任务），请参阅
<a href=/zh-cn/docs/concepts/workloads/controllers/cron-jobs/>CronJob</a>。</p><h2 id=running-an-example-job>运行示例 Job</h2><p>下面是一个 Job 配置示例。它负责计算 π 到小数点后 2000 位，并将结果打印出来。
此计算大约需要 10 秒钟完成。</p><div class=highlight><div class=copy-code-icon style=text-align:right><a href=https://raw.githubusercontent.com/kubernetes/website/main/content/zh-cn/examples/controllers/job.yaml download=controllers/job.yaml><code>controllers/job.yaml</code></a>
<img src=/images/copycode.svg style=max-height:24px;cursor:pointer onclick='copyCode("controllers-job-yaml")' title="Copy controllers/job.yaml to clipboard"></img></div><div class=includecode id=controllers-job-yaml><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>batch/v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Job<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>pi<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>template</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>pi<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>perl:5.34.0<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>command</span>:<span style=color:#bbb> </span>[<span style=color:#b44>&#34;perl&#34;</span>,<span style=color:#bbb>  </span><span style=color:#b44>&#34;-Mbignum=bpi&#34;</span>,<span style=color:#bbb> </span><span style=color:#b44>&#34;-wle&#34;</span>,<span style=color:#bbb> </span><span style=color:#b44>&#34;print bpi(2000)&#34;</span>]<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>restartPolicy</span>:<span style=color:#bbb> </span>Never<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>backoffLimit</span>:<span style=color:#bbb> </span><span style=color:#666>4</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>
</span></span></span></code></pre></div></div></div><p>你可以使用下面的命令来运行此示例：</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl apply -f https://kubernetes.io/examples/controllers/job.yaml
</span></span></code></pre></div><p>输出类似于：</p><pre tabindex=0><code>job.batch/pi created
</code></pre><p>使用 <code>kubectl</code> 来检查 Job 的状态：</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl describe jobs/pi
</span></span></code></pre></div><p>输出类似于：</p><pre tabindex=0><code>Name:           pi
Namespace:      default
Selector:       controller-uid=c9948307-e56d-4b5d-8302-ae2d7b7da67c
Labels:         controller-uid=c9948307-e56d-4b5d-8302-ae2d7b7da67c
                job-name=pi
Annotations:    kubectl.kubernetes.io/last-applied-configuration:
                  {&#34;apiVersion&#34;:&#34;batch/v1&#34;,&#34;kind&#34;:&#34;Job&#34;,&#34;metadata&#34;:{&#34;annotations&#34;:{},&#34;name&#34;:&#34;pi&#34;,&#34;namespace&#34;:&#34;default&#34;},&#34;spec&#34;:{&#34;backoffLimit&#34;:4,&#34;template&#34;:...
Parallelism:    1
Completions:    1
Start Time:     Mon, 02 Dec 2019 15:20:11 +0200
Completed At:   Mon, 02 Dec 2019 15:21:16 +0200
Duration:       65s
Pods Statuses:  0 Running / 1 Succeeded / 0 Failed
Pod Template:
  Labels:  controller-uid=c9948307-e56d-4b5d-8302-ae2d7b7da67c
           job-name=pi
  Containers:
   pi:
    Image:      perl:5.34.0
    Port:       &lt;none&gt;
    Host Port:  &lt;none&gt;
    Command:
      perl
      -Mbignum=bpi
      -wle
      print bpi(2000)
    Environment:  &lt;none&gt;
    Mounts:       &lt;none&gt;
  Volumes:        &lt;none&gt;
Events:
  Type    Reason            Age   From            Message
  ----    ------            ----  ----            -------
  Normal  SuccessfulCreate  14m   job-controller  Created pod: pi-5rwd7
</code></pre><p>要查看 Job 对应的已完成的 Pod，可以执行 <code>kubectl get pods</code>。</p><p>要以机器可读的方式列举隶属于某 Job 的全部 Pod，你可以使用类似下面这条命令：</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span><span style=color:#b8860b>pods</span><span style=color:#666>=</span><span style=color:#a2f;font-weight:700>$(</span>kubectl get pods --selector<span style=color:#666>=</span>job-name<span style=color:#666>=</span>pi --output<span style=color:#666>=</span><span style=color:#b8860b>jsonpath</span><span style=color:#666>=</span><span style=color:#b44>&#39;{.items[*].metadata.name}&#39;</span><span style=color:#a2f;font-weight:700>)</span>
</span></span><span style=display:flex><span><span style=color:#a2f>echo</span> <span style=color:#b8860b>$pods</span>
</span></span></code></pre></div><p>输出类似于：</p><pre tabindex=0><code>pi-5rwd7
</code></pre><p>这里，选择算符与 Job 的选择算符相同。<code>--output=jsonpath</code> 选项给出了一个表达式，
用来从返回的列表中提取每个 Pod 的 name 字段。</p><p>查看其中一个 Pod 的标准输出：</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl logs <span style=color:#b8860b>$pods</span>
</span></span></code></pre></div><p>输出类似于：</p><pre tabindex=0><code>3.1415926535897932384626433832795028841971693993751058209749445923078164062862089986280348253421170679821480865132823066470938446095505822317253594081284811174502841027019385211055596446229489549303819644288109756659334461284756482337867831652712019091456485669234603486104543266482133936072602491412737245870066063155881748815209209628292540917153643678925903600113305305488204665213841469519415116094330572703657595919530921861173819326117931051185480744623799627495673518857527248912279381830119491298336733624406566430860213949463952247371907021798609437027705392171762931767523846748184676694051320005681271452635608277857713427577896091736371787214684409012249534301465495853710507922796892589235420199561121290219608640344181598136297747713099605187072113499999983729780499510597317328160963185950244594553469083026425223082533446850352619311881710100031378387528865875332083814206171776691473035982534904287554687311595628638823537875937519577818577805321712268066130019278766111959092164201989380952572010654858632788659361533818279682303019520353018529689957736225994138912497217752834791315155748572424541506959508295331168617278558890750983817546374649393192550604009277016711390098488240128583616035637076601047101819429555961989467678374494482553797747268471040475346462080466842590694912933136770289891521047521620569660240580381501935112533824300355876402474964732639141992726042699227967823547816360093417216412199245863150302861829745557067498385054945885869269956909272107975093029553211653449872027559602364806654991198818347977535663698074265425278625518184175746728909777727938000816470600161452491921732172147723501414419735685481613611573525521334757418494684385233239073941433345477624168625189835694855620992192221842725502542568876717904946016534668049886272327917860857843838279679766814541009538837863609506800642251252051173929848960841284886269456042419652850222106611863067442786220391949450471237137869609563643719172874677646575739624138908658326459958133904780275901
</code></pre><h2 id=writing-a-job-spec>编写 Job 规约</h2><p>与 Kubernetes 中其他资源的配置类似，Job 也需要 <code>apiVersion</code>、<code>kind</code> 和 <code>metadata</code> 字段。
Job 的名字必须是合法的 <a href=/zh-cn/docs/concepts/overview/working-with-objects/names#dns-subdomain-names>DNS 子域名</a>。</p><p>Job 配置还需要一个 <a href=https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#spec-and-status><code>.spec</code> 节</a>。</p><h3 id=pod-template>Pod 模板</h3><p>Job 的 <code>.spec</code> 中只有 <code>.spec.template</code> 是必需的字段。</p><p>字段 <code>.spec.template</code> 的值是一个 <a href=/zh-cn/docs/concepts/workloads/pods/#pod-templates>Pod 模板</a>。
其定义规范与 <a class=glossary-tooltip title='Pod 表示你的集群上一组正在运行的容器。' data-toggle=tooltip data-placement=top href=/zh-cn/docs/concepts/workloads/pods/ target=_blank aria-label=Pod>Pod</a>
完全相同，只是其中不再需要 <code>apiVersion</code> 或 <code>kind</code> 字段。</p><p>除了作为 Pod 所必需的字段之外，Job 中的 Pod 模板必须设置合适的标签
（参见 <a href=#pod-selector>Pod 选择算符</a>）和合适的重启策略。</p><p>Job 中 Pod 的 <a href=/zh-cn/docs/concepts/workloads/pods/pod-lifecycle/#restart-policy><code>RestartPolicy</code></a>
只能设置为 <code>Never</code> 或 <code>OnFailure</code> 之一。</p><h3 id=pod-selector>Pod 选择算符</h3><p>字段 <code>.spec.selector</code> 是可选的。在绝大多数场合，你都不需要为其赋值。
参阅<a href=#specifying-your-own-pod-selector>设置自己的 Pod 选择算符</a>.</p><h3 id=parallel-jobs>Job 的并行执行</h3><p>适合以 Job 形式来运行的任务主要有三种：</p><ol><li>非并行 Job：<ul><li>通常只启动一个 Pod，除非该 Pod 失败。</li><li>当 Pod 成功终止时，立即视 Job 为完成状态。</li></ul></li><li>具有<strong>确定完成计数</strong>的并行 Job：<ul><li><code>.spec.completions</code> 字段设置为非 0 的正数值。</li><li>Job 用来代表整个任务，当成功的 Pod 个数达到 <code>.spec.completions</code> 时，Job 被视为完成。</li><li>当使用 <code>.spec.completionMode="Indexed"</code> 时，每个 Pod 都会获得一个不同的
索引值，介于 0 和 <code>.spec.completions-1</code> 之间。</li></ul></li><li>带<strong>工作队列</strong>的并行 Job：<ul><li>不设置 <code>spec.completions</code>，默认值为 <code>.spec.parallelism</code>。</li><li>多个 Pod 之间必须相互协调，或者借助外部服务确定每个 Pod 要处理哪个工作条目。
例如，任一 Pod 都可以从工作队列中取走最多 N 个工作条目。</li><li>每个 Pod 都可以独立确定是否其它 Pod 都已完成，进而确定 Job 是否完成。</li><li>当 Job 中<strong>任何</strong> Pod 成功终止，不再创建新 Pod。</li><li>一旦至少 1 个 Pod 成功完成，并且所有 Pod 都已终止，即可宣告 Job 成功完成。</li><li>一旦任何 Pod 成功退出，任何其它 Pod 都不应再对此任务执行任何操作或生成任何输出。
所有 Pod 都应启动退出过程。</li></ul></li></ol><p>对于<strong>非并行</strong>的 Job，你可以不设置 <code>spec.completions</code> 和 <code>spec.parallelism</code>。
这两个属性都不设置时，均取默认值 1。</p><p>对于<strong>确定完成计数</strong>类型的 Job，你应该设置 <code>.spec.completions</code> 为所需要的完成个数。
你可以设置 <code>.spec.parallelism</code>，也可以不设置。其默认值为 1。</p><p>对于一个<strong>工作队列</strong> Job，你不可以设置 <code>.spec.completions</code>，但要将<code>.spec.parallelism</code>
设置为一个非负整数。</p><p>关于如何利用不同类型的 Job 的更多信息，请参见 <a href=#job-patterns>Job 模式</a>一节。</p><h4 id=controlling-parallelism>控制并行性</h4><p>并行性请求（<code>.spec.parallelism</code>）可以设置为任何非负整数。
如果未设置，则默认为 1。
如果设置为 0，则 Job 相当于启动之后便被暂停，直到此值被增加。</p><p>实际并行性（在任意时刻运行状态的 Pod 个数）可能比并行性请求略大或略小，
原因如下：</p><ul><li>对于<strong>确定完成计数</strong> Job，实际上并行执行的 Pod 个数不会超出剩余的完成数。
如果 <code>.spec.parallelism</code> 值较高，会被忽略。</li><li>对于<strong>工作队列</strong> Job，有任何 Job 成功结束之后，不会有新的 Pod 启动。
不过，剩下的 Pod 允许执行完毕。</li><li>如果 Job <a class=glossary-tooltip title='控制器通过 API 服务器监控集群的公共状态，并致力于将当前状态转变为期望的状态。' data-toggle=tooltip data-placement=top href=/zh-cn/docs/concepts/architecture/controller/ target=_blank aria-label=控制器>控制器</a> 没有来得及作出响应，或者</li><li>如果 Job 控制器因为任何原因（例如，缺少 <code>ResourceQuota</code> 或者没有权限）无法创建 Pod。
Pod 个数可能比请求的数目小。</li><li>Job 控制器可能会因为之前同一 Job 中 Pod 失效次数过多而压制新 Pod 的创建。</li><li>当 Pod 处于体面终止进程中，需要一定时间才能停止。</li></ul><h3 id=completion-mode>完成模式</h3><div style=margin-top:10px;margin-bottom:10px><b>特性状态：</b> <code>Kubernetes v1.24 [stable]</code></div><p>带有<strong>确定完成计数</strong>的 Job，即 <code>.spec.completions</code> 不为 null 的 Job，
都可以在其 <code>.spec.completionMode</code> 中设置完成模式：</p><ul><li><p><code>NonIndexed</code>（默认值）：当成功完成的 Pod 个数达到 <code>.spec.completions</code> 所
设值时认为 Job 已经完成。换言之，每个 Job 完成事件都是独立无关且同质的。
要注意的是，当 <code>.spec.completions</code> 取值为 null 时，Job 被隐式处理为 <code>NonIndexed</code>。</p></li><li><p><code>Indexed</code>：Job 的 Pod 会获得对应的完成索引，取值为 0 到 <code>.spec.completions-1</code>。
该索引可以通过三种方式获取：</p><ul><li>Pod 注解 <code>batch.kubernetes.io/job-completion-index</code>。</li><li>作为 Pod 主机名的一部分，遵循模式 <code>$(job-name)-$(index)</code>。
当你同时使用带索引的 Job（Indexed Job）与 <a class=glossary-tooltip title='将运行在一组 Pods 上的应用程序公开为网络服务的抽象方法。' data-toggle=tooltip data-placement=top href=/zh-cn/docs/concepts/services-networking/service/ target=_blank aria-label=服务（Service）>服务（Service）</a>，
Job 中的 Pod 可以通过 DNS 使用确切的主机名互相寻址。</li><li>对于容器化的任务，在环境变量 <code>JOB_COMPLETION_INDEX</code> 中。</li></ul><p>当每个索引都对应一个成功完成的 Pod 时，Job 被认为是已完成的。
关于如何使用这种模式的更多信息，可参阅
<a href=/zh-cn/docs/tasks/job/indexed-parallel-processing-static/>用带索引的 Job 执行基于静态任务分配的并行处理</a>。
需要注意的是，对同一索引值可能被启动的 Pod 不止一个，尽管这种情况很少发生。
这时，只有一个会被记入完成计数中。</p></li></ul><h2 id=handling-pod-and-container-failures>处理 Pod 和容器失效</h2><p>Pod 中的容器可能因为多种不同原因失效，例如因为其中的进程退出时返回值非零，
或者容器因为超出内存约束而被杀死等等。
如果发生这类事件，并且 <code>.spec.template.spec.restartPolicy = "OnFailure"</code>，
Pod 则继续留在当前节点，但容器会被重新运行。
因此，你的程序需要能够处理在本地被重启的情况，或者要设置
<code>.spec.template.spec.restartPolicy = "Never"</code>。
关于 <code>restartPolicy</code> 的更多信息，可参阅
<a href=/zh-cn/docs/concepts/workloads/pods/pod-lifecycle/#example-states>Pod 生命周期</a>。</p><p>整个 Pod 也可能会失败，且原因各不相同。
例如，当 Pod 启动时，节点失效（被升级、被重启、被删除等）或者其中的容器失败而
<code>.spec.template.spec.restartPolicy = "Never"</code>。
当 Pod 失败时，Job 控制器会启动一个新的 Pod。
这意味着，你的应用需要处理在一个新 Pod 中被重启的情况。
尤其是应用需要处理之前运行所产生的临时文件、锁、不完整的输出等问题。</p><p>注意，即使你将 <code>.spec.parallelism</code> 设置为 1，且将 <code>.spec.completions</code> 设置为
1，并且 <code>.spec.template.spec.restartPolicy</code> 设置为 "Never"，同一程序仍然有可能被启动两次。</p><p>如果你确实将 <code>.spec.parallelism</code> 和 <code>.spec.completions</code> 都设置为比 1 大的值，
那就有可能同时出现多个 Pod 运行的情况。
为此，你的 Pod 也必须能够处理并发性问题。</p><h3 id=pod-backoff-failure-policy>Pod 回退失效策略</h3><p>在有些情形下，你可能希望 Job 在经历若干次重试之后直接进入失败状态，
因为这很可能意味着遇到了配置错误。
为了实现这点，可以将 <code>.spec.backoffLimit</code> 设置为视 Job 为失败之前的重试次数。
失效回退的限制值默认为 6。
与 Job 相关的失效的 Pod 会被 Job 控制器重建，回退重试时间将会按指数增长
（从 10 秒、20 秒到 40 秒）最多至 6 分钟。</p><p>计算重试次数有以下两种方法：</p><ul><li>计算 <code>.status.phase = "Failed"</code> 的 Pod 数量。</li><li>当 Pod 的 <code>restartPolicy = "OnFailure"</code> 时，针对 <code>.status.phase</code> 等于 <code>Pending</code> 或
<code>Running</code> 的 Pod，计算其中所有容器的重试次数。</li></ul><p>如果两种方式其中一个的值达到 <code>.spec.backoffLimit</code>，则 Job 被判定为失败。</p><p>当 <a href=#job-tracking-with-finalizers><code>JobTrackingWithFinalizers</code></a> 特性被禁用时，
失败的 Pod 数目仅基于 API 中仍然存在的 Pod。</p><div class="alert alert-info note callout" role=alert><strong>说明：</strong><p>如果你的 Job 的 <code>restartPolicy</code> 被设置为 "OnFailure"，就要注意运行该 Job 的 Pod
会在 Job 到达失效回退次数上限时自动被终止。
这会使得调试 Job 中可执行文件的工作变得非常棘手。
我们建议在调试 Job 时将 <code>restartPolicy</code> 设置为 "Never"，
或者使用日志系统来确保失效 Job 的输出不会意外遗失。</div><h2 id=clean-up-finished-jobs-automatically>Job 终止与清理</h2><p>Job 完成时不会再创建新的 Pod，不过已有的 Pod <a href=#pod-backoff-failure-policy>通常</a>也不会被删除。
保留这些 Pod 使得你可以查看已完成的 Pod 的日志输出，以便检查错误、警告或者其它诊断性输出。
Job 完成时 Job 对象也一样被保留下来，这样你就可以查看它的状态。
在查看了 Job 状态之后删除老的 Job 的操作留给了用户自己。
你可以使用 <code>kubectl</code> 来删除 Job（例如，<code>kubectl delete jobs/pi</code>
或者 <code>kubectl delete -f ./job.yaml</code>）。
当使用 <code>kubectl</code> 来删除 Job 时，该 Job 所创建的 Pod 也会被删除。</p><p>默认情况下，Job 会持续运行，除非某个 Pod 失败（<code>restartPolicy=Never</code>）
或者某个容器出错退出（<code>restartPolicy=OnFailure</code>）。
这时，Job 基于前述的 <code>spec.backoffLimit</code> 来决定是否以及如何重试。
一旦重试次数到达 <code>.spec.backoffLimit</code> 所设的上限，Job 会被标记为失败，
其中运行的 Pod 都会被终止。</p><p>终止 Job 的另一种方式是设置一个活跃期限。
你可以为 Job 的 <code>.spec.activeDeadlineSeconds</code> 设置一个秒数值。
该值适用于 Job 的整个生命期，无论 Job 创建了多少个 Pod。
一旦 Job 运行时间达到 <code>activeDeadlineSeconds</code> 秒，其所有运行中的 Pod 都会被终止，
并且 Job 的状态更新为 <code>type: Failed</code> 及 <code>reason: DeadlineExceeded</code>。</p><p>注意 Job 的 <code>.spec.activeDeadlineSeconds</code> 优先级高于其 <code>.spec.backoffLimit</code> 设置。
因此，如果一个 Job 正在重试一个或多个失效的 Pod，该 Job 一旦到达
<code>activeDeadlineSeconds</code> 所设的时限即不再部署额外的 Pod，
即使其重试次数还未达到 <code>backoffLimit</code> 所设的限制。</p><p>例如：</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>batch/v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Job<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>pi-with-timeout<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>backoffLimit</span>:<span style=color:#bbb> </span><span style=color:#666>5</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>activeDeadlineSeconds</span>:<span style=color:#bbb> </span><span style=color:#666>100</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>template</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>pi<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>perl:5.34.0<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>command</span>:<span style=color:#bbb> </span>[<span style=color:#b44>&#34;perl&#34;</span>,<span style=color:#bbb>  </span><span style=color:#b44>&#34;-Mbignum=bpi&#34;</span>,<span style=color:#bbb> </span><span style=color:#b44>&#34;-wle&#34;</span>,<span style=color:#bbb> </span><span style=color:#b44>&#34;print bpi(2000)&#34;</span>]<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>restartPolicy</span>:<span style=color:#bbb> </span>Never<span style=color:#bbb>
</span></span></span></code></pre></div><p>注意 Job 规约和 Job 中的
<a href=/zh-cn/docs/concepts/workloads/pods/init-containers/#detailed-behavior>Pod 模板规约</a>
都有 <code>activeDeadlineSeconds</code> 字段。
请确保你在合适的层次设置正确的字段。</p><p>还要注意的是，<code>restartPolicy</code> 对应的是 Pod，而不是 Job 本身：
一旦 Job 状态变为 <code>type: Failed</code>，就不会再发生 Job 重启的动作。
换言之，由 <code>.spec.activeDeadlineSeconds</code> 和 <code>.spec.backoffLimit</code> 所触发的 Job
终结机制都会导致 Job 永久性的失败，而这类状态都需要手工干预才能解决。</p><h2 id=clean-up-finished-jobs-automatically>自动清理完成的 Job</h2><p>完成的 Job 通常不需要留存在系统中。在系统中一直保留它们会给 API 服务器带来额外的压力。
如果 Job 由某种更高级别的控制器来管理，例如
<a href=/zh-cn/docs/concepts/workloads/controllers/cron-jobs/>CronJob</a>，
则 Job 可以被 CronJob 基于特定的根据容量裁定的清理策略清理掉。</p><h3 id=ttl-mechanisms-for-finished-jobs>已完成 Job 的 TTL 机制</h3><div style=margin-top:10px;margin-bottom:10px><b>特性状态：</b> <code>Kubernetes v1.23 [stable]</code></div><p>自动清理已完成 Job （状态为 <code>Complete</code> 或 <code>Failed</code>）的另一种方式是使用由
<a href=/zh-cn/docs/concepts/workloads/controllers/ttlafterfinished/>TTL 控制器</a>所提供的 TTL 机制。
通过设置 Job 的 <code>.spec.ttlSecondsAfterFinished</code> 字段，可以让该控制器清理掉已结束的资源。</p><p>TTL 控制器清理 Job 时，会级联式地删除 Job 对象。
换言之，它会删除所有依赖的对象，包括 Pod 及 Job 本身。
注意，当 Job 被删除时，系统会考虑其生命周期保障，例如其 Finalizers。</p><p>例如：</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>batch/v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Job<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>pi-with-ttl<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>ttlSecondsAfterFinished</span>:<span style=color:#bbb> </span><span style=color:#666>100</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>template</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>pi<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>perl:5.34.0<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>command</span>:<span style=color:#bbb> </span>[<span style=color:#b44>&#34;perl&#34;</span>,<span style=color:#bbb>  </span><span style=color:#b44>&#34;-Mbignum=bpi&#34;</span>,<span style=color:#bbb> </span><span style=color:#b44>&#34;-wle&#34;</span>,<span style=color:#bbb> </span><span style=color:#b44>&#34;print bpi(2000)&#34;</span>]<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>restartPolicy</span>:<span style=color:#bbb> </span>Never<span style=color:#bbb>
</span></span></span></code></pre></div><p>Job <code>pi-with-ttl</code> 在结束 100 秒之后，可以成为被自动删除的对象。</p><p>如果该字段设置为 <code>0</code>，Job 在结束之后立即成为可被自动删除的对象。
如果该字段没有设置，Job 不会在结束之后被 TTL 控制器自动清除。</p><h2 id=job-patterns>Job 模式</h2><p>Job 对象可以用来支持多个 Pod 的可靠的并发执行。
Job 对象不是设计用来支持相互通信的并行进程的，后者一般在科学计算中应用较多。
Job 的确能够支持对一组相互独立而又有所关联的<strong>工作条目</strong>的并行处理。
这类工作条目可能是要发送的电子邮件、要渲染的视频帧、要编解码的文件、NoSQL
数据库中要扫描的主键范围等等。</p><p>在一个复杂系统中，可能存在多个不同的工作条目集合。
这里我们仅考虑用户希望一起管理的工作条目集合之一：<strong>批处理作业</strong>。</p><p>并行计算的模式有好多种，每种都有自己的强项和弱点。这里要权衡的因素有：</p><ul><li>每个工作条目对应一个 Job 或者所有工作条目对应同一 Job 对象。
后者更适合处理大量工作条目的场景；
前者会给用户带来一些额外的负担，而且需要系统管理大量的 Job 对象。</li><li>创建与工作条目相等的 Pod 或者令每个 Pod 可以处理多个工作条目。
前者通常不需要对现有代码和容器做较大改动；
后者则更适合工作条目数量较大的场合，原因同上。</li><li>有几种技术都会用到工作队列。这意味着需要运行一个队列服务，
并修改现有程序或容器使之能够利用该工作队列。
与之比较，其他方案在修改现有容器化应用以适应需求方面可能更容易一些。</li></ul><p>下面是对这些权衡的汇总，第 2 到 4 列对应上面的权衡比较。
模式的名称对应了相关示例和更详细描述的链接。</p><table><thead><tr><th>模式</th><th style=text-align:center>单个 Job 对象</th><th style=text-align:center>Pod 数少于工作条目数？</th><th style=text-align:center>直接使用应用无需修改?</th></tr></thead><tbody><tr><td><a href=/zh-cn/docs/tasks/job/coarse-parallel-processing-work-queue/>每工作条目一 Pod 的队列</a></td><td style=text-align:center>✓</td><td style=text-align:center></td><td style=text-align:center>有时</td></tr><tr><td><a href=/zh-cn/docs/tasks/job/fine-parallel-processing-work-queue/>Pod 数量可变的队列</a></td><td style=text-align:center>✓</td><td style=text-align:center>✓</td><td style=text-align:center></td></tr><tr><td><a href=/zh-cn/docs/tasks/job/indexed-parallel-processing-static>静态任务分派的带索引的 Job</a></td><td style=text-align:center>✓</td><td style=text-align:center></td><td style=text-align:center>✓</td></tr><tr><td><a href=/zh-cn/docs/tasks/job/parallel-processing-expansion/>Job 模板扩展</a></td><td style=text-align:center></td><td style=text-align:center></td><td style=text-align:center>✓</td></tr></tbody></table><p>当你使用 <code>.spec.completions</code> 来设置完成数时，Job 控制器所创建的每个 Pod
使用完全相同的 <a href=https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#spec-and-status><code>spec</code></a>。
这意味着任务的所有 Pod 都有相同的命令行，都使用相同的镜像和数据卷，
甚至连环境变量都（几乎）相同。
这些模式是让每个 Pod 执行不同工作的几种不同形式。</p><p>下表显示的是每种模式下 <code>.spec.parallelism</code> 和 <code>.spec.completions</code> 所需要的设置。
其中，<code>W</code> 表示的是工作条目的个数。</p><table><thead><tr><th>模式</th><th style=text-align:center><code>.spec.completions</code></th><th style=text-align:center><code>.spec.parallelism</code></th></tr></thead><tbody><tr><td><a href=/zh-cn/docs/tasks/job/coarse-parallel-processing-work-queue/>每工作条目一 Pod 的队列</a></td><td style=text-align:center>W</td><td style=text-align:center>任意值</td></tr><tr><td><a href=/zh-cn/docs/tasks/job/fine-parallel-processing-work-queue/>Pod 个数可变的队列</a></td><td style=text-align:center>1</td><td style=text-align:center>任意值</td></tr><tr><td><a href=/zh-cn/docs/tasks/job/indexed-parallel-processing-static>静态任务分派的带索引的 Job</a></td><td style=text-align:center>W</td><td style=text-align:center></td></tr><tr><td><a href=/zh-cn/docs/tasks/job/parallel-processing-expansion/>Job 模板扩展</a></td><td style=text-align:center>1</td><td style=text-align:center>应该为 1</td></tr></tbody></table><h2 id=advanced-usage>高级用法</h2><h3 id=suspending-a-job>挂起 Job</h3><div style=margin-top:10px;margin-bottom:10px><b>特性状态：</b> <code>Kubernetes v1.24 [stable]</code></div><p>Job 被创建时，Job 控制器会马上开始执行 Pod 创建操作以满足 Job 的需求，
并持续执行此操作直到 Job 完成为止。
不过你可能想要暂时挂起 Job 执行，或启动处于挂起状态的 Job，
并拥有一个自定义控制器以后再决定什么时候开始。</p><p>要挂起一个 Job，你可以更新 <code>.spec.suspend</code> 字段为 true，
之后，当你希望恢复其执行时，将其更新为 false。
创建一个 <code>.spec.suspend</code> 被设置为 true 的 Job 本质上会将其创建为被挂起状态。</p><p>当 Job 被从挂起状态恢复执行时，其 <code>.status.startTime</code> 字段会被重置为当前的时间。
这意味着 <code>.spec.activeDeadlineSeconds</code> 计时器会在 Job 挂起时被停止，
并在 Job 恢复执行时复位。</p><p>当你挂起一个 Job 时，所有正在运行且状态不是 <code>Completed</code> 的 Pod
将被<a href=/zh-cn/docs/concepts/workloads/pods/pod-lifecycle/#pod-termination>终止</a>。
Pod 的体面终止期限会被考虑，不过 Pod 自身也必须在此期限之内处理完信号。
处理逻辑可能包括保存进度以便将来恢复，或者取消已经做出的变更等等。
Pod 以这种形式终止时，不会被记入 Job 的 <code>completions</code> 计数。</p><p>处于被挂起状态的 Job 的定义示例可能是这样子：</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get job myjob -o yaml
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>batch/v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Job<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>myjob<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>suspend</span>:<span style=color:#bbb> </span><span style=color:#a2f;font-weight:700>true</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>parallelism</span>:<span style=color:#bbb> </span><span style=color:#666>1</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>completions</span>:<span style=color:#bbb> </span><span style=color:#666>5</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>template</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>...<span style=color:#bbb>
</span></span></span></code></pre></div><p>你也可以使用命令行为 Job 打补丁来切换 Job 的挂起状态。</p><p>挂起一个活跃的 Job：</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl patch job/myjob --type<span style=color:#666>=</span>strategic --patch <span style=color:#b44>&#39;{&#34;spec&#34;:{&#34;suspend&#34;:true}}&#39;</span>
</span></span></code></pre></div><p>恢复一个挂起的 Job：</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl patch job/myjob --type<span style=color:#666>=</span>strategic --patch <span style=color:#b44>&#39;{&#34;spec&#34;:{&#34;suspend&#34;:false}}&#39;</span>
</span></span></code></pre></div><p>Job 的 <code>status</code> 可以用来确定 Job 是否被挂起，或者曾经被挂起。</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get jobs/myjob -o yaml
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>batch/v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Job<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:#080;font-style:italic># .metadata 和 .spec 已省略</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>status</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>conditions</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>lastProbeTime</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;2021-02-05T13:14:33Z&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>lastTransitionTime</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;2021-02-05T13:14:33Z&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>status</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;True&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>type</span>:<span style=color:#bbb> </span>Suspended<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>startTime</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;2021-02-05T13:13:48Z&#34;</span><span style=color:#bbb>
</span></span></span></code></pre></div><p>Job 的 "Suspended" 类型的状况在状态值为 "True" 时意味着 Job 正被挂起；
<code>lastTransitionTime</code> 字段可被用来确定 Job 被挂起的时长。
如果此状况字段的取值为 "False"，则 Job 之前被挂起且现在在运行。
如果 "Suspended" 状况在 <code>status</code> 字段中不存在，则意味着 Job 从未被停止执行。</p><p>当 Job 被挂起和恢复执行时，也会生成事件：</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl describe jobs/myjob
</span></span></code></pre></div><pre tabindex=0><code>Name:           myjob
...
Events:
  Type    Reason            Age   From            Message
  ----    ------            ----  ----            -------
  Normal  SuccessfulCreate  12m   job-controller  Created pod: myjob-hlrpl
  Normal  SuccessfulDelete  11m   job-controller  Deleted pod: myjob-hlrpl
  Normal  Suspended         11m   job-controller  Job suspended
  Normal  SuccessfulCreate  3s    job-controller  Created pod: myjob-jvb44
  Normal  Resumed           3s    job-controller  Job resumed
</code></pre><p>最后四个事件，特别是 "Suspended" 和 "Resumed" 事件，都是因为 <code>.spec.suspend</code>
字段值被改来改去造成的。在这两个事件之间，我们看到没有 Pod 被创建，不过当
Job 被恢复执行时，Pod 创建操作立即被重启执行。</p><h3 id=mutable-scheduling-directives>可变调度指令</h3><div style=margin-top:10px;margin-bottom:10px><b>特性状态：</b> <code>Kubernetes v1.23 [beta]</code></div><div class="alert alert-info note callout" role=alert><strong>说明：</strong><p>为了使用此功能，你必须在 <a href=/zh-cn/docs/reference/command-line-tools-reference/kube-apiserver/>API 服务器</a>上启用
<code>JobMutableNodeSchedulingDirectives</code> <a href=/zh-cn/docs/reference/command-line-tools-reference/feature-gates/>特性门控</a>。
默认情况下启用。</div><p>在大多数情况下，并行作业会希望 Pod 在一定约束条件下运行，
比如所有的 Pod 都在同一个区域，或者所有的 Pod 都在 GPU 型号 x 或 y 上，而不是两者的混合。</p><p><a href=#suspend-a-job>suspend</a> 字段是实现这些语义的第一步。
suspend 允许自定义队列控制器，以决定工作何时开始；然而，一旦工作被取消暂停，
自定义队列控制器对 Job 中 Pod 的实际放置位置没有影响。</p><p>此特性允许在 Job 开始之前更新调度指令，从而为定制队列提供影响 Pod
放置的能力，同时将 Pod 与节点间的分配关系留给 kube-scheduler 决定。
这一特性仅适用于之前从未被暂停过的、已暂停的 Job。
控制器能够影响 Pod 放置，同时参考实际 pod-to-node 分配给 kube-scheduler。
这仅适用于从未暂停的 Job。</p><p>Job 的 Pod 模板中可以更新的字段是节点亲和性、节点选择器、容忍、标签和注解。</p><h3 id=specifying-your-own-pod-selector>指定你自己的 Pod 选择算符</h3><p>通常，当你创建一个 Job 对象时，你不会设置 <code>.spec.selector</code>。
系统的默认值填充逻辑会在创建 Job 时添加此字段。
它会选择一个不会与任何其他 Job 重叠的选择算符设置。</p><p>不过，有些场合下，你可能需要重载这个自动设置的选择算符。
为了实现这点，你可以手动设置 Job 的 <code>spec.selector</code> 字段。</p><p>做这个操作时请务必小心。
如果你所设定的标签选择算符并不唯一针对 Job 对应的 Pod 集合，
甚或该算符还能匹配其他无关的 Pod，这些无关的 Job 的 Pod 可能会被删除。
或者当前 Job 会将另外一些 Pod 当作是完成自身工作的 Pod，
又或者两个 Job 之一或者二者同时都拒绝创建 Pod，无法运行至完成状态。
如果所设置的算符不具有唯一性，其他控制器（如 RC 副本控制器）及其所管理的 Pod
集合可能会变得行为不可预测。
Kubernetes 不会在你设置 <code>.spec.selector</code> 时尝试阻止你犯这类错误。</p><p>下面是一个示例场景，在这种场景下你可能会使用刚刚讲述的特性。</p><p>假定名为 <code>old</code> 的 Job 已经处于运行状态。
你希望已有的 Pod 继续运行，但你希望 Job 接下来要创建的其他 Pod
使用一个不同的 Pod 模板，甚至希望 Job 的名字也发生变化。
你无法更新现有的 Job，因为这些字段都是不可更新的。
因此，你会删除 <code>old</code> Job，但<strong>允许该 Job 的 Pod 集合继续运行</strong>。
这是通过 <code>kubectl delete jobs/old --cascade=orphan</code> 实现的。
在删除之前，我们先记下该 Job 所使用的选择算符。</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get job old -o yaml
</span></span></code></pre></div><p>输出类似于：</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Job<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>old<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>...<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>selector</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>matchLabels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>controller-uid</span>:<span style=color:#bbb> </span>a8f3d00d-c6d2-11e5-9f87-42010af00002<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>...<span style=color:#bbb>
</span></span></span></code></pre></div><p>接下来你会创建名为 <code>new</code> 的新 Job，并显式地为其设置相同的选择算符。
由于现有 Pod 都具有标签 <code>controller-uid=a8f3d00d-c6d2-11e5-9f87-42010af00002</code>，
它们也会被名为 <code>new</code> 的 Job 所控制。</p><p>你需要在新 Job 中设置 <code>manualSelector: true</code>，
因为你并未使用系统通常自动为你生成的选择算符。</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Job<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>new<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>...<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>manualSelector</span>:<span style=color:#bbb> </span><span style=color:#a2f;font-weight:700>true</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>selector</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>matchLabels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>controller-uid</span>:<span style=color:#bbb> </span>a8f3d00d-c6d2-11e5-9f87-42010af00002<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>...<span style=color:#bbb>
</span></span></span></code></pre></div><p>新的 Job 自身会有一个不同于 <code>a8f3d00d-c6d2-11e5-9f87-42010af00002</code> 的唯一 ID。
设置 <code>manualSelector: true</code>
是在告诉系统你知道自己在干什么并要求系统允许这种不匹配的存在。</p><h3 id=pod-failure-policy>Pod 失效策略</h3><div style=margin-top:10px;margin-bottom:10px><b>特性状态：</b> <code>Kubernetes v1.25 [alpha]</code></div><div class="alert alert-info note callout" role=alert><strong>说明：</strong><p>只有你在集群中启用了
<code>JobPodFailurePolicy</code> <a href=/zh-cn/docs/reference/command-line-tools-reference/feature-gates/>特性门控</a>
你才能为某个 Job 配置 Pod 失效策略。
此外，建议启用 <code>PodDisruptionConditions</code> 特性门控以便在 Pod 失效策略中检测和处理 Pod 干扰状况
（参考：<a href=/zh-cn/docs/concepts/workloads/pods/disruptions#pod-disruption-conditions>Pod 干扰状况</a>）。
这两个特性门控都是在 Kubernetes v1.25 中提供的。</div><p>Pod 失效策略使用 <code>.spec.podFailurePolicy</code> 字段来定义，
它能让你的集群根据容器的退出码和 Pod 状况来处理 Pod 失效事件。</p><p>在某些情况下，你可能希望更好地控制 Pod 失效的处理方式，
而不是仅限于 <a href=#pod-backoff-failure-policy>Pod 回退失效策略</a>所提供的控制能力，
后者是基于 Job 的 <code>.spec.backoffLimit</code> 实现的。以下是一些使用场景：</p><ul><li>通过避免不必要的 Pod 重启来优化工作负载的运行成本，
你可以在某 Job 中一个 Pod 失效且其退出码表明存在软件错误时立即终止该 Job。</li><li>为了保证即使有干扰也能完成 Job，你可以忽略由干扰导致的 Pod 失效
（例如<a class=glossary-tooltip title='Kubernetes 中的抢占逻辑通过驱逐节点上的低优先级 Pod 来帮助悬决的 Pod 找到合适的节点。' data-toggle=tooltip data-placement=top href=/zh-cn/docs/concepts/scheduling-eviction/pod-priority-preemption/#preemption target=_blank aria-label=抢占>抢占</a>、
<a class=glossary-tooltip title='API 发起的驱逐是一个先调用 Eviction API 创建驱逐对象，再由该对象体面地中止 Pod 的过程。' data-toggle=tooltip data-placement=top href=/zh-cn/docs/concepts/scheduling-eviction/api-eviction/ target=_blank aria-label='通过 API 发起的驱逐'>通过 API 发起的驱逐</a>
或基于<a class=glossary-tooltip title='污点是一种一个核心对象，包含三个必需的属性：key、value 和 effect。 污点会阻止在节点或节点组上调度 Pod。' data-toggle=tooltip data-placement=top href=/zh-cn/docs/concepts/scheduling-eviction/taint-and-toleration/ target=_blank aria-label=污点>污点</a>的驱逐），
这样这些失效就不会被计入 <code>.spec.backoffLimit</code> 的重试限制中。</li></ul><p>你可以在 <code>.spec.podFailurePolicy</code> 字段中配置 Pod 失效策略，以满足上述使用场景。
该策略可以根据容器退出码和 Pod 状况来处理 Pod 失效。</p><p>下面是一个定义了 <code>podFailurePolicy</code> 的 Job 的清单：</p><div class=highlight><div class=copy-code-icon style=text-align:right><a href=https://raw.githubusercontent.com/kubernetes/website/main/content/zh-cn/examples/controllers/job-pod-failure-policy-example.yaml download=controllers/job-pod-failure-policy-example.yaml><code>controllers/job-pod-failure-policy-example.yaml</code></a>
<img src=/images/copycode.svg style=max-height:24px;cursor:pointer onclick='copyCode("controllers-job-pod-failure-policy-example-yaml")' title="Copy controllers/job-pod-failure-policy-example.yaml to clipboard"></img></div><div class=includecode id=controllers-job-pod-failure-policy-example-yaml><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>batch/v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Job<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>job-pod-failure-policy-example<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>completions</span>:<span style=color:#bbb> </span><span style=color:#666>12</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>parallelism</span>:<span style=color:#bbb> </span><span style=color:#666>3</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>template</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>restartPolicy</span>:<span style=color:#bbb> </span>Never<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>main<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>docker.io/library/bash:5<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>command</span>:<span style=color:#bbb> </span>[<span style=color:#b44>&#34;bash&#34;</span>]<span style=color:#bbb>        </span><span style=color:#080;font-style:italic># 模拟一个触发 FailJob 动作的错误的示例命令</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>args</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span>- -c<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span>- echo &#34;Hello world!&#34; &amp;&amp; sleep 5 &amp;&amp; exit 42<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>backoffLimit</span>:<span style=color:#bbb> </span><span style=color:#666>6</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>podFailurePolicy</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>rules</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:green;font-weight:700>action</span>:<span style=color:#bbb> </span>FailJob<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>onExitCodes</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>containerName</span>:<span style=color:#bbb> </span>main     <span style=color:#bbb> </span><span style=color:#080;font-style:italic># 可选</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>operator</span>:<span style=color:#bbb> </span>In            <span style=color:#bbb> </span><span style=color:#080;font-style:italic># In 和 NotIn 二选一</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>values</span>:<span style=color:#bbb> </span>[<span style=color:#666>42</span>]<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:green;font-weight:700>action</span>:<span style=color:#bbb> </span>Ignore            <span style=color:#bbb> </span><span style=color:#080;font-style:italic># Ignore、FailJob、Count 其中之一</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>onPodConditions</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- <span style=color:green;font-weight:700>type</span>:<span style=color:#bbb> </span>DisruptionTarget  <span style=color:#bbb> </span><span style=color:#080;font-style:italic># 表示 Pod 失效</span><span style=color:#bbb>
</span></span></span></code></pre></div></div></div><p>在上面的示例中，Pod 失效策略的第一条规则规定如果 <code>main</code> 容器失败并且退出码为 42，
Job 将被标记为失败。以下是 <code>main</code> 容器的具体规则：</p><ul><li>退出码 0 代表容器成功</li><li>退出码 42 代表 <strong>整个 Job</strong> 失败</li><li>所有其他退出码都代表容器失败，同时也代表着整个 Pod 失效。
如果重启总次数低于 <code>backoffLimit</code> 定义的次数，则会重新启动 Pod，
如果等于 <code>backoffLimit</code> 所设置的次数，则代表 <strong>整个 Job</strong> 失效。</li></ul><div class="alert alert-info note callout" role=alert><strong>说明：</strong><p>因为 Pod 模板中指定了 <code>restartPolicy: Never</code>，
所以 kubelet 将不会重启 Pod 中的 <code>main</code> 容器。</div><p>Pod 失效策略的第二条规则，
指定对于状况为 <code>DisruptionTarget</code> 的失效 Pod 采取 <code>Ignore</code> 操作，
统计 <code>.spec.backoffLimit</code> 重试次数限制时不考虑 Pod 因干扰而发生的异常。<div class="alert alert-info note callout" role=alert><strong>说明：</strong><p>如果根据 Pod 失效策略或 Pod 回退失效策略判定 Pod 已经失效，
并且 Job 正在运行多个 Pod，Kubernetes 将终止该 Job 中仍处于 Pending 或 Running 的所有 Pod。</div></p><p>下面是此 API 的一些要求和语义：</p><ul><li>如果你想在 Job 中使用 <code>.spec.podFailurePolicy</code> 字段，
你必须将 Job 的 Pod 模板中的 <code>.spec.restartPolicy</code> 设置为 <code>Never</code>。</li><li>在 <code>spec.podFailurePolicy.rules</code> 中设定的 Pod 失效策略规则将按序评估。
一旦某个规则与 Pod 失效策略匹配，其余规则将被忽略。
当没有规则匹配 Pod 失效策略时，将会采用默认的处理方式。</li><li>你可能希望在 <code>spec.podFailurePolicy.rules[*].containerName</code>
中通过指定的名称将规则限制到特定容器。
如果不设置，规则将适用于所有容器。
如果指定了容器名称，它应该匹配 Pod 模板中的一个普通容器或一个初始容器（Init Container）。</li><li>你可以在 <code>spec.podFailurePolicy.rules[*].action</code> 指定当 Pod 失效策略发生匹配时要采取的操作。
可能的值为：<ul><li><code>FailJob</code>：表示 Pod 的任务应标记为 Failed，并且所有正在运行的 Pod 应被终止。</li><li><code>Ignore</code>：表示 <code>.spec.backoffLimit</code> 的计数器不应该增加，应该创建一个替换的 Pod。</li><li><code>Count</code>：表示 Pod 应该以默认方式处理。<code>.spec.backoffLimit</code> 的计数器应该增加。</li></ul></li></ul><h3 id=job-tracking-with-finalizers>使用 Finalizer 追踪 Job</h3><div style=margin-top:10px;margin-bottom:10px><b>特性状态：</b> <code>Kubernetes v1.23 [beta]</code></div><div class="alert alert-info note callout" role=alert><strong>说明：</strong><p>要使用该行为，你必须为 <a href=/zh-cn/docs/reference/command-line-tools-reference/kube-apiserver/>API 服务器</a>
和<a href=/zh-cn/docs/reference/command-line-tools-reference/kube-controller-manager/>控制器管理器</a>
启用 <code>JobTrackingWithFinalizers</code>
<a href=/zh-cn/docs/reference/command-line-tools-reference/feature-gates/>特性门控</a>。
默认是启用的。</p><p>启用后，控制面基于下述行为追踪新的 Job。在启用该特性之前创建的 Job 不受影响。
作为用户，你会看到的唯一区别是控制面对 Job 完成情况的跟踪更加准确。</p></div><p>该功能未启用时，Job <a class=glossary-tooltip title='控制器通过 API 服务器监控集群的公共状态，并致力于将当前状态转变为期望的状态。' data-toggle=tooltip data-placement=top href=/zh-cn/docs/concepts/architecture/controller/ target=_blank aria-label=控制器（Controller）>控制器（Controller）</a> 依靠计算集群中存在的 Pod 来跟踪作业状态。
也就是说，维持一个统计 <code>succeeded</code> 和 <code>failed</code> 的 Pod 的计数器。
然而，Pod 可以因为一些原因被移除，包括：</p><ul><li>当一个节点宕机时，垃圾收集器会删除孤立（Orphan）Pod。</li><li>垃圾收集器在某个阈值后删除已完成的 Pod（处于 <code>Succeeded</code> 或 <code>Failed</code> 阶段）。</li><li>人工干预删除 Job 的 Pod。</li><li>一个外部控制器（不包含于 Kubernetes）来删除或取代 Pod。</li></ul><p>如果你为你的集群启用了 <code>JobTrackingWithFinalizers</code> 特性，控制面会跟踪属于任何 Job 的 Pod。
并注意是否有任何这样的 Pod 被从 API 服务器上删除。
为了实现这一点，Job 控制器创建的 Pod 带有 Finalizer <code>batch.kubernetes.io/job-tracking</code>。
控制器只有在 Pod 被记入 Job 状态后才会移除 Finalizer，允许 Pod 可以被其他控制器或用户删除。</p><p>Job 控制器只对新的 Job 使用新的算法。在启用该特性之前创建的 Job 不受影响。
你可以根据检查 Job 是否含有 <code>batch.kubernetes.io/job-tracking</code> 注解，
来确定 Job 控制器是否正在使用 Pod Finalizer 追踪 Job。
你<strong>不</strong>应该给 Job 手动添加或删除该注解。</p><h2 id=alternatives>替代方案</h2><h3 id=bare-pods>裸 Pod</h3><p>当 Pod 运行所在的节点重启或者失败，Pod 会被终止并且不会被重启。
Job 会重新创建新的 Pod 来替代已终止的 Pod。
因为这个原因，我们建议你使用 Job 而不是独立的裸 Pod，
即使你的应用仅需要一个 Pod。</p><h3 id=replication-controller>副本控制器</h3><p>Job 与<a href=/zh-cn/docs/concepts/workloads/controllers/replicationcontroller/>副本控制器</a>是彼此互补的。
副本控制器管理的是那些不希望被终止的 Pod （例如，Web 服务器），
Job 管理的是那些希望被终止的 Pod（例如，批处理作业）。</p><p>正如在 <a href=/zh-cn/docs/concepts/workloads/pods/pod-lifecycle/>Pod 生命期</a> 中讨论的，
<code>Job</code> 仅适合于 <code>restartPolicy</code> 设置为 <code>OnFailure</code> 或 <code>Never</code> 的 Pod。
注意：如果 <code>restartPolicy</code> 未设置，其默认值是 <code>Always</code>。</p><h3 id=single-job-starts-controller-pod>单个 Job 启动控制器 Pod</h3><p>另一种模式是用唯一的 Job 来创建 Pod，而该 Pod 负责启动其他 Pod，
因此扮演了一种后启动 Pod 的控制器的角色。
这种模式的灵活性更高，但是有时候可能会把事情搞得很复杂，很难入门，
并且与 Kubernetes 的集成度很低。</p><p>这种模式的实例之一是用 Job 来启动一个运行脚本的 Pod，脚本负责启动 Spark
主控制器（参见 <a href=https://github.com/kubernetes/examples/tree/master/staging/spark/README.md>Spark 示例</a>），
运行 Spark 驱动，之后完成清理工作。</p><p>这种方法的优点之一是整个过程得到了 Job 对象的完成保障，
同时维持了对创建哪些 Pod、如何向其分派工作的完全控制能力，</p><h2 id=接下来>接下来</h2><ul><li>了解 <a href=/zh-cn/docs/concepts/workloads/pods>Pod</a>。</li><li>了解运行 Job 的不同的方式：<ul><li><a href=/zh-cn/docs/tasks/job/coarse-parallel-processing-work-queue/>使用工作队列进行粗粒度并行处理</a></li><li><a href=/zh-cn/docs/tasks/job/fine-parallel-processing-work-queue/>使用工作队列进行精细的并行处理</a></li><li><a href=/zh-cn/docs/tasks/job/indexed-parallel-processing-static/>使用索引作业完成静态工作分配下的并行处理</a></li><li>基于一个模板运行多个 Job：<a href=/zh-cn/docs/tasks/job/parallel-processing-expansion/>使用展开的方式进行并行处理</a></li></ul></li><li>跟随<a href=#clean-up-finished-jobs-automatically>自动清理完成的 Job</a> 文中的链接，了解你的集群如何清理完成和失败的任务。</li><li><code>Job</code> 是 Kubernetes REST API 的一部分。阅读
<a href=/zh-cn/docs/reference/kubernetes-api/workload-resources/job-v1/></a>
对象定义理解关于该资源的 API。</li><li>阅读 <a href=/zh-cn/docs/concepts/workloads/controllers/cron-jobs/><code>CronJob</code></a>，它允许你定义一系列定期运行的 Job，类似于 UNIX 工具 <code>cron</code>。</li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-4de50a37ebb6f2340484192126cb7a04>2.6 - 已完成 Job 的自动清理</h1><div style=margin-top:10px;margin-bottom:10px><b>特性状态：</b> <code>Kubernetes v1.23 [stable]</code></div><p>TTL-after-finished <a class=glossary-tooltip title='控制器通过 API 服务器监控集群的公共状态，并致力于将当前状态转变为期望的状态。' data-toggle=tooltip data-placement=top href=/zh-cn/docs/concepts/architecture/controller/ target=_blank aria-label=控制器>控制器</a> 提供了一种 TTL 机制来限制已完成执行的资源对象的生命周期。
TTL 控制器目前只处理 <a class=glossary-tooltip title='Job 是需要运行完成的确定性的或批量的任务。' data-toggle=tooltip data-placement=top href=/zh-cn/docs/concepts/workloads/controllers/job/ target=_blank aria-label=Job>Job</a>。</p><h2 id=ttl-after-finished-控制器>TTL-after-finished 控制器</h2><p>TTL-after-finished 控制器只支持 Job。集群操作员可以通过指定 Job 的 <code>.spec.ttlSecondsAfterFinished</code>
字段来自动清理已结束的作业（<code>Complete</code> 或 <code>Failed</code>），如
<a href=/zh-cn/docs/concepts/workloads/controllers/job/#clean-up-finished-jobs-automatically>示例</a>
所示。</p><p>TTL-after-finished 控制器假设作业能在执行完成后的 TTL 秒内被清理，也就是当 TTL 过期后。
当 TTL 控制器清理作业时，它将做级联删除操作，即删除资源对象的同时也删除其依赖对象。
注意，当资源被删除时，由该资源的生命周期保证其终结器（Finalizers）等被执行。</p><p>可以随时设置 TTL 秒。以下是设置 Job 的 <code>.spec.ttlSecondsAfterFinished</code> 字段的一些示例：</p><ul><li>在作业清单（manifest）中指定此字段，以便 Job 在完成后的某个时间被自动清除。</li><li>将此字段设置为现有的、已完成的作业，以采用此新功能。</li><li>在创建作业时使用 <a href=/zh-cn/docs/reference/access-authn-authz/extensible-admission-controllers/#admission-webhooks>mutating admission webhook</a>
动态设置该字段。集群管理员可以使用它对完成的作业强制执行 TTL 策略。</li><li>使用 <a href=/zh-cn/docs/reference/access-authn-authz/extensible-admission-controllers/#admission-webhooks>mutating admission webhook</a>
在作业完成后动态设置该字段，并根据作业状态、标签等选择不同的 TTL 值。</li></ul><h2 id=警告>警告</h2><h3 id=更新-ttl-秒数>更新 TTL 秒数</h3><p>请注意，在创建 Job 或已经执行结束后，仍可以修改其 TTL 周期，例如 Job 的
<code>.spec.ttlSecondsAfterFinished</code> 字段。
但是一旦 Job 变为可被删除状态（当其 TTL 已过期时），即使你通过 API 增加其 TTL
时长得到了成功的响应，系统也不保证 Job 将被保留。</p><h3 id=time-skew>时间偏差</h3><p>由于 TTL-after-finished 控制器使用存储在 Kubernetes 资源中的时间戳来确定 TTL 是否已过期，
因此该功能对集群中的时间偏差很敏感，这可能导致 TTL-after-finished 控制器在错误的时间清理资源对象。</p><p>时钟并不总是如此正确，但差异应该很小。
设置非零 TTL 时请注意避免这种风险。</p><h2 id=接下来>接下来</h2><ul><li><a href=/zh-cn/docs/concepts/workloads/controllers/job/#clean-up-finished-jobs-automatically>自动清理 Job</a></li><li><a href=https://github.com/kubernetes/enhancements/blob/master/keps/sig-apps/592-ttl-after-finish/README.md>设计文档</a></li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-2e4cec01c525b45eccd6010e21cc76d9>2.7 - CronJob</h1><div style=margin-top:10px;margin-bottom:10px><b>特性状态：</b> <code>Kubernetes v1.21 [stable]</code></div><p><em>CronJob</em> 创建基于时隔重复调度的 <a class=glossary-tooltip title='Job 是需要运行完成的确定性的或批量的任务。' data-toggle=tooltip data-placement=top href=/zh-cn/docs/concepts/workloads/controllers/job/ target=_blank aria-label=Jobs>Jobs</a>。</p><p>一个 CronJob 对象就像 <em>crontab</em> (cron table) 文件中的一行。
它用 <a href=https://en.wikipedia.org/wiki/Cron>Cron</a> 格式进行编写，
并周期性地在给定的调度时间执行 Job。</p><div class="alert alert-warning caution callout" role=alert><strong>注意：</strong><p>所有 <strong>CronJob</strong> 的 <code>schedule:</code> 时间都是基于
<a class=glossary-tooltip title=主节点上运行控制器的组件。 data-toggle=tooltip data-placement=top href=/zh-cn/docs/reference/command-line-tools-reference/kube-controller-manager/ target=_blank aria-label=kube-controller-manager>kube-controller-manager</a>.
的时区。</p><p>如果你的控制平面在 Pod 或是裸容器中运行了 kube-controller-manager，
那么为该容器所设置的时区将会决定 Cron Job 的控制器所使用的时区。</p></div><div class="alert alert-warning caution callout" role=alert><strong>注意：</strong><p>如 <a href=/zh-cn/docs/reference/kubernetes-api/workload-resources/cron-job-v1/>v1 CronJob API</a> 所述，官方并不支持设置时区。</p><p>Kubernetes 项目官方并不支持设置如 <code>CRON_TZ</code> 或者 <code>TZ</code> 等变量。
<code>CRON_TZ</code> 或者 <code>TZ</code> 是用于解析和计算下一个 Job 创建时间所使用的内部库中一个实现细节。
不建议在生产集群中使用它。</p></div><p>为 CronJob 资源创建清单时，请确保所提供的名称是一个合法的
<a href=/zh-cn/docs/concepts/overview/working-with-objects/names#dns-subdomain-names>DNS 子域名</a>。
名称不能超过 52 个字符。
这是因为 CronJob 控制器将自动在提供的 Job 名称后附加 11 个字符，并且存在一个限制，
即 Job 名称的最大长度不能超过 63 个字符。</p><h2 id=cronjob>CronJob</h2><p>CronJob 用于执行周期性的动作，例如备份、报告生成等。
这些任务中的每一个都应该配置为周期性重复的（例如：每天/每周/每月一次）；
你可以定义任务开始执行的时间间隔。</p><h3 id=example>示例</h3><p>下面的 CronJob 示例清单会在每分钟打印出当前时间和问候消息：</p><div class=highlight><div class=copy-code-icon style=text-align:right><a href=https://raw.githubusercontent.com/kubernetes/website/main/content/zh-cn/examples/application/job/cronjob.yaml download=application/job/cronjob.yaml><code>application/job/cronjob.yaml</code></a>
<img src=/images/copycode.svg style=max-height:24px;cursor:pointer onclick='copyCode("application-job-cronjob-yaml")' title="Copy application/job/cronjob.yaml to clipboard"></img></div><div class=includecode id=application-job-cronjob-yaml><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>batch/v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>CronJob<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>hello<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>schedule</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;* * * * *&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>jobTemplate</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>template</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>hello<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>            </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>busybox:1.28<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>            </span><span style=color:green;font-weight:700>imagePullPolicy</span>:<span style=color:#bbb> </span>IfNotPresent<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>            </span><span style=color:green;font-weight:700>command</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>            </span>- /bin/sh<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>            </span>- -c<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>            </span>- date; echo Hello from the Kubernetes cluster<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>restartPolicy</span>:<span style=color:#bbb> </span>OnFailure<span style=color:#bbb>
</span></span></span></code></pre></div></div></div><p><a href=/zh-cn/docs/tasks/job/automated-tasks-with-cron-jobs/>使用 CronJob 运行自动化任务</a>
一文会为你详细讲解此例。</p><h3 id=cron-schedule-syntax>Cron 时间表语法</h3><pre tabindex=0><code># ┌───────────── 分钟 (0 - 59)
# │ ┌───────────── 小时 (0 - 23)
# │ │ ┌───────────── 月的某天 (1 - 31)
# │ │ │ ┌───────────── 月份 (1 - 12)
# │ │ │ │ ┌───────────── 周的某天 (0 - 6)（周日到周一；在某些系统上，7 也是星期日）
# │ │ │ │ │                          或者是 sun，mon，tue，web，thu，fri，sat
# │ │ │ │ │
# │ │ │ │ │
# * * * * *
</code></pre><table><thead><tr><th>输入</th><th>描述</th><th>相当于</th></tr></thead><tbody><tr><td>@yearly (or @annually)</td><td>每年 1 月 1 日的午夜运行一次</td><td>0 0 1 1 *</td></tr><tr><td>@monthly</td><td>每月第一天的午夜运行一次</td><td>0 0 1 * *</td></tr><tr><td>@weekly</td><td>每周的周日午夜运行一次</td><td>0 0 * * 0</td></tr><tr><td>@daily (or @midnight)</td><td>每天午夜运行一次</td><td>0 0 * * *</td></tr><tr><td>@hourly</td><td>每小时的开始一次</td><td>0 * * * *</td></tr></tbody></table><p>例如，下面这行指出必须在每个星期五的午夜以及每个月 13 号的午夜开始任务：</p><p><code>0 0 13 * 5</code></p><p>要生成 CronJob 时间表表达式，你还可以使用 <a href=https://crontab.guru/>crontab.guru</a> 之类的 Web 工具。</p><h2 id=time-zones>时区</h2><p>对于没有指定时区的 CronJob，kube-controller-manager 基于本地时区解释排期表（Schedule）。</p><div style=margin-top:10px;margin-bottom:10px><b>特性状态：</b> <code>Kubernetes v1.25 [beta]</code></div><p>如果启用了 <code>CronJobTimeZone</code> <a href=/zh-cn/docs/reference/command-line-tools-reference/feature-gates/>特性门控</a>，
你可以为 CronJob 指定一个时区（如果你没有启用该特性门控，或者你使用的是不支持试验性时区功能的
Kubernetes 版本，集群中所有 CronJob 的时区都是未指定的）。</p><p>启用该特性后，你可以将 <code>spec.timeZone</code>
设置为有效<a href=https://zh.wikipedia.org/wiki/%E6%97%B6%E5%8C%BA%E4%BF%A1%E6%81%AF%E6%95%B0%E6%8D%AE%E5%BA%93>时区</a>名称。
例如，设置 <code>spec.timeZone: "Etc/UTC"</code> 指示 Kubernetes 采用 UTC 来解释排期表。</p><p>Go 标准库中的时区数据库包含在二进制文件中，并用作备用数据库，以防系统上没有可用的外部数据库。</p><h2 id=cronjob-limitations>CronJob 限制</h2><p>CronJob 根据其计划编排，在每次该执行任务的时候大约会创建一个 Job。
我们之所以说 "大约"，是因为在某些情况下，可能会创建两个 Job，或者不会创建任何 Job。
我们试图使这些情况尽量少发生，但不能完全杜绝。因此，Job 应该是 <em>幂等的</em>。</p><p>如果 <code>startingDeadlineSeconds</code> 设置为很大的数值或未设置（默认），并且
<code>concurrencyPolicy</code> 设置为 <code>Allow</code>，则作业将始终至少运行一次。</p><div class="alert alert-warning caution callout" role=alert><strong>注意：</strong><p>如果 <code>startingDeadlineSeconds</code> 的设置值低于 10 秒钟，CronJob 可能无法被调度。
这是因为 CronJob 控制器每 10 秒钟执行一次检查。</div><p>对于每个 CronJob，CronJob <a class=glossary-tooltip title='控制器通过 API 服务器监控集群的公共状态，并致力于将当前状态转变为期望的状态。' data-toggle=tooltip data-placement=top href=/zh-cn/docs/concepts/architecture/controller/ target=_blank aria-label=控制器（Controller）>控制器（Controller）</a>
检查从上一次调度的时间点到现在所错过了调度次数。如果错过的调度次数超过 100 次，
那么它就不会启动这个任务，并记录这个错误:</p><pre tabindex=0><code>Cannot determine if job needs to be started. Too many missed start time (&gt; 100). Set or decrease .spec.startingDeadlineSeconds or check clock skew.
</code></pre><p>需要注意的是，如果 <code>startingDeadlineSeconds</code> 字段非空，则控制器会统计从
<code>startingDeadlineSeconds</code> 设置的值到现在而不是从上一个计划时间到现在错过了多少次 Job。
例如，如果 <code>startingDeadlineSeconds</code> 是 <code>200</code>，则控制器会统计在过去 200 秒中错过了多少次 Job。</p><p>如果未能在调度时间内创建 CronJob，则计为错过。
例如，如果 <code>concurrencyPolicy</code> 被设置为 <code>Forbid</code>，并且当前有一个调度仍在运行的情况下，
试图调度的 CronJob 将被计算为错过。</p><p>例如，假设一个 CronJob 被设置为从 <code>08:30:00</code> 开始每隔一分钟创建一个新的 Job，
并且它的 <code>startingDeadlineSeconds</code> 字段未被设置。如果 CronJob 控制器从
<code>08:29:00</code> 到 <code>10:21:00</code> 终止运行，则该 Job 将不会启动，因为其错过的调度
次数超过了 100。</p><p>为了进一步阐述这个概念，假设将 CronJob 设置为从 <code>08:30:00</code> 开始每隔一分钟创建一个新的 Job，
并将其 <code>startingDeadlineSeconds</code> 字段设置为 200 秒。
如果 CronJob 控制器恰好在与上一个示例相同的时间段（<code>08:29:00</code> 到 <code>10:21:00</code>）终止运行，
则 Job 仍将从 <code>10:22:00</code> 开始。
造成这种情况的原因是控制器现在检查在最近 200 秒（即 3 个错过的调度）中发生了多少次错过的
Job 调度，而不是从现在为止的最后一个调度时间开始。</p><p>CronJob 仅负责创建与其调度时间相匹配的 Job，而 Job 又负责管理其代表的 Pod。</p><h2 id=new-controller>控制器版本</h2><p>从 Kubernetes v1.21 版本开始，CronJob 控制器的第二个版本被用作默认实现。
要禁用此默认 CronJob 控制器而使用原来的 CronJob 控制器，请在
<a class=glossary-tooltip title=主节点上运行控制器的组件。 data-toggle=tooltip data-placement=top href=/zh-cn/docs/reference/command-line-tools-reference/kube-controller-manager/ target=_blank aria-label=kube-controller-manager>kube-controller-manager</a>
中设置<a href=/zh-cn/docs/reference/command-line-tools-reference/feature-gates/>特性门控</a>
<code>CronJobControllerV2</code>，将此标志设置为 <code>false</code>。例如：</p><pre tabindex=0><code>--feature-gates=&#34;CronJobControllerV2=false&#34;
</code></pre><h2 id=接下来>接下来</h2><ul><li>了解 CronJob 所依赖的 <a href=/zh-cn/docs/concepts/workloads/pods/>Pod</a> 与 <a href=/zh-cn/docs/concepts/workloads/controllers/job/>Job</a> 的概念。</li><li>阅读 CronJob <code>.spec.schedule</code> 字段的<a href=https://pkg.go.dev/github.com/robfig/cron/v3#hdr-CRON_Expression_Format>格式</a>。</li><li>有关创建和使用 CronJob 的说明及示例规约文件，请参见
<a href=/zh-cn/docs/tasks/job/automated-tasks-with-cron-jobs/>使用 CronJob 运行自动化任务</a>。</li><li>有关自动清理失败或完成作业的说明，请参阅<a href=/zh-cn/docs/concepts/workloads/controllers/job/#clean-up-finished-jobs-automatically>自动清理作业</a></li><li><code>CronJob</code> 是 Kubernetes REST API 的一部分，
阅读
<a href=/zh-cn/docs/reference/kubernetes-api/workload-resources/cron-job-v1/>CronJob</a>
对象定义以了解关于该资源的 API。</li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-27f1331d515d95f76aa1156088b4ad91>2.8 - ReplicationController</h1><div class="alert alert-info note callout" role=alert><strong>说明：</strong><p>现在推荐使用配置 <a href=/zh-cn/docs/concepts/workloads/controllers/replicaset/><code>ReplicaSet</code></a> 的
<a href=/zh-cn/docs/concepts/workloads/controllers/deployment/><code>Deployment</code></a> 来建立副本管理机制。</div><p><strong>ReplicationController</strong> 确保在任何时候都有特定数量的 Pod 副本处于运行状态。
换句话说，ReplicationController 确保一个 Pod 或一组同类的 Pod 总是可用的。</p><h2 id=how-a-replicationcontroller-works>ReplicationController 如何工作</h2><p>当 Pod 数量过多时，ReplicationController 会终止多余的 Pod。当 Pod 数量太少时，ReplicationController 将会启动新的 Pod。
与手动创建的 Pod 不同，由 ReplicationController 创建的 Pod 在失败、被删除或被终止时会被自动替换。
例如，在中断性维护（如内核升级）之后，你的 Pod 会在节点上重新创建。
因此，即使你的应用程序只需要一个 Pod，你也应该使用 ReplicationController 创建 Pod。
ReplicationController 类似于进程管理器，但是 ReplicationController 不是监控单个节点上的单个进程，而是监控跨多个节点的多个 Pod。</p><p>在讨论中，ReplicationController 通常缩写为 "rc"，并作为 kubectl 命令的快捷方式。</p><p>一个简单的示例是创建一个 ReplicationController 对象来可靠地无限期地运行 Pod 的一个实例。
更复杂的用例是运行一个多副本服务（如 web 服务器）的若干相同副本。</p><h2 id=running-an-example-replicationcontroller>运行一个示例 ReplicationController</h2><p>这个示例 ReplicationController 配置运行 nginx Web 服务器的三个副本。</p><div class=highlight><div class=copy-code-icon style=text-align:right><a href=https://raw.githubusercontent.com/kubernetes/website/main/content/zh-cn/examples/controllers/replication.yaml download=controllers/replication.yaml><code>controllers/replication.yaml</code></a>
<img src=/images/copycode.svg style=max-height:24px;cursor:pointer onclick='copyCode("controllers-replication-yaml")' title="Copy controllers/replication.yaml to clipboard"></img></div><div class=includecode id=controllers-replication-yaml><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>ReplicationController<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>nginx<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>replicas</span>:<span style=color:#bbb> </span><span style=color:#666>3</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>selector</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>app</span>:<span style=color:#bbb> </span>nginx<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>template</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>nginx<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>labels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>app</span>:<span style=color:#bbb> </span>nginx<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>nginx<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>nginx<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>ports</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span>- <span style=color:green;font-weight:700>containerPort</span>:<span style=color:#bbb> </span><span style=color:#666>80</span><span style=color:#bbb>
</span></span></span></code></pre></div></div></div><p>通过下载示例文件并运行以下命令来运行示例任务:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl apply -f https://k8s.io/examples/controllers/replication.yaml
</span></span></code></pre></div><p>输出类似于：</p><pre tabindex=0><code>replicationcontroller/nginx created
</code></pre><p>使用以下命令检查 ReplicationController 的状态:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl describe replicationcontrollers/nginx
</span></span></code></pre></div><p>输出类似于：</p><pre tabindex=0><code>Name:        nginx
Namespace:   default
Selector:    app=nginx
Labels:      app=nginx
Annotations:    &lt;none&gt;
Replicas:    3 current / 3 desired
Pods Status: 0 Running / 3 Waiting / 0 Succeeded / 0 Failed
Pod Template:
  Labels:       app=nginx
  Containers:
   nginx:
    Image:              nginx
    Port:               80/TCP
    Environment:        &lt;none&gt;
    Mounts:             &lt;none&gt;
  Volumes:              &lt;none&gt;
Events:
  FirstSeen       LastSeen     Count    From                        SubobjectPath    Type      Reason              Message
  ---------       --------     -----    ----                        -------------    ----      ------              -------
  20s             20s          1        {replication-controller }                    Normal    SuccessfulCreate    Created pod: nginx-qrm3m
  20s             20s          1        {replication-controller }                    Normal    SuccessfulCreate    Created pod: nginx-3ntk0
  20s             20s          1        {replication-controller }                    Normal    SuccessfulCreate    Created pod: nginx-4ok8v
</code></pre><p>在这里，创建了三个 Pod，但没有一个 Pod 正在运行，这可能是因为正在拉取镜像。
稍后，相同的命令可能会显示：</p><pre tabindex=0><code>Pods Status:    3 Running / 0 Waiting / 0 Succeeded / 0 Failed
</code></pre><p>要以机器可读的形式列出属于 ReplicationController 的所有 Pod，可以使用如下命令：</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span><span style=color:#b8860b>pods</span><span style=color:#666>=</span><span style=color:#a2f;font-weight:700>$(</span>kubectl get pods --selector<span style=color:#666>=</span><span style=color:#b8860b>app</span><span style=color:#666>=</span>nginx --output<span style=color:#666>=</span><span style=color:#b8860b>jsonpath</span><span style=color:#666>={</span>.items..metadata.name<span style=color:#666>}</span><span style=color:#a2f;font-weight:700>)</span>
</span></span><span style=display:flex><span><span style=color:#a2f>echo</span> <span style=color:#b8860b>$pods</span>
</span></span></code></pre></div><p>输出类似于：</p><pre tabindex=0><code>nginx-3ntk0 nginx-4ok8v nginx-qrm3m
</code></pre><p>这里，选择算符与 ReplicationController 的选择算符相同（参见 <code>kubectl describe</code> 输出），并以不同的形式出现在 <code>replication.yaml</code> 中。
<code>--output=jsonpath</code> 选项指定了一个表达式，仅从返回列表中的每个 Pod 中获取名称。</p><h2 id=writing-a-replicationcontroller-spec>编写一个 ReplicationController 规约</h2><p>与所有其它 Kubernetes 配置一样，ReplicationController 需要 <code>apiVersion</code>、<code>kind</code> 和 <code>metadata</code> 字段。
ReplicationController 对象的名称必须是有效的
<a href=/zh-cn/docs/concepts/overview/working-with-objects/names#dns-subdomain-names>DNS 子域名</a>。
有关使用配置文件的常规信息，
参考<a href=/zh-cn/docs/concepts/overview/working-with-objects/object-management/>对象管理</a>。</p><p>ReplicationController 也需要一个 <a href=https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#spec-and-status><code>.spec</code> 部分</a>。</p><h3 id=pod-template>Pod 模板</h3><p><code>.spec.template</code> 是 <code>.spec</code> 的唯一必需字段。</p><p><code>.spec.template</code> 是一个 <a href=/zh-cn/docs/concepts/workloads/pods/#pod-templates>Pod 模板</a>。
它的模式与 <a class=glossary-tooltip title='Pod 表示你的集群上一组正在运行的容器。' data-toggle=tooltip data-placement=top href=/zh-cn/docs/concepts/workloads/pods/ target=_blank aria-label=Pod>Pod</a> 完全相同，只是它是嵌套的，没有 <code>apiVersion</code> 或 <code>kind</code> 属性。</p><p>除了 Pod 所需的字段外，ReplicationController 中的 Pod 模板必须指定适当的标签和适当的重新启动策略。
对于标签，请确保不与其他控制器重叠。参考 <a href=#pod-selector>Pod 选择算符</a>。</p><p>只允许 <a href=/zh-cn/docs/concepts/workloads/pods/pod-lifecycle/#restart-policy><code>.spec.template.spec.restartPolicy</code></a>
等于 <code>Always</code>，如果没有指定，这是默认值。</p><p>对于本地容器重启，ReplicationController 委托给节点上的代理，
例如 <a href=/zh-cn/docs/reference/command-line-tools-reference/kubelet/>Kubelet</a>。</p><h3 id=labels-on-the-replicacontroller>ReplicationController 上的标签</h3><p>ReplicationController 本身可以有标签 （<code>.metadata.labels</code>）。
通常，你可以将这些设置为 <code>.spec.template.metadata.labels</code>；
如果没有指定 <code>.metadata.labels</code> 那么它默认为 <code>.spec.template.metadata.labels</code>。
但是，Kubernetes 允许它们是不同的，<code>.metadata.labels</code> 不会影响 ReplicationController 的行为。</p><h3 id=pod-selector>Pod 选择算符</h3><p><code>.spec.selector</code> 字段是一个<a href=/zh-cn/docs/concepts/overview/working-with-objects/labels/#label-selectors>标签选择算符</a>。
ReplicationController 管理标签与选择算符匹配的所有 Pod。
它不区分它创建或删除的 Pod 和其他人或进程创建或删除的 Pod。
这允许在不影响正在运行的 Pod 的情况下替换 ReplicationController。</p><p>如果指定了 <code>.spec.template.metadata.labels</code>，它必须和 <code>.spec.selector</code> 相同，否则它将被 API 拒绝。
如果没有指定 <code>.spec.selector</code>，它将默认为 <code>.spec.template.metadata.labels</code>。</p><p>另外，通常不应直接使用另一个 ReplicationController 或另一个控制器（例如 Job）
来创建其标签与该选择算符匹配的任何 Pod。如果这样做，ReplicationController 会认为它创建了这些 Pod。
Kubernetes 并没有阻止你这样做。</p><p>如果你的确创建了多个控制器并且其选择算符之间存在重叠，那么你将不得不自己管理删除操作（参考<a href=#working-with-replicationcontrollers>后文</a>）。</p><h3 id=multiple-replicas>多个副本</h3><p>你可以通过设置 <code>.spec.replicas</code> 来指定应该同时运行多少个 Pod。
在任何时候，处于运行状态的 Pod 个数都可能高于或者低于设定值。例如，副本个数刚刚被增加或减少时，
或者一个 Pod 处于优雅终止过程中而其替代副本已经提前开始创建时。</p><p>如果你没有指定 <code>.spec.replicas</code>，那么它默认是 1。</p><h2 id=working-with-replicationcontrollers>使用 ReplicationController</h2><h3 id=deleteing-a-replicationcontroller-and-its-pods>删除一个 ReplicationController 以及它的 Pod</h3><p>要删除一个 ReplicationController 以及它的 Pod，使用
<a href=/docs/reference/generated/kubectl/kubectl-commands#delete><code>kubectl delete</code></a>。
kubectl 将 ReplicationController 缩容为 0 并等待以便在删除 ReplicationController 本身之前删除每个 Pod。
如果这个 kubectl 命令被中断，可以重新启动它。</p><p>当使用 REST API 或<a href=/zh-cn/docs/reference/using-api/client-libraries>客户端库</a>时，你需要明确地执行这些步骤（缩容副本为 0、
等待 Pod 删除，之后删除 ReplicationController 资源）。</p><h3 id=deleting-only-a-replicationcontroller>只删除 ReplicationController</h3><p>你可以删除一个 ReplicationController 而不影响它的任何 Pod。</p><p>使用 kubectl，为 <a href=/docs/reference/generated/kubectl/kubectl-commands#delete><code>kubectl delete</code></a> 指定 <code>--cascade=orphan</code> 选项。</p><p>当使用 REST API 或<a href=/zh-cn/docs/reference/using-api/client-libraries>客户端库</a>时，只需删除 ReplicationController 对象。</p><p>一旦原始对象被删除，你可以创建一个新的 ReplicationController 来替换它。
只要新的和旧的 <code>.spec.selector</code> 相同，那么新的控制器将领养旧的 Pod。
但是，它不会做出任何努力使现有的 Pod 匹配新的、不同的 Pod 模板。
如果希望以受控方式更新 Pod 以使用新的 spec，请执行<a href=#rolling-updates>滚动更新</a>操作。</p><h3 id=isolating-pods-from-a-replicationcontroller>从 ReplicationController 中隔离 Pod</h3><p>通过更改 Pod 的标签，可以从 ReplicationController 的目标中删除 Pod。
此技术可用于从服务中删除 Pod 以进行调试、数据恢复等。以这种方式删除的 Pod
将被自动替换（假设复制副本的数量也没有更改）。</p><h2 id=common-usage-patterns>常见的使用模式</h2><h3 id=rescheduling>重新调度</h3><p>如上所述，无论你想要继续运行 1 个 Pod 还是 1000 个 Pod，一个 ReplicationController 都将确保存在指定数量的 Pod，即使在节点故障或 Pod 终止(例如，由于另一个控制代理的操作)的情况下也是如此。</p><h3 id=scaling>扩缩容</h3><p>通过设置 <code>replicas</code> 字段，ReplicationController 可以允许扩容或缩容副本的数量。
你可以手动或通过自动扩缩控制代理来控制 ReplicationController 执行此操作。</p><h3 id=rolling-updates>滚动更新</h3><p>ReplicationController 的设计目的是通过逐个替换 Pod 以方便滚动更新服务。</p><p>如 <a href=https://issue.k8s.io/1353>#1353</a> PR 中所述，建议的方法是使用 1 个副本创建一个新的 ReplicationController，
逐个扩容新的（+1）和缩容旧的（-1）控制器，然后在旧的控制器达到 0 个副本后将其删除。
这一方法能够实现可控的 Pod 集合更新，即使存在意外失效的状况。</p><p>理想情况下，滚动更新控制器将考虑应用程序的就绪情况，并确保在任何给定时间都有足够数量的 Pod 有效地提供服务。</p><p>这两个 ReplicationController 将需要创建至少具有一个不同标签的 Pod，比如 Pod 主要容器的镜像标签，因为通常是镜像更新触发滚动更新。</p><h3 id=multiple-release-tracks>多个版本跟踪</h3><p>除了在滚动更新过程中运行应用程序的多个版本之外，通常还会使用多个版本跟踪来长时间，
甚至持续运行多个版本。这些跟踪将根据标签加以区分。</p><p>例如，一个服务可能把具有 <code>tier in (frontend), environment in (prod)</code> 的所有 Pod 作为目标。
现在假设你有 10 个副本的 Pod 组成了这个层。但是你希望能够 <code>canary</code> （<code>金丝雀</code>）发布这个组件的新版本。
你可以为大部分副本设置一个 ReplicationController，其中 <code>replicas</code> 设置为 9，
标签为 <code>tier=frontend, environment=prod, track=stable</code> 而为 <code>canary</code>
设置另一个 ReplicationController，其中 <code>replicas</code> 设置为 1，
标签为 <code>tier=frontend, environment=prod, track=canary</code>。
现在这个服务覆盖了 <code>canary</code> 和非 <code>canary</code> Pod。但你可以单独处理
ReplicationController，以测试、监控结果等。</p><h3 id=using-replicationcontrollers-with-services>和服务一起使用 ReplicationController</h3><p>多个 ReplicationController 可以位于一个服务的后面，例如，一部分流量流向旧版本，
一部分流量流向新版本。</p><p>一个 ReplicationController 永远不会自行终止，但它不会像服务那样长时间存活。
服务可以由多个 ReplicationController 控制的 Pod 组成，并且在服务的生命周期内
（例如，为了执行 Pod 更新而运行服务），可以创建和销毁许多 ReplicationController。
服务本身和它们的客户端都应该忽略负责维护服务 Pod 的 ReplicationController 的存在。</p><h2 id=writing-programs-for-replication>编写多副本的应用</h2><p>由 ReplicationController 创建的 Pod 是可替换的，语义上是相同的，
尽管随着时间的推移，它们的配置可能会变得异构。
这显然适合于多副本的无状态服务器，但是 ReplicationController 也可以用于维护主选、
分片和工作池应用程序的可用性。
这样的应用程序应该使用动态的工作分配机制，例如
<a href=https://www.rabbitmq.com/tutorials/tutorial-two-python.html>RabbitMQ 工作队列</a>，
而不是静态的或者一次性定制每个 Pod 的配置，这被认为是一种反模式。
执行的任何 Pod 定制，例如资源的垂直自动调整大小（例如，CPU 或内存），
都应该由另一个在线控制器进程执行，这与 ReplicationController 本身没什么不同。</p><h2 id=responsibilities-of-the-replicationcontroller>ReplicationController 的职责</h2><p>ReplicationController 仅确保所需的 Pod 数量与其标签选择算符匹配，并且是可操作的。
目前，它的计数中只排除终止的 Pod。
未来，可能会考虑系统提供的<a href=https://issue.k8s.io/620>就绪状态</a>和其他信息，
我们可能会对替换策略添加更多控制，
我们计划发出事件，这些事件可以被外部客户端用来实现任意复杂的替换和/或缩减策略。</p><p>ReplicationController 永远被限制在这个狭隘的职责范围内。
它本身既不执行就绪态探测，也不执行活跃性探测。
它不负责执行自动扩缩，而是由外部自动扩缩器控制（如
<a href=https://issue.k8s.io/492>#492</a> 中所述），后者负责更改其 <code>replicas</code> 字段值。
我们不会向 ReplicationController 添加调度策略（例如，
<a href=https://issue.k8s.io/367#issuecomment-48428019>spreading</a>）。
它也不应该验证所控制的 Pod 是否与当前指定的模板匹配，因为这会阻碍自动调整大小和其他自动化过程。
类似地，完成期限、整理依赖关系、配置扩展和其他特性也属于其他地方。
我们甚至计划考虑批量创建 Pod 的机制（查阅 <a href=https://issue.k8s.io/170>#170</a>）。</p><p>ReplicationController 旨在成为可组合的构建基元。
我们希望在它和其他补充原语的基础上构建更高级别的 API 或者工具，以便于将来的用户使用。
kubectl 目前支持的 "macro" 操作（运行、扩缩、滚动更新）就是这方面的概念示例。
例如，我们可以想象类似于 <a href=https://netflixtechblog.com/asgard-web-based-cloud-management-and-deployment-2c9fc4e4d3a1>Asgard</a>
的东西管理 ReplicationController、自动定标器、服务、调度策略、金丝雀发布等。</p><h2 id=api-object>API 对象</h2><p>在 Kubernetes REST API 中 Replication controller 是顶级资源。
更多关于 API 对象的详细信息可以在
<a href=/docs/reference/generated/kubernetes-api/v1.25/#replicationcontroller-v1-core>ReplicationController API 对象</a>找到。</p><h2 id=alternatives-to-replicationcontroller>ReplicationController 的替代方案</h2><h3 id=replicaset>ReplicaSet</h3><p><a href=/zh-cn/docs/concepts/workloads/controllers/replicaset/><code>ReplicaSet</code></a> 是下一代 ReplicationController，
支持新的<a href=/zh-cn/docs/concepts/overview/working-with-objects/labels/#set-based-requirement>基于集合的标签选择算符</a>。
它主要被 <a href=/zh-cn/docs/concepts/workloads/controllers/deployment/><code>Deployment</code></a>
用来作为一种编排 Pod 创建、删除及更新的机制。
请注意，我们推荐使用 Deployment 而不是直接使用 ReplicaSet，除非你需要自定义更新编排或根本不需要更新。</p><h3 id=deployment-推荐>Deployment （推荐）</h3><p><a href=/zh-cn/docs/concepts/workloads/controllers/deployment/><code>Deployment</code></a> 是一种更高级别的 API 对象，用于更新其底层 ReplicaSet 及其 Pod。
如果你想要这种滚动更新功能，那么推荐使用 Deployment，因为它们是声明式的、服务端的，并且具有其它特性。</p><h3 id=裸-pod>裸 Pod</h3><p>与用户直接创建 Pod 的情况不同，ReplicationController 能够替换因某些原因被删除或被终止的 Pod，
例如在节点故障或中断节点维护的情况下，例如内核升级。
因此，我们建议你使用 ReplicationController，即使你的应用程序只需要一个 Pod。
可以将其看作类似于进程管理器，它只管理跨多个节点的多个 Pod，而不是单个节点上的单个进程。
ReplicationController 将本地容器重启委托给节点上的某个代理（例如 Kubelet)。</p><h3 id=job>Job</h3><p>对于预期会自行终止的 Pod (即批处理任务)，使用
<a href=/zh-cn/docs/concepts/workloads/controllers/job/><code>Job</code></a> 而不是 ReplicationController。</p><h3 id=daemonset>DaemonSet</h3><p>对于提供机器级功能（例如机器监控或机器日志记录）的 Pod，
使用 <a href=/zh-cn/docs/concepts/workloads/controllers/daemonset/><code>DaemonSet</code></a> 而不是
ReplicationController。
这些 Pod 的生命期与机器的生命期绑定：它们需要在其他 Pod 启动之前在机器上运行，
并且在机器准备重新启动或者关闭时安全地终止。</p><h2 id=接下来>接下来</h2><ul><li>了解 <a href=/zh-cn/docs/concepts/workloads/pods>Pod</a>。</li><li>了解 <a href=/zh-cn/docs/concepts/workloads/controllers/deployment/>Depolyment</a>，ReplicationController 的替代品。</li><li><code>ReplicationController</code> 是 Kubernetes REST API 的一部分，阅读
<a href=/zh-cn/docs/reference/kubernetes-api/workload-resources/replication-controller-v1/>ReplicationController</a>
对象定义以了解 replication controllers 的 API。</li></ul></div></main></div></div><footer class=d-print-none><div class=footer__links><nav><a class=text-white href=/zh-cn/docs/home/>主页</a>
<a class=text-white href=/zh-cn/blog/>博客</a>
<a class=text-white href=/zh-cn/training/>培训</a>
<a class=text-white href=/zh-cn/partners/>合作伙伴</a>
<a class=text-white href=/zh-cn/community/>社区</a>
<a class=text-white href=/zh-cn/case-studies/>案例分析</a></nav></div><div class=container-fluid><div class=row><div class="col-6 col-sm-2 text-xs-center order-sm-2"><ul class="list-inline mb-0"><li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title="User mailing list" aria-label="User mailing list"><a class=text-white target=_blank href=https://discuss.kubernetes.io><i class="fa fa-envelope"></i></a></li><li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title=Twitter aria-label=Twitter><a class=text-white target=_blank href=https://twitter.com/kubernetesio><i class="fab fa-twitter"></i></a></li><li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title=Calendar aria-label=Calendar><a class=text-white target=_blank href="https://calendar.google.com/calendar/embed?src=calendar%40kubernetes.io"><i class="fas fa-calendar-alt"></i></a></li><li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title=Youtube aria-label=Youtube><a class=text-white target=_blank href=https://youtube.com/kubernetescommunity><i class="fab fa-youtube"></i></a></li></ul></div><div class="col-6 col-sm-2 text-right text-xs-center order-sm-3"><ul class="list-inline mb-0"><li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title=GitHub aria-label=GitHub><a class=text-white target=_blank href=https://github.com/kubernetes/kubernetes><i class="fab fa-github"></i></a></li><li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title=Slack aria-label=Slack><a class=text-white target=_blank href=https://slack.k8s.io><i class="fab fa-slack"></i></a></li><li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title=Contribute aria-label=Contribute><a class=text-white target=_blank href=https://git.k8s.io/community/contributors/guide><i class="fas fa-edit"></i></a></li><li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title="Stack Overflow" aria-label="Stack Overflow"><a class=text-white target=_blank href=https://stackoverflow.com/questions/tagged/kubernetes><i class="fab fa-stack-overflow"></i></a></li></ul></div><div class="col-12 col-sm-8 text-center order-sm-2"><small class=text-white>&copy; 2023 The Kubernetes 作者 | 文档发布基于 <a href=https://git.k8s.io/website/LICENSE class=light-text>CC BY 4.0</a> 授权许可</small><br><small class=text-white>Copyright &copy; 2023 Linux 基金会&reg;。保留所有权利。Linux 基金会已注册并使用商标。如需了解 Linux 基金会的商标列表，请访问<a href=https://www.linuxfoundation.org/trademark-usage class=light-text>商标使用页面</a></small><br><small class=text-white>ICP license: 京ICP备17074266号-3</small></div></div></div></footer></div><script src=/js/jquery-3.6.0.min.js integrity=sha384-vtXRMe3mGCbOeY7l30aIg8H9p3GdeSe4IFlP6G8JMa7o7lXvnz3GFKzPxzJdPfGK crossorigin=anonymous></script>
<script src=/js/popper-1.16.1.min.js intregrity=sha384-9/reFTGAW83EW2RDu2S0VKaIzap3H66lZH81PoYlFhbGU+6BZp6G7niu735Sk7lN crossorigin=anonymous></script>
<script src=/js/bootstrap-4.6.1.min.js integrity=sha384-VHvPCCyXqtD5DqJeNxl2dtTyhF78xXNXdkwX1CZeRusQfRKp+tA7hAShOK/B/fQ2 crossorigin=anonymous></script>
<script src=/js/script.js></script>
<script async src=/js/mermaid-8.13.4.min.js integrity=sha384-5hHNvPeMrNH14oM3IcQofDoBhiclNK3g2+hnEinKzQ07C4AliMeVpnvxuiwEGpaO crossorigin=anonymous></script>
<script src=/js/main.min.5c0bf7f21dc4f66485f74efbbeeff28a7e4f8cddaac1bae47043159c922ff3a3.js integrity="sha256-XAv38h3E9mSF9077vu/yin5PjN2qwbrkcEMVnJIv86M=" crossorigin=anonymous></script></body></html>