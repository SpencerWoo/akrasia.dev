<!doctype html><html lang=id class=no-js><head><meta name=robots content="noindex, nofollow"><link rel=alternate hreflang=en href=https://kubernetes.io/docs/concepts/workloads/><link rel=alternate hreflang=zh-cn href=https://kubernetes.io/zh-cn/docs/concepts/workloads/><link rel=alternate hreflang=ko href=https://kubernetes.io/ko/docs/concepts/workloads/><link rel=alternate hreflang=ja href=https://kubernetes.io/ja/docs/concepts/workloads/><link rel=alternate hreflang=fr href=https://kubernetes.io/fr/docs/concepts/workloads/><link rel=alternate hreflang=de href=https://kubernetes.io/de/docs/concepts/workloads/><link rel=alternate hreflang=es href=https://kubernetes.io/es/docs/concepts/workloads/><link rel=alternate hreflang=uk href=https://kubernetes.io/uk/docs/concepts/workloads/><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=generator content="Hugo 0.110.0"><link rel=canonical type=text/html href=https://kubernetes.io/id/docs/concepts/workloads/><link rel="shortcut icon" type=image/png href=/images/favicon.png><link rel=apple-touch-icon href=/favicons/apple-touch-icon-180x180.png sizes=180x180><link rel=manifest href=/manifest.webmanifest><link rel=apple-touch-icon href=/images/kubernetes-192x192.png><title>Workloads | Kubernetes</title><meta property="og:title" content="Workloads"><meta property="og:description" content="Orkestrasi Kontainer dengan Skala Produksi"><meta property="og:type" content="website"><meta property="og:url" content="https://kubernetes.io/id/docs/concepts/workloads/"><meta property="og:site_name" content="Kubernetes"><meta itemprop=name content="Workloads"><meta itemprop=description content="Orkestrasi Kontainer dengan Skala Produksi"><meta name=twitter:card content="summary"><meta name=twitter:title content="Workloads"><meta name=twitter:description content="Orkestrasi Kontainer dengan Skala Produksi"><link href=/scss/main.css rel=stylesheet><script type=application/ld+json>{"@context":"https://schema.org","@type":"Organization","url":"https://kubernetes.io","logo":"https://kubernetes.io/images/favicon.png","potentialAction":{"@type":"SearchAction","target":"https://kubernetes.io/search/?q={search_term_string}","query-input":"required name=search_term_string"}}</script><meta name=theme-color content="#326ce5"><link rel=stylesheet href=/css/feature-states.css><meta name=description content><meta property="og:description" content><meta name=twitter:description content><meta property="og:url" content="https://kubernetes.io/id/docs/concepts/workloads/"><meta property="og:title" content="Workloads"><meta name=twitter:title content="Workloads"><meta name=twitter:image content="https://kubernetes.io/images/favicon.png"><meta name=twitter:image:alt content="Kubernetes"><meta property="og:image" content="/images/kubernetes-horizontal-color.png"><meta property="og:type" content="article"><script src=/js/jquery-3.6.0.min.js intregrity=sha384-vtXRMe3mGCbOeY7l30aIg8H9p3GdeSe4IFlP6G8JMa7o7lXvnz3GFKzPxzJdPfGK crossorigin=anonymous></script></head><body class=td-section><header><nav class="js-navbar-scroll navbar navbar-expand navbar-dark flex-column flex-md-row td-navbar" data-auto-burger=primary><a class=navbar-brand href=/id/></a><div class="td-navbar-nav-scroll ml-md-auto" id=main_navbar><ul class="navbar-nav mt-2 mt-lg-0"><li class="nav-item mr-2 mb-lg-0"><a class="nav-link active" href=/id/docs/>Dokumentasi</a></li><li class="nav-item mr-2 mb-lg-0"><a class=nav-link href=/id/community/>Komunitas</a></li><li class="nav-item mr-2 mb-lg-0"><a class=nav-link href=/id/case-studies/>Studi kasus</a></li><li class="nav-item dropdown"><a class="nav-link dropdown-toggle" href=# id=navbarDropdown role=button data-toggle=dropdown aria-haspopup=true aria-expanded=false>Versi</a><div class="dropdown-menu dropdown-menu-right" aria-labelledby=navbarDropdownMenuLink><a class=dropdown-item href=/id/releases>Release Information</a>
<a class=dropdown-item href=https://kubernetes.io/id/docs/concepts/workloads/>v1.25</a>
<a class=dropdown-item href=https://v1-24.docs.kubernetes.io/id/docs/concepts/workloads/>v1.24</a>
<a class=dropdown-item href=https://v1-23.docs.kubernetes.io/id/docs/concepts/workloads/>v1.23</a>
<a class=dropdown-item href=https://v1-22.docs.kubernetes.io/id/docs/concepts/workloads/>v1.22</a>
<a class=dropdown-item href=https://v1-21.docs.kubernetes.io/id/docs/concepts/workloads/>v1.21</a></div></li><li class="nav-item dropdown"><a class="nav-link dropdown-toggle" href=# id=navbarDropdownMenuLink role=button data-toggle=dropdown aria-haspopup=true aria-expanded=false>Bahasa Indonesia</a><div class="dropdown-menu dropdown-menu-right" aria-labelledby=navbarDropdownMenuLink><a class=dropdown-item href=/docs/concepts/workloads/>English</a>
<a class=dropdown-item href=/zh-cn/docs/concepts/workloads/>中文 (Chinese)</a>
<a class=dropdown-item href=/ko/docs/concepts/workloads/>한국어 (Korean)</a>
<a class=dropdown-item href=/ja/docs/concepts/workloads/>日本語 (Japanese)</a>
<a class=dropdown-item href=/fr/docs/concepts/workloads/>Français (French)</a>
<a class=dropdown-item href=/de/docs/concepts/workloads/>Deutsch (German)</a>
<a class=dropdown-item href=/es/docs/concepts/workloads/>Español (Spanish)</a>
<a class=dropdown-item href=/uk/docs/concepts/workloads/>Українська (Ukrainian)</a></div></li></ul></div><button id=hamburger onclick=kub.toggleMenu() data-auto-burger-exclude><div></div></button></nav></header><div class="container-fluid td-outer"><div class=td-main><div class="row flex-xl-nowrap"><main class="col-12 col-md-9 col-xl-8 pl-md-5" role=main><div class=td-content><div class="pageinfo pageinfo-primary d-print-none"><p>This is the multi-page printable view of this section.
<a href=# onclick="return print(),!1">Click here to print</a>.</p><p><a href=/id/docs/concepts/workloads/>Return to the regular view of this page</a>.</p></div><h1 class=title>Workloads</h1><ul><li>1: <a href=#pg-4d68b0ccf9c683e6368ffdcc40c838d4>Pods</a></li><ul><li>1.1: <a href=#pg-37afa6c66c74400d1579f10faf55e5b6>Pengenalan Pod</a></li><li>1.2: <a href=#pg-99cce294fe789317ee684a6e1f07f20f>Pod</a></li><li>1.3: <a href=#pg-c3c2b9cf30915ec9d46c147201da3332>Siklus Hidup Pod</a></li><li>1.4: <a href=#pg-1ccbd4eeded6ab138d98b59175bd557e>Init Container</a></li><li>1.5: <a href=#pg-c8d62295ca703fdcef1aaf89fb4c916a>Batasan Persebaran Topologi Pod</a></li><li>1.6: <a href=#pg-4e9b9cbc9776b12e7335c53da377c9c8>Pod Preset</a></li><li>1.7: <a href=#pg-4aaf43c715cd764bc8ed4436f3537e68>Disrupsi</a></li><li>1.8: <a href=#pg-53a1005011e1bda2ce81819aad7c8b32>Kontainer Sementara (Ephemeral)</a></li></ul><li>2: <a href=#pg-89637410cacae45a36ab1cc278c482eb>Controllers</a></li><ul><li>2.1: <a href=#pg-d459b930218774655fa7fd1620625539>ReplicaSet</a></li><li>2.2: <a href=#pg-27f1331d515d95f76aa1156088b4ad91>ReplicationController</a></li><li>2.3: <a href=#pg-a2dc0393e0c4079e1c504b6429844e86>Deployment</a></li><li>2.4: <a href=#pg-6d72299952c37ca8cc61b416e5bdbcd4>StatefulSet</a></li><li>2.5: <a href=#pg-41600eb8b6631c88848156f381e9d588>DaemonSet</a></li><li>2.6: <a href=#pg-9add0d2120634b63073ad08dc8683bd6>Garbage Collection</a></li><li>2.7: <a href=#pg-4de50a37ebb6f2340484192126cb7a04>Pengendali TTL untuk Sumber Daya yang Telah Selesai Digunakan</a></li><li>2.8: <a href=#pg-cc7cc3c4907039d9f863162e20bfbbef>Jobs</a></li><li>2.9: <a href=#pg-2e4cec01c525b45eccd6010e21cc76d9>CronJob</a></li></ul></ul><div class=content></div></div><div class=td-content><h1 id=pg-4d68b0ccf9c683e6368ffdcc40c838d4>1 - Pods</h1></div><div class=td-content><h1 id=pg-37afa6c66c74400d1579f10faf55e5b6>1.1 - Pengenalan Pod</h1><p>Halaman ini menyajikan ikhtisar dari <code>Pod</code>, objek terkecil yang dapat di <em>deploy</em> di dalam objek model Kubernetes.</p><h2 id=memahami-pod>Memahami Pod</h2><p>Sebuah <em>Pod</em> adalah unit dasar di Kubernetes--unit terkecil dan paling sederhana di dalam objek model Kubernetes yang dapat dibuat dan di <em>deploy</em>. Sebuah <em>Pod</em> merepresentasikan suatu proses yang berjalan di dalam klaster.</p><p><em>Pod</em> membungkus sebuah kontainer (atau, di beberapa kasus, beberapa kontainer), sumber penyimpanan, alamat jaringan <em>IP</em> yang unik, dan opsi yang mengatur bagaimana kontainer harus dijalankan. <em>Pod</em> merupakan representasi dari unit <em>deployment</em>: sebuah <em>instance</em> aplikasi di dalam Kubernetes, yang mungkin terdiri dari satu kontainer atau sekumpulan kontainer yang berbagi <em>resource</em>.</p><p><a href=https://www.docker.com>Docker</a> adalah salah satu kontainer <em>runtime</em> yang paling umum digunakan di Kubernetes <em>Pod</em>, tetapi <em>Pod</em> mendukung kontainer <em>runtime</em> lainnya.</p><p><em>Pod</em> di Kubernetes klaster dapat digunakan dengan dua cara:</p><ul><li><strong>Pod menjalankan satu kontainer</strong>. Model satu kontainer per <em>Pod</em> adalah model yang umum digunakan di Kubernetes; kamu dapat membayangkan sebuah <em>Pod</em> sebagai pembungkus kontainer tersebut, dan Kubernetes tidak mengelola kontainer secara langsung tetapi mengelola <em>Pod</em> tersebut.</li><li><strong>Pod menjalankan beberapa kontainer yang perlu berjalan bersamaan</strong>. Sebuah <em>Pod</em> dapat membungkus sebuah aplikasi yang terdiri dari beberapa kontainer yang perlu berbagi <em>resource</em>. Kontainer yang ditempatkan di dalam satu <em>Pod</em> ini membentuk sebuah layanan. Sebuah kontainer menyajikan berkas dari sumber penyimpanan ke publik, sedangkan kontainer <em>sidecar</em> yang lain melakukan pembaharuan terhadap berkas tersebut. <em>Pod</em> membungkus semua kontainer dan <em>resource</em> penyimpanan sebagai satu kesatuan yang dapat dikelola.</li></ul><p><a href=http://kubernetes.io/blog>Kubernetes Blog</a> menyediakan beberapa informasi tambahan terkait penggunaan <em>Pod</em>. Informasi selengkapnya, kunjungi:</p><ul><li><a href=https://kubernetes.io/blog/2015/06/the-distributed-system-toolkit-patterns>The Distributed System Toolkit: Patterns for Composite Containers</a></li><li><a href=https://kubernetes.io/blog/2016/06/container-design-patterns>Container Design Patterns</a></li></ul><p>Setiap <em>Pod</em> dimaksudkan untuk menjalankan satu <em>instance</em> aplikasi. Jika kamu ingin mengembangkan aplikasi secara horizontal (contoh, banyak <em>instance</em> sekaligus), kamu dapat menggunakan banyak <em>Pod</em>, satu untuk setiap <em>instance</em>. Di Kubernetes, konsep ini umumnya disebut dengan replikasi. <em>Pod</em> yang direplikasi biasanya dibuat dan dikelola sebagai grup oleh objek abstraksi yang disebut kontroler. Lihat <a href=#pod-dan-kontroler>Pod dan Kontroler</a> untuk informasi selengkapnya.</p><h3 id=bagaimana-pod-mengelola-beberapa-kontainer>Bagaimana <em>Pod</em> mengelola beberapa Kontainer</h3><p><em>Pod</em> didesain untuk mendukung banyak proses (sebagai kontainer) yang membentuk sebuah layanan. Kontainer di dalam sebuah <em>Pod</em> akan otomatis ditempatkan bersama di dalam satu mesin fisik atau mesin <em>virtual</em> di dalam klaster. Kontainer tersebut dapat berbagi <em>resource</em> dan dependensi, berkomunikasi satu sama lain, dan berkoordinasi kapan dan bagaimana mereka diterminasi.</p><p>Perhatikan bahwa mengelompokan kontainer di dalam satu <em>Pod</em> merupakan kasus lanjutan. Kamu dapat menggunakan pola ini hanya dalam kasus tertentu. Sebagai contoh, kamu memiliki kontainer yang bertindak sebagai <em>web server</em> yang menyajikan berkas dari <em>resource</em> penyimpanan bersama, dan kontainer <em>sidecar</em> melakukan pembaharuan terhadap berkas tersebut dari sumber lain, seperti dalam diagram <em>Pod</em> berikut:<figure><img src=/images/docs/pod.svg width=50%><figcaption><h4>Pod diagram</h4></figcaption></figure></p><p><em>Pod</em> menyediakan dua jenis <em>resource</em> sebagai penyusun dari kontainer: <em>jaringan</em> dan <em>penyimpanan</em>.</p><h4 id=jaringan>Jaringan</h4><p>Setiap <em>Pod</em> diberikan sebuah alamat <em>IP</em> unik. Setiap kontainer di dalam <em>Pod</em> berbagi <em>network namespace</em>, termasuk alamat <em>IP</em> dan <em>port</em> jaringan. Setiap kontainer di dalam <em>Pod</em> dapat berkomunikasi satu sama lain menggunakan <em>localhost</em>. Saat para kontainer di dalam <em>Pod</em> berkomunikasi dengan entitas lain di luar <em>Pod</em>, mereka harus berkoordinasi satu sama lain bagaimana mereka menggunakan <em>resource</em> jaringan (seperti <em>Port</em>).</p><h4 id=penyimpanan>Penyimpanan</h4><p><em>Pod</em> dapat menentukan penyimpanan bersama yaitu <em>volumes</em>. Semua kontainer di dalam <em>Pod</em> dapat mengakses <em>volumes</em> ini, mengizinkan kontainer untuk berbagi data. <em>Volumes</em> juga memungkinkan data di <em>Pod</em> untuk bertahan jika salah satu kontainer perlu melakukan proses <em>restart</em>. Lihat <em><a href=/id/docs/concepts/storage/volumes/>Volumes</a></em> untuk informasi lebih lanjut bagaimana Kubernetes mengimplementasikan penyimpanan di dalam <em>Pod</em>.</p><h2 id=bekerja-dengan-pod>Bekerja dengan Pod</h2><p>Kamu akan jarang membuat <em>Pod</em> secara langsung di Kubernetes. Ini karena <em>Pod</em> dirancang sebagai entitas sesaat. Saat <em>Pod</em> dibuat (baik oleh kamu, atau secara tidak langsung oleh kontroler), <em>Pod</em> ditempatkan dan dijalankan di sebuah <em>Node</em> di dalam klaster. <em>Pod</em> akan tetap di <em>Node</em> tersebut sampai proses dihentikan, Objek <em>Pod</em> dihapus, <em>Pod</em> dihentikan karena kekurangan <em>resource</em>, atau <em>Node</em> tersebut berhenti berjalan.</p><div class="alert alert-info note callout" role=alert><strong>Catatan:</strong> Tidak perlu bingung untuk membedakan antara menjalankan ulang sebuah kontainer di dalam <em>Pod</em> dan menjalankan ulang <em>Pod</em>. <em>Pod</em> itu sendiri tidak berjalan, tetapi <em>Pod</em> adalah <em>environment</em> kontainer itu berjalan dan akan tetap ada sampai dihapus.</div><p><em>Pod</em> tidak melakukan mekanisme penyembuhan diri sendiri. Jika <em>Pod</em> ditempatkan disebuah <em>Node</em> yang gagal, atau proses penempatan <em>Pod</em> itu sendiri gagal, <em>Pod</em> akan dihapus; demikian juga, <em>Pod</em> tidak akan bertahan jika <em>Node</em> tersebut kehabisan <em>resource</em> atau sedang dalam tahap pemeliharaan. Kubernetes menggunakan abstraksi yang disebut kontroler, yang menangani dan mengelola <em>Pod</em>. Jadi, meskipun <em>Pod</em> dapat dipakai secara langsung di Kubernetes, kontroler merupakan cara umum yang digunakan untuk mengelola <em>Pod</em>. Lihat <a href=#pod-dan-kontroler>Pod dan kontroler</a> untuk informasi lebih lanjut bagaimana Kubernetes menggunakan kontroler untuk mengimpelentasikan mekanisme penyembuhan diri sendiri dan replikasi pada <em>Pod</em>.</p><h3 id=pod-dan-kontroler>Pod dan Kontroler</h3><p>Kontroler dapat membuat dan mengelola banyak <em>Pod</em> untuk kamu, menangani replikasi dan menyediakan kemampuan penyembuhan diri sendiri pada lingkup klaster. Sebagai contoh, jika sebuah <em>Node</em> gagal, kontroler akan otomatis mengganti <em>Pod</em> tersebut dengan menempatkan <em>Pod</em> yang identik di <em>Node</em> yang lain.</p><p>Beberapa contoh kontroler yang berisi satu atau lebih <em>Pod</em> meliputi:</p><ul><li><a href=/id/docs/concepts/workloads/controllers/deployment/>Deployment</a></li><li><a href=/id/docs/concepts/workloads/controllers/statefulset/>StatefulSet</a></li><li><a href=/id/docs/concepts/workloads/controllers/daemonset/>DaemonSet</a></li></ul><p>Secara umum, kontroler menggunakan templat <em>Pod</em> yang kamu sediakan untuk membuat <em>Pod</em>.</p><h2 id=templat-pod>Templat Pod</h2><p>Templat <em>Pod</em> adalah spesifikasi dari <em>Pod</em> yang termasuk di dalam objek lain seperti
<a href=/id/docs/concepts/workloads/controllers/replicationcontroller/>Replication Controllers</a>, <a href=/docs/concepts/jobs/run-to-completion-finite-workloads/>Jobs</a>, dan <a href=/id/docs/concepts/workloads/controllers/daemonset/>DaemonSets</a>. Kontroler menggunakan templat <em>Pod</em> untuk membuat <em>Pod</em>.</p><p>Contoh di bawah merupakan manifestasi sederhana untuk <em>Pod</em> yang berisi kontainer yang membuat sebuah pesan.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>myapp-pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>labels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>app</span>:<span style=color:#bbb> </span>myapp<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>myapp-container<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>busybox<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>command</span>:<span style=color:#bbb> </span>[<span style=color:#b44>&#39;sh&#39;</span>,<span style=color:#bbb> </span><span style=color:#b44>&#39;-c&#39;</span>,<span style=color:#bbb> </span><span style=color:#b44>&#39;echo Hello Kubernetes! &amp;&amp; sleep 3600&#39;</span>]<span style=color:#bbb>
</span></span></span></code></pre></div><p>Perubahan yang terjadi pada templat atau berganti ke templat yang baru tidak memiliki efek langsung pada <em>Pod</em> yang sudah dibuat. <em>Pod</em> yang dibuat oleh <em>replication controller</em> dapat diperbarui secara langsung.</p><h2 id=selanjutnya>Selanjutnya</h2><ul><li>Pelajari lebih lanjut tentang perilaku <em>Pod</em>:<ul><li><a href=/id/docs/concepts/workloads/pods/pod/#termination-of-pods>Terminasi Pod</a></li><li><a href=/id/docs/concepts/workloads/pods/pod-lifecycle/>Lifecycle Pod</a></li></ul></li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-99cce294fe789317ee684a6e1f07f20f>1.2 - Pod</h1><p>Pod adalah unit komputasi terkecil yang bisa di-<em>deploy</em> dan dibuat serta dikelola dalam Kubernetes.</p><h2 id=apa-itu-pod>Apa Itu Pod?</h2><p>Sebuah Pod (seperti pod pada paus atau kacang polong) adalah sebuah kelompok yang
terdiri dari satu atau lebih <a class=glossary-tooltip title='Sebuah image yang ringan dan dapat dijalankan yang mengandung perangkat lunak and segala dependensi yang dibutuhkan.' data-toggle=tooltip data-placement=top href=/id/docs/concepts/overview/what-is-kubernetes/#mengapa-kontainer target=_blank aria-label=kontainer>kontainer</a>
(misalnya kontainer Docker), dengan ruang penyimpanan ataupun jaringan yang dipakai bersama,
dan sebuah spesifikasi mengenai bagaimana menjalankan kontainer. Isi dari Pod akan
selalu diletakkan dan dijadwalkan bersama, serta berjalan dalam konteks yang sama.
Sebuah Pod memodelkan <em>"logical host"</em> yang spesifik terhadap aplikasi. Ini mengandung
lebih dari satu kontainer aplikasi yang secara relatif saling terhubung erat. Sebelum
masa kontainer, menjalankan aplikasi dalam mesin fisik atau <em>virtual</em> berarti
menjalankan dalam <em>logical host</em> yang sama.</p><p>Walaupun Kubernetes mendukung lebih banyak <em>runtime</em> kontainer selain Docker,
namun Docker adalah yang paling umum diketahui dan ini membantu dalam menjelaskan
Pod dengan istilah pada Docker.</p><p>Konteks bersama dalam sebuah Pod adalah kumpulan Linux namespace, cgroup dan
kemungkinan segi isolasi lain, hal yang sama yang mengisolasi kontainer Docker.
Dalam sebuah konteks pada Pod, setiap aplikasi bisa menerapkan sub-isolasi lebih lanjut.</p><p>Semua kontainer dalam suatu Pod akan berbagi alamat IP dan <em>port</em> yang sama,
dan bisa saling berkomunikasi melalui <code>localhost</code>. Komunikasi tersebut mengunakan
standar <em>inter-process communications</em> (IPC) seperti SystemV semaphores
atau POSIX shared memory. Kontainer pada Pod yang berbeda memiliki alamat IP
yang berbeda dan tidak dapat berkomunikasi menggunakan IPC tanpa
<a href=/id/docs/concepts/policy/pod-security-policy/>pengaturan khusus</a>. Kontainer ini
biasa berkomunikasi dengan yang lain menggunakan alamat IP setiap Pod.</p><p>Aplikasi dalam suatu Pod juga memiliki akses ke <a class=glossary-tooltip title='Sebuah direktori yang mengandung data, dapat diakses o;eh kontainer-kontainer di dalam pod.' data-toggle=tooltip data-placement=top href=/docs/concepts/storage/volumes/ target=_blank aria-label='ruang penyimpanan'>ruang penyimpanan</a> bersama,
yang didefinisikan sebagai bagian dari Pod dan dibuat bisa diikatkan ke masing-masing
<em>filesystem</em> pada aplikasi.</p><p>Dalam istilah konsep <a href=https://www.docker.com/>Docker</a>, sebuah Pod dimodelkan sebagai
gabungan dari kontainer Docker yang berbagi <em>namespace</em> dan ruang penyimpanan <em>filesystem</em>.</p><p>Layaknya aplikasi dengan kontainer, Pod dianggap sebagai entitas yang relatif tidak kekal
(tidak bertahan lama). Seperti yang didiskusikan dalam
<a href=/id/docs/concepts/workloads/pods/pod-lifecycle/>siklus hidup Pod</a>, Pod dibuat, diberikan
ID unik (UID), dan dijadwalkan pada suatu mesin dan akan tetap disana hingga dihentikan
(bergantung pada aturan <em>restart</em>) atau dihapus. Jika <a class=glossary-tooltip title='A node is a worker machine in Kubernetes.' data-toggle=tooltip data-placement=top href=/docs/concepts/architecture/nodes/ target=_blank aria-label=mesin>mesin</a>
mati, maka semua Pod pada mesin tersebut akan dijadwalkan untuk dihapus, namun setelah
suatu batas waktu. Suatu Pod tertentu (sesuai dengan ID unik) tidak akan dijadwalkan ulang
ke mesin baru, namun akan digantikan oleh Pod yang identik, bahkan jika dibutuhkan bisa
dengan nama yang sama, tapi dengan ID unik yang baru
(baca <a href=/id/docs/concepts/workloads/controllers/replicationcontroller/><em>replication controller</em></a>
untuk info lebih lanjut)</p><p>Ketika sesuatu dikatakan memiliki umur yang sama dengan Pod, misalnya saja ruang penyimpanan,
maka itu berarti akan tetap ada selama Pod tersebut masih ada. Jika Pod dihapus dengan
alasan apapun, sekalipun Pod pengganti yang identik telah dibuat, semua yang berhubungan
(misalnya ruang penyimpanan) akan dihapus dan dibuat ulang.</p><figure><img src=/images/docs/pod.svg width=50%><figcaption><h4>Pod diagram</h4></figcaption></figure><p><em>Sebuah Pod dengan banyak kontainer, yaitu <em>File Puller</em> dan <em>Web Server</em> yang menggunakan
ruang penyimpanan persisten untuk berbagi ruang penyimpanan bersama antara kontainer.</em></p><h2 id=motivasi-suatu-pods>Motivasi suatu Pods</h2><h3 id=pengelolaan>Pengelolaan</h3><p>Pod adalah suatu model dari pola beberapa proses yang bekerja sama dan membentuk
suatu unit layanan yang kohesif. Menyederhanakan proses melakukan <em>deploy</em> dan
pengelolaan aplikasi dengan menyediakan abstraksi tingkat yang lebih tinggi
daripada konstituen aplikasinya. Pod melayani sebagai unit dari <em>deployment</em>,
penskalaan horizontal, dan replikasi. <em>Colocation</em> (<em>co-scheduling</em>), berbagi nasib
(misalnya dimatikan), replikasi terkoordinasi, berbagi sumber daya dan
pengelolaan ketergantungan akan ditangani otomatis untuk kontainer dalam suatu Pod.</p><h3 id=berbagi-sumber-daya-dan-komunikasi>Berbagi sumber daya dan komunikasi</h3><p>Pod memungkinkan berbagi data dan komunikasi diantara konstituennya.</p><p>Semua aplikasi dalam suatu Pod menggunakan <em>namespace</em> jaringan yang sama
(alamat IP dan <em>port</em> yang sama), dan menjadikan bisa saling mencari dan berkomunikasi
dengan menggunakan <code>localhost</code>. Oleh karena itu, aplikasi dalam Pod harus
berkoordinasi mengenai penggunaan <em>port</em>. Setiap Pod memiliki alamat IP
dalam satu jaringan bersama yang bisa berkomunikasi dengan komputer lain
dan Pod lain dalam jaringan yang sama.</p><p>Kontainer dalam suatu Pod melihat <em>hostname</em> sistem sebagai sesuatu yang sama
dengan konfigurasi <code>name</code> pada Pod. Informasi lebih lanjut terdapat dibagian
<a href=/id/docs/concepts/cluster-administration/networking/>jaringan</a>.</p><p>Sebagai tambahan dalam mendefinisikan kontainer aplikasi yang berjalan dalam Pod,
Pod memberikan sepaket sistem penyimpanan bersama. Sistem penyimpanan memungkinkan
data untuk bertahan saat kontainer dijalankan ulang dan dibagikan kepada semua
aplikasi dalam Pod tersebut.</p><h2 id=penggunaan-pod>Penggunaan Pod</h2><p>Pod dapat digunakan untuk menjalankan beberapa aplikasi yang terintegrasi
secara vertikal (misalnya LAMP), namun motivasi utamanya adalah untuk mendukung
berlokasi bersama, mengelola program pembantu, diantaranya adalah:</p><ul><li>sistem pengelolaan konten, pemuat berkas dan data, manajer <em>cache</em> lokal, dll.</li><li>catatan dan <em>checkpoint</em> cadangan, kompresi, rotasi, dll.</li><li>pengamat perubahan data, pengintip catatan, adapter pencatatan dan pemantauan,
penerbit peristiwa, dll.</li><li>proksi, jembatan dan adaptor.</li><li>pengontrol, manajer, konfigurasi dan pembaharu.</li></ul><p>Secara umum, masing-masing Pod tidak dimaksudkan untuk menjalankan beberapa
aplikasi yang sama.</p><p>Penjelasan lebih lengkap bisa melihat <a href=https://kubernetes.io/blog/2015/06/the-distributed-system-toolkit-patterns>The Distributed System ToolKit: Patterns for Composite Containers</a>.</p><h2 id=alternatif-pertimbangan>Alternatif pertimbangan</h2><p>Kenapa tidak menjalankan banyak program dalam satu kontainer (Docker)?</p><ol><li>Transparansi. Membuat kontainer dalam suatu Pod menjadi terlihat dari infrastruktur,
memungkinkan infrastruktur menyediakan servis ke kontainer tersebut, misalnya saja
pengelolaan proses dan pemantauan sumber daya. Ini memfasilitasi sejumlah
kenyamanan untuk pengguna.</li><li>Pemisahan ketergantungan perangkat lunak. Setiap kontainer mungkin memiliki
versi, dibuat dan dijalankan ulang secara independen. Kubernetes mungkin mendukung
pembaharuan secara langsung terhadap suatu kontainer, suatu saat nanti.</li><li>Mudah digunakan. Penguna tidak diharuskan menjalankan manajer prosesnya sendiri,
khawatir dengan sinyal dan propagasi <em>exit-code</em>, dan lain sebagainya.</li><li>Efisiensi. Karena infrastruktur memegang lebih banyak tanggung jawab, kontainer
bisa lebih ringan.</li></ol><p>Kenapa tidak mendukung penjadwalan kontainer berdasarkan <em>affinity</em>?</p><p>Cara itu bisa menyediakan lokasi yang sama, namun tidak memberikan banyak
keuntungan dari Pod, misalnya saja berbagi sumber daya, IPC, jaminan berbagi nasib
dan kemudahan manajemen.</p><h2 id=ketahanan-suatu-pod-atau-kekurangan>Ketahanan suatu Pod (atau kekurangan)</h2><p>Pod tidak dimaksudkan untuk diperlakukan sebagai entitas yang tahan lama.
Mereka tidak akan bertahan dengan kegagalan penjadwalan, kegagalan mesin,
atau <em>eviction</em> (pengusiran), misalnya karena kurangnya sumber daya atau dalam suatu
kasus mesin sedang dalam pemeliharaan.</p><p>Secara umum, pengguna tidak seharusnya butuh membuat Pod secara langsung. Mereka
seharusnya selalu menggunakan pengontrol, sekalipun untuk yang tunggal, misalnya,
<a href=/id/docs/concepts/workloads/controllers/deployment/><em>Deployment</em></a>. Pengontrol
menyediakan penyembuhan diri dengan ruang lingkup kelompok, begitu juga dengan
pengelolaan replikasi dan penluncuran.
Pengontrol seperti <a href=/id/docs/concepts/workloads/controllers/statefulset.md><em>StatefulSet</em></a>
bisa memberikan dukungan terhadap Pod yang <em>stateful</em>.</p><p>Penggunaan API kolektif sebagai <em>user-facing primitive</em> utama adalah hal yang
relatif umum diantara sistem penjadwalan kluster, seperti</p><p><a href=https://research.google.com/pubs/pub43438.html>Borg</a>,
<a href=https://mesosphere.github.io/marathon/docs/rest-api.html>Marathon</a>,
<a href=http://aurora.apache.org/documentation/latest/reference/configuration/#job-schema>Aurora</a>, dan
<a href=https://www.slideshare.net/Docker/aravindnarayanan-facebook140613153626phpapp02-37588997>Tupperware</a>.</p><p>Pod diekspose sebagai <em>primitive</em> untuk memfasilitasi hal berikut:</p><ul><li>penjadwalan dan pengontrol sifat <em>pluggability</em></li><li>mendukung operasi pada level Pod tanpa perlu melakukan proksi melalui API pengontrol</li><li>pemisahan antara umur suatu Pod dan pengontrol, seperti misalnya <em>bootstrapping</em>.</li><li>pemisahan antara pengontrol dan servis, pengontrol <em>endpoint</em> hanya memperhatikan Pod</li><li>komposisi yang bersih antara fungsionalitas dilevel Kubelet dan klaster. Kubelet
secara efektif adalah pengontrol Pod.</li><li>aplikasi dengan ketersediaan tinggi, yang akan mengharapkan Pod akan digantikan
sebelum dihentikan dan tentu saja sebelum dihapus, seperti dalam kasus penggusuran
yang direncanakan atau pengambilan gambar.</li></ul><h2 id=penghentian-pod>Penghentian Pod</h2><p>Karena Pod merepresentasikan proses yang berjalan pada mesin didalam klaster, sangat
penting untuk memperbolehkan proses ini berhenti secara normal ketika sudah tidak
dibutuhkan (dibandingkan dengan dihentikan paksa dengan sinyal KILL dan tidak memiliki
waktu untuk dibersihkan). Pengguna seharusnya dapat meminta untuk menghapus dan tahu
proses penghentiannya, serta dapat memastikan penghentian berjalan sempurna. Ketika
pengguna meminta menghapus Pod, sistem akan mencatat masa tenggang untuk penghentian
secara normal sebelum Pod dipaksa untuk dihentikan, dan sinyal TERM akan dikirim ke
proses utama dalam setiap kontainer. Setelah masa tenggang terlewati, sinyal KILL
akan dikirim ke setiap proses dan Pod akan dihapus dari API server. Jika Kubelet
atau kontainer manajer dijalankan ulang ketika menunggu suatu proses dihentikan,
penghentian tersebut akan diulang dengan mengembalikan masa tenggang senilai semula.</p><p>Contohnya sebagai berikut:</p><ol><li>Pengguna mengirim perintah untuk menghapus Pod, dengan masa tenggang (30 detik)</li><li>Pod dalam API server akan diperbarui dengan waktu dimana Pod dianggap "mati"
bersama dengan masa tenggang.</li><li>Pod ditampilkan dalam status "Terminating" ketika tercantum dalam perintah klien</li><li>(bersamaan dengan poin 3) Ketika Kubelet melihat Pod sudah ditandai sebagai
"Terminating" karena waktu pada poin 2 sudah diatur, ini memulai proses penghentian Pod<ol><li>Jika salah satu kontainer pada Pod memiliki
<a href=/id/docs/concepts/containers/container-lifecycle-hooks/#hook-details>preStop <em>hook</em></a>,
maka akan dipanggil di dalam kontainer. Jika <code>preStop</code> <em>hook</em> masih berjalan
setelah masa tenggang habis, langkah 2 akan dipanggil dengan tambahan masa tenggang
yang sedikit, 2 detik.</li><li>Semua kontainer akan diberikan sinyal TERM. Sebagai catatan, tidak semua kontainer
akan menerima sinyal TERM dalam waktu yang sama dan mungkin butuh waktu untuk
menjalankan <code>preStop</code> <em>hook</em> jika bergantung pada urutan penghentiannya.</li></ol></li><li>(bersamaan dengan poin 3) Pod akan dihapus dari daftar <em>endpoint</em> untuk servis dan
tidak lagi dianggap sebagai bagian dari Pod yang berjalan dalam <em>replication controllers</em>.
Pod yang dihentikan, secara perlahan tidak akan melayani permintaan karena load balancer
(seperti servis proksi) menghapus mereka dari daftar rotasi.</li><li>Ketika masa tenggang sudah lewat, semua proses yang masih berjalan dalam Pod
akan dihentikan dengan sinyal SIGKILL.</li><li>Kubelet akan selesai menghapus Pod dalam API server dengan mengatur masa tenggang
menjadi 0 (langsung menghapus). Pod akan menghilang dari API dan tidak lagi terlihat
oleh klien.</li></ol><p>Secara <em>default</em>, semua penghapusan akan berjalan normal selama 30 detik. Perintah
<code>kubectl delete</code> mendukung opsi <code>--grace-period=&lt;waktu dalam detik></code> yang akan
memperbolehkan pengguna untuk menimpa nilai awal dan memberikan nilai sesuai keinginan
pengguna. Nilai <code>0</code> akan membuat Pod
<a href=/id/docs/concepts/workloads/pods/pod/#force-deletion-of-pods>dihapus paksa</a>.
Kamu harus memberikan opsi tambahan <code>--force</code> bersamaan dengan <code>--grace-period=0</code>
untuk melakukan penghapusan paksa.</p><h3 id=penghapusan-paksa-sebuah-pod>Penghapusan paksa sebuah Pod</h3><p>Penghapusan paksa dari sebuah Pod didefinisikan sebagai penghapusan Pod dari <em>state</em>
klaster dan etcd secara langsung. Ketika penghapusan paksa dilakukan, API server tidak
akan menunggu konfirmasi dari kubelet bahwa Pod sudah dihentikan pada mesin ia berjalan.
Ini menghapus Pod secara langsung dari API, sehingga Pod baru bisa dibuat dengan nama
yang sama. Dalam mesin, Pod yang dihentikan paksa akan tetap diberikan sedikit masa
tenggang sebelum dihentikan paksa.</p><p>Penghentian paksa dapat menyebabkan hal berbahaya pada beberapa Pod dan seharusnya
dilakukan dengan perhatian lebih. Dalam kasus StatefulSet Pods, silakan melihat
dokumentasi untuk <a href=/docs/tasks/run-application/force-delete-stateful-set-pod/>penghentian Pod dari StatefulSet</a>.</p><h2 id=hak-istimewa-untuk-kontainer-pada-pod>Hak istimewa untuk kontainer pada Pod</h2><p>Setiap kontainer dalam Pod dapat mengaktifkan hak istimewa (mode <em>privileged</em>), dengan menggunakan tanda
<code>privileged</code> pada <a href=/id/docs/tasks/configure-pod-container/security-context/>konteks keamanan</a>
pada spesifikasi kontainer. Ini akan berguna untuk kontainer yang ingin menggunakan
kapabilitas Linux seperti memanipulasi jaringan dan mengakses perangkat. Proses dalam
kontainer mendapatkan hak istimewa yang hampir sama dengan proses di luar kontainer.
Dengan hak istimerwa, seharusnya lebih mudah untuk menulis pada jaringan dan <em>plugin</em>
ruang penyimpanan sebagai Pod berbeda yang tidak perlu dikompilasi ke dalam kubelet.</p><div class="alert alert-info note callout" role=alert><strong>Catatan:</strong> <em>Runtime</em> kontainer kamu harus mendukung konsep hak istimewa kontainer untuk membuat
pengaturan ini menjadi relevan.</div><h2 id=api-object>API Object</h2><p>Pod adalah sumber daya tingkat tinggi dalam Kubernetes REST API.
Definisi <a href=/docs/reference/generated/kubernetes-api/v1.25/#pod-v1-core>Objek Pod API</a> menjelaskan mengenai objek secara lengkap.</p></div><div class=td-content style=page-break-before:always><h1 id=pg-c3c2b9cf30915ec9d46c147201da3332>1.3 - Siklus Hidup Pod</h1><p></p><p>Halaman ini menjelaskan siklus hidup sebuah Pod</p><h2 id=fase-pod>Fase Pod</h2><p><em>Field</em> <code>status</code> dari sebuah Pod merupakan sebuah objek <a href=/docs/reference/generated/kubernetes-api/v1.25/#podstatus-v1-core>PodStatus</a>, yang memiliki sebuah <em>field</em> <code>phase</code>.</p><p>Fase dari sebuah Pod adalah sesuatu yang sederhana, ringkasan yang lebih tinggi tentang Pod dalam siklus hidupnya. Fase ini tidak ditujukan sebagai sebuah kesimpulan yang luas dari observasi suatu kontainer atau <em>state</em> suatu Pod, serta tidak ditujukan sebagai <em>state machine</em> yang luas.</p><p>Jumlah dan arti dari nilai-nilai fase Pod dijaga ketat. Selain yang ada dalam dokumentasi ini, tidak perlu berasumsi mengenai Pod telah diberikan nilai <code>phase</code>.</p><p>Berikut adalah nilai yang mungkin diberikan untuk suatu <code>phase</code>:</p><table><thead><tr><th style=text-align:left>Nilai</th><th style=text-align:left>Deskripsi</th></tr></thead><tbody><tr><td style=text-align:left><code>Pending</code></td><td style=text-align:left>Pod telah disetujui oleh sistem Kubernetes, tapi ada satu atau lebih <em>image</em> kontainer yang belum terbuat. Ini termasuk saat sebelum dijadwalkan dan juga saat mengunduh <em>image</em> melalui jaringan, yang mungkin butuh beberapa waktu.</td></tr><tr><td style=text-align:left><code>Running</code></td><td style=text-align:left>Pod telah terikat ke suatu node, dan semua kontainer telah terbuat. Setidaknya ada 1 kontainer yang masih berjalan, atau dalam proses memulai atau <em>restart</em>.</td></tr><tr><td style=text-align:left><code>Succeeded</code></td><td style=text-align:left>Semua kontainer di dalam Pod sudah berhasil dihentikan, dan tidak akan dilakukan <em>restart</em>.</td></tr><tr><td style=text-align:left><code>Failed</code></td><td style=text-align:left>Semua kontainer dalan suatu Pod telah dihentikan, dan setidaknya ada satu kontainer yang terhenti karena kegagalan. Itu merupakan kontainer yang keluar dengan kode status bukan 0 atau dihentikan oleh sistem.</td></tr><tr><td style=text-align:left><code>Unknown</code></td><td style=text-align:left><em>State</em> suatu Pod tidak dapat diperoleh karena suatu alasan, biasanya karena kesalahan dalam komunikasi dengan <em>host</em> yang digunakan Pod tersebut.</td></tr></tbody></table><h2 id=kondisi-pod>Kondisi Pod</h2><p>Suatu Pod memiliki sebuah PodStatus, yang merupakan <em>array</em> dari <a href=/docs/reference/generated/kubernetes-api/v1.25/#podcondition-v1-core>PodConditions</a> yang telah atau belum dilewati oleh Pod. Setiap elemen dari <em>array</em> PodConditions mungkin memiliki enam <em>field</em> berikut:</p><ul><li><p><em>Field</em> <code>lastProbeTime</code> memberikan nilai <em>timestamp</em> yang menandakan kapan terakhir kali kondisi kondisi Pod diperiksa.</p></li><li><p><em>Field</em> <code>lastTransitionTime</code> memberikan nilai <em>timestamp</em> yang menandakan kapan terakhir kali Pod berubah status ke status lain.</p></li><li><p><em>Field</em> <code>message</code> adalah pesan yang bisa dibaca manusia yang mengidikasikan detail dari suatu transisi.</p></li><li><p><em>Field</em> <code>reason</code> adalah suatu alasan yang unik, satu kata, ditulis secara <em>CamelCase</em> untuk kondisi transisi terakhir.</p></li><li><p><em>Field</em> <code>status</code> adalah sebuah kata dengan kemungkinan nilainya berupa "<code>True</code>", "<code>False</code>", dan "<code>Unknown</code>".</p></li><li><p><em>Field</em> <code>type</code> adalah sebuah kata yang memiliki kemungkinan nilai sebagai berikut:</p><ul><li><code>PodScheduled</code>: Pod telah dijadwalkan masuk ke node;</li><li><code>Ready</code>: Pod sudah mampu menerima <em>request</em> masuk dan seharusnya sudah ditambahkan ke daftar pembagian beban kerja untuk servis yang sama;</li><li><code>Initialized</code>: Semua <a href=/id/docs/concepts/workloads/pods/init-containers>init containers</a> telah berjalan sempurna.</li><li><code>Unschedulable</code>: <em>scheduler</em> belum dapat menjadwalkan Pod saat ini, sebagai contoh karena kekurangan <em>resources</em> atau ada batasan-batasan lain.</li><li><code>ContainersReady</code>: Semua kontainer di dalam Pod telah siap.</li></ul></li></ul><h2 id=pemeriksaan-kontainer>Pemeriksaan Kontainer</h2><p>Sebuah <a href=/docs/reference/generated/kubernetes-api/v1.25/#probe-v1-core>Probe</a> adalah sebuah diagnosa yang dilakukan secara berkala oleh <a href=/docs/admin/kubelet/>kubelet</a> dalam suatu kontainer. Untuk melakukan diagnosa, kubelet memanggil sebuah <a href=https://godoc.org/k8s.io/kubernetes/pkg/api/v1#Handler>Handler</a> yang diimplementasikan oleh kontainer. Ada 3 tipe <em>Handler</em> yang tersedia, yaitu:</p><ul><li><p><a href=/docs/reference/generated/kubernetes-api/v1.25/#execaction-v1-core>ExecAction</a>: Mengeksekusi perintah tertentu di dalam kontainer. Diagnosa dikatakan berhasil jika perintah selesai dengan kode status 0.</p></li><li><p><a href=/docs/reference/generated/kubernetes-api/v1.25/#tcpsocketaction-v1-core>TCPSocketAction</a>: Melakukan pengecekan TCP terhadap alamat IP kontainer dengan <em>port</em> tertentu. Diagnosa dikatakan berhasil jika <em>port</em> tersebut terbuka.</p></li><li><p><a href=/docs/reference/generated/kubernetes-api/v1.25/#httpgetaction-v1-core>HTTPGetAction</a>: Melakukan sebuah <em>request</em> HTTP Get terhadap alamat IP kontainer dengan <em>port</em> dan <em>path</em> tertentu. Diagnosa dikatakan berhasil jika responnya memiliki kode status lebih besar atau sama dengan 200 dan kurang dari 400.</p></li></ul><p>Setiap pemeriksaan akan menghasilkan salah satu dari tiga hasil berikut:</p><ul><li><em>Success</em>: Kontainer berhasil melakukan diagnosa.</li><li><em>Failure</em>: Kontainer gagal melakukan diagnosa.</li><li><em>Unknown</em>: Gagal melakukan diagnosa, sehingga tidak ada aksi yang harus dilakukan.</li></ul><p><em>Kubelet</em> dapat secara optimal melakukan dan bereaksi terhadap dua jenis pemeriksaan yang sedang berjalan pada kontainer, yaitu:</p><ul><li><p><code>livenessProbe</code>: Ini menunjukkan apakah kontainer sedang berjalan. Jika tidak berhasil melakukan pemeriksaan terhadap <em>liveness</em> dari kontainer, maka kubelet akan mematikan kontainer, dan kontainer akan mengikuti aturan dari <a href=#restart-policy><em>restart policy</em></a>. Jika kontainer tidak menyediakan pemeriksaan terhadap <em>liveness</em>, maka nilai dari <em>state</em> adalah <code>Success</code>.</p></li><li><p><code>readinessProbe</code>: Ini menunjukan apakah kontainer sudah siap melayani <em>request</em>. Jika tidak berhasil melakukan pemeriksaan terhadap kesiapan dari kontainer, maka <em>endpoints controller</em> akan menghapus alamat IP Pod dari daftar semua <em>endpoint</em> untuk servis yang sama dengan Pod. Nilai awal <em>state</em> sebelum jeda awal adalah <code>Failure</code>. Jika kontainer tidak menyediakan pemeriksaan terhadap <em>readiness</em>, maka nilai awal <em>state</em> adalah <code>Success</code>.</p></li></ul><h3 id=kapan-sebaiknya-menggunakan-pemeriksaan-terhadap-liveness-atau-readiness>Kapan sebaiknya menggunakan pemeriksaan terhadap <em>liveness</em> atau <em>readiness</em>?</h3><p>Jika proses dalam kontainer mungkin gagal yang dikarenakan menghadapi suatu masalah
atau menjadi tidak sehat, maka pemeriksaan terhadap <em>liveness</em> tidak diperlukan.
Kubelet akan secara otomatis melakukan aksi yang tepat mengikuti <code>restartPolicy</code> dari Pod.</p><p>Jika kamu ingin kontainer bisa dimatikan dan dijalankan ulang ketika gagal melakukan
pemeriksaan, maka tentukan pemeriksaan <em>liveness</em> dan tentukan nilai <code>restartPolicy</code> sebagai <code>Always</code> atau <code>OnFailure</code>.</p><p>Jika kamu ingin mulai mengirim <em>traffic</em> ke Pod hanya ketika pemeriksaan berhasil,
maka tentukan pemeriksaan <em>readiness</em>. Dalam kasus ini, pemeriksaan <em>readiness</em> mungkin
akan sama dengan pemeriksaan <em>liveness</em>, tapi keberadaan pemeriksaan <em>readiness</em> dalam
<em>spec</em> berarti Pod akan tetap dijalankan tanpa menerima <em>traffic</em> apapun dan akan
mulai menerima <em>traffic</em> ketika pemeriksaan yang dilakukan mulai berhasil.
Jika kontainermu dibutuhkan untuk tetap berjalan ketika <em>loading</em> data yang besar,
<em>file</em> konfigurasi, atau melakukan migrasi ketika <em>startup</em>, maka tentukanlah pemeriksaan <em>readiness</em>.</p><p>Jika kamu ingin kontainermu dalam mematikan dirinya sendiri, kamu dapat menentukan
suatu pemeriksaan <em>readiness</em> yang melakukan pengecekan terhadap <em>endpoint</em> untuk <em>readiness</em>.
<em>endpoint</em> tersebut berbeda dengan <em>endpoint</em> untuk pengecekan <em>liveness</em>.</p><p>Perlu dicatat, jika kamu hanya ingin bisa menutup <em>request</em> ketika Pod sedang dihapus
maka kamu tidak perlu menggunakan pemeriksaan <em>readiness</em>. Dalam penghapusan, Pod akan
secara otomatis mengubah <em>state</em> dirinya menjadi <em>unready</em> tanpa peduli apakah terdapat
pemeriksaan <em>readiness</em> atau tidak. Pod tetap ada pada <em>state unready</em> selama menunggu
kontainer dalam Pod berhenti.</p><p>Untuk informasi lebih lanjut mengenai pengaturan pemeriksaan <em>liveness</em> atau <em>readiness</em>, lihat bagian
<a href=/docs/tasks/configure-pod-container/configure-liveness-readiness-probes/>Konfigurasi <em>Liveness</em> dan <em>Readiness</em> <em>Probe</em></a>.</p><h2 id=status-pod-dan-kontainer>Status Pod dan Kontainer</h2><p>Untuk informasi lebih mendalam mengenai status Pod dan kontainer, silakan lihat
<a href=/docs/reference/generated/kubernetes-api/v1.25/#podstatus-v1-core>PodStatus</a>
dan
<a href=/docs/reference/generated/kubernetes-api/v1.25/#containerstatus-v1-core>ContainerStatus</a>.
Mohon diperhatikan, informasi tentang status Pod bergantung pada
<a href=/docs/reference/generated/kubernetes-api/v1.25/#containerstatus-v1-core>ContainerState</a>.</p><h2 id=state-kontainer>State Kontainer</h2><p>Ketika Pod sudah ditempatkan pada suatu node oleh scheduler, kubelet mulai membuat kontainer menggunakan <em>runtime</em> kontainer.
Ada tiga kemungkinan <em>state</em> untuk suatu kontainer, yaitu Waiting, Running, dan Terminated.
Untuk mengecek <em>state</em> suatu kontainer, kamu bisa menggunakan perintah <code>kubectl describe pod [NAMA_POD]</code>.
<em>State</em> akan ditampilkan untuk masing-masing kontainer dalam Pod tersebut.</p><ul><li><p><code>Waiting</code>: Merupakan <em>state</em> default dari kontainer. Jika <em>state</em> kontainer bukan Running atau Terminated, berarti dalam <em>Wating state</em>.
Suatu kontainer dalam Waiting <em>state</em> akan tetap menjalan operasi-operasi yang dibutuhkan, misalnya mengunduh <em>images</em>, mengaplikasikan Secrets, dsb.
Bersamaan dengan <em>state</em> ini, sebuah pesan dan alasan tentang <em>state</em> akan ditampilkan untuk memberi informasi lebih.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#00f;font-weight:700>...</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>State</span>:<span style=color:#bbb>          </span>Waiting<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>   </span><span style=color:green;font-weight:700>Reason</span>:<span style=color:#bbb>       </span>ErrImagePull<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>...<span style=color:#bbb>
</span></span></span></code></pre></div></li><li><p><code>Running</code>: Menandakan kontainer telah berjalan tanpa masalah. Setelah kontainer masuk ke <em>state</em> Running, jika terdapat <em>hook</em> <code>postStart</code> maka akan dijalankan. <em>State</em> ini juga menampilkan waktu ketika kontainer masuk ke <em>state</em> Running.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#00f;font-weight:700>...</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>   </span><span style=color:green;font-weight:700>State</span>:<span style=color:#bbb>          </span>Running<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>Started</span>:<span style=color:#bbb>      </span>Wed, 30 Jan 2019 16:46:38 +0530<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:#00f;font-weight:700>...</span><span style=color:#bbb>
</span></span></span></code></pre></div></li><li><p><code>Terminated</code>: Menandakan kontainer telah menyelesaikan "tugasnya". Kontainer akan menjadi <em>state</em> ini ketika telah menyelesaikan eksekusi atau terjadi kesalahan. Terlepas dari itu, sebuah alasan dan <em>exit code</em> akan ditampilkan, bersama dengan waktu kontainer mulai dijalankan dan waktu berhenti. Sebelum kontainer masuk ke <em>state</em> Terminated, jika terdapat <code>preStop</code> <em>hook</em> maka akan dijalankan.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#00f;font-weight:700>...</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>   </span><span style=color:green;font-weight:700>State</span>:<span style=color:#bbb>          </span>Terminated<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>     </span><span style=color:green;font-weight:700>Reason</span>:<span style=color:#bbb>       </span>Completed<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>     </span><span style=color:green;font-weight:700>Exit Code</span>:<span style=color:#bbb>    </span><span style=color:#666>0</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>     </span><span style=color:green;font-weight:700>Started</span>:<span style=color:#bbb>      </span>Wed, 30 Jan 2019 11:45:26 +0530<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>     </span><span style=color:green;font-weight:700>Finished</span>:<span style=color:#bbb>     </span>Wed, 30 Jan 2019 11:45:26 +0530<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb> </span>...<span style=color:#bbb>
</span></span></span></code></pre></div></li></ul><h2 id=pod-readiness-gate>Pod readiness gate</h2><div style=margin-top:10px;margin-bottom:10px><b>FEATURE STATE:</b> <code>Kubernetes v1.14 [stable]</code></div><p>Dalam rangka menambahkan ekstensibilitas terhadap kesiapan Pod dengan menggunakan
injeksi umpan balik tambahan atau sinyal ke dalam <code>PodStatus</code>,
Kubernetes 1.11 memperkenalkan sebuah fitur bernama <a href=https://github.com/kubernetes/enhancements/blob/master/keps/sig-network/0007-pod-ready%2B%2B.md>Pod ready++</a>.
Kamu dapat menggunakan <em>field</em> baru <code>ReadinessGate</code> dalam sebuah <code>PodSpec</code> untuk
menunjukan kondisi tambahan yang akan dievaluasi untuk kesiapan Pod. Jika Kubernetes
tidak dapat menemukan kondisi pada <em>field</em> <code>status.conditions</code> dalam suatu Pod,
maka statusnya akan secara otomatis menjadi <code>False</code>. Berikut adalah contoh pemakaiannya:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>Kind</span>:<span style=color:#bbb> </span>Pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:#00f;font-weight:700>...</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>readinessGates</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:green;font-weight:700>conditionType</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;www.example.com/feature-1&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>status</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>conditions</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:green;font-weight:700>type</span>:<span style=color:#bbb> </span>Ready <span style=color:#bbb> </span><span style=color:#080;font-style:italic># ini adalah PodCondition yang telah tersedia</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>status</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;False&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>lastProbeTime</span>:<span style=color:#bbb> </span><span style=color:#a2f;font-weight:700>null</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>lastTransitionTime</span>:<span style=color:#bbb> </span>2018-01-01T00:00:00Z<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:green;font-weight:700>type</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;www.example.com/feature-1&#34;</span><span style=color:#bbb>   </span><span style=color:#080;font-style:italic># sebuah PodCondition tambahan</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>status</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;False&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>lastProbeTime</span>:<span style=color:#bbb> </span><span style=color:#a2f;font-weight:700>null</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>lastTransitionTime</span>:<span style=color:#bbb> </span>2018-01-01T00:00:00Z<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>containerStatuses</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:green;font-weight:700>containerID</span>:<span style=color:#bbb> </span>docker://abcd...<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>ready</span>:<span style=color:#bbb> </span><span style=color:#a2f;font-weight:700>true</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:#00f;font-weight:700>...</span><span style=color:#bbb>
</span></span></span></code></pre></div><p>Kondisi Pod yang baru harus memenuhi <a href=/id/docs/concepts/overview/working-with-objects/labels/#syntax-and-character-set>format label</a> pada Kubernetes.
Sejak perintah <code>kubectl patch</code> belum mendukung perubahan status objek, kondisi Pod yang baru harus mengubah melalui aksi <code>PATCH</code> dengan menggunakan
salah satu dari <a href=/docs/reference/using-api/client-libraries/>KubeClient <em>libraries</em></a>.</p><p>Dengan diperkenalkannya kondisi Pod yang baru, sebuah Pod akan dianggap siap hanya jika memenuhi dua syarat berikut:</p><ul><li>Semua kontainer dalam Pod telah siap.</li><li>Semua kontainer yang diatur dalam <code>ReadinessGates</code> bernilai "<code>True</code>".</li></ul><p>Untuk memfasilitasi perubahan tersebut terhadap evaluasi kesiapan Pod, dibuatkan sebuah kondisi Pod baru yaitu <code>ContainerReady</code>,
untuk dapat menangani kondisi Pod <code>Ready</code> yang sudah ada.</p><p>Dalam K8s 1.11, sebagai fitur <em>alpha</em>, fitur "Pod Ready++" harus diaktifkan melalui pengaturan
<a href=/docs/reference/command-line-tools-reference/feature-gates/>fitur <em>gate</em> pada <code>PodReadinessGates</code></a>.</p><p>Dalam K8s 1.12, fitur tersebut sudah diaktifkan dari awal.</p><h2 id=aturan-menjalankan-ulang>Aturan Menjalankan Ulang</h2><p>Sebuah PodSpec memiliki <em>field</em> <code>restartPolicy</code> dengan kemungkinan nilai berupa Always, OnFailure, dan Never.
Nilai awalnya berupa Always. <code>restartPolicy</code> akan berlaku untuk semua kontainer dalam Pod.
Kontainer yang mati dan dijalankan ulang oleh kubelet akan dijalankan ulang dengan jeda waktu yang ekponensial (10s, 20s, 40s, ...)
dengan batas atas senilai lima menit. Jeda waktu ini akan diatur ulang setelah sukses berjalan selama 10 menit.
Sesuai dengan diskusi pada <a href=/docs/user-guide/pods/#durability-of-pods-or-lack-thereof>dokumen Pod</a>,
setelah masuk ke suatu node, sebuah Pod tidak akan pindah ke node lain.</p><h2 id=umur-pod>Umur Pod</h2><p>Secara umum, Pod tidak hilang sampai ada yang menghapusnya. Ini mungkin dihapus oleh orang atau pengontrol.
Satu pengecualian untuk aturan ini adalah Pod dengan <code>phase</code> bernilai Succeeded atau Failed untuk waktu
beberapa lama yang akan berakhir dan secara otomatis akan dihapus.
(diatur dalam <code>terminated-pod-gc-threshold</code> pada master)</p><p>Tiga tipe pengontrol yang tersedia yaitu:</p><ul><li><p>Menggunakan sebuah <a href=/docs/concepts/jobs/run-to-completion-finite-workloads/>Job</a> untuk Pod yang diharapkan akan berakhir,
sebagai contoh, penghitungan dalam jumlah banyak. Jobs hanyak cocok untuk Pod dengan <code>restartPolicy</code> yang
bernilai OnFailure atau Never.</p></li><li><p>Menggunakan sebuah <a href=/id/docs/concepts/workloads/controllers/replicationcontroller/>ReplicationController</a>,
<a href=/id/docs/concepts/workloads/controllers/replicaset/>ReplicaSet</a>, atau
<a href=/id/docs/concepts/workloads/controllers/deployment/>Deployment</a> untuk Pod yang tidak diharapkan untuk berakhir,
sebagai contoh, <em>web servers</em>. ReplicationControllers hanya cocok digunakan pada Pod dengan <code>restartPolicy</code>
yang bernilai Always.</p></li><li><p>Menggunakan sebuah <a href=/id/docs/concepts/workloads/controllers/daemonset/>DaemonSet</a> untuk Pod yang akan berjalan
hanya satu untuk setiap mesin, karena menyediakan servis yang spesifik untuk suatu mesin.</p></li></ul><p>Ketiga tipe pengontrol ini memiliki sebuah PodTemplate. Direkomdasikan untuk membuat
pengontrol yang sesuai dan membiarkan ini membuat Pod, daripada membuat Pod sendiri secara langsung.
Karena Pod itu sendiri tidak tahan terhadap gagalnya suatu mesin, namun pengontrol tahan.</p><p>Jika node mati atau sambungannya terputus dari klaster, Kubernetes mengatur
<code>phase</code> dari semua Pod pada node yang mati untuk menjadi Failed.</p><h2 id=contoh>Contoh</h2><h3 id=contoh-liveness-probe-tingkat-lanjut>Contoh <em>Liveness Probe</em> tingkat lanjut</h3><p><em>Liveness probe</em> dieksekusi oleh kubelet, jadi semua permintaan akan dilakukan
di dalam <em>namespace</em> jaringan kubelet.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>labels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>test</span>:<span style=color:#bbb> </span>liveness<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>liveness-http<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>args</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- /server<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>k8s.gcr.io/liveness<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>livenessProbe</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>httpGet</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:#080;font-style:italic># ketika &#34;host&#34; tidak ditentukan, &#34;PodIP&#34; akan digunakan</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:#080;font-style:italic># host: my-host</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:#080;font-style:italic># ketika &#34;scheme&#34; tidak ditentukan, _scheme_ &#34;HTTP&#34; akan digunakan. Hanya &#34;HTTP&#34; and &#34;HTTPS&#34; yang diperbolehkan</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:#080;font-style:italic># scheme: HTTPS</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>path</span>:<span style=color:#bbb> </span>/healthz<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>port</span>:<span style=color:#bbb> </span><span style=color:#666>8080</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>httpHeaders</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>X-Custom-Header<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>value</span>:<span style=color:#bbb> </span>Awesome<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>initialDelaySeconds</span>:<span style=color:#bbb> </span><span style=color:#666>15</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>timeoutSeconds</span>:<span style=color:#bbb> </span><span style=color:#666>1</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>liveness<span style=color:#bbb>
</span></span></span></code></pre></div><h3 id=contoh-state>Contoh <em>State</em></h3><ul><li><p>Pod sedang berjalan dan memiliki sebuah kontainer. Kontainer berhenti dengan sukses.</p><ul><li>Mencatat <em>event</em> penyelesaian.</li><li>Jika nilai <code>restartPolicy</code> adalah:<ul><li>Always: Jalankan ulang kontainer; nilai <code>phase</code> Pod akan tetap Running.</li><li>OnFailure: nilai <code>phase</code> Pod akan berubah menjadi Succeeded.</li><li>Never: nilai <code>phase</code> Pod akan berubah menjadi Succeeded.</li></ul></li></ul></li><li><p>Pod sedang berjalan dan memiliki sebuah kontainer. Kontainer berhenti dengan kegagalan.</p><ul><li>Mencatat <em>event</em> kegagalan.</li><li>Jika nilai <code>restartPolicy</code> adalah:<ul><li>Always: Jalankan ulang kontainer, nilai <code>phase</code> Pod akan tetap Running.</li><li>OnFailure: Jalankan ulang kontainer, nilai <code>phase</code> Pod akan tetap Running.</li><li>Never: nilai <code>phase</code> Pod akan menjadi Failed.</li></ul></li></ul></li><li><p>Pod sedang berjalan dan memiliki dua kontainer. Kontainer pertama berhenti dengan kegagalan.</p><ul><li>Mencatat <em>event</em> kegagalan.</li><li>Jika nilai <code>restartPolicy</code> adalah:<ul><li>Always: Jalankan ulang kontainer, nilai <code>phase</code> Pod akan tetap Running.</li><li>OnFailure: Jalankan ulang kontainer, nilai <code>phase</code> Pod akan tetap Running.</li><li>Never: Tidak akan menjalankan ulang kontainer, nilai <code>phase</code> Pod akan tetap Running.</li></ul></li><li>Jika kontainer pertama tidak berjalan dan kontainer kedua berhenti:<ul><li>Mencatat <em>event</em> kegagalan.</li><li>Jika nilai <code>restartPolicy</code> adalah:<ul><li>Always: Jalankan ulang kontainer, nilai <code>phase</code> Pod akan tetap Running.</li><li>OnFailure: Jalankan ulang kontainer, nilai <code>phase</code> Pod akan tetap Running.</li><li>Never: nilai <code>phase</code> Pod akan menjadi Failed.</li></ul></li></ul></li></ul></li><li><p>Pod sedang berjalan dan memiliki satu kontainer. Kontainer berhenti karena kehabisan <em>memory</em>.</p><ul><li>Kontainer diberhentikan dengan kegagalan.</li><li>Mencatat kejadian kehabisan <em>memory</em> (OOM)</li><li>Jika nilai <code>restartPolicy</code> adalah:<ul><li>Always: Jalankan ulang kontainer, nilai <code>phase</code> Pod akan tetap Running.</li><li>OnFailure: Jalankan ulang kontainer, nilai <code>phase</code> Pod akan tetap Running.</li><li>Never: Mencatat kejadian kegagalan, nilai <code>phase</code> Pod akan menjadi Failed.</li></ul></li></ul></li><li><p>Pod sedang berjalan dan sebuah <em>disk</em> mati.</p><ul><li>Menghentikan semua kontainer.</li><li>Mencatat kejadian yang sesuai.</li><li>Nilai <code>phase</code> Pod menjadi Failed.</li><li>Jika berjalan menggunakan pengontrol, maka Pod akan dibuat ulang di tempat lain.</li></ul></li><li><p>Pod sedang berjalan, dan node mengalami <em>segmented out</em>.</p><ul><li>Node pengontrol menunggu sampai suatu batas waktu.</li><li>Node pengontrol mengisi nilai <code>phase</code> Pod menjadi Failed.</li><li>Jika berjalan menggunakan pengontrol, maka Pod akan dibuat ulang di tempat lain.</li></ul></li></ul><h2 id=selanjutnya>Selanjutnya</h2><ul><li><p>Dapatkan pengalaman langsung mengenai
<a href=/docs/tasks/configure-pod-container/attach-handler-lifecycle-event/>penambahan <em>handlers</em> pada kontainer <em>lifecycle events</em></a>.</p></li><li><p>Dapatkan pengalaman langsung mengenai
<a href=/docs/tasks/configure-pod-container/configure-liveness-readiness-probes/>pengaturan <em>liveness</em> dan <em>readiness probes</em></a>.</p></li><li><p>Pelajari lebih lanjut mengenai <a href=/id/docs/concepts/containers/container-lifecycle-hooks/><em>lifecycle hooks</em> pada kontainer</a>.</p></li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-1ccbd4eeded6ab138d98b59175bd557e>1.4 - Init Container</h1><p>Halaman ini menyediakan ikhtisar untuk Init Container, yaitu Container khusus yang dijalankan sebelum Container aplikasi dan berisi skrip peralatan atau <em>setup</em> yang tidak tersedia di dalam <em>image</em> dari Container aplikasi.</p><p>Fitur ini telah keluar dari trek Beta sejak versi 1.6. Init Container dapat dispesifikasikan di dalam PodSpec bersama dengan <em>array</em> <code>containers</code> aplikasi. Nilai anotasi <em>beta</em> akan tetap diperhitungkan dan akan menimpa nilai pada PodSpec, tetapi telah ditandai sebagai kedaluarsa pada versi 1.6 dan 1.7. Pada versi 1.8, anotasi <em>beta</em> tidak didukung lagi dan harus diganti menjadi nilai pada PodSpec.</p><h2 id=memahami-init-container>Memahami Init Container</h2><p>Sebuah <a href=/id/docs/concepts/workloads/pods/pod-overview/>Pod</a> dapat memiliki beberapa Container yang berjalan di dalamnya, dan dapat juga memiliki satu atau lebih Init Container, yang akan berjalan sebelum Container aplikasi dijalankan.</p><p>Init Container sama saja seperti Container biasa, kecuali:</p><ul><li>Mereka selalu berjalan hingga selesai.</li><li>Setiap Init Container harus selesai secara sukses sebelum Init Container berikutnya dijalankan.</li></ul><p>Jika sebuah Init Container tidak selesai secara sukses untuk sebuah Pod, Kubernetes akan mengulang kembali Pod tersebut secara terus menerus hingga Init Container selesai secara sukses. Tetapi, jika Pod tersebut memiliki nilai <code>restartPolicy</code> berupa <code>Never</code>, Pod tersebut tidak akan diulang kembali.</p><p>Untuk menspesifikasikan sebuah Container sebagai Init Container, tambahkan kolom <code>initContainers</code> pada PodSpec sebagai sebuah <em>array</em> JSON yang berisi objek dengan tipe <a href=/docs/reference/generated/kubernetes-api/v1.25/#container-v1-core>Container</a>, berdampingan dengan array <code>containers</code> aplikasi.
Status-status dari Init Container dikembalikan di kolom <code>.status.initContainerStatuses</code> sebagai sebuah <em>array</em> dari status-status Container (mirip seperti kolom <code>status.containerStatuses</code>)</p><h3 id=perbedaan-dengan-container-biasa>Perbedaan dengan Container biasa</h3><p>Init Container mendukung semua kolom dan fitur dari Container aplikasi, termasuk konfigurasi <code>limit</code> sumber daya, <code>volume</code>, dan keamanan. Tetapi, <code>request</code> dan <code>limit</code> sumber daya dari sebuah Init Container ditangani dengan cara yang sedikit berbeda, yang didokumentasikan di bagian <a href=#sumber-daya>Sumber Daya</a> di bawah. Juga, Init Container tidak mendukung <em>readiness probe</em> karena mereka harus berjalan hingga selesai sebelum Pod dapat siap.</p><p>Jika beberapa Init Container dispesifikasikan untuk sebuah Pod, Container-container tersebut akan dijalankan satu per satu secara berurutan. Setiap Init Container harus selesai secara sukses sebelum yang berikutnya dapat berjalan.
Saat semua Init Container telah berjalan hingga selesai, Kubernetes akan menginisialisasi Pod dan menjalankan Container aplikasi seperti biasa.</p><h2 id=apa-kegunaan-init-container>Apa kegunaan Init Container?</h2><p>Karena Init Container memiliki <em>image</em> yang berbeda dengan Container aplikasi, mereka memiliki beberapa kelebihan untuk kode yang berhubungan dengan dimulainya Init Container:</p><ul><li>Mereka dapat berisi dan menjalankan skrip peralatan yang tidak diinginkan untuk berada di dalam <em>image</em> Container aplikasi karena alasan keamanan.</li><li>Mereka dapat berisi skrip peralatan atau <em>setup</em> yang tidak tersedia di dalam <em>image</em> aplikasi. Misalnya, kita tidak perlu membuat <em>image</em> dengan instruksi <code>FROM</code> dari <em>image</em> lainnya hanya untuk menggunakan peralatan seperti <code>sed</code>, <code>awk</code>, <code>python</code>, atau <code>dig</code> pada saat <em>setup</em>.</li><li>Peran <em>builder</em> atau <em>deployer</em> dari <em>image</em> dapat bekerja secara independen tanpa harus digabung untuk membuat satu <em>image</em> aplikasi.</li><li>Mereka menggunakan <em>namespace</em> Linux, sehingga mereka dapat memiliki sudut pandang <em>filesystem</em> yang berbeda dengan Container aplikasi. Oleh karenanya, mereka dapat diberikan akses terhadap <code>Secret</code> yang tidak boleh diakses oleh Container aplikasi.</li><li>Mereka berjalan hingga selesai sebelum Container aplikasi manapun dimulai, sedangkan Container aplikasi dijalankan secara paralel, sehingga Init Container menyediakan cara yang mudah untuk menunda dijalankannya Container aplikasi hingga ketentuan-ketentuan yang diinginkan dipenuhi.</li></ul><h3 id=contoh-contoh>Contoh-contoh</h3><p>Berikut beberapa contoh kasus penggunaan Init Container:</p><ul><li><p>Menunggu sebuah Service untuk dibuat dengan perintah <em>shell</em> seperti:</p><pre><code>for i in {1..100}; do sleep 1; if dig myservice; then exit 0; fi; done; exit 1
</code></pre></li><li><p>Mendaftarkan suatu Pod ke sebuah peladen terpisah dari <em>downward API</em> dengan perintah seperti:</p><pre><code>`curl -X POST http://$MANAGEMENT_SERVICE_HOST:$MANAGEMENT_SERVICE_PORT/register -d 'instance=$(&lt;POD_NAME&gt;)&amp;ip=$(&lt;POD_IP&gt;)'`
</code></pre></li><li><p>Menunggu beberapa waktu sebelum menjalankan Container aplikasi dengan perintah seperti <code>sleep 60</code>.</p></li><li><p>Mengklon sebuah <em>git repository</em> ke dalam sebuah <em>volume</em>.</p></li><li><p>Menaruh nilai-nilai tertentu ke dalam sebuah <em>file</em> konfigurasi dan menjalankan peralatan <em>template</em> untuk membuat <em>file</em> konfigurasi secara dinamis untuk Container aplikasi utama. Misalnya, untuk menaruh nilai POD_IP ke dalam sebuah konfigurasi dan membuat konfigurasi aplikasi utama menggunakan Jinja.</p></li></ul><p>Contoh-contoh penggunaan yang lebih detail dapat dilihat pada <a href=/id/docs/concepts/workloads/controllers/statefulset/>dokumentasi StatefulSet</a> dan <a href=/docs/tasks/configure-pod-container/configure-pod-initialization/>petunjuk Produksi Pod</a>.</p><h3 id=menggunakan-init-container>Menggunakan Init Container</h3><p><em>File</em> YAML untuk Kubernetes 1.5 berikut menguraikan sebuah Pod sederhana yang memiliki dua buah Init Container.
Pod pertama menunggu <code>myservice</code> dan yang kedua menunggu <code>mydb</code>. Saat kedua Init Container tersebut sudah selesai, Podnya akan dijalankan.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>myapp-pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>labels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>app</span>:<span style=color:#bbb> </span>myapp<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>annotations</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>pod.beta.kubernetes.io/init-containers</span>:<span style=color:#bbb> </span><span style=color:#b44>&#39;[
</span></span></span><span style=display:flex><span><span style=color:#b44>        {
</span></span></span><span style=display:flex><span><span style=color:#b44>            &#34;name&#34;: &#34;init-myservice&#34;,
</span></span></span><span style=display:flex><span><span style=color:#b44>            &#34;image&#34;: &#34;busybox:1.28&#34;,
</span></span></span><span style=display:flex><span><span style=color:#b44>            &#34;command&#34;: [&#39;</span>sh&#39;, &#39;-c&#39;, &#34;until nslookup myservice.$(cat /var/run/secrets/kubernetes.io/serviceaccount/namespace).svc.cluster.local; do echo waiting for myservice; sleep 2; done&#34;]<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span>},<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span>{<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>            </span><span style=color:green;font-weight:700>&#34;name&#34;: </span><span style=color:#b44>&#34;init-mydb&#34;</span>,<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>            </span><span style=color:green;font-weight:700>&#34;image&#34;: </span><span style=color:#b44>&#34;busybox:1.28&#34;</span>,<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>            </span><span style=color:green;font-weight:700>&#34;command&#34;: </span>[<span style=color:#b44>&#39;sh&#39;</span>,<span style=color:#bbb> </span><span style=color:#b44>&#39;-c&#39;</span>,<span style=color:#bbb> </span><span style=color:#b44>&#34;until nslookup mydb.$(cat /var/run/secrets/kubernetes.io/serviceaccount/namespace).svc.cluster.local; do echo waiting for mydb; sleep 2; done&#34;</span>]<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span>}<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>]<span style=color:#b44>&#39;
</span></span></span><span style=display:flex><span><span style=color:#b44>spec:
</span></span></span><span style=display:flex><span><span style=color:#b44>  containers:
</span></span></span><span style=display:flex><span><span style=color:#b44>  - name: myapp-container
</span></span></span><span style=display:flex><span><span style=color:#b44>    image: busybox:1.28
</span></span></span><span style=display:flex><span><span style=color:#b44>    command: [&#39;</span>sh&#39;, &#39;-c&#39;, &#39;echo The app is running! &amp;&amp; sleep 3600&#39;]<span style=color:#bbb>
</span></span></span></code></pre></div><p>Ada sintaksis baru pada Kubernetes 1.6, walaupun sintaksis anotasi yang lama tetap akan bekerja untuk versi 1.6 dan 1.7. Sintaksis yang baru harus digunakan untuk versi 1.8 ke atas. Deklarasi Init Container dipindahkan ke dalam <code>spec</code>:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>myapp-pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>labels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>app</span>:<span style=color:#bbb> </span>myapp<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>myapp-container<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>busybox:1.28<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>command</span>:<span style=color:#bbb> </span>[<span style=color:#b44>&#39;sh&#39;</span>,<span style=color:#bbb> </span><span style=color:#b44>&#39;-c&#39;</span>,<span style=color:#bbb> </span><span style=color:#b44>&#39;echo The app is running! &amp;&amp; sleep 3600&#39;</span>]<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>initContainers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>init-myservice<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>busybox:1.28<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>command</span>:<span style=color:#bbb> </span>[<span style=color:#b44>&#39;sh&#39;</span>,<span style=color:#bbb> </span><span style=color:#b44>&#39;-c&#39;</span>,<span style=color:#bbb> </span><span style=color:#b44>&#39;until nslookup myservice; do echo waiting for myservice; sleep 2; done;&#39;</span>]<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>init-mydb<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>busybox:1.28<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>command</span>:<span style=color:#bbb> </span>[<span style=color:#b44>&#39;sh&#39;</span>,<span style=color:#bbb> </span><span style=color:#b44>&#39;-c&#39;</span>,<span style=color:#bbb> </span><span style=color:#b44>&#39;until nslookup mydb; do echo waiting for mydb; sleep 2; done;&#39;</span>]<span style=color:#bbb>
</span></span></span></code></pre></div><p>Sintaksis versi 1.5 tetap akan bekerja pada versi 1.6 dan 1.7, tetapi kami menyarankan untuk menggunakan sintaksis versi 1.6. Pada Kubernetes 1.6, Init Container dijadikan sebagai sebuah kolom di dalam API Kubernetes. Anotasi <em>beta</em> tetap akan diperhitungkan pada versi 1.6 dan 1.7, tetapi tidak didukung lagi pada versi 1.8 ke atas.</p><p><em>File</em> YAML di bawah menguraikan Service <code>mydb</code> dan <code>myservice</code>.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Service<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>myservice<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>ports</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>protocol</span>:<span style=color:#bbb> </span>TCP<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>port</span>:<span style=color:#bbb> </span><span style=color:#666>80</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>targetPort</span>:<span style=color:#bbb> </span><span style=color:#666>9376</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:#00f;font-weight:700>---</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Service<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>mydb<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>ports</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>protocol</span>:<span style=color:#bbb> </span>TCP<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>port</span>:<span style=color:#bbb> </span><span style=color:#666>80</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>targetPort</span>:<span style=color:#bbb> </span><span style=color:#666>9377</span><span style=color:#bbb>
</span></span></span></code></pre></div><p>Pod ini dapat dijalankan dan di-<em>debug</em> dengan menggunakan perintah berikut:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl apply -f myapp.yaml
</span></span></code></pre></div><pre tabindex=0><code>pod/myapp-pod created
</code></pre><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get -f myapp.yaml
</span></span></code></pre></div><pre tabindex=0><code>NAME        READY     STATUS     RESTARTS   AGE
myapp-pod   0/1       Init:0/2   0          6m
</code></pre><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl describe -f myapp.yaml
</span></span></code></pre></div><pre tabindex=0><code>Name:          myapp-pod
Namespace:     default
[...]
Labels:        app=myapp
Status:        Pending
[...]
Init Containers:
  init-myservice:
[...]
    State:         Running
[...]
  init-mydb:
[...]
    State:         Waiting
      Reason:      PodInitializing
    Ready:         False
[...]
Containers:
  myapp-container:
[...]
    State:         Waiting
      Reason:      PodInitializing
    Ready:         False
[...]
Events:
  FirstSeen    LastSeen    Count    From                      SubObjectPath                           Type          Reason        Message
  ---------    --------    -----    ----                      -------------                           --------      ------        -------
  16s          16s         1        {default-scheduler }                                              Normal        Scheduled     Successfully assigned myapp-pod to 172.17.4.201
  16s          16s         1        {kubelet 172.17.4.201}    spec.initContainers{init-myservice}     Normal        Pulling       pulling image &#34;busybox&#34;
  13s          13s         1        {kubelet 172.17.4.201}    spec.initContainers{init-myservice}     Normal        Pulled        Successfully pulled image &#34;busybox&#34;
  13s          13s         1        {kubelet 172.17.4.201}    spec.initContainers{init-myservice}     Normal        Created       Created container with docker id 5ced34a04634; Security:[seccomp=unconfined]
  13s          13s         1        {kubelet 172.17.4.201}    spec.initContainers{init-myservice}     Normal        Started       Started container with docker id 5ced34a04634
</code></pre><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl logs myapp-pod -c init-myservice <span style=color:#080;font-style:italic># Memeriksa Init Container pertama</span>
</span></span><span style=display:flex><span>kubectl logs myapp-pod -c init-mydb      <span style=color:#080;font-style:italic># Memeriksa Init Container kedua</span>
</span></span></code></pre></div><p>Saat kita menjalankan Service <code>mydb</code> dan <code>myservice</code>, kita dapat melihat Init Container telah selesai dan <code>myapp-pod</code> pun dibuat:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl apply -f services.yaml
</span></span></code></pre></div><pre tabindex=0><code>service/myservice created
service/mydb created
</code></pre><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get -f myapp.yaml
</span></span><span style=display:flex><span>NAME        READY     STATUS    RESTARTS   AGE
</span></span><span style=display:flex><span>myapp-pod   1/1       Running   <span style=color:#666>0</span>          9m
</span></span></code></pre></div><p>Contoh ini sangat sederhana, tetapi dapat memberikan sedikit petunjuk bagi kamu untuk membuat Init Container sendiri.</p><h2 id=perilaku-mendetail>Perilaku mendetail</h2><p>Saat dimulainya sebuah Pod, Init Container dijalankan secara berurutan, setelah jaringan dan <em>volume</em> telah diinisialisasi. Setiap Init Container harus selesai dan keluar secara berhasil sebelum yang berikutnya dijalankan. Jika ada Init Container yang gagal dijalankan atau keluar secara gagal, dia akan diulang kembali sesuai dengan <code>restartPolicy</code> yang dimiliki Pod. Tetapi, jika <code>restartPolicy</code> Pod disetel dengan nilai <code>Always</code>, Init Container akan menggunakan strategi <code>RestartPolicy</code> <code>OnFailure</code>.</p><p>Sebuah Pod tidak dapat masuk ke status <code>Ready</code> hingga semua Init Container berhasil selesai. <em>Port</em> di sebuah Init Container tidak diagregasikan di dalam sebuah Service. Sebuah Pod yang sedang diinisalisasikan akan masuk ke dalam status <code>Pending</code>, tetapi akan memiliki kondisi <code>Initialized</code> yang disetel menjadi <code>true</code>.</p><p>Jika sebuah Pod diulang <a href=#alasan-pod-diulang-kembali>kembali</a>, semua Init Container harus dijalankan kembali.</p><p>Perubahan pada spesifikasi Init Container dibatasi hanya pada kolom <code>image</code> pada Init Container. Mengganti kolom <code>image</code> sebuah Init Container sama dengan mengulang kembali Pod tersebut.</p><p>Karena Init Container dapat diulang kembali, dicoba ulang, atau dijalankan ulang, Init Container sebaiknya bersifat <em>idempotent</em>. Khususnya, kode yang menulis ke dalam <em>file</em> pada <code>EmptyDir</code> sebaiknya dipersiapkan untuk menangani kemungkinan jika <em>file</em> keluaran yang diharapkan sudah ada di dalam <code>EmptyDir</code> tersebut.</p><p>Init Container memiliki semua kolom yang dimiliki oleh Container aplikasi. Tetapi, Kubernetes melarang penggunaan <code>readinessProbe</code> karena Init Container tidak dapat mendefinisikan/menggunakan <em>readiness probe</em> setelah selesai/keluar secara berhasil. Hal ini dipaksakan saat proses validasi.</p><p>Gunakan <code>activeDeadlineSeconds</code> pada Pod dan <code>livenessProbe</code> pada Container untuk mencegah Init Container gagal terus menerus. Nilai <code>activeDeadlineSeconds</code> berlaku juga terhadap Init Container.</p><p>Nama setiap Container aplikasi dan Init Container pada sebuah Pod haruslah unik; Kesalahan validasi akan terjadi jika ada Container atau Init Container yang memiliki nama yang sama.</p><h3 id=sumber-daya>Sumber Daya</h3><p>Karena eksekusi Init Container yang berurutan, aturan-aturan untuk sumber daya berlaku sebagai berikut:</p><ul><li>Yang tertinggi antara <code>request</code> atau <code>limit</code> sumber daya yang didefinisikan pada <strong>semua Init Container</strong> adalah <strong><code>request</code>/<code>limit</code> inisialisasi yang berlaku</strong>.</li><li><code>request</code>/<code>limit</code> sumber daya Pod yang berlaku adalah yang paling besar diantara:<ul><li>Jumah <code>request</code>/<code>limit</code> semua Container aplikasi untuk suatu sumber daya.</li><li><code>request</code>/<code>limit</code> inisialisasi yang berlaku untuk suatu sumber daya.</li></ul></li><li>Penjadwalan dilakukan berdasarkan <code>request</code>/<code>limit</code> (Pod) yang berlaku, yang berarti bahwa Init Container dapat mengambil sumber daya inisialisasi yang tidak digunakan selama umur Pod tersebut.</li><li><strong>Tingkat QoS yang berlaku</strong> milik Pod adalah sama dengan tingkat QoS untuk Init Container dan Container aplikasi.</li></ul><p><code>ResourceQuota</code> dan <code>limitedResources</code> diberlakukan berdasarkan <code>request</code> dan <code>limit</code> Pod yang berlaku.</p><p>Cgroup pada tingat Pod didasarkan pada <code>request</code> dan <code>limit</code> Pod yang berlaku, sama dengan <em>scheduler</em>.</p><h3 id=alasan-pod-diulang-kembali>Alasan Pod diulang kembali</h3><p>Pod dapat diulang kembali, yang berakibat pada diulangnya eksekusi Init Container, diakibatkan oleh beberapa alasan berikut:</p><ul><li>Seorang pengguna memperbarui <code>PodSpec</code>, mengakibatkan <code>image</code> Init Container berubah. Perubahan apapun pada <code>image</code> Init Container akan mengulang kembali Pod tersebut. Perubahan pada <code>image</code> Container aplikasi hanya mengulang kembali Container aplikasi yang bersangkutan.</li><li>Infrastruktur Container Pod diulang kembali. Hal ini jarang terjadi, dan hanya dapat dilakukan oleh seseorang yang memiliki akses <em>root</em> pada <em>node</em> yang bersangkutan.</li><li>Semua Container di dalam Pod diterminasi, dengan nilai <code>restartPolicy</code> yang disetel sebagai <code>Always</code>, memaksa pengulangan kembali, dan catatan selesainya Init Container telah hilang karena <em>garbage collection</em>.</li></ul><h2 id=dukungan-dan-kompatibilitas>Dukungan dan kompatibilitas</h2><p>Sebuah klaster dengan versi Apiserver 1.6.0 ke atas mendukung Init Container melalui kolom <code>.spec.initContainers</code>. Versi-versi sebelumnya mendukung Init Container melalui anotasi <em>alpha</em> atau <em>beta</em>. Kolom <code>.spec.initContainers</code> juga diduplikasikan dalam bentuk anotasi <em>alpha</em> dan <em>beta</em> agar Kubelet versi 1.3.0 ke atas dapat menjalankan Init Container, dan agar Apiserver versi 1.6 dapat dengan aman dikembalikan ke versi 1.5.x tanpa kehilangan fungsionalitas Pod-pod yang telah dibuat sebelumnya.</p><p>Pada Apiserver dan Kubelet versi 1.8.0 ke atas, dukungan untuk anotasi <em>alpha</em> dan <em>beta</em> telah dihapus, sehingga dibutuhkan konversi (manual) dari anotasi yang telah kedaluwarsa tersebut ke dalam bentuk kolom <code>.spec.initContainers</code>.</p><h2 id=selanjutnya>Selanjutnya</h2><ul><li><a href=/docs/tasks/configure-pod-container/configure-pod-initialization/#creating-a-pod-that-has-an-init-container>Membuat Pod yang memiliki Init Container</a></li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-c8d62295ca703fdcef1aaf89fb4c916a>1.5 - Batasan Persebaran Topologi Pod</h1><div style=margin-top:10px;margin-bottom:10px><b>FEATURE STATE:</b> <code>Kubernetes v1.18 [beta]</code></div><p>Kamu dapat menggunakan batasan perseberan topologi (<em>topology spread constraints</em>)
untuk mengatur bagaimana <a class=glossary-tooltip title='Unit Kubernetes yang paling sederhana dan kecil. Sebuah Pod merepresentasikan sebuah set kontainer yang dijalankan pada kluster kamu.' data-toggle=tooltip data-placement=top href=/docs/concepts/workloads/pods/pod-overview/ target=_blank aria-label=Pod>Pod</a> akan disebarkan
pada klaster yang ditetapkan sebagai <em>failure-domains</em>, seperti wilayah, zona, Node dan domain
topologi yang ditentukan oleh pengguna. Ini akan membantu untuk mencapai ketersediaan yang tinggi
dan juga penggunaan sumber daya yang efisien.</p><h2 id=persyaratan>Persyaratan</h2><h3 id=mengaktifkan-gerbang-fitur>Mengaktifkan Gerbang Fitur</h3><p><a href=/docs/reference/command-line-tools-reference/feature-gates/>Gerbang fitur (<em>feature gate</em>)</a>
<code>EvenPodsSpread</code> harus diaktifkan untuk
<a class=glossary-tooltip title='Komponen control plane yang mengekspos API Kubernetes. Merupakan front-end dari control plane Kubernetes.' data-toggle=tooltip data-placement=top href=/docs/reference/generated/kube-apiserver/ target=_blank aria-label='API Server'>API Server</a> <strong>dan</strong>
<a class=glossary-tooltip title='Komponen control plane yang bertugas mengamati Pod baru yang belum ditempatkan di node manapun dan kemudian memilihkan node di mana Pod baru tersebut akan dijalankan.' data-toggle=tooltip data-placement=top href=/docs/reference/generated/kube-scheduler/ target=_blank aria-label='penjadwal (_scheduler_)'>penjadwal (_scheduler_)</a>.</p><h3 id=label-node>Label Node</h3><p>Batasan persebaran topologi bergantung dengan label pada Node untuk menentukan
domain topologi yang memenuhi untuk semua Node. Misalnya saja, sebuah Node bisa memiliki
label sebagai berikut: <code>node=node1,zone=us-east-1a,region=us-east-1</code></p><p>Misalkan kamu memiliki klaster dengan 4 Node dengan label sebagai berikut:</p><pre tabindex=0><code>NAME    STATUS   ROLES    AGE     VERSION   LABELS
node1   Ready    &lt;none&gt;   4m26s   v1.16.0   node=node1,zone=zoneA
node2   Ready    &lt;none&gt;   3m58s   v1.16.0   node=node2,zone=zoneA
node3   Ready    &lt;none&gt;   3m17s   v1.16.0   node=node3,zone=zoneB
node4   Ready    &lt;none&gt;   2m43s   v1.16.0   node=node4,zone=zoneB
</code></pre><p>Maka klaster tersebut secara logika akan dilihat sebagai berikut:</p><pre tabindex=0><code>+---------------+---------------+
|     zoneA     |     zoneB     |
+-------+-------+-------+-------+
| node1 | node2 | node3 | node4 |
+-------+-------+-------+-------+
</code></pre><p>Tanpa harus memberi label secara manual, kamu dapat menggunakan [label ternama]
(/docs/reference/kubernetes-api/labels-annotations-taints/) yang terbuat dan terkumpulkan
secara otomatis pada kebanyakan klaster.</p><h2 id=batasan-persebaran-untuk-pod>Batasan Persebaran untuk Pod</h2><h3 id=api>API</h3><p><em>Field</em> <code>pod.spec.topologySpreadConstraints</code> diperkenalkan pada versi 1.16 sebagai berikut:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>mypod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>topologySpreadConstraints</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>maxSkew</span>:<span style=color:#bbb> </span>&lt;integer&gt;<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>minDomains</span>:<span style=color:#bbb> </span>&lt;integer&gt;<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>topologyKey</span>:<span style=color:#bbb> </span>&lt;string&gt;<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>whenUnsatisfiable</span>:<span style=color:#bbb> </span>&lt;string&gt;<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>labelSelector</span>:<span style=color:#bbb> </span>&lt;object&gt;<span style=color:#bbb>
</span></span></span></code></pre></div><p>Kamu dapat mendefinisikan satu atau lebih <code>topologySpreadConstraint</code> untuk menginstruksikan
kube-scheduler mengenai cara peletakan tiap Pod baru dengan menggunakan kondisi Pod yang
sudah ada dalam klaster kamu. <em>Field</em> yang ada adalah:</p><ul><li><strong>maxSkew</strong> menentukan batasan yang menandakan Pod tidak tersebar secara merata.
Ini merupakan nilai maksimal dari selisih jumlah Pod yang sama untuk setiap 2 domain topologi
yang sama. Nilai ini harus lebih dari 0.</li><li><strong>topologyKey</strong> adalah kunci dari label Node. Jika terdapat dua Node memiliki label dengan
kunci ini dan memiliki nilai yang identik untuk label tersebut, maka penjadwal akan menganggap
kedua Noode dalam topologi yang sama. Penjadwal akan mencoba untuk menyeimbangkan jumlah Pod
dalam setiap domain topologi.</li><li><strong>whenUnsatisfiable</strong> mengindikasikan cara menangani Pod yang tidak memenuhi batasan persebaran:<ul><li><code>DoNotSchedule</code> (<em>default</em>) memberitahukan penjadwal untuk tidak menjadwalkan Pod tersebut.</li><li><code>ScheduleAnyway</code> memberitahukan penjadwal untuk tetap menjadwalkan Pod namun tetap menjaga ketidakseimbangan Node sekecil mungkin.</li></ul></li><li><strong>labelSelector</strong> digunakan untuk mencari Pod yang sesuai. Pod dengan label yang sama dengan ini akan dihitung untuk menentukan jumlah Pod dalam domain topologi yang sesuai. Silakan baca <a href=/id/docs/concepts/overview/working-with-objects/labels/#selektor-label>Label dan Selector</a> untuk lebih detailnya.</li></ul><p>Kamu juga bisa membaca lebih detail mengenai <em>field</em> ini dengan menjalankan perintah
<code>kubectl explain Pod.spec.topologySpreadConstraints</code>.</p><h3 id=contoh-satu-topologyspreadconstraint>Contoh: Satu TopologySpreadConstraint</h3><p>Misalkan kamu memiliki klaster dengan 4 Node dimana 3 Pod berlabel <code>foo:bar</code> terdapat pada node1,
node2 dan node3 (<code>P</code> merepresentasikan Pod):</p><pre tabindex=0><code>+---------------+---------------+
|     zoneA     |     zoneB     |
+-------+-------+-------+-------+
| node1 | node2 | node3 | node4 |
+-------+-------+-------+-------+
|   P   |   P   |   P   |       |
+-------+-------+-------+-------+
</code></pre><p>Jika kita ingin Pod baru akan disebar secara merata berdasarkan Pod yang telah ada pada semua zona,
maka <em>spec</em> bernilai sebagai berikut:</p><div class=highlight><div class=copy-code-icon style=text-align:right><a href=https://raw.githubusercontent.com/kubernetes/website/main/content/id/examples/pods/topology-spread-constraints/one-constraint.yaml download=pods/topology-spread-constraints/one-constraint.yaml><code>pods/topology-spread-constraints/one-constraint.yaml</code></a>
<img src=/images/copycode.svg style=max-height:24px;cursor:pointer onclick='copyCode("pods-topology-spread-constraints-one-constraint-yaml")' title="Copy pods/topology-spread-constraints/one-constraint.yaml to clipboard"></img></div><div class=includecode id=pods-topology-spread-constraints-one-constraint-yaml><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>mypod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>labels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>foo</span>:<span style=color:#bbb> </span>bar<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>topologySpreadConstraints</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>maxSkew</span>:<span style=color:#bbb> </span><span style=color:#666>1</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>topologyKey</span>:<span style=color:#bbb> </span>zone<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>whenUnsatisfiable</span>:<span style=color:#bbb> </span>DoNotSchedule<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>labelSelector</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>matchLabels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>foo</span>:<span style=color:#bbb> </span>bar<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>pause<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>k8s.gcr.io/pause:3.1</span></span></code></pre></div></div></div><p><code>topologyKey: zone</code> berarti persebaran merata hanya akan digunakan pada Node dengan pasangan label
"zone: <nilai apapun>". <code>whenUnsatisfiable: DoNotSchedule</code> memberitahukan penjadwal untuk membiarkan
tetap ditunda jika Pod yang baru tidak memenuhi batasan yang diterapkan.</p><p>Jika penjadwal menempatkan Pod baru pada "zoneA", persebaran Pod akan menjadi [3, 1], menjadikan
ketidakseimbangan menjadi bernilai 2 (3 - 1), yang mana akan melanggar batasan <code>maxSkew: 1</code>.
Dalam contoh ini, Pod baru hanya dapat ditempatkan pada "zoneB":</p><pre tabindex=0><code>+---------------+---------------+      +---------------+---------------+
|     zoneA     |     zoneB     |      |     zoneA     |     zoneB     |
+-------+-------+-------+-------+      +-------+-------+-------+-------+
| node1 | node2 | node3 | node4 |  OR  | node1 | node2 | node3 | node4 |
+-------+-------+-------+-------+      +-------+-------+-------+-------+
|   P   |   P   |   P   |   P   |      |   P   |   P   |  P P  |       |
+-------+-------+-------+-------+      +-------+-------+-------+-------+
</code></pre><p>Kamu dapat mengatur spesifikasi Pod untuk memenuhi beberapa persyaratan berikut:</p><ul><li>Ubah nilai <code>maxSkew</code> menjadi lebih besar, misal "2", sehingga Pod baru dapat ditempatkan pada "zoneA".</li><li>Ubah nilai <code>topologyKey</code> menjadi "node" agar Pod disebarkan secara merata pada semua Node, bukan zona. Pada contoh di atas, jika <code>maxSkew</code> tetap bernilai "1", maka Pod baru hanya akan ditempatkan pada "node4".</li><li>Ubah nilai <code>whenUnsatisfiable: DoNotSchedule</code> menjadi <code>whenUnsatisfiable: ScheduleAnyway</code> untuk
menjamin agar semua Pod baru akan tetap dijadwalkan (misalkan saja API penjadwalan lain tetap
terpenuhi). Namun, ini lebih suka ditempatkan pada domain topologi yang memiliki lebih sedikit
Pod yang sesuai. (Harap diperhatikan bahwa preferensi ini digabungkan bersama dengan prioritas
penjadwalan internal yang lain, seperti rasio penggunaan sumber daya, dan lain sebagainya.)</li></ul><h3 id=contoh-beberapa-topologyspreadconstraint>Contoh: Beberapa TopologySpreadConstraint</h3><p>Ini dibuat berdasarkan contoh sebelumnya. Misalkan kamu memiliki klaster dengan 4 Node dengan
3 Pod berlabel <code>foo:bar</code> yang ditempatkan pada node1, node2 dan node3. (<code>P</code> merepresentasikan Pod):</p><pre tabindex=0><code>+---------------+---------------+
|     zoneA     |     zoneB     |
+-------+-------+-------+-------+
| node1 | node2 | node3 | node4 |
+-------+-------+-------+-------+
|   P   |   P   |   P   |       |
+-------+-------+-------+-------+
</code></pre><p>Kamu dapat menggunakan 2 TopologySpreadConstraint untuk mengatur persebaran Pod pada zona dan Node:</p><div class=highlight><div class=copy-code-icon style=text-align:right><a href=https://raw.githubusercontent.com/kubernetes/website/main/content/id/examples/pods/topology-spread-constraints/two-constraints.yaml download=pods/topology-spread-constraints/two-constraints.yaml><code>pods/topology-spread-constraints/two-constraints.yaml</code></a>
<img src=/images/copycode.svg style=max-height:24px;cursor:pointer onclick='copyCode("pods-topology-spread-constraints-two-constraints-yaml")' title="Copy pods/topology-spread-constraints/two-constraints.yaml to clipboard"></img></div><div class=includecode id=pods-topology-spread-constraints-two-constraints-yaml><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>mypod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>labels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>foo</span>:<span style=color:#bbb> </span>bar<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>topologySpreadConstraints</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>maxSkew</span>:<span style=color:#bbb> </span><span style=color:#666>1</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>topologyKey</span>:<span style=color:#bbb> </span>zone<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>whenUnsatisfiable</span>:<span style=color:#bbb> </span>DoNotSchedule<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>labelSelector</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>matchLabels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>foo</span>:<span style=color:#bbb> </span>bar<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>maxSkew</span>:<span style=color:#bbb> </span><span style=color:#666>1</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>topologyKey</span>:<span style=color:#bbb> </span>node<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>whenUnsatisfiable</span>:<span style=color:#bbb> </span>DoNotSchedule<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>labelSelector</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>matchLabels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>foo</span>:<span style=color:#bbb> </span>bar<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>pause<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>k8s.gcr.io/pause:3.1</span></span></code></pre></div></div></div><p>Dalam contoh ini, untuk memenuhi batasan pertama, Pod yang baru hanya akan ditempatkan pada "zoneB",
sedangkan untuk batasan kedua, Pod yang baru hanya akan ditempatkan pada "node4". Maka hasil dari
2 batasan ini akan digunakan (<em>AND</em>), sehingga opsi untuk menempatkan Pod hanya pada "node4".</p><p>Beberapa batasan dapat berujung pada konflik. Misalnya saja kamu memiliki klaster dengan 3 Node
pada 2 zona berbeda:</p><pre tabindex=0><code>+---------------+-------+
|     zoneA     | zoneB |
+-------+-------+-------+
| node1 | node2 | node3 |
+-------+-------+-------+
|  P P  |   P   |  P P  |
+-------+-------+-------+
</code></pre><p>Jika kamu menerapkan "two-constraints.yaml" pada klaster ini, kamu akan mendapatkan "mypod" tetap
dalam kondisi <code>Pending</code>. Ini dikarenakan oleh: untuk memenuhi batasan pertama, "mypod" hanya dapat
ditempatkan pada "zoneB", sedangkan untuk batasan kedua, "mypod" hanya dapat ditempatkan pada
"node2". Tidak ada hasil penggabungan dari "zoneB" dan "node2".</p><p>Untuk mengatasi situasi ini, kamu bisa menambahkan nilai <code>maxSkew</code> atau mengubah salah satu dari
batasan untuk menggunakan <code>whenUnsatisfiable: ScheduleAnyway</code>.</p><h3 id=konvensi>Konvensi</h3><p>Ada beberapa konvensi implisit yang perlu diperhatikan di sini:</p><ul><li><p>Hanya Pod dengan Namespace yang sama dengan Pod baru yang bisa menjadi kandidat yang cocok.</p></li><li><p>Node tanpa memiliki <code>topologySpreadConstraints[*].topologyKey</code> akan dilewatkan. Ini berarti:</p><ol><li>Pod yang ditempatkan pada Node tersebut tidak berpengaruh pada perhitungan <code>maxSkew</code>. Dalam contoh di atas, misalkan "node1" tidak memiliki label "zone", maka kedua Pod tidak diperhitungkan dan menyebabkan Pod yang baru akan dijadwalkan masuk ke "zoneA".</li><li>Pod yang baru tidak memiliki kesempatan untuk dijadwalkan ke Node tersebut, pada contoh di atas, misalkan terdapat "node5" dengan label <code>{zone-typo: zoneC}</code> bergabung dalam klaster, Node ini akan dilewatkan karena tidak memiliki label dengan kunci "zone".</li></ol></li><li><p>Harap diperhatikan mengenai hal yang terjadi jika nilai <code>topologySpreadConstraints[*].labelSelector</code> pada Pod yang baru tidak sesuai dengan labelnya.
Pada contoh di atas, jika kita menghapus label pada Pod yang baru, maka Pod akan tetap ditempatkan
pada "zoneB" karena batasan yang ada masih terpenuhi. Namun, setelah ditempatkan, nilai
ketidakseimbangan pada klaster masih tetap tidak berubah, zoneA tetap memiliki 2 Pod dengan label
{foo:bar} dan zoneB memiliki 1 Pod dengan label {foo:bar}. Jadi jika ini tidak yang kamu harapkan,
kami menyarankan nilai dari <code>topologySpreadConstraints[*].labelSelector</code> disamakan dengan labelnya.</p></li><li><p>Jika Pod yang baru memiliki <code>spec.nodeSelector</code> atau <code>spec.affinity.nodeAffinity</code>, Node yang tidak
sesuai dengan nilai tersebut akan dilewatkan.</p><p>Misalkan kamu memiliki klaster dengan 5 Node dari zoneA sampai zoneC:</p><pre tabindex=0><code>+---------------+---------------+-------+
|     zoneA     |     zoneB     | zoneC |
+-------+-------+-------+-------+-------+
| node1 | node2 | node3 | node4 | node5 |
+-------+-------+-------+-------+-------+
|   P   |   P   |   P   |       |       |
+-------+-------+-------+-------+-------+
</code></pre><p>dan kamu mengetahui bahwa "zoneC" harus tidak diperhitungkan. Dalam kasus ini, kamu dapat membuat
berkas yaml seperti di bawah, jadi "mypod" akan ditempatkan pada "zoneB", bukan "zoneC".
Demikian juga <code>spec.nodeSelector</code> akan digunakan.</p><div class=highlight><div class=copy-code-icon style=text-align:right><a href=https://raw.githubusercontent.com/kubernetes/website/main/content/id/examples/pods/topology-spread-constraints/one-constraint-with-nodeaffinity.yaml download=pods/topology-spread-constraints/one-constraint-with-nodeaffinity.yaml><code>pods/topology-spread-constraints/one-constraint-with-nodeaffinity.yaml</code></a>
<img src=/images/copycode.svg style=max-height:24px;cursor:pointer onclick='copyCode("pods-topology-spread-constraints-one-constraint-with-nodeaffinity-yaml")' title="Copy pods/topology-spread-constraints/one-constraint-with-nodeaffinity.yaml to clipboard"></img></div><div class=includecode id=pods-topology-spread-constraints-one-constraint-with-nodeaffinity-yaml><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Pod<span style=color:#bbb>
    </span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
    </span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
    </span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>mypod<span style=color:#bbb>
    </span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>labels</span>:<span style=color:#bbb>
    </span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>foo</span>:<span style=color:#bbb> </span>bar<span style=color:#bbb>
    </span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
    </span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>topologySpreadConstraints</span>:<span style=color:#bbb>
    </span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>maxSkew</span>:<span style=color:#bbb> </span><span style=color:#666>1</span><span style=color:#bbb>
    </span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>topologyKey</span>:<span style=color:#bbb> </span>zone<span style=color:#bbb>
    </span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>whenUnsatisfiable</span>:<span style=color:#bbb> </span>DoNotSchedule<span style=color:#bbb>
    </span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>labelSelector</span>:<span style=color:#bbb>
    </span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>matchLabels</span>:<span style=color:#bbb>
    </span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>foo</span>:<span style=color:#bbb> </span>bar<span style=color:#bbb>
    </span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>affinity</span>:<span style=color:#bbb>
    </span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>nodeAffinity</span>:<span style=color:#bbb>
    </span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>requiredDuringSchedulingIgnoredDuringExecution</span>:<span style=color:#bbb>
    </span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>nodeSelectorTerms</span>:<span style=color:#bbb>
    </span></span></span><span style=display:flex><span><span style=color:#bbb>        </span>- <span style=color:green;font-weight:700>matchExpressions</span>:<span style=color:#bbb>
    </span></span></span><span style=display:flex><span><span style=color:#bbb>          </span>- <span style=color:green;font-weight:700>key</span>:<span style=color:#bbb> </span>zone<span style=color:#bbb>
    </span></span></span><span style=display:flex><span><span style=color:#bbb>            </span><span style=color:green;font-weight:700>operator</span>:<span style=color:#bbb> </span>NotIn<span style=color:#bbb>
    </span></span></span><span style=display:flex><span><span style=color:#bbb>            </span><span style=color:green;font-weight:700>values</span>:<span style=color:#bbb>
    </span></span></span><span style=display:flex><span><span style=color:#bbb>            </span>- zoneC<span style=color:#bbb>
    </span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
    </span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>pause<span style=color:#bbb>
    </span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>k8s.gcr.io/pause:3.1</span></span></code></pre></div></div></div></li></ul><h3 id=batasan-default-pada-tingkat-klaster>Batasan <em>default</em> pada tingkat klaster</h3><div style=margin-top:10px;margin-bottom:10px><b>FEATURE STATE:</b> <code>Kubernetes v1.18 [alpha]</code></div><p>Ini memungkinkan untuk mengatur batasan persebaran topologi bawaan untuk klaster.
Batasan persebaran topologi bawaan akan digunakan pada Pod jika dan hanya jika:</p><ul><li>Hal ini tidak mendefinisikan batasan apapun pada <code>.spec.topologySpreadConstraints</code>.</li><li>Hal ini milik sebuah Service, ReplicationController, ReplicaSet atau StatefulSet.</li></ul><p>Batasan bawaan akan diatur sebagai bagian dari argumen pada <em>plugin</em> <code>PodTopologySpread</code>
di dalam sebuah <a href=/docs/reference/scheduling/profiles>profil penjadwalan</a>.
Batasan dispesifikasikan dengan <a href=#api>API yang sama dengan di atas</a>, kecuali bagian <code>labelSelector</code>
harus kosong. <em>selector</em> akan dihitung dari Service, ReplicationController, ReplicaSet atau
StatefulSet yang dimiliki oleh Pod tersebut.</p><p>Sebuah contoh konfigurasi sebagai berikut:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>kubescheduler.config.k8s.io/v1alpha2<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>KubeSchedulerConfiguration<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>profiles</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>pluginConfig</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>PodTopologySpread<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>args</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>defaultConstraints</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>            </span>- <span style=color:green;font-weight:700>maxSkew</span>:<span style=color:#bbb> </span><span style=color:#666>1</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>              </span><span style=color:green;font-weight:700>topologyKey</span>:<span style=color:#bbb> </span>topology.kubernetes.io/zone<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>              </span><span style=color:green;font-weight:700>whenUnsatisfiable</span>:<span style=color:#bbb> </span>ScheduleAnyway<span style=color:#bbb>
</span></span></span></code></pre></div><div class="alert alert-info note callout" role=alert><strong>Catatan:</strong> Nilai yang dihasilkan oleh batasan penjadwalan bawaan mungkin akan konflik dengan
nilai yang dihasilkan oleh
<a href=/docs/reference/scheduling/profiles/#scheduling-plugins><code>DefaultPodTopologySpread</code> plugin</a>.
Direkomendasikan untuk kamu menonaktifkan <em>plugin</em> ini dalam profil penjadwalan ketika
menggunakan batasan <em>default</em> untuk <code>PodTopologySpread</code>.</div><h2 id=perbandingan-dengan-podaffinity-podantiaffinity>Perbandingan dengan PodAffinity/PodAntiAffinity</h2><p>Di Kubernetes, arahan yang terkait dengan "Afinitas" mengontrol bagaimana Pod dijadwalkan -
lebih terkumpul atau lebih tersebar.</p><ul><li>Untuk <code>PodAffinity</code>, kamu dapat mencoba mengumpulkan beberapa Pod ke dalam suatu
domain topologi yang memenuhi syarat.</li><li>Untuk <code>PodAntiAffinity</code>, hanya satu Pod yang dalam dijadwalkan pada sebuah domain topologi.</li></ul><p>Fitur "EvenPodsSpread" memberikan opsi fleksibilas untuk mendistribusikan Pod secara merata
pada domain topologi yang berbeda, untuk meraih ketersediaan yang tinggi atau menghemat biaya.
Ini juga dapat membantu saat perbaruan bergilir dan menaikan jumlah replika dengan lancar.
Silakan baca <a href=https://github.com/kubernetes/enhancements/blob/master/keps/sig-scheduling/20190221-even-pods-spreading.md#motivation>motivasi</a> untuk lebih detail.</p><h2 id=limitasi-yang-diketahui>Limitasi yang diketahui</h2><p>Pada versi 1.18, dimana fitur ini masih Beta, beberapa limitasi yang sudah diketahui:</p><ul><li>Pengurangan jumlah Deployment akan membuat ketidakseimbangan pada persebaran Pod.</li><li>Pod yang cocok pada <em>tainted</em> Node akan dihargai. Lihat <a href=https://github.com/kubernetes/kubernetes/issues/80921>Issue 80921</a></li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-4e9b9cbc9776b12e7335c53da377c9c8>1.6 - Pod Preset</h1><p>Halaman ini menyajikan gambaran umum tentang PodPreset, yang merupakan objek untuk memasukkan informasi tertentu ke dalam Pod pada saat waktu penciptaan. Informasi dapat berupa <em>secret</em>, <em>volume</em>, <em>volume mount</em>, dan variabel <em>environment</em>.</p><h2 id=memahami-pod-preset>Memahami Pod Preset</h2><hr><p>Sebuah <code>Pod Preset</code> adalah sebuah <em>resource</em> API untuk memasukkan kebutuhan <em>runtime</em> tambahan ke dalam sebuah Pod pada saat waktu penciptaan. Kamu akan menggunakan <em>label selector</em> untuk menunjuk Pod dimana Pod Preset diterapkan.</p><p>Menggunakan sebuah Pod Preset memungkinkan pembuat templat pod untuk tidak menyediakan secara eksplisit semua informasi untuk setiap pod. Dengan demikian, pembuat templat pod yang mengkonsumsi sebuah <em>service</em> spesifik tidak perlu tahu semua detail-detail tentang <em>service</em> tersebut.</p><p>Untuk informasi lebih lanjut mengenai latar belakang lihat <a href=https://github.com/kubernetes/community/blob/master/contributors/design-proposals/service-catalog/pod-preset.md>proposal desain untuk PodPreset</a>.</p><h2 id=bagaimana-cara-kerja-pod-preset>Bagaimana Cara Kerja Pod Preset</h2><hr><p>Kubernetes menyediakan sebuah <em>admission controller</em> (<code>PodPreset</code>) dimana, ketika diaktifkan, PodPreset diterapkan kepada permintaan penciptaan Pod yang akan datang. Ketika sebuah penciptaan Pod terjadi, sistem melakukan hal-hal berikut:</p><ol><li>Mengambil semua <code>PodPreset</code> yang tersedia untuk digunakan.</li><li>Cek jika <em>label selector</em> dari salah satu <code>PodPreset</code> cocok dengan <em>label</em> pada pod yang sedang diciptakan.</li><li>Usaha untuk menggabungkan berbagai <em>resource</em> didefinisikan oleh <code>PodPreset</code> ke dalam Pod yang sedang diciptakan.</li><li>Ketika terjadi galat, lempar sebuah <em>event</em> yang mendokumentasikan galat penggabungan dalam pod, dan membuat pod tanpa salah satu <em>resource</em> dari <code>PodPreset</code>.</li><li>Anotasikan hasil spesifikasi Pod yang telah dimodifikasi untuk menunjukkan bahwa Pod telah dimodifikasi oleh sebuah PodPreset. Anotasi berupa <code>podpreset.admission.kubernetes.io/podpreset-&lt;nama pod-preset>: "&lt;versi resource>"</code>.</li></ol><p>Tiap Pod akan bisa dipasangkan oleh nol atau lebih PodPreset; dan tiap PodPreset bisa diterapkan ke nol atau lebih Pod. Ketika sebuah PodPreset diterapkan ke satu atau lebih Pod, Kubernetes memodifikasi Pod Spec. Untuk perubahan terhadap <code>Env</code>,<code>EnvFrom</code>, dan <code>VolumeMount</code>, Kubernetes memodifikasi spesifikasi kontainer untuk semua kontainer di dalam Pod; Untuk perubahan terhadap <code>Volume</code>, Kubernetes memodifikasi Pod Spec.</p><div class="alert alert-info note callout" role=alert><strong>Catatan:</strong> Sebuah Pod Preset mampu memodifikasi kolom <code>.spec.containers</code> pada sebuah Pod Spec jika sesuai. Tidak ada definisi resource dari Pod Preset yang akan diterapkan kepada kolom <code>initContainer</code>.</div><h3 id=menonaktifkan-pod-preset-untuk-sebuah-pod-spesifik>Menonaktifkan Pod Preset untuk sebuah Pod Spesifik</h3><p>Mungkin akan ada keadaan dimana kamu menginginkan sebuah Pod tidak bisa diubah oleh sebuah mutasi PodPreset. Pada kasus ini, kamu bisa menambahkan sebuah anotasi pada Pod Spec dalam bentuk: <code>podpreset.admission.kubernetes.io/exclude: "true"</code>.</p><h2 id=mengaktifkan-pod-preset>Mengaktifkan Pod Preset</h2><hr><p>Dalam rangka untuk menggunakan Pod Preset di dalam klaster kamu, kamu harus memastikan hal berikut:</p><ol><li><p>Kamu telah mengaktifkan tipe API <code>settings.k8s.io/v1alpha1/podpreset</code>. Sebagai contoh, ini bisa dilakukan dengan menambahkan <code>settings.k8s.io/v1alpha1=true</code> di dalam opsi <code>--runtime-config</code> untuk API <em>server</em>. Dalam <em>minikube</em> tambahkan argumen berikut <code>--extra-config=apiserver.runtime-config=settings.k8s.io/v1alpha1=true</code> saat menginisialisasi klaster.</p></li><li><p>Kamu telah mengaktifkan <em>admission controller</em> dari <code>PodPreset</code>. Salah satu cara untuk melakukannya adalah dengan menambahkan <code>PodPreset</code> di dalam nilai opsi <code>--enable-admission-plugins</code> yang dispesifikasikan untuk API <em>server</em>. Dalam <em>minikube</em> tambahkan argumen berikut</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>--extra-config<span style=color:#666>=</span>apiserver.enable-admission-plugins<span style=color:#666>=</span>NamespaceLifecycle,LimitRanger,ServiceAccount,DefaultStorageClass,DefaultTolerationSeconds,NodeRestriction,MutatingAdmissionWebhook,ValidatingAdmissionWebhook,ResourceQuota,PodPreset
</span></span></code></pre></div><p>saat menginisialisasi klaster.</p></li><li><p>Kamu telah membuat objek <code>PodPreset</code> pada <em>namespace</em> yang kamu gunakan dengan cara mendefinisikan Pod Preset.</p></li></ol><h2 id=selanjutnya>Selanjutnya</h2><ul><li><a href=/id/docs/concepts/workloads/pods/pod/#injecting-data-into-a-pod-using-podpreset.md>Memasukkan data ke dalam sebuah Pod dengan PodPreset</a></li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-4aaf43c715cd764bc8ed4436f3537e68>1.7 - Disrupsi</h1><p>Petunjuk ini ditujukan pada pemilik aplikasi yang meninginkan aplikasinya memiliki ketersediaan yang tinggi, sehingga butuh untuk mengerti jenis-jenis Disrupsi yang dapat terjadi pada Pod-pod.</p><p>Petunjuk ini juga ditujukan pada administrator klaster yang ingin melakukan berbagai tindakan otomasi pada klaster, seperti pembaruan dan <em>autoscaling</em> klaster.</p><h2 id=disrupsi-yang-disengaja-dan-tidak-disengaja>Disrupsi yang Disengaja dan Tidak Disengaja</h2><p>Pod-pod tidak akan terhapus sampai sesuatu (orang ataupun <em>pengendali</em>) menghancurkan mereka atau ada kesalahan perangkat keras maupun perangkat lunak yang tidak dapat dihindari.</p><p>Kita menyebut kasus-kasus yang tidak dapat dihindari sebagai <strong>disrupsi yang tidak disengaja</strong> terhadap aplikasi. Beberapa contohnya adalah sebagai berikut:</p><ul><li>Kesalahan perangkat keras pada mesin yang menjalankan Node</li><li>Administrator klaster menghapus <em>virtual machine</em> secara tidak sengaja</li><li>Kesalahan pada penyedia layanan <em>cloud</em> yang mengakibatkan terhapusnya <em>virtual machine</em></li><li>Sebuah <em>kernel panic</em></li><li>Node menghilang dari klaster karena partisi jaringan klaster</li><li>Pod mengalami <em>eviction</em> karena Node <a href=/docs/tasks/administer-cluster/out-of-resource>kehabisan sumber daya</a></li></ul><p>Dengan pengecualian pada kondisi kehabisan sumber daya, kondisi-kondisi tersebut pada umumnya diketahui oleh kebanyakan pengguna karena kondisi-kondisi tersebut tidak spesifik pada Kubernetes saja.</p><p>Kita menyebut kasus-kasus lainnya sebagai <strong>disrupsi yang disengaja</strong>. Hal ini termasuk tindakan yang dilakukan oleh pemilik aplikasi atau yang dilakukan oleh administrator klaster. Pemilik aplikasi umumnya melakukan hal-hal berikut:</p><ul><li>Menghapus Deployment atau pengendali yang mengatur Pod</li><li>Memperbarui templat Pod yang menyebabkan pengulangan kembali/<em>restart</em></li><li>Menghapus Pod secara langsung</li></ul><p>Administrator klaster umumnya melakukan hal-hal berikut:</p><ul><li><a href=/docs/tasks/administer-cluster/safely-drain-node/>Melakukan <em>drain</em> terhadap Node</a> untuk perbaikan atau pembaruan.</li><li>Melakukan <em>drain</em> terhadap sebuah node dari klaster untuk memperkecil ukuran klaster (untuk lebih lanjutnya, pelajari <a href=/docs/tasks/administer-cluster/cluster-management/#cluster-autoscaler><em>Autoscaling</em> klaster</a>).</li><li>Menghapus sebuah Pod dari node untuk memuat Pod lain ke node tersebut.</li></ul><p>Tindakan-tindakan tersebut dapat dilakukan secara langsung oleh administrator klaster, atau oleh alat otomasi yang dijalankan oleh administrator klaster, atau oleh penyedia layanan Kubernetes kamu.</p><p>Tanyakan administrator klaster atau penyedia layanan <em>cloud</em> kamu, atau lihatlah dokumentasi penyedia layanan Kubernetes kamu untuk mengetahui bila ada sumber-sumber yang berpotensi mengakibatkan disrupsi yang disengaja yang ada pada klastermu. Jika tidak ada, kamu bisa melewatkan pembuatan <em>PodDisruptionBudget</em></p><div class="alert alert-warning caution callout" role=alert><strong>Perhatian:</strong> Tidak semua disrupsi yang disengaja dibatasi oleh Pod Disruption Budget. Contohnya, menghapus Deployment atau Pod dapat mengabaikan PodDisruptionBudget.</div><h2 id=mengatasi-disrupsi>Mengatasi Disrupsi</h2><p>Berikut beberapa cara untuk mengatasi disrupsi yang tidak disengaja:</p><ul><li>Pastikan Pod-pod kamu <a href=/docs/tasks/configure-Pod-container/assign-cpu-ram-container>merinci permintaan sumber daya klaster</a> yang dibutuhkan.</li><li>Replikasikan aplikasimu jika membutuhkan ketersediaan yang tinggi. (Pelajari tentang menjalankan aplikasi
<a href=/docs/tasks/run-application/run-stateless-application-deployment/><em>stateless</em></a> dan <a href=/docs/tasks/run-application/run-replicated-stateful-application/><em>stateful</em></a>).</li><li>Untuk mencapai ketersediaan yang bahkan lebih tinggi lagi saat mereplikasikan aplikasi, sebarkanlah Pod-pod kamu di rak-rak pada <em>data center</em> (menggunakan <a href=/docs/user-guide/node-selection/#inter-Pod-affinity-and-anti-affinity-beta-feature><em>anti-affinity</em></a>) atau di seluruh zona (jika kamu menggunakan <a href=/docs/setup/multiple-zones>klaster pada beberapa zona</a>).</li></ul><p>Frekuensi disrupsi yang disengaja dapat berubah-ubah. Pada klaster Kubernetes yang dasar, tidak ada disrupsi yang disengaja sama sekali. Tetapi, administrator klaster atau penyedia layanan Kubernetes kamu mungkin saja menjalankan beberapa servis tambahan yang dapat mengakibatkan disrupsi yang disengaja. Misalnya, memperbarui perangkat lunak pada node yang dapat mengakibatkan disrupsi yang disengaja. Selain itu, beberapa implementasi <em>autoscaling</em> klaster (atau node) dapat mengakibatkan disrupsi yang disengaja untuk merapikan dan memadatkan node-node pada klaster.
Administrator klaster atau penyedia layanan Kubernetes kamu perlu mendokumentasikan tingkatan disrupsi yang disengaja, jika ada disrupsi yang telah diperkirakan.</p><p>Kubernetes menawarkan fitur-fitur untuk membantu menjalankan aplikasi-aplikasi dengan ketersediaan tinggi bersamaan dengan seringnya disrupsi yang disengaja, fitur-fitur tersebut dinamai <em>Disruption Budget</em>.</p><h2 id=bagaimana-cara-kerja-disruption-budget>Bagaimana cara kerja <em>Disruption Budget</em></h2><p>Pemilik aplikasi dapat membuat objek <code>PodDisruptionBudget</code> (PDB) untuk setiap aplikasi. Sebuah PDB membatasi jumlah Pod yang boleh mati secara bersamaan pada aplikasi yang direplikasi dikarenakan disrupsi yang disengaja.
Misalnya, sebuah aplikasi yang bekerja secara <em>quorum</em> mau memastikan bahwa jumlah replika yang berjalan tidak jatuh ke bawah yang dibutuhkan untuk membentuk sebuah <em>quorum</em>. Contoh lainnya, sebuah <em>front-end</em> web mungkin perlu memastikan bahwa jumlah replika yang melayani trafik tidak pernah turun ke total persentase yang telah ditentukan.</p><p>Administrator klaster dan penyedia layanan Kubernetes sebaiknya menggunakan alat-alat yang menghormati PDB dengan cara berkomunikasi dengan <a href=/docs/tasks/administer-cluster/safely-drain-node/#the-eviction-api>Eviction API</a> dari pada menghapus Pod atau Deployment secara langsung. Contohnya adalah perintah <code>kubectl drain</code> dan skrip pembaruan Kubernetes-on-GCE (<code>cluster/gce/upgrade.sh</code>)</p><p>Saat seorang administrator klaster ingin melakukan <em>drain</em> terhadap sebuah node, ia akan menggunakan perintah <code>kubectl drain</code>. Alat tersebut mencoba untuk "mengusir" semua Pod di node tersebut. Permintaan untuk mengusir Pod tersebut mungkin ditolak untuk sementara, dan alat tersebut akan mencoba ulang permintaannya secara periodik hingga semua Pod dihapus, atau hingga batas waktu yang ditentukan telah dicapai.</p><p>Sebua PDB merinci jumlah replika yang dapat ditoleransi oleh sebuah aplikasi, relatif terhadap berapa banyak yang seharusnya dimiliki oleh aplikasi tersebut. Sebagai contoh, sebuah Deployment yang memiliki rincian <code>.spec.replicas :5</code> diharapkan memiliki 5 Pod pada satu waktu. Jika PDB aplikasi tersebut mengizinkan ada 4 replika pada satu waktu, maka Eviction API akan mengizinkan disrupsi yag disengaja sebanyak satu, tapi tidak mengizinkan dua, pada satu waktu.</p><p>Sebuah kelompok Pod yang mewakili aplikasi dispesifikasikan menggunakan sebuah <em>label selector</em> yang sama dengan yang digunakan oleh pengatur aplikasi tersebut (Deployment, StatefulSet, dsb.)</p><p>Jumlah Pod yang "diharapkan" dihitung dari <code>.spec.replicas</code> dari pengendali Pod tersebut. Pengendali dari sebuah Pod dapat ditemukan di spesifikasi <code>.metadata.ownerReferences</code> objek Pod yang bersangkutan.</p><p>PDB tidak dapat mencegah <a href=#disrupsi-yang-disengaja-dan-tidak-disengaja>disrupsi yang tidak disengaja</a>, tapi disrupsi ini akan dihitung terhadap bujet PDB.</p><p>Pod yang dihapus atau tidak tersetia dikarenakan pembaruan bertahap juga dihitung terhadap bujet PDB, tetapi pengendali (seperti Deployment dan StatefulSet) tidak dibatasi oleh PDB ketika melakukan pembaruan bertahap; Penanganan kerusakan saat pembaruan aplikasi dikonfigurasikan pada spesifikasi pengendali. (Pelajari tentang <a href=/id/docs/concepts/workloads/controllers/deployment/#updating-a-deployment>memperbarui sebuah Deployment</a>.)</p><p>Saat sebuah Pod diusir menggunakan <em>eviction API</em>, Pod tersebut akan dihapus secara <em>graceful</em> (lihat <code>terminationGracePeriodSeconds</code> pada <a href=/docs/reference/generated/kubernetes-api/v1.25/#Podspec-v1-core>PodSpec</a>.))</p><h2 id=contoh-pdb>Contoh PDB</h2><p>Kita ambil contoh sebuah klaster dengan 3 node, <code>node-1</code> hingga <code>node-3</code>.
Klaster tersebut menjalankan beberapa aplikasi. Salah satu dari aplikasi tersebut awalnya memiliki 3 replika, yang akan kita namai <code>Pod-a</code>, <code>Pod-b</code>, dan <code>Pod-c</code>. Sebuah Pod lain yang tidak bersangkutan dan tidak memiliki PDB, dinamai <code>Pod-x</code> juga terlihat. Awalnya, Pod-pod tersebut berada pada node-node sebagai berikut:</p><table><thead><tr><th style=text-align:center>node-1</th><th style=text-align:center>node-2</th><th style=text-align:center>node-3</th></tr></thead><tbody><tr><td style=text-align:center>Pod-a <em>available</em></td><td style=text-align:center>Pod-b <em>available</em></td><td style=text-align:center>Pod-c <em>available</em></td></tr><tr><td style=text-align:center>Pod-x <em>available</em></td><td style=text-align:center></td><td style=text-align:center></td></tr></tbody></table><p>3 Pod <code>Pod-a</code> hingga <code>Pod-c</code> adalah bagian dari sebuah Deployment, dan mereka secara kolektif memiliki sebuah PDB yang mengharuskan ada setidaknya 2 dari 3 Pod untuk tersedia sepanjang waktu.</p><p>Sebagai contoh, asumsikan administrator klaster ingin me-<em>reboot</em> ke dalam versi kernel baru untuk memperbaiki kesalahan di dalam kernel lama. Administator klaster pertama-tama mencoba untuk melakukan <em>drain</em> terhadap <code>node-1</code> menggunakan perintah <code>kubectl drain</code>. Perintah tersebut mencoba untuk mengusir <code>Pod-a</code> dan <code>Pod-x</code>. Hal ini langsung berhasil. Kedua Pod tersebut masuk ke dalam kondisi <code>terminating</code> secara bersamaan. Hal ini mengubah kondisi klaster menjadi sebagai berikut:</p><table><thead><tr><th style=text-align:center>node-1 <em>draining</em></th><th style=text-align:center>node-2</th><th style=text-align:center>node-3</th></tr></thead><tbody><tr><td style=text-align:center>Pod-a <em>terminating</em></td><td style=text-align:center>Pod-b <em>available</em></td><td style=text-align:center>Pod-c <em>available</em></td></tr><tr><td style=text-align:center>Pod-x <em>terminating</em></td><td style=text-align:center></td><td style=text-align:center></td></tr></tbody></table><p>Deployment tersebut melihat bahwa salah satu Pod berada dalam kondisi <code>terminating</code>, sehingga Deployment mencoba untuk membuat penggantinya, <code>Pod-d</code>. Sejak <code>node-1</code> ditutup (karena perintah <code>kubectl-drain</code>), <code>Pod-d</code> masuk ke node lainnya. Sesuatu juga membuat <code>Pod-y</code> sebagai pengganti <code>Pod-x</code></p><p>(Catatan: untuk sebuah StatefulSet, <code>Pod-a</code>, akan dinamai dengan <code>Pod-1</code>, harus diterminasi hingga selesai sebelum penggantinya, yang juga dinamai <code>Pod-1</code> tetapi memiliki UID yang berbeda, akan dibuat. Selain hal ini, seluruh contoh ini juga berlaku untuk StatefulSet.)</p><p>Sekarang, klaster berada pada kondisi berikut:</p><table><thead><tr><th style=text-align:center>node-1 <em>draining</em></th><th style=text-align:center>node-2</th><th style=text-align:center>node-3</th></tr></thead><tbody><tr><td style=text-align:center>Pod-a <em>terminating</em></td><td style=text-align:center>Pod-b <em>available</em></td><td style=text-align:center>Pod-c <em>available</em></td></tr><tr><td style=text-align:center>Pod-x <em>terminating</em></td><td style=text-align:center>Pod-d <em>starting</em></td><td style=text-align:center>Pod-y</td></tr></tbody></table><p>Pada satu waktu, Pod-pod yang diusir pun selesai diterminasi, dan kondisi klaster menjadi seperti berikut:</p><table><thead><tr><th style=text-align:center>node-1 <em>drained</em></th><th style=text-align:center>node-2</th><th style=text-align:center>node-3</th></tr></thead><tbody><tr><td style=text-align:center></td><td style=text-align:center>Pod-b <em>available</em></td><td style=text-align:center>Pod-c <em>available</em></td></tr><tr><td style=text-align:center></td><td style=text-align:center>Pod-d <em>starting</em></td><td style=text-align:center>Pod-y</td></tr></tbody></table><p>Pada titik ini, jika seorang administrator klaster yang tidak sabar mencoba untuk melakukan <em>drain</em> terhadap <code>node-2</code> atau <code>node-3</code>, perintah untuk melakukan <em>drain</em> terhadap node tersebut akan terhalang, karena hanya ada 2 Pod yang tersedia, dan PDB-nya membutuhkan setidaknya ada 2 Pod tersedia. Setelah beberapa waktu, <code>Pod-d</code> menjadi tersedia.</p><p>Kondisi klaster menjadi seperti berikut:</p><table><thead><tr><th style=text-align:center>node-1 <em>drained</em></th><th style=text-align:center>node-2</th><th style=text-align:center>node-3</th></tr></thead><tbody><tr><td style=text-align:center></td><td style=text-align:center>Pod-b <em>available</em></td><td style=text-align:center>Pod-c <em>available</em></td></tr><tr><td style=text-align:center></td><td style=text-align:center>Pod-d <em>available</em></td><td style=text-align:center>Pod-y</td></tr></tbody></table><p>Sekarang, administrator klaster mencoba untuk melakukan <em>drain</em> terhadap <code>node-2</code>. Perintah <em>drain</em> tersebut akan mencoba mengusir Pod-pod tersebut secara berurutan (tidak bersamaan), misalnya <code>Pod-b</code> yang pertama dan diikuti dengan <code>Pod-d</code>. Perintah tersebut akan berhasil mengusir <code>Pod-b</code>. Tetapi, pada saat ia mencoba untuk mengusir <code>Pod-d</code>, hal tersebut akan ditolak karena hal tersebut akan mengakibatkan hanya satu Pod yang tersedia untuk Deployment yang bersangkutan.</p><p>Deployment tersebut membuat pengganti <code>Pod-b</code> yang dinamai <code>Pod-e</code>.
Karena tidak ada sumber daya klaster yang cukup untuk mengalokasikan <code>Pod-e</code>, proses <em>drain</em> akan kembali terhalang.
Klaster mungkin berada pada kondisi berikut:</p><table><thead><tr><th style=text-align:center>node-1 <em>drained</em></th><th style=text-align:center>node-2</th><th style=text-align:center>node-3</th><th style=text-align:center><em>no node</em></th></tr></thead><tbody><tr><td style=text-align:center></td><td style=text-align:center>Pod-b <em>available</em></td><td style=text-align:center>Pod-c <em>available</em></td><td style=text-align:center>Pod-e <em>pending</em></td></tr><tr><td style=text-align:center></td><td style=text-align:center>Pod-d <em>available</em></td><td style=text-align:center>Pod-y</td><td style=text-align:center></td></tr></tbody></table><p>Pada titik ini, administrator klaster mesti menambah sebuah node untuk klaster agar bisa melanjutkan pembaruan klaster.</p><p>Kamu dapat melihat bagaimana frekuensi disrupsi dapat berubah-ubah pada Kubernetes, tergantung pada:</p><ul><li>Berapa banyak replika yang dibutuhkan sebuah aplikasi</li><li>Berapa lama waktu yang dibutuhkan untuk mematikan sebuah Pod secara <em>graceful</em></li><li>Berapa lama waktu yang dibutuhkan untuk memulai sebuah Pod</li><li>Tipe pengendali</li><li>Kapasitas sumber daya klaster</li></ul><h2 id=memisahkan-peran-pemilik-klaster-dan-pemilik-aplikasi>Memisahkan Peran Pemilik Klaster dan Pemilik Aplikasi</h2><p>Seringkali akan bermanfaat untuk berpikir Administrator Klaster dan Pemilik Aplikasi sebagai peran yang terpisah dan dengan pengetahuan yang terbatas satu sama lainnya. Pemisahan ini dapat dimengerti dalam beberapa skenario berikut:</p><ul><li>Saat ada banyak tim aplikasi yang berbagi pakai sebuah klaster Kubernetes, dan ada pembagian peran yang spesifik</li><li>Saat alat atau servis pihak ketiga digunakan untuk melakukan otomasi manajemen klaster.</li></ul><p>PDB mendukung pemisahan peran ini dengan cara menyediakan antarmuka bagi peran-peran tersebut.</p><p>Jika kamu tidak memiliki pemisahan peran seperti ini pada organisasimu, kamu mungkin tidak membutuhkan PDB.</p><h2 id=bagaimana-cara-melakukan-tindakan-disruptif-terhadap-klaster>Bagaimana cara melakukan Tindakan Disruptif terhadap Klaster</h2><p>Jika kamu adalah Administrator Klaster, maka kamu mesti melakukan tindakan disruptif pada setiap node di klastermu, seperti melakukan pembaruan perangkat lunak pada node, berikut beberapa opsinya:</p><ul><li>Menerima <em>downtime</em> pada saat pembaruan node</li><li>Melakukan <em>failover</em> ke replika lengkap klaster lain.<ul><li>Tanpa <em>downtime</em>, tetapi mungkin lebih mahal, baik ongkos duplikasi node-node dan tenaga yang dibutuhkan untuk melakukan <em>failover</em>.</li></ul></li><li>Membuat aplikasi yang toleran terhadap disrupsi, dan gunakan PDB.<ul><li>Tanpa <em>downtime</em>.</li><li>Duplikasi sumber daya yang minimal.</li><li>Mengizinkan lebih banyak otomasi administrasi klaster.</li><li>Membuat aplikasi yang toleran terhadap disrupsi agak rumit, tetapi usaha yang dilakukan untuk menoleransi disrupsi yang disengaja kebanyakan beririsan dengan usaha untuk mendukung <em>autoscaling</em> dan menoleransi disrupsi yang tidak disengaja.</li></ul></li></ul><h2 id=selanjutnya>Selanjutnya</h2><ul><li><p>Ikuti langkah-langkah untuk melindungi aplikasimu dengan <a href=/docs/tasks/run-application/configure-pdb/>membuat sebuah PodDisruptionBudget</a>.</p></li><li><p>Pelajari lebih lanjut mengenai <a href=/docs/tasks/administer-cluster/safely-drain-node/>melakukan <em>drain</em> terhadap node</a>.</p></li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-53a1005011e1bda2ce81819aad7c8b32>1.8 - Kontainer Sementara (Ephemeral)</h1><div style=margin-top:10px;margin-bottom:10px><b>FEATURE STATE:</b> <code>Kubernetes v1.16 [alpha]</code></div><p>Halaman ini memberikan gambaran umum tentang kontainer sementara: satu jenis
kontainer khusus yang berjalan sementara pada <a class=glossary-tooltip title='Unit Kubernetes yang paling sederhana dan kecil. Sebuah Pod merepresentasikan sebuah set kontainer yang dijalankan pada kluster kamu.' data-toggle=tooltip data-placement=top href=/docs/concepts/workloads/pods/pod-overview/ target=_blank aria-label=Pod>Pod</a>
yang sudah ada untuk melakukan tindakan yang diinisiasi oleh pengguna seperti
dalam pemecahan masalah. Kamu menggunakan kontainer sementara untuk memeriksa
layanan bukan untuk membangun aplikasi.</p><div class="alert alert-danger warning callout" role=alert><strong>Peringatan:</strong> Kontainer sementara masih berada dalam fase alpha dan tidak cocok untuk
klaster produksi. Kamu harus mengharapkan adanya suatu fitur yang tidak akan
berfungsi dalam beberapa situasi tertentu, seperti saat menargetkan <em>namespace</em>
dari suatu kontainer. Sesuai dengan Kubernetes
<a href=/docs/reference/using-api/deprecation-policy/><em>Deprecation Policy</em></a>, fitur alpha
ini dapat berubah secara signifikan di masa depan atau akan dihapus seluruhnya.</div><h2 id=memahami-kontainer-sementara>Memahami Kontainer Sementara</h2><p><a class=glossary-tooltip title='Unit Kubernetes yang paling sederhana dan kecil. Sebuah Pod merepresentasikan sebuah set kontainer yang dijalankan pada kluster kamu.' data-toggle=tooltip data-placement=top href=/docs/concepts/workloads/pods/pod-overview/ target=_blank aria-label=Pod>Pod</a> adalah blok pembangun
fundamental dalam aplikasi Kubernetes. Karena Pod diharapkan digunakan hanya
sekali dan dapat diganti, sehingga kamu tidak dapat menambahkan kontainer ke
dalam Pod setelah Pod tersebut dibuat. Sebaliknya, kamu biasanya menghapus dan
mengganti beberapa Pod dengan cara yang terkontrol melalui
<a class=glossary-tooltip title='Mengelola aplikasi yang direplikasi di dalam klastermu.' data-toggle=tooltip data-placement=top href=/id/docs/concepts/workloads/controllers/deployment/ target=_blank aria-label=Deployment>Deployment</a>.</p><p>Namun, kadang-kadang perlu juga untuk memeriksa keadaan Pod yang telah ada,
sebagai contoh untuk memecahkan masalah <em>bug</em> yang sulit direproduksi. Dalam
kasus ini, kamu dapat menjalankan sebuah kontainer sementara di dalam suatu Pod
yang sudah ada untuk memeriksa statusnya dan menjalankannya segala macam
perintah.</p><h3 id=apa-itu-kontainer-sementara>Apa itu Kontainer Sementara?</h3><p>Kontainer sementara berbeda dengan kontainer lainnya karena tidak memiliki
jaminan sumber daya maupun akan eksekusi, dan mereka tidak akan pernah secara
otomatis melakukan <em>restart</em>, jadi mereka tidak sesuai untuk membangun aplikasi.
Kontainer sementara dideskripsikan dengan menggunakan ContainerSpec yang sama
dengan kontainer biasa, tetapi banyak bagian yang tidak kompatibel dan tidak
diperbolehkan untuk kontainer sementara.</p><ul><li>Kontainer sementara mungkin tidak memiliki port, sehingga bagian seperti
<code>port</code>, <code>livenessProbe</code>, <code>readinessProbe</code> tidak diperbolehkan.</li><li>Alokasi sumber daya untuk Pod tidak dapat diubah, sehingga pengaturan
sumber daya tidak diperbolehkan.</li><li>Untuk daftar lengkap bagian yang diperbolehkan, dapat di lihat
<a href=/docs/reference/generated/kubernetes-api/v1.25/#ephemeralcontainer-v1-core>referensi dokumentasi Kontainer Sementara</a>.</li></ul><p>Kontainer sementara dibuat dengan menggunakan <em>handler</em> khusus
EphemeralContainers dalam API tanpa menambahkannya langsung ke <code>pod.spec</code>,
sehingga tidak memungkinan untuk menambahkan kontainer sementara dengan
menggunakan <code>kubectl edit</code>.</p><p>Seperti dengan kontainer biasa, kamu tidak dapat mengubah atau menghapus
kontainer sementara setelah kamu memasukkannya ke dalam sebuah Pod.</p><h2 id=penggunaan-kontainer-sementara>Penggunaan Kontainer Sementara</h2><p>Kontainer sementara berguna untuk pemecahan masalah secara interaktif pada saat
<code>kubectl exec</code> tidak mencukupi karena sebuah kontainer telah hancur atau
kontainer <em>image</em> tidak memiliki utilitas untuk <em>debugging</em>.</p><p>Khususnya, untuk <a href=https://github.com/GoogleContainerTools/distroless><em>images_distroless</em></a>
memungkinkan kamu untuk menyebarkan kontainer <em>image</em> minimal yang mengurangi
<em>surface attack</em> dan paparan <em>bug</em> dan <em>vulnerability</em>. Karena
<em>image distroless</em> tidak mempunyai sebuah <em>shell</em> atau utilitas <em>debugging</em> apa
pun, sehingga sulit untuk memecahkan masalah <em>image distroless</em> dengan
menggunakan <code>kubectl exec</code> saja.</p><p>Saat menggunakan kontainer sementara, akan sangat membantu untuk mengaktifkan
<a href=/id/docs/tasks/configure-pod-container/share-process-namespace/><em>process namespace sharing</em></a>
sehingga kamu dapat melihat proses pada kontainer lain.</p><h3 id=contoh>Contoh</h3><div class="alert alert-info note callout" role=alert><strong>Catatan:</strong> Contoh-contoh pada bagian ini membutuhkan <code>EphemeralContainers</code> <a href=/docs/reference/command-line-tools-reference/feature-gates/>feature
gate</a> untuk
diaktifkan, dan membutuhkan Kubernetes klien dan server versi v1.16 atau
yang lebih baru.</div><p>Contoh-contoh pada bagian ini menunjukkan bagaimana kontainer sementara muncul
dalam API. Kamu biasanya dapat menggunakan plugin <code>kubectl</code> untuk mengatasi
masalah untuk mengotomatiskan langkah-langkah ini.</p><p>Kontainer sementara dibuat menggunakan <em>subresource</em> <code>ephemeralcontainers</code>
Pod, yang dapat didemonstrasikan menggunakan <code>kubectl --raw</code>. Pertama-tama
deskripsikan kontainer sementara untuk ditambahkan dalam daftar
<code>EphemeralContainers</code>:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-json data-lang=json><span style=display:flex><span>{
</span></span><span style=display:flex><span>    <span style=color:green;font-weight:700>&#34;apiVersion&#34;</span>: <span style=color:#b44>&#34;v1&#34;</span>,
</span></span><span style=display:flex><span>    <span style=color:green;font-weight:700>&#34;kind&#34;</span>: <span style=color:#b44>&#34;EphemeralContainers&#34;</span>,
</span></span><span style=display:flex><span>    <span style=color:green;font-weight:700>&#34;metadata&#34;</span>: {
</span></span><span style=display:flex><span>        <span style=color:green;font-weight:700>&#34;name&#34;</span>: <span style=color:#b44>&#34;example-pod&#34;</span>
</span></span><span style=display:flex><span>    },
</span></span><span style=display:flex><span>    <span style=color:green;font-weight:700>&#34;ephemeralContainers&#34;</span>: [{
</span></span><span style=display:flex><span>        <span style=color:green;font-weight:700>&#34;command&#34;</span>: [
</span></span><span style=display:flex><span>            <span style=color:#b44>&#34;sh&#34;</span>
</span></span><span style=display:flex><span>        ],
</span></span><span style=display:flex><span>        <span style=color:green;font-weight:700>&#34;image&#34;</span>: <span style=color:#b44>&#34;busybox&#34;</span>,
</span></span><span style=display:flex><span>        <span style=color:green;font-weight:700>&#34;imagePullPolicy&#34;</span>: <span style=color:#b44>&#34;IfNotPresent&#34;</span>,
</span></span><span style=display:flex><span>        <span style=color:green;font-weight:700>&#34;name&#34;</span>: <span style=color:#b44>&#34;debugger&#34;</span>,
</span></span><span style=display:flex><span>        <span style=color:green;font-weight:700>&#34;stdin&#34;</span>: <span style=color:#a2f;font-weight:700>true</span>,
</span></span><span style=display:flex><span>        <span style=color:green;font-weight:700>&#34;tty&#34;</span>: <span style=color:#a2f;font-weight:700>true</span>,
</span></span><span style=display:flex><span>        <span style=color:green;font-weight:700>&#34;terminationMessagePolicy&#34;</span>: <span style=color:#b44>&#34;File&#34;</span>
</span></span><span style=display:flex><span>    }]
</span></span><span style=display:flex><span>}
</span></span></code></pre></div><p>Untuk memperbarui kontainer yang sudah berjalan dalam <code>example-pod</code>:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl replace --raw /api/v1/namespaces/default/pods/example-pod/ephemeralcontainers  -f ec.json
</span></span></code></pre></div><p>Ini akan menampilkan daftar baru dari seluruh kontainer sementara:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-json data-lang=json><span style=display:flex><span>{
</span></span><span style=display:flex><span>   <span style=color:green;font-weight:700>&#34;kind&#34;</span>:<span style=color:#b44>&#34;EphemeralContainers&#34;</span>,
</span></span><span style=display:flex><span>   <span style=color:green;font-weight:700>&#34;apiVersion&#34;</span>:<span style=color:#b44>&#34;v1&#34;</span>,
</span></span><span style=display:flex><span>   <span style=color:green;font-weight:700>&#34;metadata&#34;</span>:{
</span></span><span style=display:flex><span>      <span style=color:green;font-weight:700>&#34;name&#34;</span>:<span style=color:#b44>&#34;example-pod&#34;</span>,
</span></span><span style=display:flex><span>      <span style=color:green;font-weight:700>&#34;namespace&#34;</span>:<span style=color:#b44>&#34;default&#34;</span>,
</span></span><span style=display:flex><span>      <span style=color:green;font-weight:700>&#34;selfLink&#34;</span>:<span style=color:#b44>&#34;/api/v1/namespaces/default/pods/example-pod/ephemeralcontainers&#34;</span>,
</span></span><span style=display:flex><span>      <span style=color:green;font-weight:700>&#34;uid&#34;</span>:<span style=color:#b44>&#34;a14a6d9b-62f2-4119-9d8e-e2ed6bc3a47c&#34;</span>,
</span></span><span style=display:flex><span>      <span style=color:green;font-weight:700>&#34;resourceVersion&#34;</span>:<span style=color:#b44>&#34;15886&#34;</span>,
</span></span><span style=display:flex><span>      <span style=color:green;font-weight:700>&#34;creationTimestamp&#34;</span>:<span style=color:#b44>&#34;2019-08-29T06:41:42Z&#34;</span>
</span></span><span style=display:flex><span>   },
</span></span><span style=display:flex><span>   <span style=color:green;font-weight:700>&#34;ephemeralContainers&#34;</span>:[
</span></span><span style=display:flex><span>      {
</span></span><span style=display:flex><span>         <span style=color:green;font-weight:700>&#34;name&#34;</span>:<span style=color:#b44>&#34;debugger&#34;</span>,
</span></span><span style=display:flex><span>         <span style=color:green;font-weight:700>&#34;image&#34;</span>:<span style=color:#b44>&#34;busybox&#34;</span>,
</span></span><span style=display:flex><span>         <span style=color:green;font-weight:700>&#34;command&#34;</span>:[
</span></span><span style=display:flex><span>            <span style=color:#b44>&#34;sh&#34;</span>
</span></span><span style=display:flex><span>         ],
</span></span><span style=display:flex><span>         <span style=color:green;font-weight:700>&#34;resources&#34;</span>:{
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>         },
</span></span><span style=display:flex><span>         <span style=color:green;font-weight:700>&#34;terminationMessagePolicy&#34;</span>:<span style=color:#b44>&#34;File&#34;</span>,
</span></span><span style=display:flex><span>         <span style=color:green;font-weight:700>&#34;imagePullPolicy&#34;</span>:<span style=color:#b44>&#34;IfNotPresent&#34;</span>,
</span></span><span style=display:flex><span>         <span style=color:green;font-weight:700>&#34;stdin&#34;</span>:<span style=color:#a2f;font-weight:700>true</span>,
</span></span><span style=display:flex><span>         <span style=color:green;font-weight:700>&#34;tty&#34;</span>:<span style=color:#a2f;font-weight:700>true</span>
</span></span><span style=display:flex><span>      }
</span></span><span style=display:flex><span>   ]
</span></span><span style=display:flex><span>}
</span></span></code></pre></div><p>Kamu dapat melihat kondisi kontainer sementara yang baru dibuat dengan
menggunakan <code>kubectl describe</code>:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl describe pod example-pod
</span></span></code></pre></div><pre tabindex=0><code>...
Ephemeral Containers:
  debugger:
    Container ID:  docker://cf81908f149e7e9213d3c3644eda55c72efaff67652a2685c1146f0ce151e80f
    Image:         busybox
    Image ID:      docker-pullable://busybox@sha256:9f1003c480699be56815db0f8146ad2e22efea85129b5b5983d0e0fb52d9ab70
    Port:          &lt;none&gt;
    Host Port:     &lt;none&gt;
    Command:
      sh
    State:          Running
      Started:      Thu, 29 Aug 2019 06:42:21 +0000
    Ready:          False
    Restart Count:  0
    Environment:    &lt;none&gt;
    Mounts:         &lt;none&gt;
...
</code></pre><p>Kamu dapat mengakses kontainer sementara yang baru menggunakan
<code>kubectl attach</code>:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl attach -it example-pod -c debugger
</span></span></code></pre></div><p>Jika proses berbagi <em>namespace</em> diaktifkan, kamu dapat melihat proses dari semua
kontainer dalam Pod tersebut. Misalnya, setelah mengakses, kamu jalankan
<code>ps</code> di kontainer <em>debugger</em>:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span><span style=color:#080;font-style:italic># Jalankan ini pada _shell_ dalam _debugger_ dari kontainer sementara</span>
</span></span><span style=display:flex><span>ps auxww
</span></span></code></pre></div><p>Hasilnya akan seperti ini:</p><pre tabindex=0><code>PID   USER     TIME  COMMAND
    1 root      0:00 /pause
    6 root      0:00 nginx: master process nginx -g daemon off;
   11 101       0:00 nginx: worker process
   12 101       0:00 nginx: worker process
   13 101       0:00 nginx: worker process
   14 101       0:00 nginx: worker process
   15 101       0:00 nginx: worker process
   16 101       0:00 nginx: worker process
   17 101       0:00 nginx: worker process
   18 101       0:00 nginx: worker process
   19 root      0:00 /pause
   24 root      0:00 sh
   29 root      0:00 ps auxww
</code></pre></div><div class=td-content style=page-break-before:always><h1 id=pg-89637410cacae45a36ab1cc278c482eb>2 - Controllers</h1></div><div class=td-content><h1 id=pg-d459b930218774655fa7fd1620625539>2.1 - ReplicaSet</h1><p>Tujuan dari ReplicaSet adalah untuk memelihara himpunan stabil dari replika Pod yang sedang berjalan pada satu waktu tertentu. Maka dari itu, ReplicaSet seringkali digunakan untuk menjamin ketersediaan dari beberapa Pod identik dalam jumlah tertentu.</p><h2 id=cara-kerja-replicaset>Cara kerja ReplicaSet</h2><p>Sebuah ReplicaSet didefinisikan dengan beberapa <em>field</em> termasuk selektor yang menentukan bagaimana mengidentifikasi Pod yang dapat diakuisisi, jumlah replika yang mengindikasi berapa jumlah Pod yang harus dikelola, dan sebuah templat pod yang menentukan data dari berbagai Pod baru yang harus dibuat untuk memenuhi kriteria jumlah replika. Sebuah ReplicaSet selanjutnya akan memenuhi tujuannya dengan membuat dan menghapus Pod sesuai dengan kebutuhan untuk mencapai jumlah yang diinginkan. Ketika ReplicaSet butuh untuk membuat Pod baru, templat Pod akan digunakan.</p><p>Tautan dari sebuah ReplicaSet terhadap Pod yang dimiliki adalah melalui <em>field</em> <a href=https://kubernetes.io/docs/concepts/workloads/controllers/garbage-collection/#owners-and-dependents>metadata.ownerReferences</a> pada Pod, yang menentukan sumber daya yang dimiliki oleh objek saat ini. Semua Pod yang diakuisisi oleh sebuah ReplicaSet masing-masing memiliki informasi yang mengidentifikasi ReplicaSet dalam <em>field</em> ownerReferences. Melalui tautan ini ReplicaSet dapat mengetahui keadaan dari Pod yang sedang dikelola dan melakukan perencanaan yang sesuai.</p><p>Sebuah ReplicaSet mengidentifikasi Pod baru untuk diakuisisi menggunakan selektornya. Jika terdapat sebuah Pod yang tidak memiliki OwnerReference atau OwnerReference yang dimiliki bukanlah sebuah <a href=https://kubernetes.io/docs/concepts/architecture/controller><em>Controller</em></a> dan sesuai dengan selektor dari ReplicaSet, maka Pod akan langsung diakuisisi oleh ReplicaSet tersebut.</p><h2 id=kapan-menggunakan-replicaset>Kapan menggunakan ReplicaSet</h2><p>Sebuah ReplicaSet memastikan replika-replika pod dalam jumlah yang ditentukan berjalan pada satu waktu tertentu. Namun demikian, sebuah Deployment adalah konsep dengan tingkatan yang lebih tinggi yang mengatur ReplicaSet dan mengubah Pod secara deklaratif serta berbagai fitur bermanfaat lainnya. Maka dari itu, kami merekomendasikan untuk menggunakan Deployment alih-alih menggunakan ReplicaSet secara langsung, kecuali jika kamu membutuhkan orkestrasi pembaruan yang khusus atau tidak membutuhkan pembaruan sama sekali.</p><p>Hal ini berarti kamu boleh jadi tidak akan membutuhkan manipulasi objek ReplicaSet: Gunakan Deployment dan definisikan aplikasi kamu pada bagian <em>spec</em>.</p><h2 id=contoh>Contoh</h2><div class=highlight><div class=copy-code-icon style=text-align:right><a href=https://raw.githubusercontent.com/kubernetes/website/main/content/id/examples/controllers/frontend.yaml download=controllers/frontend.yaml><code>controllers/frontend.yaml</code></a>
<img src=/images/copycode.svg style=max-height:24px;cursor:pointer onclick='copyCode("controllers-frontend-yaml")' title="Copy controllers/frontend.yaml to clipboard"></img></div><div class=includecode id=controllers-frontend-yaml><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>apps/v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>ReplicaSet<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>frontend<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>labels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>app</span>:<span style=color:#bbb> </span>guestbook<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>tier</span>:<span style=color:#bbb> </span>frontend<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:#080;font-style:italic># modify replicas according to your case</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>replicas</span>:<span style=color:#bbb> </span><span style=color:#666>3</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>selector</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>matchLabels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>tier</span>:<span style=color:#bbb> </span>frontend<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>template</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>labels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>tier</span>:<span style=color:#bbb> </span>frontend<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>php-redis<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>gcr.io/google_samples/gb-frontend:v3<span style=color:#bbb>
</span></span></span></code></pre></div></div></div><p>Menyimpan <em>manifest</em> ini dalam <code>frontend.yaml</code> dan mengirimkannya ke klaster Kubernetes akan membuat ReplicaSet yang telah didefinisikan beserta dengan Pod yang dikelola.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl apply -f https://kubernetes.io/examples/controllers/frontend.yaml
</span></span></code></pre></div><p>Selanjutnya kamu bisa mendapatkan ReplicaSet yang sedang di-<em>deploy</em>:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get rs
</span></span></code></pre></div><p>Dan melihat <em>frontend</em> yang telah dibuat:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>NAME       DESIRED   CURRENT   READY   AGE
</span></span><span style=display:flex><span>frontend   <span style=color:#666>3</span>         <span style=color:#666>3</span>         <span style=color:#666>3</span>       6s
</span></span></code></pre></div><p>Kamu juga dapat memeriksa kondisi dari ReplicaSet:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl describe rs/frontend
</span></span></code></pre></div><p>Dan kamu akan melihat keluaran yang serupa dengan:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>Name:		frontend
</span></span><span style=display:flex><span>Namespace:	default
</span></span><span style=display:flex><span>Selector:	<span style=color:#b8860b>tier</span><span style=color:#666>=</span>frontend,tier in <span style=color:#666>(</span>frontend<span style=color:#666>)</span>
</span></span><span style=display:flex><span>Labels:		<span style=color:#b8860b>app</span><span style=color:#666>=</span>guestbook
</span></span><span style=display:flex><span>		<span style=color:#b8860b>tier</span><span style=color:#666>=</span>frontend
</span></span><span style=display:flex><span>Annotations:	&lt;none&gt;
</span></span><span style=display:flex><span>Replicas:	<span style=color:#666>3</span> current / <span style=color:#666>3</span> desired
</span></span><span style=display:flex><span>Pods Status:	<span style=color:#666>3</span> Running / <span style=color:#666>0</span> Waiting / <span style=color:#666>0</span> Succeeded / <span style=color:#666>0</span> Failed
</span></span><span style=display:flex><span>Pod Template:
</span></span><span style=display:flex><span>  Labels:       <span style=color:#b8860b>app</span><span style=color:#666>=</span>guestbook
</span></span><span style=display:flex><span>                <span style=color:#b8860b>tier</span><span style=color:#666>=</span>frontend
</span></span><span style=display:flex><span>  Containers:
</span></span><span style=display:flex><span>   php-redis:
</span></span><span style=display:flex><span>    Image:      gcr.io/google_samples/gb-frontend:v3
</span></span><span style=display:flex><span>    Port:       80/TCP
</span></span><span style=display:flex><span>    Requests:
</span></span><span style=display:flex><span>      cpu:      100m
</span></span><span style=display:flex><span>      memory:   100Mi
</span></span><span style=display:flex><span>    Environment:
</span></span><span style=display:flex><span>      GET_HOSTS_FROM:   dns
</span></span><span style=display:flex><span>    Mounts:             &lt;none&gt;
</span></span><span style=display:flex><span>  Volumes:              &lt;none&gt;
</span></span><span style=display:flex><span>Events:
</span></span><span style=display:flex><span>  FirstSeen    LastSeen    Count    From                SubobjectPath    Type        Reason            Message
</span></span><span style=display:flex><span>  ---------    --------    -----    ----                -------------    --------    ------            -------
</span></span><span style=display:flex><span>  1m           1m          <span style=color:#666>1</span>        <span style=color:#666>{</span>replicaset-controller <span style=color:#666>}</span>             Normal      SuccessfulCreate  Created pod: frontend-qhloh
</span></span><span style=display:flex><span>  1m           1m          <span style=color:#666>1</span>        <span style=color:#666>{</span>replicaset-controller <span style=color:#666>}</span>             Normal      SuccessfulCreate  Created pod: frontend-dnjpy
</span></span><span style=display:flex><span>  1m           1m          <span style=color:#666>1</span>        <span style=color:#666>{</span>replicaset-controller <span style=color:#666>}</span>             Normal      SuccessfulCreate  Created pod: frontend-9si5l
</span></span></code></pre></div><p>Terakhir, kamu dapat memeriksa Pod yang dibawa:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get Pods
</span></span></code></pre></div><p>Kamu akan melihat informasi Pod yang serupa dengan:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>NAME             READY     STATUS    RESTARTS   AGE
</span></span><span style=display:flex><span>frontend-9si5l   1/1       Running   <span style=color:#666>0</span>          1m
</span></span><span style=display:flex><span>frontend-dnjpy   1/1       Running   <span style=color:#666>0</span>          1m
</span></span><span style=display:flex><span>frontend-qhloh   1/1       Running   <span style=color:#666>0</span>          1m
</span></span></code></pre></div><p>Kamu juga dapat memastikan bahwa referensi pemilik dari pod-pod ini telah disesuaikan terhadap ReplicaSet <em>frontend</em>.
Untuk melakukannya, <em>yaml</em> dari Pod yang sedang berjalan bisa didapatkan dengan:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get pods frontend-9si5l -o yaml
</span></span></code></pre></div><p>Keluarannya akan terlihat serupa dengan contoh berikut ini, dengan informasi ReplicaSet <em>frontend</em> yang ditentukan pada <em>field</em> ownerReferences pada bagian metadata:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>apiVersion: v1
</span></span><span style=display:flex><span>kind: Pod
</span></span><span style=display:flex><span>metadata:
</span></span><span style=display:flex><span>  creationTimestamp: 2019-01-31T17:20:41Z
</span></span><span style=display:flex><span>  generateName: frontend-
</span></span><span style=display:flex><span>  labels:
</span></span><span style=display:flex><span>    tier: frontend
</span></span><span style=display:flex><span>  name: frontend-9si5l
</span></span><span style=display:flex><span>  namespace: default
</span></span><span style=display:flex><span>  ownerReferences:
</span></span><span style=display:flex><span>  - apiVersion: extensions/v1beta1
</span></span><span style=display:flex><span>    blockOwnerDeletion: <span style=color:#a2f>true</span>
</span></span><span style=display:flex><span>    controller: <span style=color:#a2f>true</span>
</span></span><span style=display:flex><span>    kind: ReplicaSet
</span></span><span style=display:flex><span>    name: frontend
</span></span><span style=display:flex><span>    uid: 892a2330-257c-11e9-aecd-025000000001
</span></span><span style=display:flex><span>...
</span></span></code></pre></div><h2 id=akuisisi-pod-non-templat>Akuisisi Pod Non-Templat</h2><p>Walaupun kamu bisa membuat Pod biasa tanpa masalah, sangat direkomendasikan untuk memastikan Pod tersebut tidak memiliki label yang sama dengan selektor dari salah satu ReplicaSet yang kamu miliki. Hal in disebabkan sebuah ReplicaSet tidak dibatasi untuk memilki Pod sesuai dengan templatnya -- ReplicaSet dapat mengakuisisi Pod lain dengan cara yang telah dijelaskan pada bagian sebelumnya.</p><p>Mengambil contoh ReplicaSet <em>frontend</em> sebelumnya, dan Pod yang ditentukan pada <em>manifest</em> berikut:</p><div class=highlight><div class=copy-code-icon style=text-align:right><a href=https://raw.githubusercontent.com/kubernetes/website/main/content/id/examples/pods/pod-rs.yaml download=pods/pod-rs.yaml><code>pods/pod-rs.yaml</code></a>
<img src=/images/copycode.svg style=max-height:24px;cursor:pointer onclick='copyCode("pods-pod-rs-yaml")' title="Copy pods/pod-rs.yaml to clipboard"></img></div><div class=includecode id=pods-pod-rs-yaml><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>pod1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>labels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>tier</span>:<span style=color:#bbb> </span>frontend<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>hello1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>gcr.io/google-samples/hello-app:2.0<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:#00f;font-weight:700>---</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>pod2<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>labels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>tier</span>:<span style=color:#bbb> </span>frontend<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>hello2<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>gcr.io/google-samples/hello-app:1.0<span style=color:#bbb>
</span></span></span></code></pre></div></div></div><p>Karena Pod tersebut tidak memiliki Controller (atau objek lain) sebagai referensi pemilik yang sesuai dengan selektor dari ReplicaSet <em>frontend</em>, Pod tersebut akan langsung diakuisisi oleh ReplicaSet.</p><p>Misalkan kamu membuat Pod tersebut setelah ReplicaSet <em>frontend</em> telah di-<em>deploy</em> dan telah mengkonfigurasi replika Pod awal untuk memenuhi kebutuhan jumlah replika:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl apply -f https://kubernetes.io/examples/pods/pod-rs.yaml
</span></span></code></pre></div><p>Pod baru akan diakuisisi oleh ReplicaSet, dan setelah itu langsung diterminasi ketika ReplicaSet melebihi jumlah yang diinginkan.</p><p>Memperoleh Pod:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get Pods
</span></span></code></pre></div><p>Keluaran menunjukkan bahwa Pod baru dalam keaadan telah diterminasi, atau sedang dalam proses terminasi:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>NAME             READY   STATUS        RESTARTS   AGE
</span></span><span style=display:flex><span>frontend-9si5l   1/1     Running       <span style=color:#666>0</span>          1m
</span></span><span style=display:flex><span>frontend-dnjpy   1/1     Running       <span style=color:#666>0</span>          1m
</span></span><span style=display:flex><span>frontend-qhloh   1/1     Running       <span style=color:#666>0</span>          1m
</span></span><span style=display:flex><span>pod2             0/1     Terminating   <span style=color:#666>0</span>          4s
</span></span></code></pre></div><p>Jika kamu membuat Pod terlebih dahulu:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl apply -f https://kubernetes.io/examples/pods/pod-rs.yaml
</span></span></code></pre></div><p>Dan selanjutnya membuat ReplicaSet maka:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl apply -f https://kubernetes.io/examples/controllers/frontend.yaml
</span></span></code></pre></div><p>Kamu akan melihat bahwa ReplicaSet telah mengakuisisi Pod dan hanya membuat Pod yang baru sesuai dengan <code>spec</code> yang ditentukan hingga jumlah dari Pod yang baru dan yang orisinil sesuai dengan jumlah yang diinginkan. Dengan memperoleh Pod:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get Pods
</span></span></code></pre></div><p>Akan diperlihatkan pada keluarannya:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>NAME             READY   STATUS    RESTARTS   AGE
</span></span><span style=display:flex><span>frontend-pxj4r   1/1     Running   <span style=color:#666>0</span>          5s
</span></span><span style=display:flex><span>pod1             1/1     Running   <span style=color:#666>0</span>          13s
</span></span><span style=display:flex><span>pod2             1/1     Running   <span style=color:#666>0</span>          13s
</span></span></code></pre></div><p>Dengan cara ini, sebuah ReplicaSet dapat memiliki himpunan berbagai Pod yang tidak homogen.</p><h2 id=menulis-manifest-replicaset>Menulis <em>manifest</em> ReplicaSet</h2><p>Seperti objek API Kubernetes lainnya, sebuah ReplicaSet membutuhkan <em>field</em> <code>apiVersion</code>, <code>kind</code>, dan <code>metadata</code>. Untuk ReplicaSet, nilai dari <code>kind</code> yang memungkinkan hanyalah ReplicaSet. Pada Kubernetes 1.9 versi API <code>apps/v1</code> pada <code>kind</code> ReplicaSet adalah versi saat ini dan diaktifkan secara <em>default</em>. Versi API <code>apps/v1beta2</code> telah dideprekasi. Lihat baris-baris awal pada contoh <code>frontend.yaml</code> untuk petunjuk.</p><p>Sebuah ReplicaSet juga membutuhkan <a href=https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#spec-and-status>bagian <code>.spec</code></a>.</p><h3 id=templat-pod>Templat Pod</h3><p><code>.spec.template</code> adalah sebuah <a href=/docs/concepts/workloads/Pods/pod-overview/#pod-templates>templat pod</a> yang juga dibutuhkan untuk mempunyai label. Pada contoh <code>frontend.yaml</code> kita memiliki satu label: <code>tier: frontend</code>.
Hati-hati agar tidak tumpang tindih dengan selektor dari <em>controller</em> lain, agar mereka tidak mencoba untuk mengadopsi Pod ini.</p><p>Untuk <em>field</em> <a href=/docs/concepts/workloads/Pods/pod-lifecycle/#restart-policy><em>restart policy</em></a> dari templat, <code>.spec.template.spec.restartPolicy</code>, nilai yang diperbolehkan hanyalah <code>Always</code>, yang merupakan nilai <em>default</em>.</p><h3 id=selektor-pod>Selektor Pod</h3><p><em>Field</em> <code>.spec.selector</code> adalah sebuah <a href=/id/docs/concepts/overview/working-with-objects/labels/>selektor labe</a>. Seperti yang telah dibahas <a href=#how-a-replicaset-works>sebelumnya</a>, <em>field</em> ini adalah label yang digunakan untuk mengidentifikasi Pod yang memungkinkan untuk diakuisisi. Pada contoh <code>frontend.yaml</code>, selektornya adalah:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>matchLabels:
</span></span><span style=display:flex><span>	tier: frontend
</span></span></code></pre></div><p>Pada ReplicaSet, <code>.spec.template.metadata.labels</code> harus memiliki nilai yang sama dengan <code>spec.selector</code>, atau akan ditolak oleh API.</p><div class="alert alert-info note callout" role=alert><strong>Catatan:</strong> Untuk 2 ReplicaSet dengan nilai <code>.spec.selector</code> yang sama tetapi memiliki nilai yang berbeda pada <em>field</em> <code>.spec.template.metadata.labels</code> dan <code>.spec.template.spec</code>, setiap ReplicaSet akan mengabaikan Pod yang dibuat oleh ReplicaSet lain.</div><h3 id=replika>Replika</h3><p>Kamu dapat menentukan jumlah Pod yang seharusnya berjalan secara konkuren dengan mengatur nilai dari <code>.spec.replicas</code>. ReplicaSet akan membuat/menghapus Pod-nya hingga jumlahnya sesuai dengan <em>field</em> ini.</p><p>Jika nilai <code>.spec.replicas</code> tidak ditentukan maka akan diatur ke nilai <em>default</em> 1.</p><h2 id=menggunakan-replicaset>Menggunakan ReplicaSet</h2><h3 id=menghapus-replicaset-dan-pod-nya>Menghapus ReplicaSet dan Pod-nya</h3><p>Untuk menghapus sebuah ReplicaSet beserta dengan Pod-nya, gunakan <a href=/docs/reference/generated/kubectl/kubectl-commands#delete><code>kubectl delete</code></a>. <a href=/id/docs/concepts/workloads/controllers/garbage-collection/><em>Garbage collector</em></a> secara otomatis akan menghapus semua Pod dependen secara <em>default</em>.</p><p>Ketika menggunakan REST API atau <em>library</em> <code>client-go</code>, kamu harus mengatur nilai <code>propagationPolicy</code> menjadi <code>Background</code> atau <code>Foreground</code> pada opsi -d.
Sebagai contoh:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl proxy --port<span style=color:#666>=</span><span style=color:#666>8080</span>
</span></span><span style=display:flex><span>curl -X DELETE  <span style=color:#b44>&#39;localhost:8080/apis/extensions/v1beta1/namespaces/default/replicasets/frontend&#39;</span> <span style=color:#b62;font-weight:700>\
</span></span></span><span style=display:flex><span><span style=color:#b62;font-weight:700></span>&gt; -d <span style=color:#b44>&#39;{&#34;kind&#34;:&#34;DeleteOptions&#34;,&#34;apiVersion&#34;:&#34;v1&#34;,&#34;propagationPolicy&#34;:&#34;Foreground&#34;}&#39;</span> <span style=color:#b62;font-weight:700>\
</span></span></span><span style=display:flex><span><span style=color:#b62;font-weight:700></span>&gt; -H <span style=color:#b44>&#34;Content-Type: application/json&#34;</span>
</span></span></code></pre></div><h3 id=menghapus-hanya-replicaset>Menghapus hanya ReplicaSet</h3><p>Kamu dapat menghapus ReplicaSet tanpa memengaruhi Pod-nya menggunakan <a href=/docs/reference/generated/kubectl/kubectl-commands#delete><code>kubectl delete</code></a> dengan menggunakan opsi <code>--cascade=false</code>.
Ketika menggunakan REST API atau <em>library</em> <code>client-go</code>, kamu harus mengatur nilai <code>propagationPolicy</code> menjadi <code>Orphan</code>.
Sebagai contoh:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl proxy --port<span style=color:#666>=</span><span style=color:#666>8080</span>
</span></span><span style=display:flex><span>curl -X DELETE  <span style=color:#b44>&#39;localhost:8080/apis/extensions/v1beta1/namespaces/default/replicasets/frontend&#39;</span> <span style=color:#b62;font-weight:700>\
</span></span></span><span style=display:flex><span><span style=color:#b62;font-weight:700></span>&gt; -d <span style=color:#b44>&#39;{&#34;kind&#34;:&#34;DeleteOptions&#34;,&#34;apiVersion&#34;:&#34;v1&#34;,&#34;propagationPolicy&#34;:&#34;Orphan&#34;}&#39;</span> <span style=color:#b62;font-weight:700>\
</span></span></span><span style=display:flex><span><span style=color:#b62;font-weight:700></span>&gt; -H <span style=color:#b44>&#34;Content-Type: application/json&#34;</span>
</span></span></code></pre></div><p>Ketika ReplicaSet yang asli telah dihapus, kamu dapat membuat ReplicaSet baru untuk menggantikannya. Selama <em>field</em> <code>.spec.selector</code> yang lama dan baru memilki nilai yang sama, maka ReplicaSet baru akan mengadopsi Pod lama namun tidak serta merta membuat Pod yang sudah ada sama dan sesuai dengan templat Pod yang baru.
Untuk memperbarui Pod dengan <em>spec</em> baru dapat menggunakan <a href=/id/docs/concepts/workloads/controllers/deployment/#creating-a-deployment>Deployment</a> karena ReplicaSet tidak mendukung pembaruan secara langsung.</p><h3 id=mengisolasi-pod-dari-replicaset>Mengisolasi Pod dari ReplicaSet</h3><p>Kamu dapat menghapus Pod dari ReplicaSet dengan mengubah nilai labelnya. Cara ini dapat digunakan untuk menghapus Pod dari servis untuk keperluan <em>debugging</em>, <em>data recovery</em>, dan lainnya. Pod yang dihapus dengan cara ini akan digantikan seecara otomatis (dengan asumsi jumlah replika juga tidak berubah).</p><h3 id=mengatur-jumlah-pod-pada-replicaset>Mengatur jumlah Pod pada ReplicaSet</h3><p>Jumlah Pod pada ReplicaSet dapat diatur dengan mengubah nilai dari <em>field</em> <code>.spec.replicas</code>. Pengatur ReplicaSet akan memastikan Pod dengan jumlah yang telah ditentukan dan dengan nilai selektor yang sama sedang dalam keadaan berjalan.</p><h3 id=pengaturan-jumlah-pod-pada-replicaset-menggunakan-horizontal-pod-autoscaler>Pengaturan jumlah Pod pada ReplicaSet menggunakan Horizontal Pod Autoscaler</h3><p>Pengaturan jumlah Pod pada ReplicaSet juga dapat dilakukan mengunakan <a href=/docs/tasks/run-application/horizontal-pod-autoscale/>Horizontal Pod Autoscalers (HPA)</a>. Berikut adalah contoh HPA terhadap ReplicaSet yang telah dibuat pada contoh sebelumnya.</p><div class=highlight><div class=copy-code-icon style=text-align:right><a href=https://raw.githubusercontent.com/kubernetes/website/main/content/id/examples/controllers/hpa-rs.yaml download=controllers/hpa-rs.yaml><code>controllers/hpa-rs.yaml</code></a>
<img src=/images/copycode.svg style=max-height:24px;cursor:pointer onclick='copyCode("controllers-hpa-rs-yaml")' title="Copy controllers/hpa-rs.yaml to clipboard"></img></div><div class=includecode id=controllers-hpa-rs-yaml><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>autoscaling/v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>HorizontalPodAutoscaler<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>frontend-scaler<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>scaleTargetRef</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>ReplicaSet<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>frontend<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>minReplicas</span>:<span style=color:#bbb> </span><span style=color:#666>3</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>maxReplicas</span>:<span style=color:#bbb> </span><span style=color:#666>10</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>targetCPUUtilizationPercentage</span>:<span style=color:#bbb> </span><span style=color:#666>50</span><span style=color:#bbb>
</span></span></span></code></pre></div></div></div><p>Menyimpan <em>manifest</em> ini dalam <code>hpa-rs.yaml</code> dan mengirimkannya ke klaster Kubernetes akan membuat HPA tersebut yang akan mengatur jumlah Pod pada ReplicaSet yang telah didefinisikan bergantung terhadap penggunaan CPU dari Pod yang direplikasi.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl apply -f https://k8s.io/examples/controllers/hpa-rs.yaml
</span></span></code></pre></div><p>Opsi lainnya adalah dengan menggunakan perintah <code>kubectl autoscale</code> untuk tujuan yang sama.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl autoscale rs frontend --max<span style=color:#666>=</span><span style=color:#666>10</span>
</span></span></code></pre></div><h2 id=alternatif-selain-replicaset>Alternatif selain ReplicaSet</h2><h3 id=deployment-direkomendasikan>Deployment (direkomendasikan)</h3><p><a href=/id/docs/concepts/workloads/controllers/deployment/><code>Deployment</code></a> adalah sebuah objek yang bisa memiliki ReplicaSet dan memperbarui ReplicaSet dan Pod-nya melalui <em>rolling update</em> deklaratif dan <em>server-side</em>.
Walaupun ReplicaSet dapat digunakan secara independen, seringkali ReplicaSet digunakan oleh Deployments sebagai mekanisme untuk mengorkestrasi pembuatan, penghapusan dan pembaruan Pod. Ketika kamu menggunakan Deployments kamu tidak perlu khawatir akan pengaturan dari ReplicaSet yang dibuat. Deployments memiliki dan mengatur ReplicaSet-nya sendiri.
Maka dari itu penggunaan Deployments direkomendasikan jika kamu menginginkan ReplicaSet.</p><h3 id=pod-sederhana>Pod sederhana</h3><p>Tidak seperti pada kasus ketika pengguna secara langsung membuat Pod, ReplicaSet akan menggantikan Pod yang dihapus atau diterminasi dengan alasan apapun, seperti pada kasus dimana terjadi kegagalan <em>node</em> atau pemeliharaan <em>node</em> yang disruptif, seperti pada kasus <em>upgrade</em> kernel. Karena alasan ini kami merekomendasikan kamu untuk menggunakan ReplicaSet walaupun jika aplikasimu membutuhkan hanya satu Pod. Hal ini mirip dengan pengawas proses, hanya saja pada kasus ini mengawasi banyak Pod pada berbagai <em>node</em> alih-alih berbagai proses individu pada sebuah <em>node</em>. ReplicaSet mendelegasikan proses pengulangan kembali dari kontainer lokal kepada agen yang terdapat di <em>node</em> (sebagai contoh, Kubelet atau Docker).</p><h3 id=job>Job</h3><p>Gunakan <a href=/docs/concepts/jobs/run-to-completion-finite-workloads/><code>Job</code></a> alih-alih ReplicaSet untuk Pod yang diharapkan untuk diterminasi secara sendirinya.</p><h3 id=daemonset>DaemonSet</h3><p>Gunakan <a href=/id/docs/concepts/workloads/controllers/daemonset/><code>DaemonSet</code></a> alih-alih ReplicaSet untuk Pod yang menyediakan fungsi pada level mesin, seperti <em>monitoring</em> mesin atau <em>logging</em> mesin. Pod ini memiliki waktu hidup yang bergantung terhadap waktu hidup mesin: Pod perlu untuk berjalan pada mesin sebelum Pod lain dijalankan, dan aman untuk diterminasi ketika mesin siap untuk di-<em>reboot</em> atau dimatikan.</p><h3 id=replicationcontroller>ReplicationController</h3><p>ReplicaSet adalah suksesor dari <a href=/id/docs/concepts/workloads/controllers/replicationcontroller/><em>ReplicationControllers</em></a>. Keduanya memenuhi tujuan yang sama dan memiliki perilaku yang serupa, kecuali bahwa ReplicationController tidak mendukung kebutuhan selektor <em>set-based</em> seperti yang dijelaskan pada <a href=/id/docs/concepts/overview/working-with-objects/labels/#label-selectors>panduan penggunaan label</a>. Pada kasus tersebut, ReplicaSet lebih direkomendasikan dibandingkan ReplicationController.</p></div><div class=td-content style=page-break-before:always><h1 id=pg-27f1331d515d95f76aa1156088b4ad91>2.2 - ReplicationController</h1><div class="alert alert-info note callout" role=alert><strong>Catatan:</strong> <a href=/id/docs/concepts/workloads/controllers/deployment/><code>Deployment</code></a> yang mengonfigurasi <a href=/id/docs/concepts/workloads/controllers/replicaset/><code>ReplicaSet</code></a> sekarang menjadi cara yang direkomendasikan untuk melakukan replikasi.</div><p>Sebuah <em>ReplicationController</em> memastikan bahwa terdapat sejumlah Pod yang sedang berjalan dalam suatu waktu tertentu. Dengan kata lain, ReplicationController memastikan bahwa sebuah Pod atau sebuah kumpulan Pod yang homogen selalu berjalan dan tersedia.</p><h2 id=bagaimana-replicationcontroller-bekerja>Bagaimana ReplicationController Bekerja</h2><p>Jika terdapat terlalu banyak Pod, maka ReplicationController akan membatasi dan mematikan Pod-Pod yang berlebih. Jika terdapat terlalu sedikit, maka ReplicationController akan memulai dan menjalankan Pod-Pod baru lainnya. Tidak seperti Pod yang dibuat secara manual, Pod-Pod yang diatur oleh sebuah ReplicationController akan secara otomatis diganti jika mereka gagal, dihapus, ataupun dimatikan.
Sebagai contoh, Pod-Pod yang kamu miliki akan dibuat ulang dalam sebuah Node setelah terjadi proses pemeliharaan seperti pembaruan kernel. Untuk alasan ini, maka kamu sebaiknya memiliki sebuah ReplicationController bahkan ketika aplikasimu hanya membutuhkan satu buah Pod saja. Sebuah ReplicationController memiliki kemiripan dengan sebuah pengawas proses, tetapi alih-alih mengawasi sebuah proses individu pada sebuah Node, ReplicationController banyak Pod yang terdapat pada beberapa Node.</p><p>ReplicationController seringkali disingkat sebagai "rc" dalam diskusi, dan sebagai <em>shortcut</em> dalam perintah kubectl.</p><p>Sebuah contoh sederhana adalah membuat sebuah objek ReplicationController untuk menjalankan sebuah <em>instance</em> Pod secara berkelanjutan. Contoh pemakaian lainnya adalah untuk menjalankan beberapa replika identik dari sebuah servis yang direplikasi, seperti peladen web.</p><h2 id=menjalankan-sebuah-contoh-replicationcontroller>Menjalankan Sebuah Contoh ReplicationController</h2><p>Contoh ReplicationController ini mengonfigurasi tiga salinan dari peladen web nginx.</p><div class=highlight><div class=copy-code-icon style=text-align:right><a href=https://raw.githubusercontent.com/kubernetes/website/main/content/id/examples/controllers/replication.yaml download=controllers/replication.yaml><code>controllers/replication.yaml</code></a>
<img src=/images/copycode.svg style=max-height:24px;cursor:pointer onclick='copyCode("controllers-replication-yaml")' title="Copy controllers/replication.yaml to clipboard"></img></div><div class=includecode id=controllers-replication-yaml><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>ReplicationController<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>nginx<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>replicas</span>:<span style=color:#bbb> </span><span style=color:#666>3</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>selector</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>app</span>:<span style=color:#bbb> </span>nginx<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>template</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>nginx<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>labels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>app</span>:<span style=color:#bbb> </span>nginx<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>nginx<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>nginx<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>ports</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span>- <span style=color:green;font-weight:700>containerPort</span>:<span style=color:#bbb> </span><span style=color:#666>80</span></span></span></code></pre></div></div></div><p>Jalankan contoh di atas dengan mengunduh berkas contoh dan menjalankan perintah ini:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl apply -f https://k8s.io/examples/controllers/replication.yaml
</span></span></code></pre></div><pre tabindex=0><code>replicationcontroller/nginx created
</code></pre><p>Periksa status dari ReplicationController menggunakan perintah ini:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl describe replicationcontrollers/nginx
</span></span></code></pre></div><pre tabindex=0><code>Name:        nginx
Namespace:   default
Selector:    app=nginx
Labels:      app=nginx
Annotations:    &lt;none&gt;
Replicas:    3 current / 3 desired
Pods Status: 0 Running / 3 Waiting / 0 Succeeded / 0 Failed
Pod Template:
  Labels:       app=nginx
  Containers:
   nginx:
    Image:              nginx
    Port:               80/TCP
    Environment:        &lt;none&gt;
    Mounts:             &lt;none&gt;
  Volumes:              &lt;none&gt;
Events:
  FirstSeen       LastSeen     Count    From                        SubobjectPath    Type      Reason              Message
  ---------       --------     -----    ----                        -------------    ----      ------              -------
  20s             20s          1        {replication-controller }                    Normal    SuccessfulCreate    Created pod: nginx-qrm3m
  20s             20s          1        {replication-controller }                    Normal    SuccessfulCreate    Created pod: nginx-3ntk0
  20s             20s          1        {replication-controller }                    Normal    SuccessfulCreate    Created pod: nginx-4ok8v
</code></pre><p>Tiga Pod telah dibuat namun belum ada yang berjalan, kemungkinan karena <em>image</em> yang sedang di-<em>pull</em>.
Beberapa waktu kemudian, perintah yang sama akan menunjukkan:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>Pods Status:    <span style=color:#666>3</span> Running / <span style=color:#666>0</span> Waiting / <span style=color:#666>0</span> Succeeded / <span style=color:#666>0</span> Failed
</span></span></code></pre></div><p>Untuk melihat semua Pod yang dibuat oleh ReplicationController dalam bentuk yang lebih mudah dibaca mesin, kamu dapat menggunakan perintah seperti ini:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span><span style=color:#b8860b>pods</span><span style=color:#666>=</span><span style=color:#a2f;font-weight:700>$(</span>kubectl get pods --selector<span style=color:#666>=</span><span style=color:#b8860b>app</span><span style=color:#666>=</span>nginx --output<span style=color:#666>=</span><span style=color:#b8860b>jsonpath</span><span style=color:#666>={</span>.items..metadata.name<span style=color:#666>}</span><span style=color:#a2f;font-weight:700>)</span>
</span></span><span style=display:flex><span><span style=color:#a2f>echo</span> <span style=color:#b8860b>$pods</span>
</span></span></code></pre></div><pre tabindex=0><code>nginx-3ntk0 nginx-4ok8v nginx-qrm3m
</code></pre><p>Pada perintah di atas, selektor yang dimaksud adalah selektor yang sama dengan yang terdapat pada ReplicationController (yang dapat dilihat pada keluaran <code>kubectl describe</code>), dan dalam bentuk yang berbeda dengan yang terdapat pada <code>replication.yaml</code>. Opsi <code>--output=jsonpath</code> menentukan perintah untuh mendapatkan hanya nama dari setiap Pod yang ada pada daftar hasil.</p><h2 id=menulis-spesifikasi-replicationcontroller>Menulis Spesifikasi ReplicationController</h2><p>Seperti semua konfigurasi Kubernetes lainnya, sebuah ReplicationController membutuhkan <em>field</em> <code>apiVersion</code>, <code>kind</code>, dan <code>metadata</code>.</p><p>Untuk informasi umum mengenai berkas konfigurasi, kamu dapat melihat <a href=/id/docs/concepts/overview/working-with-objects/object-management/>pengaturan objek</a>.</p><p>Sebuah ReplicationController juga membutuhkan <a href=https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#spec-and-status>bagian <code>.spec</code></a>.</p><h3 id=templat-pod>Templat Pod</h3><p><code>.spec.template</code> adalah satu-satunya <em>field</em> yang diwajibkan pada <code>.spec</code>.</p><p><code>.spec.template</code> adalah sebuah <a href=/id/docs/concepts/workloads/pods/pod-overview/#pod-templates>templat Pod</a>. Ia memiliki skema yang sama persis dengan sebuah <a href=/id/docs/concepts/workloads/pods/pod/>Pod</a>, namun dapat berbentuk <em>nested</em> dan tidak memiliki <em>field</em> <code>apiVersion</code> ataupun <code>kind</code>.</p><p>Selain <em>field-field</em> yang diwajibkan untuk sebuah Pod, templat Pod pada ReplicationController harus menentukan label dan kebijakan pengulangan kembali yang tepat. Untuk label, pastikan untuk tidak tumpang tindih dengan kontroler lain. Lihat <a href=#selektor-pod>selektor pod</a>.</p><p>Nilai yang diperbolehkan untuk <a href=/id/docs/concepts/workloads/pods/pod-lifecycle/#restart-policy><code>.spec.template.spec.restartPolicy</code></a> hanyalah <code>Always</code>, yaitu nilai bawaan jika tidak ditentukan.</p><p>Untuk pengulangan kembali dari sebuah kontainer lokal, ReplicationController mendelegasikannya ke agen pada Node, contohnya <a href=/docs/admin/kubelet/>Kubelet</a> atau Docker.</p><h3 id=label-pada-replicationcontroller>Label pada ReplicationController</h3><p>ReplicationController itu sendiri dapat memiliki label (<code>.metadata.labels</code>). Biasanya, kamu akan mengaturnya untuk memiliki nilai yang sama dengan <code>.spec.template.metadata.labels</code>; jika <code>.metadata.labels</code> tidak ditentukan maka akan menggunakan nilai bawaan yaitu <code>.spec.template.metadata.labels</code>. Namun begitu, kedua label ini diperbolehkan untuk memiliki nilai yang berbeda, dan <code>.metadata.labels</code> tidak akan memengaruhi perilaku dari ReplicationController.</p><h3 id=selektor-pod>Selektor Pod</h3><p><em>Field</em> <code>.spec.selector</code> adalah sebuah <a href=/id/docs/concepts/overview/working-with-objects/labels/#label-selectors>selektor label</a>. Sebuah ReplicationController mengatur semua Pod dengan label yang sesuai dengan nilai selektor tersebut. Ia tidak membedakan antara Pod yang ia buat atau hapus atau Pod yang dibuat atau dihapus oleh orang atau proses lain. Hal ini memungkinkan ReplicationController untuk digantikan tanpa memengaruhi Pod-Pod yang sedang berjalan.</p><p>Jika ditentukan, <code>.spec.template.metadata.labels</code> harus memiliki nilai yang sama dengan <code>.spec.selector</code>, atau akan ditolak oleh API. Jika <code>.spec.selector</code> tidak ditentukan, maka akan menggunakan nilai bawaan yaitu <code>.spec.template.metadata.labels</code>.</p><p>Selain itu, kamu juga sebaiknya tidak membuat Pod dengan label yang cocok dengan selektor ini, baik secara langsung, dengan menggunakan ReplicationController lain, ataupun menggunakan kontroler lain seperti Job. Jika kamu melakukannya, ReplicationController akan menganggap bahwa ia telah membuat Pod-Pod lainnya. Kubernetes tidak akan menghentikan kamu untuk melakukan aksi ini.</p><p>Jika kamu pada akhirnya memiliki beberapa kontroler dengan selektor-selektor yang tumpang tindih, kamu harus mengatur penghapusannya sendiri (lihat <a href=#bekerja-dengan-replicationcontroller>di bawah</a>).</p><h3 id=beberapa-replika>Beberapa Replika</h3><p>Kamu dapat menentukan jumlah Pod yang seharusnya berjalan secara bersamaan dengan mengatur nilai <code>.spec.replicas</code> dengan jumlah Pod yang kamu inginkan untuk berjalan secara bersamaan. Jumlah yang berjalan dalam satu satuan waktu dapat lebih tinggi ataupun lebih rendah, seperti jika replika-replika tersebut melewati proses penambahan atau pengurangan, atau jika sebuah Pod melalui proses <em>graceful shutdown</em>, dan penggantinya telah dijalankan terlebih dahulu.</p><p>Jika kamu tidak menentukan nilai dari <code>.spec.replicas</code>, maka akan digunakan nilai bawaan 1.</p><h2 id=bekerja-dengan-replicationcontroller>Bekerja dengan ReplicationController</h2><h3 id=menghapus-sebuah-replicationcontroller-dan-pod-nya>Menghapus Sebuah ReplicationController dan Pod-nya</h3><p>Untuk menghapus sebuah ReplicationController dan Pod-Pod yang berhubungan dengannya, gunakan perintah <a href=/docs/reference/generated/kubectl/kubectl-commands#delete><code>kubectl delete</code></a>. Kubectl akan mengatur ReplicationController ke nol dan menunggunya untuk menghapus setiap Pod sebelum menghapus ReplicationController itu sendiri. Jika perintah kubectl ini terhenti, maka dapat diulang kembali.</p><p>Ketika menggunakan REST API atau <em>library</em> klien go, maka kamu perlu melakukan langkah-langkahnya secara eksplisit (mengatur replika-replika ke 0, menunggu penghapusan Pod, dan barulah menghapus ReplicationController).</p><h3 id=menghapus-hanya-replicationcontroller>Menghapus Hanya ReplicationController</h3><p>Kamu dapat menghapus ReplicationController tanpa memengaruhi Pod-Pod yang berhubungan dengannya.</p><p>Dengan menggunakan kubectl, tentukan opsi <code>--cascade=false</code> ke <a href=/docs/reference/generDeated/kubectl/kubectl-commands#delete><code>kubectl delete</code></a>.</p><p>Ketika menggunakan REST API atau <em>library</em> klien go, cukup hapus objek ReplicationController.</p><p>Ketika ReplicationController yang asli telah dihapus, kamu dapat membuat ReplicationController yang baru sebagai penggantinya. Selama <code>.spec.selector</code> yang lama dan baru memiliki nilai yang sama, maka ReplicationController baru akan mengadopsi Pod-Pod yang lama.
Walaupun begitu, ia tidak akan melakukan usaha apapun untuk membuat Pod-Pod yang telah ada sebelumnya untuk sesuai dengan templat Pod yang baru dan berbeda.
Untuk memperbarui Pod-Pod ke spesifikasi yang baru dengan cara yang terkontrol, gunakan <a href=#pembaruan-bergulir>pembaruan bergulir</a>.</p><h3 id=mengisolasi-pod-dari-replicationcontroller>Mengisolasi Pod dari ReplicationController</h3><p>Pod-Pod dapat dihapus dari kumpulan target sebuah ReplicationController dengan mengganti nilai dari labelnya. Teknik ini dapat digunakan untuk mencopot Pod-Pod dari servis untuk keperluan pengawakutuan (<em>debugging</em>), pemulihan data, dan lainnya. Pod-Pod yang dicopot dengan cara ini dapat digantikan secara otomatis (dengan asumsi bahwa jumlah replika juga tidak berubah).</p><h2 id=pola-penggunaan-umum>Pola penggunaan umum</h2><h3 id=penjadwalan-ulang>Penjadwalan ulang</h3><p>Seperti yang telah disebutkan sebelumnya, baik kamu memiliki hanya 1 Pod untuk tetap dijalankan, ataupun 1000, ReplicationController akan memastikan tersedianya jumlah Pod yang telat ditentukan, bahkan ketika terjadi kegagalan Node atau terminasi Pod (sebagai contoh karena adanya tindakan dari agen kontrol lain).</p><h3 id=penskalaan>Penskalaan</h3><p>ReplicationController memudahkan penskalaan jumlah replika, baik meningkatkan ataupun mengurangi, secara manual ataupun dengan agen kontrol penskalaan otomatis, dengan hanya mengubah nilai dari <em>field</em> <code>replicas</code>.</p><h3 id=pembaruan-bergulir>Pembaruan bergulir</h3><p>ReplicationController didesain untuk memfasilitasi pembaruan bergulir untuk sebuah servis dengan mengganti Pod-Pod satu per satu.</p><p>Seperti yang telah dijelaskan di <a href=http://issue.k8s.io/1353>#1353</a>, pendekatan yang direkomendasikan adalah dengan membuat ReplicationController baru dengan 1 replika, skala kontroler yang baru (+1) atau yang lama (-1) satu per satu, dan kemudian hapus kontroler lama setelah menyentuh angka 0 replika. Hal ini memungkinkan pembaruan dilakukan dengan dapat diprediksi terlepas dari adanya kegagalan yang tak terduga.</p><p>Idealnya, kontroler pembaruan bergulir akan memperhitungkan kesiapan dari aplikasi, dan memastikan cukupnya jumlah Pod yang secara produktif meladen kapanpun.</p><p>Dua ReplicationController diharuskan untuk memiliki setidaknya satu label yang berbeda, seperti <em>tag</em> <em>image</em> dari kontainer utama dari Pod, karena pembaruan bergulir biasanya dilakukan karena adanya pembaruan <em>image</em>.</p><p>Pembaruan bergulir diimplementasikan pada perkakas klien <a href=/docs/reference/generated/kubectl/kubectl-commands#rolling-update><code>kubectl rolling-update</code></a>. Lihat <a href=/docs/tasks/run-application/rolling-update-replication-controller/><code>kubectl rolling-update</code> task</a> untuk contoh-contoh yang lebih konkrit.</p><h3 id=operasi-rilis-majemuk>Operasi rilis majemuk</h3><p>Selain menjalankan beberapa rilis dari sebuah aplikasi ketika proses pembaruan bergulir sedang berjalan, adalah hal yang awam untuk menjalankan beberapa rilis untuk suatu periode waktu tertentu, atau bahkan secara kontinu, menggunakan operasi rilis majemuk. Operasi-operasi ini akan dibedakan menggunakan label.</p><p>Sebagai contoh, sebuah servis dapat menyasar semua Pod dengan <code>tier in (frontend), environment in (prod)</code>. Anggap kamu memiliki 10 Pod tiruan yang membangun <em>tier</em> ini tetapi kamu ingin bisa menggunakan 'canary' terhadap versi baru dari komponen ini. Kamu dapat mengatur sebuah ReplicationController dengan nilai <code>replicas</code> 9 untuk replika-replikanya, dengan label <code>tier=frontend, environment=prod, track=stable</code>, dan ReplicationController lainnya dengan nilai <code>replicas</code> 1 untuk canary, dengan label <code>tier=frontend, environment=prod, track=canary</code>. Sekarang servis sudah mencakup baik canary maupun Pod-Pod yang bukan canary. Kamu juga dapat mencoba-coba ReplicationController secara terpisah untuk melakukan pengujian, mengamati hasilnya, dan lainnya.</p><h3 id=menggunakan-replicationcontroller-dengan-service>Menggunakan ReplicationController dengan Service</h3><p>Beberapa ReplicationController dapat berada di belakang sebuah Service, sedemikian sehingga, sebagai contoh, sebagian <em>traffic</em> dapat ditujukan ke versi lama, dan sebagian lainnya ke versi yang baru.</p><p>Sebuah ReplicationController tidak akan berhenti dengan sendirinya, namun ia tidak diekspektasikan untuk berjalan selama Service-Service yang ada. Service dapat terdiri dari berbagai Pod yang dikontrol beberapa ReplicationController, dan terdapat kemungkinan bahwa beberapa ReplicationController untuk dibuat dan dimatikan dalam jangka waktu hidup Service (contohnya adalah untuk melakukan pembaruan Pod-Pod yang menjalankan Service). Baik Service itu sendiri dan kliennya harus tetap dalam keadaan tidak mempunyai pengetahuan terhadap ReplicationController yang memelihara Pod-Pod dari Service tersebut.</p><h2 id=menulis-program-untuk-replikasi>Menulis program untuk Replikasi</h2><p>Pod-Pod yang dibuat oleh ReplicationController ditujukan untuk dapat sepadan dan memiliki semantik yang identik, walaupun konfigurasi mereka dapat berbeda seiring keberjalanan waktunya. Ini adalah contoh yang cocok untuk peladen <em>stateless</em>, namun ReplicationController juga dapat digunakan untuk memelihara ketersediaan dari aplikasi-aplikasi yang <em>master-elected</em>, <em>sharded</em>, <em>worker-pool</em>. Aplikasi-aplikasi seperti itu sebaiknya menggunakan mekanisme penetapan kerja yang dinamis, seperti <a href=https://www.rabbitmq.com/tutorials/tutorial-two-python.html>antrian kerja RabbitMQ</a>, berlainan dengan pengubahan statis/satu kali dari konfigurasi setiap Pod, yang dipandang sebagai sebuah <em>anti-pattern</em>. Pengubahan apapun yang dilakukan terhadap Pod, seperti <em>auto-sizing</em> vertikal dari sumber daya (misalnya cpu atau memori), sebaiknya dilakukan oleh proses kontroller luring lainnya, dan bukan oleh ReplicationController itu sendiri.</p><h2 id=tanggung-jawab-replicationcontroller>Tanggung Jawab ReplicationController</h2><p>ReplicationController hanya memastikan ketersediaan dari sejumlah Pod yang cocok dengan selektor label dan berjalan dengan baik. Saat ini, hanya Pod yang diterminasi yang dijadikan pengecualian dari penghitungan. Kedepannya, <a href=http://issue.k8s.io/620>kesiapan</a> dan informasi yang ada lainnya dari sistem dapat menjadi pertimbangan, kami dapat meningkatkan kontrol terhadap kebijakan penggantian, dan kami berencana untuk menginformasikan kejadian (<em>event</em>) yang dapat digunakan klien eksternal untuk implementasi penggantian yang sesuai dan/atau kebijakan pengurangan.</p><p>ReplicationController akan selalu dibatasi terhadap tanggung jawab spesifik ini. Ia tidak akan melakukan <em>probe</em> kesiapan atau keaktifan. Daripada melakukan <em>auto-scaling</em>, ia ditujukan untuk dikontrol oleh <em>auto-scaler</em> eksternal (seperti yang didiskusikan pada <a href=http://issue.k8s.io/492>#492</a>), yang akan mengganti <em>field</em> <code>replicas</code>. Kami tidak akan menambahkan kebijakan penjadwalan (contohnya <a href=http://issue.k8s.io/367#issuecomment-48428019><em>spreading</em></a>) untuk ReplicationController. Ia juga tidak seharusnya melakukan verifikasi terhadap Pod-Pod yang sedang dikontrol yang cocok dengan spesifikasi templat saat ini, karena hal itu dapat menghambat <em>auto-sizing</em> dan proses otomatis lainnya. Demikian pula batas waktu penyelesaian, pengurutan <em>dependencies</em>, ekspansi konfigurasi, dan fitur-fitur lain yang seharusnya berada di komponen lain. Kami juga bahkan berencana untuk mengeluarkan mekanisme pembuatan Pod secara serentak (<a href=http://issue.k8s.io/170>#170</a>).</p><p>ReplicationController ditujukan untuk menjadi primitif komponen yang dapat dibangun untuk berbagai kebutuhan. Kami menargetkan API dengan tingkatan yang lebih tinggi dan/atau perkakas-perkakas untuk dibangun di atasnya dan primitif tambahan lainnya untuk kenyamanan pengguna kedepannya. Operasi-operasi makro yang sudah didukung oleh kubectl (<em>run</em>, <em>scale</em>, <em>rolling-update</em>) adalah contoh <em>proof-of-concept</em> dari konsep ini. Sebagai contohnya, kita dapat menganggap sesuatu seperti <a href=http://techblog.netflix.com/2012/06/asgard-web-based-cloud-management-and.html>Asgard</a> yang mengatur beberapa ReplicationController, <em>auto-scaler</em>, servis, kebijakan penjadwalan, canary, dan yang lainnya.</p><h2 id=objek-api>Objek API</h2><p>ReplicationController adalah sebuah sumber daya <em>top-level</em> pada REST API Kubernetes. Detil dari objek API dapat ditemukan di: <a href=/docs/reference/generated/kubernetes-api/v1.25/#replicationcontroller-v1-core>objek API ReplicationController</a>.</p><h2 id=alternatif-untuk-replicationcontroller>Alternatif untuk ReplicationController</h2><h3 id=replicaset>ReplicaSet</h3><p><a href=/id/docs/concepts/workloads/controllers/replicaset/><code>ReplicaSet</code></a> adalah kelanjutan dari ReplicationController yang mendukung selektor <a href=/id/docs/concepts/overview/working-with-objects/labels/#set-based-requirement>selektor label <em>set-based</em></a> yang baru. Umumnya digunakan oleh <a href=/id/docs/concepts/workloads/controllers/deployment/><code>Deployment</code></a> sebagai mekanisme untuk mengorkestrasi pembuatan, penghapusan, dan pembaruan Pod.
Perhatikan bahwa kami merekomendasikan untuk menggunakan Deployment sebagai ganti dari menggunakan ReplicaSet secara langsung, kecuali jika kamu membutuhkan orkestrasi pembaruan khusus atau tidak membutuhkan pembaruan sama sekali.</p><h3 id=deployment-direkomendasikan>Deployment (Direkomendasikan)</h3><p><a href=/id/docs/concepts/workloads/controllers/deployment/><code>Deployment</code></a> adalah objek API tingkat tinggi yang memperbarui ReplicaSet dan Pod-Pod di bawahnya yang mirip dengan cara kerja <code>kubectl rolling-update</code>. Deployment direkomendasikan jika kamu menginginkan fungsionalitas dari pembaruan bergulir ini, karena tidak seperti <code>kubectl rolling-update</code>, Deployment memiliki sifat deklaratif, <em>server-side</em>, dan memiliki beberapa fitur tambahan lainnya.</p><h3 id=pod-sederhana>Pod sederhana</h3><p>Tidak seperti pada kasus ketika pengguna secara langsung membuat Pod, ReplicationController menggantikan Pod-Pod yang dihapus atau dimatikan untuk alasan apapun, seperti pada kasus kegagalan Node atau pemeliharaan Node yang disruptif, seperti pembaruan kernel. Untuk alasan ini, kami merekomendasikan kamu untuk menggunakan ReplicationController bahkan ketika aplikasimu hanya membutuhkan satu Pod saja. Anggap hal ini mirip dengan pengawas proses, hanya pada kasus ini mengawasi banyak Pod yang terdapat pada berbagai Node dan bukan proses-proses tunggal pada satu Node. ReplicationController mendelegasikan pengulangan kontainer lokal ke agen yang terdapat dalam Node (contohnya Kubelet atau Docker).</p><h3 id=job>Job</h3><p>Gunakan <a href=/docs/concepts/jobs/run-to-completion-finite-workloads/><code>Job</code></a> sebagai ganti ReplicationController untuk Pod-Pod yang diharapkan diterminasi dengan sendirinya (seperti <em>batch jobs</em>).</p><h3 id=daemonset>DaemonSet</h3><p>Gunakan <a href=/id/docs/concepts/workloads/controllers/daemonset/><code>DaemonSet</code></a> sebagai ganti ReplicationController untuk Pod-Pod yang menyediakan fungsi pada level mesin, seperti pengamatan mesin atau pencatatan mesin. Pod-Pod ini memiliki waktu hidup yang bergantung dengan waktu hidup mesin: Pod butuh untuk dijalankan di mesin sebelum Pod-Pod lainnya dimulai, dan aman untuk diterminasi ketika mesin sudah siap untuk dinyalakan ulang atau dimatikan.</p><h2 id=informasi-lanjutan>Informasi lanjutan</h2><p>Baca <a href=/docs/tutorials/stateless-application/run-stateless-ap-replication-controller/>Menjalankan Kontroler Replikasi AP <em>Stateless</em></a>.</p></div><div class=td-content style=page-break-before:always><h1 id=pg-a2dc0393e0c4079e1c504b6429844e86>2.3 - Deployment</h1><p>Deployment menyediakan pembaruan <a href=/id/docs/concepts/workloads/pods/pod/>Pods</a> dan
<a href=/id/docs/concepts/workloads/controllers/replicaset/>ReplicaSets</a> secara deklaratif.</p><p>Kamu mendeskripsikan sebuah state yang diinginkan dalam Deployment, kemudian Deployment <a class=glossary-tooltip title='Kontrol tertutup yang mengawasi kondisi bersama dari klaster melalui apiserver dan membuat perubahan yang mencoba untuk membawa kondisi saat ini ke kondisi yang diinginkan.' data-toggle=tooltip data-placement=top href=/id/docs/concepts/architecture/controller/ target=_blank aria-label=Pengontrol>Pengontrol</a> mengubah state sekarang menjadi seperti pada deskripsi secara bertahap. Kamu dapat mendefinisikan Deployment untuk membuat ReplicaSets baru atau untuk menghapus Deployment yang sudah ada dan mengadopsi semua resourcenya untuk Deployment baru.</p><div class="alert alert-info note callout" role=alert><strong>Catatan:</strong> Jangan mengganti ReplicaSets milik Deployment. Pertimbangkan untuk membuat isu pada repositori utama Kubernetes jika kasusmu tidak diatasi semua kasus di bawah.</div><h2 id=penggunaan>Penggunaan</h2><p>Berikut adalah penggunaan yang umum pada Deployment:</p><ul><li><a href=#membuat-deployment>Membuat Deployment untuk merilis ReplicaSet</a>. ReplicaSet membuat Pod di belakang layar. Cek status rilis untuk tahu proses rilis sukses atau tidak.</li><li><a href=#membarui-deployment>Mendeklarasikan state baru dari Pods</a> dengan membarui PodTemplateSpec milik Deployment. ReplicaSet baru akan dibuat dan Deployment mengatur perpindahan Pod secara teratur dari ReplicaSet lama ke ReplicaSet baru. Tiap ReplicaSet baru akan mengganti revisi Deployment.</li><li><a href=#membalikkan-deployment>Mengembalikan ke revisi Deployment sebelumnya</a> jika state Deployment sekarang tidak stabil. Tiap pengembalian mengganti revisi Deployment.</li><li><a href=#mengatur-skala-deployment>Memperbesar Deployment untuk memfasilitasi beban yang lebih</a>.</li><li><a href=#menjeda-dan-melanjutkan-deployment>Menjeda Deployment</a> untuk menerapkan perbaikan pada PodTemplateSpec-nya, lalu melanjutkan untuk memulai rilis baru.</li><li><a href=#status-deployment>Memakai status Deployment</a> sebagai indikator ketika rilis tersendat.</li><li><a href=#kebijakan-pembersihan>Membersihkan ReplicaSet lama</a> yang sudah tidak terpakai.</li></ul><h2 id=membuat-deployment>Membuat Deployment</h2><p>Berikut adalah contoh Deployment. Dia membuat ReplicaSet untuk membangkitkan tiga Pod <code>nginx</code>:</p><div class=highlight><div class=copy-code-icon style=text-align:right><a href=https://raw.githubusercontent.com/kubernetes/website/main/content/id/examples/controllers/nginx-deployment.yaml download=controllers/nginx-deployment.yaml><code>controllers/nginx-deployment.yaml</code></a>
<img src=/images/copycode.svg style=max-height:24px;cursor:pointer onclick='copyCode("controllers-nginx-deployment-yaml")' title="Copy controllers/nginx-deployment.yaml to clipboard"></img></div><div class=includecode id=controllers-nginx-deployment-yaml><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>apps/v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Deployment<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>nginx-deployment<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>labels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>app</span>:<span style=color:#bbb> </span>nginx<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>replicas</span>:<span style=color:#bbb> </span><span style=color:#666>3</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>selector</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>matchLabels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>app</span>:<span style=color:#bbb> </span>nginx<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>template</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>labels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>app</span>:<span style=color:#bbb> </span>nginx<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>nginx<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>nginx:1.7.9<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>ports</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span>- <span style=color:green;font-weight:700>containerPort</span>:<span style=color:#bbb> </span><span style=color:#666>80</span><span style=color:#bbb>
</span></span></span></code></pre></div></div></div><p>Dalam contoh ini:</p><ul><li><p>Deployment baru akan dibuat dengan nama <code>nginx-deployment</code>, tertulis pada kolom <code>.metadata.name</code>.</p></li><li><p>Deployment membuat tiga Pod yang direplikasi, ditandai dengan kolom <code>replicas</code>.</p></li><li><p>Kolom <code>selector</code> mendefinisikan bagaimana Deployment menemukan Pod yang diatur.
Dalam kasus ini, kamu hanya perlu memilih sebuah label yang didefinisikan pada templat Pod (<code>app: nginx</code>).
Namun, aturan pemilihan yang lebih canggih mungkin dilakukan asal templat Pod-nya memenuhi aturan.<div class="alert alert-info note callout" role=alert><strong>Catatan:</strong> Kolom <code>matchLabels</code> berbentuk pasangan {key,value}. Sebuah {key,value} dalam <em>map</em> <code>matchLabels</code> ekuivalen dengan
elemen pada <code>matchExpressions</code>, yang mana kolom key adalah "key", operator adalah "In", dan larik values hanya berisi "value".
Semua prasyarat dari <code>matchLabels</code> maupun <code>matchExpressions</code> harus dipenuhi agar dapat dicocokkan.</div></p></li><li><p>Kolom <code>template</code> berisi sub kolom berikut:</p><ul><li>Pod dilabeli <code>app: nginx</code> dengan kolom <code>labels</code>.</li><li>Spesifikasi templat Pod atau kolom <code>.template.spec</code> menandakan bahwa Pod mennjalankan satu kontainer <code>nginx</code>,
yang menjalankan image <code>nginx</code> <a href=https://hub.docker.com/>Docker Hub</a> dengan versi 1.7.9.</li><li>Membuat satu kontainer bernama <code>nginx</code> sesuai kolom <code>name</code>.</li></ul><p>Ikuti langkah-langkah berikut untuk membuat Deployment di atas:</p><p>Sebelum memulai, pastikan klaster Kubernetes sedang menyala dan bekerja.</p><ol><li><p>Buat Deployment dengan menjalankan perintah berikut:</p><div class="alert alert-info note callout" role=alert><strong>Catatan:</strong> Kamu dapat menambahkan argument <code>--record</code> untuk menulis perintah yang dijalankan pada anotasi sumber daya <code>kubernetes.io/change-cause</code>. Ini berguna untuk pemeriksaan di masa depan.
Contohnya yaitu untuk melihat perintah yang dijalankan pada tiap revisi Deployment.</div></li></ol><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl apply -f https://k8s.io/examples/controllers/nginx-deployment.yaml
</span></span></code></pre></div><ol start=2><li>Jalankan <code>kubectl get deployments</code> untuk mengecek apakah Deployment telah dibuat. Jika Deployment masih sedang pembuatan, keluaran akan tampil seperti berikut:</li></ol><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>NAME               DESIRED   CURRENT   UP-TO-DATE   AVAILABLE   AGE
</span></span><span style=display:flex><span>nginx-deployment   <span style=color:#666>3</span>         <span style=color:#666>0</span>         <span style=color:#666>0</span>            <span style=color:#666>0</span>           1s
</span></span></code></pre></div><p>Ketika kamu memeriksa Deployments pada klastermu, kolom berikut akan tampil:</p><pre><code>* `NAME` menampilkan daftar nama Deployment pada klaster.
* `DESIRED` menampilkan jumlah replika aplikasi yang diinginkan sesuai yang didefinisikan saat pembuatan Deployment. Ini adalah _state_ yang diinginkan.
* `CURRENT` menampilkan berapa jumlah replika yang sedang berjalan.
* `UP-TO-DATE` menampilkan jumlah replika yang diperbarui agar sesuai state yang diinginkan.
* `AVAILABLE` menampilkan jumlah replika aplikasi yang dapat diakses pengguna.
* `AGE` menampilkan lama waktu aplikasi telah berjalan.
</code></pre><p>Perhatikan bahwa jumlah replika yang diinginkan adalah tiga sesuai kolom <code>.spec.replicas</code>.</p><ol start=3><li>Untuk melihat status rilis Deployment, jalankan <code>kubectl rollout status deployment.v1.apps/nginx-deployment</code>. Keluaran akan tampil seperti berikut:</li></ol><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>Waiting <span style=color:#a2f;font-weight:700>for</span> rollout to finish: <span style=color:#666>2</span> out of <span style=color:#666>3</span> new replicas have been updated...
</span></span><span style=display:flex><span>deployment <span style=color:#b44>&#34;nginx-deployment&#34;</span> successfully rolled out
</span></span></code></pre></div><ol start=4><li>Jalankan <code>kubectl get deployments</code> lagi beberapa saat kemudian. Keluaran akan tampil seperti berikut:</li></ol><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>NAME               DESIRED   CURRENT   UP-TO-DATE   AVAILABLE   AGE
</span></span><span style=display:flex><span>nginx-deployment   <span style=color:#666>3</span>         <span style=color:#666>3</span>         <span style=color:#666>3</span>            <span style=color:#666>3</span>           18s
</span></span></code></pre></div><p>Perhatikan bahwa Deployment telah membuat ketiga replika dan semua replika sudah merupakan yang terbaru (mereka mengandung pembaruan terakhir templat Pod) dan dapat diakses.</p><ol start=5><li>Untuk melihat ReplicaSet (<code>rs</code>) yang dibuat Deployment, jalankan <code>kubectl get rs</code>. Keluaran akan tampil seperti berikut:</li></ol><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>NAME                          DESIRED   CURRENT   READY   AGE
</span></span><span style=display:flex><span>nginx-deployment-75675f5897   <span style=color:#666>3</span>         <span style=color:#666>3</span>         <span style=color:#666>3</span>       18s
</span></span></code></pre></div><p>Perhatikan bahwa nama ReplicaSet selalu dalam format <code>[NAMA-DEPLOYMENT]-[KATA-ACAK]</code>. Kata acak dibangkitkan secara acak dan menggunakan pod-template-hash sebagai benih.</p><ol start=6><li>Untuk melihat label yang dibangkitkan secara otomatis untuk tiap Pod, jalankan <code>kubectl get pods --show-labels</code>. Perintah akan menghasilkan keluaran berikut:</li></ol><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>NAME                                READY     STATUS    RESTARTS   AGE       LABELS
</span></span><span style=display:flex><span>nginx-deployment-75675f5897-7ci7o   1/1       Running   <span style=color:#666>0</span>          18s       <span style=color:#b8860b>app</span><span style=color:#666>=</span>nginx,pod-template-hash<span style=color:#666>=</span><span style=color:#666>3123191453</span>
</span></span><span style=display:flex><span>nginx-deployment-75675f5897-kzszj   1/1       Running   <span style=color:#666>0</span>          18s       <span style=color:#b8860b>app</span><span style=color:#666>=</span>nginx,pod-template-hash<span style=color:#666>=</span><span style=color:#666>3123191453</span>
</span></span><span style=display:flex><span>nginx-deployment-75675f5897-qqcnn   1/1       Running   <span style=color:#666>0</span>          18s       <span style=color:#b8860b>app</span><span style=color:#666>=</span>nginx,pod-template-hash<span style=color:#666>=</span><span style=color:#666>3123191453</span>
</span></span></code></pre></div><p>ReplicaSet yang dibuat menjamin bahwa ada tiga Pod <code>nginx</code>.</p><div class="alert alert-info note callout" role=alert><strong>Catatan:</strong> Kamu harus memasukkan selektor dan label templat Pod yang benar pada Deployment (dalam kasus ini, <code>app: nginx</code>).
Jangan membuat label atau selektor yang beririsan dengan kontroler lain (termasuk Deployment dan StatefulSet lainnya). Kubernetes tidak akan mencegah adanya label yang beririsan.
Namun, jika beberapa kontroler memiliki selektor yang beririsan, kontroler itu mungkin akan konflik dan berjalan dengan tidak semestinya.</div></li></ul><h3 id=label-pod-template-hash>Label pod-template-hash</h3><div class="alert alert-info note callout" role=alert><strong>Catatan:</strong> Jangan ubah label ini.</div><p>Label <code>pod-template-hash</code> ditambahkan oleh Deployment kontroler pada tiap ReplicaSet yang dibuat atau diadopsi Deployment.</p><p>Label ini menjamin anak-anak ReplicaSet milik Deployment tidak tumpang tindih. Dia dibangkitkan dengan melakukan hash pada <code>PodTemplate</code> milik ReplicaSet dan memakainya sebagai label untuk ditambahkan ke selektor ReplicaSet, label templat Pod, dan Pod apapun yang ReplicaSet miliki.</p><h2 id=membarui-deployment>Membarui Deployment</h2><div class="alert alert-info note callout" role=alert><strong>Catatan:</strong> Rilis Deployment hanya dapat dipicu oleh perubahan templat Pod Deployment (yaitu, <code>.spec.template</code>), contohnya perubahan kolom label atau image container. Yang lain, seperti replika, tidak akan memicu rilis.</div><p>Ikuti langkah-langkah berikut untuk membarui Deployment:</p><ol><li><p>Ganti Pod nginx menjadi image <code>nginx:1.9.1</code> dari image <code>nginx:1.7.9</code>.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl --record deployment.apps/nginx-deployment <span style=color:#a2f>set</span> image deployment.v1.apps/nginx-deployment <span style=color:#b8860b>nginx</span><span style=color:#666>=</span>nginx:1.9.1
</span></span></code></pre></div><p>Keluaran akan tampil seperti berikut:</p><pre tabindex=0><code>deployment.apps/nginx-deployment image updated
</code></pre><p>Alternatif lainnya, kamu dapat <code>edit</code> Deployment dan mengganti <code>.spec.template.spec.containers[0].image</code> dari <code>nginx:1.7.9</code> ke <code>nginx:1.9.1</code>:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl edit deployment.v1.apps/nginx-deployment
</span></span></code></pre></div><p>Keluaran akan tampil seperti berikut:</p><pre tabindex=0><code>deployment.apps/nginx-deployment edited
</code></pre></li><li><p>Untuk melihat status rilis, jalankan:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl rollout status deployment.v1.apps/nginx-deployment
</span></span></code></pre></div><p>Keluaran akan tampil seperti berikut:</p><pre tabindex=0><code>Waiting for rollout to finish: 2 out of 3 new replicas have been updated...
</code></pre><p>atau</p><pre tabindex=0><code>deployment &#34;nginx-deployment&#34; successfully rolled out
</code></pre></li></ol><p>Untuk menampilkan detail lain dari Deployment yang terbaru:</p><ul><li><p>Setelah rilis sukses, kamu dapat melihat Deployment dengan menjalankan <code>kubectl get deployments</code>.
Keluaran akan tampil seperti berikut:</p><pre tabindex=0><code>NAME               DESIRED   CURRENT   UP-TO-DATE   AVAILABLE   AGE
nginx-deployment   3         3         3            3           36s
</code></pre></li><li><p>Jalankan <code>kubectl get rs</code> to see that the Deployment updated the Pods dengan membuat ReplicaSet baru dan
menggandakannya menjadi 3 replika, sembari menghapus ReplicaSet menjadi 0 replika.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get rs
</span></span></code></pre></div><p>Keluaran akan tampil seperti berikut:</p><pre tabindex=0><code>NAME                          DESIRED   CURRENT   READY   AGE
nginx-deployment-1564180365   3         3         3       6s
nginx-deployment-2035384211   0         0         0       36s
</code></pre></li><li><p>Menjalankan <code>get pods</code> sekarang hanya akan menampilkan Pod baru:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get pods
</span></span></code></pre></div><p>Keluaran akan tampil seperti berikut:</p><pre tabindex=0><code>NAME                                READY     STATUS    RESTARTS   AGE
nginx-deployment-1564180365-khku8   1/1       Running   0          14s
nginx-deployment-1564180365-nacti   1/1       Running   0          14s
nginx-deployment-1564180365-z9gth   1/1       Running   0          14s
</code></pre><p>Selanjutnya ketika ingin membarui Pod, kamu hanya perlu mengganti templat Pod Deployment lagi.</p><p>Deployment memastikan hanya ada beberapa Pod yang mati saat pembaruan berlangsung. Umumnya,
dia memastikan paling sedikit ada 75% jumlah Pod yang diinginkan menyala (25% maksimal tidak dapat diakses).</p><p>Deployment juga memastikan hanya ada beberapa Pod yang dibuat melebihi jumlah Pod yang diinginkan.
Umumnya, dia memastikan paling banyak ada 125% jumlah Pod yang diinginkan menyala (25% tambahan maksimal).</p><p>Misalnya, jika kamu lihat Deployment diatas lebih jauh, kamu akan melihat bahwa pertama-tama dia membuat Pod baru,
kemudian menghapus beberapa Pod lama, dan membuat yang baru. Dia tidak akan menghapus Pod lama sampai ada cukup
Pod baru menyala, dan pula tidak membuat Pod baru sampai ada cukup Pod lama telah mati.
Dia memastikan paling sedikit 2 Pod menyala dan paling banyak total 4 Pod menyala.</p></li><li><p>Melihat detil Deployment:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl describe deployments
</span></span></code></pre></div><p>Keluaran akan tampil seperti berikut:</p><pre tabindex=0><code>Name:                   nginx-deployment
Namespace:              default
CreationTimestamp:      Thu, 30 Nov 2017 10:56:25 +0000
Labels:                 app=nginx
Annotations:            deployment.kubernetes.io/revision=2
Selector:               app=nginx
Replicas:               3 desired | 3 updated | 3 total | 3 available | 0 unavailable
StrategyType:           RollingUpdate
MinReadySeconds:        0
RollingUpdateStrategy:  25% max unavailable, 25% max surge
Pod Template:
  Labels:  app=nginx
   Containers:
    nginx:
      Image:        nginx:1.9.1
      Port:         80/TCP
      Environment:  &lt;none&gt;
      Mounts:       &lt;none&gt;
    Volumes:        &lt;none&gt;
  Conditions:
    Type           Status  Reason
    ----           ------  ------
    Available      True    MinimumReplicasAvailable
    Progressing    True    NewReplicaSetAvailable
  OldReplicaSets:  &lt;none&gt;
  NewReplicaSet:   nginx-deployment-1564180365 (3/3 replicas created)
  Events:
    Type    Reason             Age   From                   Message
    ----    ------             ----  ----                   -------
    Normal  ScalingReplicaSet  2m    deployment-controller  Scaled up replica set nginx-deployment-2035384211 to 3
    Normal  ScalingReplicaSet  24s   deployment-controller  Scaled up replica set nginx-deployment-1564180365 to 1
    Normal  ScalingReplicaSet  22s   deployment-controller  Scaled down replica set nginx-deployment-2035384211 to 2
    Normal  ScalingReplicaSet  22s   deployment-controller  Scaled up replica set nginx-deployment-1564180365 to 2
    Normal  ScalingReplicaSet  19s   deployment-controller  Scaled down replica set nginx-deployment-2035384211 to 1
    Normal  ScalingReplicaSet  19s   deployment-controller  Scaled up replica set nginx-deployment-1564180365 to 3
    Normal  ScalingReplicaSet  14s   deployment-controller  Scaled down replica set nginx-deployment-2035384211 to 0
</code></pre><p>Disini bisa dilihat ketika pertama Deployment dibuat, dia membuat ReplicaSet (nginx-deployment-2035384211)
dan langsung menggandakannya menjadi 3 replika. Saat Deployment diperbarui, dia membuat ReplicaSet baru
(nginx-deployment-1564180365) dan menambah 1 replika kemudian mengecilkan ReplicaSet lama menjadi 2,
sehingga paling sedikit 2 Pod menyala dan paling banyak 4 Pod dibuat setiap saat. Dia kemudian lanjut menaik-turunkan
ReplicaSet baru dan ReplicaSet lama, dengan strategi pembaruan rolling yang sama.
Terakhir, kamu akan dapat 3 replika di ReplicaSet baru telah menyala, dan ReplicaSet lama akan hilang (berisi 0).</p></li></ul><h3 id=perpanjangan-alias-banyak-pembaruan-secara-langsung>Perpanjangan (alias banyak pembaruan secara langsung)</h3><p>Setiap kali Deployment baru is teramati oleh Deployment kontroler, ReplicaSet dibuat untuk membangkitkan Pod sesuai keinginan.
Jika Deployment diperbarui, ReplicaSet yang terkait Pod dengan label <code>.spec.selector</code> yang cocok,
namun kolom <code>.spec.template</code> pada templat tidak cocok akan dihapus. Kemudian, ReplicaSet baru akan
digandakan sebanyak <code>.spec.replicas</code> dan semua ReplicaSet lama dihapus.</p><p>Jika kamu mengubah Deployment saat rilis sedang berjalan, Deployment akan membuat ReplicaSet baru
tiap perubahan dan memulai penggandaan. Lalu, dia akan mengganti ReplicaSet yang dibuat sebelumnya
-- mereka ditambahkan ke dalam daftar ReplicaSet lama dan akan mulai dihapus.</p><p>Contohnya, ketika kamu membuat Deployment untuk membangkitkan 5 replika <code>nginx:1.7.9</code>,
kemudian membarui Deployment dengan versi <code>nginx:1.9.1</code> ketika ada 3 replika <code>nginx:1.7.9</code> yang dibuat.
Dalam kasus ini, Deployment akan segera menghapus 3 replika Pod <code>nginx:1.7.9</code> yang telah dibuat, dan mulai membuat
Pod <code>nginx:1.9.1</code>. Dia tidak akan menunggu kelima replika <code>nginx:1.7.9</code> selesai baru menjalankan perubahan.</p><h3 id=mengubah-selektor-label>Mengubah selektor label</h3><p>Umumnya, sekali dibuat, selektor label tidak boleh diubah. Sehingga disarankan untuk direncanakan dengan hati-hati sebelumnya.
Bagaimanapun, jika kamu perlu mengganti selektor label, lakukan dengan seksama dan pastikan kamu tahu segala konsekuensinya.</p><div class="alert alert-info note callout" role=alert><strong>Catatan:</strong> Pada versi API <code>apps/v1</code>, selektor label Deployment tidak bisa diubah ketika selesai dibuat.</div><ul><li>Penambahan selektor mensyaratkan label templat Pod di spek Deployment untuk diganti dengan label baru juga.
Jika tidak, galat validasi akan muncul. Perubahan haruslah tidak tumpang-tindih, dengan kata lain selektor baru tidak mencakup ReplicaSet dan Pod yang dibuat dengan selektor lama. Sehingga, semua ReplicaSet lama akan menggantung sedangkan ReplicaSet baru tetap dibuat.</li><li>Pengubahan selektor mengubah nilai pada kunci selektor -- menghasilkan perilaku yang sama dengan penambahan.</li><li>Penghapusan selektor menghilangkan kunci yang ada pada selektor Deployment -- tidak mensyaratkan perubahan apapun pada label templat Pod.
ReplicaSet yang ada tidak menggantung dan ReplicaSet baru tidak dibuat.
Tapi perhatikan bahwa label yang dihapus masih ada pada Pod dan ReplicaSet masing-masing.</li></ul><h2 id=membalikkan-deployment>Membalikkan Deployment</h2><p>Kadang, kamu mau membalikkan Deployment; misalnya, saat Deployment tidak stabil, seperti crash looping.
Umumnya, semua riwayat rilis Deployment disimpan oleh sistem sehingga kamu dapat kembali kapanpun kamu mau
(kamu dapat mengubahnya dengan mengubah batas riwayat revisi).</p><div class="alert alert-info note callout" role=alert><strong>Catatan:</strong> Revisi Deployment dibuat saat rilis Deployment dipicu. Ini berarti revisi baru dibuat jika dan hanya jika
templat Pod Deployment (<code>.spec.template</code>) berubah, misalnya jika kamu membarui label atau image kontainer pada templat.
Pembaruan lain, seperti penggantian skala Deployment, tidak membuat revisi Deployment, jadi kamu dapat memfasilitasi
penggantian skala secara manual atau otomatis secara simultan. Artinya saat kamu membalikkan ke versi sebelumnya,
hanya bagian templat Pod Deployment yang dibalikkan.</div><ul><li><p>Misal kamu membuat saltik saat mengganti Deployment, dengan memberi nama image dengan <code>nginx:1.91</code> alih-alih <code>nginx:1.9.1</code>:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl <span style=color:#a2f>set</span> image deployment.v1.apps/nginx-deployment <span style=color:#b8860b>nginx</span><span style=color:#666>=</span>nginx:1.91 --record<span style=color:#666>=</span><span style=color:#a2f>true</span>
</span></span></code></pre></div><p>Keluaran akan tampil seperti berikut:</p><pre tabindex=0><code>deployment.apps/nginx-deployment image updated
</code></pre></li><li><p>Rilis akan tersendat. Kamu dapat memeriksanya dengan melihat status rilis:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl rollout status deployment.v1.apps/nginx-deployment
</span></span></code></pre></div><p>Keluaran akan tampil seperti berikut:</p><pre tabindex=0><code>Waiting for rollout to finish: 1 out of 3 new replicas have been updated...
</code></pre></li><li><p>Tekan Ctrl-C untuk menghentikan pemeriksaan status rilis di atas. Untuk info lebih lanjut
tentang rilis tersendat, <a href=#status-deployment>baca disini</a>.</p></li><li><p>Kamu lihat bahwa jumlah replika lama (<code>nginx-deployment-1564180365</code> dan <code>nginx-deployment-2035384211</code>) adalah 2, dan replika baru (nginx-deployment-3066724191) adalah 1.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get rs
</span></span></code></pre></div><p>Keluaran akan tampil seperti berikut:</p><pre tabindex=0><code>NAME                          DESIRED   CURRENT   READY   AGE
nginx-deployment-1564180365   3         3         3       25s
nginx-deployment-2035384211   0         0         0       36s
nginx-deployment-3066724191   1         1         0       6s
</code></pre></li><li><p>Lihat pada Pod yang dibuat. Akan ada 1 Pod dibuat dari ReplicaSet baru tersendat loop(?) ketika penarikan image.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get pods
</span></span></code></pre></div><p>Keluaran akan tampil seperti berikut:</p><pre tabindex=0><code>NAME                                READY     STATUS             RESTARTS   AGE
nginx-deployment-1564180365-70iae   1/1       Running            0          25s
nginx-deployment-1564180365-jbqqo   1/1       Running            0          25s
nginx-deployment-1564180365-hysrc   1/1       Running            0          25s
nginx-deployment-3066724191-08mng   0/1       ImagePullBackOff   0          6s
</code></pre><div class="alert alert-info note callout" role=alert><strong>Catatan:</strong> Controller Deployment menghentikan rilis yang buruk secara otomatis dan juga berhenti meningkatkan ReplicaSet baru.
Ini tergantung pada parameter rollingUpdate (secara khusus <code>maxUnavailable</code>) yang dimasukkan.
Kubernetes umumnya mengatur jumlahnya menjadi 25%.</div></li><li><p>Tampilkan deskripsi Deployment:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl describe deployment
</span></span></code></pre></div><p>Keluaran akan tampil seperti berikut:</p><pre tabindex=0><code>Name:           nginx-deployment
Namespace:      default
CreationTimestamp:  Tue, 15 Mar 2016 14:48:04 -0700
Labels:         app=nginx
Selector:       app=nginx
Replicas:       3 desired | 1 updated | 4 total | 3 available | 1 unavailable
StrategyType:       RollingUpdate
MinReadySeconds:    0
RollingUpdateStrategy:  25% max unavailable, 25% max surge
Pod Template:
  Labels:  app=nginx
  Containers:
   nginx:
    Image:        nginx:1.91
    Port:         80/TCP
    Host Port:    0/TCP
    Environment:  &lt;none&gt;
    Mounts:       &lt;none&gt;
  Volumes:        &lt;none&gt;
Conditions:
  Type           Status  Reason
  ----           ------  ------
  Available      True    MinimumReplicasAvailable
  Progressing    True    ReplicaSetUpdated
OldReplicaSets:     nginx-deployment-1564180365 (3/3 replicas created)
NewReplicaSet:      nginx-deployment-3066724191 (1/1 replicas created)
Events:
  FirstSeen LastSeen    Count   From                    SubobjectPath   Type        Reason              Message
  --------- --------    -----   ----                    -------------   --------    ------              -------
  1m        1m          1       {deployment-controller }                Normal      ScalingReplicaSet   Scaled up replica set nginx-deployment-2035384211 to 3
  22s       22s         1       {deployment-controller }                Normal      ScalingReplicaSet   Scaled up replica set nginx-deployment-1564180365 to 1
  22s       22s         1       {deployment-controller }                Normal      ScalingReplicaSet   Scaled down replica set nginx-deployment-2035384211 to 2
  22s       22s         1       {deployment-controller }                Normal      ScalingReplicaSet   Scaled up replica set nginx-deployment-1564180365 to 2
  21s       21s         1       {deployment-controller }                Normal      ScalingReplicaSet   Scaled down replica set nginx-deployment-2035384211 to 1
  21s       21s         1       {deployment-controller }                Normal      ScalingReplicaSet   Scaled up replica set nginx-deployment-1564180365 to 3
  13s       13s         1       {deployment-controller }                Normal      ScalingReplicaSet   Scaled down replica set nginx-deployment-2035384211 to 0
  13s       13s         1       {deployment-controller }                Normal      ScalingReplicaSet   Scaled up replica set nginx-deployment-3066724191 to 1
</code></pre><p>Untuk memperbaikinya, kamu harus kembali ke revisi Deployment yang sebelumnya stabil.</p></li></ul><h3 id=mengecek-riwayat-rilis-deployment>Mengecek Riwayat Rilis Deployment</h3><p>Ikuti langkah-langkah berikut untuk mengecek riwayat rilis:</p><ol><li><p>Pertama, cek revisi Deployment sekarang:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl rollout <span style=color:#a2f>history</span> deployment.v1.apps/nginx-deployment
</span></span></code></pre></div><p>Keluaran akan tampil seperti berikut:</p><pre tabindex=0><code>deployments &#34;nginx-deployment&#34;
REVISION    CHANGE-CAUSE
1           kubectl apply --filename=https://k8s.io/examples/controllers/nginx-deployment.yaml --record=true
2           kubectl set image deployment.v1.apps/nginx-deployment nginx=nginx:1.9.1 --record=true
3           kubectl set image deployment.v1.apps/nginx-deployment nginx=nginx:1.91 --record=true
</code></pre><p><code>CHANGE-CAUSE</code> disalin dari anotasi Deployment <code>kubernetes.io/change-cause</code> ke revisi saat pembuatan. Kamu dapat menentukan pesan <code>CHANGE-CAUSE</code> dengan:</p><ul><li>Menambahkan anotasi pada Deployment dengan <code>kubectl annotate deployment.v1.apps/nginx-deployment kubernetes.io/change-cause="image updated to 1.9.1"</code></li><li>Menambahkan argumen <code>--record</code> untuk menyimpan perintah <code>kubectl</code> yang menyebabkan perubahan sumber daya.</li><li>Mengganti manifest sumber daya secara manual.</li></ul></li><li><p>Untuk melihat detil tiap revisi, jalankan:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl rollout <span style=color:#a2f>history</span> deployment.v1.apps/nginx-deployment --revision<span style=color:#666>=</span><span style=color:#666>2</span>
</span></span></code></pre></div><p>Keluaran akan tampil seperti berikut:</p><pre tabindex=0><code>deployments &#34;nginx-deployment&#34; revision 2
  Labels:       app=nginx
          pod-template-hash=1159050644
  Annotations:  kubernetes.io/change-cause=kubectl set image deployment.v1.apps/nginx-deployment nginx=nginx:1.9.1 --record=true
  Containers:
   nginx:
    Image:      nginx:1.9.1
    Port:       80/TCP
     QoS Tier:
        cpu:      BestEffort
        memory:   BestEffort
    Environment Variables:      &lt;none&gt;
  No volumes.
</code></pre></li></ol><h3 id=kembali-ke-revisi-sebelumnya>Kembali ke Revisi Sebelumnya</h3><p>Ikuti langkah-langkah berikut untuk membalikkan Deployment dari versi sekarang ke versi sebelumnya, yaitu versi 2.</p><ol><li><p>Sekarang kamu telah menentukan akan mengembalikan rilis sekarang ke sebelumnya:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl rollout undo deployment.v1.apps/nginx-deployment
</span></span></code></pre></div><p>Keluaran akan tampil seperti berikut:</p><pre tabindex=0><code>deployment.apps/nginx-deployment
</code></pre><p>Gantinya, kamu dapat kambali ke revisi tertentu dengan menambahkan argumen <code>--to-revision</code>:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl rollout undo deployment.v1.apps/nginx-deployment --to-revision<span style=color:#666>=</span><span style=color:#666>2</span>
</span></span></code></pre></div><p>Keluaran akan tampil seperti berikut:</p><pre tabindex=0><code>deployment.apps/nginx-deployment
</code></pre><p>Untuk detil lebih lanjut perintah terkait rilis, baca <a href=/docs/reference/generated/kubectl/kubectl-commands#rollout><code>rilis kubectl</code></a>.</p><p>Deployment sekarang dikembalikan ke revisi stabil sebelumnya. Seperti terlihat, ada event <code>DeploymentRollback</code>
yang dibentuk oleh kontroler Deployment untuk pembalikan ke revisi 2.</p></li><li><p>Cek apakah rilis telah sukses dan Deployment berjalan seharusnya, jalankan:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get deployment nginx-deployment
</span></span></code></pre></div><p>Keluaran akan tampil seperti berikut:</p><pre tabindex=0><code>NAME               DESIRED   CURRENT   UP-TO-DATE   AVAILABLE   AGE
nginx-deployment   3         3         3            3           30m
</code></pre></li><li><p>Tampilkan deskripsi Deployment:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl describe deployment nginx-deployment
</span></span></code></pre></div><p>Keluaran akan tampil seperti berikut:</p><pre tabindex=0><code>Name:                   nginx-deployment
Namespace:              default
CreationTimestamp:      Sun, 02 Sep 2018 18:17:55 -0500
Labels:                 app=nginx
Annotations:            deployment.kubernetes.io/revision=4
                        kubernetes.io/change-cause=kubectl set image deployment.v1.apps/nginx-deployment nginx=nginx:1.9.1 --record=true
Selector:               app=nginx
Replicas:               3 desired | 3 updated | 3 total | 3 available | 0 unavailable
StrategyType:           RollingUpdate
MinReadySeconds:        0
RollingUpdateStrategy:  25% max unavailable, 25% max surge
Pod Template:
  Labels:  app=nginx
  Containers:
   nginx:
    Image:        nginx:1.9.1
    Port:         80/TCP
    Host Port:    0/TCP
    Environment:  &lt;none&gt;
    Mounts:       &lt;none&gt;
  Volumes:        &lt;none&gt;
Conditions:
  Type           Status  Reason
  ----           ------  ------
  Available      True    MinimumReplicasAvailable
  Progressing    True    NewReplicaSetAvailable
OldReplicaSets:  &lt;none&gt;
NewReplicaSet:   nginx-deployment-c4747d96c (3/3 replicas created)
Events:
  Type    Reason              Age   From                   Message
  ----    ------              ----  ----                   -------
  Normal  ScalingReplicaSet   12m   deployment-controller  Scaled up replica set nginx-deployment-75675f5897 to 3
  Normal  ScalingReplicaSet   11m   deployment-controller  Scaled up replica set nginx-deployment-c4747d96c to 1
  Normal  ScalingReplicaSet   11m   deployment-controller  Scaled down replica set nginx-deployment-75675f5897 to 2
  Normal  ScalingReplicaSet   11m   deployment-controller  Scaled up replica set nginx-deployment-c4747d96c to 2
  Normal  ScalingReplicaSet   11m   deployment-controller  Scaled down replica set nginx-deployment-75675f5897 to 1
  Normal  ScalingReplicaSet   11m   deployment-controller  Scaled up replica set nginx-deployment-c4747d96c to 3
  Normal  ScalingReplicaSet   11m   deployment-controller  Scaled down replica set nginx-deployment-75675f5897 to 0
  Normal  ScalingReplicaSet   11m   deployment-controller  Scaled up replica set nginx-deployment-595696685f to 1
  Normal  DeploymentRollback  15s   deployment-controller  Rolled back deployment &#34;nginx-deployment&#34; to revision 2
  Normal  ScalingReplicaSet   15s   deployment-controller  Scaled down replica set nginx-deployment-595696685f to 0
</code></pre></li></ol><h2 id=mengatur-skala-deployment>Mengatur Skala Deployment</h2><p>Kamu dapat mengatur skala Deployment dengan perintah berikut:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl scale deployment.v1.apps/nginx-deployment --replicas<span style=color:#666>=</span><span style=color:#666>10</span>
</span></span></code></pre></div><p>Keluaran akan tampil seperti berikut:</p><pre tabindex=0><code>deployment.apps/nginx-deployment scaled
</code></pre><p>Dengan asumsi <a href=/docs/tasks/run-application/horizontal-pod-autoscale-walkthrough/>horizontal Pod autoscaling</a> dalam klaster dinyalakan,
kamu dapat mengatur autoscaler untuk Deployment-mu dan memilih jumlah minimal dan maksimal Pod yang mau dijalankan berdasarkan penggunaan CPU
dari Pod.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl autoscale deployment.v1.apps/nginx-deployment --min<span style=color:#666>=</span><span style=color:#666>10</span> --max<span style=color:#666>=</span><span style=color:#666>15</span> --cpu-percent<span style=color:#666>=</span><span style=color:#666>80</span>
</span></span></code></pre></div><p>Keluaran akan tampil seperti berikut:</p><pre tabindex=0><code>deployment.apps/nginx-deployment scaled
</code></pre><h3 id=pengaturan-skala-proporsional>Pengaturan skala proporsional</h3><p>Deployment RollingUpdate mendukung beberapa versi aplikasi berjalan secara bersamaan. Ketika kamu atau autoscaler
mengubah skala Deployment RollingUpdate yang ada di tengah rilis (yang sedang berjalan maupun terjeda),
kontroler Deployment menyeimbangkan replika tambahan dalam ReplicaSet aktif (ReplicaSet dengan Pod) untuk mencegah resiko.
Ini disebut <em>pengaturan skala proporsional</em>.</p><p>Sebagai contoh, kamu menjalankan Deployment dengan 10 replika, <a href=#max-surge>maxSurge</a>=3, dan <a href=#max-unavailable>maxUnavailable</a>=2.</p><ul><li><p>Pastikan ada 10 replica di Deployment-mu yang berjalan.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get deploy
</span></span></code></pre></div><p>Keluaran akan tampil seperti berikut:</p><pre tabindex=0><code>NAME                 DESIRED   CURRENT   UP-TO-DATE   AVAILABLE   AGE
nginx-deployment     10        10        10           10          50s
</code></pre></li><li><p>Ganti ke image baru yang kebetulan tidak bisa ditemukan dari dalam klaster.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl <span style=color:#a2f>set</span> image deployment.v1.apps/nginx-deployment <span style=color:#b8860b>nginx</span><span style=color:#666>=</span>nginx:sometag
</span></span></code></pre></div><p>Keluaran akan tampil seperti berikut:</p><pre tabindex=0><code>deployment.apps/nginx-deployment image updated
</code></pre></li><li><p>Penggantian image akan memulai rilis baru dengan ReplicaSet nginx-deployment-1989198191, namun dicegah karena
persyaratan <code>maxUnavailable</code> yang disebut di atas. Cek status rilis:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get rs
</span></span></code></pre></div><pre><code>Keluaran akan tampil seperti berikut:
</code></pre><pre tabindex=0><code>NAME                          DESIRED   CURRENT   READY     AGE
nginx-deployment-1989198191   5         5         0         9s
nginx-deployment-618515232    8         8         8         1m
</code></pre></li><li><p>Kemudian, permintaan peningkatan untuk Deployment akan masuk. Autoscaler menambah replika Deployment
menjadi 15. Controller Deployment perlu menentukan dimana 5 replika ini ditambahkan. Jika kamu memakai
pengaturan skala proporsional, kelima replika akan ditambahkan ke ReplicaSet baru. Dengan pengaturan skala proporsional,
kamu menyebarkan replika tambahan ke semua ReplicaSet. Proporsi terbesar ada pada ReplicaSet dengan
replika terbanyak dan proporsi yang lebih kecil untuk replika dengan ReplicaSet yang lebih sedikit.
Sisanya akan diberikan ReplicaSet dengan replika terbanyak. ReplicaSet tanpa replika tidak akan ditingkatkan.</p></li></ul><p>Dalam kasus kita di atas, 3 replika ditambahkan ke ReplicaSet lama dan 2 replika ditambahkan ke ReplicaSet baru.
Proses rilis akan segera memindahkan semua ReplicaSet baru, dengan asumsi semua replika dalam kondisi sehat.
Untuk memastikannya, jalankan:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get deploy
</span></span></code></pre></div><p>Keluaran akan tampil seperti berikut:</p><pre tabindex=0><code>NAME                 DESIRED   CURRENT   UP-TO-DATE   AVAILABLE   AGE
nginx-deployment     15        18        7            8           7m
</code></pre><p>Status rilis mengkonfirmasi bagaimana replika ditambahkan ke tiap ReplicaSet.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get rs
</span></span></code></pre></div><p>Keluaran akan tampil seperti berikut:</p><pre tabindex=0><code>NAME                          DESIRED   CURRENT   READY     AGE
nginx-deployment-1989198191   7         7         0         7m
nginx-deployment-618515232    11        11        11        7m
</code></pre><h2 id=menjeda-dan-melanjutkan-deployment>Menjeda dan Melanjutkan Deployment</h2><p>Kamu dapat menjeda Deployment sebelum memicu satu atau lebih pembaruan kemudian meneruskannya.
Hal ini memungkinkanmu menerapkan beberapa perbaikan selama selang jeda tanpa melakukan rilis yang tidak perlu.</p><ul><li><p>Sebagai contoh, Deployment yang baru dibuat:
Lihat detil Deployment:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get deploy
</span></span></code></pre></div><p>Keluaran akan tampil seperti berikut:</p><pre tabindex=0><code>NAME      DESIRED   CURRENT   UP-TO-DATE   AVAILABLE   AGE
nginx     3         3         3            3           1m
</code></pre><p>Lihat status rilis:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get rs
</span></span></code></pre></div><p>Keluaran akan tampil seperti berikut:</p><pre tabindex=0><code>NAME               DESIRED   CURRENT   READY     AGE
nginx-2142116321   3         3         3         1m
</code></pre></li><li><p>Jeda dengan menjalankan perintah berikut:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl rollout pause deployment.v1.apps/nginx-deployment
</span></span></code></pre></div><p>Keluaran akan tampil seperti berikut:</p><pre tabindex=0><code>deployment.apps/nginx-deployment paused
</code></pre></li><li><p>Lalu ganti kolom image Deployment:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl <span style=color:#a2f>set</span> image deployment.v1.apps/nginx-deployment <span style=color:#b8860b>nginx</span><span style=color:#666>=</span>nginx:1.9.1
</span></span></code></pre></div><p>Keluaran akan tampil seperti berikut:</p><pre tabindex=0><code>deployment.apps/nginx-deployment image updated
</code></pre></li><li><p>Perhatikan tidak ada rilis baru yang muncul:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl rollout <span style=color:#a2f>history</span> deployment.v1.apps/nginx-deployment
</span></span></code></pre></div><p>Keluaran akan tampil seperti berikut:</p><pre tabindex=0><code>deployments &#34;nginx&#34;
REVISION  CHANGE-CAUSE
1   &lt;none&gt;
</code></pre></li><li><p>Lihat status rilis untuk memastikan Deployment berhasil diperbarui:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get rs
</span></span></code></pre></div><p>Keluaran akan tampil seperti berikut:</p><pre tabindex=0><code>NAME               DESIRED   CURRENT   READY     AGE
nginx-2142116321   3         3         3         2m
</code></pre></li><li><p>Kamu bisa membuat pembaruan sebanyak yang kamu mau. Contohnya pembaruan sumber daya yang akan dipakai:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl <span style=color:#a2f>set</span> resources deployment.v1.apps/nginx-deployment -c<span style=color:#666>=</span>nginx --limits<span style=color:#666>=</span><span style=color:#b8860b>cpu</span><span style=color:#666>=</span>200m,memory<span style=color:#666>=</span>512Mi
</span></span></code></pre></div><p>Keluaran akan tampil seperti berikut:</p><pre tabindex=0><code>deployment.apps/nginx-deployment resource requirements updated
</code></pre><p>The state awal Deployment sebelum jeda akan melanjutkan fungsinya, tapi perubahan
Deployment tidak akan berefek apapun selama Deployment masih terjeda.</p></li><li><p>Kemudian, mulai kembali Deployment dan perhatikan ReplicaSet baru akan muncul dengan semua perubahan baru:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl rollout resume deployment.v1.apps/nginx-deployment
</span></span></code></pre></div><p>Keluaran akan tampil seperti berikut:</p><pre tabindex=0><code>deployment.apps/nginx-deployment resumed
</code></pre></li><li><p>Perhatikan status rilis sampai selesai.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get rs -w
</span></span></code></pre></div><p>Keluaran akan tampil seperti berikut:</p><pre tabindex=0><code>NAME               DESIRED   CURRENT   READY     AGE
nginx-2142116321   2         2         2         2m
nginx-3926361531   2         2         0         6s
nginx-3926361531   2         2         1         18s
nginx-2142116321   1         2         2         2m
nginx-2142116321   1         2         2         2m
nginx-3926361531   3         2         1         18s
nginx-3926361531   3         2         1         18s
nginx-2142116321   1         1         1         2m
nginx-3926361531   3         3         1         18s
nginx-3926361531   3         3         2         19s
nginx-2142116321   0         1         1         2m
nginx-2142116321   0         1         1         2m
nginx-2142116321   0         0         0         2m
nginx-3926361531   3         3         3         20s
</code></pre></li><li><p>Lihat status rilis terakhir:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get rs
</span></span></code></pre></div><p>Keluaran akan tampil seperti berikut:</p><pre tabindex=0><code>NAME               DESIRED   CURRENT   READY     AGE
nginx-2142116321   0         0         0         2m
nginx-3926361531   3         3         3         28s
</code></pre></li></ul><div class="alert alert-info note callout" role=alert><strong>Catatan:</strong> Kamu tidak bisa membalikkan Deployment yang terjeda sampai dia diteruskan.</div><h2 id=status-deployment>Status Deployment</h2><p>Deployment melalui berbagai state dalam daur hidupnya. Dia dapat <a href=#deployment-berlangsung>berlangsung</a> selagi merilis ReplicaSet baru, bisa juga <a href=#deployment-selesai>selesai</a>,
atau juga <a href=#deployment-gagal>gagal</a>.</p><h3 id=deployment-berlangsung>Deployment Berlangsung</h3><p>Kubernetes menandai Deployment sebagai <em>progressing</em> saat salah satu tugas di bawah dikerjakan:</p><ul><li>Deployment membuat ReplicaSet baru.</li><li>Deployment menaikkan kapasitas ReplicaSet terbaru.</li><li>Deployment menurunkan kapasitas ReplicaSet yang lebih lama.</li><li>Pod baru menjadi siap atau dapat diakses (siap selama setidaknya <a href=#min-ready-seconds>MinReadySeconds</a>).</li></ul><p>Kamu dapat mengawasi perkembangan Deployment dengan <code>kubectl rollout status</code>.</p><h3 id=deployment-selesai>Deployment Selesai</h3><p>Kubernetes menandai Deployment sebagai <em>complete</em> saat memiliki karakteristik berikut:</p><ul><li>Semua replika terkait Deployment telah diperbarui ke versi terbaru yang dispecify, artinya semua pembaruan yang kamu inginkan telah selesai.</li><li>Semua replika terkait Deployment dapat diakses.</li><li>Tidak ada replika lama untuk Deployment yang berjalan.</li></ul><p>Kamu dapat mengecek apakah Deployment telah selesai dengan <code>kubectl rollout status</code>.
Jika rilis selesai, <code>kubectl rollout status</code> akan mengembalikan nilai balik nol.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl rollout status deployment.v1.apps/nginx-deployment
</span></span></code></pre></div><p>Keluaran akan tampil seperti berikut:</p><pre tabindex=0><code>Waiting for rollout to finish: 2 of 3 updated replicas are available...
deployment &#34;nginx-deployment&#34; successfully rolled out
$ echo $?
0
</code></pre><h3 id=deployment-gagal>Deployment Gagal</h3><p>Deployment-mu bisa saja terhenti saat mencoba deploy ReplicaSet terbaru tanpa pernah selesai.
Ini dapat terjadi karena faktor berikut:</p><ul><li>Kuota tidak mencukupi</li><li>Kegagalan pengecekan kesiapan</li><li>Galat saat mengunduh image</li><li>Tidak memiliki ijin</li><li>Limit ranges</li><li>Konfigurasi runtime aplikasi yang salah</li></ul><p>Salah satu cara untuk mendeteksi kondisi ini adalah untuk menjelaskan parameter tenggat pada spesifikasi Deployment:
(<a href=#progress-deadline-seconds><code>.spec.progressDeadlineSeconds</code></a>). <code>.spec.progressDeadlineSeconds</code> menyatakan
lama kontroler Deployment menunggu sebelum mengindikasikan (pada status Deployment) bahwa kemajuan Deployment
tersendat dalam detik.</p><p>Perintah <code>kubectl</code> berikut menetapkan spek dengan <code>progressDeadlineSeconds</code> untuk membuat kontroler
melaporkan kemajuan Deployment yang sedikit setelah 10 menit:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl patch deployment.v1.apps/nginx-deployment -p <span style=color:#b44>&#39;{&#34;spec&#34;:{&#34;progressDeadlineSeconds&#34;:600}}&#39;</span>
</span></span></code></pre></div><p>Keluaran akan tampil seperti berikut:</p><pre tabindex=0><code>deployment.apps/nginx-deployment patched
</code></pre><p>Ketika tenggat sudah lewat, kontroler Deployment menambah DeploymentCondition dengan atribut
berikut ke <code>.status.conditions</code> milik Deployment:</p><ul><li>Type=Progressing</li><li>Status=False</li><li>Reason=ProgressDeadlineExceeded</li></ul><p>Lihat <a href=https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#typical-status-properties>konvensi Kubernetes API</a> untuk info lebih lanjut tentang kondisi status.</p><div class="alert alert-info note callout" role=alert><strong>Catatan:</strong> Kubernetes tidak melakukan apapun pada Deployment yang tersendat selain melaporkannya sebagai <code>Reason=ProgressDeadlineExceeded</code>.
Orkestrator yang lebih tinggi dapat memanfaatkannya untuk melakukan tindak lanjut. Misalnya, mengembalikan Deployment ke versi sebelumnya.</div><div class="alert alert-info note callout" role=alert><strong>Catatan:</strong> Jika Deployment terjeda, Kubernetes tidak akan mengecek kemajuan pada selang itu.
Kamu dapat menjeda Deployment di tengah rilis dan melanjutkannya dengan aman tanpa memicu kondisi saat tenggat telah lewat.</div><p>Kamu dapat mengalami galat sejenak pada Deployment disebabkan timeout yang dipasang terlalu kecil atau
hal-hal lain yang terjadi sementara. Misalnya, kamu punya kuota yang tidak mencukupi. Jika kamu mendeskripsikan Deployment
kamu akan menjumpai pada bagian ini:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl describe deployment nginx-deployment
</span></span></code></pre></div><p>Keluaran akan tampil seperti berikut:</p><pre tabindex=0><code>&lt;...&gt;
Conditions:
  Type            Status  Reason
  ----            ------  ------
  Available       True    MinimumReplicasAvailable
  Progressing     True    ReplicaSetUpdated
  ReplicaFailure  True    FailedCreate
&lt;...&gt;
</code></pre><p>Jika kamu menjalankan <code>kubectl get deployment nginx-deployment -o yaml</code>, Deployment status akan muncul seperti berikut:</p><pre tabindex=0><code>status:
  availableReplicas: 2
  conditions:
  - lastTransitionTime: 2016-10-04T12:25:39Z
    lastUpdateTime: 2016-10-04T12:25:39Z
    message: Replica set &#34;nginx-deployment-4262182780&#34; is progressing.
    reason: ReplicaSetUpdated
    status: &#34;True&#34;
    type: Progressing
  - lastTransitionTime: 2016-10-04T12:25:42Z
    lastUpdateTime: 2016-10-04T12:25:42Z
    message: Deployment has minimum availability.
    reason: MinimumReplicasAvailable
    status: &#34;True&#34;
    type: Available
  - lastTransitionTime: 2016-10-04T12:25:39Z
    lastUpdateTime: 2016-10-04T12:25:39Z
    message: &#39;Error creating: pods &#34;nginx-deployment-4262182780-&#34; is forbidden: exceeded quota:
      object-counts, requested: pods=1, used: pods=3, limited: pods=2&#39;
    reason: FailedCreate
    status: &#34;True&#34;
    type: ReplicaFailure
  observedGeneration: 3
  replicas: 2
  unavailableReplicas: 2
</code></pre><p>Begitu tenggat kemajuan Deployment terlewat, Kubernetes membarui status dan alasan untuk kondisi Progressing:</p><pre tabindex=0><code>Conditions:
  Type            Status  Reason
  ----            ------  ------
  Available       True    MinimumReplicasAvailable
  Progressing     False   ProgressDeadlineExceeded
  ReplicaFailure  True    FailedCreate
</code></pre><p>Kamu dapat menangani isu keterbatasan kuota dengan menurunkan jumlah Deployment, bisa dengan menghapus kontrolers
yang sedang berjalan, atau dengan meningkatkan kuota pada namespace. Jika kuota tersedia, kemudian kontroler Deployment
akan dapat menyelesaikan rilis Deployment. Kamu akan melihat bahwa status Deployment berubah menjadi kondisi sukses (<code>Status=True</code> dan <code>Reason=NewReplicaSetAvailable</code>).</p><pre tabindex=0><code>Conditions:
  Type          Status  Reason
  ----          ------  ------
  Available     True    MinimumReplicasAvailable
  Progressing   True    NewReplicaSetAvailable
</code></pre><p><code>Type=Available</code> dengan <code>Status=True</code> artinya Deployment-mu punya ketersediaan minimum. Ketersediaan minimum diatur
oleh parameter yang dibuat pada strategi deployment. <code>Type=Progressing</code> dengan <code>Status=True</code> berarti Deployment
sedang dalam rilis dan masih berjalan atau sudah selesai berjalan dan jumlah minimum replika tersedia
(lihat bagian Alasan untuk kondisi tertentu - dalam kasus ini <code>Reason=NewReplicaSetAvailable</code> berarti Deployment telah selesai).</p><p>Kamu dapat mengecek apakah Deployment gagal berkembang dengan perintah <code>kubectl rollout status</code>. <code>kubectl rollout status</code>
mengembalikan nilai selain nol jika Deployment telah melewati tenggat kemajuan.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl rollout status deployment.v1.apps/nginx-deployment
</span></span></code></pre></div><p>Keluaran akan tampil seperti berikut:</p><pre tabindex=0><code>Waiting for rollout to finish: 2 out of 3 new replicas have been updated...
error: deployment &#34;nginx&#34; exceeded its progress deadline
$ echo $?
1
</code></pre><h3 id=menindak-deployment-yang-gagal>Menindak Deployment yang gagal</h3><p>Semua aksi yang dapat diterapkan pada Deployment yang selesai berjalan juga pada Deployment gagal. Kamu dapat menaik/turunkan replika, membalikkan ke versi sebelumnya, atau menjedanya jika kamu perlu menerapkan beberapa perbaikan pada templat Pod Deployment.</p><h2 id=kebijakan-pembersihan>Kebijakan Pembersihan</h2><p>Kamu dapat mengisi kolom <code>.spec.revisionHistoryLimit</code> di Deployment untuk menentukan banyak ReplicaSet
pada Deployment yang ingin dipertahankan. Sisanya akan di garbage-collected di balik layar. Umumnya, nilai kolom berisi 10.</p><div class="alert alert-info note callout" role=alert><strong>Catatan:</strong> Mengisi secara eksplisit dengan nilai 0 akan membuat pembersihan semua riwayat rilis Deployment
sehingga Deployment tidak akan dapat dikembalikan.</div><h2 id=deployment-canary>Deployment Canary</h2><p>Jika kamu ingin merilis ke sebagian pengguna atau server menggunakan Deployment,
kamu dapat membuat beberapa Deployment, satu tiap rilis, dengan mengikuti pola canary yang didesripsikan pada
<a href=/id/docs/concepts/cluster-administration/manage-deployment/#deploy-dengan-canary>mengelola sumber daya</a>.</p><h2 id=menulis-spesifikasi-deployment>Menulis Spesifikasi Deployment</h2><p>Sebagaimana konfigurasi Kubernetes lainnya, Deployment memerlukan kolom <code>apiVersion</code>, <code>kind</code>, dan <code>metadata</code>.
Untuk informasi umum tentang penggunaan berkas konfigurasi, lihat dokumen <a href=/id/docs/tutorials/stateless-application/run-stateless-application-deployment/>deploy aplikasi</a>,
mengatur kontainer, dan <a href=/id/docs/concepts/overview/working-with-objects/object-management/>memakai kubectl untuk mengatur sumber daya</a>.</p><p>Deployment juga perlu <a href=https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#spec-and-status>bagian <code>.spec</code></a>.</p><h3 id=templat-pod>Templat Pod</h3><p>Dalam <code>.spec</code> hanya ada kolom <code>.spec.template</code> dan <code>.spec.selector</code> yang wajib diisi.</p><p><code>.spec.template</code> adalah <a href=/id/docs/concepts/workloads/pods/pod-overview/#templat-pod>templat Pod</a>. Dia memiliki skema yang sama dengan <a href=/id/docs/concepts/workloads/pods/pod/>Pod</a>. Bedanya dia bersarang dan tidak punya <code>apiVersion</code> atau <code>kind</code>.</p><p>Selain kolom wajib untuk Pod, templat Pod pada Deployment harus menentukan label dan aturan menjalankan ulang yang tepat.
Untuk label, pastikaan tidak bertumpang tindih dengan kontroler lainnya. Lihat <a href=#selektor>selektor</a>).</p><p><a href=/id/docs/concepts/workloads/pods/pod-lifecycle/#aturan-menjalankan-ulang><code>.spec.template.spec.restartPolicy</code></a> hanya boleh berisi <code>Always</code>,
yang tidak ditentukan pada bawaan.</p><h3 id=replika>Replika</h3><p><code>.spec.replicas</code> adalah kolom opsional yang mengatur jumlah Pod yang diinginkan. Setelan bawaannya berisi 1.</p><h3 id=selektor>Selektor</h3><p><code>.spec.selector</code> adalah kolom wajib yang mengatur <a href=/id/docs/concepts/overview/working-with-objects/labels/>selektor label</a>
untuk Pod yang dituju oleh Deployment ini.</p><p><code>.spec.selector</code> harus sesuai <code>.spec.template.metadata.labels</code>, atau akan ditolak oleh API.</p><p>Di versi API <code>apps/v1</code>, <code>.spec.selector</code> dan <code>.metadata.labels</code> tidak berisi <code>.spec.template.metadata.labels</code> jika tidak disetel.
Jadi mereka harus disetel secara eksplisit. Perhatikan juga <code>.spec.selector</code> tidak dapat diubah setelah Deployment dibuat pada <code>apps/v1</code>.</p><p>Deployment dapat mematikan Pod yang labelnya cocok dengan selektor jika templatnya berbeda
dari <code>.spec.template</code> atau total jumlah Pod melebihi <code>.spec.replicas</code>. Dia akan membuat Pod baru
dengan <code>.spec.template</code> jika jumlah Pod kurang dari yang diinginkan.</p><div class="alert alert-info note callout" role=alert><strong>Catatan:</strong> Kamu sebaiknya tidak membuat Pod lain yang labelnya cocok dengan selektor ini, baik secara langsung,
melalui Deployment lain, atau membuat kontroler lain seperti ReplicaSet atau ReplicationController.
Kalau kamu melakukannya, Deployment pertama akan mengira dia yang membuat Pod-pod ini.
Kubernetes tidak akan mencegahmu melakukannya.</div><p>Jika kamu punya beberapa kontroler dengan selektor bertindihan, mereka akan saling bertikai
dan tidak akan berjalan semestinya.</p><h3 id=strategi>Strategi</h3><p><code>.spec.strategy</code> mengatur strategi yang dipakai untuk mengganti Pod lama dengan yang baru.
<code>.spec.strategy.type</code> dapat berisi "Recreate" atau "RollingUpdate". Nilai bawaannya adalah "RollingUpdate".</p><h4 id=membuat-ulang-deployment>Membuat Ulang Deployment</h4><p>Semua Pod yang ada dimatikan sebelum yang baru dibuat ketika nilai <code>.spec.strategy.type==Recreate</code>.</p><h4 id=membarui-deployment-secara-bergulir>Membarui Deployment secara Bergulir</h4><p>Deployment membarui Pod secara bergulir
saat <code>.spec.strategy.type==RollingUpdate</code>. Kamu dapat menentukan <code>maxUnavailable</code> dan <code>maxSurge</code> untuk mengatur
proses pembaruan bergulir.</p><h5 id=ketidaktersediaan-maksimum>Ketidaktersediaan Maksimum</h5><p><code>.spec.strategy.rollingUpdate.maxUnavailable</code> adalah kolom opsional yang mengatur jumlah Pod maksimal
yang tidak tersedia selama proses pembaruan. Nilainya bisa berupa angka mutlak (contohnya 5)
atau persentase dari Pod yang diinginkan (contohnya 10%). Angka mutlak dihitung berdasarkan persentase
dengan pembulatan ke bawah. Nilai tidak bisa nol jika <code>.spec.strategy.rollingUpdate.maxSurge</code> juga nol.
Nilai bawaannya yaitu 25%.</p><p>Sebagai contoh, ketika nilai berisi 30%, ReplicaSet lama dapat segera diperkecil menjadi 70% dari Pod
yang diinginkan saat pembaruan bergulir dimulai. Seketika Pod baru siap, ReplicaSet lama dapat lebih diperkecil lagi,
diikuti dengan pembesaran ReplicaSet, menjamin total jumlah Pod yang siap kapanpun ketika pembaruan
paling sedikit 70% dari Pod yang diinginkan.</p><h5 id=kelebihan-maksimum>Kelebihan Maksimum</h5><p><code>.spec.strategy.rollingUpdate.maxSurge</code> adalah kolom opsional yang mengatur jumlah Pod maksimal yang
dapat dibuat melebihi jumlah Pod yang diinginkan. Nilainya bisa berupa angka mutlak (contohnya 5) atau persentase
dari Pod yang diinginkan (contohnya 10%). Nilai tidak bisa nol jika <code>MaxUnavailable</code> juga nol. Angka mutlak
dihitung berdasarkan persentase dengan pembulatan ke bawah. Nilai bawaannya yaitu 25%.</p><p>Sebagai contoh, ketika nilai berisi 30%, ReplicaSet baru dapat segera diperbesar saat pembaruan bergulir dimulai,
sehingga total jumlah Pod yang baru dan lama tidak melebihi 130% dari Pod yang diinginkan.
Saat Pod lama dimatikan, ReplicaSet baru dapat lebih diperbesar lagi, menjamin total jumlah Pod yang siap
kapanpun ketika pembaruan paling banyak 130% dari Pod yang diinginkan.</p><h3 id=tenggat-kemajuan-dalam-detik>Tenggat Kemajuan dalam Detik</h3><p><code>.spec.progressDeadlineSeconds</code> adalah kolom opsional yang mengatur lama tunggu dalam dalam detik untuk Deployment-mu berjalan
sebelum sistem melaporkan lagi bahwa Deployment <a href=#deployment-gagal>gagal</a> - ditunjukkan dengan kondisi <code>Type=Progressing</code>, <code>Status=False</code>,
dan <code>Reason=ProgressDeadlineExceeded</code> pada status sumber daya. Controller Deployment akan tetap mencoba ulang Deployment.
Nantinya begitu pengembalian otomatis diimplementasikan, kontroler Deployment akan membalikkan Deployment segera
saat dia menjumpai kondisi tersebut.</p><p>Jika ditentukan, kolom ini harus lebih besar dari <code>.spec.minReadySeconds</code>.</p><h3 id=lama-minimum-untuk-siap-dalam-detik>Lama Minimum untuk Siap dalam Detik</h3><p><code>.spec.minReadySeconds</code> adalah kolom opsional yang mengatur lama minimal sebuah Pod yang baru dibuat
seharusnya siap tanpa ada kontainer yang rusak, untuk dianggap tersedia, dalam detik.
Nilai bawaannya yaitu 0 (Pod akan dianggap tersedia segera ketika siap). Untuk mempelajari lebih lanjut
kapan Pod dianggap siap, lihat <a href=/id/docs/concepts/workloads/pods/pod-lifecycle/#pemeriksaan-kontainer>Pemeriksaan Kontainer</a>.</p><h3 id=kembali-ke>Kembali Ke</h3><p>Kolom <code>.spec.rollbackTo</code> telah ditinggalkan pada versi API <code>extensions/v1beta1</code> dan <code>apps/v1beta1</code>, dan sudah tidak didukung mulai versi API <code>apps/v1beta2</code>.
Sebagai gantinya, disarankan untuk menggunakan <code>kubectl rollout undo</code> sebagaimana diperkenalkan dalam <a href=#kembali-ke-revisi-sebelumnya>Kembali ke Revisi Sebelumnya</a>.</p><h3 id=batas-riwayat-revisi>Batas Riwayat Revisi</h3><p>Riwayat revisi Deployment disimpan dalam ReplicaSet yang dia kendalikan.</p><p><code>.spec.revisionHistoryLimit</code> adalah kolom opsional yang mengatur jumlah ReplicaSet lama yang dipertahankan
untuk memungkinkan pengembalian. ReplicaSet lama ini mengambil sumber daya dari <code>etcd</code> dan memunculkan keluaran
dari <code>kubectl get rs</code>. Konfigurasi tiap revisi Deployment disimpan pada ReplicaSet-nya; sehingga, begitu ReplicaSet lama dihapus,
kamu tidak mampu lagi membalikkan revisi Deployment-nya. Umumnya, 10 ReplicaSet lama akan dipertahankan,
namun nilai idealnya tergantung pada frekuensi dan stabilitas Deployment-deployment baru.</p><p>Lebih spesifik, mengisi kolom dengan nol berarti semua ReplicaSet lama dengan 0 replika akan dibersihkan.
Dalam kasus ini, rilis Deployment baru tidak dapat dibalikkan, sebab riwayat revisinya telah dibersihkan.</p><h3 id=terjeda>Terjeda</h3><p><code>.spec.paused</code> adalah kolom boolean opsional untuk menjeda dan melanjutkan Deployment. Perbedaan antara Deployment yang terjeda
dan yang tidak hanyalah perubahan apapun pada PodTemplateSpec Deployment terjeda tidak akan memicu rilis baru selama masih terjeda.
Deployment umumnya tidak terjeda saat dibuat.</p><h2 id=alternatif-untuk-deployment>Alternatif untuk Deployment</h2><h3 id=kubectl-rolling-update>kubectl rolling update</h3><p><a href=/id/docs/reference/generated/kubectl/kubectl-commands#rolling-update><code>kubectl rolling update</code></a> membarui Pod dan ReplicationController
dengan cara yang serupa. Namun, Deployments lebih disarankan karena deklaratif, berjalan di sisi server, dan punya fitur tambahan,
seperti pembalikkan ke revisi manapun sebelumnya bahkan setelah pembaruan rolling selesais.</p></div><div class=td-content style=page-break-before:always><h1 id=pg-6d72299952c37ca8cc61b416e5bdbcd4>2.4 - StatefulSet</h1><p>StatefulSet merupakan salah satu objek API <em>workload</em> yang digunakan untuk aplikasi <em>stateful</em>.</p><div class="alert alert-info note callout" role=alert><strong>Catatan:</strong> StatefulSet merupakan fitur stabil (GA) sejak versi 1.9.</div><p>Melakukan proses manajemen deployment dan <em>scaling</em> dari sebuah set <a class=glossary-tooltip title='Unit Kubernetes yang paling sederhana dan kecil. Sebuah Pod merepresentasikan sebuah set kontainer yang dijalankan pada kluster kamu.' data-toggle=tooltip data-placement=top href=/docs/concepts/workloads/pods/pod-overview/ target=_blank aria-label=Pods>Pods</a>, <em>serta menjamin mekanisme <em>ordering</em> dan keunikan</em> dari Pod ini.</p><p>Seperti halnya <a class=glossary-tooltip title='Mengelola aplikasi yang direplikasi di dalam klastermu.' data-toggle=tooltip data-placement=top href=/id/docs/concepts/workloads/controllers/deployment/ target=_blank aria-label=Deployment>Deployment</a>, sebuah StatefulSet akan melakukan proses manajemen Pod yang didasarkan pada spec container identik. Meskipun begitu tidak seperti sebuah Deployment, sebuah StatefulSet akan menjamin identitas setiap Pod yang ada. Pod ini akan dibuat berdasarkan spec yang sama, tetapi tidak dapat digantikan satu sama lainnya: setiap Pod memiliki identifier persisten yang akan di-maintain meskipun pod tersebut di (re)schedule.</p><p>Sebuah StatefulSet beroperasi dengan pola yang sama dengan Kontroler lainnya. Kamu dapat mendefinisikan state yang diinginkan pada objek StatefulSet, dan kontroler StatefulSet akan membuat update yang dibutuhkan dari <em>state</em> saat ini.</p><h2 id=menggunakan-statefulset>Menggunakan StatefulSet</h2><p>StatefulSet akan sangat bermanfaat apabila digunakan untuk aplikasi
yang membutuhkan salah satu atau beberapa fungsi berikut.</p><ul><li>Memiliki identitas jaringan unik yang stabil.</li><li>Penyimpanan persisten yang stabil.</li><li>Mekanisme <em>scaling</em> dan <em>deployment</em> yang <em>graceful</em> tertara berdasarkan urutan.</li><li>Mekanisme <em>rolling update</em> yang otomatis berdasarkan urutan.</li></ul><p>Stabil dalam poin-poin di atas memiliki arti yang sama dengan persisten pada
Pod saat dilakukan <em>(re)scheduling</em>. Jika suatu aplikasi tidak membutuhkan
identitas yang stabil atau <em>deployment</em> yang memiliki urutan, penghapusan, atau
mekanisme <em>scaling</em>, kamu harus melakukan <em>deploy</em> aplikasi dengan <em>controller</em> yang menyediakan
replika <em>stateless</em>. <em>Controller</em> seperti <a href=/id/docs/concepts/workloads/controllers/deployment/>Deployment</a> atau
<a href=/id/docs/concepts/workloads/controllers/replicaset/>ReplicaSet</a> akan lebih sesuai dengan kebutuhan kamu.</p><h2 id=keterbatasan>Keterbatasan</h2><ul><li>StatefulSet merupakan sumber daya beta sebelum 1.9 dan tidak tersedia
pada Kubernetes rilis sebelum versi 1.5.</li><li>Penyimpanan untuk sebuah Pod harus terlebih dahulu di-<em>provision</em> dengan menggunakan sebuah <a href=https://github.com/kubernetes/examples/tree/main/staging/persistent-volume-provisioning/README.md>Provisioner PersistentVolume</a> berdasarkan <code>storage class</code> yang dispesifikasikan, atau sudah ditentukan sebelumnya oleh administrator.</li><li>Menghapus dan/atau <em>scaling</em> sebuah StatefulSet <em>tidak akan</em> menghapus volume yang berkaitan dengan StatefulSet tersebut. Hal ini dilakukan untuk menjamin data yang disimpan, yang secara umum dinilai lebih berhaga dibandingkan dengan mekanisme penghapusan data secara otomatis pada sumber daya terkait.</li><li>StatefulSet saat ini membutuhkan sebuah <a href=/id/docs/concepts/services-networking/service/#headless-services>Headless Service</a> yang nantinya akan bertanggung jawab terhadap pada identitas jaringan pada Pod. Kamulah yang bertanggung jawab untuk membuat Service tersebut.</li><li>StatefulSet tidak menjamin terminasi Pod ketika sebuah StatefulSet dihapus. Untuk mendapatkan terminasi Pod yang terurut dan <em>graceful</em> pada StatefulSet, kita dapat melakukan <em>scale down</em> Pod ke 0 sebelum penghapusan.</li><li>Ketika menggunakan <a href=#mekanisme-strategi-update-rolling-update>Rolling Update</a> dengan
<a href=#kebijakan-manajemen-pod>Kebijakan Manajemen Pod</a> (<code>OrderedReady</code>) secara default,
hal ini memungkinkan untuk mendapatkan <em>state</em> yang lebih terperinci yang membutuhkan
<a href=#forced-rollback>mekanisme intervensi manual untuk perbaikan</a>.</li></ul><h2 id=komponen-komponen>Komponen-Komponen</h2><p>Contoh di bawah ini akna menunjukkan komponen-komponen penyusun StatefulSet.</p><ul><li>Sebuah Service Headless, dengan nama nginx, digunakan untuk mengontrol domain jaringan.</li><li>StatefulSet, dengan nama web, memiliki Spek yang mengindikasikan terdapat 3 replika Container yang akan dihidupkan pada Pod yang unik.</li><li><em>Field</em> <code>volumeClaimTemplates</code> akan menyediakan penyimpanan stabil menggunakan <a href=/id/docs/concepts/storage/persistent-volumes/>PersistentVolume</a> yang di-<em>provision</em> oleh sebuah Provisioner PersistentVolume.</li></ul><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Service<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>nginx<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>labels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>app</span>:<span style=color:#bbb> </span>nginx<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>ports</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>port</span>:<span style=color:#bbb> </span><span style=color:#666>80</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>web<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>clusterIP</span>:<span style=color:#bbb> </span>None<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>selector</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>app</span>:<span style=color:#bbb> </span>nginx<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:#00f;font-weight:700>---</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>apps/v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>StatefulSet<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>web<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>selector</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>matchLabels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>app</span>:<span style=color:#bbb> </span>nginx<span style=color:#bbb> </span><span style=color:#080;font-style:italic># harus sesuai dengan .spec.template.metadata.labels</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>serviceName</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;nginx&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>replicas</span>:<span style=color:#bbb> </span><span style=color:#666>3</span><span style=color:#bbb> </span><span style=color:#080;font-style:italic># nilai default-nya adalah 1</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>template</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>labels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>app</span>:<span style=color:#bbb> </span>nginx<span style=color:#bbb> </span><span style=color:#080;font-style:italic># harus sesuai dengan .spec.selector.matchLabels</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>terminationGracePeriodSeconds</span>:<span style=color:#bbb> </span><span style=color:#666>10</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>nginx<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>k8s.gcr.io/nginx-slim:0.8<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>ports</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span>- <span style=color:green;font-weight:700>containerPort</span>:<span style=color:#bbb> </span><span style=color:#666>80</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>web<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>volumeMounts</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>www<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>mountPath</span>:<span style=color:#bbb> </span>/usr/share/nginx/html<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>volumeClaimTemplates</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>www<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>accessModes</span>:<span style=color:#bbb> </span>[<span style=color:#bbb> </span><span style=color:#b44>&#34;ReadWriteOnce&#34;</span><span style=color:#bbb> </span>]<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>storageClassName</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;my-storage-class&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>resources</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>requests</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>storage</span>:<span style=color:#bbb> </span>1Gi<span style=color:#bbb>
</span></span></span></code></pre></div><h2 id=selector-pod><em>Selector</em> Pod</h2><p>Kamu harus menspesifikasikan <em>field</em> <code>.spec.selector</code> dari sebuah StatefulSet untuk menyesuaikan dengan label yang ada pada <code>.spec.template.metadata.labels</code>. Sebelum Kubernetes 1.8, <em>field</em> <code>.spec.selector</code> dapat diabaikan. Sejak versi 1.8 dan versi selanjutnya, apabila tidak terdapat <em>selector</em> Pod yang sesuai maka akan menghasilkan eror pada validasi pembuatan StatefulSet.</p><h2 id=identitas-pod>Identitas Pod</h2><p>Pod pada StatefulSet memiliki identitas unik yang tersusun berdasarkan skala ordinal, sebuah
identitas jaringan yang stabil, serta penyimpanan yang stabil. Identitas yang ada pada Pod
ini akan tetap melekat, meskipun Pod tersebut dilakukan <em>(re)schedule</em> pada Node yang berbeda.</p><h3 id=indeks-ordinal>Indeks Ordinal</h3><p>Untuk sebuah StatefulSet dengan N buah replika, setiap Pod di dalam StatefulSet akan
diberi nama pada suatu indeks ordinal tertentu, dari 0 hingga N-1, yang unik pada Set ini.</p><h3 id=id-jaringan-yang-stabil>ID Jaringan yang Stabil</h3><p>Setiap Pod di dalam StatefulSet memiliki <em>hostname</em> diturunkan dari nama SatetulSet tersebut
serta ordinal Pod tersebut. Pola pada <em>hostname</em> yang terbentuk adalah
<code>$(statefulset name)-$(ordinal)</code>. Contoh di atas akan menghasilkan tiga Pod
dengan nama <code>web-0,web-1,web-2</code>.
Sebuah StatefulSet dapat menggunakan sebuah <a href=/id/docs/concepts/services-networking/service/#headless-services>Service Headless</a>
untuk mengontrol domain dari Pod yang ada. Domain yang diatur oleh Service ini memiliki format:
<code>$(service name).$(namespace).svc.cluster.local</code>, dimana "cluster.local" merupakan
domain klaster.
Seiring dibuatnya setiap Pod, Pod tersebut akan memiliki subdomain DNS-nya sendiri, yang memiliki format:
<code>$(podname).$(governing service domain)</code>, dimana Service yang mengatur didefinisikan oleh
<em>field</em> <code>serviceName</code> pada StatefulSet.</p><p>Seperti sudah disebutkan di dalam bagian <a href=#keterbatasan>keterbatasan</a>, kamulah yang bertanggung jawab
untuk membuat <a href=/id/docs/concepts/services-networking/service/#headless-services>Service Headless</a>
yang bertanggung jawab terhadap identitas jaringan pada Pod.</p><p>Di sini terdapat beberapa contoh penggunaan Domain Klaster, nama Service,
nama StatefulSet, dan bagaimana hal tersebut berdampak pada nama DNS dari Pod StatefulSet.</p><table><thead><tr><th>Domain Klaster</th><th>Service (ns/nama)</th><th>StatefulSet (ns/nama)</th><th>Domain StatefulSet</th><th>DNS Pod</th><th>Hostname Pod</th></tr></thead><tbody><tr><td>cluster.local</td><td>default/nginx</td><td>default/web</td><td>nginx.default.svc.cluster.local</td><td>web-{0..N-1}.nginx.default.svc.cluster.local</td><td>web-{0..N-1}</td></tr><tr><td>cluster.local</td><td>foo/nginx</td><td>foo/web</td><td>nginx.foo.svc.cluster.local</td><td>web-{0..N-1}.nginx.foo.svc.cluster.local</td><td>web-{0..N-1}</td></tr><tr><td>kube.local</td><td>foo/nginx</td><td>foo/web</td><td>nginx.foo.svc.kube.local</td><td>web-{0..N-1}.nginx.foo.svc.kube.local</td><td>web-{0..N-1}</td></tr></tbody></table><div class="alert alert-info note callout" role=alert><strong>Catatan:</strong> Domain klaster akan diatur menjadi <code>cluster.local</code> kecuali
<a href=/id/docs/concepts/services-networking/dns-pod-service/>nilainya dikonfigurasi</a>.</div><h3 id=penyimpanan-stabil>Penyimpanan Stabil</h3><p>Kubernetes membuat sebuah <a href=/id/docs/concepts/storage/persistent-volumes/>PersistentVolume</a> untuk setiap
VolumeClaimTemplate. Pada contoh nginx di atas, setiap Pod akan menerima sebuah PersistentVolume
dengan StorageClass <code>my-storage-class</code> dan penyimpanan senilai 1 Gib yang sudah di-<em>provisioning</em>. Jika tidak ada StorageClass
yang dispesifikasikan, maka StorageClass <em>default</em> akan digunakan. Ketika sebuah Pod dilakukan <em>(re)schedule</em>
pada sebuah Node, <code>volumeMounts</code> akan me-<em>mount</em> PersistentVolumes yang terkait dengan
PersistentVolume Claim-nya. Perhatikan bahwa, PersistentVolume yang terkait dengan
PersistentVolumeClaim dari Pod tidak akan dihapus ketika Pod, atau StatefulSet dihapus.
Penghapusan ini harus dilakukan secara manual.</p><h3 id=label-pod-name>Label <em>Pod Name</em></h3><p>Ketika sebuah <em>controller</em> StatefulSet membuat sebuah Pod, <em>controller</em> ini akan menambahkan label, <code>statefulset.kubernetes.io/pod-name</code>,
yang akan diaktifkan pada nama Pod. Label ini akan mengizinkan kamu untuk meng-<em>attach</em> sebuah Service pada Pod spesifik tertentu.
di StatefulSet.</p><h2 id=jaminan-deployment-dan-mekanisme-scaling>Jaminan Deployment dan Mekanisme <em>Scaling</em></h2><ul><li>Untuk sebuah StatefulSet dengan N buah replika, ketika Pod di-<em>deploy</em>, Pod tersebut akan dibuat secara berurutan dengan urutan nilai {0..N-1}.</li><li>Ketika Pod dihapus, Pod tersebut akan dihentikan dengan urutan terbalik, yaitu {N-1..0}.</li><li>Sebelum operasi <em>scaling</em> diaplikasikan pada sebuah Pod, semua Pod sebelum Pod tersebut haruslah sudah dalam status Running dan Ready.</li><li>Sebelum sebuah Pod dihentikan, semua Pod setelah Pod tersebut haruslah sudah terlebih dahulu dihentikan.</li></ul><p>StatefulSet tidak boleh menspesifikasikan nilai dari <code>pod.Spec.TerminationGracePeriodSeconds</code> menjadi 0. Hal ini tidaklah aman dan tidak disarankan. Untuk penjelasan lebih lanjut, silakan lihat <a href=/docs/tasks/run-application/force-delete-stateful-set-pod/>penghapusan paksa Pod pada StatefulSet</a>.</p><p>Ketika contoh nginx di atas dibuat, tiga Pod akan di-<em>deploy</em> dengan urutan
web-0, web-1, web-2. web-1 tidak akan di-<em>deploy</em> sebelum web-0 berada dalam status
<a href=/docs/user-guide/pod-states/>Running dan Ready</a>, dan web-2 tidak akan di-<em>deploy</em> sebelum
web-1 berada dalam status Running dan Ready. Jika web-0 gagal, setelah web-1 berada dalam status Running and Ready,
tapi sebelum web-2 dibuat, maka web-2 tidak akan dibuat hingga web-0 sukses dibuat ulang dan
berada dalam status Running dan Ready.</p><p>Jika seorang pengguna akan melakukan mekanisme <em>scale</em> pada contoh di atas dengan cara melakukan <em>patch</em>,
pada StatefulSet sehingga <code>replicas=1</code>, maka web-2 akan dihentikan terlebih dahulu.
web-1 tidak akan dihentikan hingga web-2 benar-benar berhenti dan dihapus.
Jika web-0 gagal setelah web-2 diterminasi dan berada dalam status mati,
tetapi sebelum web-1 dihentikan, maka web-1 tidak akan dihentikan hingga
web-0 berada dalam status Running dan Ready.</p><h3 id=kebijakan-manajemen-pod>Kebijakan Manajemen Pod</h3><p>Pada Kubernetes versi 1.7 dan setelahnya, StatefulSet mengizinkan kamu untuk
melakukan mekanisme urutan tadi menjadi lebih fleksibel dengan tetap
menjamin keunikan dan identitas yang ada melalui <em>field</em> <code>.spec.podManagementPolicy</code>.</p><h4 id=manajemen-orderedready-pada-pod>Manajemen OrderedReady pada Pod</h4><p>Manajemen <code>OrderedReady</code> pada Pod merupakan nilai default dari StatefulSet.
Hal ini akan mengimplementasikan perilaku yang dijelaskan <a href=#jaminan-deployment-dan-mekanisme-scaling>di atas</a>.</p><h4 id=manajemen-pod-secara-paralel>Manajemen Pod secara Paralel</h4><p>Manajemen Pod secara <code>paralel</code> akan menyebabkan kontroler StatefulSet untuk
memulai atau menghentikan semua Pod yang ada secara paralel, dan tidak
menunggu Pod berada dalam status Running dan Ready atau sudah dihentikan secara menyeluruh
sebelum me-<em>launch</em> atau menghentikan Pod yang lain. Opsi ini hanya akan memengaruhi operasi
<em>scaling</em>. Operasi pembaruan tidak akan terpengaruh.</p><h2 id=strategi-update>Strategi Update</h2><p>Pada Kubernetes versi 1.7 dan setelahnya, <em>field</em> <code>.spec.updateStrategy</code> pada StatefulSet
memungkinkan-mu untuk melakukan konfigurasi dan menonaktifkan otomatisasi
<em>rolling updates</em> untuk container, label, resource request/limits, dan
annotation pada Pod yang ada di dalam sebuah StatefulSet.</p><h3 id=mekanisme-strategi-update-on-delete>Mekanisme Strategi Update <em>On Delete</em></h3><p>Mekanisme strategi update <code>OnDelete</code> mengimplementasikan perilaku legasi (versi 1.6 dan sebelumnya).
Ketika sebuah <em>field</em> <code>.spec.updateStrategy.type</code> pada StatefulSet diubah menjadi <code>OnDelete</code>
maka kontroler StatefulSet tidak akan secara otomatis melakukan update
pada Pod yang ada di dalam StatefulSet tersebut. Pengguna haruslah secara manual
melakukan penghapusan Pod agar kontroler membuat Pod baru yang mengandung modifikasi
yang dibuat pada <em>field</em> <code>.spec.template</code> StatefulSet.</p><h3 id=mekanisme-strategi-update-rolling-updates>Mekanisme Strategi Update <em>Rolling Updates</em></h3><p>Mekanisme strategi update <code>RollingUpdate</code> mengimplementasikan otomatisasi <em>rolling update</em>
untuk Pod yang ada pada StatefulSet. Strategi inilah yang diterapkan ketika <code>.spec.updateStrategy</code> tidak dispesifikasikan.
Ketika <em>field</em> <code>.spec.updateStrategy.type</code> diubah nilainya menjadi <code>RollingUpdate</code>, maka
kontroler StatefulSet akan menghapus dan membuat setiap Pod di dalam StatefulSet. Kemudian
hal ini akan diterapkan dengan urutan yang sama dengan mekanisme terminasi Pod (dari nilai ordinal terbesar ke terkecil),
yang kemudian akan melakukan update Pod satu per satu. Mekanisme ini akan memastikan sebuah Pod yang di-update
berada dalam status Running dan Ready sebelum meng-update Pod dengan nilai ordinal lebih rendah.</p><h4 id=mekanisme-strategi-update-dengan-partisi>Mekanisme Strategi Update dengan Partisi</h4><p>Mekanisme strategi update <code>RollingUpdate</code> dapat dipartisi, dengan cara menspesifikasikan nilai
dari <code>.spec.updateStrategy.rollingUpdate.partition</code>. Jika nilai dari <em>field</em> ini dispesifikasikan,
maka semua Pod dengan nilai ordinal yang lebih besar atau sama dengan nilai partisi akan diupdate ketika
nilai <code>.spec.template</code> pada StatefulSet diubah. Semua Pod dengan nilai ordinal yang lebih kecil
dari partisi tidak akan diupdate, dan, bahkan setelah Pod tersebut dihapus, Pod ini akan digantikan
dengan Pod versi sebelumnya. Jika nilai <code>.spec.updateStrategy.rollingUpdate.partition</code> lebih besar dari
nilai <code>.spec.replicas</code>, update pada <code>.spec.template</code> tidak akan dipropagasi pada Pod-Pod-nya.
Pada sebagian besar kasus, kamu tidak akan perlu menggunakan partisi, tapi hal tersebut
akan sangat berguna apabila kamu ingin mekakukan mekanisme update <em>canary</em>.</p><h4 id=mekanisme-strategi-update-yang-dipaksa-forced-rollback>Mekanisme Strategi Update yang Dipaksa (<em>Forced Rollback</em>)</h4><p>Ketika menggunakan strategi update <a href=#mekanisme-strategi-update-rolling-updates>Rolling Updates</a> dengan nilai default
<a href=#kebijakan-manajemen-pod>Kebijakan Manajemen Pod</a> (<code>OrderedReady</code>),
hal ini memungkinkan adanya kondisi <em>broken</em> yang membutuhkan intervensi secara manual
agar kondisi ini dapat diperbaiki.</p><p>Jika kamu melakukan update pada template Pod untuk konfigurasi
yang tidak pernah berada dalam status Running dan Ready (sebagai contohnya, apabila terdapat kode <em>binary</em> yang buruk atau error pada konfigurasi di level aplikasi),
maka StatefulSet akan menghentikan proses rollout dan berada dalam status <em>wait</em>.</p><p>Dalam kondisi ini, maka templat Pod tidak akan diubah secara otomatis pada konfigurasi sebelumnya
Hal ini terjadi karena adanya <a href=https://github.com/kubernetes/kubernetes/issues/67250>isu</a>,
StatefulSet akan tetap berada dalam kondisi <em>wait</em> untuk menunggu Pod yang bermasalah untuk menjadi Ready
(yang tidak akan terjadi) dan sebelum StatefulSet ini berusaha untuk melakukan <em>revert</em> pada konfigurasi sebelumnya.</p><p>Setelah melakukan mekanisme <em>revert</em> templat, kamu juga harus menghapus semua Pod di dalam
StatefulSet tersebut yang telah berusaha untuk menggunakan konfigurasi yang <em>broken</em>.
StatefulSet akan mulai membuat Pod dengan templat konfigurasi yang sudah di-<em>revert</em>.</p><h2 id=selanjutnya>Selanjutnya</h2><ul><li>Ikuti contoh yang ada pada <a href=/docs/tutorials/stateful-application/basic-stateful-set/>bagaimana cara melakukan deployi aplikasi stateful</a>.</li><li>Ikuti contoh yang ada pada <a href=/docs/tutorials/stateful-application/cassandra/>bagaimana cara melakukan deploy Cassandra dengan StatefulSets</a>.</li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-41600eb8b6631c88848156f381e9d588>2.5 - DaemonSet</h1><p>DaemonSet memastikan semua atau sebagian Node memiliki salinan sebuah Pod.
Ketika Node baru ditambahkan ke klaster, Pod ditambahkan ke Node tersebut.
Ketika Node dihapus dari klaster, Pod akan dibersihkan oleh <em>garbage collector</em>.
Menghapus DaemonSet akan menghapus semua Pod yang ia buat.</p><p>Beberapa penggunaan umum DaemonSet, yaitu:</p><ul><li>menjalankan <em>daemon</em> penyimpanan di klaster, seperti <code>glusterd</code>, <code>ceph</code>, di
setiap Node.</li><li>menjalankan <em>daemon</em> pengumpulan log di semua Node, seperti <code>fluentd</code> atau
<code>logstash</code>.</li><li>menjalankan <em>daemon</em> pemantauan Node di setiap Node, seperti <a href=https://github.com/prometheus/node_exporter>Prometheus Node Exporter</a>, <a href=https://github.com/Flowmill/flowmill-k8s/>Flowmill</a>, <a href=https://docs.sysdig.com>Sysdig Agent</a>, <code>collectd</code>, <a href=https://www.dynatrace.com/technologies/kubernetes-monitoring/>Dynatrace OneAgent</a>, <a href=https://docs.appdynamics.com/display/CLOUD/Container+Visibility+with+Kubernetes>AppDynamics Agent</a>, <a href=https://docs.datadoghq.com/agent/kubernetes/daemonset_setup/>Datadog agent</a>, <a href=https://docs.newrelic.com/docs/integrations/kubernetes-integration/installation/kubernetes-installation-configuration>New Relic agent</a>, Ganglia <code>gmond</code> atau <a href=https://www.instana.com/supported-integrations/kubernetes-monitoring/>Instana Agent</a>.</li></ul><p>Dalam kasus sederhana, satu DaemonSet, mencakup semua Node, akan digunakan untuk
setiap jenis <em>daemon</em>. Pengaturan yang lebih rumit bisa saja menggunakan lebih
dari satu DaemonSet untuk satu jenis <em>daemon</em>, tapi dengan <em>flag</em> dan/atau
permintaan cpu/memori yang berbeda untuk jenis <em>hardware</em> yang berbeda.</p><h2 id=menulis-spek-daemonset>Menulis Spek DaemonSet</h2><h3 id=buat-daemonset>Buat DaemonSet</h3><p>Kamu bisa definisikan DaemonSet dalam berkas YAML. Contohnya, berkas
<code>daemonset.yaml</code> di bawah mendefinisikan DaemonSet yang menjalankan <em>image</em> Docker
fluentd-elasticsearch:</p><div class=highlight><div class=copy-code-icon style=text-align:right><a href=https://raw.githubusercontent.com/kubernetes/website/main/content/id/examples/controllers/daemonset.yaml download=controllers/daemonset.yaml><code>controllers/daemonset.yaml</code></a>
<img src=/images/copycode.svg style=max-height:24px;cursor:pointer onclick='copyCode("controllers-daemonset-yaml")' title="Copy controllers/daemonset.yaml to clipboard"></img></div><div class=includecode id=controllers-daemonset-yaml><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>apps/v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>DaemonSet<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>fluentd-elasticsearch<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>namespace</span>:<span style=color:#bbb> </span>kube-system<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>labels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>k8s-app</span>:<span style=color:#bbb> </span>fluentd-logging<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>selector</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>matchLabels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>fluentd-elasticsearch<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>template</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>labels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>fluentd-elasticsearch<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>tolerations</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- <span style=color:green;font-weight:700>key</span>:<span style=color:#bbb> </span>node-role.kubernetes.io/master<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>operator</span>:<span style=color:#bbb> </span>Exists<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>effect</span>:<span style=color:#bbb> </span>NoSchedule<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>fluentd-elasticsearch<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>quay.io/fluentd_elasticsearch/fluentd:v2.5.2<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>resources</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>limits</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>            </span><span style=color:green;font-weight:700>memory</span>:<span style=color:#bbb> </span>200Mi<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>requests</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>            </span><span style=color:green;font-weight:700>cpu</span>:<span style=color:#bbb> </span>100m<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>            </span><span style=color:green;font-weight:700>memory</span>:<span style=color:#bbb> </span>200Mi<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>volumeMounts</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>varlog<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>mountPath</span>:<span style=color:#bbb> </span>/var/log<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>varlibdockercontainers<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>mountPath</span>:<span style=color:#bbb> </span>/var/lib/docker/containers<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>readOnly</span>:<span style=color:#bbb> </span><span style=color:#a2f;font-weight:700>true</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>terminationGracePeriodSeconds</span>:<span style=color:#bbb> </span><span style=color:#666>30</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>volumes</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>varlog<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>hostPath</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>path</span>:<span style=color:#bbb> </span>/var/log<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>varlibdockercontainers<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>hostPath</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>path</span>:<span style=color:#bbb> </span>/var/lib/docker/containers<span style=color:#bbb>
</span></span></span></code></pre></div></div></div><ul><li>Buat DaemonSet berdasarkan berkas YAML:</li></ul><pre tabindex=0><code>kubectl apply -f https://k8s.io/examples/controllers/daemonset.yaml
</code></pre><h3 id=field-wajib><em>Field</em> Wajib</h3><p>Seperti semua konfigurasi Kubernetes lainnya, DaemonSet membutuhkan <em>field</em>
<code>apiVersion</code>, <code>kind</code>, dan <code>metadata</code>. Untuk informasi umum tentang berkas konfigurasi, lihat dokumen <a href=/docs/user-guide/deploying-applications/>men-<em>deploy</em> aplikasi</a>,
<a href=/docs/tasks/>pengaturan kontainer</a>, dan <a href=/id/docs/concepts/overview/working-with-objects/object-management/>pengelolaan objek dengan kubectl</a>.</p><p>DaemonSet juga membutuhkan bagian <a href=https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#spec-and-status><code>.spec</code></a>.</p><h3 id=templat-pod>Templat Pod</h3><p><code>.spec.template</code> adalah salah satu <em>field</em> wajib di dalam <code>.spec</code>.</p><p><code>.spec.template</code> adalah sebuah <a href=/id/docs/concepts/workloads/pods/pod-overview/#templat-pod>templat Pod</a>. Skemanya benar-benar sama dengan <a href=/id/docs/concepts/workloads/pods/pod/>Pod</a>, kecuali bagian bahwa ia bersarang/<em>nested</em> dan tidak memiliki <code>apiVersion</code> atau <code>kind</code>.</p><p>Selain <em>field</em> wajib untuk Pod, templat Pod di DaemonSet harus
menspesifikasikan label yang sesuai (lihat <a href=#selektor-pod>selektor Pod</a>).</p><p>Templat Pod di DaemonSet harus memiliki <a href=/id/docs/concepts/workloads/pods/pod-lifecycle/#restart-policy><code>RestartPolicy</code></a>
yang bernilai <code>Always</code>, atau tidak dispesifikasikan, sehingga <em>default</em> menjadi <code>Always</code>.
DaemonSet dengan nilai <code>Always</code> membuat Pod akan selalu di-<em>restart</em> saat kontainer
keluar/berhenti atau terjadi <em>crash</em>.</p><h3 id=selektor-pod>Selektor Pod</h3><p><em>Field</em> <code>.spec.selector</code> adalah selektor Pod. Cara kerjanya sama dengan <code>.spec.selector</code> pada <a href=/docs/concepts/jobs/run-to-completion-finite-workloads/>Job</a>.</p><p>Pada Kubernetes 1.8, kamu harus menspesifikasikan selektor Pod yang cocok dengan label pada <code>.spec.template</code>.
Selektor Pod tidak akan lagi diberi nilai <em>default</em> ketika dibiarkan kosong. Nilai <em>default</em> selektor tidak
cocok dengan <code>kubectl apply</code>. Juga, sesudah DaemonSet dibuat, <code>.spec.selector</code> tidak dapat diubah.
Mengubah selektor Pod dapat menyebabkan Pod <em>orphan</em> yang tidak disengaja, dan membingungkan pengguna.</p><p>Objek <code>.spec.selector</code> memiliki dua <em>field</em>:</p><ul><li><code>matchLabels</code> - bekerja seperti <code>.spec.selector</code> pada <a href=/id/docs/concepts/workloads/controllers/replicationcontroller/>ReplicationController</a>.</li><li><code>matchExpressions</code> - bisa digunakan untuk membuat selektor yang lebih canggih
dengan mendefinisikan <em>key</em>, daftar <em>value</em> dan operator yang menyatakan
hubungan antara <em>key</em> dan <em>value</em>.</li></ul><p>Ketika keduanya dispesifikasikan hasilnya diperoleh dari operasi AND.</p><p>Jika <code>.spec.selector</code> dispesifikasikan, nilainya harus cocok dengan <code>.spec.template.metadata.labels</code>. Konfigurasi yang tidak cocok akan ditolak oleh API.</p><p>Selain itu kamu tidak seharusnya membuat Pod apapun yang labelnya cocok dengan
selektor tersebut, entah secara langsung, via DaemonSet lain, atau via <em>workload resource</em> lain seperti ReplicaSet.
Jika kamu coba buat, <a class=glossary-tooltip title='Kontrol tertutup yang mengawasi kondisi bersama dari klaster melalui apiserver dan membuat perubahan yang mencoba untuk membawa kondisi saat ini ke kondisi yang diinginkan.' data-toggle=tooltip data-placement=top href=/id/docs/concepts/architecture/controller/ target=_blank aria-label=Pengontrol>Pengontrol</a> DaemonSet akan
berpikir bahwa Pod tersebut dibuat olehnya. Kubernetes tidak akan menghentikan
kamu melakukannya. Contoh kasus di mana kamu mungkin melakukan ini dengan
membuat Pod dengan nilai yang berbeda di sebuah Node untuk <em>testing</em>.</p><h3 id=menjalankan-pod-di-sebagian-node>Menjalankan Pod di Sebagian Node</h3><p>Jika kamu menspesifikasikan <code>.spec.template.spec.nodeSelector</code>, maka <em>controller</em> DaemonSet akan
membuat Pod pada Node yang cocok dengan <a href=/id/docs/concepts/scheduling-eviction/assign-pod-node/>selektor
Node</a>. Demikian juga, jika kamu menspesifikasikan <code>.spec.template.spec.affinity</code>,
maka <em>controller</em> DaemonSet akan membuat Pod pada Node yang cocok dengan <a href=/id/docs/concepts/scheduling-eviction/assign-pod-node/>Node affinity</a>.
Jika kamu tidak menspesifikasikan sama sekali, maka <em>controller</em> DaemonSet akan
membuat Pod pada semua Node.</p><h2 id=bagaimana-pod-daemon-dijadwalkan>Bagaimana Pod Daemon Dijadwalkan</h2><h3 id=dijadwalkan-oleh-default-scheduler>Dijadwalkan oleh <em>default scheduler</em></h3><div style=margin-top:10px;margin-bottom:10px><b>FEATURE STATE:</b> <code>Kubernetes 1.17 [stable]</code></div><p>DaemonSet memastikan bahwa semua Node yang memenuhi syarat menjalankan salinan
Pod. Normalnya, Node yang menjalankan Pod dipilih oleh <em>scheduler</em> Kubernetes.
Namun, Pod DaemonSet dibuat dan dijadwalkan oleh <em>controller</em> DaemonSet. Hal ini
mendatangkan masalah-masalah berikut:</p><ul><li>Inkonsistensi perilaku Pod: Pod normal yang menunggu dijadwalkan akan dibuat
dalam keadaan <code>Pending</code>, tapi Pod DaemonSet tidak seperti itu. Ini
membingungkan untuk pengguna.</li><li><a href=/id/docs/concepts/configuration/pod-priority-preemption/>Pod preemption</a>
ditangani oleh <em>default scheduler</em>. Ketika <em>preemption</em> dinyalakan,
<em>controller</em> DaemonSet akan membuat keputusan penjadwalan tanpa
memperhitungkan prioritas Pod dan <em>preemption</em>.</li></ul><p><code>ScheduleDaemonSetPods</code> mengizinkan kamu untuk menjadwalkan DaemonSet
menggunakan <em>default scheduler</em> daripada <em>controller</em> DaemonSet, dengan
menambahkan syarat <code>NodeAffinity</code> pada Pod DaemonSet daripada syarat
<code>.spec.nodeName</code>. Kemudian, <em>default scheduler</em> digunakan untuk mengikat Pod ke
host target. Jika afinitas Node dari Pod DaemonSet sudah ada, maka ini
akan diganti. <em>Controller DaemonSet</em> hanya akan melakukan operasi-operasi ini
ketika membuat atau mengubah Pod DaemonSet, dan tidak ada perubahan yang terjadi
pada <code>spec.template</code> DaemonSet.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>nodeAffinity</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>requiredDuringSchedulingIgnoredDuringExecution</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>nodeSelectorTerms</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:green;font-weight:700>matchFields</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- <span style=color:green;font-weight:700>key</span>:<span style=color:#bbb> </span>metadata.name<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>operator</span>:<span style=color:#bbb> </span>In<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>values</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span>- target-host-name<span style=color:#bbb>
</span></span></span></code></pre></div><p>Sebagai tambahan, <em>toleration</em> <code>node.kubernetes.io/unschedulable:NoSchedule</code>
ditambahkan secara otomatis pada Pod DaemonSet. <em>Default scheduler</em> akan
mengabaikan Node <code>unschedulable</code> ketika menjadwalkan Pod DaemonSet.</p><h3 id=taint-dan-toleration><em>Taint</em> dan <em>Toleration</em></h3><p>Meskipun Pod Daemon menghormati
<a href=/id/docs/concepts/configuration/taint-and-toleration>taint dan toleration</a>,
<em>toleration</em> berikut ini akan otomatis ditambahkan ke Pod DaemonSet sesuai
dengan fitur yang bersangkutan.</p><table><thead><tr><th><em>Toleration Key</em></th><th><em>Effect</em></th><th>Versi</th><th>Deskripsi</th></tr></thead><tbody><tr><td><code>node.kubernetes.io/not-ready</code></td><td>NoExecute</td><td>1.13+</td><td>Pod DaemonSet tidak akan menjadi <em>evicted</em> ketika ada masalah Node seperti partisi jaringan.</td></tr><tr><td><code>node.kubernetes.io/unreachable</code></td><td>NoExecute</td><td>1.13+</td><td>Pod DaemonSet tidak akan menjadi <em>evicted</em> ketika ada masalah Node seperti partisi jaringan.</td></tr><tr><td><code>node.kubernetes.io/disk-pressure</code></td><td>NoSchedule</td><td>1.8+</td><td></td></tr><tr><td><code>node.kubernetes.io/memory-pressure</code></td><td>NoSchedule</td><td>1.8+</td><td></td></tr><tr><td><code>node.kubernetes.io/unschedulable</code></td><td>NoSchedule</td><td>1.12+</td><td>Pod DaemonSet mentoleransi atribut <code>unschedulable</code> <em>default scheduler</em>.</td></tr><tr><td><code>node.kubernetes.io/network-unavailable</code></td><td>NoSchedule</td><td>1.12+</td><td>Pod DaemonSet yang menggunakan jaringan host mentoleransi atribut <code>network-unavailable</code> <em>default scheduler</em>.</td></tr></tbody></table><h2 id=berkomunikasi-dengan-pod-daemon>Berkomunikasi dengan Pod Daemon</h2><p>Beberapa pola yang mungkin digunakan untuk berkomunikasi dengan Pod dalam DaemonSet, yaitu:</p><ul><li><strong>Push</strong>: Pod dalam DaemonSet diatur untuk mengirim pembaruan status ke servis lain,
contohnya <em>stats database</em>. Pod ini tidak memiliki klien.</li><li><strong>IP Node dan Konvensi Port</strong>: Pod dalam DaemonSet dapat menggunakan <code>hostPort</code>, sehingga Pod dapat diakses menggunakan IP Node. Klien tahu daftar IP Node dengan suatu cara, dan tahu port berdasarkan konvensi.</li><li><strong>DNS</strong>: Buat <a href=/id/docs/concepts/services-networking/service/#headless-services>headless service</a> dengan Pod selektor yang sama,
dan temukan DaemonSet menggunakan <em>resource</em> <code>endpoints</code> atau mengambil beberapa A <em>record</em> dari DNS.</li><li><strong>Service</strong>: Buat Servis dengan Pod selektor yang sama, dan gunakan Servis untuk mengakses <em>daemon</em> pada
Node random. (Tidak ada cara mengakses spesifik Node)</li></ul><h2 id=melakukan-pembaruan-daemonset>Melakukan Pembaruan DaemonSet</h2><p>Jika label Node berubah, DaemonSet akan menambahkan Pod ke Node cocok yang baru dan menghapus Pod dari
Node tidak cocok yang baru.</p><p>Kamu bisa mengubah Pod yang dibuat DaemonSet. Namun, Pod tidak membolehkan perubahan semua <em>field</em>.
Perlu diingat, <em>controller</em> DaemonSet akan menggunakan templat yang asli di waktu selanjutnya
Node baru (bahkan dengan nama yang sama) dibuat.</p><p>Kamu bisa menghapus DaemonSet. Jika kamu spesifikasikan <code>--cascade=false</code> dengan <code>kubectl</code>, maka
Pod akan dibiarkan pada Node. Jika kamu pada waktu kemudian membuat DaemonSet baru dengan selektor
yang sama, DaemonSet yang baru akan mengadopsi Pod yang sudah ada. Jika ada Pod yang perlu diganti,
DaemonSet akan mengganti sesuai dengan <code>updateStrategy</code>.</p><p>Kamu bisa <a href=/docs/tasks/manage-daemon/update-daemon-set/>melakukan rolling update</a> pada DaemonSet.</p><h2 id=alternatif-daemonset>Alternatif DaemonSet</h2><h3 id=init-scripts><em>Init Scripts</em></h3><p>Kamu mungkin menjalankan proses <em>daemon</em> dengan cara menjalankan mereka langsung pada Node (e.g.
menggunakan <code>init</code>, <code>upstartd</code>, atau <code>systemd</code>). Tidak ada salahnya seperti itu. Namun, ada beberapa
keuntungan menjalankan proses <em>daemon</em> via DaemonSet.</p><ul><li>Kemampuan memantau dan mengatur log <em>daemon</em> dengan cara yang sama dengan aplikasi.</li><li>Bahasa dan alat Konfigurasi yang sama (e.g. Templat Pod, <code>kubectl</code>) untuk <em>daemon</em> dan aplikasi.</li><li>Menjalankan <em>daemon</em> dalam kontainer dengan batasan <em>resource</em> meningkatkan isolasi antar <em>daemon</em> dari
kontainer aplikasi. Namun, hal ini juga bisa didapat dengan menjalankan <em>daemon</em> dalam kontainer tapi
tanpa Pod (e.g. dijalankan langsung via Docker).</li></ul><h3 id=pod-polosan>Pod Polosan</h3><p>Dimungkinkan untuk membuat Pod langsung dengan menspesifikasikan Node mana untuk dijalankan. Namun,
DaemonSet akan menggantikan Pod yang untuk suatu alasan dihapus atau dihentikan, seperti pada saat
kerusakan Node atau pemeliharaan Node yang mengganggu seperti pembaruan <em>kernel</em>. Oleh karena itu, kamu
perlu menggunakan DaemonSet daripada membuat Pod satu per satu.</p><h3 id=pod-statis>Pod Statis</h3><p>Dimungkinkan untuk membuat Pod dengan menulis sebuah berkas ke direktori tertentu yang di-<em>watch</em> oleh Kubelet.
Pod ini disebut dengan istilah <a href=/docs/concepts/cluster-administration/static-pod/>Pod statis</a>.
Berbeda dengan DaemonSet, Pod statis tidak dapat dikelola menggunakan kubectl atau klien API Kubernetes
yang lain. Pod statis tidak bergantung kepada apiserver, membuat Pod statis berguna pada kasus-kasus
<em>bootstrapping</em> klaster.</p><h3 id=deployment>Deployment</h3><p>DaemonSet mirip dengan <a href=/id/docs/concepts/workloads/controllers/deployment/>Deployment</a> sebab mereka
sama-sama membuat Pod, dan Pod yang mereka buat punya proses yang seharusnya tidak berhenti (e.g. peladen web,
peladen penyimpanan)</p><p>Gunakan Deployment untuk layanan <em>stateless</em>, seperti <em>frontend</em>, di mana proses <em>scaling</em> naik
dan turun jumlah replika dan <em>rolling update</em> lebih penting daripada mengatur secara tepat di
host mana Pod berjalan. Gunakan DaemonSet ketika penting untuk satu salinan Pod
selalu berjalan di semua atau sebagian host, dan ketika Pod perlu berjalan
sebelum Pod lainnya.</p></div><div class=td-content style=page-break-before:always><h1 id=pg-9add0d2120634b63073ad08dc8683bd6>2.6 - Garbage Collection</h1><p>Peran daripada <em>garbage collector</em> Kubernetes adalah untuk menghapus objek tertentu yang sebelumnya mempunyai pemilik, tetapi tidak lagi mempunyai pemilik.</p><h2 id=pemilik-dan-dependen>Pemilik dan dependen</h2><p>Beberapa objek Kubernetes adalah pemilik dari objek lainnya. Sebagai contoh, sebuah ReplicaSet adalah pemilik dari sekumpulan Pod. Objek-objek yang dimiliki disebut <em>dependen</em> dari objek pemilik. Setiap objek dependen memiliki sebuah kolom <code>metadata.ownerReferences</code> yang menunjuk ke objek pemilik.</p><p>Terkadang, Kubernetes menentukan nilai dari <code>ownerReference</code> secara otomatis. Sebagai contoh, ketika kamu membuat sebuah ReplicaSet, Kubernetes secara otomatis akan menentukan tiap kolom <code>ownerReference</code> dari tiap Pod di dalam ReplicaSet. Pada versi 1.8, Kubernetes secara otomatis menentukan nilai dari <code>ownerReference</code> untuk objek yang diciptakan atau diadopsi oleh ReplicationController, ReplicaSet, StatefulSet, DaemonSet, Deployment, Job dan CronJob.</p><p>Kamu juga bisa menspesifikasikan hubungan antara pemilik dan dependen dengan cara menentukan kolom <code>ownerReference</code> secara manual.</p><p>Berikut adalah berkas untuk sebuah ReplicaSet yang memiliki tiga Pod:</p><div class=highlight><div class=copy-code-icon style=text-align:right><a href=https://raw.githubusercontent.com/kubernetes/website/main/content/id/examples/controllers/replicaset.yaml download=controllers/replicaset.yaml><code>controllers/replicaset.yaml</code></a>
<img src=/images/copycode.svg style=max-height:24px;cursor:pointer onclick='copyCode("controllers-replicaset-yaml")' title="Copy controllers/replicaset.yaml to clipboard"></img></div><div class=includecode id=controllers-replicaset-yaml><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>apps/v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>ReplicaSet<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>my-repset<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>replicas</span>:<span style=color:#bbb> </span><span style=color:#666>3</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>selector</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>matchLabels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>pod-is-for</span>:<span style=color:#bbb> </span>garbage-collection-example<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>template</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>labels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>pod-is-for</span>:<span style=color:#bbb> </span>garbage-collection-example<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>nginx<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>nginx</span></span></code></pre></div></div></div><p>Jika kamu membuat ReplicaSet tersebut dan kemudian melihat metadata Pod, kamu akan melihat kolom OwnerReferences:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl apply -f https://k8s.io/examples/controllers/replicaset.yaml
</span></span><span style=display:flex><span>kubectl get pods --output<span style=color:#666>=</span>yaml
</span></span></code></pre></div><p>Keluaran menunjukkan bahwa pemilik Pod adalah sebuah ReplicaSet bernama <code>my-repset</code>:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>apiVersion: v1
</span></span><span style=display:flex><span>kind: Pod
</span></span><span style=display:flex><span>metadata:
</span></span><span style=display:flex><span>  ...
</span></span><span style=display:flex><span>  ownerReferences:
</span></span><span style=display:flex><span>  - apiVersion: apps/v1
</span></span><span style=display:flex><span>    controller: <span style=color:#a2f>true</span>
</span></span><span style=display:flex><span>    blockOwnerDeletion: <span style=color:#a2f>true</span>
</span></span><span style=display:flex><span>    kind: ReplicaSet
</span></span><span style=display:flex><span>    name: my-repset
</span></span><span style=display:flex><span>    uid: d9607e19-f88f-11e6-a518-42010a800195
</span></span><span style=display:flex><span>  ...
</span></span></code></pre></div><div class="alert alert-info note callout" role=alert><strong>Catatan:</strong><p>Referensi pemilik lintas <em>namespace</em> tidak diperbolehkan oleh desain. Artinya:</p><ol><li>Dependen dengan cakupan <em>namespace</em> hanya bisa menspesifikasikan pemilik jika berada di <em>namespace</em> yang sama, dan pemilik memiliki cakupan klaster.</li><li>Dependen dengan cakupan klaster hanya bisa menspesifikasikan pemilik yang memiliki cakupan klaster, tetapi tidak berlaku untuk pemilik yang memiliki cakupan klaster.</li></ol></div><h2 id=mengontrol-bagaimana-garbage-collector-menghapus-dependen>Mengontrol bagaimana <em>garbage collector</em> menghapus dependen</h2><p>Ketika kamu menghapus sebuah objek, kamu bisa menspesifikasi apakah dependen objek tersebut juga dihapus secara otomatis. Menghapus dependen secara otomatis disebut <em>cascading deletion</em>. <em>Cascading deletion</em> memiliki dua mode: <em>background</em> dan <em>foreground</em>.</p><h3 id=foreground-cascading-deletion>Foreground cascading deletion</h3><p>Pada <em>foreground cascading deletion</em>, pertama objek utama akan memasuki keadaan "<em>deletion in progress</em>". Pada saat keadaan "<em>deletion in progress</em>", kondisi-kondisi berikut bernilai benar:</p><ul><li>Objek masih terlihat via REST API</li><li><code>deletionTimestamp</code> objek telah ditentukan</li><li><code>metadata.finalizers</code> objek memiliki nilai <code>foregroundDeletion</code>.</li></ul><p>Ketika dalam keadaan "<em>deletion in progress</em>", <em>garbage collector</em> menghapus dependen dari objek. Ketika <em>garbage collector</em> telah menghapus semua "<em>blocking</em>" dependen (objek dengan <code>ownerReference.blockOwnerDeleteion=true</code>), <em>garbage collector</em> menghapus objek pemilik.</p><p>Jika kolom <code>ownerReferences</code> sebuah objek ditentukan oleh sebuah <em>controller</em> (seperti Deployment atau Replicaset), <code>blockOwnerDeletion</code> akan ditentukan secara otomatis dan kamu tidak perlu memodifikasi kolom ini secara manual.</p><h3 id=background-cascading-deletion>Background cascading deletion</h3><p>Pada <em>background cascading deletion</em>, Kubernetes segera menghapus objek pemilik dan <em>garbage collector</em> kemudian menghapus dependen pada <em>background</em>.</p><h3 id=mengatur-kebijakan-cascading-deletion>Mengatur kebijakan <em>cascading deletion</em></h3><p>Untuk mengatur kebijakan <em>cascading deletion</em>, tambahkan kolom <code>propagationPolicy</code> pada argumen <code>deleteOptions</code> ketika menghapus sebuah Object. Nilai yang dapat digunakan adalah "Orphan", "Foreground", atau "Background".</p><p>Sebelum Kubernetes 1.9, kebijakan <em>default</em> dari <em>garbage collection</em> untuk banyak <em>resource controller</em> adalah <strong>orphan</strong>. Ini meliputi ReplicationController, ReplicaSet, StatefulSet, DaemonSet, dan Deployment. Untuk jenis pada kelompok versi <code>extensions/v1beta1</code>, <code>apps/v1beta1</code>, dan <code>apps/v1beta2</code>, kecuali kamu menspesifikasikan dengan cara lain, objek dependen adalah <em>orphan</em> secara <em>default</em>. Pada Kubernetes 1.9, untuk semua jenis pada kelompok versi <code>apps/v1</code>, objek dependen dihapus secara <em>default</em>.</p><p>Berikut sebuah contoh yang menghapus dependen di <em>background</em>:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl proxy --port<span style=color:#666>=</span><span style=color:#666>8080</span>
</span></span><span style=display:flex><span>curl -X DELETE localhost:8080/apis/apps/v1/namespaces/default/replicasets/my-repset <span style=color:#b62;font-weight:700>\
</span></span></span><span style=display:flex><span><span style=color:#b62;font-weight:700></span>-d <span style=color:#b44>&#39;{&#34;kind&#34;:&#34;DeleteOptions&#34;,&#34;apiVersion&#34;:&#34;v1&#34;,&#34;propagationPolicy&#34;:&#34;Background&#34;}&#39;</span> <span style=color:#b62;font-weight:700>\
</span></span></span><span style=display:flex><span><span style=color:#b62;font-weight:700></span>-H <span style=color:#b44>&#34;Content-Type: application/json&#34;</span>
</span></span></code></pre></div><p>Berikut adalah sebuah contoh yang mengapus dependen di <em>foreground</em>:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl proxy --port<span style=color:#666>=</span><span style=color:#666>8080</span>
</span></span><span style=display:flex><span>curl -X DELETE localhost:8080/apis/apps/v1/namespaces/default/replicasets/my-repset <span style=color:#b62;font-weight:700>\
</span></span></span><span style=display:flex><span><span style=color:#b62;font-weight:700></span>-d <span style=color:#b44>&#39;{&#34;kind&#34;:&#34;DeleteOptions&#34;,&#34;apiVersion&#34;:&#34;v1&#34;,&#34;propagationPolicy&#34;:&#34;Foreground&#34;}&#39;</span> <span style=color:#b62;font-weight:700>\
</span></span></span><span style=display:flex><span><span style=color:#b62;font-weight:700></span>-H <span style=color:#b44>&#34;Content-Type: application/json&#34;</span>
</span></span></code></pre></div><p>Berikut adalah contoh <em>orphan</em> yang dependen:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl proxy --port<span style=color:#666>=</span><span style=color:#666>8080</span>
</span></span><span style=display:flex><span>curl -X DELETE localhost:8080/apis/apps/v1/namespaces/default/replicasets/my-repset <span style=color:#b62;font-weight:700>\
</span></span></span><span style=display:flex><span><span style=color:#b62;font-weight:700></span>-d <span style=color:#b44>&#39;{&#34;kind&#34;:&#34;DeleteOptions&#34;,&#34;apiVersion&#34;:&#34;v1&#34;,&#34;propagationPolicy&#34;:&#34;Orphan&#34;}&#39;</span> <span style=color:#b62;font-weight:700>\
</span></span></span><span style=display:flex><span><span style=color:#b62;font-weight:700></span>-H <span style=color:#b44>&#34;Content-Type: application/json&#34;</span>
</span></span></code></pre></div><p>kubectl juga mendukung <em>cascading deletion</em>. Untuk menghapus dependen secara otomatis dengan menggunakan kubectl, Ubah nilai <code>--cascade</code> menjadi <em>true</em>. Untuk <em>orphan</em> yang dependen, ubah nilai <code>--cascade</code> menjadi <em>false</em>. Nilai <em>default</em> untuk <code>--cascade</code> adalah <em>true</em>.</p><p>Berikut adalah contoh yang membuat dependen ReplicaSet menjadi <em>orphan</em>:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl delete replicaset my-repset --cascade<span style=color:#666>=</span><span style=color:#a2f>false</span>
</span></span></code></pre></div><h3 id=catatan-tambahan-untuk-deployment>Catatan tambahan untuk Deployment</h3><p>Sebelum versi 1.7, ketika menggunakan <em>cascading delete</em> dengan Deployment, kamu <em>harus</em> menggunakan <code>propagationPolicy: Foreground</code> untuk menghapus tidak hanya ReplicaSet yang telah diciptakan, tetapi juga Pod yang mereka miliki. Jika tipe <em>propagationPolicy</em> tidak digunakan, hanya ReplicaSet yag akan dihapus, dan Pod akan menjadi <em>orphan</em>. Lihat <a href=https://github.com/kubernetes/kubeadm/issues/149#issuecomment-284766613>kubeadm/#149</a> untuk informasi lebih lanjut.</p><h2 id=isu-yang-diketahui>Isu yang diketahui</h2><p>Ditemukan pada <a href=https://github.com/kubernetes/kubernetes/issues/26120>#26120</a></p><h2 id=selanjutnya>Selanjutnya</h2><p><a href=https://git.k8s.io/community/contributors/design-proposals/api-machinery/garbage-collection.md>Dokumen Desain 1</a></p><p><a href=https://git.k8s.io/community/contributors/design-proposals/api-machinery/synchronous-garbage-collection.md>Dokumen Desain 2</a></p></div><div class=td-content style=page-break-before:always><h1 id=pg-4de50a37ebb6f2340484192126cb7a04>2.7 - Pengendali TTL untuk Sumber Daya yang Telah Selesai Digunakan</h1><div style=margin-top:10px;margin-bottom:10px><b>FEATURE STATE:</b> <code>Kubernetes v1.12 [alpha]</code></div><p>Pengendali TTL menyediakan mekanisme TTL yang membatasi umur dari suatu
objek sumber daya yang telah selesai digunakan. Pengendali TTL untuk saat ini hanya menangani
<a class=glossary-tooltip title='Tugas terbatas atau bertumpuk (batch) yang berjalan sampai selesai.' data-toggle=tooltip data-placement=top href=/docs/concepts/workloads/controllers/job/ target=_blank aria-label=Jobs>Jobs</a>,
dan nantinya bisa saja digunakan untuk sumber daya lain yang telah selesai digunakan
misalnya saja Pod atau sumber daya khusus (<em>custom resource</em>) lainnya.</p><p>Peringatan Fitur Alpha: fitur ini tergolong datam fitur alpha dan dapat diaktifkan dengan
<a href=/docs/reference/command-line-tools-reference/feature-gates/><em>feature gate</em></a>
<code>TTLAfterFinished</code>.</p><h2 id=pengendali-ttl>Pengendali TTL</h2><p>Pengendali TTL untuk saat ini hanya mendukung Job. Sebuah operator klaster
dapat menggunakan fitur ini untuk membersihkan Job yang telah dieksekusi (baik
<code>Complete</code> atau <code>Failed</code>) secara otomatis dengan menentukan <em>field</em>
<code>.spec.ttlSecondsAfterFinished</code> pada Job, seperti yang tertera di
<a href=/id/docs/concepts/workloads/controllers/job/#clean-up-finished-jobs-automatically>contoh</a>.
Pengendali TTL akan berasumsi bahwa sebuah sumber daya dapat dihapus apabila
TTL dari sumber daya tersebut telah habis. Proses dihapusnya sumber daya ini
dilakukan secara berantai, dimana sumber daya lain yang
berkaitan akan ikut terhapus. Perhatikan bahwa ketika sebuah sumber daya dihapus,
siklus hidup yang ada akan menjaga bahwa <em>finalizer</em> akan tetap dijalankan sebagaimana mestinya.</p><p>Waktu TTL dalam detik dapat diatur kapan pun. Terdapat beberapa contoh untuk mengaktifkan <em>field</em>
<code>.spec.ttlSecondsAfterFinished</code> pada suatu Job:</p><ul><li>Spesifikasikan <em>field</em> ini pada <em>manifest</em> sumber daya, sehingga Job akan
dihapus secara otomatis beberapa saat setelah selesai dieksekusi.</li><li>Aktifkan <em>field</em> ini pada sumber daya yang sudah selesai dieksekusi untuk
menerapkan fitur ini.</li><li>Gunakan sebuah
<a href=/docs/reference/access-authn-authz/extensible-admission-controllers/#admission-webhooks>mengubah (<em>mutating</em>) _admission)</a>
untuk mengaktifkan <em>field</em> ini secara dinamis pada saat pembuatan sumber daya.
Administrator klaster dapat menggunakan hal ini untuk menjamin kebijakan (<em>policy</em>) TTL pada
sumber daya yang telah selesai digunakan.</li><li>Gunakan sebuah
<a href=/docs/reference/access-authn-authz/extensible-admission-controllers/#admission-webhooks>mengubah (<em>mutating</em>) _admission</a>
untuk mengaktifkan <em>field</em> ini secara dinamis setelah sumber daya
selesai digunakan dan TTL didefinisikan sesuai dengan status, label, atau hal lain
yang diinginkan.</li></ul><h2 id=peringatan>Peringatan</h2><h3 id=mengubah-ttl-detik>Mengubah TTL Detik</h3><p>Perhatikan bahwa periode TTL, yaitu <em>field</em> <code>.spec.ttlSecondsAfterFinished</code> pada Job,
dapat dimodifikasi baik setelah sumber daya dibuat atau setelah selesai digunakan.
Meskipun begitu, setelah Job dapat dihapus (TTL sudah habis), sistem tidak akan
menjamin Job tersebut akan tetap ada, meskipun nilai TTL berhasil diubah.</p><h3 id=time-skew><em>Time Skew</em></h3><p>Karena pengendali TTL menggunakan cap waktu (<em>timestamp</em>) yang disimpan di sumber daya
Kubernetes untuk menentukan apakah TTL sudah habis atau belum, fitur ini tidak sensitif
terhadap <em>time skew</em> yang ada pada klaster dan bisa saja menghapus objek pada waktu yang salah
bagi objek tersebut akibat adanya <em>time skew</em>.</p><p>Pada Kubernetes, NTP haruslah dilakukan pada semua node untuk mecegah adanya <em>time skew</em>
(lihat <a href=https://github.com/kubernetes/kubernetes/issues/6159#issuecomment-93844058>#6159</a>).
<em>Clock</em> tidak akan selalu tepat, meskipun begitu perbedaan yang ada haruslah diminimalisasi.
Perhatikan bahwa hal ini dapat terjadi apabila TTL diaktifkan dengan nilai selain 0.</p><h2 id=selanjutnya>Selanjutnya</h2><p><a href=/id/docs/concepts/workloads/controllers/jobs-run-to-completion/#clean-up-finished-jobs-automatically>Membersikan Job secara Otomatis</a></p><p><a href=https://github.com/kubernetes/enhancements/blob/master/keps/sig-apps/592-ttl-after-finish/README.md>Dokumentasi Rancangan</a></p></div><div class=td-content style=page-break-before:always><h1 id=pg-cc7cc3c4907039d9f863162e20bfbbef>2.8 - Jobs</h1><p>Sebuah Job membuat satu atau beberapa Pod dan menjamin bahwa jumlah Pod yang telah dispesifikasikan sebelumnya
berhasil dijalankan. Pada saat Pod telah dihentikan, Job akan menandainya sebagai Job yang sudah berhasil dijalankan.
Ketika jumlah sukses yang dispesifikasikan sebelumnya sudah terpenuhi, maka Job tersebut dianggap selesai.
Menghapus sebuah Job akan menghapus semua Pod yang dibuat oleh Job tersebut.</p><p>Sebuah kasus sederhana yang dapat diberikan adalah membuat sebuah objek Job untuk menjamin
sebuah Pod dijalankan hingga selesai. Objek Job ini akan membuat sebuah Pod baru apabila
Pod pertama gagal atau dihapus (salah satu contohnya adalah akibat adanya kegagalan pada
perangkat keras atau terjadinya <em>reboot</em> pada Node).</p><p>Kamu juga dapat menggunakan Job untuk menjalankan beberapa Pod secara paralel.</p><h2 id=menjalankan-contoh-job>Menjalankan Contoh Job</h2><p>Berikut merupakan contoh konfigurasi Job. Job ini melakukan komputasi π hingga
digit ke 2000 kemudian memberikan hasilnya sebagai keluaran. Job tersebut memerlukan
waktu 10 detik untuk dapat diselesaikan.</p><div class=highlight><div class=copy-code-icon style=text-align:right><a href=https://raw.githubusercontent.com/kubernetes/website/main/content/id/examples/controllers/job.yaml download=controllers/job.yaml><code>controllers/job.yaml</code></a>
<img src=/images/copycode.svg style=max-height:24px;cursor:pointer onclick='copyCode("controllers-job-yaml")' title="Copy controllers/job.yaml to clipboard"></img></div><div class=includecode id=controllers-job-yaml><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>batch/v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Job<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>pi<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>template</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>pi<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>perl<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>command</span>:<span style=color:#bbb> </span>[<span style=color:#b44>&#34;perl&#34;</span>,<span style=color:#bbb>  </span><span style=color:#b44>&#34;-Mbignum=bpi&#34;</span>,<span style=color:#bbb> </span><span style=color:#b44>&#34;-wle&#34;</span>,<span style=color:#bbb> </span><span style=color:#b44>&#34;print bpi(2000)&#34;</span>]<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>restartPolicy</span>:<span style=color:#bbb> </span>Never<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>backoffLimit</span>:<span style=color:#bbb> </span><span style=color:#666>4</span><span style=color:#bbb>
</span></span></span></code></pre></div></div></div><p>Kamu dapat menjalankan contoh tersebut dengan menjalankan perintah berikut:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl apply -f https://k8s.io/examples/controllers/job.yaml
</span></span></code></pre></div><pre tabindex=0><code>job &#34;pi&#34; created
</code></pre><p>Perhatikan status dari Job yang baru dibuat dengan menggunakan perintah<code>kubectl</code>:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl describe jobs/pi
</span></span></code></pre></div><pre tabindex=0><code>Name:             pi
Namespace:        default
Selector:         controller-uid=b1db589a-2c8d-11e6-b324-0209dc45a495
Labels:           controller-uid=b1db589a-2c8d-11e6-b324-0209dc45a495
                  job-name=pi
Annotations:      &lt;none&gt;
Parallelism:      1
Completions:      1
Start Time:       Tue, 07 Jun 2016 10:56:16 +0200
Pods Statuses:    0 Running / 1 Succeeded / 0 Failed
Pod Template:
  Labels:       controller-uid=b1db589a-2c8d-11e6-b324-0209dc45a495
                job-name=pi
  Containers:
   pi:
    Image:      perl
    Port:
    Command:
      perl
      -Mbignum=bpi
      -wle
      print bpi(2000)
    Environment:        &lt;none&gt;
    Mounts:             &lt;none&gt;
  Volumes:              &lt;none&gt;
Events:
  FirstSeen    LastSeen    Count    From            SubobjectPath    Type        Reason            Message
  ---------    --------    -----    ----            -------------    --------    ------            -------
  1m           1m          1        {job-controller }                Normal      SuccessfulCreate  Created pod: pi-dtn4q
</code></pre><p>Untuk melihat Pod yang sudah selesai dari sebuah Job, kamu dapat menggunakan perintah <code>kubectl get pods</code>.</p><p>Untuk menampilkan semua Pod yang merupakan bagian dari suatu Job di mesin kamu dalam bentuk
yang mudah dipahami, kamu dapat menggunakan perintah berikut ini:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span><span style=color:#b8860b>pods</span><span style=color:#666>=</span><span style=color:#a2f;font-weight:700>$(</span>kubectl get pods --selector<span style=color:#666>=</span>job-name<span style=color:#666>=</span>pi --output<span style=color:#666>=</span><span style=color:#b8860b>jsonpath</span><span style=color:#666>=</span><span style=color:#b44>&#39;{.items[*].metadata.name}&#39;</span><span style=color:#a2f;font-weight:700>)</span>
</span></span><span style=display:flex><span><span style=color:#a2f>echo</span> <span style=color:#b8860b>$pods</span>
</span></span></code></pre></div><pre tabindex=0><code>pi-aiw0a
</code></pre><p>Disini, selektor yang ada merupakan selektor yang sama dengan yang ada pada Job.
Opsi <code>--output=jsonpath</code> menspesifikasikan bahwa ekspresi yang hanya
menampilkan nama dari setiap Pod pada <em>list</em> yang dikembalikan.</p><p>Untuk melihat keluaran standar dari salah satu pod:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl logs <span style=color:#b8860b>$pods</span>
</span></span></code></pre></div><p>Keluaran yang dihasilkan akan sama dengan:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>3.1415926535897932384626433832795028841971693993751058209749445923078164062862089986280348253421170679821480865132823066470938446095505822317253594081284811174502841027019385211055596446229489549303819644288109756659334461284756482337867831652712019091456485669234603486104543266482133936072602491412737245870066063155881748815209209628292540917153643678925903600113305305488204665213841469519415116094330572703657595919530921861173819326117931051185480744623799627495673518857527248912279381830119491298336733624406566430860213949463952247371907021798609437027705392171762931767523846748184676694051320005681271452635608277857713427577896091736371787214684409012249534301465495853710507922796892589235420199561121290219608640344181598136297747713099605187072113499999983729780499510597317328160963185950244594553469083026425223082533446850352619311881710100031378387528865875332083814206171776691473035982534904287554687311595628638823537875937519577818577805321712268066130019278766111959092164201989380952572010654858632788659361533818279682303019520353018529689957736225994138912497217752834791315155748572424541506959508295331168617278558890750983817546374649393192550604009277016711390098488240128583616035637076601047101819429555961989467678374494482553797747268471040475346462080466842590694912933136770289891521047521620569660240580381501935112533824300355876402474964732639141992726042699227967823547816360093417216412199245863150302861829745557067498385054945885869269956909272107975093029553211653449872027559602364806654991198818347977535663698074265425278625518184175746728909777727938000816470600161452491921732172147723501414419735685481613611573525521334757418494684385233239073941433345477624168625189835694855620992192221842725502542568876717904946016534668049886272327917860857843838279679766814541009538837863609506800642251252051173929848960841284886269456042419652850222106611863067442786220391949450471237137869609563643719172874677646575739624138908658326459958133904780275901
</span></span></code></pre></div><h2 id=menulis-spek-job>Menulis Spek Job</h2><p>Sama halnya dengan konfigurasi Kubernetes lainnya, sebuah Job memerlukan <em>field</em>
<code>apiVersion</code>, <code>kind</code>, dan <code>metadata</code>.</p><p>Sebuah Job juga membutuhkan sebuah <a href=https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#spec-and-status>bagian <code>.spec</code></a>.</p><h3 id=templat-pod>Templat Pod</h3><p><em>Field</em> <code>.spec.template</code> merupakan satu-satunya <em>field</em> wajib pada <code>.spec</code>.</p><p><em>Field</em> <code>.spec.template</code> merupakan sebuah <a href=/id/docs/concepts/workloads/pods/pod-overview/#pod-templates>templat Pod</a>. <em>Field</em> ini memiliki skema yang sama dengan yang ada pada <a href=/docs/user-guide/pods>Pod</a>,
kecuali <em>field</em> ini bersifat <em>nested</em> dan tidak memiliki <em>field</em> <code>apiVersion</code> atau <em>field</em> <code>kind</code>.</p><p>Sebagai tambahan dari <em>field</em> wajib pada sebuah Job, sebuah tempat pod pada Job
haruslah menspesifikasikan label yang sesuai (perhatikan <a href=#pod-selektor>selektor pod</a>)
dan sebuah mekanisme <em>restart</em> yang sesuai.</p><p>Hanya sebuah <a href=/id/docs/concepts/workloads/pods/pod-lifecycle/#restart-policy><code>RestartPolicy</code></a> yang sesuai dengan <code>Never</code> atau <code>OnFailure</code> yang bersifat valid.</p><h3 id=selektor-pod>Selektor Pod</h3><p><em>Field</em> <code>.spec.selector</code> bersifat opsional. Dan dalam sebagian besar kasus, kamu tidak perlu memberikan
spesifikasi untuk hal ini. Perhatikan bagian <a href=#menspesifikasikan-selektor-pod-kamu-sendiri>menspesifikasikan selektor Pod kamu sendiri</a>.</p><h3 id=job-paralel>Job Paralel</h3><p>Terdapat tiga jenis utama dari <em>task</em> yang sesuai untuk dijalankan sebagai sebuah Job:</p><ol><li>Job non-paralel</li></ol><ul><li>secara umum, hanya sebuah Pod yang dimulai, kecuali jika Pod tersebut gagal.</li><li>Job akan dianggap sudah selesai dikerjakan apabila Pod dari Job tersebut sudah selesai dijalankan dan mengalami terminasi dengan status sukses.</li></ul><ol><li>Job paralel dengan <em>jumlah nilai penyelesaian tetap</em>:</li></ol><ul><li>berikan spesifikasi pada <code>.spec.completions</code> dengan nilai non-negatif.</li><li>Job yang ada merupakan representasi dari <em>task</em> yang dikerjakan, dan akan dianggap selesai apabila terdapat lebih dari satu Pod yang sukses untuk setiap nilai yang ada dalam jangkauan 1 hingga <code>.spec.completions</code>.</li><li><strong>belum diimplementasikan saat ini:</strong> Setiap Pod diberikan nilai indeks yang berbeda di dalam jangkauan 1 hingga <code>.spec.completions</code>.</li></ul><ol><li>Job paralel dengan sebuah <em><em>work queue</em></em>:</li></ol><ul><li>jangan berikan spesifikasi pada <code>.spec.completions</code>, nilai <em>default</em>-nya merupakan <code>.spec.parallelism</code>.</li><li>Pod yang ada haruslah dapat berkoordinasi satu sama lain atau dengan Service eksternal lain untuk menentukan apa yang setiap Pod tadi perlu lakukan. Sebagai contohnya, sebuah Pod bisa saja melakukan <em>fetch</em> job <em>batch</em> hingga N kali pada <em>work queue</em></li><li>setiap Pod secara independen mampu menentukan apakah Pod lainnya telah menyelesaikan tugasnya dengan baik atau belum, dengan kata lain suatu Job telah dikatakan selesai</li><li>ketika Pod mana pun dari sebuah Job berhenti dalam keadaan sukses, maka tidak ada Pod lain yang akan dibuat untuk Job tersebut.</li><li>apabila salah satu Pod sudah dihentikan sekali dalam keadaan sukses, maka Job akan ditandai sebagai sukses.</li><li>apabila sebuah Pod sudah dihentikan dalam keadaan sukses, tidak boleh ada Pod lain yang mengerjakan <em>task</em> tersebut. Dengan kata lain, semua Pod tersebut haruslah dalam keadaan akan dihentikan.</li></ul><p>Untuk sebuah Job yang non-paralel, kamu tidak perlu menspesifikasikan <em>field</em> <code>.spec.completions</code> dan <code>.spec.parallelism</code>. Ketika kedua <em>field</em> tersebut
dalam keadaan tidak dispesifikasikan, maka nilai <em>defult</em>-nya akan diubah menjadi 1.</p><p>Untuk sebuah Job dengan jumlah nilai penyelesaian tetap, kamu harus memberikan spesifikasi nilai
dari <code>.spec.completions</code> dengan nilai yang diinginkan. Kamu dapat menspesifikasikan <code>.spec.parallelism</code>,
atau jika kamu tidak melakukannya nilai dari <em>field</em> ini akan memiliki nilai default 1.</p><p>Untuk sebuah Job <em>work queue</em>, kamu harus meninggalkan spesifikasi <em>field</em> <code>.spec.completions</code> menjadi kosong, serta
memberikan nilai pada <code>.spec.parallelism</code> menjadi sebuah bilangan bulat non negatif.</p><p>Untuk informasi lebih lanjut mengenai bagaimana menggunakan Job dengan jenis yang berbeda, kamu
dapat melihat bagian <a href=#pola-job>pola job</a>.</p><h4 id=mengendalikan-paralelisme>Mengendalikan Paralelisme</h4><p>Paralelisme yang diminta (<code>.spec.parallelism</code>) dapat diaktifkan dengan cara
memberikan nilai bilangan bulat non-negatif. Jika tidak dispesifikasikan maka nilainya akan
secara default yaitu 1. Jika dispesifikasikan sebagai 0, maka Job akan secara otomatis dihentikan sementara
hingga nilainya dinaikkan.</p><p>Paralelisme yang sebenarnya (jumlah Pod yang dijalankan pada satu waktu tertentu)
bisa saja lebih atau kurang dari nilai yang diharapkan karena adanya alasan berikut:</p><ul><li>Untuk Job <em>fixed completion count</em>, nilai sebenarnya dari jumlah Pod yang dijalankan secara paralel tidak akan melebihi jumlah<br><em>completion</em> yang tersisa. Nilai yang lebih tinggi dari <code>.spec.parallelism</code> secara efektif, akan diabaikan.</li><li>Untuk Job <em>work queue</em>, tidak akan ada Pod yang dimulai setelah ada Pod yang berhasil -- meskipun begitu, sisa Pod yang ada akan diizinkan untuk menyelesaikan tugasnya.</li><li>Jika sebuah <a class=glossary-tooltip title='Kontrol tertutup yang mengawasi kondisi bersama dari klaster melalui apiserver dan membuat perubahan yang mencoba untuk membawa kondisi saat ini ke kondisi yang diinginkan.' data-toggle=tooltip data-placement=top href=/id/docs/concepts/architecture/controller/ target=_blank aria-label=Pengontrol>Pengontrol</a> Job tidak memiliki waktu untuk memberikan reaksi.</li><li>Jika sebuah <em>controller</em> Job gagal membuat Pod dengan alasan apa pun (kurangnya <code>ResourceQuota</code>, kurangnya <em>permission</em>, dkk.),
maka bisa saja terdapat lebih sedikit Pod dari yang diminta.</li><li>Jika <em>controller</em> Job melakukan <em>throttle</em> pembuatan Pod karena terdapat gagalnya pembuatan Pod yang berlebihan sebelumnya pada Job yang sama.</li><li>Ketika sebuah Pod dihentikan secara <em>graceful</em>, maka Pod tersebut akan membutuhkan waktu untuk berhenti.</li></ul><h2 id=mengatasi-kegagalan-pod-dan-container>Mengatasi Kegagalan Pod dan Container</h2><p>Sebuah Container pada sebuah Pod bisa saja mengalami kegagalan karena berbagai alasan
yang berbeda, misalnya saja karena proses yang ada di dalamnya berakhir dengan <em>exit code</em>
yang tidak sama dengan nol, atau Container yang ada di-<em>kill</em> karena menyalahi batasan memori, dkk.
Jika hal ini terjadi, dan <code>.spec.template.spec.restartPolicy = "OnFailure"</code>, maka Pod
akan tetap ada di dalam node, tetapi Container tersebut akan dijalankan kembali. Dengan demikian,
program kamu harus dapat mengatasi kasus dimana program tersebut di-<em>restart</em> secara lokal, atau jika
tidak maka spesifikasikan <code>.spec.template.spec.restartPolicy = "Never"</code>. Perhatikan
<a href=/id/docs/concepts/workloads/pods/pod-lifecycle/#example-states><em>lifecycle</em> pod</a> untuk informasi lebih lanjut mengenai <code>restartPolicy</code>.</p><p>Sebuah Pod juga dapat gagal secara menyeluruh, untuk beberapa alasan yang mungkin, misalnya saja,
ketika Pod tersebut dipindahkan dari Node (ketika Node diperbarui, di-<em>restart</em>, dihapus, dsb.), atau
jika sebuah Container dalam Pod gagal dan <code>.spec.template.spec.restartPolicy = "Never"</code>. Ketika
sebuah Pod gagal, maka <em>controller</em> Job akan membuat sebuah Pod baru. Ini berarti aplikasi kamu haruslah
bisa mengatasi kasus dimana aplikasimu dimulai pada Pod yang baru. Secara khusus apabila aplikasi kamu
berurusan dengan berkas temporer, <em>locks</em>, keluaran yang tak lengkap dan hal-hal terkait dengan
program yang dijalankan sebelumnya.</p><p>Perhatikan bahwa bahakan apabila kamu menspesifikasikan <code>.spec.parallelism = 1</code> dan <code>.spec.completions = 1</code> dan
<code>.spec.template.spec.restartPolicy = "Never"</code>, program yang sama bisa saja tetap dijalankan lebih dari sekali.</p><p>Jika kamu menspesifikasikan <code>.spec.parallelism</code> dan <code>.spec.completions</code> dengan nilai yang lebih besar dari 1,
maka bisa saja terdapat keadaan dimana terdapat beberapa Pod yang dijalankan pada waktu yang sama.
Dengan demikian, Pod kamu haruslah fleksibel terhadap adanya konkurensi.</p><h3 id=mekanisme-kebijakan-backoff-apabila-terjadi-kegagalan>Mekanisme Kebijakan <em>Backoff</em> apabila Terjadi Kegagalan</h3><p>Terdapat situasi dimana kamu ingin membuat suatu Job gagal
setelah dijalankan mekanisme <em>retry</em> beberapa kali akibat adanya kesalahan pada konfigurasi
dsb. Untuk melakukan hal tersebut, spesifikasikan <code>.spec.backoffLimit</code> dengan nilai <em>retry</em> yang diinginkan
sebelum menerjemahkan Job dalam keadaan gagal. Secara default, nilai dari <em>field</em> tersebut adalah 6.
Pod yang gagal dijalankan dan terkait dengan suatu Job tertentu akan dibuat kembali oleh
<em>controller</em> Job dengan <em>delay</em> <em>back-off</em> eksponensial (10 detik, 20 detik, 40 detik ...)
yang dibatasi pada 6 menit. Penghitungan <em>back-off</em> akan diulang jika tidak terdapat Pod baru yang gagal
sebelum siklus pengecekan status Job selanjutnya.</p><p><div class="alert alert-info note callout" role=alert><strong>Catatan:</strong> Isu <a href=https://github.com/kubernetes/kubernetes/issues/54870>#54870</a> masih ada untuk versi Kubernetes sebelum 1.12.</div><div class="alert alert-info note callout" role=alert><strong>Catatan:</strong> Jika Job yang kamu miliki memiliki <code>restartPolicy = "OnFailure"</code>, perhatikan bahwa Container kamu yang menjalankan
Job tersebut akan dihentikan ketika limit <em>back-off</em> telah dicapai. Hal ini akan membuat proses <em>debugging</em> semakin sulit.
Dengan demikian, kami memberikan saran untuk menspesifikasikan <code>restartPolicy = "Never"</code> ketika melakukan
proses <em>debugging</em> atau menggunakan mekanisme <em>logging</em> untuk menjamin keluaran
dari Job yang gagal agar tidak terus menerus hilang.</div></p><h2 id=terminasi-dan-clean-up-job>Terminasi dan <em>Clean Up</em> Job</h2><p>Ketika sebuah Job selesai dijalankan, tidak akan ada lagi Pod yang dibuat,
meskipun begitu Pod yang ada juga tidak akan dihapus. Dengan demikian kamu masih bisa mengakses log
yang ada dari Pod yang sudah dalam status <em>complete</em> untuk mengecek apabila terjadi eror, <em>warning</em>, atau hal-hal
yang dapat digunakan untuk proses pelaporan dan identifikasi. Objek Job itu sendiri akan tetap ada,
sehingga kamu tetap bisa melihat statusnya. Penghapusan objek akan diserahkan sepenuhnya pada pengguna
apabila Job tidak lagi digunakan. Penghapusan Job dengan perintah <code>kubectl</code> (misalnya, <code>kubectl delete jobs/pi</code> atau <code>kubectl delete -f ./job.yaml</code>).
Ketika kamu menghapus Job menggunakan perintah <code>kubectl</code>, semua Pod yang terkait dengan Job tersebut akan ikut dihapus.</p><p>Secara <em>default</em>, sebuah Job akan dijalankan tanpa adanya interupsi kecuali terdapat Pod yang gagal, (<code>restartPolicy=Never</code>) atau terdapat
Container yang dihentikan dalam kondisi error (<code>restartPolicy=OnFailure</code>), suatu keadaan dimana Job akan dijalankan dengan mekanisme
yang dijelaskan di atas berdasarkan pada <code>.spec.backoffLimit</code>.
Apabila <code>.spec.backoffLimit</code> telah mencapai limit, maka Job akan ditandai sebagai gagal dan Pod yang saat ini sedang dijalankan juga akan dihentikan.</p><p>Cara lain untuk menghentikan sebuah Job adalah dengan mengatur <em>deadline</em> aktif.
Untuk melakukannya kamu dapat menspesifikasikan <em>field</em> <code>.spec.activeDeadlineSeconds</code>
dari sebuah Job dengan suatu angka dalam satuan detik. <em>Field</em> <code>activeDeadlineSeconds</code>
diterapkan pada durasi dari sebuah Job, tidak peduli seberapa banyak Pod yang dibuat.
Setelah sebuah Job mencapai limit <code>activeDeadlineSeconds</code>, semua Pod yang dijalankan akan dihentikan
dan status dari Job tersebut akan berubah menjadi <code>type: Failed</code> dengan <code>reason: DeadlineExceeded</code>.</p><p>Perhatikan bahwa <em>field</em> <code>.spec.activeDeadlineSeconds</code> pada Job memiliki tingkat
presedensi di atas <code>.spec.backoffLimit</code>. Dengan demikian, sebuah Job
yang sedang mencoba melakukan <em>restart</em> pada suatu Pod-nya tidak akan melakukan
pembuatan Pod yang baru apabila Job tersebut telah mencapai limit yang didefinisikan pada
<code>activeDeadlineSeconds</code>, bahkan apabila nilai dari <code>backoffLimit</code> belum tercapai.</p><p>Contoh:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>batch/v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Job<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>pi-with-timeout<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>backoffLimit</span>:<span style=color:#bbb> </span><span style=color:#666>5</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>activeDeadlineSeconds</span>:<span style=color:#bbb> </span><span style=color:#666>100</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>template</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>Containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>pi<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>perl<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>command</span>:<span style=color:#bbb> </span>[<span style=color:#b44>&#34;perl&#34;</span>,<span style=color:#bbb>  </span><span style=color:#b44>&#34;-Mbignum=bpi&#34;</span>,<span style=color:#bbb> </span><span style=color:#b44>&#34;-wle&#34;</span>,<span style=color:#bbb> </span><span style=color:#b44>&#34;print bpi(2000)&#34;</span>]<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>restartPolicy</span>:<span style=color:#bbb> </span>Never<span style=color:#bbb>
</span></span></span></code></pre></div><p>Perhatikan bahwa baik spek Job dan <a href=/docs/concepts/workloads/pods/init-Containers/#detailed-behavior>spek templat Pod</a> di dalam Job memiliki <em>field</em> <code>activeDeadlineSeconds</code>.
Pastikan kamu telah menspesifikasikan nilai tersebut pada level yang dibutuhkan.</p><h2 id=mekanisme-clean-up-otomatis-pada-job-yang-sudah-selesai>Mekanisme <em>Clean Up</em> Otomatis pada Job yang Sudah Selesai</h2><p>Job yang sudah selesai biasanya tidak lagi dibutuhkan di dalam sistem. Tetap menjaga keberadaan
objek-objek tersebut di dalam sistem akan memberikan tekanan tambahan pada API server. Jika sebuah Job
yang diatur secara langsung oleh <em>controller</em> dengan level yang lebih tinggi, seperti
<a href=/id/docs/concepts/workloads/controllers/cron-jobs/>CronJob</a>, maka Job ini dapat
di-<em>clean up</em> oleh CronJob berdasarkan <em>policy</em> berbasis kapasitas yang dispesifikasikan.</p><h3 id=mekanisme-ttl-untuk-job-yang-telah-selesai-dijalankan>Mekanisme TTL untuk Job yang Telah Selesai Dijalankan</h3><div style=margin-top:10px;margin-bottom:10px><b>FEATURE STATE:</b> <code>Kubernetes v1.12 [alpha]</code></div><p>Salah satu cara untuk melakukan <em>clean up</em> Job yang telah selesai dijalankan
(baik dengan status <code>Complete</code> atau <code>Failed</code>) secara otomatis adalah dengan
menerapkan mekanisme TTL yang disediakan oleh
<a href=/id/docs/concepts/workloads/controllers/ttlafterfinished/><em>controller</em> TTL</a> untuk
sumber daya yang telah selesai digunakan, dengan cara menspesifikasikan
<em>field</em> <code>.spec.ttlSecondsAfterFinished</code> dari Job tersebut.</p><p>Ketika <em>controller</em> TTL melakukan proses <em>clean up</em> pada Job,
maka <em>controller</em> tersebut akan menghapus objek-objek terkait seperti Pod, serta Job itu sendiri.
Perhatikan bahwa ketika suatu Job dihapus, maka <em>lifecycle</em>-nya akan menjamin, mekanisme
<em>finalizer</em> yang ada akan tetap dihargai.</p><p>Sebagai contoh:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>batch/v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Job<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>pi-with-ttl<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>ttlSecondsAfterFinished</span>:<span style=color:#bbb> </span><span style=color:#666>100</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>template</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>Containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>pi<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>perl<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>command</span>:<span style=color:#bbb> </span>[<span style=color:#b44>&#34;perl&#34;</span>,<span style=color:#bbb>  </span><span style=color:#b44>&#34;-Mbignum=bpi&#34;</span>,<span style=color:#bbb> </span><span style=color:#b44>&#34;-wle&#34;</span>,<span style=color:#bbb> </span><span style=color:#b44>&#34;print bpi(2000)&#34;</span>]<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>restartPolicy</span>:<span style=color:#bbb> </span>Never<span style=color:#bbb>
</span></span></span></code></pre></div><p>Job <code>pi-with-ttl</code> akan dihapus secara otomatis, dalam jangka waktu <code>100</code>
detik setelah Job tersebut selesai dijalankan.</p><p>Jika <em>field</em> ini dispesifikasikan sebagai <code>0</code>, maka Job akan secara otomatis dihapus
segera setelah Job tersebut selesai dijalankan. Jika <em>field</em> tersebut tidak dispesifikasikan,
maka Job ini tidak akan dihapus oleh <em>controller</em> TTL setelah Job ini selesai dijalankan.</p><p>Perhatikan bahwa mekanisme TTL ini merupakan fitur alpha, dengan gerbang fitur <code>TTLAfterFinished</code>.
Untuk informasi lebih lanjut, kamu dapat membaca dokumentasi untuk
<a href=/id/docs/concepts/workloads/controllers/ttlafterfinished/><em>controller</em> TTL</a> untuk
sumber daya yang telah selesai dijalankan.</p><h2 id=pola-job>Pola Job</h2><p>Sebuah objek Job dapat digunakan untuk mendukung eksekusi paralel yang dapat diandalkan pada Pod.
Objek Job tidak di-desain untuk mendukung proses paralel bersifat <em>closely-communicating</em>,
seperti yang secara umum ditemukan dalam komputasi ilmiah. Meskipun begitu objek ini mendukung
set <em>work item</em> yang independen namun saling terkait satu sama lainnya. Ini termasuk surel yang harus dikirim,
<em>frame</em> yang harus di-<em>render</em>, berkas yang harus di-<em>transcoded</em>, jangkauan <em>key</em> yang ada
di dalam basis data NoSQL, dsb.</p><p>Pada suatu sistem yang kompleks, terdapat beberapa set <em>work item</em> yang berbeda.
Di sini, kami hanya mempertimbangkan <em>work item</em> yang ingin digunakan oleh pengguna
untuk melakukan manajemen secara bersamaan — sebuah <em>batch job</em>.</p><p>Terdapat beberapa perbedaan pola pada komputasi paralel,
setiap pola memiliki kelebihan dan kekurangannya masing-masing. Kekurangan dan kelebihan ini
dijabarkan sebagai berikut:</p><ul><li>Satu objek Job untuk setiap <em>work item</em>, atau sebuah Job untuk semua <em>work item</em>. Pilihan kedua akan lebih baik apabila digunakan untuk jumlah <em>work item</em> yang lebih besar.
Sementara itu, pilihan pertama akan mengakibatkan <em>overhead</em> bagi pengguna dan juga sistem
untuk mengaur jumlah objek Job yang cukup banyak.</li><li>Jumlah Pod yang dibuat sesuai dengan jumlah <em>work item</em> atau setiap Pod dapat memproses beberapa <em>work item</em> sekaligus.
Pilihan pertama secara umum memerlukan modifikasi lebih sedikit untuk kode dan Container yang suda ada. Pilihan kedua
akan lebih baik jika digunakan untuk jumlah <em>work item</em> yang lebih banyak, untuk alasan yang sama dengan poin sebelumnya.</li><li>Beberapa pendekatan menggunakan prinsip <em>work queue</em>. Hal ini membutuhkan sebuah <em>service queue</em> yang dijalankan,
serta modifikasi untuk program atau Container yang sudah ada untuk mengizinkannya menggunakan <em>working queue</em>.
Pendekatan lain akan lebih mudah untuk digunakan bagi aplikasi yang sudah ada.</li></ul><p><em>Tradeoff</em> yang dirangkum di sini, dengan kolom 2 dan 4 berkaitan dengan <em>tradeoff</em> yang dijelaskan di atas.
Nama dari pola yang ada juga terkait dengan contoh dan deskripsi lebih lanjut.</p><table><thead><tr><th>Pola</th><th style=text-align:center>Objek dengan satu Job</th><th style=text-align:center>Pod yang lebih sedikit tadi <em>work items</em>?</th><th style=text-align:center>Penggunaan app tanpa modifikasi?</th><th style=text-align:center>Dapat dijalankan pada Kube versi 1.1?</th></tr></thead><tbody><tr><td><a href=/docs/tasks/job/parallel-processing-expansion/>Perluasan Templat Job</a></td><td style=text-align:center></td><td style=text-align:center></td><td style=text-align:center>✓</td><td style=text-align:center>✓</td></tr><tr><td><a href=/docs/tasks/job/coarse-parallel-processing-work-queue/>Queue dengan Pod untuk setiap <em>Work Item</em></a></td><td style=text-align:center>✓</td><td style=text-align:center></td><td style=text-align:center>sometimes</td><td style=text-align:center>✓</td></tr><tr><td><a href=/docs/tasks/job/fine-parallel-processing-work-queue/>Queue dengan Variabel <em>Pod Count</em></a></td><td style=text-align:center>✓</td><td style=text-align:center>✓</td><td style=text-align:center></td><td style=text-align:center>✓</td></tr><tr><td>Job Single dengan penempatan Kerja Statis</td><td style=text-align:center>✓</td><td style=text-align:center></td><td style=text-align:center>✓</td><td style=text-align:center></td></tr></tbody></table><p>Ketika kamu menspesifikasikan <em>completion</em> dengan <code>.spec.completions</code>, setiap Pod yang dibuat oleh <em>controller</em> Job
memiliki <a href=https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#spec-and-status><code>spec</code></a> yang identik. Artinya
semua Pod untuk sebuah <em>task</em> akan memiliki perintah yang sama serta <em>image</em>, volume, serta variabel <em>environment</em> yang (hampir) sama.
Pola ini merupakan salah satu cara berbeda yang diterapkan untuk mengatur Pod agar dapat bekerja untuk hal yang berbeda-beda.</p><p>Tabel ini menunjukkan pengaturan yang dibutuhkan untuk <code>.spec.parallelism</code> dan <code>.spec.completions</code> bagi setiap pola.
Disini, <code>W</code> merupakan jumlah dari <em>work item</em>.</p><table><thead><tr><th>Pattern</th><th style=text-align:center><code>.spec.completions</code></th><th style=text-align:center><code>.spec.parallelism</code></th></tr></thead><tbody><tr><td><a href=/docs/tasks/job/parallel-processing-expansion/>Job Template Expansion</a></td><td style=text-align:center>1</td><td style=text-align:center>should be 1</td></tr><tr><td><a href=/docs/tasks/job/coarse-parallel-processing-work-queue/>Queue with Pod Per Work Item</a></td><td style=text-align:center>W</td><td style=text-align:center>any</td></tr><tr><td><a href=/docs/tasks/job/fine-parallel-processing-work-queue/>Queue with Variable Pod Count</a></td><td style=text-align:center>1</td><td style=text-align:center>any</td></tr><tr><td>Single Job with Static Work Assignment</td><td style=text-align:center>W</td><td style=text-align:center>any</td></tr></tbody></table><h2 id=penggunaan-tingkat-lanjut>Penggunaan Tingkat Lanjut</h2><h3 id=menspesifikasikan-selektor-pod-kamu-sendiri>Menspesifikasikan Selektor Pod Kamu Sendiri</h3><p>Secara umum, ketika kamu membuat sebuah objek Job, kamu
tidak menspesifikasikan <code>.spec.selector</code>. Sistem akan memberikan nilai
default pada <em>field</em> ini ketika Job dibuat. Sistem akan memilih nilai dari selektor yang ada
dan memastikan nilainya tidak akan beririsan dengan Job lainnya.</p><p>Meskipun demikian, pada beberapa kasus, kamu bisa saja memiliki kebutuhan untuk meng-<em>override</em>
nilai dari selektor ini. Untuk melakukannya, kamu dapat menspesifikasikan <code>.spec.selector</code>
dari Job.</p><p>Berhati-hatilah ketika kamu melakukan proses ini. Jika kamu menspesifikasikan sebuah label
selektor yang tidak unik pada Pod yang ada di dalam Job tersebut, serta sesuai dengan Pod yang tidak
terkait dengan Job tadi, maka Pod dari Job yang tidak terkait dengan Job tadi akna dihapus, atau Job ini
akan menghitung <em>completion</em> dari Pod lain sebagai tolak ukur suksesnya Job tersebut, atau bisa saja salah satu
atau kedua Job tidak dapat membuat Pod baru yang digunakan untuk menyelesaikan Job tersebut.
Jika selektor yang tidak unik dipilih, maka <em>controller</em> lain (misalnya ReplicationController) dan Pod
yang ada di dalamnya bisa saja memiliki perilaku yang tidak dapat diprediksi. Kubernetes tidak akan
mencegah kemungkinan terjadinya hal ini ketika kamu menspesifikasikan nilai <code>.spec.selector</code>.</p><p>Berikut merupakan contoh skenario dimana kamu ingin menggunakan fitur ini.</p><p>Misalnya saja Job dengan nama <code>old</code> sudah dijalankan.
Dan kamu ingin Pod yang sudah dijalankan untuk tetap berada pada state tersebut,
tapi kamu juga ingin Pod selanjutnya yang dibuat untuk menggunakan templat Pod yang berbeda dan agar
Job tersebut memiliki nama yang berbeda. Kamu tidak dapat mengubah Job karena <em>field</em> ini
merupakan nilai yang tidak bisa diubah. Dengan demikian, kamu menghapus Job <code>old</code>
tetapi tetap membiarkan Pod yang ada untuk jalan, menggunakan perintah <code>kubectl delete jobs/old --cascade=false</code>.
Sebelum menghapus Job tadi, kamu mencatat selektor yang digunakan oleh Job tadi:</p><pre tabindex=0><code>kubectl get job old -o yaml
</code></pre><pre tabindex=0><code>kind: Job
metadata:
  name: old
  ...
spec:
  selector:
    matchLabels:
      controller-uid: a8f3d00d-c6d2-11e5-9f87-42010af00002
  ...
</code></pre><p>Kemudian kamu membuat sebuah Job baru dengan nama <code>new</code>
dan kamu secara eksplisit menspesifikasikan selektor yang sama.
Karena Pod dengan selektor yang sama memiliki label <code>controller-uid=a8f3d00d-c6d2-11e5-9f87-42010af00002</code>,
maka Pod-Pod lama tadi dikendalikan juga oleh Job <code>new</code>.</p><p>Kamu harus menspesifikasikan <code>manualSelector: true</code> pada Job yang baru
karena kamu tidak menggunakan selektor yang diberikan secara default oleh sistem.</p><pre tabindex=0><code>kind: Job
metadata:
  name: new
  ...
spec:
  manualSelector: true
  selector:
    matchLabels:
      controller-uid: a8f3d00d-c6d2-11e5-9f87-42010af00002
  ...
</code></pre><p>Job yang baru tadi kemudian akan memiliki uid yang berbeda dari <code>a8f3d00d-c6d2-11e5-9f87-42010af00002</code>. Pengaturan
<code>manualSelector: true</code> memberikan perintah pada sistem bahwa kamu mengetahui apa yang kamu lakukan
dan untuk mengizikan ketidaksesuaian ini untuk terjadi.</p><h2 id=alternatif>Alternatif</h2><h3 id=pod-polosan><em>Pod Polosan</em></h3><p>Ketika node dimana Pod dijalankan berada dalam kondisi <em>reboot</em> atau gagal, Pod tadi akan dihentikan
dan tidak akan di-restart. Meskipun demikian, sebuah Job akan membuat Pod baru yang menggantikan
Pod lama yang dihentikan. Untuk alasan inilah, kami memberikan rekomendasi agar kamu menggunakan sebuah Job dibandingkan dengan
Pod yang biasa, bahkan jika aplikasi yang kamu gunakan hanya memerlukan sebuah Pod.</p><h3 id=replication-controller>Replication Controller</h3><p>Job merupakan komplemen dari <a href=/docs/user-guide/replication-controller>Replication Controller</a>.
Sebuah Replication Controller mengatur Pod yang diharapkan untuk tidak dihentikan (misalnya, <em>web server</em>), dan sebuah Job
mengatur Pod yang diharapkan untuk berhenti (misalnya, <em>batch task</em>).</p><p>Seperti yang sudah dibahas pada <a href=/id/docs/concepts/workloads/pods/pod-lifecycle/><em>Lifecycle</em> Pod</a>, <code>Job</code> <em>hanya</em> pantas
digunakan untuk Pod dengan <code>RestartPolicy</code> yang sama dengan <code>OnFailure</code> atau <code>Never</code>.
(Perhatikan bahwa: Jika <code>RestartPolicy</code> tidak dispesifikasikan, nilai defaultnya adalah <code>Always</code>.)</p><h3 id=job-tunggal-akan-menginisiasi-kontroller-pod>Job Tunggal akan menginisiasi Kontroller Pod</h3><p>Pola lain yang mungkin diterapkan adalah untuk sebuah Job tunggal untuk membuat
sebuah Pod yang kemudian akan membuat Pod lainnya, bersifat selayaknya <em>controller</em> kustom
bagi Pod tersebut. Hal ini mengizinkan fleksibilitas optimal, tetapi cukup kompleks untuk digunakan
dan memiliki integrasi terbatas dengan Kubernetes.</p><p>Salah satu contoh dari pola ini adalah sebuah Job yang akan menginisiasi sebuah Pod
yang menjalankan <em>script</em> yang kemudian akan
menjalankan <em>controller</em> master Spark (kamu dapat melihatnya di <a href=https://github.com/kubernetes/examples/tree/main/staging/spark/README.md>contoh Spark</a>),
yang menjalankan <em>driver</em> Spark, dan kemudian melakukan mekanisme <em>clean up</em>.</p><p>Keuntungan dari pendekatan ini adalah proses keseluruhan yang memiliki jaminan <em>completion</em>
dari sebuah Job, tetapi kontrol secara mutlak atas Pod yang dibuat serta tugas yang diberikan pada Pod tersebut.</p><h2 id=cron-jobs>CronJob</h2><p>Kamu dapat menggunakan <a href=/id/docs/concepts/workloads/controllers/cron-jobs/><code>CronJob</code></a> untuk membuat Job yang akan
dijalankan pada waktu/tanggal yang spesifik, mirip dengan perangkat lunak <code>cron</code> yang ada pada Unix.</p></div><div class=td-content style=page-break-before:always><h1 id=pg-2e4cec01c525b45eccd6010e21cc76d9>2.9 - CronJob</h1><p>Suatu CronJob menciptakan <a href=/id/docs/concepts/workloads/controllers/jobs-run-to-completion/>Job</a> yang dijadwalkan berdasarkan waktu tertentu.</p><p>Satu objek CronJob sepadan dengan satu baris pada <em>file</em> <em>crontab</em> (<em>cron table</em>). CronJob tersebut menjalankan suatu pekerjaan secara berkala
pada waktu tertentu, dituliskan dalam format <a href=https://en.wikipedia.org/wiki/Cron>Cron</a>.</p><div class="alert alert-info note callout" role=alert><strong>Catatan:</strong> Seluruh waktu <code>schedule:</code> pada <em><strong>CronJob</strong></em> mengikuti zona waktu dari <em>master</em> di mana Job diinisiasi.</div><p>Untuk panduan dalam berkreasi dengan <em>cron job</em>, dan contoh <em>spec file</em> untuk suatu <em>cron job</em>, lihat <a href=/id/docs/tasks/job/automated-tasks-with-cron-jobs>Menjalankan otomasi <em>task</em> dengan <em>cron job</em></a>.</p><h2 id=limitasi-cron-job>Limitasi <em>Cron Job</em></h2><p>Suatu <em>cron job</em> menciptakan <em>kurang lebih</em> satu objek Job setiap penjadwalan. Istilah yang digunakan adalah "<em>kurang lebih</em>" karena
terdapat beberapa kasus yang menyebabkan dua Job terbuat, atau tidak ada Job sama sekali yang terbuat. Kemungkinan-kemungkinan
seperti itu memang diusahakan untuk tidak sering terjadi, tapi tidak ada jaminan kemungkinan-kemungkinan tersebut tidak akan pernah terjadi.
Oleh karena itu, Job sudah sepantasnya memiliki sifat idempoten.</p><p>Jika pengaturan <code>startingDeadlineSeconds</code> menggunakan nilai yang besar atau tidak diatur (menggunakan nilai <em>default</em>)
dan jika pengaturan <code>concurrencyPolicy</code> dijadikan <code>Allow</code>, Job yang terbuat akan dijalankan paling tidak satu kali.</p><p>CronJob <em>controller</em> memeriksa berapa banyak jadwal yang terlewatkan sejak waktu terakhir eksekusi hingga saat ini. Jika terdapat lebih dari 100 jadwal yang terlewat, maka CronJob <em>controller</em> tidak memulai Job dan mencatat kesalahan:</p><pre tabindex=0><code>Cannot determine if job needs to be started. Too many missed start time (&gt; 100). Set or decrease .spec.startingDeadlineSeconds or check clock skew.
</code></pre><p>Perlu diingat bahwa jika pengaturan <code>startingDeadlineSeconds</code> memiliki suatu nilai (bukan <code>nil</code>), CronJob <em>controller</em> akan menghitung berapa banyak Job yang terlewatkan dari sejak <code>startingDeadlineSeconds</code> hingga sekarang dan bukan sejak waktu terakhir eksekusi. Misalnya: Jika <code>startingDeadlineSeconds</code> memiliki nilai <code>200</code>, CronJob <em>controller</em> akan menghitung berapa banyak Job yang terlewatkan dalam 200 detik terakhir.</p><p>Suatu CronJob dianggap terlewat jika ia gagal diciptakan pada waktu yang semestinya. Misalnya: Jika pengaturan <code>concurrencyPolicy</code> dijadikan <code>Forbid</code>
dan suatu CronJob dicoba dijadwalkan saat masih ada penjadwalan sebelumnya yang masih berjalan, maka ia akan dianggap terlewat.</p><p>Contoh: Suatu CronJob akan menjadwalkan Job baru tiap satu menit dimulai sejak <code>08:30:00</code>, dan <code>startingDeadlineSeconds</code> tidak diatur.
Jika CronJob <em>controller</em> tidak aktif dari <code>08:29:00</code> sampai <code>10:21:00</code>, Job tidak akan dijalankan karena jumlah Job yang terlewat
sudah lebih dari 100.</p><p>Sebagai ilustrasi lebih lanjut, misalkan suatu CronJob diatur untuk menjadwalkan Job baru setiap satu menit dimulai sejak <code>08:30:00</code>,
dan <code>startingDeadlineSeconds</code> memiliki nilai <code>200</code>. Jika CronJob <em>controller</em> tidak aktif seperti pada contoh sebelumnya (<code>08:29:00</code> sampai <code>10:21:00</code>),
Job akan tetap dijalankan pada 10:22:00. Hal ini terjadi karena CronJob <em>controller</em> memeriksa banyaknya jadwal yang terlewatkan pada 200 detik terakhir
(dalam kasus ini: 3 jadwal terlewat), dan bukan dari sejak waktu eksekusi terakhir.</p><p>CronJob hanya bertanggung-jawab untuk menciptakan Job yang sesuai dengan jadwalnya sendiri,
dan Job tersebut bertanggung jawab terhadap pengelolaan Pod yang direpresentasikan olehnya.</p></div></main></div></div><footer class=d-print-none><div class=footer__links><nav><a class=text-white href=/id/docs/home/>Home</a>
<a class=text-white href=/id/community/>Komunitas</a>
<a class=text-white href=/id/case-studies/>Studi kasus</a></nav></div><div class=container-fluid><div class=row><div class="col-6 col-sm-2 text-xs-center order-sm-2"><ul class="list-inline mb-0"><li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title="User mailing list" aria-label="User mailing list"><a class=text-white target=_blank href=https://discuss.kubernetes.io><i class="fa fa-envelope"></i></a></li><li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title=Twitter aria-label=Twitter><a class=text-white target=_blank href=https://twitter.com/kubernetesio><i class="fab fa-twitter"></i></a></li><li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title=Calendar aria-label=Calendar><a class=text-white target=_blank href="https://calendar.google.com/calendar/embed?src=calendar%40kubernetes.io"><i class="fas fa-calendar-alt"></i></a></li><li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title=Youtube aria-label=Youtube><a class=text-white target=_blank href=https://youtube.com/kubernetescommunity><i class="fab fa-youtube"></i></a></li></ul></div><div class="col-6 col-sm-2 text-right text-xs-center order-sm-3"><ul class="list-inline mb-0"><li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title=GitHub aria-label=GitHub><a class=text-white target=_blank href=https://github.com/kubernetes/kubernetes><i class="fab fa-github"></i></a></li><li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title=Slack aria-label=Slack><a class=text-white target=_blank href=https://slack.k8s.io><i class="fab fa-slack"></i></a></li><li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title=Contribute aria-label=Contribute><a class=text-white target=_blank href=https://git.k8s.io/community/contributors/guide><i class="fas fa-edit"></i></a></li><li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title="Stack Overflow" aria-label="Stack Overflow"><a class=text-white target=_blank href=https://stackoverflow.com/questions/tagged/kubernetes><i class="fab fa-stack-overflow"></i></a></li></ul></div><div class="col-12 col-sm-8 text-center order-sm-2"><small class=text-white>&copy; 2023 Para Pencipta Kubernetes | Dokumentasi didistribusikan di bawah <a href=https://git.k8s.io/website/LICENSE class=light-text>CC BY 4.0</a></small><br><small class=text-white>Copyright &copy; 2023 Linux Foundation &reg;. Hak cipta dilindungi. Linux Foundation telah mendaftarkan merek dagang dan pengunaannya. Perinciannya bisa dilihat pada <a href=https://www.linuxfoundation.org/trademark-usage class=light-text>halaman penggunaan merek dagang</a></small><br><small class=text-white>ICP license: 京ICP备17074266号-3</small></div></div></div></footer></div><script src=/js/jquery-3.6.0.min.js integrity=sha384-vtXRMe3mGCbOeY7l30aIg8H9p3GdeSe4IFlP6G8JMa7o7lXvnz3GFKzPxzJdPfGK crossorigin=anonymous></script>
<script src=/js/popper-1.16.1.min.js intregrity=sha384-9/reFTGAW83EW2RDu2S0VKaIzap3H66lZH81PoYlFhbGU+6BZp6G7niu735Sk7lN crossorigin=anonymous></script>
<script src=/js/bootstrap-4.6.1.min.js integrity=sha384-VHvPCCyXqtD5DqJeNxl2dtTyhF78xXNXdkwX1CZeRusQfRKp+tA7hAShOK/B/fQ2 crossorigin=anonymous></script>
<script src=/js/script.js></script>
<script async src=/js/mermaid-8.13.4.min.js integrity=sha384-5hHNvPeMrNH14oM3IcQofDoBhiclNK3g2+hnEinKzQ07C4AliMeVpnvxuiwEGpaO crossorigin=anonymous></script>
<script src=/js/main.min.5c0bf7f21dc4f66485f74efbbeeff28a7e4f8cddaac1bae47043159c922ff3a3.js integrity="sha256-XAv38h3E9mSF9077vu/yin5PjN2qwbrkcEMVnJIv86M=" crossorigin=anonymous></script></body></html>