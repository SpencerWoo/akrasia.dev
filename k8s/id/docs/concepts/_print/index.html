<!doctype html><html lang=id class=no-js><head><meta name=robots content="noindex, nofollow"><link rel=alternate hreflang=en href=https://kubernetes.io/docs/concepts/><link rel=alternate hreflang=zh-cn href=https://kubernetes.io/zh-cn/docs/concepts/><link rel=alternate hreflang=ko href=https://kubernetes.io/ko/docs/concepts/><link rel=alternate hreflang=ja href=https://kubernetes.io/ja/docs/concepts/><link rel=alternate hreflang=fr href=https://kubernetes.io/fr/docs/concepts/><link rel=alternate hreflang=it href=https://kubernetes.io/it/docs/concepts/><link rel=alternate hreflang=de href=https://kubernetes.io/de/docs/concepts/><link rel=alternate hreflang=es href=https://kubernetes.io/es/docs/concepts/><link rel=alternate hreflang=pt-br href=https://kubernetes.io/pt-br/docs/concepts/><link rel=alternate hreflang=ru href=https://kubernetes.io/ru/docs/concepts/><link rel=alternate hreflang=pl href=https://kubernetes.io/pl/docs/concepts/><link rel=alternate hreflang=uk href=https://kubernetes.io/uk/docs/concepts/><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=generator content="Hugo 0.110.0"><link rel=canonical type=text/html href=https://kubernetes.io/id/docs/concepts/><link rel="shortcut icon" type=image/png href=/images/favicon.png><link rel=apple-touch-icon href=/favicons/apple-touch-icon-180x180.png sizes=180x180><link rel=manifest href=/manifest.webmanifest><link rel=apple-touch-icon href=/images/kubernetes-192x192.png><title>Konsep | Kubernetes</title><meta property="og:title" content="Konsep"><meta property="og:description" content="Orkestrasi Kontainer dengan Skala Produksi"><meta property="og:type" content="website"><meta property="og:url" content="https://kubernetes.io/id/docs/concepts/"><meta property="og:site_name" content="Kubernetes"><meta itemprop=name content="Konsep"><meta itemprop=description content="Orkestrasi Kontainer dengan Skala Produksi"><meta name=twitter:card content="summary"><meta name=twitter:title content="Konsep"><meta name=twitter:description content="Orkestrasi Kontainer dengan Skala Produksi"><link href=/scss/main.css rel=stylesheet><script type=application/ld+json>{"@context":"https://schema.org","@type":"Organization","url":"https://kubernetes.io","logo":"https://kubernetes.io/images/favicon.png","potentialAction":{"@type":"SearchAction","target":"https://kubernetes.io/search/?q={search_term_string}","query-input":"required name=search_term_string"}}</script><meta name=theme-color content="#326ce5"><link rel=stylesheet href=/css/feature-states.css><meta name=description content="Bagian konsep ini membantu kamu belajar tentang bagian-bagian sistem serta abstraksi yang digunakan Kubernetes untuk merepresentasikan klaster kamu, serta membantu kamu belajar lebih dalam bagaimana cara kerja Kubernetes.
Ikhtisar Untuk menggunakan Kubernetes, kamu menggunakan objek-objek Kubernetes API untuk merepresentasikan state yang diinginkan: apa yang aplikasi atau workload lain yang ingin kamu jalankan, image kontainer yang digunakan, jaringan atau resource disk apa yang ingin kamu sediakan, dan lain sebagainya. Kamu membuat state yang diinginkan dengan cara membuat objek dengan menggunakan API Kubernetes, dan biasanya menggunakan command-line interface, yaitu kubectl."><meta property="og:description" content="Bagian konsep ini membantu kamu belajar tentang bagian-bagian sistem serta abstraksi yang digunakan Kubernetes untuk merepresentasikan klaster kamu, serta membantu kamu belajar lebih dalam bagaimana cara kerja Kubernetes.
Ikhtisar Untuk menggunakan Kubernetes, kamu menggunakan objek-objek Kubernetes API untuk merepresentasikan state yang diinginkan: apa yang aplikasi atau workload lain yang ingin kamu jalankan, image kontainer yang digunakan, jaringan atau resource disk apa yang ingin kamu sediakan, dan lain sebagainya. Kamu membuat state yang diinginkan dengan cara membuat objek dengan menggunakan API Kubernetes, dan biasanya menggunakan command-line interface, yaitu kubectl."><meta name=twitter:description content="Bagian konsep ini membantu kamu belajar tentang bagian-bagian sistem serta abstraksi yang digunakan Kubernetes untuk merepresentasikan klaster kamu, serta membantu kamu belajar lebih dalam bagaimana cara kerja Kubernetes.
Ikhtisar Untuk menggunakan Kubernetes, kamu menggunakan objek-objek Kubernetes API untuk merepresentasikan state yang diinginkan: apa yang aplikasi atau workload lain yang ingin kamu jalankan, image kontainer yang digunakan, jaringan atau resource disk apa yang ingin kamu sediakan, dan lain sebagainya. Kamu membuat state yang diinginkan dengan cara membuat objek dengan menggunakan API Kubernetes, dan biasanya menggunakan command-line interface, yaitu kubectl."><meta property="og:url" content="https://kubernetes.io/id/docs/concepts/"><meta property="og:title" content="Konsep"><meta name=twitter:title content="Konsep"><meta name=twitter:image content="https://kubernetes.io/images/favicon.png"><meta name=twitter:image:alt content="Kubernetes"><meta property="og:image" content="/images/kubernetes-horizontal-color.png"><meta property="og:type" content="article"><script src=/js/jquery-3.6.0.min.js intregrity=sha384-vtXRMe3mGCbOeY7l30aIg8H9p3GdeSe4IFlP6G8JMa7o7lXvnz3GFKzPxzJdPfGK crossorigin=anonymous></script></head><body class=td-section><header><nav class="js-navbar-scroll navbar navbar-expand navbar-dark flex-column flex-md-row td-navbar" data-auto-burger=primary><a class=navbar-brand href=/id/></a><div class="td-navbar-nav-scroll ml-md-auto" id=main_navbar><ul class="navbar-nav mt-2 mt-lg-0"><li class="nav-item mr-2 mb-lg-0"><a class="nav-link active" href=/id/docs/>Dokumentasi</a></li><li class="nav-item mr-2 mb-lg-0"><a class=nav-link href=/id/community/>Komunitas</a></li><li class="nav-item mr-2 mb-lg-0"><a class=nav-link href=/id/case-studies/>Studi kasus</a></li><li class="nav-item dropdown"><a class="nav-link dropdown-toggle" href=# id=navbarDropdown role=button data-toggle=dropdown aria-haspopup=true aria-expanded=false>Versi</a><div class="dropdown-menu dropdown-menu-right" aria-labelledby=navbarDropdownMenuLink><a class=dropdown-item href=/id/releases>Release Information</a>
<a class=dropdown-item href=https://kubernetes.io/id/docs/concepts/>v1.25</a>
<a class=dropdown-item href=https://v1-24.docs.kubernetes.io/id/docs/concepts/>v1.24</a>
<a class=dropdown-item href=https://v1-23.docs.kubernetes.io/id/docs/concepts/>v1.23</a>
<a class=dropdown-item href=https://v1-22.docs.kubernetes.io/id/docs/concepts/>v1.22</a>
<a class=dropdown-item href=https://v1-21.docs.kubernetes.io/id/docs/concepts/>v1.21</a></div></li><li class="nav-item dropdown"><a class="nav-link dropdown-toggle" href=# id=navbarDropdownMenuLink role=button data-toggle=dropdown aria-haspopup=true aria-expanded=false>Bahasa Indonesia</a><div class="dropdown-menu dropdown-menu-right" aria-labelledby=navbarDropdownMenuLink><a class=dropdown-item href=/docs/concepts/>English</a>
<a class=dropdown-item href=/zh-cn/docs/concepts/>中文 (Chinese)</a>
<a class=dropdown-item href=/ko/docs/concepts/>한국어 (Korean)</a>
<a class=dropdown-item href=/ja/docs/concepts/>日本語 (Japanese)</a>
<a class=dropdown-item href=/fr/docs/concepts/>Français (French)</a>
<a class=dropdown-item href=/it/docs/concepts/>Italiano (Italian)</a>
<a class=dropdown-item href=/de/docs/concepts/>Deutsch (German)</a>
<a class=dropdown-item href=/es/docs/concepts/>Español (Spanish)</a>
<a class=dropdown-item href=/pt-br/docs/concepts/>Português (Portuguese)</a>
<a class=dropdown-item href=/ru/docs/concepts/>Русский (Russian)</a>
<a class=dropdown-item href=/pl/docs/concepts/>Polski (Polish)</a>
<a class=dropdown-item href=/uk/docs/concepts/>Українська (Ukrainian)</a></div></li></ul></div><button id=hamburger onclick=kub.toggleMenu() data-auto-burger-exclude><div></div></button></nav></header><div class="container-fluid td-outer"><div class=td-main><div class="row flex-xl-nowrap"><main class="col-12 col-md-9 col-xl-8 pl-md-5" role=main><div class=td-content><div class="pageinfo pageinfo-primary d-print-none"><p>This is the multi-page printable view of this section.
<a href=# onclick="return print(),!1">Click here to print</a>.</p><p><a href=/id/docs/concepts/>Return to the regular view of this page</a>.</p></div><h1 class=title>Konsep</h1><ul><li>1: <a href=#pg-0554ac387412eaf4e6e89b2f847dacde>Ikhtisar</a></li><ul><li>1.1: <a href=#pg-45bdca6129cf540121623e903c18ba46>Apa itu Kubernetes?</a></li><li>1.2: <a href=#pg-13b0f1dbe89228e3d76d2ac231e245f1>Komponen-Komponen Kubernetes</a></li><li>1.3: <a href=#pg-0c745f42e623d2b70a53bc0e6db73d95>API Kubernetes</a></li><li>1.4: <a href=#pg-110f33530cf761140cb1dab536baef04>Menggunakan Objek-Objek Kubernetes</a></li><ul><li>1.4.1: <a href=#pg-9f5adfa77f48c50d5cc81155a3cecb98>Memahami Konsep Objek-Objek yang ada pada Kubernetes</a></li><li>1.4.2: <a href=#pg-6751db8ff5409476de8225d17d6c42dd>Pengaturan Objek Kubernetes</a></li><li>1.4.3: <a href=#pg-f37749a83c2916b63279ea60f3cfe53e>Nama</a></li><li>1.4.4: <a href=#pg-1127165f472b7181b9c1d5a0b187d620>Namespace</a></li><li>1.4.5: <a href=#pg-f1dec4557fb8ffbac9f11390aaaf9fa4>Label dan Selektor</a></li><li>1.4.6: <a href=#pg-93cd7a1d4e1623e2bf01afc49a5af69c>Anotasi</a></li><li>1.4.7: <a href=#pg-046c03090d47bc4b89b818dc645c3865>Selektor Field</a></li><li>1.4.8: <a href=#pg-5dd62c6a4a481b4cf1ac50f6799eb581>Label yang Disarankan</a></li></ul></ul><li>2: <a href=#pg-2bf36ccd6b3dbeafecf87c39761b07c7>Arsitektur Kubernetes</a></li><ul><li>2.1: <a href=#pg-9ef2890698e773b6c0d24fd2c20146f5>Node</a></li><li>2.2: <a href=#pg-c0251def6da29b30afebfb04549f1703>Komunikasi antara Control Plane dan Node</a></li><li>2.3: <a href=#pg-ca8819042a505291540e831283da66df>Controller</a></li><li>2.4: <a href=#pg-bc804b02614d67025b4c788f1ca87fbc>Konsep-konsep di balik Controller Manager</a></li></ul><li>3: <a href=#pg-a5f7383c83ab9eb9cd0e3c4c020b3ae6>Kontainer</a></li><ul><li>3.1: <a href=#pg-8fda96dc403731ceba5e0ddd0ab3ad15>Ikhtisar Kontainer</a></li><li>3.2: <a href=#pg-16042b4652ad19e565c7263824029a43>Image</a></li><li>3.3: <a href=#pg-643212488f778acf04bebed65ba34441>Kontainer Environment</a></li><li>3.4: <a href=#pg-a858027489648786a3b16264e451272b>Runtime Class</a></li><li>3.5: <a href=#pg-e6941d969d81540208a3e78bc56f43bc>Lifecyle Hook pada Kontainer</a></li></ul><li>4: <a href=#pg-d52aadda80edd9f8c514cfe2321363c2>Workloads</a></li><ul><li>4.1: <a href=#pg-4d68b0ccf9c683e6368ffdcc40c838d4>Pods</a></li><ul><li>4.1.1: <a href=#pg-37afa6c66c74400d1579f10faf55e5b6>Pengenalan Pod</a></li><li>4.1.2: <a href=#pg-99cce294fe789317ee684a6e1f07f20f>Pod</a></li><li>4.1.3: <a href=#pg-c3c2b9cf30915ec9d46c147201da3332>Siklus Hidup Pod</a></li><li>4.1.4: <a href=#pg-1ccbd4eeded6ab138d98b59175bd557e>Init Container</a></li><li>4.1.5: <a href=#pg-c8d62295ca703fdcef1aaf89fb4c916a>Batasan Persebaran Topologi Pod</a></li><li>4.1.6: <a href=#pg-4e9b9cbc9776b12e7335c53da377c9c8>Pod Preset</a></li><li>4.1.7: <a href=#pg-4aaf43c715cd764bc8ed4436f3537e68>Disrupsi</a></li><li>4.1.8: <a href=#pg-53a1005011e1bda2ce81819aad7c8b32>Kontainer Sementara (Ephemeral)</a></li></ul><li>4.2: <a href=#pg-89637410cacae45a36ab1cc278c482eb>Controllers</a></li><ul><li>4.2.1: <a href=#pg-d459b930218774655fa7fd1620625539>ReplicaSet</a></li><li>4.2.2: <a href=#pg-27f1331d515d95f76aa1156088b4ad91>ReplicationController</a></li><li>4.2.3: <a href=#pg-a2dc0393e0c4079e1c504b6429844e86>Deployment</a></li><li>4.2.4: <a href=#pg-6d72299952c37ca8cc61b416e5bdbcd4>StatefulSet</a></li><li>4.2.5: <a href=#pg-41600eb8b6631c88848156f381e9d588>DaemonSet</a></li><li>4.2.6: <a href=#pg-9add0d2120634b63073ad08dc8683bd6>Garbage Collection</a></li><li>4.2.7: <a href=#pg-4de50a37ebb6f2340484192126cb7a04>Pengendali TTL untuk Sumber Daya yang Telah Selesai Digunakan</a></li><li>4.2.8: <a href=#pg-cc7cc3c4907039d9f863162e20bfbbef>Jobs</a></li><li>4.2.9: <a href=#pg-2e4cec01c525b45eccd6010e21cc76d9>CronJob</a></li></ul></ul><li>5: <a href=#pg-0a0a7eca3e302a3c08f8c85e15d337fd>Services, Load Balancing, dan Jaringan</a></li><ul><li>5.1: <a href=#pg-5701136fd2ce258047b6ddc389112352>Service</a></li><li>5.2: <a href=#pg-3a38878244d862dfdb8d7adb32f77584>Topologi Service (Service Topology)</a></li><li>5.3: <a href=#pg-f51db1097575de8072afe1f5b156a70c>EndpointSlice</a></li><li>5.4: <a href=#pg-91cb8a4438b003df11bc1c426a81b756>DNS untuk Service dan Pod</a></li><li>5.5: <a href=#pg-f804ac0532fcade3966ea2e3769ca031>Menghubungkan aplikasi dengan Service</a></li><li>5.6: <a href=#pg-199bcc92443dbc9bed44819467d7eb75>Ingress</a></li><li>5.7: <a href=#pg-5a8edeb1f2dc8e38cd6d561bb08b0d78>Kontroler Ingress</a></li><li>5.8: <a href=#pg-ded1daafdcd293023ee333728007ca61>NetworkPolicy</a></li><li>5.9: <a href=#pg-509638b5ca0e420fa426f14f34e2d3b1>Menambahkan Entry pada /etc/hosts Pod dengan HostAliases</a></li><li>5.10: <a href=#pg-21f8d19c60c33914baab66224c3d46a7>Dual-stack IPv4/IPv6</a></li></ul><li>6: <a href=#pg-f018f568c6723865753f150c3c59bdda>Storage</a></li><ul><li>6.1: <a href=#pg-27795584640a03bd2024f1fe3b3ab754>Volume</a></li><li>6.2: <a href=#pg-ffd12528a12882b282e1bd19e29f9e75>Persistent Volume</a></li><li>6.3: <a href=#pg-c262af210c6828dec445d2f55a1d877a>VolumeSnapshot</a></li><li>6.4: <a href=#pg-707ca81a34eb1ca202f34692e9917d1e>Pengklonaan Volume CSI</a></li><li>6.5: <a href=#pg-f0276d05eef111249272a1c932a91e2c>StorageClass</a></li><li>6.6: <a href=#pg-4d00116c86dade62bdd5be7dc2afa1ca>VolumeSnapshotClass</a></li><li>6.7: <a href=#pg-018f0a7fc6e2f6d16da37702fc39b4f3>Penyediaan Volume Dinamis</a></li><li>6.8: <a href=#pg-b2e4b16ac37988c678a3312a4a6639f8>Limit Volume yang Spesifik terhadap Node</a></li></ul><li>7: <a href=#pg-275bea454e1cf4c5adeca4058b5af988>Konfigurasi</a></li><ul><li>7.1: <a href=#pg-ddef6fd0e47bb51c6f05e8e7fb11d2dd>Konfigurasi dan Penerapan Konsep</a></li><li>7.2: <a href=#pg-4c9401ed6b037e1adb958cbce20630c7>Mengatur Sumber Daya Komputasi untuk Container</a></li><li>7.3: <a href=#pg-e511ed821ada65d0053341dbd8ad2bb5>Secret</a></li><li>7.4: <a href=#pg-ab6d20f33ad930a67ee7ef57bff6c75e>Mengatur Akses Klaster Menggunakan Berkas kubeconfig</a></li><li>7.5: <a href=#pg-ed4ae5e4344d619bc6df6e1278efae74>Prioritas dan Pemindahan Pod</a></li></ul><li>8: <a href=#pg-712cb3c03ff14a39e5a83a6d9b71d203>Keamanan</a></li><ul><li>8.1: <a href=#pg-04eeb110d75afc8acb2cf7a3db743985>Ikhtisar Keamanan Cloud Native</a></li></ul><li>9: <a href=#pg-c21d05f31057c5bcd2ebdd01f4e62a0e>Penjadwalan dan Pengusiran</a></li><ul><li>9.1: <a href=#pg-961126cd43559012893979e568396a49>Bin Packing Sumber Daya untuk Sumber Daya Tambahan</a></li><li>9.2: <a href=#pg-da22fe2278df236f71efbe672f392677>Overhead Pod</a></li><li>9.3: <a href=#pg-21169f516071aea5d16734a4c27789a5>Menetapkan Pod ke Node</a></li><li>9.4: <a href=#pg-ede4960b56a3529ee0bfe7c8fe2d09a5>Taint dan Toleration</a></li><li>9.5: <a href=#pg-598f36d691ab197f9d995784574b0a12>Penjadwal Kubernetes</a></li><li>9.6: <a href=#pg-602208c95fe7b1f1170310ce993f5814>Kerangka Kerja Penjadwalan (Scheduling Framework)</a></li><li>9.7: <a href=#pg-d9574a30fcbc631b0d2a57850e161e89>Penyetelan Kinerja Penjadwal</a></li></ul><li>10: <a href=#pg-ac9161c6d952925b083ad9602b4e8e7f>Policies</a></li><ul><li>10.1: <a href=#pg-a935ff8c59eb116b43494255cc67f69a>LimitRange</a></li><li>10.2: <a href=#pg-94ddc6e901c30f256138db11d09f05a3>Resource Quota</a></li><li>10.3: <a href=#pg-59977cbac423e20437db079757cb03df>Pod Security Policy</a></li></ul><li>11: <a href=#pg-285a3785fd3d20f437c28d87ca4dadca>Administrasi Klaster</a></li><ul><li>11.1: <a href=#pg-fb494ea3b1874bd753dcd11c3f35c2dc>Ikhtisar Administrasi Klaster</a></li><li>11.2: <a href=#pg-2bf9a93ab5ba014fb6ff70b22c29d432>Sertifikat</a></li><li>11.3: <a href=#pg-d0e81230313a2684e7b7e40b21834e30>Penyedia Layanan Cloud</a></li><li>11.4: <a href=#pg-3aeeecf7cdb2a21eb4b31db7a71c81e2>Mengelola Resource</a></li><li>11.5: <a href=#pg-d649067a69d8d5c7e71564b42b96909e>Jaringan Kluster</a></li><li>11.6: <a href=#pg-c4b1e87a84441f8a90699a345ce48d68>Arsitektur Logging</a></li><li>11.7: <a href=#pg-cbfd3654996eae9fcdef009f70fa83f0>Metrik untuk Komponen Sistem Kubernetes</a></li><li>11.8: <a href=#pg-2e05a56491965ae320c2662590b2ca18>Konfigurasi Garbage Collection pada kubelet</a></li><li>11.9: <a href=#pg-3003324f360fdacc06ca144e57ff0e97>Federation</a></li><li>11.10: <a href=#pg-08e94e6a480e0d6b2de72d84a1b97617>Berbagai Proxy di Kubernetes</a></li><li>11.11: <a href=#pg-d5cc46b61677b53f61a407d20bdd0830>Metrik controller manager</a></li><li>11.12: <a href=#pg-85d633ae590aa20ec024f1b7af1d74fc>Instalasi Add-ons</a></li><li>11.13: <a href=#pg-31c9327d2332c585341b64ddafa19cdd>Prioritas dan Kesetaraan API (API Priority and Fairness)</a></li></ul><li>12: <a href=#pg-7e0d97616b15e2c383c6a0a96ec442cb>Memperluas Kubernetes</a></li><ul><li>12.1: <a href=#pg-5c2b36cd0ddbe006b575d4e54c63d508>Memperluas Klaster Kubernetes Kamu</a></li><li>12.2: <a href=#pg-0af41d3bd7c785621b58b7564793396a>Memperluas API Kubernetes</a></li><ul><li>12.2.1: <a href=#pg-1ea4977c0ebf97569bf54a477faa7fa5>Memperluas Kubernetes API dengan Lapisan Agregasi</a></li><li>12.2.2: <a href=#pg-342388440304e19ce30c0f8ada1c77ce>Custom Resource</a></li></ul><li>12.3: <a href=#pg-c8937cdc9df96f3328becf04f8211292>Ekstensi Komputasi, Penyimpanan, dan Jaringan</a></li><ul><li>12.3.1: <a href=#pg-1ac2260db9ecccbf0303a899bc27ce6d>Plugin Jaringan</a></li><li>12.3.2: <a href=#pg-53e1ea8892ceca307ba19e8d6a7b8d32>Plugin Perangkat</a></li></ul><li>12.4: <a href=#pg-3131452556176159fb269593c1a52012>Pola Operator</a></li><li>12.5: <a href=#pg-b26fcf43d01abc16c8110766026dafed>Service Catalog</a></li><li>12.6: <a href=#pg-bad3c3629d0ab48ed84b6caf66d02f89>Poseidon-Firmament - Sebuah Penjadwal Alternatif</a></li></ul></ul><div class=content><p>Bagian konsep ini membantu kamu belajar tentang bagian-bagian sistem serta abstraksi
yang digunakan Kubernetes untuk merepresentasikan klaster kamu, serta membantu
kamu belajar lebih dalam bagaimana cara kerja Kubernetes.</p><h2 id=ikhtisar>Ikhtisar</h2><p>Untuk menggunakan Kubernetes, kamu menggunakan objek-objek <em>Kubernetes API</em> untuk merepresentasikan
<em>state</em> yang diinginkan: apa yang aplikasi atau <em>workload</em> lain yang ingin kamu
jalankan, <em>image</em> kontainer yang digunakan, jaringan atau <em>resource disk</em> apa yang ingin
kamu sediakan, dan lain sebagainya. Kamu membuat <em>state</em> yang diinginkan dengan cara membuat
objek dengan menggunakan API Kubernetes, dan biasanya menggunakan <code>command-line interface</code>, yaitu <code>kubectl</code>.
Kamu juga dapat secara langsung berinteraksi dengan klaster untuk membuat atau mengubah
<em>state</em> yang kamu inginkan.</p><p>Setelah kamu membuat <em>state</em> yang kamu inginkan, <em>Control Plane</em> Kubernetes
menggunakan <code>Pod Lifecycle Event Generator (PLEG)</code> untuk mengubah
<em>state</em> yang ada saat ini supaya sama dengan <em>state</em> yang diinginkan.
Untuk melakukan hal tersebut, Kubernetes melakukan berbagai <em>task</em> secara otomatis,
misalnya dengan mekanisme <code>start</code> atau <code>stop</code> kontainer, melakukan <em>scale</em> replika dari
suatu aplikasi, dan lain sebagainya. <em>Control Plane</em> Kubernetes terdiri dari sekumpulan
<code>process</code> yang dijalankan di klaster:</p><ul><li><strong>Kubernetes Master</strong> terdiri dari tiga buah <em>process</em> yang dijalankan pada sebuah <em>node</em> di klaster kamu, <em>node</em> ini disebut sebagai <em>master</em>, yang terdiri <a href=/docs/admin/kube-apiserver/>kube-apiserver</a>, <a href=/docs/admin/kube-controller-manager/>kube-controller-manager</a> dan <a href=/docs/admin/kube-scheduler/>kube-scheduler</a>.</li><li>Setiap <em>node</em> non-master pada klaster kamu menjalankan dua buah <em>process</em>:<ul><li><strong><a href=/docs/admin/kubelet/>kubelet</a></strong>, yang menjadi perantara komunikasi dengan <em>master</em>.</li><li><strong><a href=/docs/admin/kube-proxy/>kube-proxy</a></strong>, sebuah <em>proxy</em> yang merupakan representasi jaringan yang ada pada setiap <em>node</em>.</li></ul></li></ul><h2 id=objek-kubernetes>Objek Kubernetes</h2><p>Kubernetes memiliki beberapa abstraksi yang merepresentasikan <em>state</em> dari sistem kamu:
apa yang aplikasi atau <em>workload</em> lain yang ingin kamu jalankan, jaringan atau <em>resource disk</em> apa yang ingin
kamu sediakan, serta beberapa informasi lain terkait apa yang sedang klaster kamu lakukan.
Abstraksi ini direpresentasikan oleh objek yang tersedia di API Kubernetes;
lihat <a href=/docs/concepts/abstractions/overview/>ikhtisar objek-objek Kubernetes</a>
untuk penjelasan yang lebih mendetail.</p><p>Objek mendasar Kubernetes termasuk:</p><ul><li><a href=/id/docs/concepts/workloads/pods/pod-overview/>Pod</a></li><li><a href=/id/docs/concepts/services-networking/service/>Service</a></li><li><a href=/id/docs/concepts/storage/volumes/>Volume</a></li><li><a href=/id/docs/concepts/overview/working-with-objects/namespaces/>Namespace</a></li></ul><p>Sebagai tambahan, Kubernetes memiliki beberapa abstraksi yang lebih tinggi yang disebut kontroler.
Kontroler merupakan objek mendasar dengan fungsi tambahan, contoh dari kontroler ini adalah:</p><ul><li><a href=/id/docs/concepts/workloads/controllers/replicaset/>ReplicaSet</a></li><li><a href=/id/docs/concepts/workloads/controllers/deployment/>Deployment</a></li><li><a href=/id/docs/concepts/workloads/controllers/statefulset/>StatefulSet</a></li><li><a href=/id/docs/concepts/workloads/controllers/daemonset/>DaemonSet</a></li><li><a href=/id/docs/concepts/workloads/controllers/job/>Job</a></li></ul><h2 id=control-plane-kubernetes><em>Control Plane</em> Kubernetes</h2><p>Berbagai bagian <em>Control Plane</em> Kubernetes, seperti <em>master</em> dan <em>process-process</em> kubelet,
mengatur bagaimana Kubernetes berkomunikasi dengan klaster kamu. <em>Control Plane</em>
menjaga seluruh <em>record</em> dari objek Kubernetes serta terus menjalankan
iterasi untuk melakukan manajemen <em>state</em> objek. <em>Control Plane</em> akan memberikan respon
apabila terdapat perubahan pada klaster kamu dan mengubah <em>state</em> saat ini agar sesuai
dengan <em>state</em> yang diinginkan.</p><p>Contohnya, ketika kamu menggunakan API Kubernetes untuk membuat sebuah <em>Deployment</em>,
kamu memberikan sebuah <em>state</em> baru yang harus dipenuhi oleh sistem. <em>Control Plane</em>
kemudian akan mencatat objek apa saja yang dibuat, serta menjalankan instruksi yang kamu berikan
dengan cara melakukan <code>start</code> aplikasi dan melakukan <code>scheduling</code> aplikasi tersebut
pada <em>node</em>, dengan kata lain mengubah <em>state</em> saat ini agar sesuai dengan <em>state</em> yang diinginkan.</p><h3 id=master>Master</h3><p>Master Kubernetes bertanggung jawab untuk memelihara <em>state</em> yang diinginkan pada klaster kamu.
Ketika kamu berinteraksi dengan Kubernetes, misalnya saja menggunakan perangkat <code>kubectl</code>,
kamu berkomunikasi dengan <em>master</em> klaster Kubernetes kamu.</p><blockquote><p>"master" merujuk pada tiga buah <em>process</em> yang dijalankan pada sebuah <em>node</em> pada klaster kamu, <em>node</em> ini disebut sebagai <em>master</em>, yang terdiri <a href=/docs/admin/kube-apiserver/>kube-apiserver</a>, <a href=/docs/admin/kube-controller-manager/>kube-controller-manager</a> dan <a href=/docs/admin/kube-scheduler/>kube-scheduler</a>.</p></blockquote><h3 id=node>Node</h3><p><em>Node</em> di dalam klaster Kubernetes adalah mesin (mesin virtual maupun fisik) yang
menjalankan aplikasi kamu. Master mengontrol setiap node; kamu akan jarang berinteraksi
dengan <em>node</em> secara langsung.</p><h4 id=metadata-objek>Metadata objek</h4><ul><li><a href=/id/docs/concepts/overview/working-with-objects/annotations/>Anotasi</a></li></ul><h2 id=selanjutnya>Selanjutnya</h2><p>Jika kamu ingin menulis halaman konsep, perhatikan
<a href=/docs/home/contribute/page-templates/>cara penggunaan template pada laman</a>
untuk informasi mengenai konsep tipe halaman dan <em>template</em> konsep.</p></div></div><div class=td-content style=page-break-before:always><h1 id=pg-0554ac387412eaf4e6e89b2f847dacde>1 - Ikhtisar</h1></div><div class=td-content><h1 id=pg-45bdca6129cf540121623e903c18ba46>1.1 - Apa itu Kubernetes?</h1><div class=lead>Kubernetes merupakan <em>platform open-source</em> yang digunakan untuk melakukan manajemen <em>workloads</em> aplikasi yang dikontainerisasi, serta menyediakan konfigurasi dan otomatisasi secara deklaratif. Kubernetes berada di dalam ekosistem yang besar dan berkembang cepat. <em>Service</em>, <em>support</em>, dan perkakas Kubernetes tersedia secara meluas. Kubernetes merupakan <em>platform open-source</em> yang digunakan untuk melakukan manajemen <em>workloads</em> aplikasi yang dikontainerisasi, serta menyediakan konfigurasi dan otomatisasi secara deklaratif. Kubernetes berada di dalam ekosistem yang besar dan berkembang cepat. <em>Service</em>, <em>support</em>, dan perkakas Kubernetes tersedia secara meluas.</div><p>Laman ini merupakan ikhtisar Kubernetes.</p><p>Kubernetes merupakan <i>platform open-source</i> yang digunakan untuk melakukan
manajemen <i>workloads</i> aplikasi yang dikontainerisasi, serta menyediakan
konfigurasi dan otomatisasi secara deklaratif. Kubernetes berada di dalam ekosistem
yang besar dan berkembang cepat. <i>Service</i>, <i>support</i>, dan perkakas
Kubernetes tersedia secara meluas.</p><p>Google membuka Kubernetes sebagai proyek <i>open source</i> pada tahun 2014.
Kubernetes dibangun berdasarkan <a href=https://research.google.com/pubs/pub43438.html>pengalaman Google selama satu setengah dekade dalam menjalankan workloads</a>
bersamaan dengan kontribusi berupa ide-ide terbaik yang diberikan oleh komunitas.</p><h2 id=mengapa-kubernetes-dan-hal-apa-saja-yang-dapat-dilakukan-oleh-kubernetes>Mengapa Kubernetes dan hal apa saja yang dapat dilakukan oleh Kubernetes?</h2><p>Kubernetes memiliki sejumlah fitur yang dapat dijabarkan sebagai berikut:</p><ul><li><i>platform</i> kontainer</li><li><i>platform microservices</i></li><li><i>platform cloud</i> yang tidak mudah dipindahkan</li></ul><p>Kubernetes menyediakan manajemen <i>environment</i> yang berpusat pada kontainer.
Kubernetes melakukan orkestrasi terhadap <i>computing</i>, <i>networking</i>,
dan inftrastruktur penyimpanan. Fitur inilah yang kemudian membuat konsep Platform as a Service (PaaS)
menjadi lebih sederhana dilengkapi dengan fleksibilitas yang dimiliki oleh Infrastructure as a Service (IaaS).</p><h2 id=lalu-apa-yang-menyebabkan-kubernetes-disebut-sebagai-sebuah-platform>Lalu apa yang menyebabkan Kubernetes disebut sebagai sebuah platform?</h2><p>Meskipun Kubernetes menyediakan banyak fungsionalitas, selalu ada keadaan dimana
hal tersebut membutuhkan fitur baru. <i>Workflow</i> spesifik yang terkait dengan
proses pengembangan aplikasi dapat ditambahkan pada <i>streamline</i> untuk meningkatkan
produktivitas developer. Orkestrasi ad-hoc yang dapat diterima biasanya membutuhkan desain
otomatisasi yang kokoh agar bersifat <i>scalable</i>. Hal inilah yang membuat
Kubernetes juga didesain sebagai <i>platform</i> untuk membangun ekosistem komponen dan
dan perkakas untuk memudahkan proses <i>deployment</i>, <i>scale</i>, dan juga manajemen
aplikasi.</p><p><a href>Labels</a> memudahkan pengguna mengkategorisasikan <i>resources</i> yang mereka miliki
sesuai dengan kebutuhan. <a href>Annotations</a> memungkinkan pengguna untuk menambahkan informasi
tambahan pada <i>resource</i> yang dimiliki.</p><p>Selain itu, <a href>Kubernetes control plane</a> dibuat berdasarkan
<a href=/docs/reference/using-api/api-overview/>API</a> yang tersedia bagi pengguna dan developer. Pengguna
dapat mengimplementasikan kontroler sesuai dengan kebutuhan mereka, contohnya adalah
<a href=https://github.com/kubernetes/community/blob/main/contributors/devel/scheduler.md>schedulers</a>,
dengan <a href>API kustom yang mereka miliki</a>, kontroler kustom ini kemudian dapat digunakan
pada <a href>command-line
tool</a> generik yang ada.</p><p><a href=https://git.k8s.io/community/contributors/design-proposals/architecture/architecture.md>Desain</a>
inilah yang memungkinkan beberapa sistem lain untuk dapat dibangun di atas Kubernetes.</p><h2 id=lalu-hal-apakah-yang-tidak-termasuk-di-dalam-kubernetes>Lalu hal apakah yang tidak termasuk di dalam Kubernetes?</h2><p>Kubernetes bukanlah sebuah <i>PaaS (Platform as a
Service)</i> yang biasanya. Meskipun Kubernetes dijalankan pada tingkatan kontainer
dan bukan pada tingkatan perangkat keras, Kubernetes menyediakan beberapa fitur
yang biasanya disediakan oleh Paas, seperti <i>deployment</i>, <i>scaling</i>,
<i>load balancing</i>, <i>logging</i>, dan <i>monitoring</i>. Akan tetapi,
Kubernetes bukanlah sistem monolitik, melainkan suatu sistem yang bersifat sebagai
<i>bulding block</i> dan <i>pluggable</i> yang dapat digunakan untuk membangun sebuah
platform yang dibutuhkan oleh developer dengan tetap mengutamakan konsep fleksibilitas.</p><p>Kubernetes:</p><ul><li>Tidak melakukan limitasi terhadap aplikasi yang di-support. Kubernetes bertujuan
untuk mendukung berbagai variasi <i>workloads</i>, termasuk
<i>stateless</i>, <i>stateful</i>, dan <i>data-processing</i>. Jika sebuah
aplikasi dapat dijalankan di atas kontainer, maka aplikasi tersebut juga dapat
dijalankan di atas Kubernetes.</li><li>Tidak menyediakan mekanisme untuk melakukan <i>deploy</i> kode sumber
maupun mekanisme <i>build</i> sebuah aplikasi. <i>Continuous Integration, Delivery, and Deployment
(CI/CD) workflows</i> ditentukan oleh preferensi serta kebutuhan teknis organisasi.</li><li>Tidak menyediakan <i>application-level services</i>, seperti <i>middleware
(e.g., message buses)</i>, <i>data-processing frameworks (for example,
Spark)</i>, <i>databases (e.g., mysql)</i>, <i>caches</i>, maupun <i>cluster storage systems (e.g.,
Ceph)</i> sebagai suatu <i>built-in services</i>. Komponen tersebut dapat dijalankan di atas Kubernetes, dan/atau
dapat diakses oleh aplikasi yang dijalankan di atas Kubernetes melalui sebuah mekanisme tidak mudah dipindahkan
misalnya saja <i>Open Service Broker</i>.</li><li>Tidak membatasi penyedia layanan <i>logging</i>, <i>monitoring</i>, maupun <i>alerting</i> yang digunakan.
Kubernetes menyediakan <i>proof of concept</i> dan mekanisme integrasi yang dapat digunakan
untuk mengumpulkan serta mengekspor metriks yang ada.</li><li>Tidak menyediakan atau mengharuskan penggunaan <i>configuration language/system (e.g.,
<a href=https://github.com/google/jsonnet>jsonnet</a>)</i>. Kubernetes menyediakan suatu API deklaratif
yang dapat digunakan oleh berbagai jenis spesifikasi deklaratif.</li><li>Tidak menyediakan atau mengadaptasi sebuah konfigurasi, <i>maintenance</i>, manajemen, atau
<i>self-healing</i> mesin dengan spesifikasi khusus.</li></ul><p>Sebagai tambahan, Kubernetes bukanlah sebuah <em>sitem orkestrasi biasa</em>. Bahkan pada kenyataannya,
Kubernetes menghilangkan kebutuhan untuk melakukan orkestrasi. Definisi teknis dari
<em>orkestrasi</em> merupakan eksekusi dari sebuah workflow yang sudah didefinisikan sebelumnya: pertama kerjakan A, kemudian B,
dan terakhir C. Sebaliknya, Kubernetes disusun oleh seperangkat
proses kontrol yang dapat idekomposisi yang selalu menjalankan <i>state</i> yang ada
saat ini hingga sesuai dengan <i>state</i> yang dinginkan.
Kita tidak perlu peduli proses apa saja yang perlu dilakukan untuk melakukan A hingga C.
Mekanisme kontrol yang tersentralisasi juga tidak dibutuhkan. Dengan demikian, sistem yang
dihasilkan lebih mudah digunakan lebih kokoh, serta lebih <i>extensible</i>.</p><h2 id=mengapa-kontainer>Mengapa kontainer?</h2><p>Mencari alasan kenapa kita harus menggunakan kontainer?</p><p><img src=/images/docs/why_containers.svg alt="Mengapa kontainer?"></p><p><em>Cara Lama</em> untuk melakukan mekanisme <i>deploy</i> suatu aplikasi
adalah dengan cara instalasi aplikasi tersebut pada sebuah mesin
dengan menggunakan <i>package manager</i> yang dimiliki oleh sistem operasi
mesin tersebut. Hal ini menciptakan suatu ketergantungan antara <i>executables</i>,
konfigurasi, serta ketergantungan lain yang dibutuhkan aplikasi dengan sistem operasi
yang digunakan oleh mesin. Untuk mengatasi hal ini, tentunya bisa saja kita melakukan
mekanisme <i>build</i> suatu <i>image</i> VM yang <i>immutable</i> untuk mendapatkan
mekanisme <i>rollouts</i> dan <i>rollback</i> yang dapat diprediksi.
Meskipun demikian, VM masih dianggap "berat" dan tidak tidak mudah dipindahkan.</p><p><em>Cara Baru</em> adalah dengan melakukan mekanisme <i>deploy</i> kontainer pada tingkatan
virtualisasi di level sistem operasi (OS) bukan pada tingkatan virtualisasi perangkat keras.
Kontainer ini berada dalam lingkungan yang terisolasi satu sama lain serta terisolasi dengan
mesin dimana kontainer ini berada. Kontainer ini memiliki <i>filesystems</i> masing-masing.
Selain itu, setiap kontainer tidak dapat "melihat" <i>process</i> yang sedang dijalankan di
kontainer lain. Selain itu <i>resource</i> komputasi yang digunakan oleh kontainer
ini juga dapat dibatasi. Kontainer juga dapat dengan lebih mudah di-<i>build</i> jika
dibandingkan dengan VM, karena kontainer tidak bergantung pada <i>filesystem</i>
yang dimiliki mesin, serta dengan mudah dapat didistribusikan.</p><p>Karena kontainer ukurannya kecil dan lebih cepat, sebuah aplikasi dapat dibangun di setiap
<i>image</i> kontainer. Mekanisme pemetaan satu-satu antara kontainer dan aplikasi
inilah yang membuka keuntungan secara meyeluruh yang dapat diberikan oleh kontainer.
Dengan menggunakan kontainer, <i>image</i> kontainer dapat dibuat diwaktu rilis aplikasi.
Pembuatan <i>image</i> ini memungkinkan aplikasi secara konsisten dirilis pada
<i>environment</i> <i>development</i> maupun <i>production</i>. Selain itu,
kontainer juga memiliki transparasi yang lebih tinggi dibandingkan dengan VM. Maksudnya,
infrastruktur punya tugas untuk mengatur lifecycle seluruh process yang ada di dalam kontainer. Ini bukanlah lagi tugas sebuah supervisor process yang tersembunyi di dalam kontainer.</p><p>Secara garis besar, penggunaan kontainer memiliki keuntungan sebagai berikut:</p><ul><li><strong>Mekanisme pembuatan aplikasi serta proses deployment yang lebih efektif</strong>:
Kontainer dapat meningkatkan kemudahan dan efisiensi jika dibandingkan dengan penggunaan VM.</li><li><strong>Continuous development, integration, and deployment</strong>:
Digunakan untuk melakukan proses <i>build</i> dan <i>deploy</i> yang sering dilakukan
serta kemudahan mekanisme <i>rollback</i> karena image yang ada sifatnya <i>immutable</i>.</li><li><strong>Pemisahan kepentingan antara Dev dan Ops</strong>:
Pembuatan <i>image</i> container dilakukan pada saat rilis dan bukan pada saat <i>deploy</i>
mengurangi ketergantungan aplikasi dan infrastruktur.</li><li><strong>Observabilitas</strong>
Tidak hanya informasi dan metriks pada level OS, tapi juga kesehatan aplikasi dan <i>signal</i> lain.</li><li><strong>Konsistensi <i>environment</i> pada masa pengembangan , <i>testing</i>, dan <i>production</i></strong>:
Memiliki perilaku yang sama baik ketika dijalankan di mesin lokal maupun penyedia layanan <i>cloud</i>.</li><li><strong>Portabilitas antar penyedia layanan <i>cloud</i> maupun distribusi OS</strong>:
Dapat dijalankan pada Ubuntu, RHEL, CoreOS, on-prem, Google Kubernetes Engine, dan dimanapun.</li><li><strong>Manajemen yang bersifat Aplikasi sentris</strong>:
Meningkatkan level abstraksi dari proses menjalankan OS pada perangkat keras virtual
ke proses menjalankan aplikasi pada sebuah OS dengan menggunakan <i>resource</i> logis.</li><li><strong><a href=https://martinfowler.com/articles/microservices.html>Mikroservis</a> yang renggang (loosely coupled), terdistribusi, elastis, dan terliberasi</strong>:
Aplikasi dapat dipecah menjadi komponen yang lebih kecil yang independen dan dapat
di-<i>deploy</i> dan diatur secara dinamis -- bukan sebuah sistem monolitik yang dijalankan pada
sebuah mesin yang hanya punya satu tujuan.</li><li><strong>Isolasi <i>resource</i></strong>:
Performa aplikasi yang bisa diprediksi.</li><li><strong>Utilisasi <i>resource</i></strong>:
Efisiensi yang tinggi</li></ul><h2 id=apakah-arti-kubernetes-k8s>Apakah arti Kubernetes? K8s?</h2><p>Nama <strong>Kubernetes</strong> berasal dari Bahasa Yunani, yang berarti <em>juru mudi</em> atau
<em>pilot</em>, dan merupakan asal kata <em>gubernur</em> dan
<a href="http://www.etymonline.com/index.php?term=cybernetics">cybernetic</a>. <em>K8s</em>
merupakan sebuah singkatan yang didapat dengan mengganti 8 huruf "ubernete" dengan
"8".</p><h2 id=selanjutnya>Selanjutnya</h2><ul><li>Siap untuk <a href=/docs/setup/>memulai</a>?</li><li>Untuk penjelasan lebih rinci, silahkan lihat <a href=/docs/home/>Dokumentasi Kubernetes</a>.</li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-13b0f1dbe89228e3d76d2ac231e245f1>1.2 - Komponen-Komponen Kubernetes</h1><div class=lead>Sebuah klaster Kubernetes terdiri dari komponen yang merepresentasikan bidang kontrol dan sepasang mesin yaitu <em>nodes</em>.</div><p>Dokumen ini merupakan ikhtisar yang mencakup berbagai komponen
yang dibutuhkan agar klaster Kubernetes dapat berjalan secara fungsional.</p><h2 id=komponen-i-master-i>Komponen <i>Master</i></h2><p>Komponen <i>master</i> menyediakan <i>control plane</i> bagi klaster.
Komponen ini berperan dalam proses pengambilan secara global
pada klaster (contohnya, mekanisme <i>schedule</i>), serta berperan dalam proses
deteksi serta pemberian respons terhadap <i>events</i> yang berlangsung di dalam klaster
(contohnya, penjadwalan pod baru apabila jumlah replika yang ada pada
<i>replication controller</i> tidak terpenuhi).</p><p>Komponen master dapat dijalankan di mesin manapun yang ada di klaster. Meski begitu,
untuk memudahkan proses yang ada, <i>script</i> inisiasi awal yang dijalankan
biasanya memulai komponen master pada mesin yang sama, serta tidak menjalankan
kontainer bagi pengguna di mesin ini. Contoh konfigurasi <i>multi-master VM</i>
dapat dilihat di modul [Membangun Klaster HA] (/docs/admin/high-availability/).</p><h3 id=kube-apiserver>kube-apiserver</h3><p>Komponen <em>control plane</em> yang mengekspos API Kubernetes. Merupakan <em>front-end</em> dari <em>control plane</em> Kubernetes.</p><p>Komponen ini didesain agar dapat diskalakan secara horizontal. Lihat <a href=/docs/admin/high-availability/>Membangun Klaster HA</a>.</p><h3 id=etcd>etcd</h3><p>Penyimpanan <i>key value</i> konsisten yang digunakan sebagai penyimpanan data klaster Kubernetes.</p><p>Selalu perhatikan mekanisme untuk mem-<i>backup</i> data etcd pada klaster Kubernetes kamu. Untuk informasi lebih lanjut tentang etcd, lihat <a href=https://etcd.io/docs>dokumentasi etcd</a>.</p><h3 id=kube-scheduler>kube-scheduler</h3><p>Komponen <em>control plane</em> yang bertugas mengamati <a class=glossary-tooltip title='Unit Kubernetes yang paling sederhana dan kecil. Sebuah Pod merepresentasikan sebuah set kontainer yang dijalankan pada kluster kamu.' data-toggle=tooltip data-placement=top href=/docs/concepts/workloads/pods/pod-overview/ target=_blank aria-label=Pod>Pod</a> baru yang belum ditempatkan di node manapun dan kemudian memilihkan <a class=glossary-tooltip title='A node is a worker machine in Kubernetes.' data-toggle=tooltip data-placement=top href=/docs/concepts/architecture/nodes/ target=_blank aria-label=Node>Node</a> di mana Pod baru tersebut akan dijalankan.</p><p>Faktor-faktor yang dipertimbangkan untuk keputusan penjadwalan termasuk: kebutuhan sumber daya secara individual dan kolektif, batasan perangkat keras/perangkat lunak/peraturan, spesifikasi afinitas dan nonafinitas, lokalisasi data, interferensi antar beban kerja dan tenggat waktu.</p><h3 id=kube-controller-manager>kube-controller-manager</h3><p>Komponen <em>control plane</em> yang menjalankan pengontrol.</p><p>Secara logis, setiap pengontrol adalah sebuah proses yang berbeda, tetapi untuk mengurangi kompleksitas, kesemuanya dikompilasi menjadi sebuah biner (<em>binary</em>) yang dijalankan sebagai satu proses.</p><p>Kontroler-kontroler ini meliputi:</p><ul><li>Kontroler <i>Node</i> : Bertanggung jawab untuk mengamati dan memberikan
respons apabila jumlah <i>node</i> berkurang.</li><li>Kontroler Replikasi : Bertanggung jawab untuk menjaga jumlah <i>pod</i> agar
jumlahnya sesuai dengan kebutuhan setiap objek kontroler replikasi yang ada di sistem.</li><li>Kontroler <i>Endpoints</i> : Menginisiasi objek <i>Endpoints</i>
(yang merupakan gabungan <i>Pods</i> dan <i>Services</i>).</li><li>Kontroler <i>Service Account & Token</i>: Membuat akun dan
akses token API standar untuk setiap <i>namespaces</i> yang dibuat.</li></ul><h3 id=cloud-controller-manager>cloud-controller-manager</h3><p><a href=/docs/tasks/administer-cluster/running-cloud-controller/>Cloud-controller-manager</a> merupakan kontroler yang berinteraksi dengan penyedia layanan <i>cloud</i>.
Kontroler ini merupakat fitur alfa yang diperkenalkan pada Kubernetes versi 1.6.</p><p><i>Cloud-controller-manager</i> hanya menjalankan iterasi kontroler <i>cloud-provider-specific</i> .
Kamu harus menonaktifkan iterasi kontroler ini pada <i>kube-controller-manager</i>.
Kamu dapat menonaktifka iterasi kontroler ini dengan mengubah nilai argumen <code>--cloud-provider</code> dengan <code>external</code>
ketika menginisiasi <i>kube-controller-manager</i>.</p><p>Adanya <i>cloud-controller-manager</i> memungkinkan kode yang dimiliki oleh penyedia layanan <i>cloud</i>
dan kode yang ada pada Kubernetes saling tidak bergantung selama masa <i>development</i>.
Pada versi sebelumnya, Kubernetes bergantung pada fungsionalitas spesifik yang disediakan oleh
penyedia layanan <i>cloud</i>. Di masa mendatang, kode yang secara spesifik dimiliki oleh
penyedia layanan <i>cloud</i> akan dipelihara oleh penyedia layanan <i>cloud</i> itu sendiri,
kode ini selanjutnya akan dihubungkan dengan <i>cloud-controller-manager</i> ketika Kubernetes dijalankan.</p><p>Kontroler berikut ini memiliki keterkaitan dengan penyedia layanan <i>cloud</i>:</p><ul><li>Kontroler Node : Melakukan pengecekan pada penyedia layanan <i>cloud</i> ketika menentukan apakah sebuah <i>node</i> telah dihapus pada <i>cloud</i> apabila <i>node</i> tersebut berhenti memberikan respons.</li><li>Kontroler Route : Melakukan pengaturan awal <i>route</i> yang ada pada penyedia layanan <i>cloud</i></li><li>Kontroler Service : Untuk membuat, memperbaharui, menghapus <i>load balancer</i> yang disediakan oleh penyedia layanan <i>cloud</i></li><li>Kontroler Volume : Untuk membuat, meng-attach, dan melakukan <i>mount volume</i> serta melakukan inetraksi dengan penyedia layanan <i>cloud</i> untuk melakukan orkestrasi <i>volume</i></li></ul><h2 id=komponen-i-node-i>Komponen <i>Node</i></h2><p>Komponen ini ada pada setiap <i>node</i>, fungsinya adalah melakukan pemeliharaan terhadap <i>pod</i> serta menyediakan <i>environment runtime</i> bagi Kubernetes.</p><h3 id=kubelet>kubelet</h3><p>Agen yang dijalankan pada setiap node di klaster yang bertugas untuk memastikan kontainer dijalankan di dalam Pod.</p><h3 id=kube-proxy>kube-proxy</h3><p><a href=/docs/admin/kube-proxy/>kube-proxy</a> membantu abstraksi service Kubernetes melakukan tugasnya. Hal ini terjadi dengan cara memelihara aturan-aturan jaringan (network rules) serta meneruskan koneksi yang ditujukan pada suatu host.</p><h3 id=i-container-runtime-i><i>Container Runtime</i></h3><p><i>Container runtime</i> adalah perangkat lunak yang bertanggung jawab dalam menjalankan kontainer.
Kubernetes mendukung beberapa <i>runtime</i>, diantaranya adalah: <a href=http://www.docker.com>Docker</a>, <a href=https://containerd.io>containerd</a>, <a href=https://cri-o.io/>cri-o</a>, <a href=https://github.com/kubernetes-incubator/rktlet>rktlet</a> dan semua implementasi <a href=https://github.com/kubernetes/community/blob/master/contributors/devel/sig-node/container-runtime-interface.md>Kubernetes CRI (Container Runtime Interface)</a>.</p><h2 id=i-addons-i><i>Addons</i></h2><p><i>Addons</i> merupakan pod dan service yang mengimplementasikan fitur-fitur yang diperlukan klaster.</p><p>Beberapa <i>addons</i> akan dijelaskan selanjutnya.</p><h3 id=dns>DNS</h3><p>Meskipun tidak semua <i>addons</i> dibutuhkan, semua klaster Kubernetes hendaknya
memiliki DNS klaster. Komponen ini penting karena banyak dibutuhkan oleh komponen
lainnya.</p><p><a href=/id/docs/concepts/cluster-administration/addons/>Klaster DNS</a> adalah server DNS, selain beberapa server DNS lain yang sudah ada di
<i>environment</i> kamu, yang berfungsi sebagai catatan DNS bagi Kubernetes <i>services</i></p><p>Kontainer yang dimulai oleh kubernetes secara otomatis akan memasukkan server DNS ini
ke dalam mekanisme pencarian DNS yang dimilikinya.</p><h3 id=i-web-ui-i-dasbor><i>Web UI</i> (Dasbor)</h3><p><a href=/id/docs/tasks/access-application-cluster/web-ui-dashboard/>Dasbor</a> adalah antar muka berbasis web multifungsi yang ada pada klaster Kubernetes.
Dasbor ini memungkinkan user melakukan manajemen dan <i>troubleshooting</i> klaster maupun
aplikasi yang ada pada klaster itu sendiri.</p><h3 id=i-container-resource-monitoring-i><i>Container Resource Monitoring</i></h3><p><a href=/docs/tasks/debug-application-cluster/resource-usage-monitoring/>Container Resource Monitoring</a> mencatat metrik <i>time-series</i> yang diperoleh
dari kontainer ke dalam basis data serta menyediakan antar muka yang dapat digunakan
untuk melakukan pencarian data yang dibutuhkan.</p><h3 id=i-cluster-level-logging-i><i>Cluster-level Logging</i></h3><p><a href=/id/docs/concepts/cluster-administration/logging/>Cluster-level logging</a> bertanggung jawab mencatat <i>log</i> kontainer pada
penyimpanan <i>log</i> terpusat dengan antar muka yang dapat digunakan untuk melakukan
pencarian.</p></div><div class=td-content style=page-break-before:always><h1 id=pg-0c745f42e623d2b70a53bc0e6db73d95>1.3 - API Kubernetes</h1><div class=lead>API Kubernetes membuatmu dapat melakukan <em>query</em> dan memanipulasi keadaan objek dalam Kubernetes. Inti dari bidang kontrol Kubernetes adalah <em>server</em> API dan HTTP API yang diekspos. Pengguna, berbagai bagian klastermu, dan komponen eksternal semuanya berkomunikasi satu sama lain melalui server API.</div><p>Secara keseluruhan standar yang digunakan untuk API dijelaskan di dalam <a href=https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md>dokumentasi API standar</a>.</p><p><i>Endpoints API</i>, <i>resource types</i> serta contoh penggunaan dijelaskan di dalam <a href=/docs/reference>API Reference</a>.</p><p>Akses <i>remote</i> penggunaan API dijelaskan di dalam <a href=/docs/reference/access-authn-authz/controlling-access/>dokumentasi akses API</a>.</p><p>API Kubernetes juga berperan sebagai skema konfigurasi yang deklaratif di dalam sistem.. Sementara itu, <a href=/docs/reference/kubectl/overview/>kubectl</a> merupakan <i>command-line</i> yang dapat digunakan untuk membuat, menmperbaharui, menghapus, dan mendapatkan obyek API.</p><p>Kubernetes menyimpan bentuk terserialisasi dari obyek API yang dimilikinya di dalam <a href=https://coreos.com/docs/distributed-configuration/getting-started-with-etcd/>etcd</a>.</p><p>Kubernetes sendiri dibagi menjadi beberapa komponen yang saling dapat saling interaksi melalui API.</p><h2 id=perubahan-api>Perubahan API</h2><p>Berdasarkan pengalaman kami, semua sistem yang berhasil memerlukan kebutuhan
untuk terus tumbuh dan berkembang seiring dengan bertambahnya kebutuhan
yang ada. Dengan demikian, kami berekspektasi bahwa API akan selalu berubah seiring dengan bertambahnya kebutuhan yang ada.
Meski begitu, perubahan yang ada akan selalu kompatibel dengan implementasi sebelumnya, untuk jangka waktu tertentu.
Secara umum, penambahan pada sebuah resource API atau field resource bisa sering terjadi.. Penghapusan <i>resource API</i> atau suatu <i>field</i>, di sisi lain,
diharapkan untuk dapat memenuhi <a href=/docs/reference/using-api/deprecation-policy/>kaidah deprecation API</a>.</p><p>Hal-hal apa saja yang perlu diperhatikan untuk menjamin kompatibilitas API
secara rinci dibahas di dalam <a href=https://git.k8s.io/community/contributors/devel/sig-architecture/api_changes.md>dokumentasi perubahan API</a>.</p><h2 id=swagger-and-openapi-definition>Swagger and OpenAPI Definition</h2><p>Detail mengenai API didokumentasikan dengan menggunakan <a href=https://www.openapis.org/>OpenAPI</a>.</p><p>Semenjak Kubernetes versi 1.10, Kubernetes menghadirkan spesifikasi <i>OpenAPI</i> melalui <i>endpoint</i> <code>/openapi/v2</code>.
Format <i>request</i> dapat diterapkan dengan cara menambahkan <i>header HTTP</i>:</p><table><thead><tr><th>Header</th><th>Opsi</th></tr></thead><tbody><tr><td>Accept</td><td><code>application/json</code>, <code>application/com.github.proto-openapi.spec.v2@v1.0+protobuf</code> (<i>content-type</i> standar yang digunakan adalah <code>application/json</code> untuk <code>*/*</code>)</td></tr><tr><td>Accept-Encoding</td><td><code>gzip</code></td></tr></tbody></table><p>Sebelum versi 1.14, terdapat 4 buah <i>endpoint</i> yang menyediakan spesifikasi <i>OpenAPI</i>
dalam format berbeda yang dapat digunakan (<code>/swagger.json</code>, <code>/swagger-2.0.0.json</code>, <code>/swagger-2.0.0.pb-v1</code>, <code>/swagger-2.0.0.pb-v1.gz</code>).
<i>Endpoint</i> ini bersifat <i>deprecated</i> dan akan dihapus pada Kubernetes versi 1.14.</p><p><strong>Cara mendapatkan spesifikasi <i>OpenAPI</i></strong>:</p><table><thead><tr><th>Sebelum 1.10</th><th>Mulai Kubernetes 1.10</th></tr></thead><tbody><tr><td>GET /swagger.json</td><td>GET /openapi/v2 <strong>Accept</strong>: application/json</td></tr><tr><td>GET /swagger-2.0.0.pb-v1</td><td>GET /openapi/v2 <strong>Accept</strong>: <a href=mailto:application/com.github.proto-openapi.spec.v2@v1.0>application/com.github.proto-openapi.spec.v2@v1.0</a>+protobuf</td></tr><tr><td>GET /swagger-2.0.0.pb-v1.gz</td><td>GET /openapi/v2 <strong>Accept</strong>: <a href=mailto:application/com.github.proto-openapi.spec.v2@v1.0>application/com.github.proto-openapi.spec.v2@v1.0</a>+protobuf <strong>Accept-Encoding</strong>: gzip</td></tr></tbody></table><p>Kubernetes juga menyediakan alternatif mekanisme serialisasi lain,
yaitu dengan menggunakan <i>Protobuf</i>, yang secara umum digunakan untuk mekanisme komunikasi
intra-klaster, hal ini didokumentasikan di dalam <a href=https://github.com/kubernetes/community/blob/master/contributors/design-proposals/api-machinery/protobuf.md>proposal desain</a>
serta berkas IDL sebagai bentuk spesifikasi skema berada dalam <i>package</i> Go</p><p>Sebelum Kubernetes versi 1.14, <i>apiserver</i> Kubernetes juga mengekspos API
yang dapat digunakan untuk mendapatkan spesifikasi <a href=http://swagger.io/>Swagger v1.2</a> pada <i>endpoint</i> <code>/swaggerapi</code>.
<i>Endpoint</i> ini akan sudah bersifat <i>deprecated</i> dan akan dihapus pada
Kubernetes versi 1.14.</p><h2 id=pemberian-versi-pada-api>Pemberian Versi pada API</h2><p>Untuk memudahkan restrukturisasi field dan resource yang ada,
Kubernetes menyediakan beberapa versi API yang berada pada <i>path</i> yang berbeda,
misalnya <code>/api/v1</code> atau <code>/apis/extensions/v1beta1</code>.</p><p>Kita dapat memilih versi yang akan digunakan pada tingkatan API
dan bukan pada tingkatan <i>field</i> atau <i>resource</i> untuk memastikan
API yang digunakan memperlihatkan gambaran yang jelas serta konsisten
mengenai <i>resoure</i> dan sifat sistem yang ada.</p><p>Perhatikan bahwa pemberian versi pada API dan pemberian versi pada API dan perangkat lunak memiliki keterkaitan secara tak langsung.
Proposal <a href=https://git.k8s.io/community/contributors/design-proposals/release/versioning.md>API and release
versioning</a> memberikan deskripsi keterkaitan antara
pemberian versi pada API dan pemberian versi pada perangkat lunak.</p><p>API dengan versi yang berbeda menunjukan tingkatan kestabilan dan ketersediaan yang diberikan pada versi tersebut.
Kriteria untuk setiap tingkatan dideskripsikan secara lebih detail di dalam
<a href=https://git.k8s.io/community/contributors/devel/sig-architecture/api_changes.md#alpha-beta-and-stable-versions>dokumentasi perubahan API</a>. They are summarized here:</p><ul><li>Tingkatan <i>Alpha</i>:<ul><li>Nama dari versi ini mengandung string <code>alpha</code> (misalnya, <code>v1alpha1</code>).</li><li>Bisa jadi terdapat <i>bug</i>. Secara <i>default</i> fitur ini tidak diekspos.</li><li>Ketersediaan untuk fitur yang ada bisa saja dihilangkan pada suatu waktu tanpa pemberitahuan sebelumnya.</li><li>API yang ada mungkin saja berubah tanpa memperhatikan kompatibilitas dengan versi perangkat lunak sebelumnya.</li><li>Hanya direkomendasikan untuk klaster yang digunakan untuk tujuan <i>testing</i>.</li></ul></li><li>Tingkatan <i>Beta</i>:<ul><li>Nama dari versi ini mengandung string <code>beta</code> (misalnya <code>v2beta3</code>).</li><li>Kode yang ada sudah melalui mekanisme <i>testing</i> yang cukup baik. Menggunakan fitur ini dianggap cukup aman. Fitur ini diekspos secara <i>default</i>.</li><li>Ketersediaan untuk fitur secara menyeluruh tidak akan dihapus, meskipun begitu detail untuk suatu fitur bisa saja berubah.</li><li>Skema dan/atau semantik dari suatu obyek mungkin saja berubah tanpa memerhatikan kompatibilitas pada rilis <i>beta</i> selanjutnya.
Jika hal ini terjadi, kami akan menyediakan suatu instruksi untuk melakukan migrasi di versi rilis selanjutnya. hal ini bisa saja terdiri dari penghapusan, pengubahan, ataupun pembuatan
obyek API. Proses pengubahan mungkin saja membutuhkan pemikiran yang matang. Dampak proses ini bisa saja menyebabkan <i>downtime</i> aplikasi yang bergantung pada fitur ini.</li><li>Disarankan hanya untuk digunakan untuk penggunaan yang untuk penggunaan yang tidak berdampak langsung pada bisnis kamu.</li><li><strong>Kami mohon untuk mencoba versi <i>beta</i> yang kami sediakan dan berikan masukan terhadap fitur yang kamu pakai! Apabila fitur tersebut sudah tidak lagi berada di dalam tingkatan <i>beta</i> perubahan yang kami buat terhadap fitur tersebut bisa jadi tidak lagi dapat digunakan</strong></li></ul></li><li>Tingkatan stabil:<ul><li>Nama dari versi ini mengandung string <code>vX</code> dimana <code>X</code> merupakan bilangan bulat.</li><li>Fitur yang ada pada tingkatan ini akan selalu muncul di rilis berikutnya.</li></ul></li></ul><h2 id=i-api-groups-i><i>API groups</i></h2><p>Untuk memudahkan proses ekstensi suatu API Kubernetes, kami mengimplementasikan <a href=https://git.k8s.io/community/contributors/design-proposals/api-machinery/api-group.md><em>API groups</em></a>.
<i>API group</i> ini dispesifikasikan di dalam <i>path</i> <i>REST</i> serta di dalam <i>field</i> <code>apiVersion</code> dari sebuah obyek yang sudah diserialisasi.</p><p>Saat ini, terdapat beberapa <i>API groups</i> yang digunakan:</p><ol><li><p>Kelompok <em>core</em>, seringkali disebut sebagai <em>legacy group</em>, berada pada <i>path</i> <i>REST</i> <code>/api/v1</code> serta menggunakan <code>apiVersion: v1</code>.</p></li><li><p><i>Named groups</i> berada pada <i>path</i> <i>REST</i> <code>/apis/$GROUP_NAME/$VERSION</code>, serta menggunakan <code>apiVersion: $GROUP_NAME/$VERSION</code>
(misalnya <code>apiVersion: batch/v1</code>). Daftar menyeluruh mengenai apa saja <i>API groups</i> dapat dilihat di <a href=/docs/reference/>Kubernetes API reference</a>.</p></li></ol><p>Ekstensi API dengan custom resources dapat dilakukan melalui dua buah path:</p><ol><li><a href>CustomResourceDefinition</a>
digunakan jika memerlukan seluruh set semantik Kubernetes API, pengguna boleh implementasi apiserver sendiri dengan menggunakan aggregator.</li><li>Pengguna yang membutuhkan seperangkat semantik API Kubernetes API dapat mengimplementasikan <i>apiserver</i> mereka sendiri.
dengan menggunakan <a href>aggregator</a>
untuk membuat integrasi dengan klien menjadi lebih mudah.</li></ol><h2 id=mengaktifkan-i-api-groups-i>Mengaktifkan <i>API groups</i></h2><p>Beberapa <i>resources</i> dan <i>API groups</i> sudah diaktifkan secara <i>default</i>.
<i>Resource</i> dan <i>API groups</i> ini dapat diaktifkan dan dinonaktifkan dengan mengatur penanda <code>--runtime-config</code>
pada <i>apiserver</i>. <code>--runtime-config</code> menerima nilai yang dipisahkan oleh koma. Sebagai contoh: untuk menonaktifkan batch/v1, tetapkan
<code>--runtime-config=batch/v1=false</code>, untuk mengaktifkan batch/v2alpha1, tetapkan <code>--runtime-config=batch/v2alpha1</code>.
Penanda menerima nilai yang dipisahkan oleh pasangan <code>key=value</code> yang mendeskripsikan konfigurasi <i>runtime</i> pada <i>apiserver</i>.</p><p>PENTING: Melakukan proses mengaktifkan atau menonaktifkan <i>groups</i> atau <i>resources</i>
membutuhkan mekanisme <i>restart</i> <i>apiserver</i> dan <i>controller-manager</i>
agar <i>apiserver</i> dapat menerima perubahan <code>--runtime-config</code>.</p><h2 id=mengaktifkan-i-resources-i-di-dalam-i-groups-i>Mengaktifkan <i>resources</i> di dalam <i>groups</i></h2><p><i>DaemonSets</i>, <i>Deployments</i>, <i>HorizontalPodAutoscalers</i>,
<i>Ingresses</i>, <i>Jobs</i>, dan <i>ReplicaSets</i> diaktifkan secara <i>default</i>.
Ekstensi lain dapat diaktifkan penanda <code>--runtime-config</code> pada <i>apiserver</i>. Penanda <code>--runtime-config</code> menerima nilai yang dipisahkan oleh koma.
Sebagai contoh untuk menonaktifkan <i>deployments</i> dan <i>ingress</i>, tetapkan.
<code>--runtime-config=extensions/v1beta1/deployments=false,extensions/v1beta1/ingresses=false</code></p></div><div class=td-content style=page-break-before:always><h1 id=pg-110f33530cf761140cb1dab536baef04>1.4 - Menggunakan Objek-Objek Kubernetes</h1><div class=lead>Objek-objek Kubernetes adalah entitas yang tetap dalam sistem Kubernetes. Kubernetes menggunakan entitas tersebut untuk merepresentasikan keadaan dari klastermu. Pelajari tentang objek model Kubernetes dan bagaimana menggunakan objek tersebut.</div></div><div class=td-content><h1 id=pg-9f5adfa77f48c50d5cc81155a3cecb98>1.4.1 - Memahami Konsep Objek-Objek yang ada pada Kubernetes</h1><p>Laman ini menjelaskan bagaimana objek-objek Kubernetes direpresentasikan di dalam API Kubernetes,
dan bagaimana kamu dapat merepresentasikannya di dalam format <code>.yaml</code>.</p><h2 id=memahami-konsep-objek-objek-yang-ada-pada-kubernetes>Memahami Konsep Objek-Objek yang Ada pada Kubernetes</h2><p>Objek-objek Kubernetes adalah entitas persisten di dalam sistem Kubernetes.
Kubernetes menggunakan entitas ini untuk merepresentasikan <em>state</em> yang ada pada
klaster kamu. Secara spesifik, hal itu dapat dideskripsikan sebagai:</p><ul><li>Aplikasi-aplikasi kontainer apa sajakah yang sedang dijalankan (serta pada <em>node</em> apa aplikasi tersebut dijalankan)</li><li><em>Resource</em> yang tersedia untuk aplikasi tersebut</li><li><em>Policy</em> yang mengatur bagaimana aplikasi tersebut dijalankan, misalnya <em>restart</em>, <em>upgrade</em>, dan <em>fault-tolerance</em>.</li></ul><p>Objek Kubernetes merupakan sebuah <em>"record of intent"</em>--yang mana sekali kamu membuat suatu objek,
sistem Kubernetes akan bekerja secara konsisten untuk menjamin
bahwa objek tersebut akan selalu ada. Dengan membuat sebuah objek, secara tak langsung kamu
memberikan informasi pada sistem Kubernetes mengenai perilaku apakah yang kamu inginkan pada <em>workload</em> klaster yang kamu miliki;
dengan kata lain ini merupakan definisi <em>state</em> klaster yang kamu inginkan.</p><p>Untuk menggunakan objek-objek Kubernetes--baik membuat, mengubah, atau menghapus objek-objek tersebut--kamu
harus menggunakan <a href=/id/docs/concepts/overview/kubernetes-api/>API Kubernetes</a>.
Ketika kamu menggunakan perintah <code>kubectl</code>, perintah ini akan melakukan <em>API call</em> untuk perintah
yang kamu berikan. Kamu juga dapat menggunakan API Kubernetes secara langsung pada program yang kamu miliki
menggunakan salah satu <a href=/docs/reference/using-api/client-libraries/><em>library</em> klien</a> yang disediakan.</p><h3 id=spec-dan-status-objek><em>Spec</em> dan Status Objek</h3><p>Setiap objek Kubernetes memiliki <em>field</em> berantai yang mengatur konfigurasi sebuah objek:
<em>spec</em> dan status. <em>Spec</em>, merupakan <em>field</em> yang harus kamu sediakan, <em>field</em> ini mendeskripsikan
<em>state</em> yang kamu inginkan untuk objek tersebut--karakteristik dari objek yang kamu miliki.
Status mendeskripsikan <em>state</em> yang sebenarnya dari sebuah objek, dan hal ini disediakan dan selalu diubah oleh
sistem Kubernetes. Setiap saat, <em>Control Plane</em> Kubernetes selalu memantau apakah <em>state</em> aktual sudah sesuai dengan
<em>state</em> yang diinginkan.</p><p>Sebagai contoh, <em>Deployment</em> merupakan sebuah objek yang merepresentasikan sebuah aplikasi yang dijalankan di klaster kamu.
Ketika kamu membuat sebuah <em>Deployment</em>, kamu bisa saja memberikan <em>spec</em> bagi <em>Deployment</em> untuk memberikan spesifikasi
berapa banyak <em>replica</em> yang kamu inginkan. Sistem Kubernetes kemudian akan membaca konfigurasi yang kamu berikan
dan mengaktifkan tiga buah instans untuk aplikasi yang kamu inginkan--mengubah status yang ada saat ini agar sesuai dengan apa yang kamu inginkan.
Jika terjadi kegagalan dalam instans yang dibuat, sistem Kubernetes akan memberikan respons bahwa terdapat perbedaan antara <em>spec</em> dan status serta
melakukan penyesuaian dengan cara memberikan instans pengganti.</p><p>Informasi lebih lanjut mengenai <em>spec</em> objek, status, dan <em>metadata</em> dapat kamu baca di <a href=https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md>Konvensi API Kubernetes</a>.</p><h3 id=mendeskripsikan-objek-kubernetes>Mendeskripsikan Objek Kubernetes</h3><p>Ketika kamu membuat sebuah objek di Kubernetes, kamu harus menyediakan <em>spec</em> objek yang
mendeskripsikan <em>state</em> yang diinginkan, serta beberapa informasi tentang objek tersebut (seperti nama).
Ketika kamu menggunakan API Kubernetes untuk membuat objek tersebut (baik secara langsung atau menggunakan perintah
<code>kubectl</code>), <em>request</em> API yang dibuat harus mencakup informasi seperti <em>request body</em> dalam format JSON.
Apabila kamu memberikan <strong>informasi dalam bentuk <code>.yaml</code> ketika menggunakan perintah <code>kubectl</code></strong> maka <code>kubectl</code>
akan mengubah informasi yang kamu berikan ke dalam format JSON ketika melakukan <em>request</em> API.</p><p>Berikut merupakan contoh <em>file</em> <code>.yaml</code> yang menunjukkan <em>field</em> dan <em>spec</em> objek untuk <em>Deployment</em>:</p><div class=highlight><div class=copy-code-icon style=text-align:right><a href=https://raw.githubusercontent.com/kubernetes/website/main/content/id/examples/application/deployment.yaml download=application/deployment.yaml><code>application/deployment.yaml</code></a>
<img src=/images/copycode.svg style=max-height:24px;cursor:pointer onclick='copyCode("application-deployment-yaml")' title="Copy application/deployment.yaml to clipboard"></img></div><div class=includecode id=application-deployment-yaml><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>apps/v1<span style=color:#bbb> </span><span style=color:#080;font-style:italic># for versions before 1.9.0 use apps/v1beta2</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Deployment<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>nginx-deployment<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>selector</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>matchLabels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>app</span>:<span style=color:#bbb> </span>nginx<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>replicas</span>:<span style=color:#bbb> </span><span style=color:#666>2</span><span style=color:#bbb> </span><span style=color:#080;font-style:italic># tells deployment to run 2 pods matching the template</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>template</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>labels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>app</span>:<span style=color:#bbb> </span>nginx<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>nginx<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>nginx:1.7.9<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>ports</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>            </span>- <span style=color:green;font-weight:700>containerPort</span>:<span style=color:#bbb> </span><span style=color:#666>80</span><span style=color:#bbb>
</span></span></span></code></pre></div></div></div><p>Salah satu cara untuk membuat <em>Deployment</em> menggunakan <em>file</em> <code>.yaml</code>
seperti yang dijabarkan di atas adalah dengan menggunakan perintah
<a href=/docs/reference/generated/kubectl/kubectl-commands#apply><code>kubectl apply</code></a>
pada <em>command-line interface</em> <code>kubectl</code> kamu menerapkan <em>file</em> <code>.yaml</code> sebagai sebuah argumen.
Berikut merupakan contoh penggunaannya:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl apply -f https://k8s.io/examples/application/deployment.yaml --record
</span></span></code></pre></div><p>Keluaran yang digunakan kurang lebih akan ditampilkan sebagai berikut:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>deployment.apps/nginx-deployment created
</span></span></code></pre></div><h3 id=field-field-yang-dibutuhkan><em>Field-Field</em> yang dibutuhkan</h3><p>Pada <em>file</em> <code>.yaml</code> untuk objek Kubernetes yang ingin kamu buat, kamu perlu
menyediakan <em>value</em> untuk <em>field-field</em> berikut:</p><ul><li><em>apiVersion</em> - Version API Kubernetes mana yang kamu gunakan untuk membuat objek tersebut</li><li><em>kind</em> - Objek apakah yang ingin kamu buat</li><li><em>metadata</em> - Data yang dapat kamu gunakan untuk melakukan identifikasi objek termasuk <em>name</em> dalam betuk string, <em>UID</em>, dan <em>namespace</em> yang bersifat opsional</li></ul><p>Kamu juga harus menyediakan <em>field</em> <em>spec</em>. Format spesifik dari <em>spec</em> sebuah objek akan berbeda bergantung
pada objek apakah yang ingin kamu buat, serta mengandung <em>field</em> berantai yang spesifik bagi objek tersebut.
<a href=/docs/reference/generated/kubernetes-api/v1.25/>Referensi API Kubernetes</a> memberikan penjelasan
lebih lanjut mengenai format <em>spec</em> untuk semua objek Kubernetes yang dapat kamu buat. Misalnya saja format <em>spec</em>
untuk <em>Pod</em> dapat kamu temukan <a href=/docs/reference/generated/kubernetes-api/v1.25/#podspec-v1-core>di sini</a>,
dan format <em>spec</em> untuk <em>Deployment</em> dapat ditemukan
<a href=/docs/reference/generated/kubernetes-api/v1.25/#deploymentspec-v1-apps>di sini</a>.</p><h2 id=selanjutnya>Selanjutnya</h2><ul><li>Pelajari lebih lanjut mengenai dasar-dasar penting bagi objek Kubernetes, seperti <a href=/id/docs/concepts/workloads/pods/pod-overview/>Pod</a>.</li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-6751db8ff5409476de8225d17d6c42dd>1.4.2 - Pengaturan Objek Kubernetes</h1><p>Perangkat <code>kubectl</code> mendukung beberapa cara untuk membuat dan mengatur objek-objek Kubernetes.
Laman ini menggambarkan berbagai macam metodenya. Baca <a href=https://kubectl.docs.kubernetes.io>Kubectl gitbook</a>
untuk penjelasan pengaturan objek dengan Kubectl secara detail.</p><h2 id=metode-pengaturan>Metode pengaturan</h2><div class="alert alert-danger warning callout" role=alert><strong>Peringatan:</strong> Sebuah objek Kubernetes hanya boleh diatur dengan menggunakan satu metode saja. Mengkombinasikan
beberapa metode untuk objek yang sama dapat menghasilkan perilaku yang tidak diinginkan.</div><table><thead><tr><th>Metode pengaturan</th><th>Dijalankan pada</th><th><em>Environment</em> yang disarankan</th><th>Jumlah penulis yang didukung</th><th>Tingkat kesulitan mempelajari</th></tr></thead><tbody><tr><td>Perintah imperatif</td><td>Objek <em>live</em></td><td>Proyek pengembangan (<em>dev</em>)</td><td>1+</td><td>Terendah</td></tr><tr><td>Konfigurasi objek imperatif</td><td>Berkas individu</td><td>Proyek produksi (<em>prod</em>)</td><td>1</td><td>Sedang</td></tr><tr><td>Konfigurasi objek deklaratif</td><td>Direktori berkas</td><td>Proyek produksi (<em>prod</em>)</td><td>1+</td><td>Tertinggi</td></tr></tbody></table><h2 id=perintah-imperatif>Perintah imperatif</h2><p>Ketika menggunakan perintah-perintah imperatif, seorang pengguna menjalankan operasi secara langsung
pada objek-objek <em>live</em> dalam sebuah klaster. Pengguna menjalankan operasi tersebut melalui
argumen atau <em>flag</em> pada perintah <code>kubectl</code>.</p><p>Ini merupakan cara yang paling mudah untuk memulai atau menjalankan tugas "sekali jalan" pada sebuah klaster.
Karena metode ini dijalankan secara langsung pada objek <em>live</em>, tidak ada <em>history</em> yang menjelaskan konfigurasi-konfigurasi terkait sebelumnya.</p><h3 id=contoh>Contoh</h3><p>Menjalankan sebuah instans Container nginx dengan membuat suatu objek Deployment:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh><span style=display:flex><span>kubectl run nginx --image nginx
</span></span></code></pre></div><p>Melakukan hal yang sama menggunakan sintaks yang berbeda:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh><span style=display:flex><span>kubectl create deployment nginx --image nginx
</span></span></code></pre></div><h3 id=kelebihan-dan-kekurangan>Kelebihan dan kekurangan</h3><p>Beberapa kelebihan metode ini dibandingkan metode konfigurasi objek:</p><ul><li>Sederhana, mudah dipelajari dan diingat.</li><li>Hanya memerlukan satu langkah untuk membuat perubahan pada klaster.</li></ul><p>Beberapa kekurangan metode ini dibandingkan metode konfigurasi objek:</p><ul><li>Tidak terintegrasi dengan proses peninjauan (<em>review</em>) perubahan.</li><li>Tidak menyediakan jejak audit yang terkait dengan perubahan.</li><li>Tidak menyediakan sumber <em>record</em> kecuali dari apa yang <em>live</em> terlihat.</li><li>Tidak menyediakan templat untuk membuat objek-objek baru.</li></ul><h2 id=konfigurasi-objek-imperatif>Konfigurasi objek imperatif</h2><p>Pada konfigurasi objek imperatif, perintah kubectl menetapkan jenis operasi
(<em>create</em>, <em>replace</em>, etc.), <em>flag-flag</em> pilihan dan minimal satu nama berkas.
Berkas ini harus berisi definisi lengkap dari objek tersebut
dalam bentuk YAML atau JSON.</p><p>Lihat <a href=/docs/reference/generated/kubernetes-api/v1.25/>referensi API</a>
untuk info lebih detail mengenai definisi objek.</p><div class="alert alert-danger warning callout" role=alert><strong>Peringatan:</strong> Perintah imperatif <code>replace</code> menggantikan spek yang sudah ada dengan spek yang baru,
membuang semua perubahan terhadap objek tersebut yang tidak didefinisikan pada berkas konfigurasi.
Metode ini sebaiknya tidak dilakukan pada tipe sumber daya yang spek-nya diperbarui
secara independen di luar berkas konfigurasi. Service dengan tipe <code>LoadBalancer</code>, sebagai contoh,
memiliki <em>field</em> <code>externalIPs</code> yang diperbarui secara independen di luar konfigurasi, dilakukan
oleh klaster.</div><h3 id=contoh-1>Contoh</h3><p>Membuat objek yang didefinisikan pada sebuah berkas konfigurasi:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh><span style=display:flex><span>kubectl create -f nginx.yaml
</span></span></code></pre></div><p>Menghapus objek-objek yang didefinisikan pada dua berkas konfigurasi:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh><span style=display:flex><span>kubectl delete -f nginx.yaml -f redis.yaml
</span></span></code></pre></div><p>Memperbarui objek yang didefinisikan pada sebuah berkas konfigurasi dengan
menimpa konfigurasi <em>live</em>:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh><span style=display:flex><span>kubectl replace -f nginx.yaml
</span></span></code></pre></div><h3 id=kelebihan-dan-kekurangan-1>Kelebihan dan kekurangan</h3><p>Beberapa kelebihan dibandingkan metode perintah imperatif:</p><ul><li>Konfigurasi objek dapat disimpan pada suatu sistem kontrol kode seperti Git.</li><li>Konfigurasi objek dapat diintegrasikan dengan proses-proses, misalnya peninjauan (<em>review</em>) perubahan sebelum <em>push</em> dan jejak audit.</li><li>Konfigurasi objek dapat menyediakan templat untuk membuat objek-objek baru.</li></ul><p>Beberapa kekurangan dibandingkan metode perintah imperatif:</p><ul><li>Konfigurasi objek memerlukan pemahaman yang mendasar soal skema objek.</li><li>Konfigurasi objek memerlukan langkah tambahan untuk menulis berkas YAML.</li></ul><p>Beberapa kelebihan dibandingkan metode konfigurasi objek deklaratif:</p><ul><li>Konfigurasi objek imperatif memiliki perilaku yang lebih sederhana dan mudah dimengerti.</li><li>Sejak Kubernetes versi 1.5, konfigurasi objek imperatif sudah lebih stabil.</li></ul><p>Beberapa kekurangan dibandingkan metode konfigurasi objek deklaratif:</p><ul><li>Konfigurasi objek imperatif bekerja dengan baik untuk berkas-berkas, namun tidak untuk direktori.</li><li>Pembaruan untuk objek-objek <em>live</em> harus diterapkan pada berkas-berkas konfigurasi, jika tidak, hasil perubahan akan hilang pada penggantian berikutnya.</li></ul><h2 id=konfigurasi-objek-deklaratif>Konfigurasi objek deklaratif</h2><p>Ketika menggunakan konfigurasi objek deklaratif, seorang pengguna beroperasi pada berkas-berkas
konfigurasi objek yang disimpan secara lokal, namun pengguna tidak mendefinisikan operasi
yang akan dilakukan pada berkas-berkas tersebut. Operasi <em>create</em>, <em>update</em>, dan <em>delete</em>
akan dideteksi secara otomatis per-objek dengan <code>kubectl</code>. Hal ini memungkinkan penerapan
melalui direktori, dimana operasi yang berbeda mungkin diperlukan untuk objek-objek yang berbeda.</p><div class="alert alert-info note callout" role=alert><strong>Catatan:</strong> Konfigurasi objek deklaratif mempertahankan perubahan yang dibuat oleh penulis lainnya, bahkan
jika perubahan tidak digabungkan (<em>merge</em>) kembali pada berkas konfigurasi objek. Hal ini
bisa terjadi dengan menggunakan operasi API <code>patch</code> supaya hanya perbedaannya saja yang ditulis,
daripada menggunakan operasi API <code>replace</code> untuk menggantikan seluruh konfigurasi objek.</div><h3 id=contoh-2>Contoh</h3><p>Melakukan pemrosesan pada semua berkas konfigurasi objek di direktori <code>configs</code>, dan melakukan
<em>create</em> atau <em>patch</em> untuk objek-objek <em>live</em>. Kamu dapat terlebih dahulu melakukan <code>diff</code> untuk
melihat perubahan-perubahan apa saja yang akan dilakukan, dan kemudian terapkan:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh><span style=display:flex><span>kubectl diff -f configs/
</span></span><span style=display:flex><span>kubectl apply -f configs/
</span></span></code></pre></div><p>Melakukan pemrosesan direktori secara rekursif:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh><span style=display:flex><span>kubectl diff -R -f configs/
</span></span><span style=display:flex><span>kubectl apply -R -f configs/
</span></span></code></pre></div><h3 id=kelebihan-dan-kekurangan-2>Kelebihan dan kekurangan</h3><p>Beberapa kelebihan dibandingkan konfigurasi objek imperatif:</p><ul><li>Perubahan-perubahan yang dilakukan secara langsung pada objek-objek <em>live</em> akan dipertahankan, bahkan jika perubahan tersebut tidak digabungkan kembali pada berkas-berkas konfigurasi.</li><li>Konfigurasi objek deklaratif memiliki dukungan yang lebih baik dalam mengoperasikan direktori dan secara otomatis mendeteksi tipe operasi (<em>create</em>, <em>patch</em>, <em>delete</em>) per-objek.</li></ul><p>Beberapa kekurangan dibandingkan konfigurasi objek imperatif:</p><ul><li>Konfigurasi objek deklaratif lebih sulit untuk di-<em>debug</em> dan hasilnya lebih sulit dimengerti untuk perilaku yang tidak diinginkan.</li><li>Pembaruan sebagian menggunakan <em>diff</em> menghasilkan operasi <em>merge</em> dan <em>patch</em> yang rumit.</li></ul><h2 id=selanjutnya>Selanjutnya</h2><ul><li><a href=/docs/tasks/manage-kubernetes-objects/imperative-command/>Mengatur Objek Kubernetes menggunakan Perintah Imperatif</a></li><li><a href=/docs/tasks/manage-kubernetes-objects/imperative-config/>Mengatur Objek Kubernetes menggunakan Konfigurasi Objek (Imperatif)</a></li><li><a href=/docs/tasks/manage-kubernetes-objects/declarative-config/>Mengatur Objek Kubernetes menggunakan Konfigurasi Objek (Deklaratif)</a></li><li><a href=/docs/tasks/manage-kubernetes-objects/kustomization/>Mengatur Objek Kubernetes menggunakan Kustomize (Deklaratif)</a></li><li><a href=/docs/reference/generated/kubectl/kubectl-commands/>Referensi Perintah Kubectl</a></li><li><a href=https://kubectl.docs.kubernetes.io>Kubectl Gitbook</a></li><li><a href=/docs/reference/generated/kubernetes-api/v1.25/>Referensi API Kubernetes</a></li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-f37749a83c2916b63279ea60f3cfe53e>1.4.3 - Nama</h1><p>Seluruh objek di dalam REST API Kubernetes secara jelas ditandai dengan nama dan UID.</p><p>Apabila pengguna ingin memberikan atribut tidak unik, Kubernetes menyediakan <a href=/docs/user-guide/labels>label</a> dan <a href=/id/docs/concepts/overview/working-with-objects/annotations/>anotasi</a>.</p><p>Bacalah <a href=https://git.k8s.io/community/contributors/design-proposals/architecture/identifiers.md>dokumentasi desain penanda</a> agar kamu dapat memahami lebih lanjut sintaks yang digunakan untuk Nama dan UID.</p><h2 id=nama>Nama</h2><p>String yang dihasilkan oleh klien yang mengacu pada sebuah objek dalam suatu URL <em>resource</em>, seperti <code>/api/v1/pods/some-name</code>.</p><p>Sebuah objek dengan kind yang sama tidak boleh memiliki nama yang sama pada suatu waktu tertentu. Meskipun begitu, apabila kamu menghapus sebuah objek, kamu membuat sebuah objek baru (yang memiliki kind yang sama) dengan nama yang sama dengan objek yang kamu hapus sebelumnya.</p><p>Berdasarkan ketentuan, nama dari <em>resources</em> Kubernetes memiliki panjang maksimum 253 karakter yang terdiri dari karakter alfanumerik huruf kecil, <code>-</code>, dan <code>.</code>, tetapi <em>resources</em> tertentu punya lebih banyak batasan yang spesifik</p><h2 id=uid>UID</h2><p>String yang dihasilkan oleh sistem Kubernetes untuk mengidentifikasi objek secara unik.</p><p>Setiap objek yang ada pada klaster Kubernetes memiliki UID yang unik. Hal ini dilakukan untuk membedakan keberadaan historis suatu entitas dengan kind dan nama yang serupa.</p></div><div class=td-content style=page-break-before:always><h1 id=pg-1127165f472b7181b9c1d5a0b187d620>1.4.4 - Namespace</h1><p>Kubernetes mendukung banyak klaster virtual di dalam satu klaster fisik. Klaster virtual tersebut disebut dengan <em>namespace</em>.</p><h2 id=kapan-menggunakan-banyak-namespace>Kapan menggunakan banyak Namespace</h2><p><em>Namespace</em> dibuat untuk digunakan di <em>environment</em> dengan banyak pengguna yang berada di dalam banyak tim ataupun proyek. Untuk sebuah klaster dengan beberapa pengguna saja, kamu tidak harus membuat ataupun memikirkan tentang <em>namespace</em>. Mulai gunakan <em>namespace</em> saat kamu membutuhkan fitur dari <em>namespace</em> itu sendiri.</p><p><em>Namespace</em> menyediakan ruang untuk nama objek. Nama dari <em>resource</em> atau objek harus berbeda di dalam sebuah <em>namespace</em>, tetapi boleh sama jika berbeda <em>namespace</em>. <em>Namespace</em> tidak bisa dibuat di dalam <em>namespace</em> lain dan setiap <em>resource</em> atau objek Kubernetes hanya dapat berada di dalam satu <em>namespace</em>.</p><p><em>Namespace</em> merupakan cara yang digunakan untuk memisahkan <em>resource</em> klaster untuk beberapa pengguna (dengan <a href=/id/docs/concepts/policy/resource-quotas/><em>resource quota</em></a>).</p><p>Dalam versi Kubernetes yang akan datang, objek di dalam satu <em>namespace</em> akan mempunyai <em>access control policies</em> yang sama secara <em>default</em>.</p><p>Tidak perlu menggunakan banyak <em>namespace</em> hanya untuk memisahkan sedikit perbedaan pada <em>resource</em>, seperti perbedaan versi dari perangkat lunak yang sama: gunakan <a href=/docs/user-guide/labels>label</a> untuk membedakan <em>resource</em> di dalam <em>namespace</em> yang sama.</p><h2 id=bekerja-dengan-namespace>Bekerja dengan Namespace</h2><p>Pembuatan dan penghapusan <em>namespace</em> dijelaskan di <a href=/docs/admin/namespaces>dokumentasi panduan admin untuk <em>namespace</em></a>.</p><h3 id=melihat-namespace>Melihat namespace</h3><p>Kamu dapat melihat daftar <em>namespace</em> di dalam klaster menggunakan:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get namespace
</span></span></code></pre></div><pre tabindex=0><code>NAME          STATUS    AGE
default       Active    1d
kube-system   Active    1d
kube-public   Active    1d
</code></pre><p>Kubernetes berjalan dengan tiga <em>namespace</em> awal:</p><ul><li><code>default</code>, <em>namespace default</em> untuk objek yang dibuat tanpa mencantumkan <em>namespace</em> pada spesifikasinya.</li><li><code>kube-system</code>, <em>namespace</em> yang digunakan untuk objek yang dibuat oleh sistem Kubernetes.</li><li><code>kube-public</code>, <em>namespace</em> ini dibuat secara otomatis dan dapat diakses oleh semua pengguna (termasuk yang tidak diautentikasi). <em>Namespace</em> ini disediakan untuk penggunaan klaster, jika beberapa <em>resouce</em> harus terlihat dan dapat dibaca secara publik di seluruh klaster. Aspek publik dari <em>namespace</em> ini hanya sebuah konvensi, bukan persyaratan.</li></ul><h3 id=mengkonfigurasi-namespace-untuk-request>Mengkonfigurasi namespace untuk request</h3><p>Untuk mengkonfigurasi sementara <em>request</em> untuk menggunakan <em>namespace</em> tertentu, gunakan <code>--namespace</code> <em>flag</em>.</p><p>Sebagai contoh:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl --namespace<span style=color:#666>=</span>&lt;insert-namespace-name-here&gt; run nginx --image<span style=color:#666>=</span>nginx
</span></span><span style=display:flex><span>kubectl --namespace<span style=color:#666>=</span>&lt;insert-namespace-name-here&gt; get pods
</span></span></code></pre></div><h3 id=mengkonfigurasi-preferensi-namespace>Mengkonfigurasi preferensi namespace</h3><p>Kamu dapat menyimpan konfigurasi <em>namespace</em> untuk semua perintah <code>kubectl</code> dengan perintah:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl config set-context --current --namespace<span style=color:#666>=</span>&lt;insert-namespace-name-here&gt;
</span></span><span style=display:flex><span><span style=color:#080;font-style:italic># Cek namespace</span>
</span></span><span style=display:flex><span>kubectl config view | grep namespace:
</span></span></code></pre></div><h2 id=namespace-dan-dns>Namespace dan DNS</h2><p>Saat kamu membuat sebuah <a href=/docs/user-guide/services>Service</a>, Kubernetes membuat <a href=/id/docs/concepts/services-networking/dns-pod-service/>Entri DNS</a> untuk <em>service</em> tersebut. Entri <em>DNS</em> ini berformat <code>&lt;service-name>.&lt;namespace-name>.svc.cluster.local</code>, yang berarti jika sebuah kontainer hanya menggunakan <code>&lt;service-name></code>, kontainer tersebut akan berkomunikasi dengan <em>service</em> yang berada di dalam satu <em>namespace</em>. Ini berguna untuk menggunakan konfigurasi yang sama di beberapa <em>namespace</em> seperti <em>Development</em>, <em>Staging</em>, dan <em>Production</em>. Jika kamu ingin berkomunikasi antar <em>namespace</em>, kamu harus menggunakan seluruh <em>fully qualified domain name (FQDN)</em>.</p><h2 id=tidak-semua-objek-di-dalam-namespace>Tidak semua objek di dalam Namespace</h2><p>Kebanyakan <em>resource</em> di Kubernetes (contohnya <em>pod</em>, <em>service</em>, <em>replication controller</em>, dan yang lain) ada di dalam <em>namespace</em>. Namun <em>resource namespace</em> sendiri tidak berada di dalam <em>namespace</em>. Dan <em>low-level resource</em> seperti <a href=/docs/admin/node>node</a> dan <em>persistentVolume</em> tidak berada di <em>namespace</em> manapun.</p><p>Untuk melihat <em>resource</em> di dalam kubernetes yang berada di dalam <em>namespace</em> ataupun tidak:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span><span style=color:#080;font-style:italic># Di dalam namespace</span>
</span></span><span style=display:flex><span>kubectl api-resources --namespaced<span style=color:#666>=</span><span style=color:#a2f>true</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#080;font-style:italic># Tidak di dalam namespace</span>
</span></span><span style=display:flex><span>kubectl api-resources --namespaced<span style=color:#666>=</span><span style=color:#a2f>false</span>
</span></span></code></pre></div></div><div class=td-content style=page-break-before:always><h1 id=pg-f1dec4557fb8ffbac9f11390aaaf9fa4>1.4.5 - Label dan Selektor</h1><p><em>Label</em> merupakan pasangan <em>key/value</em> yang melekat pada objek-objek, misalnya pada Pod.
Label digunakan untuk menentukan atribut identitas dari objek agar memiliki arti dan relevan bagi para pengguna, namun tidak secara langsung memiliki makna terhadap sistem inti.
Label dapat digunakan untuk mengatur dan memilih sebagian dari banyak objek. Label-label dapat ditempelkan ke objek-objek pada saat dibuatnya objek-objek tersebut dan kemudian ditambahkan atau diubah kapan saja setelahnya.
Setiap objek dapat memiliki satu set label <em>key/value</em>. Setiap <em>Key</em> harus unik untuk objek tersebut.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-json data-lang=json><span style=display:flex><span><span style=color:#b44>&#34;metadata&#34;</span><span>:</span> {
</span></span><span style=display:flex><span>  <span style=color:green;font-weight:700>&#34;labels&#34;</span>: {
</span></span><span style=display:flex><span>    <span style=color:green;font-weight:700>&#34;key1&#34;</span> : <span style=color:#b44>&#34;value1&#34;</span>,
</span></span><span style=display:flex><span>    <span style=color:green;font-weight:700>&#34;key2&#34;</span> : <span style=color:#b44>&#34;value2&#34;</span>
</span></span><span style=display:flex><span>  }
</span></span><span style=display:flex><span>}
</span></span></code></pre></div><p>Label memungkinkan untuk menjalankan kueri dan pengamatan dengan efisien, serta ideal untuk digunakan pada UI dan CLI. Informasi yang tidak digunakan untuk identifikasi sebaiknya menggunakan <a href=/id/docs/concepts/overview/working-with-objects/annotations/>anotasi</a>.</p><h2 id=motivasi>Motivasi</h2><p>Label memungkinkan pengguna untuk memetakan struktur organisasi mereka ke dalam objek-objek sistem yang tidak terikat secara erat, tanpa harus mewajibkan klien untuk menyimpan pemetaan tersebut.</p><p><em>Service deployments</em> dan <em>batch processing pipelines</em> sering menjadi entitas yang berdimensi ganda (contohnya partisi berganda atau <em>deployment</em>, jalur rilis berganda, tingkatan berganda, <em>micro-services</em> berganda per tingkatan). Manajemen seringkali membutuhkan operasi lintas tim, yang menyebabkan putusnya enkapsulasi dari representasi hierarki yang ketat, khususnya pada hierarki-hierarki kaku yang justru ditentukan oleh infrastruktur, bukan oleh pengguna.</p><p>Contoh label:</p><ul><li><code>"release" : "stable"</code>, <code>"release" : "canary"</code></li><li><code>"environment" : "dev"</code>, <code>"environment" : "qa"</code>, <code>"environment" : "production"</code></li><li><code>"tier" : "frontend"</code>, <code>"tier" : "backend"</code>, <code>"tier" : "cache"</code></li><li><code>"partition" : "customerA"</code>, <code>"partition" : "customerB"</code></li><li><code>"track" : "daily"</code>, <code>"track" : "weekly"</code></li></ul><p>Ini hanya contoh label yang biasa digunakan; kamu bebas mengembangkan caramu sendiri. Perlu diingat bahwa <em>Key</em> dari label harus unik untuk objek tersebut.</p><h2 id=sintaksis-dan-set-karakter>Sintaksis dan set karakter</h2><p><em>Label</em> merupakan pasangan <em>key/value</em>. <em>Key-key</em> dari Label yang valid memiliki dua segmen: sebuah prefiks dan nama yang opsional, yang dipisahkan oleh garis miring (<code>/</code>). Segmen nama wajib diisi dan tidak boleh lebih dari 63, dimulai dan diakhiri dengan karakter alfanumerik (<code>[a-z0-9A-Z]</code>) dengan tanda pisah (<code>-</code>), garis bawah (<code>_</code>), titik (<code>.</code>), dan alfanumerik di antaranya. Sedangkan prefiks bersifat opsional. Jika ditentukan, prefiks harus berupa subdomain DNS: rangkaian label DNS yang dipisahkan oleh titik (<code>.</code>), dengan total tidak lebih dari 253 karakter, yang diikuti oleh garis miring (<code>/</code>).</p><p>Jika prefiks dihilangkan, <em>Key</em> dari label diasumsikan privat bagi pengguna. Komponen sistem otomatis (contoh <code>kube-scheduler</code>, <code>kube-controller-manager</code>, <code>kube-apiserver</code>, <code>kubectl</code>, atau otomasi pihak ketiga lainnya) yang akan menambah label ke objek-objek milik pengguna akhir harus menentukan prefiks.</p><p>Prefiks <code>kubernetes.io/</code> dan <code>k8s.io/</code> dikhususkan untuk komponen inti Kubernetes.</p><p>Nilai label yang valid tidak boleh lebih dari 63 karakter dan harus kosong atau diawali dan diakhiri dengan karakter alfanumerik (<code>[a-z0-9A-Z]</code>) dengan tanda pisah (<code>-</code>), garis bawah (<code>_</code>), titik (<code>.</code>), dan alfanumerik di antaranya.</p><p>Contoh di bawah ini merupakan berkas konfigurasi untuk Pod yang memiliki dua label <code>environment: production</code> dan <code>app: nginx</code> :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>label-demo<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>labels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>environment</span>:<span style=color:#bbb> </span>production<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>app</span>:<span style=color:#bbb> </span>nginx<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>nginx<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>nginx:1.7.9<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>ports</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:green;font-weight:700>containerPort</span>:<span style=color:#bbb> </span><span style=color:#666>80</span><span style=color:#bbb>
</span></span></span></code></pre></div><h2 id=selektor-label>Selektor label</h2><p>Tidak seperti <a href=/id/docs/concepts/overview/working-with-objects/names/>nama dan UID</a>, label tidak memberikan keunikan. Secara umum, kami memperkirakan bahwa banyak objek yang akan memiliki label yang sama.</p><p>Menggunakan sebuah <em>label selector</em>, klien/pengguna dapat mengidentifikasi suatu kumpulan objek. Selektor label merupakan alat/cara pengelompokan utama pada Kubernetes.</p><p>Saat ini API mendukung dua jenis selektor: <em>equality-based</em> dan <em>set-based</em>.
Sebuah selektor label dapat dibuat dari kondisi berganda yang dipisahkan oleh koma. Pada kasus kondisi berganda, semua kondisi harus dipenuhi sehingga separator koma dapat bertindak sebagai operator logika <em>AND</em> (<code>&&</code>).</p><p>Makna dari selektor yang kosong atau tidak diisi tergantung dari konteks, dan tipe API yang menggunakan selektor harus mendokumentasikan keabsahan dan arti dari selektor yang kosong tersebut.</p><div class="alert alert-info note callout" role=alert><strong>Catatan:</strong> Untuk beberapa tipe API, seperti ReplicaSet, selektor label untuk dua objek tidak boleh tumpang tindih dengan Namespace, jika tidak maka <em>controller</em> akan melihatnya sebagai instruksi yang menyebabkan konflik dan akan gagal menentukan berapa banyak replika yang seharusnya tersedia.</div><div class="alert alert-warning caution callout" role=alert><strong>Perhatian:</strong> Untuk kedua kondisi <em>equality-based</em> dan <em>set-based</em> tidak ada logika operator <em>OR</em> (<code>||</code>). Pastikan struktur pernyataan filter kamu ikut disesuaikan.</div><h3 id=kondisi-equality-based>Kondisi <em>Equality-based</em></h3><p>Kondisi <em>Equality-based</em> atau <em>inequality-based</em> memungkinkan untuk melakukan filter dengan menggunakan <em>key</em> dan <em>value</em> dari label. Objek yang cocok harus memenuhi semua batasan label yang telah ditentukan, meskipun mereka dapat memiliki label tambahan lainnya.
Terdapat tiga jenis operator yang didukung yaitu <code>=</code>,<code>==</code>,<code>!=</code>. Dua operator pertama menyatakan kesamaan (keduanya hanyalah sinonim), sementara operator terakhir menyatakan ketidaksamaan. Contoh:</p><pre tabindex=0><code>environment = production
tier != frontend
</code></pre><p>Kondisi pertama akan memilih semua sumber daya dengan <em>key</em> <code>environment</code> dan nilai <em>key</em> <code>production</code>.
Kondisi berikutnya akan memilih semua sumber daya dengan <em>key</em> <code>tier</code> dan nilai <em>key</em> selain <code>frontend</code>, dan semua sumber daya yang tidak memiliki label dengan <em>key</em> <code>tier</code>.
Kamu juga dapat memfilter sumber daya dalam <code>production</code> selain <code>frontend</code> dengan menggunakan operator koma: <code>environment=production,tier!=frontend</code></p><p>Salah satu skenario penggunaan label dengan kondisi <em>equality-based</em> yaitu untuk kriteria pemilihan Node untuk Pod-Pod. Sebagai contoh, Pod percontohan di bawah ini akan memilih Node dengan label "<code>accelerator=nvidia-tesla-p100</code>".</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>cuda-test<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>cuda-test<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;k8s.gcr.io/cuda-vector-add:v0.1&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>resources</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>limits</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>nvidia.com/gpu</span>:<span style=color:#bbb> </span><span style=color:#666>1</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>nodeSelector</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>accelerator</span>:<span style=color:#bbb> </span>nvidia-tesla-p100<span style=color:#bbb>
</span></span></span></code></pre></div><h3 id=kondisi-set-based>Kondisi <em>Set-based</em></h3><p>Kondisi label <em>Set-based</em> memungkinkan memfilter <em>key</em> terhadap suatu kumpulan nilai. Terdapat tiga jenis operator yang didukung, yaitu: <code>in</code>,<code>notin</code>, dan <code>exists</code> (hanya <em>key</em>-nya saja). Contoh:</p><pre tabindex=0><code>environment in (production, qa)
tier notin (frontend, backend)
partition
!partition
</code></pre><p>Contoh pertama akan memilih semua sumber daya dengan <em>key</em> <code>environment</code> dan nilai <code>production</code> atau <code>qa</code>.
Contoh kedua akan memilih semua sumber daya dengan <em>key</em> <code>tier</code> dan nilai selain <code>frontend</code> dan <code>backend</code>, serta semua sumber daya yang tidak memiliki label dengan <em>key</em> <code>tier</code>.
Contoh ketiga akan memilih semua sumber daya yang memiliki <em>key</em> dari label<code>partition</code>; nilainya tidak diperiksa.
Sedangkan contoh keempat akan memilih semua sumber daya yang tidak memiliki label dengan <em>key</em> <code>partition</code>; nilainya tidak diperiksa.
Secara serupa, operator koma bertindak sebagai operator <em>AND</em>. Sehingga penyaringan sumber daya dengan <em>key</em> <code>partition</code> (tidak peduli nilai dari <em>key</em>) dan <code>environment</code> yang tidak sama dengan <code>qa</code> dapat dicapai dengan <code>partition,environment notin (qa)</code>.
Selektor label <em>set-based</em> merupakan bentuk umum persamaan karena <code>environment=production</code> sama dengan <code>environment in (production)</code>; demikian pula <code>!=</code> dan <code>notin</code>.</p><p>Kondisi <em>Set-based</em> dapat digabungkan dengan kondisi <em>equality-based</em>. Contoh: <code>partition in (customerA, customerB),environment!=qa</code>.</p><h2 id=api>API</h2><h3 id=penyaringan-list-dan-watch>Penyaringan LIST dan WATCH</h3><p>Operasi LIST dan WATCH dapat menentukan selektor label untuk memfilter suatu kumpulan objek yang didapat dengan menggunakan parameter kueri. Kedua jenis kondisi diperbolehkan (ditampilkan sebagai berikut, sama seperti saat tampil pada string kueri di URL):</p><ul><li>Kondisi <em>equality-based</em>: <code>?labelSelector=environment%3Dproduction,tier%3Dfrontend</code></li><li>Kondisi <em>set-based</em>: <code>?labelSelector=environment+in+%28production%2Cqa%29%2Ctier+in+%28frontend%29</code></li></ul><p>Kedua jenis selektor label dapat digunakan untuk menampilkan (<em>list</em>) dan mengamati (<em>watch</em>) sumber daya melalui klien REST. Contohnya, menargetkan <code>apiserver</code> dengan <code>kubectl</code> dan menggunakan <em>equality-based</em> kamu dapat menuliskan:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get pods -l <span style=color:#b8860b>environment</span><span style=color:#666>=</span>production,tier<span style=color:#666>=</span>frontend
</span></span></code></pre></div><p>atau menggunakan kondisi <em>set-based</em>:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get pods -l <span style=color:#b44>&#39;environment in (production),tier in (frontend)&#39;</span>
</span></span></code></pre></div><p>Seperti yang telah disebutkan sebelumnya, kondisi <em>set-based</em> lebih ekspresif. Sebagai contoh, mereka dapat digunakan untuk mengimplementasi operator <em>OR</em> pada nilai:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get pods -l <span style=color:#b44>&#39;environment in (production, qa)&#39;</span>
</span></span></code></pre></div><p>atau membatasi pencocokan negatif dengan operator <em>exists</em>:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get pods -l <span style=color:#b44>&#39;environment,environment notin (frontend)&#39;</span>
</span></span></code></pre></div><h3 id=mengatur-referensi-pada-objek-api>Mengatur referensi pada objek API</h3><p>Pada beberapa objek Kubernetes, seperti <a href=/docs/user-guide/services><code>Service</code></a> dan <a href=/id/docs/concepts/workloads/controllers/replicationcontroller/><code>ReplicationController</code></a>, juga menggunakan selektor label untuk menentukan kumpulan dari sumber daya lain, seperti <a href=/id/docs/concepts/workloads/pods/pod>Pod</a>.</p><h4 id=service-dan-replicationcontroller>Service dan ReplicationController</h4><p>Kumpulan Pod yang ditargetkan oleh sebuah <code>service</code> ditentukan dengan selektor label. Demikian pula kumpulan Pod yang harus ditangani oleh <code>replicationcontroller</code> juga ditentukan dengan selektor label.</p><p>Selektor label untuk kedua objek tersebut ditentukan dalam berkas <code>json</code> atau <code>yaml</code> menggunakan <em>maps</em>, dan hanya mendukung kondisi <em>equality-based</em>:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-json data-lang=json><span style=display:flex><span><span style=color:#b44>&#34;selector&#34;</span><span>:</span> {
</span></span><span style=display:flex><span>    <span style=color:green;font-weight:700>&#34;component&#34;</span> : <span style=color:#b44>&#34;redis&#34;</span>,
</span></span><span style=display:flex><span>}
</span></span></code></pre></div><p>atau</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>selector</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>component</span>:<span style=color:#bbb> </span>redis<span style=color:#bbb>
</span></span></span></code></pre></div><p>selektor ini (baik dalam bentuk <code>json</code> atau <code>yaml</code>) sama dengan <code>component=redis</code> atau <code>component in (redis)</code>.</p><h4 id=sumber-daya-yang-mendukung-kondisi-set-based>Sumber daya yang mendukung kondisi set-based</h4><p>Sumber daya yang lebih baru, seperti <a href=/id/docs/concepts/workloads/controllers/jobs-run-to-completion/><code>Job</code></a>, <a href=/id/docs/concepts/workloads/controllers/deployment/><code>Deployment</code></a>, <a href=/id/docs/concepts/workloads/controllers/replicaset/><code>ReplicaSet</code></a>, dan <a href=/id/docs/concepts/workloads/controllers/daemonset/><code>DaemonSet</code></a>, juga mendukung kondisi <em>set-based</em>.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>selector</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>matchLabels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>component</span>:<span style=color:#bbb> </span>redis<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>matchExpressions</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- {<span style=color:green;font-weight:700>key: tier, operator: In, values</span>:<span style=color:#bbb> </span>[cache]}<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- {<span style=color:green;font-weight:700>key: environment, operator: NotIn, values</span>:<span style=color:#bbb> </span>[dev]}<span style=color:#bbb>
</span></span></span></code></pre></div><p><code>matchLabels</code> merupakan pemetaan dari pasangan <code>{key,value}</code>. Sebuah <code>{key,value}</code> pada pemetaan <code>matchLabels</code> adalah sama dengan elemen dari <code>matchExpressions</code>, yang nilai <code>key</code> nya adalah "key", dengan <code>operator</code> "In", dan <em>array</em> <code>values</code> hanya berisi "value". <code>matchExpressions</code> merupakan daftar kondisi untuk selektor Pod. Operator yang valid termasuk In, NotIn, Exists, dan DoesNotExist. Kumpulan nilai ini tidak boleh kosong pada kasus In dan NotIn. Semua kondisi, baik dari <code>matchLabels</code> dan <code>matchExpressions</code> di-AND secara sekaligus -- mereka harus memenuhi semua kondisi agar cocok.</p><h4 id=memilih-kumpulan-node>Memilih kumpulan Node</h4><p>Salah satu contoh penggunaan pemilihan dengan menggunakan label yaitu untuk membatasi suatu kumpulan Node tertentu yang dapat digunakan oleh Pod.
Lihat dokumentasi pada <a href=/id/docs/concepts/scheduling-eviction/assign-pod-node/>pemilihan Node</a> untuk informasi lebih lanjut.</p></div><div class=td-content style=page-break-before:always><h1 id=pg-93cd7a1d4e1623e2bf01afc49a5af69c>1.4.6 - Anotasi</h1><p>Kamu dapat menggunakan fitur anotasi dari Kubernetes untuk menempelkan sembarang
metadata tanpa identitas pada suatu objek. Klien, seperti perangkat dan <em>library</em>,
dapat memperoleh metadata tersebut.</p><h2 id=mengaitkan-metadata-pada-objek>Mengaitkan metadata pada objek</h2><p>Kamu dapat menggunakan label maupun anotasi untuk menempelkan metadata pada suatu
objek Kubernetes. Label dapat digunakan untuk memilih objek dan mencari sekumpulan
objek yang memenuhi kondisi tertentu. Sebaliknya, anotasi tidak digunakan untuk
mengenali atau memilih objek. Metadata dalam sebuah anotasi bisa berukuran kecil atau besar,
terstruktur atau tidak terstruktur, dan dapat berisikan karakter-karakter yang tidak
diperbolehkan oleh label.</p><p>Anotasi, seperti label, merupakan pemetaan <em>key/value</em>:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-json data-lang=json><span style=display:flex><span><span style=color:#b44>&#34;metadata&#34;</span><span>:</span> {
</span></span><span style=display:flex><span>  <span style=color:green;font-weight:700>&#34;annotations&#34;</span>: {
</span></span><span style=display:flex><span>    <span style=color:green;font-weight:700>&#34;key1&#34;</span> : <span style=color:#b44>&#34;value1&#34;</span>,
</span></span><span style=display:flex><span>    <span style=color:green;font-weight:700>&#34;key2&#34;</span> : <span style=color:#b44>&#34;value2&#34;</span>
</span></span><span style=display:flex><span>  }
</span></span><span style=display:flex><span>}
</span></span></code></pre></div><p>Berikut merupakan beberapa contoh informasi yang dapat dicatat dengan menggunakan anotasi:</p><ul><li><p><em>Field-field</em> yang dikelola secara deklaratif oleh <em>layer</em> konfigurasi. Menempelkan
<em>field-field</em> tersebut sebagai anotasi membedakan mereka dari nilai <em>default</em> yang
ditetapkan oleh klien ataupun server, dari <em>field-field</em> yang otomatis di-<em>generate</em>, serta
dari <em>field-field</em> yang ditetapkan oleh sistem <em>auto-sizing</em> atau <em>auto-scaling</em>.</p></li><li><p>Informasi mengenai <em>build</em>, rilis, atau <em>image</em>, seperti <em>timestamp</em>, rilis ID, git <em>branch</em>,
nomor PR, <em>hash</em> suatu <em>image</em>, dan alamat registri.</p></li><li><p>Penanda untuk <em>logging</em>, <em>monitoring</em>, <em>analytics</em>, ataupun repositori audit.</p></li><li><p>Informasi mengenai <em>library</em> klien atau perangkat yang dapat digunakan untuk <em>debugging</em>:
misalnya, informasi nama, versi, dan <em>build</em>.</p></li><li><p>Informasi yang berhubungan dengan pengguna atau perangkat/sistem, seperti URL objek yang terkait
dengan komponen dari ekosistem lain.</p></li><li><p>Metadata untuk perangkat <em>rollout</em> yang ringan (<em>lightweight</em>): contohnya, untuk
konfigurasi atau penanda (<em>checkpoint</em>).</p></li><li><p>Nomor telepon atau <em>pager</em> dari orang yang bertanggung jawab, atau entri direktori
yang berisi informasi lebih lanjut, seperti <em>website</em> sebuah tim.</p></li><li><p>Arahan dari pengguna (<em>end-user</em>) untuk melakukan implementasi, perubahan perilaku,
ataupun untuk interaksi dengan fitur-fitur non-standar.</p></li></ul><p>Tanpa menggunakan anotasi, kamu dapat saja menyimpan informasi-informasi dengan tipe
di atas pada suatu basis data atau direktori eksternal, namun hal ini sangat mempersulit
pembuatan <em>library</em> klien dan perangkat yang bisa digunakan sama-sama (<em>shared</em>) untuk melakukan
<em>deploy</em>, pengelolaan, introspeksi, dan semacamnya.</p><h2 id=sintaksis-dan-sekumpulan-karakter>Sintaksis dan sekumpulan karakter</h2><p>Anotasi merupakan <em>key/value pair</em>. <em>Key</em> dari sebuah anotasi yang valid memiliki dua segmen: segmen prefiks yang opsional dan segmen nama, dipisahkan
oleh sebuah garis miring (<code>/</code>). Segmen nama bersifat wajib dan harus terdiri dari 63 karakter atau kurang, dimulai dan diakhiri dengan karakter alfanumerik (<code>[a-z0-9A-Z]</code>) dengan tanda minus (<code>-</code>), garis bawah (<code>_</code>), titik (<code>.</code>), dan alfanumerik di tengahnya. Jika terdapat prefiks,
prefiks haruslah berupa subdomain DNS: urutan dari label DNS yang dipisahkan oleh titik (<code>.</code>), totalnya tidak melebihi 253 karakter,
diikuti dengan garis miring (<code>/</code>).</p><p>Jika tidak terdapat prefiks, maka <em>key</em> dari anotasi diasumsikan hanya bisa dilihat oleh pengguna (privat). Komponen sistem otomasi
(seperti <code>kube-scheduler</code>, <code>kube-controller-manager</code>, <code>kube-apiserver</code>, <code>kubectl</code>, ataupun otomasi pihak ketiga) yang menambahkan anotasi
pada objek-objek pengguna harus memiliki sebuah prefiks.</p><p>Prefiks <code>kubernetes.io/</code> dan <code>k8s.io/</code> merupakan reservasi dari komponen inti Kubernetes.</p><h2 id=selanjutnya>Selanjutnya</h2><p>Pelajari lebih lanjut tentang <a href=/id/docs/concepts/overview/working-with-objects/labels/>Label dan Selektor</a>.</p></div><div class=td-content style=page-break-before:always><h1 id=pg-046c03090d47bc4b89b818dc645c3865>1.4.7 - Selektor Field</h1><p>Selektor <em>field</em> memungkinkan kamu untuk <a href=/id/docs/concepts/overview/working-with-objects/kubernetes-objects>memilih (<em>select</em>) <em>resource</em> Kubernetes</a> berdasarkan
nilai dari satu atau banyak <em>field resource</em>. Di bawah ini merupakan contoh dari beberapa <em>query</em> selektor <em>field</em>:</p><ul><li><code>metadata.name=my-service</code></li><li><code>metadata.namespace!=default</code></li><li><code>status.phase=Pending</code></li></ul><p>Perintah <code>kubectl</code> di bawah ini memilih semua Pod dengan <em>field</em> <a href=/id/docs/concepts/workloads/pods/pod-lifecycle/#pod-phase><code>status.phase</code></a> yang bernilai
<code>Running</code>:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get pods --field-selector status.phase<span style=color:#666>=</span>Running
</span></span></code></pre></div><div class="alert alert-info note callout" role=alert><strong>Catatan:</strong><p>Pada dasarnya, selektor <em>field</em> merupakan filter dari <em>resource</em>. Secara <em>default</em>, tidak ada selektor/filter apapun yang diterapkan. Artinya,
semua <em>resource</em> dengan tipe apapun akan terpilih. Akibatnya, <em>query</em> dengan perintah <code>kubectl</code> di bawah ini akan memberikan hasil yang sama:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get pods
</span></span><span style=display:flex><span>kubectl get pods --field-selector <span style=color:#b44>&#34;&#34;</span>
</span></span></code></pre></div></div><h2 id=field-yang-didukung><em>Field</em> yang didukung</h2><p>Selektor-selektor <em>field</em> yang didukung oleh Kubernetes bervariasi tergantung dari tipe <em>resource</em>. Semua tipe <em>resource</em> mendukung <em>field</em>
<code>metadata.name</code> dan <code>metadata.namespace</code>. Jika kamu menggunakan selektor <em>field</em> yang tidak didukung, maka akan terjadi error. Contohnya:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get ingress --field-selector foo.bar<span style=color:#666>=</span>baz
</span></span></code></pre></div><pre tabindex=0><code>Error from server (BadRequest): Unable to find &#34;ingresses&#34; that match label selector &#34;&#34;, field selector &#34;foo.bar=baz&#34;: &#34;foo.bar&#34; is not a known field selector: only &#34;metadata.name&#34;, &#34;metadata.namespace&#34;
</code></pre><h2 id=operator-yang-didukung>Operator yang didukung</h2><p>Kamu dapat menggunakan operator <code>=</code>, <code>==</code>, dan <code>!=</code> pada selektor <em>field</em> (<code>=</code> dan <code>==</code> punya arti yang sama). Sebagai contoh, perintah <code>kubectl</code> ini
memilih semua Kubernetes Service yang tidak terdapat pada <em>namespace</em> <code>default</code>:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get services --field-selector metadata.namespace!<span style=color:#666>=</span>default
</span></span></code></pre></div><h2 id=selektor-berantai>Selektor berantai</h2><p>Seperti halnya <a href=/id/docs/concepts/overview/working-with-objects/labels>label</a> dan selektor-selektor lainnya, kamu dapat membuat selektor <em>field</em> berantai
(<em>chained</em>) dengan <em>list</em> yang dipisahkan oleh koma. Perintah <code>kubectl</code> di bawah ini memilih semua Pod dengan <code>status.phase</code> tidak sama dengan
<code>Running</code> dan <em>field</em> <code>spec.restartPolicy</code> sama dengan <code>Always</code>:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get pods --field-selector<span style=color:#666>=</span>status.phase!<span style=color:#666>=</span>Running,spec.restartPolicy<span style=color:#666>=</span>Always
</span></span></code></pre></div><h2 id=resource-dengan-beberapa-tipe><em>Resource</em> dengan beberapa tipe</h2><p>Kamu dapat menggunakan selektor-selektor <em>field</em> dengan beberapa tipe <em>resource</em> sekaligus. Perintah <code>kubectl</code> di bawah ini memilih semua Statefulset
dan Service yang tidak terdapat pada <em>namespace</em> <code>default</code>:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get statefulsets,services --all-namespaces --field-selector metadata.namespace!<span style=color:#666>=</span>default
</span></span></code></pre></div></div><div class=td-content style=page-break-before:always><h1 id=pg-5dd62c6a4a481b4cf1ac50f6799eb581>1.4.8 - Label yang Disarankan</h1><p>Kamu dapat melakukan visualisasi dan mengatur objek Kubernetes dengan lebih banyak <em>tools</em>
dibandingkan dengan perintah kubectl dan dasbor. Sekumpulan label mengizinkan <em>tools</em>
untuk bekerja dengan interoperabilitas, mendeskripsikan objek dengan cara yang umum yang dapat
dipahami semua <em>tools</em>.</p><p>Sebagai tambahan bagi <em>tooling</em> tambahan, label yang disarankan ini mendeskripsikan
aplikasi sehingga informasi yang ada diapat di-<em>query</em>.</p><p>Metadata ini diorganisasi berbasis konsep dari sebuah aplikasi. Kubernetes bukan merupakan
sebuah platform sebagai sebuah <em>service</em> (<em>platform as a service</em>/PaaS) dan tidak
mewajibkan sebuah gagasan formal dari sebuah aplikasi.
Sebagai gantinya, aplikasi merupakan suatu hal informal yang dideskripsikan melalui metadata.
Definisi yang dimiliki oleh sebuah aplikasi merupakan sebuah hal yang cukup longgar.</p><div class="alert alert-info note callout" role=alert><strong>Catatan:</strong> Berikut merupakan label yang disarankan. Label ini mempermudah
proses manajemen aplikasi tetapi tidak dibutuhkan untuk <em>tooling</em> utama apa pun.</div><p>Label yang digunakan secara umum serta anotasi memiliki prefiks yang serupa: <code>app.kubernetes.io</code>. Label
tanpa sebuah prefiks bersifat privat khusus pengguna saja. Prefiks yang digunakan secara umum tadi
menjamin bahwa label tadi tidak akan mengganggu label <em>custom</em> yang diberikan oleh pengguna.</p><h2 id=label>Label</h2><p>Untuk mendapatkan keuntungan menyeluruh dari penggunaan label ini,
label harus digunakan pada seluruh objek sumber daya.</p><table><thead><tr><th><em>Key</em></th><th>Deskripsi</th><th>Contoh</th><th>Tipe</th></tr></thead><tbody><tr><td><code>app.kubernetes.io/name</code></td><td>Nama aplikasi</td><td><code>mysql</code></td><td>string</td></tr><tr><td><code>app.kubernetes.io/instance</code></td><td>Nama unik yang bersifat sebagai pengidentifikasi dari sebuah instans aplikasi</td><td><code>wordpress-abcxzy</code></td><td>string</td></tr><tr><td><code>app.kubernetes.io/version</code></td><td>Versi saat ini dari aplikasi (misalnya sebuah versi semantik, hash revisi, etc.)</td><td><code>5.7.21</code></td><td>string</td></tr><tr><td><code>app.kubernetes.io/component</code></td><td>Komponen yang ada pada arsitektur</td><td><code>database</code></td><td>string</td></tr><tr><td><code>app.kubernetes.io/part-of</code></td><td>Nama dari komponen lebih tinggi dari aplikasi yang mencakup bagian ini</td><td><code>wordpress</code></td><td>string</td></tr><tr><td><code>app.kubernetes.io/managed-by</code></td><td>Alat yang digunakan untuk mengatur operasi pada aplikasi</td><td><code>helm</code></td><td>string</td></tr></tbody></table><p>Untuk memberikan ilustrasi dari penggunaan label, bayangkan sebuah objek StatefulSet yang didefinisikan sebagai berikut:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>apps/v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>StatefulSet<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>labels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>app.kubernetes.io/name</span>:<span style=color:#bbb> </span>mysql<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>app.kubernetes.io/instance</span>:<span style=color:#bbb> </span>wordpress-abcxzy<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>app.kubernetes.io/version</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;5.7.21&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>app.kubernetes.io/component</span>:<span style=color:#bbb> </span>database<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>app.kubernetes.io/part-of</span>:<span style=color:#bbb> </span>wordpress<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>app.kubernetes.io/managed-by</span>:<span style=color:#bbb> </span>helm<span style=color:#bbb>
</span></span></span></code></pre></div><h2 id=aplikasi-dan-instans-aplikasi>Aplikasi dan Instans Aplikasi</h2><p>Sebuah aplikasi dapat diinstal sekali atau beberapa kali di dalam klaster Kubernetes dan,
pada beberapa kasus, di dalam sebuah <em>namespace</em> yang sama. Misalnya, wordpress dapat
diinstal lebih dari satu kali dimana situs web yang berbeda merupakan hasil instalasi yang berbeda.</p><p>Nama dari sebuah aplikasi dan nama instans akan dicatat secara terpisah. Sebagai contoh,
WordPress memiliki <code>wordpress</code> sebagai nilai dari <code>app.kubernetes.io/name</code> dimana
nama instans yang digunakan adalah <code>wordpress-abcxzy</code> yang merupakan nilai dari <code>app.kubernetes.io/instance</code>.
Hal ini memungkinkan aplikasi dan instans aplikasi untuk dapat diidentifikasi. Setiap instans dari aplikasi
haruslah memiliki nama yang unik.</p><h2 id=contoh>Contoh</h2><p>Untuk memberikan ilustrasi dengan cara yang berbeda pada penggunaan label, contoh di bawah ini
memiliki tingkat kompleksitas yang cukup beragam.</p><h3 id=sebuah-aplikasi-stateless-sederhana>Sebuah Aplikasi <em>Stateless</em> Sederhana</h3><p>Bayangkan sebuah kasus dimana sebuah aplikasi <em>stateless</em> di-<em>deploy</em>
menggunakan Deployment dan Service. Di bawah ini merupakan
contoh kutipan yang merepresentasikan bagaimana
label dapat digunakan secara sederhana.</p><p>Deployment digunakan untuk memastikan Pod dijalankan untuk aplikasi itu sendiri.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>apps/v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Deployment<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>labels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>app.kubernetes.io/name</span>:<span style=color:#bbb> </span>myservice<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>app.kubernetes.io/instance</span>:<span style=color:#bbb> </span>myservice-abcxzy<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:#00f;font-weight:700>...</span><span style=color:#bbb>
</span></span></span></code></pre></div><p>Service digunakan untuk mengekspos aplikasi.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Service<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>labels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>app.kubernetes.io/name</span>:<span style=color:#bbb> </span>myservice<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>app.kubernetes.io/instance</span>:<span style=color:#bbb> </span>myservice-abcxzy<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:#00f;font-weight:700>...</span><span style=color:#bbb>
</span></span></span></code></pre></div><h3 id=sebuah-aplikasi-web-dengan-basis-data>Sebuah Aplikasi Web dengan Basis Data</h3><p>Bayangkan sebuah aplikasi yang lebih kompleks: sebuah aplikasi web (WordPress)
yang menggunakan basis data (MySQL), yang diinstal menggunakan Helm.
Kutipan berikut merepresentasikan objek yang di-<em>deploy</em> untuk aplikasi ini.</p><p>Berikut merupakan konfigurasi Deployment yang digunakan untuk WordPress:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>apps/v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Deployment<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>labels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>app.kubernetes.io/name</span>:<span style=color:#bbb> </span>wordpress<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>app.kubernetes.io/instance</span>:<span style=color:#bbb> </span>wordpress-abcxzy<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>app.kubernetes.io/version</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;4.9.4&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>app.kubernetes.io/managed-by</span>:<span style=color:#bbb> </span>helm<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>app.kubernetes.io/component</span>:<span style=color:#bbb> </span>server<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>app.kubernetes.io/part-of</span>:<span style=color:#bbb> </span>wordpress<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:#00f;font-weight:700>...</span><span style=color:#bbb>
</span></span></span></code></pre></div><p>Service yang digunakan untuk mengekspos WordPress:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Service<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>labels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>app.kubernetes.io/name</span>:<span style=color:#bbb> </span>wordpress<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>app.kubernetes.io/instance</span>:<span style=color:#bbb> </span>wordpress-abcxzy<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>app.kubernetes.io/version</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;4.9.4&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>app.kubernetes.io/managed-by</span>:<span style=color:#bbb> </span>helm<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>app.kubernetes.io/component</span>:<span style=color:#bbb> </span>server<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>app.kubernetes.io/part-of</span>:<span style=color:#bbb> </span>wordpress<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:#00f;font-weight:700>...</span><span style=color:#bbb>
</span></span></span></code></pre></div><p>MySQL diekspos sebagai StatefulSet dengan metadata yang digunakan untuk StatefulSet tersebut serta aplikasi yang menggunakannya:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>apps/v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>StatefulSet<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>labels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>app.kubernetes.io/name</span>:<span style=color:#bbb> </span>mysql<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>app.kubernetes.io/instance</span>:<span style=color:#bbb> </span>mysql-abcxzy<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>app.kubernetes.io/version</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;5.7.21&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>app.kubernetes.io/managed-by</span>:<span style=color:#bbb> </span>helm<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>app.kubernetes.io/component</span>:<span style=color:#bbb> </span>database<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>app.kubernetes.io/part-of</span>:<span style=color:#bbb> </span>wordpress<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:#00f;font-weight:700>...</span><span style=color:#bbb>
</span></span></span></code></pre></div><p>Service yang digunakan untuk mengekspos MySQL sebagai bagian dari WordPress:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Service<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>labels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>app.kubernetes.io/name</span>:<span style=color:#bbb> </span>mysql<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>app.kubernetes.io/instance</span>:<span style=color:#bbb> </span>mysql-abcxzy<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>app.kubernetes.io/version</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;5.7.21&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>app.kubernetes.io/managed-by</span>:<span style=color:#bbb> </span>helm<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>app.kubernetes.io/component</span>:<span style=color:#bbb> </span>database<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>app.kubernetes.io/part-of</span>:<span style=color:#bbb> </span>wordpress<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:#00f;font-weight:700>...</span><span style=color:#bbb>
</span></span></span></code></pre></div><p>Dengan StatefulSet MySQL dan Service kamu dapat mengetahui informasi yang ada pada MySQL dan Wordpress.</p></div><div class=td-content style=page-break-before:always><h1 id=pg-2bf36ccd6b3dbeafecf87c39761b07c7>2 - Arsitektur Kubernetes</h1></div><div class=td-content><h1 id=pg-9ef2890698e773b6c0d24fd2c20146f5>2.1 - Node</h1><p>Node merupakan sebuah mesin <i>worker</i> di dalam Kubernetes, yang sebelumnya dinamakan <code>minion</code>.
Sebuah node bisa berupa VM ataupun mesin fisik, tergantung dari klaster-nya.
Masing-masing node berisi beberapa servis yang berguna untuk menjalankan banyak <a href=/id/docs/concepts/workloads/pods/pod/>pod</a> dan diatur oleh komponen-komponen yang dimiliki oleh master.
Servis-servis di dalam sebuah node terdiri dari <a href=/id/docs/concepts/overview/components/#node-components>runtime kontainer</a>, kubelet dan kube-proxy.
Untuk lebih detail, lihat dokumentasi desain arsitektur pada <a href=https://git.k8s.io/community/contributors/design-proposals/architecture/architecture.md#the-kubernetes-node>Node Kubernetes</a>.</p><h2 id=status-node>Status Node</h2><p>Sebuah status node berisikan informasi sebagai berikut:</p><ul><li><a href=#addresses>Addresses</a></li><li><a href=#condition>Condition</a></li><li><a href=#capacity>Capacity</a></li><li><a href=#info>Info</a></li></ul><p>Masing-masing bagian dijelaskan secara rinci di bawah ini.</p><h3 id=addresses>Addresses</h3><p>Penggunaan <i>field-field</i> ini bergantung pada penyedia layanan cloud ataupun konfigurasi bare metal yang kamu punya.</p><ul><li>HostName: Merupakan hostname yang dilaporkan oleh kernel node. Dapat diganti melalui parameter <code>--hostname-override</code> pada kubelet.</li><li>ExternalIP: Biasanya merupakan alamat IP pada node yang punya <i>route</i> eksternal (bisa diakses dari luar klaster).</li><li>InternalIP: Biasanya merupakan alamat IP pada node yang hanya punya <i>route</i> di dalam klaster.</li></ul><h3 id=condition>Condition</h3><p><i>Field</i> <code>conditions</code> menjelaskan tentang status dari semua node yang sedang berjalan (<code>Running</code>).</p><table><thead><tr><th>Kondisi Node</th><th>Penjelasan</th></tr></thead><tbody><tr><td><code>OutOfDisk</code></td><td><code>True</code> jika node sudah tidak punya cukup kapasitas disk untuk menjalankan pod baru, <code>False</code> jika sebaliknya</td></tr><tr><td><code>Ready</code></td><td><code>True</code> jika node sehat (<i>healthy</i>) dan siap untuk menerima pod, <code>False</code> jika node tidak lagi sehat (<i>unhealthy</i>) dan tidak siap menerima pod, serta <code>Unknown</code> jika kontroler node tidak menerima pesan di dalam <code>node-monitor-grace-period</code> (standarnya 40 detik)</td></tr><tr><td><code>MemoryPressure</code></td><td><code>True</code> jika memori pada node terkena tekanan (<i>pressure</i>) -- maksudnya, jika kapasitas memori node sudah di titik rendah; <code>False</code> untuk sebaliknya</td></tr><tr><td><code>PIDPressure</code></td><td><code>True</code> jika <i>process-process</i> mengalami tekanan (<i>pressure</i>) -- maksudnya, jika node menjalankan terlalu banyak <i>process</i>; <code>False</code> untuk sebaliknya</td></tr><tr><td><code>DiskPressure</code></td><td><code>True</code> jika ukuran disk mengalami tekanan (<i>pressure</i>) -- maksudnya, jika kapasitas disk sudah di titik rendah; <code>False</code> untuk sebaliknya</td></tr><tr><td><code>NetworkUnavailable</code></td><td><code>True</code> jika jaringan untuk node tidak dikonfigurasi dengan benar, <code>False</code> untuk sebaliknya</td></tr></tbody></table><p><i>Condition</i> pada node direpresentasikan oleh suatu obyek JSON. Sebagai contoh, respon berikut ini menggambarkan node yang sedang sehat (<i>healthy</i>).</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-json data-lang=json><span style=display:flex><span><span style=color:#b44>&#34;conditions&#34;</span><span>:</span> [
</span></span><span style=display:flex><span>  {
</span></span><span style=display:flex><span>    <span style=color:green;font-weight:700>&#34;type&#34;</span>: <span style=color:#b44>&#34;Ready&#34;</span>,
</span></span><span style=display:flex><span>    <span style=color:green;font-weight:700>&#34;status&#34;</span>: <span style=color:#b44>&#34;True&#34;</span>
</span></span><span style=display:flex><span>  }
</span></span><span style=display:flex><span>]
</span></span></code></pre></div><p>Jika status untuk <code>Ready condition</code> bernilai <code>Unknown</code> atau <code>False</code> untuk waktu yang lebih dari <code>pod-eviction-timeout</code>, tergantung bagaimana <a href=/docs/admin/kube-controller-manager/>kube-controller-manager</a> dikonfigurasi, semua pod yang dijalankan pada node tersebut akan dihilangkan oleh Kontroler Node.
Durasi <i>eviction timeout</i> yang standar adalah <strong>lima menit</strong>.
Pada kasus tertentu ketika node terputus jaringannya, apiserver tidak dapat berkomunikasi dengan kubelet yang ada pada node.
Keputusan untuk menghilangkan pod tidak dapat diberitahukan pada kubelet, sampai komunikasi dengan apiserver terhubung kembali.
Sementara itu, pod-pod akan terus berjalan pada node yang sudah terputus, walaupun mendapati <i>schedule</i> untuk dihilangkan.</p><p>Pada versi Kubernetes sebelum 1.5, kontroler node dapat menghilangkan dengan paksa (<a href=/id/docs/concepts/workloads/pods/pod/#force-deletion-of-pods>force delete</a>) pod-pod yang terputus dari apiserver.
Namun, pada versi 1.5 dan seterusnya, kontroler node tidak menghilangkan pod dengan paksa, sampai ada konfirmasi bahwa pod tersebut sudah berhenti jalan di dalam klaster.
Pada kasus dimana Kubernetes tidak bisa menarik kesimpulan bahwa ada node yang telah meninggalkan klaster, admin klaster mungkin perlu untuk menghilangkan node secara manual.
Menghilangkan obyek node dari Kubernetes akan membuat semua pod yang berjalan pada node tersebut dihilangkan oleh apiserver, dan membebaskan nama-namanya agar bisa digunakan kembali.</p><p>Pada versi 1.12, fitur <code>TaintNodesByCondition</code> telah dipromosikan ke beta, sehingga kontroler <i>lifecycle</i> node secara otomatis membuat <a href=/id/docs/concepts/configuration/taint-and-toleration/>taints</a> yang merepresentasikan <i>conditions</i>.
Akibatnya, <i>scheduler</i> menghiraukan <i>conditions</i> ketika mempertimbangkan sebuah Node; <i>scheduler</i> akan melihat pada <i>taints</i> sebuah Node dan <i>tolerations</i> sebuah Pod.</p><p>Sekarang, para pengguna dapat memilih antara model <i>scheduling</i> yang lama dan model <i>scheduling</i> yang lebih fleksibel.
Pada model yang lama, sebuah pod tidak memiliki <i>tolerations</i> apapun sampai mendapat giliran <i>schedule</i>. Namun, pod dapat dijalankan pada Node tertentu, dimana pod melakukan toleransi terhadap <i>taints</i> yang dimiliki oleh Node tersebut.</p><div class="alert alert-warning caution callout" role=alert><strong>Perhatian:</strong> Mengaktifkan fitur ini menambahkan <i>delay</i> sedikit antara waktu saat suatu <i>condition</i> terlihat dan saat suatu <i>taint</i> dibuat. <i>Delay</i> ini biasanya kurang dari satu detik, tapi dapat menambahkan jumlah yang telah berhasil mendapat <i>schedule</i>, namun ditolak oleh kubelet untuk dijalankan.</div><h3 id=capacity>Capacity</h3><p>Menjelaskan tentang <i>resource-resource</i> yang ada pada node: CPU, memori, dan jumlah pod secara maksimal yang dapat dijalankan pada suatu node.</p><h3 id=info>Info</h3><p>Informasi secara umum pada suatu node, seperti versi kernel, versi Kubernetes (versi kubelet dan kube-proxy), versi Docker (jika digunakan), nama OS.
Informasi ini dikumpulkan oleh Kubelet di dalam node.</p><h2 id=manajemen>Manajemen</h2><p>Tidak seperti <a href=/id/docs/concepts/workloads/pods/pod/>pod</a> dan <a href=/id/docs/concepts/services-networking/service/>service</a>, sebuah node tidaklah dibuat dan dikonfigurasi oleh Kubernetes: tapi node dibuat di luar klaster oleh penyedia layanan cloud, seperti Google Compute Engine, atau <i>pool</i> mesin fisik ataupun virtual (VM) yang kamu punya.
Jadi ketika Kubernetes membuat sebuah node, obyek yang merepresentasikan node tersebut akan dibuat.
Setelah pembuatan, Kubernetes memeriksa apakah node tersebut valid atau tidak.
Contohnya, jika kamu mencoba untuk membuat node dari konten berikut:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-json data-lang=json><span style=display:flex><span>{
</span></span><span style=display:flex><span>  <span style=color:green;font-weight:700>&#34;kind&#34;</span>: <span style=color:#b44>&#34;Node&#34;</span>,
</span></span><span style=display:flex><span>  <span style=color:green;font-weight:700>&#34;apiVersion&#34;</span>: <span style=color:#b44>&#34;v1&#34;</span>,
</span></span><span style=display:flex><span>  <span style=color:green;font-weight:700>&#34;metadata&#34;</span>: {
</span></span><span style=display:flex><span>    <span style=color:green;font-weight:700>&#34;name&#34;</span>: <span style=color:#b44>&#34;10.240.79.157&#34;</span>,
</span></span><span style=display:flex><span>    <span style=color:green;font-weight:700>&#34;labels&#34;</span>: {
</span></span><span style=display:flex><span>      <span style=color:green;font-weight:700>&#34;name&#34;</span>: <span style=color:#b44>&#34;my-first-k8s-node&#34;</span>
</span></span><span style=display:flex><span>    }
</span></span><span style=display:flex><span>  }
</span></span><span style=display:flex><span>}
</span></span></code></pre></div><p>Kubernetes membuat sebuah obyek node secara internal (representasinya), dan melakukan validasi terhadap node. Validasi dilakukan dengan memeriksa kondisi kesehatan node (<i>health checking</i>), berdasarkan <i>field</i> <code>metadata.name</code>. Jika node valid -- terjadi saat semua servis yang diperlukan sudah jalan -- maka node diperbolehkan untuk menjalankan sebuah pod.
Namun jika tidak valid, node tersebut akan dihiraukan untuk aktivitas apapun yang berhubungan dengan klaster, sampai telah menjadi valid.</p><div class="alert alert-info note callout" role=alert><strong>Catatan:</strong> Kubernetes tetap menyimpan obyek untuk node yang tidak valid, dan terus memeriksa apakah node telah menjadi valid atau belum.
Kamu harus secara eksplisit menghilangkan obyek Node tersebut untuk menghilangkan proses ini.</div><p>Saat ini, ada tiga komponen yang berinteraksi dengan antarmuka node di Kubernetes: kontroler node, kubelet, dan kubectl.</p><h3 id=kontroler-node>Kontroler Node</h3><p>Kontroler node adalah komponen master Kubernetes yang berfungsi untuk mengatur berbagai aspek dari node.</p><p>Kontroler node memiliki berbagai peran (<i>role</i>) dalam sebuah <i>lifecycle</i> node.
Pertama, menetapkan blok CIDR pada node tersebut saat registrasi (jika CIDR <i>assignment</i> diaktifkan).</p><p>Kedua, terus memperbarui daftar internal node di dalam kontroler node, sesuai dengan daftar mesin yang tersedia di dalam penyedia layanan cloud.
Ketika berjalan di dalam <i>environment</i> cloud, kapanpun saat sebuah node tidak lagi sehat (<i>unhealthy</i>), kontroler node bertanya pada penyedia cloud, apakah VM untuk node tersebut masihkah tersedia atau tidak.
Jika sudah tidak tersedia, kontroler node menghilangkan node tersebut dari daftar node.</p><p>Ketiga, melakukan monitor terhadap kondisi kesehatan (<i>health</i>) node.
Kontroler node bertanggung jawab untuk mengubah status <code>NodeReady condition</code> pada <code>NodeStatus</code> menjadi <code>ConditionUnknown</code>, ketika sebuah node terputus jaringannya (kontroler node tidak lagi mendapat <i>heartbeat</i> karena suatu hal, contohnya karena node tidak hidup), dan saat kemudian melakukan <i>eviction</i> terhadap semua pod yang ada pada node tersebut (melalui terminasi halus -- <i>graceful</i>) jika node masih terus terputus. (<i>Timeout</i> standar adalah 40 detik untuk mulai melaporkan <code>ConditionUnknown</code> dan 5 menit setelah itu untuk mulai melakukan <i>eviction</i> terhadap pod.)</p><p>Kontroler node memeriksa <i>state</i> masing-masing node untuk durasi yang ditentukan oleh argumen <code>--node-monitor-period</code>.</p><p>Pada versi Kubernetes sebelum 1.13, <code>NodeStatus</code> adalah <i>heartbeat</i> yang diberikan oleh node.
Setelah versi 1.13, fitur <i>node lease</i> diperkenalkan sebagai fitur alpha (fitur gate <code>NodeLease</code>,
<a href=https://github.com/kubernetes/enhancements/blob/master/keps/sig-node/0009-node-heartbeat.md>KEP-0009</a>).
Ketika fitur <i>node lease</i> diaktifasi, setiap node terhubung dengan obyek <code>Lease</code> di dalam <i>namespace</i> <code>kube-node-lease</code> yang terus diperbarui secara berkala.
Kemudian, <code>NodeStatus</code> dan <i>node lease</i> keduanya dijadikan sebagai <i>heartbeat</i> dari node.
Semua <i>node lease</i> diperbarui sesering mungkin, sedangkan <code>NodeStatus</code> dilaporkan dari node untuk master hanya ketika ada perubahan atau telah melewati periode waktu tertentu (<i>default</i>-nya 1 menit, lebih lama daripada <i>default timeout</i> node-node yang terputus jaringannya).
Karena <i>node lease</i> jauh lebih ringan daripada <code>NodeStatus</code>, fitur ini membuat <i>heartbeat</i> dari node jauh lebih murah secara signifikan dari sudut pandang skalabilitas dan performa.</p><p>Di Kubernetes 1.4, kami telah memperbarui <i>logic</i> dari kontroler node supaya lebih baik dalam menangani kasus saat banyak sekali node yang tidak bisa terhubung dengan master (contohnya, karena master punya masalah jaringan).
Mulai dari 1.4, kontroler node melihat <i>state</i> dari semua node di dalam klaster, saat memutuskan untuk melakukan <i>eviction</i> pada pod.</p><p>Pada kasus kebanyakan, kontroler node membatasi <i>rate eviction</i> menjadi <code>--node-eviction-rate</code> (<i>default</i>-nya 0.1) per detik.
Artinya, kontroler node tidak akan melakukan <i>eviction</i> pada pod lebih dari 1 node per 10 detik.</p><p>Perlakuan <i>eviction</i> pada node berubah ketika sebuah node menjadi tidak sehat (<i>unhealthy</i>) di dalam suatu zona <i>availability</i>.
Kontroler node memeriksa berapa persentase node di dalam zona tersebut yang tidak sehat (saat <code>NodeReady condition</code> menjadi <code>ConditionUnknown</code> atau <code>ConditionFalse</code>) pada saat yang bersamaan.
Jika persentase node yang tidak sehat bernilai <code>--unhealthy-zone-threshold</code> (<i>default</i>-nya 0.55), maka <i>rate eviction</i> berkurang: untuk ukuran klaster yang kecil (saat jumlahnya lebih kecil atau sama dengan jumlah node <code>--large-cluster-size-threshold</code> - <i>default</i>-nya 50), maka <i>eviction</i> akan berhenti dilakukan.
Jika masih besar jumlahnya, <i>rate eviction</i> dikurangi menjadi <code>--secondary-node-eviction-rate</code> (<i>default</i>-nya 0.01) per detik.</p><p>Alasan kenapa hal ini diimplementasi untuk setiap zona <i>availability</i> adalah karena satu zona bisa saja terputus dari master, saat yang lainnya masih terhubung.
Jika klaster tidak menjangkau banyak zona <i>availability</i> yang disediakan oleh penyedia cloud, maka hanya ada satu zona (untuk semua node di dalam klaster).</p><p>Alasan utama untuk menyebarkan node pada banyak zona <i>availability</i> adalah supaya <i>workload</i> dapat dipindahkan ke zona sehat (<i>healthy</i>) saat suatu zona mati secara menyeluruh.
Kemudian, jika semua node di dalam suatu zona menjadi tidak sehat (<i>unhealthy</i>), maka kontroler node melakukan <i>eviction</i> pada <i>rate</i> normal <code>--node-eviction-rate</code>.
Kasus khusus, ketika seluruh zona tidak ada satupun sehat (tidak ada node yang sehat satupun di dalam klaster).
Pada kasus ini, kontroler node berasumsi ada masalah pada jaringan master, dan menghentikan semua <i>eviction</i> sampai jaringan terhubung kembali.</p><p>Mulai dari Kubernetes 1.6, kontroler node juga bertanggung jawab untuk melakukan <i>eviction</i> pada pod-pod yang berjalan di atas node dengan <i>taints</i> <code>NoExecute</code>, ketika pod-pod tersebut sudah tidak lagi <i>tolerate</i> terhadap <i>taints</i>.
Sebagai tambahan, hal ini di-nonaktifkan secara <i>default</i> pada fitur alpha, kontroler node bertanggung jawab untuk menambahkan <i>taints</i> yang berhubungan dengan masalah pada node, seperti terputus atau <code>NotReady</code>.
Lihat <a href=/id/docs/concepts/scheduling-eviction/taint-and-toleration/>dokumentasi ini</a> untuk bahasan detail tentang <i>taints</i> <code>NoExecute</code> dan fitur alpha.</p><p>Mulai dari versi 1.8, kontroler node bisa diatur untuk bertanggung jawab pada pembuatan <i>taints</i> yang merepresentasikan node <i>condition</i>.
Ini merupakan fitur alpha untuk versi 1.8.</p><h3 id=i-self-registration-i-untuk-node><i>Self-Registration</i> untuk Node</h3><p>Ketika argumen <code>--register-node</code> pada kubelet bernilai <i>true</i> (<i>default</i>-nya), kubelet akan berusaha untuk registrasi dirinya melalui API server.
Ini merupakan <i>pattern</i> yang disukai, digunakan oleh kebanyakan <i>distros</i>.</p><p>Kubelet memulai registrasi diri (<i>self-registration</i>) dengan opsi-opsi berikut:</p><ul><li><code>--kubeconfig</code> - <i>Path</i> berisi kredensial-kredensial yang digunakan untuk registrasi diri pada apiserver.</li><li><code>--cloud-provider</code> - Cara berbicara pada sebuah penyedia layanan cloud, baca tentang metadata-nya.</li><li><code>--register-node</code> - Registrasi secara otomatis pada API server.</li><li><code>--register-with-taints</code> - Registrasi node dengan daftar <i>taints</i> (dipisahkan oleh koma <code>&lt;key>=&lt;value>:&lt;effect></code>). No-op jika <code>register-node</code> bernilai <i>false</i>.</li><li><code>--node-ip</code> - Alamat IP dari node dimana kubelet berjalan.</li><li><code>--node-labels</code> - Label-label untuk ditambahkan saat melakukan registrasi untuk node di dalam klaster (lihat label yang dibatasi secara paksa oleh <a href=/docs/reference/access-authn-authz/admission-controllers/#noderestriction>NodeRestriction admission plugin</a> untuk 1.13+).</li><li><code>--node-status-update-frequency</code> - Menentukan seberapa sering kubelet melaporkan status pada master.</li></ul><p>Ketika mode <a href=/docs/reference/access-authn-authz/node/>otorisasi Node</a> dan <a href=/docs/reference/access-authn-authz/admission-controllers/#noderestriction>NodeRestriction admission plugin</a> diaktifkan, semua kubelet hanya punya otoritas untuk membuat/modifikasi <i>resource</i> Node masing-masing.</p><h4 id=administrasi-node-secara-manual>Administrasi Node secara Manual</h4><p>Seorang admin klaster dapat membuat dan memodifikasi obyek node.</p><p>Jika admin ingin untuk membuat obyek node secara manual, atur argument <code>--register-node=false</code> pada kubelet.</p><p>Admin dapat memodifikasi <i>resource-resource</i> node (terlepas dari <code>--register-node</code>).
Modifikasi terdiri dari pengaturan label pada node dan membuat node tidak dapat di-<i>schedule</i>.</p><p>Label-label pada node digunakan oleh <i>selector</i> node untuk mengatur proses <i>schedule</i> untuk pod, misalnya, membatasi sebuah pod hanya boleh dijalankan pada node-node tertentu.</p><p>Menandai sebuah node untuk tidak dapat di-<i>schedule</i> mencegah pod baru untuk tidak di-<i>schedule</i> pada node, tanpa mempengaruhi pod-pod yang sudah berjalan pada node tersebut.
Ini berguna sebagai langkah persiapan untuk melakukan <i>reboote</i> pada node.
Sebagai contoh, untuk menandai sebuah node untuk tidak dapat di-<i>schedule</i>, jalankan perintah berikut:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl cordon <span style=color:#b8860b>$NODENAME</span>
</span></span></code></pre></div><div class="alert alert-info note callout" role=alert><strong>Catatan:</strong> Pod-pod yang dibuat oleh suatu kontroler DaemonSet menghiraukan <i>scheduler</i> Kubernetes dan mengabaikan tanda <i>unschedulable</i> pada node.
Hal ini mengasumsikan bahwa <i>daemons</i> dimiliki oleh mesin, walaupun telah dilakukan <i>drain</i> pada aplikasi, saat melakukan persaiapan <i>reboot</i>.</div><h3 id=kapasitas-node>Kapasitas Node</h3><p>Kapasitas node (jumlah CPU dan memori) adalah bagian dari obyek node.
Pada umumnya, node-node melakukan registrasi diri dan melaporkan kapasitasnya saat obyek node dibuat.
Jika kamu melakukan <a href=#manual-node-administration>administrasi node manual</a>, maka kamu perlu mengatur kapasitas node saat menambahkan node baru.</p><p><i>Scheduler</i> Kubernetes memastikan kalau ada <i>resource</i> yang cukup untuk menjalankan semua pod di dalam sebuah node.
Kubernetes memeriksa jumlah semua <i>request</i> untuk kontainer pada sebuah node tidak lebih besar daripada kapasitas node.
Hal ini termasuk semua kontainer yang dijalankan oleh kubelet. Namun, ini tidak termasuk kontainer-kontainer yang dijalankan secara langsung oleh <a href=/id/docs/concepts/overview/components/#node-components>runtime kontainer</a> ataupun <i>process</i> yang ada di luar kontainer.</p><p>Kalau kamu ingin secara eksplisit menyimpan <i>resource</i> cadangan untuk menjalankan <i>process-process</i> selain Pod, ikut tutorial <a href=/docs/tasks/administer-cluster/reserve-compute-resources/#system-reserved>menyimpan resource cadangan untuk <i>system daemon</i></a>.</p><h2 id=obyek-api>Obyek API</h2><p>Node adalah tingkatan tertinggi dari <i>resource</i> di dalam Kubernetes REST API.
Penjelasan lebih detail tentang obyek API dapat dilihat pada: <a href=/docs/reference/generated/kubernetes-api/v1.25/#node-v1-core>Obyek Node API</a>.</p></div><div class=td-content style=page-break-before:always><h1 id=pg-c0251def6da29b30afebfb04549f1703>2.2 - Komunikasi antara Control Plane dan Node</h1><p>Dokumen ini menjelaskan tentang jalur-jalur komunikasi di antara klaster Kubernetes dan control plane yang sebenarnya hanya berhubungan dengan apiserver saja.
Kenapa ada dokumen ini? Supaya kamu, para pengguna Kubernetes, punya gambaran bagaimana mengatur instalasi untuk memperketat konfigurasi jaringan di dalam klaster.
Hal ini cukup penting, karena klaster bisa saja berjalan pada jaringan tak terpercaya (<i>untrusted network</i>), ataupun melalui alamat-alamat IP publik pada penyedia cloud.</p><h2 id=node-menuju-control-plane>Node Menuju Control Plane</h2><p>Kubernetes memiliki sebuah pola API "hub-and-spoke". Semua penggunaan API dari Node (atau Pod dimana Pod-Pod tersebut dijalankan) akan diterminasi pada apiserver (tidak ada satu komponen <em>control plane</em> apa pun yang didesain untuk diekspos pada servis <em>remote</em>).
Apiserver dikonfigurasi untuk mendengarkan koneksi aman <em>remote</em> yang pada umumnya terdapat pada porta HTTPS (443) dengan satu atau lebih bentuk <a href=/docs/reference/access-authn-authz/authentication/>autentikasi</a> klien yang dipasang.
Sebaiknya, satu atau beberapa metode <a href=/docs/reference/access-authn-authz/authorization/>otorisasi</a> juga dipasang, terutama jika kamu memperbolehkan <a href=/docs/reference/access-authn-authz/authentication/#anonymous-requests>permintaan anonim (<i>anonymous request</i>)</a> ataupun <a href=/docs/reference/access-authn-authz/authentication/#service-account-tokens>service account token</a>.</p><p>Jika diperlukan, Pod-Pod dapat terhubung pada apiserver secara aman dengan menggunakan ServiceAccount.
Dengan ini, Kubernetes memasukkan <em>public root certificate</em> dan <em>bearer token</em> yang valid ke dalam Pod, secara otomatis saat Pod mulai dijalankan.
Kubernetes Service (di dalam semua Namespace) diatur dengan sebuah alamat IP virtual. Semua yang mengakses alamat IP ini akan dialihkan (melalui kube-proxy) menuju <em>endpoint</em> HTTPS dari apiserver.</p><p>Komponen-komponen juga melakukan koneksi pada apiserver klaster melalui porta yang aman.</p><p>Akibatnya, untuk konfigurasi yang umum dan standar, semua koneksi dari klaster (node-node dan pod-pod yang berjalan di atas node tersebut) menujucontrol planesudah terhubung dengan aman.
Dan juga, klaster dancontrol planebisa terhubung melalui jaringan publik dan/atau yang tak terpercaya (<i>untrusted</i>).</p><h2 id=control-plane-menuju-node>Control Plane menuju Node</h2><p>Ada dua jalur komunikasi utama dari <em>control plane</em> (apiserver) menuju klaster. Pertama, dari apiserver ke proses kubelet yang berjalan pada setiap Node di dalam klaster. Kedua, dari apiserver ke setiap Node, Pod, ataupun Service melalui fungsi proksi pada apiserver</p><h3 id=apiserver-menuju-kubelet>Apiserver menuju kubelet</h3><p>Koneksi dari apiserver menuju kubelet bertujuan untuk:</p><ul><li>Melihat log dari pod-pod.</li><li>Masuk ke dalam pod-pod yang sedang berjalan (<i>attach</i>).</li><li>Menyediakan fungsi port-forward dari kubelet.</li></ul><p>Semua koneksi ini diterminasi pada <i>endpoint</i> HTTPS dari kubelet.
Secara <i>default</i>, apiserver tidak melakukan verifikasi <i>serving certificate</i> dari kubelet, yang membuat koneksi terekspos pada serangan <i>man-in-the-middle</i>, dan juga <strong>tidak aman</strong> untuk terhubung melalui jaringan tak terpercaya (<i>untrusted</i>) dan/atau publik.</p><p>Untuk melakukan verifikasi koneksi ini, berikan <i>root certificate</i> pada apiserver melalui tanda <code>--kubelet-certificate-authority</code>, sehingga apiserver dapat memverifikasi <i>serving certificate</i> dari kubelet.</p><p>Cara lainnya, gunakan <a href=/docs/concepts/architecture/master-node-communication/#ssh-tunnels>tunnel SSH</a> antara apiserver dan kubelet jika diperlukan, untuk menghindari komunikasi melalui jaringan tak terpercaya (<i>untrusted</i>) atau publik.</p><p>Terakhir, yang terpenting, aktifkan <a href=/docs/admin/kubelet-authentication-authorization/>autentikasi dan/atau otorisasi Kubelet</a> untuk mengamankan API kubelet.</p><h3 id=apiserver-menuju-node-pod-dan-service>Apiserver menuju Node, Pod, dan Service</h3><p>Secara <i>default</i>, koneksi apiserver menuju node, pod atau service hanyalah melalui HTTP polos (<i>plain</i>), sehingga tidak ada autentikasi maupun enkripsi.
Koneksi tersebut bisa diamankan melalui HTTPS dengan menambahkan <code>https:</code> pada URL API dengan nama dari node, pod, atau service.
Namun, koneksi tidak tervalidasi dengan <i>certificate</i> yang disediakan oleh <i>endpoint</i> HTTPS maupun kredensial <i>client</i>, sehingga walaupun koneksi sudah terenkripsi, tidak ada yang menjamin integritasnya.
Koneksi ini <strong>tidak aman</strong> untuk dilalui pada jaringan publik dan/atau tak terpercaya <i>untrusted</i>.</p><h3 id=tunnel-ssh>Tunnel SSH</h3><p>Kubernetes menyediakan tunnel SSH untuk mengamankan jalur komunikasi control plane -> Klaster.
Dengan ini, apiserver menginisiasi sebuah <i>tunnel</i> SSH untuk setiap node di dalam klaster (terhubung ke server SSH di port 22) dan membuat semua trafik menuju kubelet, node, pod, atau service dilewatkan melalui <i>tunnel</i> tesebut.
<i>Tunnel</i> ini memastikan trafik tidak terekspos keluar jaringan dimana node-node berada.</p><p><i>Tunnel</i> SSH saat ini sudah usang (<i>deprecated</i>), jadi sebaiknya jangan digunakan, kecuali kamu tahu pasti apa yang kamu lakukan.
Sebuah desain baru untuk mengganti kanal komunikasi ini sedang disiapkan.</p></div><div class=td-content style=page-break-before:always><h1 id=pg-ca8819042a505291540e831283da66df>2.3 - Controller</h1><p>Dalam bidang robotika dan otomatisasi, <em>control loop</em> atau kontrol tertutup adalah
lingkaran tertutup yang mengatur keadaan suatu sistem.</p><p>Berikut adalah salah satu contoh kontrol tertutup: termostat di sebuah ruangan.</p><p>Ketika kamu mengatur suhunya, itu mengisyaratkan ke termostat
tentang <em>keadaan yang kamu inginkan</em>. Sedangkan suhu kamar yang sebenarnya
adalah <em>keadaan saat ini</em>. Termostat berfungsi untuk membawa keadaan saat ini
mendekati ke keadaan yang diinginkan, dengan menghidupkan atau mematikan
perangkat.</p><p>Di Kubernetes, <em>controller</em> adalah kontrol tertutup yang mengawasi keadaan klaster
<a class=glossary-tooltip title='Sekumpulan mesin pekerja, yang dikenal sebagai Node, yang menjalankan aplikasi dalam Container. Setiap klaster setidaknya mempunyai satu Node pekerja.' data-toggle=tooltip data-placement=top href='/id/docs/reference/glossary/?all=true#term-cluster' target=_blank aria-label=klaster>klaster</a> kamu, lalu membuat atau meminta
perubahan jika diperlukan. Setiap <em>controller</em> mencoba untuk memindahkan status
klaster saat ini mendekati keadaan yang diinginkan.</p>Di Kubernetes, pengontrol adalah kontrol tertutup yang mengawasi kondisi <a class=glossary-tooltip title='Sekumpulan mesin pekerja, yang dikenal sebagai Node, yang menjalankan aplikasi dalam Container. Setiap klaster setidaknya mempunyai satu Node pekerja.' data-toggle=tooltip data-placement=top href='/id/docs/reference/glossary/?all=true#term-cluster' target=_blank aria-label=klaster>klaster</a>, lalu membuat atau meminta perubahan jika diperlukan. Setiap pengontrol mencoba untuk memindahkan status klaster saat ini lebih dekat ke kondisi yang diinginkan.<h2 id=pola-controller>Pola <em>controller</em></h2><p>Sebuah <em>controller</em> melacak sekurang-kurangnya satu jenis sumber daya dari
Kubernetes.
<a href=/id/docs/concepts/overview/working-with-objects/kubernetes-objects/>objek-objek</a> ini
memiliki <em>spec field</em> yang merepresentasikan keadaan yang diinginkan. Satu atau
lebih <em>controller</em> untuk <em>resource</em> tersebut bertanggung jawab untuk membuat
keadaan sekarang mendekati keadaan yang diinginkan.</p><p><em>Controller</em> mungkin saja melakukan tindakan itu sendiri; namun secara umum, di
Kubernetes, <em>controller</em> akan mengirim pesan ke
<a class=glossary-tooltip title='Komponen control plane yang mengekspos API Kubernetes. Merupakan front-end dari control plane Kubernetes.' data-toggle=tooltip data-placement=top href=/docs/reference/generated/kube-apiserver/ target=_blank aria-label='API server'>API server</a> yang
mempunyai efek samping yang bermanfaat. Kamu bisa melihat contoh-contoh
di bawah ini.</p><h3 id=kontrol-melalui-server-api>Kontrol melalui server API</h3><p><em>Controller</em> <a class=glossary-tooltip title='Tugas terbatas atau bertumpuk (batch) yang berjalan sampai selesai.' data-toggle=tooltip data-placement=top href=/docs/concepts/workloads/controllers/job/ target=_blank aria-label=Job>Job</a> adalah contoh dari <em>controller</em>
bawaan dari Kubernetes. <em>Controller</em> bawaan tersebut mengelola status melalui
interaksi dengan server API dari suatu klaster.</p><p>Job adalah sumber daya dalam Kubernetes yang menjalankan a
<a class=glossary-tooltip title='Unit Kubernetes yang paling sederhana dan kecil. Sebuah Pod merepresentasikan sebuah set kontainer yang dijalankan pada kluster kamu.' data-toggle=tooltip data-placement=top href=/docs/concepts/workloads/pods/pod-overview/ target=_blank aria-label=Pod>Pod</a>, atau mungkin beberapa Pod sekaligus,
untuk melakukan sebuah pekerjaan dan kemudian berhenti.</p><p>(Setelah <a href=../../../../en/docs/concepts/scheduling-eviction/>dijadwalkan</a>, objek Pod
akan menjadi bagian dari keadaan yang diinginkan oleh kubelet).</p><p>Ketika <em>controller job</em> melihat tugas baru, maka <em>controller</em> itu memastikan bahwa,
di suatu tempat pada klaster kamu, kubelet dalam sekumpulan Node menjalankan
Pod-Pod dengan jumlah yang benar untuk menyelesaikan pekerjaan. <em>Controller job</em>
tidak menjalankan sejumlah Pod atau kontainer apa pun untuk dirinya sendiri.
Namun, <em>controller job</em> mengisyaratkan kepada server API untuk membuat atau
menghapus Pod. Komponen-komponen lain dalam
<a class=glossary-tooltip title='Merupakan lapisan orkestrasi Container yang mengekspos API dan antarmuka untuk mendefinisikan, menggelar, dan mengelola siklus hidup suatu Container.' data-toggle=tooltip data-placement=top href='/id/docs/reference/glossary/?all=true#term-control-plane' target=_blank aria-label='control plane'>control plane</a>
bekerja berdasarkan informasi baru (adakah Pod-Pod baru untuk menjadwalkan dan
menjalankan pekerjan), dan pada akhirnya pekerjaan itu selesai.</p><p>Setelah kamu membuat Job baru, status yang diharapkan adalah bagaimana
pekerjaan itu bisa selesai. <em>Controller job</em> membuat status pekerjaan saat ini
agar mendekati dengan keadaan yang kamu inginkan: membuat Pod yang melakukan
pekerjaan yang kamu inginkan untuk Job tersebut, sehingga Job hampir
terselesaikan.</p><p><em>Controller</em> juga memperbarui objek yang mengkonfigurasinya. Misalnya: setelah
pekerjaan dilakukan untuk Job tersebut, <em>controller job</em> memperbarui objek Job
dengan menandainya <code>Finished</code>.</p><p>(Ini hampir sama dengan bagaimana beberapa termostat mematikan lampu untuk
mengindikasikan bahwa kamar kamu sekarang sudah berada pada suhu yang kamu
inginkan).</p><h3 id=kontrol-langsung>Kontrol Langsung</h3><p>Berbeda dengan sebuah Job, beberapa dari <em>controller</em> perlu melakukan perubahan
sesuatu di luar dari klaster kamu.</p><p>Sebagai contoh, jika kamu menggunakan kontrol tertutup untuk memastikan apakah
cukup <a class=glossary-tooltip title='A node is a worker machine in Kubernetes.' data-toggle=tooltip data-placement=top href=/docs/concepts/architecture/nodes/ target=_blank aria-label=Node>Node</a>
dalam kluster kamu, maka <em>controller</em> memerlukan sesuatu di luar klaster saat ini
untuk mengatur Node-Node baru apabila dibutuhkan.</p><p><em>controller</em> yang berinteraksi dengan keadaan eksternal dapat menemukan keadaan
yang diinginkannya melalui server API, dan kemudian berkomunikasi langsung
dengan sistem eksternal untuk membawa keadaan saat ini mendekat keadaan yang
diinginkan.</p><p>(Sebenarnya ada sebuah <a href=https://github.com/kubernetes/autoscaler/><em>controller</em></a> yang melakukan penskalaan node secara
horizontal dalam klaster kamu.</p><h2 id=sekarang-banding-diinginkan>Status sekarang berbanding status yang diinginkan</h2><p>Kubernetes mengambil pandangan sistem secara <em>cloud-native</em>, dan mampu menangani
perubahan yang konstan.</p><p>Klaster kamu dapat mengalami perubahan kapan saja pada saat pekerjaan sedang
berlangsung dan kontrol tertutup secara otomatis memperbaiki setiap kegagalan.
Hal ini berarti bahwa, secara potensi, klaster kamu tidak akan pernah mencapai
kondisi stabil.</p><p>Selama <em>controller</em> dari klaster kamu berjalan dan mampu membuat perubahan yang
bermanfaat, tidak masalah apabila keadaan keseluruhan stabil atau tidak.</p><h2 id=perancangan>Perancangan</h2><p>Sebagai prinsip dasar perancangan, Kubernetes menggunakan banyak <em>controller</em> yang
masing-masing mengelola aspek tertentu dari keadaan klaster. Yang paling umum,
kontrol tertutup tertentu menggunakan salah satu jenis sumber daya
sebagai suatu keadaan yang diinginkan, dan memiliki jenis sumber daya yang
berbeda untuk dikelola dalam rangka membuat keadaan yang diinginkan terjadi.</p><p>Sangat penting untuk memiliki beberapa <em>controller</em> sederhana daripada hanya satu
<em>controller</em> saja, dimana satu kumpulan monolitik kontrol tertutup saling
berkaitan satu sama lain. Karena <em>controller</em> bisa saja gagal, sehingga Kubernetes
dirancang untuk memungkinkan hal tersebut.</p><p>Misalnya: <em>controller</em> pekerjaan melacak objek pekerjaan (untuk menemukan
adanya pekerjaan baru) dan objek Pod (untuk menjalankan pekerjaan tersebut dan
kemudian melihat lagi ketika pekerjaan itu sudah selesai). Dalam hal ini yang
lain membuat pekerjaan, sedangkan <em>controller</em> pekerjaan membuat Pod-Pod.</p><div class="alert alert-info note callout" role=alert><strong>Catatan:</strong><p>Ada kemungkinan beberapa <em>controller</em> membuat atau memperbarui jenis objek yang
sama. Namun di belakang layar, <em>controller</em> Kubernetes memastikan bahwa mereka
hanya memperhatikan sumbr daya yang terkait dengan sumber daya yang mereka
kendalikan.</p><p>Misalnya, kamu dapat memiliki Deployment dan Job; dimana keduanya akan membuat
Pod. <em>Controller Job</em> tidak akan menghapus Pod yang dibuat oleh Deployment kamu,
karena ada informasi (<a class=glossary-tooltip title='Tags objects with identifying attributes that are meaningful and relevant to users.' data-toggle=tooltip data-placement=top href=/docs/concepts/overview/working-with-objects/labels target=_blank aria-label=labels>labels</a>)
yang dapat oleh <em>controller</em> untuk membedakan Pod-Pod tersebut.</p></div><h2 id=menjalankan-_controller_>Berbagai cara menjalankan beberapa <em>controller</em></h2><p>Kubernetes hadir dengan seperangkat <em>controller</em> bawaan yang berjalan di dalam
<a class=glossary-tooltip title='Komponen control plane yang menjalankan pengontrol.' data-toggle=tooltip data-placement=top href=/docs/reference/generated/kube-controller-manager/ target=_blank aria-label=kube-controller-manager>kube-controller-manager</a>. Beberapa <em>controller</em>
bawaan memberikan perilaku inti yang sangat penting.</p><p><em>Controller Deployment</em> dan <em>controller Job</em> adalah contoh dari <em>controller</em> yang
hadir sebagai bagian dari Kubernetes itu sendiri (<em>controller</em> "bawaan").
Kubernetes memungkinkan kamu menjalankan <em>control plane</em> yang tangguh, sehingga
jika ada <em>controller</em> bawaan yang gagal, maka bagian lain dari <em>control plane</em> akan
mengambil alih pekerjaan.</p><p>Kamu juga dapat menemukan pengontrol yang berjalan di luar <em>control plane</em>, untuk
mengembangkan lebih jauh Kubernetes. Atau, jika mau, kamu bisa membuat
<em>controller</em> baru sendiri. Kamu dapat menjalankan <em>controller</em> kamu sendiri sebagai
satu kumpulan dari beberapa Pod, atau bisa juga sebagai bagian eksternal dari
Kubernetes. Manakah yang paling sesuai akan tergantung pada apa yang <em>controller</em>
khusus itu lakukan.</p><h2 id=selanjutnya>Selanjutnya</h2><ul><li>Silahkan baca tentang <a href=/docs/concepts/#kubernetes-control-plane><em>control plane</em> Kubernetes</a></li><li>Temukan beberapa dasar tentang <a href=/docs/concepts/#kubernetes-objects>objek-objek Kubernetes</a></li><li>Pelajari lebih lanjut tentang <a href=/id/docs/concepts/overview/kubernetes-api/>Kubernetes API</a></li><li>Apabila kamu ingin membuat <em>controller</em> sendiri, silakan lihat <a href=/id/docs/concepts/extend-kubernetes/extend-cluster/#extension-patterns>pola perluasan</a> dalam memperluas Kubernetes.</li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-bc804b02614d67025b4c788f1ca87fbc>2.4 - Konsep-konsep di balik Controller Manager</h1><p>Konsep <em>Cloud Controller Manager</em>/CCM (jangan tertukar dengan program biner kube-controller-manager) awalnya dibuat untuk memungkinkan kode vendor <em>cloud</em> spesifik dan kode inti Kubernetes untuk berkembang secara independen satu sama lainnya. CCM berjalan bersama dengan komponen Master lainnya seperti Kubernetes Controller Manager, API Server, dan Scheduler. CCM juga dapat dijalankan sebagai Kubernetes Addon (tambahan fungsi terhadap Kubernetes), yang akan berjalan di atas klaster Kubernetes.</p><p>Desain CCM didasarkan pada mekanisme <em>plugin</em> yang memungkinkan penyedia layanan <em>cloud</em> untuk berintegrasi dengan Kubernetes dengan mudah dengan menggunakan <em>plugin</em>. Sudah ada rencana untuk pengenalan penyedia layanan <em>cloud</em> baru pada Kubernetes, dan memindahkan penyedia layanan <em>cloud</em> yang sudah ada dari model yang lama ke model CCM.</p><p>Dokumen ini mendiskusikan konsep di balik CCM dan mendetail fungsi-fungsinya.</p><p>Berikut adalah arsitektur sebuah klaster Kubernetes tanpa CCM:</p><p><img src=/images/docs/pre-ccm-arch.png alt="Pre CCM Kube Arch"></p><h2 id=desain>Desain</h2><p>Pada diagram sebelumnya, Kubernetes dan penyedia layanan <em>cloud</em> diintegrasikan melalui beberapa komponen berbeda:</p><ul><li>Kubelet</li><li>Kubernetes Controller Manager</li><li>Kubernetes API server</li></ul><p>CCM menggabungkan semua logika yang bergantung pada <em>cloud</em> dari dalam tiga komponen tersebut ke dalam sebuah titik integrasi dengan <em>cloud</em>. Arsitektur baru di dalam model CCM adalah sebagai berikut:</p><p><img src=/images/docs/post-ccm-arch.png alt="CCM Kube Arch"></p><h2 id=komponen-komponen-ccm>Komponen-komponen CCM</h2><p>CCM memisahkan beberapa fungsi Kubernetes Controller Manager (KCM) dan menjalankannya sebagai proses yang berbeda. Secara spesifik, CCM memisahkan pengendali-pengendali (<em>controller</em>) di dalam KCM yang bergantung terhadap penyedia layanan <em>cloud</em>. KCM memiliki beberapa komponen pengendali yang bergantung pada <em>cloud</em> sebagai berikut:</p><ul><li>Node Controller</li><li>Volume Controller</li><li>Route Controller</li><li>Service Controller</li></ul><p>Pada versi 1.9, CCM menjalankan pengendali-pengendali dari daftar sebelumnya sebagai berikut:</p><ul><li>Node Controller</li><li>Route Controller</li><li>Service Controller</li></ul><div class="alert alert-info note callout" role=alert><strong>Catatan:</strong> Volume Controller secara sengaja tidak dipilih sebagai bagian dari CCM. Hal ini adalah karena kerumitan untuk melakukannya, dan mempertimbangkan usaha-usaha yang sedang berlangsung untuk memisahkan logika volume yang spesifik vendor dari KCM, sehingga diputuskan bahwa Volume Contoller tidak akan dipisahkan dari KCM ke CCM.</div><p>Rencana awal untuk mendukung volume menggunakan CCM adalah dengan menggunakan FlexVolume untuk mendukung penambahan volume secara <em>pluggable</em>. Namun, ada sebuah usaha lain yang diberi nama Container Storage Interface (CSI) yang sedang berlangsung untuk menggantikan FlexVolume.</p><p>Mempertimbangkan dinamika tersebut, kami memutuskan untuk mengambil tindakan sementara hingga CSI siap digunakan.</p><h2 id=fungsi-fungsi-ccm>Fungsi-fungsi CCM</h2><p>Fungsi-fungsi CCM diwarisi oleh komponen-komponen Kubernetes yang bergantung pada penyedia layanan <em>cloud</em>. Bagian ini disusun berdasarkan komponen-komponen tersebut.</p><h3 id=1-kubernetes-controller-manager>1. Kubernetes Controller Manager</h3><p>Kebanyakan fungsi CCM diturunkan dari KCM. Seperti yang telah disebutkan pada bagian sebelumnya, CCM menjalankan komponen-komponen pengendali sebagai berikut:</p><ul><li>Node Controller</li><li>Route Controller</li><li>Service Controller</li></ul><h4 id=node-controller>Node Controller</h4><p>Node Controller bertugas untuk menyiapkan sebuah node dengan cara mengambil informasi node-node yang berjalan di dalam klaster dari penyedia layanan <em>cloud</em>. Node Controller melakukan fungsi-fungsi berikut:</p><ol><li>Menyiapkan sebuah node dengan memberi label <em>zone</em>/<em>region</em> yang spesifik pada <em>cloud</em>.</li><li>Menyiapkan sebuah node dengan informasi <em>instance</em> yang spesifik <em>cloud</em> , misalnya tipe dan ukurannya.</li><li>Mendapatkan alamat jaringan dan <em>hostname</em> milik node tersebut.</li><li>Dalam hal sebuah node menjadi tidak responsif, memeriksa <em>cloud</em> untuk melihat apakah node tersebut telah dihapus dari <em>cloud</em>. Juga, menghapus objek Node tersebut dari klaster Kubernetes, jika node tersebut telah dihapus dari <em>cloud</em>.</li></ol><h4 id=route-controller>Route Controller</h4><p>Route Controller bertugas mengkonfigurasi rute jaringan di dalam <em>cloud</em> secara sesuai agar Container pada node-node yang berbeda di dalam klaster Kubernetes dapat berkomunikasi satu sama lain. Route Controller hanya berlaku untuk klaster yang berjalan pada Google Compute Engine (GCE) di penyedia layanan <em>cloud</em> GCP.</p><h4 id=service-controller>Service Controller</h4><p>Service Controller bertugas memantau terjadinya operasi <code>create</code>, <code>update</code>, dan <code>delete</code> pada Service. Berdasarkan keadaan terkini Service-service pada klaster Kubernetes, Service Controller mengkonfigurasi <em>load balancer</em> spesifik <em>cloud</em> (seperti ELB, Google LB, atau Oracle Cloud Infrastructure LB) agar sesuai dengan keadaan Service-service pada klaster Kubernetes. Sebagai tambahan, Service Controller juga memastikan bahwa <em>service backend</em> (target dari <em>load balancer</em> yang bersangkutan) dari <em>load balancer cloud</em> tersebut berada dalam kondisi terkini.</p><h3 id=2-kubelet>2. Kubelet</h3><p>Node Controller berisi fungsi Kubelet yang bergantung pada <em>cloud</em>. Sebelum CCM, Kubelet bertugas untuk menyiapkan node dengan informasi spesifik <em>cloud</em> seperti alamat IP, label <em>zone</em>/<em>region</em>, dan tipe <em>instance</em>. Setelah diperkenalkannya CCM, tugas tersebut telah dipindahkan dari Kubelet ke dalam CCM.</p><p>Pada model baru ini, Kubelet menyiapkan sebuah node tanpa informasi spesifik <em>cloud</em>. Namun, Kubelet menambahkan sebuah Taint pada node yang baru dibuat yang menjadikan node tersebut tidak dapat dijadwalkan (sehingga tidak ada Pod yang dapat dijadwalkan ke node tersebut) hingga CCM menyiapkan node tersebut dengan informasi spesifik <em>cloud</em>. Setelah itu, Kubelet menghapus Taint tersebut.</p><h2 id=mekanisme-plugin>Mekanisme <em>Plugin</em></h2><p>CCM menggunakan <em>interface</em> Go untuk memungkinkan implementasi dari <em>cloud</em> apapun untuk ditambahkan. Secara spesifik, CCM menggunakan CloudProvider Interface yang didefinisikan <a href=https://github.com/kubernetes/cloud-provider/blob/9b77dc1c384685cb732b3025ed5689dd597a5971/cloud.go#L42-L62>di sini</a></p><p>Implementasi dari empat kontroler-kontroler yang disorot di atas, dan beberapa kerangka kerja, bersama dengan CloudProvider Interface, akan tetap berada pada kode inti Kubernetes. Implementasi spesifik penyedia layanan <em>cloud</em> akan dibuat di luar kode inti dan menggunakan CloudProvider Interface yang didefinisikan di kode inti.</p><p>Untuk informasi lebih lanjut mengenai pengembangan <em>plugin</em>, lihat <a href=/docs/tasks/administer-cluster/developing-cloud-controller-manager/>Mengembangkan Cloud Controller Manager</a>.</p><h2 id=otorisasi>Otorisasi</h2><p>Bagian ini memerinci akses yang dibutuhkan oleh CCM terhadap berbagai objek API untuk melakukan tugas-tugasnya.</p><h3 id=akses-untuk-node-controller>Akses untuk Node Controller</h3><p>Node Controller hanya berinteraksi dengan objek-objek Node. Node Controller membutuhkan akses penuh untuk operasi <code>get</code>, <code>list</code>, <code>create</code>, <code>update</code>, <code>patch</code>, <code>watch</code>, dan <code>delete</code> terhadap objek-objek Node.</p><p>v1/Node:</p><ul><li>Get</li><li>List</li><li>Create</li><li>Update</li><li>Patch</li><li>Watch</li><li>Delete</li></ul><h3 id=akses-untuk-route-controller>Akses untuk Route Controller</h3><p>Route Controller memantau pembuatan objek Node dan mengkonfigurasi rute jaringan secara sesuai. Route Controller membutuhkan akses untuk operasi <code>get</code> terhadap objek-objek Node.</p><p>v1/Node:</p><ul><li>Get</li></ul><h3 id=akses-untuk-service-controller>Akses untuk Service Controller</h3><p>Service Controller memantau terjadinya operasi <code>create</code>, <code>update</code> dan <code>delete</code>, kemudian mengkonfigurasi Endpoint untuk Service-service tersebut secara sesuai.</p><p>Untuk mengakses Service-service, Service Controller membutuhkan akses untuk operasi <em>list</em> dan <em>watch</em>. Untuk memperbarui Service-service, dibutuhkan akses untuk operasi <code>patch</code> dan <code>update</code>.</p><p>Untuk menyiapkan Endpoint bagi untuk Service-service, dibutuhkan akses untuk operasi <code>create</code>, <code>list</code>, <code>get</code>, <code>watch</code>, dan <code>update</code>.</p><p>v1/Service:</p><ul><li>List</li><li>Get</li><li>Watch</li><li>Patch</li><li>Update</li></ul><h3 id=akses-lainnya>Akses Lainnya</h3><p>Implementasi dari inti CCM membutuhkan akses untuk membuat Event, dan untuk memastikan operasi yang aman, dibutuhkan akses untuk membuat ServiceAccount.</p><p>v1/Event:</p><ul><li>Create</li><li>Patch</li><li>Update</li></ul><p>v1/ServiceAccount:</p><ul><li>Create</li></ul><p>Detail RBAC dari ClusterRole untuk CCM adalah sebagai berikut:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>rbac.authorization.k8s.io/v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>ClusterRole<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>cloud-controller-manager<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>rules</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span>- <span style=color:green;font-weight:700>apiGroups</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:#b44>&#34;&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>resources</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- events<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>verbs</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- create<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- patch<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- update<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span>- <span style=color:green;font-weight:700>apiGroups</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:#b44>&#34;&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>resources</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- nodes<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>verbs</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:#b44>&#39;*&#39;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span>- <span style=color:green;font-weight:700>apiGroups</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:#b44>&#34;&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>resources</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- nodes/status<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>verbs</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- patch<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span>- <span style=color:green;font-weight:700>apiGroups</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:#b44>&#34;&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>resources</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- services<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>verbs</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- list<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- patch<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- update<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- watch<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span>- <span style=color:green;font-weight:700>apiGroups</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:#b44>&#34;&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>resources</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- serviceaccounts<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>verbs</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- create<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span>- <span style=color:green;font-weight:700>apiGroups</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:#b44>&#34;&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>resources</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- persistentvolumes<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>verbs</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- get<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- list<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- update<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- watch<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span>- <span style=color:green;font-weight:700>apiGroups</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:#b44>&#34;&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>resources</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- endpoints<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>verbs</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- create<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- get<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- list<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- watch<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- update<span style=color:#bbb>
</span></span></span></code></pre></div><h2 id=implementasi-vendor-vendor>Implementasi Vendor-vendor</h2><p>Penyedia layanan cloud berikut telah mengimplementasikan CCM:</p><ul><li><a href=https://github.com/digitalocean/digitalocean-cloud-controller-manager>Digital Ocean</a></li><li><a href=https://github.com/oracle/oci-cloud-controller-manager>Oracle</a></li><li><a href=https://github.com/kubernetes/cloud-provider-azure>Azure</a></li><li><a href=https://github.com/kubernetes/cloud-provider-gcp>GCP</a></li><li><a href=https://github.com/kubernetes/cloud-provider-aws>AWS</a></li><li><a href=https://github.com/baidu/cloud-provider-baiducloud>BaiduCloud</a></li><li><a href=https://github.com/linode/linode-cloud-controller-manager>Linode</a></li></ul><h2 id=administrasi-klaster>Administrasi Klaster</h2><p>Petunjuk lengkap untuk mengkonfigurasi dan menjalankan CCM disediakan <a href=/docs/tasks/administer-cluster/running-cloud-controller/#cloud-controller-manager>di sini</a>.</p></div><div class=td-content style=page-break-before:always><h1 id=pg-a5f7383c83ab9eb9cd0e3c4c020b3ae6>3 - Kontainer</h1></div><div class=td-content><h1 id=pg-8fda96dc403731ceba5e0ddd0ab3ad15>3.1 - Ikhtisar Kontainer</h1><p>Kontainer adalah teknologi untuk mengemas kode (yang telah dikompilasi) menjadi
suatu aplikasi beserta dengan dependensi-dependensi yang dibutuhkannya pada saat
dijalankan. Setiap kontainer yang Anda jalankan dapat diulang; standardisasi
dengan menyertakan dependensinya berarti Anda akan mendapatkan perilaku yang
sama di mana pun Anda menjalankannya.</p><p>Kontainer memisahkan aplikasi dari infrastruktur host yang ada dibawahnya. Hal
ini membuat penyebaran lebih mudah di lingkungan cloud atau OS yang berbeda.</p><h2 id=image-image-kontainer>Image-Image Kontainer</h2><p><a href=/id/docs/concepts/containers/images/>Kontainer image</a> meruapakan paket perangkat lunak
yang siap dijalankan, mengandung semua yang diperlukan untuk menjalankan
sebuah aplikasi: kode dan setiap <em>runtime</em> yang dibutuhkan, <em>library</em> dari
aplikasi dan sistem, dan nilai <em>default</em> untuk penganturan yang penting.</p><p>Secara desain, kontainer tidak bisa berubah: Anda tidak dapat mengubah kode
dalam kontainer yang sedang berjalan. Jika Anda memiliki aplikasi yang
terkontainerisasi dan ingin melakukan perubahan, maka Anda perlu membuat
kontainer baru dengan menyertakan perubahannya, kemudian membuat ulang kontainer
dengan memulai dari <em>image</em> yang sudah diubah.</p><h2 id=kontainer-runtime>Kontainer <em>runtime</em></h2><p>Kontainer <em>runtime</em> adalah perangkat lunak yang bertanggung jawab untuk
menjalankan kontainer. Kubernetes mendukung beberapa kontainer <em>runtime</em>:
<a class=glossary-tooltip title='Docker merupakan suatu teknologi perangkat lunak yang menyediakan virtualisasi pada level sistem operasi yang juga dikenal sebagai Container.' data-toggle=tooltip data-placement=top href=https://docs.docker.com/engine/ target=_blank aria-label=Docker>Docker</a>,
<a class=glossary-tooltip title='A container runtime with an emphasis on simplicity, robustness and portability' data-toggle=tooltip data-placement=top href=https://containerd.io/docs/ target=_blank aria-label=containerd>containerd</a>,
<a class=glossary-tooltip title='A lightweight container runtime specifically for Kubernetes' data-toggle=tooltip data-placement=top href=https://cri-o.io/#what-is-cri-o target=_blank aria-label=CRI-O>CRI-O</a>, dan semua implementasi dari
<a href=https://github.com/kubernetes/community/blob/master/contributors/devel/sig-node/container-runtime-interface.md>Kubernetes CRI (Container Runtime Interface)</a>.</p><h2 id=selanjutnya>Selanjutnya</h2><ul><li>Baca tentang <a href=https://kubernetes.io/docs/concepts/containers/images/>image-image kontainer</a></li><li>Baca tentang <a href=https://kubernetes.io/docs/concepts/workloads/pods/>Pod</a></li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-16042b4652ad19e565c7263824029a43>3.2 - Image</h1><p>Kamu membuat Docker <em>image</em> dan mengunduhnya ke sebuah registri sebelum digunakan di dalam Kubernetes Pod.</p><p>Properti <code>image</code> dari sebuah Container mendukung sintaksis yang sama seperti perintah <code>docker</code>, termasuk registri privat dan <em>tag</em>.</p><h2 id=memperbarui-image>Memperbarui Image</h2><p>Kebijakan <em>pull default</em> adalah <code>IfNotPresent</code> yang membuat Kubelet tidak
lagi mengunduh (<em>pull</em>) sebuah image jika sudah ada terlebih dahulu. Jika kamu ingin agar
selalu diunduh, kamu bisa melakukan salah satu dari berikut:</p><ul><li>mengatur <code>imagePullPolicy</code> dari Container menjadi <code>Always</code>.</li><li>buang <code>imagePullPolicy</code> dan gunakan <code>:latest</code> <em>tag</em> untuk <em>image</em> yang digunakan.</li><li>buang <code>imagePullPolicy</code> dan juga <em>tag</em> untuk <em>image</em>.</li><li>aktifkan <a href=/docs/reference/access-authn-authz/admission-controllers/#alwayspullimages>AlwaysPullImages</a> <em>admission controller</em>.</li></ul><p>Harap diingat kamu sebaiknya hindari penggunaan <em>tag</em> <code>:latest</code>, lihat <a href=/id/docs/concepts/configuration/overview/#container-images>panduan konfigurasi</a> untuk informasi lebih lanjut.</p><h2 id=membuat-image-multi-arsitektur-dengan-manifest>Membuat Image Multi-arsitektur dengan Manifest</h2><p>Docker CLI saat ini mendukung perintah <code>docker manifest</code> dengan anak perintah <code>create</code>, <code>annotate</code>, dan <code>push</code>. Perintah-perintah ini dapat digunakan
untuk membuat (<em>build</em>) dan mengunggah (<em>push</em>) manifes. Kamu dapat menggunakan perintah <code>docker manifest inspect</code> untuk membaca manifes.</p><p>Lihat dokumentasi docker di sini:
<a href=https://docs.docker.com/edge/engine/reference/commandline/manifest/>https://docs.docker.com/edge/engine/reference/commandline/manifest/</a></p><p>Lihat contoh-contoh bagaimana kami menggunakan ini untuk proses <em>build harness</em>:
<a href="https://cs.k8s.io/?q=docker%20manifest%20(create%7Cpush%7Cannotate)&i=nope&files=&repos=">https://cs.k8s.io/?q=docker%20manifest%20(create%7Cpush%7Cannotate)&i=nope&files=&repos=</a></p><p>Perintah-perintah ini bergantung pada Docker CLI, dan diimplementasi hanya di sisi CLI. Kamu harus mengubah <code>$HOME/.docker/config.json</code> dan mengatur <em>key</em> <code>experimental</code> untuk mengaktifkan
atau cukup dengan mengatur <code>DOCKER_CLI_EXPERIMENTAL</code> variabel <em>environment</em> menjadi <code>enabled</code> ketika memanggil perintah-perintah CLI.</p><div class="alert alert-info note callout" role=alert><strong>Catatan:</strong> Gunakan Docker <em>18.06 ke atas</em>, versi-versi di bawahnya memiliki <em>bug</em> ataupun tidak mendukung perintah eksperimental. Contohnya <a href=https://github.com/docker/cli/issues/1135>https://github.com/docker/cli/issues/1135</a> yang menyebabkan masalah di bawah containerd.</div><p>Kalau kamu terkena masalah ketika mengunggah manifes-manifes yang rusak, cukup bersihkan manifes-manifes yang lama di <code>$HOME/.docker/manifests</code> untuk memulai dari awal.</p><p>Untuk Kubernetes, kami biasanya menggunakan <em>image-image</em> dengan sufiks <code>-$(ARCH)</code>. Untuk kompatibilitas (<em>backward compatibility</em>), lakukan <em>generate image-image</em> yang lama dengan sufiks. Idenya adalah men-<em>generate</em>, misalnya <code>pause</code> image yang memiliki manifes untuk semua arsitektur dan misalnya <code>pause-amd64</code> yang punya kompatibilitas terhadap konfigurasi-konfigurasi lama atau berkas-berkas YAML yang bisa saja punya <em>image-image</em> bersufiks yang di-<em>hardcode</em>.</p><h2 id=menggunakan-registri-privat>Menggunakan Registri Privat (<em>Private Registry</em>)</h2><p>Biasanya kita memerlukan <em>key</em> untuk membaca <em>image-image</em> yang tersedia pada suatu registri privat.
Kredensial ini dapat disediakan melalui beberapa cara:</p><ul><li>Menggunakan Google Container Registry<ul><li>per-klaster</li><li>konfigurasi secara otomatis pada Google Compute Engine atau Google Kubernetes Engine</li><li>semua Pod dapat membaca registri privat yang ada di dalam proyek</li></ul></li><li>Menggunakan Amazon Elastic Container Registry (ECR)<ul><li>menggunakan IAM <em>role</em> dan <em>policy</em> untuk mengontrol akses ke repositori ECR</li><li>secara otomatis <em>refresh</em> kredensial login ECR</li></ul></li><li>Menggunakan Oracle Cloud Infrastructure Registry (OCIR)<ul><li>menggunakan IAM <em>role</em> dan <em>policy</em> untuk mengontrol akses ke repositori OCIR</li></ul></li><li>Menggunakan Azure Container Registry (ACR)</li><li>Menggunakan IBM Cloud Container Registry<ul><li>menggunakan IAM <em>role</em> dan <em>policy</em> untuk memberikan akses ke IBM Cloud Container Registry</li></ul></li><li>Konfigurasi Node untuk otentikasi registri privat<ul><li>semua Pod dapat membaca registri privat manapun</li><li>memerlukan konfigurasi Node oleh admin klaster</li></ul></li><li>Pra-unduh <em>image</em><ul><li>semua Pod dapat menggunakan <em>image</em> apapun yang di-<em>cached</em> di dalam sebuah Node</li><li>memerlukan akses root ke dalam semua Node untuk pengaturannya</li></ul></li><li>Mengatur ImagePullSecrets dalam sebuah Pod<ul><li>hanya Pod-Pod yang menyediakan <em>key</em> sendiri yang dapat mengakses registri privat</li></ul></li></ul><p>Masing-masing opsi dijelaskan lebih lanjut di bawah ini.</p><h3 id=menggunakan-google-container-registry>Menggunakan Google Container Registry</h3><p>Kubernetes memiliki dukungan <em>native</em> untuk <a href=https://cloud.google.com/tools/container-registry/>Google Container
Registry (GCR)</a>, ketika dijalankan pada
Google Compute Engine (GCE). Jika kamu menjalankan klaster pada GCE atau Google Kubernetes Engine,
cukup gunakan nama panjang <em>image</em> (misalnya gcr.io/my_project/image:tag).</p><p>Semua Pod di dalam klaster akan memiliki akses baca <em>image</em> di registri ini.</p><p>Kubelet akan melakukan otentikasi GCR menggunakan <em>service account</em> yang dimiliki
<em>instance</em> Google. <em>Service acccount</em> pada <em>instance</em> akan memiliki sebuah <code>https://www.googleapis.com/auth/devstorage.read_only</code>,
sehingga dapat mengunduh dari GCR di proyek yang sama, tapi tidak untuk unggah.</p><h3 id=menggunakan-amazon-elastic-container-registry>Menggunakan Amazon Elastic Container Registry</h3><p>Kubernetes memiliki dukungan <em>native</em> untuk <a href=https://aws.amazon.com/ecr/>Amazon Elastic Container Registry</a>, ketika Node adalah
AWS EC2 <em>instance</em>.</p><p>Cukup gunakan nama panjang <em>image</em> (misalnya <code>ACCOUNT.dkr.ecr.REGION.amazonaws.com/imagename:tag</code>) di dalam definisi Pod.</p><p>Semua pengguna klaster yang dapat membuat Pod akan bisa menjalankan Pod yang dapat menggunakan
<em>image-image</em> di dalam registri ECR.</p><p>Kubelet akan mengambil dan secara periodik memperbarui kredensial ECR, yang memerlukan <em>permission</em> sebagai berikut:</p><ul><li><code>ecr:GetAuthorizationToken</code></li><li><code>ecr:BatchCheckLayerAvailability</code></li><li><code>ecr:GetDownloadUrlForLayer</code></li><li><code>ecr:GetRepositoryPolicy</code></li><li><code>ecr:DescribeRepositories</code></li><li><code>ecr:ListImages</code></li><li><code>ecr:BatchGetImage</code></li></ul><p>Persyaratan:</p><ul><li>Kamu harus menggunakan versi kubelet <code>v1.2.0</code> atau lebih (misal jalankan <code>/usr/bin/kubelet --version=true</code>).</li><li>Jika Node yang kamu miliki ada di region A dan registri kamu ada di region yang berbeda misalnya B, kamu perlu versi <code>v1.3.0</code> atau lebih.</li><li>ECR harus tersedia di region kamu.</li></ul><p>Cara <em>troubleshoot</em>:</p><ul><li>Verifikasi semua persyaratan di atas.</li><li>Dapatkan kredensial $REGION (misalnya <code>us-west-2</code>) pada <em>workstation</em> kamu. Lakukan SSH ke dalam <em>host</em> dan jalankan Docker secara manual menggunakan kredensial tersebut. Apakah berhasil?</li><li>Tambahkan verbositas level <em>log</em> kubelet paling tidak 3 dan periksa <em>log</em> kubelet (misal <code>journalctl -u kubelet</code>) di baris-baris yang seperti ini:<ul><li><code>aws_credentials.go:109] unable to get ECR credentials from cache, checking ECR API</code></li><li><code>aws_credentials.go:116] Got ECR credentials from ECR API for &lt;AWS account ID for ECR>.dkr.ecr.&lt;AWS region>.amazonaws.com</code></li></ul></li></ul><h3 id=menggunakan-azure-container-registry-acr>Menggunakan Azure Container Registry (ACR)</h3><p>Ketika menggunakan <a href=https://azure.microsoft.com/en-us/services/container-registry/>Azure Container Registry</a>
kamu dapat melakukan otentikasi menggunakan pengguna admin maupun sebuah <em>service principal</em>.
Untuk keduanya, otentikasi dilakukan melalui proses otentikasi Docker standar. Instruksi-instruksi ini
menggunakan perangkat <a href=https://github.com/azure/azure-cli>azure-cli</a>.</p><p>Kamu pertama perlu membuat sebuah registri dan men-<em>generate</em> kredensial, dokumentasi yang lengkap tentang hal ini
dapat dilihat pada <a href=https://docs.microsoft.com/en-us/azure/container-registry/container-registry-get-started-azure-cli>dokumentasi Azure container registry</a>.</p><p>Setelah kamu membuat registri, kamu akan menggunakan kredensial berikut untuk login:</p><ul><li><code>DOCKER_USER</code> : <em>service principal</em>, atau pengguna admin</li><li><code>DOCKER_PASSWORD</code>: kata sandi dari <em>service principal</em>, atau kata sandi dari pengguna admin</li><li><code>DOCKER_REGISTRY_SERVER</code>: <code>${some-registry-name}.azurecr.io</code></li><li><code>DOCKER_EMAIL</code>: <code>${some-email-address}</code></li></ul><p>Ketika kamu sudah memiliki variabel-variabel di atas, kamu dapat
<a href=/id/docs/concepts/containers/images/#specifying-imagepullsecrets-on-a-pod>mengkonfigurasi sebuah Kubernetes Secret dan menggunakannya untuk <em>deploy</em> sebuah Pod</a>.</p><h3 id=menggunakan-ibm-cloud-container-registry>Menggunakan IBM Cloud Container Registry</h3><p>IBM Cloud Container Registry menyediakan sebuah registri <em>image</em> privat yang <em>multi-tenant</em>, dapat kamu gunakan untuk menyimpan dan membagikan <em>image-image</em> secara aman. Secara <em>default</em>, <em>image-image</em> di dalam registri privat kamu akan dipindai (<em>scan</em>) oleh Vulnerability Advisor terintegrasi untuk deteksi isu
keamanan dan kerentanan (<em>vulnerability</em>) yang berpotensi. Para pengguna di dalam akun IBM Cloud kamu dapat mengakses <em>image</em>, atau kamu dapat menggunakan IAM
<em>role</em> dan <em>policy</em> untuk memberikan akses ke <em>namespace</em> di IBM Cloud Container Registry.</p><p>Untuk instalasi <em>plugin</em> CLI di IBM Cloud Containerr Registry dan membuat sebuah <em>namespace</em> untuk <em>image-image</em> kamu, lihat <a href="https://cloud.ibm.com/docs/Registry?topic=registry-getting-started">Mulai dengan IBM Cloud Container Registry</a>.</p><p>Jika kamu menggunakan akun dan wilayah (<em>region</em>) yang sama, kamu dapat melakukan <em>deploy image-image</em> yang disimpan di dalam IBM Cloud Container Registry
ke dalam <em>namespace default</em> dari klaster IBM Cloud Kubernetes Service yang kamu miliki tanpa konfigurasi tambahan, lihat <a href="https://cloud.ibm.com/docs/containers?topic=containers-images">Membuat kontainer dari <em>image</em></a>. Untuk opsi konfigurasi lainnya, lihat <a href="https://cloud.ibm.com/docs/containers?topic=containers-registry#cluster_registry_auth">Bagaimana cara mengotorasi klaster untuk mengunduh <em>image</em> dari sebuah registri</a>.</p><h3 id=konfigurasi-node-untuk-otentikasi-ke-sebuah-registri-privat>Konfigurasi Node untuk Otentikasi ke sebuah Registri Privat</h3><div class="alert alert-info note callout" role=alert><strong>Catatan:</strong> Jika kamu jalan di Google Kubernetes Engine, akan ada <code>.dockercfg</code> pada setiap Node dengan kredensial untuk Google Container Registry. Kamu tidak bisa menggunakan cara ini.</div><div class="alert alert-info note callout" role=alert><strong>Catatan:</strong> Jika kamu jalan di AWS EC2 dan menggunakan EC2 Container Registry (ECR), kubelet pada setiap Node akan dapat
mengatur dan memperbarui kredensial login ECR. Kamu tidak bisa menggunakan cara ini.</div><div class="alert alert-info note callout" role=alert><strong>Catatan:</strong> Cara ini cocok jika kamu dapat mengontrol konfigurasi Node. Cara ini tidak akan bekerja dengan baik pada GCE,
dan penyedia layanan cloud lainnya yang tidak melakukan penggantian Node secara otomatis.</div><div class="alert alert-info note callout" role=alert><strong>Catatan:</strong> Kubernetes pada saat ini hanya mendukung bagian <code>auths</code> dan <code>HttpHeaders</code> dari konfigurasi docker. Hal ini berarti bantuan kredensial (<code>credHelpers</code> atau <code>credsStore</code>) tidak didukung.</div><p>Docker menyimpan <em>key</em> untuk registri privat pada <code>$HOME/.dockercfg</code> atau berkas <code>$HOME/.docker/config.json</code>. Jika kamu menempatkan berkas yang sama
pada daftar jalur pencarian (<em>search path</em>) berikut, kubelet menggunakannya sebagai penyedia kredensial saat mengunduh <em>image</em>.</p><ul><li><code>{--root-dir:-/var/lib/kubelet}/config.json</code></li><li><code>{cwd of kubelet}/config.json</code></li><li><code>${HOME}/.docker/config.json</code></li><li><code>/.docker/config.json</code></li><li><code>{--root-dir:-/var/lib/kubelet}/.dockercfg</code></li><li><code>{cwd of kubelet}/.dockercfg</code></li><li><code>${HOME}/.dockercfg</code></li><li><code>/.dockercfg</code></li></ul><div class="alert alert-info note callout" role=alert><strong>Catatan:</strong> Kamu mungkin harus mengatur <code>HOME=/root</code> secara eksplisit pada berkas <em>environment</em> kamu untuk kubelet.</div><p>Berikut langkah-langkah yang direkomendasikan untuk mengkonfigurasi Node kamu supaya bisa menggunakan registri privat.
Pada contoh ini, coba jalankan pada <em>desktop/laptop</em> kamu:</p><ol><li>Jalankan <code>docker login [server]</code> untuk setiap set kredensial yang ingin kamu gunakan. Ini akan memperbarui <code>$HOME/.docker/config.json</code>.</li><li>Lihat <code>$HOME/.docker/config.json</code> menggunakan <em>editor</em> untuk memastikan sudah berisi kredensial yang ingin kamu gunakan.</li><li>Dapatkan daftar Node, contohnya:<ul><li>jika kamu ingin mendapatkan nama: <code>nodes=$(kubectl get nodes -o jsonpath='{range.items[*].metadata}{.name} {end}')</code></li><li>jika kamu ingin mendapatkan IP: <code>nodes=$(kubectl get nodes -o jsonpath='{range .items[*].status.addresses[?(@.type=="ExternalIP")]}{.address} {end}')</code></li></ul></li><li>Salin <code>.docker/config.json</code> yang ada di lokal kamu pada salah satu jalur pencarian di atas.<ul><li>contohnya: <code>for n in $nodes; do scp ~/.docker/config.json root@$n:/var/lib/kubelet/config.json; done</code></li></ul></li></ol><p>Verifikasi dengana membuat sebuah Pod yanag menggunakan <em>image</em> privat, contohnya:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl apply -f - <span style=color:#b44>&lt;&lt;EOF
</span></span></span><span style=display:flex><span><span style=color:#b44>apiVersion: v1
</span></span></span><span style=display:flex><span><span style=color:#b44>kind: Pod
</span></span></span><span style=display:flex><span><span style=color:#b44>metadata:
</span></span></span><span style=display:flex><span><span style=color:#b44>  name: private-image-test-1
</span></span></span><span style=display:flex><span><span style=color:#b44>spec:
</span></span></span><span style=display:flex><span><span style=color:#b44>  containers:
</span></span></span><span style=display:flex><span><span style=color:#b44>    - name: uses-private-image
</span></span></span><span style=display:flex><span><span style=color:#b44>      image: $PRIVATE_IMAGE_NAME
</span></span></span><span style=display:flex><span><span style=color:#b44>      imagePullPolicy: Always
</span></span></span><span style=display:flex><span><span style=color:#b44>      command: [ &#34;echo&#34;, &#34;SUCCESS&#34; ]
</span></span></span><span style=display:flex><span><span style=color:#b44>EOF</span>
</span></span></code></pre></div><pre tabindex=0><code>pod/private-image-test-1 created
</code></pre><p>Jika semuanya berjalan dengan baik, maka setelah beberapa lama, kamu dapat menjalankan:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl logs private-image-test-1
</span></span></code></pre></div><p>dan lihat pada keluaran perintah:</p><pre tabindex=0><code>SUCCESS
</code></pre><p>Jika kamu mencurigai ada perintah yang gagal, kamu dapat menjalankan:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl describe pods/private-image-test-1 | grep <span style=color:#b44>&#39;Failed&#39;</span>
</span></span></code></pre></div><p>Pada kasus gagal, keluarannya mirip seperti:</p><pre tabindex=0><code>  Fri, 26 Jun 2015 15:36:13 -0700    Fri, 26 Jun 2015 15:39:13 -0700    19    {kubelet node-i2hq}    spec.containers{uses-private-image}    failed        Failed to pull image &#34;user/privaterepo:v1&#34;: Error: image user/privaterepo:v1 not found
</code></pre><p>Kamu harus memastikan semua Node di dalam klaster memiliki <code>.docker/config.json</code> yang sama. Jika tidak, Pod-Pod
akan jalan pada beberapa Node saja dan gagal di Node lainnya. Contohnya, jika kamu menggunakan Node <em>autoscaling</em>, maka
setiap templat <em>instance</em> perlu untuk mempunyai <code>.docker/config.json</code> atau <em>mount</em> sebuah penyimpanan yang berisi berkas tersebut.</p><p>Semua Pod memiliki akses baca (<em>read</em>) untuk <em>image-image</em> di registri privat manapun ketika
<em>key</em> registri privat ditambahkan pada <code>.docker/config.json</code>.</p><h3 id=image-pra-unduh><em>Image</em> Pra-unduh</h3><div class="alert alert-info note callout" role=alert><strong>Catatan:</strong> Jika kamu jalan di Google Kubernetes Engine, maka akan ada <code>.dockercfg</code> pada setiap Node dengan kredensial untuk Google Container Registry. Kamu dapat menggunakan cara ini.</div><div class="alert alert-info note callout" role=alert><strong>Catatan:</strong> Cara ini cocok jika kamu dapat mengontrol konfigurasi Node. Cara ini tidak akan
bisa berjalan dengan baik pada GCE, dan penyedia cloud lainnya yang tidak menggantikan
Node secara otomatis.</div><p>Secara <em>default</em>, kubelet akan mencoba untuk mengunduh setiap <em>image</em> dari registri yang dispesifikasikan.
Hanya saja, jika properti <code>imagePullPolicy</code> diatur menjadi <code>IfNotPresent</code> atau <code>Never</code>, maka
sebuah <em>image</em> lokal digunakan.</p><p>Jika kamu ingin memanfaatkan <em>image</em> pra-unduh sebagai pengganti untuk otentikasi registri,
kamu harus memastikan semua Node di dalam klaster memiliki <em>image</em> pra-unduh yang sama.</p><p>Cara ini bisa digunakan untuk memuat <em>image</em> tertentu untuk kecepatan atau sebagai alternatif untuk otentikasi untuk sebuah registri privat.</p><p>Semua Pod akan mendapatkan akses baca ke <em>image</em> pra-unduh manapun.</p><h3 id=tentukan-imagepullsecrets-pada-sebuah-pod>Tentukan ImagePullSecrets pada sebuah Pod</h3><div class="alert alert-info note callout" role=alert><strong>Catatan:</strong> Cara ini merupakan cara yang direkomendasikan saat ini untuk Google Kubernetes Engine, GCE, dan penyedia cloud lainnya yang
secara otomatis dapat membuat Node.</div><p>Kubernetes mendukung penentuan <em>key</em> registri pada sebuah Pod.</p><h4 id=membuat-sebuah-secret-dengan-docker-config>Membuat sebuah Secret dengan Docker Config</h4><p>Jalankan perintah berikut, ganti nilai huruf besar dengan yang tepat:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl create secret docker-registry &lt;name&gt; --docker-server<span style=color:#666>=</span>DOCKER_REGISTRY_SERVER --docker-username<span style=color:#666>=</span>DOCKER_USER --docker-password<span style=color:#666>=</span>DOCKER_PASSWORD --docker-email<span style=color:#666>=</span>DOCKER_EMAIL
</span></span></code></pre></div><p>Jika kamu sudah memiliki berkas kredensial Docker, daripada menggunakan perintah di atas,
kamu dapat mengimpor berkas kredensial sebagai Kubernetes Secret.
<a href=/id/docs/tasks/configure-pod-container/pull-image-private-registry/#registry-secret-existing-credentials>Membuat sebuah Secret berbasiskan pada kredensial Docker yang sudah ada</a> menjelaskan bagaimana mengatur ini.
Cara ini berguna khususnya jika kamu menggunakan beberapa registri kontainer privat,
perintah <code>kubectl create secret docker-registry</code> akan membuat sebuah Secret yang akan
hanya bekerja menggunakan satu registri privat.</p><div class="alert alert-info note callout" role=alert><strong>Catatan:</strong> Pod-Pod hanya dapat mengacu pada imagePullSecrets di dalam <em>namespace</em>,
sehingga proses ini perlu untuk diselesaikan satu kali setiap <em>namespace</em>.</div><h4 id=mengacu-pada-imagepullsecrets-di-dalam-sebuah-pod>Mengacu pada imagePullSecrets di dalam sebuah Pod</h4><p>Sekarang, kamu dapat membuat Pod yang mengacu pada Secret dengan menambahkan bagian <code>imagePullSecrets</code>
untuk sebuah definisi Pod.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>cat <span style=color:#b44>&lt;&lt;EOF &gt; pod.yaml
</span></span></span><span style=display:flex><span><span style=color:#b44>apiVersion: v1
</span></span></span><span style=display:flex><span><span style=color:#b44>kind: Pod
</span></span></span><span style=display:flex><span><span style=color:#b44>metadata:
</span></span></span><span style=display:flex><span><span style=color:#b44>  name: foo
</span></span></span><span style=display:flex><span><span style=color:#b44>  namespace: awesomeapps
</span></span></span><span style=display:flex><span><span style=color:#b44>spec:
</span></span></span><span style=display:flex><span><span style=color:#b44>  containers:
</span></span></span><span style=display:flex><span><span style=color:#b44>    - name: foo
</span></span></span><span style=display:flex><span><span style=color:#b44>      image: janedoe/awesomeapp:v1
</span></span></span><span style=display:flex><span><span style=color:#b44>  imagePullSecrets:
</span></span></span><span style=display:flex><span><span style=color:#b44>    - name: myregistrykey
</span></span></span><span style=display:flex><span><span style=color:#b44>EOF</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>cat <span style=color:#b44>&lt;&lt;EOF &gt;&gt; ./kustomization.yaml
</span></span></span><span style=display:flex><span><span style=color:#b44>resources:
</span></span></span><span style=display:flex><span><span style=color:#b44>- pod.yaml
</span></span></span><span style=display:flex><span><span style=color:#b44>EOF</span>
</span></span></code></pre></div><p>Cara ini perlu untuk diselesaikan untuk setiap Pod yang mengguunakan registri privat.</p><p>Hanya saja, mengatur <em>field</em> ini dapat diotomasi dengan mengatur imagePullSecrets di dalam
sumber daya <a href=/docs/user-guide/service-accounts>serviceAccount</a>.
Periksa <a href=/id/docs/tasks/configure-pod-container/configure-service-account/#add-imagepullsecrets-to-a-service-account>Tambahan ImagePullSecrets untuk sebuah Service Account</a> untuk instruksi yang lebih detail.</p><p>Kamu dapat menggunakan cara ini bersama <code>.docker/config.json</code> pada setiap Node. Kredensial-kredensial
akan dapat di-<em>merged</em>. Cara ini akan dapat bekerja pada Google Kubernetes Engine.</p><h3 id=kasus-kasus-penggunaan-use-case>Kasus-Kasus Penggunaan (<em>Use Case</em>)</h3><p>Ada beberapa solusi untuk konfigurasi registri privat. Berikut beberapa kasus penggunaan
dan solusi yang disarankan.</p><ol><li>Klaster yang hanya menjalankan <em>image non-proprietary</em> (misalnya open-source). Tidak perlu unutuk menyembunyikan <em>image</em>.<ul><li>Gunakan <em>image</em> publik pada Docker hub.<ul><li>Tidak ada konfigurasi yang diperlukan.</li><li>Pada GCE/Google Kubernetes Engine, sebuah <em>mirror</em> lokal digunakan secara otomatis untuk meningkatkan kecepatan dan ketersediaan.</li></ul></li></ul></li><li>Klaster yang menjalankan <em>image proprietary</em> yang seharusnya disembunyikan dari luar perusahaan, tetapi bisa terlihat oleh pengguna klaster.<ul><li>Gunakan sebuah privat <a href=https://docs.docker.com/registry/>registri Docker</a> yang <em>hosted</em>.<ul><li>Bisa saja di-<em>host</em> pada <a href=https://hub.docker.com/signup>Docker Hub</a>, atau lainnya.</li><li>Konfigurasi <code>.docker/config.json</code> secara manual pada setiap Node seperti dijelaskan di atas.</li></ul></li><li>Atau, jalankan sebuah registri privat internal di belakang <em>firewall</em> kamu dengan akses baca terbuka.<ul><li>Tidak ada konfigurasi Kubernetes yang diperlukan.</li></ul></li><li>Atau, ketika pada GCE/Google Kubernetes Engine, menggunakan Google Container Registry yang ada di proyek.<ul><li>Hal ini bisa bekerja baik dengan <em>autoscaling</em> klaster dibandingkan konfigurasi Node manual.</li></ul></li><li>Atau, pada sebuah klaster dimana mengubah konfigurasi Node tidak nyaman, gunakan <code>imagePullSecrets</code>.</li></ul></li><li>Klaster dengan <em>image proprietary</em>, beberapa memerlukan akses kontrol yang lebih ketat.<ul><li>Pastikan <a href=/docs/reference/access-authn-authz/admission-controllers/#alwayspullimages>AlwaysPullImages <em>admission controller</em></a> aktif. Sebaliknya, semua Pod berpotensi memiliki akses ke semua <em>image</em>.</li><li>Pindahkan data sensitif pada sumber daya "Secret", daripada mengemasnya menjadi sebuah <em>image</em>.</li></ul></li><li>Sebuah klaster <em>multi-tenant</em> dimana setiap <em>tenant</em> memerlukan registri privatnya masing-masing.<ul><li>Pastikan <a href=/docs/reference/access-authn-authz/admission-controllers/#alwayspullimages>AlwaysPullImages <em>admission controller</em></a> aktif. Sebaliknya, semua Pod dari semua tenant berpotensi memiliki akses pada semua <em>image</em>.</li><li>Jalankan sebuah registri privat dimana otorisasi diperlukan.</li><li>Men-<em>generate</em> kredensial registri uuntuk setiap <em>tenant</em>, masukkan ke dalam <em>secret</em> uuntuk setiap <em>namespace tenant</em>.</li><li><em>Tenant</em> menambahkan <em>secret</em> pada imagePullSecrets uuntuk setiap <em>namespace</em>.</li></ul></li></ol><p>Jika kamu memiliki akses pada beberapa registri, kamu dapat membuat satu <em>secret</em> untuk setiap registri.
Kubelet akan melakukan <em>merge</em> <code>imagePullSecrets</code> manapun menjadi sebuah virtual <code>.docker/config.json</code>.</p></div><div class=td-content style=page-break-before:always><h1 id=pg-643212488f778acf04bebed65ba34441>3.3 - Kontainer Environment</h1><p>Laman ini menjelaskan berbagai <em>resource</em> yang tersedia di dalam Kontainer pada suatu <em>environment</em>.</p><h2 id=environment-kontainer><em>Environment</em> Kontainer</h2><p><em>Environment</em> Kontainer pada Kubernetes menyediakan beberapa <em>resource</em> penting yang tersedia di dalam Kontainer:</p><ul><li>Sebuah <em>Filesystem</em>, yang merupakan kombinasi antara <a href=/id/docs/concepts/containers/images/>image</a> dan satu atau banyak <a href=/id/docs/concepts/storage/volumes/><em>volumes</em></a>.</li><li>Informasi tentang Kontainer tersebut.</li><li>Informasi tentang objek-objek lain di dalam klaster.</li></ul><h3 id=informasi-tentang-kontainer>Informasi tentang Kontainer</h3><p><em>Hostname</em> sebuah Kontainer merupakan nama dari Pod dimana Kontainer dijalankan.
Informasi ini tersedia melalui perintah <code>hostname</code> atau panggilan (<em>function call</em>)
<a href=http://man7.org/linux/man-pages/man2/gethostname.2.html><code>gethostname</code></a> pada <code>libc</code>.</p><p>Nama Pod dan <em>namespace</em> tersedia sebagai variabel <em>environment</em> melalui <a href=/docs/tasks/inject-data-application/downward-api-volume-expose-pod-information/>API <em>downward</em></a>.</p><p>Variabel <em>environment</em> yang ditulis pengguna dalam Pod <em>definition</em> juga tersedia di dalam Kontainer,
seperti halnya variabel <em>environment</em> yang ditentukan secara statis di dalam <em>image</em> Docker.</p><h3 id=informasi-tentang-klaster>Informasi tentang Klaster</h3><p>Daftar semua <em>Service</em> yang dijalankan ketika suatu Kontainer dibuat, tersedia di dalam Kontainer tersebut sebagai variabel <em>environment</em>.
Variabel-variabel <em>environment</em> tersebut sesuai dengan sintaksis <em>links</em> dari Docker.</p><p>Untuk suatu <em>Service</em> bernama <em>foo</em> yang terkait dengan Kontainer bernama <em>bar</em>,
variabel-variabel di bawah ini tersedia:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span><span style=color:#b8860b>FOO_SERVICE_HOST</span><span style=color:#666>=</span>&lt;host dimana service dijalankan&gt;
</span></span><span style=display:flex><span><span style=color:#b8860b>FOO_SERVICE_PORT</span><span style=color:#666>=</span>&lt;port dimana service dijalankan&gt;
</span></span></code></pre></div><p>Semua <em>Service</em> memiliki alamat-alamat IP yang bisa didapatkan di dalam Kontainer melalui DNS,
jika <a href=http://releases.k8s.io/main/cluster/addons/dns/><em>addon</em> DNS</a> diaktifkan. </p><h2 id=selanjutnya>Selanjutnya</h2><ul><li>Pelajari lebih lanjut tentang <a href=/id/docs/concepts/containers/container-lifecycle-hooks/>berbagai <em>hook</em> pada <em>lifecycle</em> Kontainer</a>.</li><li>Dapatkan pengalaman praktis soal
<a href=/docs/tasks/configure-pod-container/attach-handler-lifecycle-event/>memberikan <em>handler</em> untuk <em>event</em> dari <em>lifecycle</em> Kontainer</a>.</li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-a858027489648786a3b16264e451272b>3.4 - Runtime Class</h1><div style=margin-top:10px;margin-bottom:10px><b>FEATURE STATE:</b> <code>Kubernetes v1.14 [beta]</code></div><p>Laman ini menjelaskan tentang <em>resource</em> RuntimeClass dan proses pemilihan <em>runtime</em>.</p><div class="alert alert-danger warning callout" role=alert><strong>Peringatan:</strong> RuntimeClass memiliki <em>breaking change</em> untuk pembaruan ke beta pada v1.14. Jika kamu menggunakan
RuntimeClass sebelum v1.14, lihat <a href=#memperbarui-runtimeclass-dari-alpha-ke-beta>Memperbarui RuntimeClass dari Alpha ke Beta</a>.</div><h2 id=runtime-class><code>Runtime Class</code></h2><p>RuntimeClass merupakan sebuah fitur untuk memilih konfigurasi <em>runtime</em> kontainer. Konfigurasi
tersebut digunakan untuk menjalankan kontainer-kontainer milik suatu Pod.</p><h3 id=persiapan>Persiapan</h3><p>Pastikan gerbang fitur (<em>feature gate</em>) <code>RuntimeClass</code> sudah aktif (secara <em>default</em> sudah aktif).
Lihat <a href=/docs/reference/command-line-tools-reference/feature-gates/>Gerbang Fitur</a> untuk lebih
jelasnya soal pengaktifan gerbang fitur.
Gerbang fitur RuntimeClass ini harus aktif pada semua apiserver dan kubelet.</p><ol><li>Lakukan konfigurasi pada implementasi CRI untuk setiap <em>node</em> (tergantung <em>runtime</em> yang dipilih)</li><li>Buat <em>resource</em> RuntimeClass yang terkait</li></ol><h4 id=1-lakukan-konfigurasi-pada-implementasi-cri-untuk-setiap-node>1. Lakukan konfigurasi pada implementasi CRI untuk setiap <em>node</em></h4><p>Pilihan konfigurasi yang tersedia melalui RuntimeClass tergantung pada implementasi
<em>Container Runtime Interface</em> (CRI). Lihat bagian (<a href=#konfigurasi-cri>di bawah ini</a>)
soal bagaimana melakukan konfigurasi untuk implementasi CRI yang kamu miliki.</p><div class="alert alert-info note callout" role=alert><strong>Catatan:</strong> Untuk saat ini, RuntimeClass berasumsi bahwa semua <em>node</em> di dalam klaster punya
konfigurasi yang sama (homogen). Jika ada <em>node</em> yang punya konfigurasi berbeda dari
yang lain (heterogen), maka perbedaan ini harus diatur secara independen di luar RuntimeClass
melalui fitur <em>scheduling</em> (lihat <a href=/id/docs/concepts/scheduling-eviction/assign-pod-node/>Menempatkan Pod pada Node</a>).</div><p>Seluruh konfigurasi memiliki nama <code>handler</code> yang terkait, dijadikan referensi oleh RuntimeClass.
Nama <em>handler</em> harus berupa valid label 1123 DNS (alfanumerik + karakter <code>-</code>).</p><h4 id=2-buat-resource-runtimeclass-yang-terkait>2. Buat <em>resource</em> <code>RuntimeClass</code> yang terkait</h4><p>Masing-masing konfigurasi pada langkah no.1 punya nama <code>handler</code> yang merepresentasikan
konfigurasi-konfigurasi tersebut. Untuk masing-masing <code>handler</code>, buatlah sebuah objek RuntimeClass terkait.</p><p><em>Resource</em> RuntimeClass saat ini hanya memiliki 2 <em>field</em> yang penting: nama RuntimeClass tersebut
(<code>metadata.name</code>) dan <em>handler</em> (<code>handler</code>). Definisi objek tersebut terlihat seperti ini:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>node.k8s.io/v1beta1 <span style=color:#bbb> </span><span style=color:#080;font-style:italic># RuntimeClass didefinisikan pada grup API node.k8s.io</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>RuntimeClass<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>myclass <span style=color:#bbb> </span><span style=color:#080;font-style:italic># Nama dari RuntimeClass yang nantinya akan dijadikan referensi</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:#080;font-style:italic># RuntimeClass merupakan resource tanpa namespace</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>handler</span>:<span style=color:#bbb> </span>myconfiguration <span style=color:#bbb> </span><span style=color:#080;font-style:italic># Nama dari konfigurasi CRI terkait</span><span style=color:#bbb>
</span></span></span></code></pre></div><div class="alert alert-info note callout" role=alert><strong>Catatan:</strong> Sangat disarankan untuk hanya memperbolehkan admin klaster melakukan operasi
<em>write</em> pada RuntimeClass. Biasanya ini sudah jadi <em>default</em>. Lihat <a href=/docs/reference/access-authn-authz/authorization/>Ikhtisar
Autorisasi</a> untuk penjelasan lebih jauh.</div><h3 id=penggunaan>Penggunaan</h3><p>Ketika RuntimeClass sudah dikonfigurasi pada klaster, penggunaannya sangatlah mudah.
Kamu bisa tentukan <code>runtimeClassName</code> di dalam <code>spec</code> sebuah Pod, sebagai contoh:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>mypod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>runtimeClassName</span>:<span style=color:#bbb> </span>myclass<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:#080;font-style:italic># ...</span><span style=color:#bbb>
</span></span></span></code></pre></div><p>Kubelet akan mendapat instruksi untuk menggunakan RuntimeClass dengan nama yang sudah ditentukan tersebut
untuk menjalankan Pod ini. Jika RuntimeClass dengan nama tersebut tidak ditemukan, atau CRI tidak dapat
menjalankan <em>handler</em> yang terkait, maka Pod akan memasuki <a href=/id/docs/concepts/workloads/pods/pod-lifecycle/#pod-phase>tahap</a> <code>Failed</code>.
Lihat <a href=/docs/tasks/debug-application-cluster/debug-application-introspection/><em>event</em></a> untuk mengetahui pesan error yang terkait.</p><p>Jika tidak ada <code>runtimeClassName</code> yang ditentukan di dalam Pod, maka RuntimeHandler yang <em>default</em> akan digunakan.
Untuk kasus ini, perilaku klaster akan seperti saat fitur RuntimeClass dinonaktifkan.</p><h3 id=konfigurasi-cri>Konfigurasi CRI</h3><p>Lihat <a href=/docs/setup/cri/>instalasi CRI</a> untuk lebih detail mengenai pengaturan <em>runtime</em> CRI.</p><h4 id=dockershim>dockershim</h4><p><em>Built-in</em> dockershim CRI yang dimiliki Kubernetes tidak mendukung <em>handler runtime</em>.</p><h4 id=containerd-https-containerd-io><a href=https://containerd.io/>containerd</a></h4><p><em>Handler runtime</em> diatur melalui konfigurasi containerd pada <code>/etc/containerd/config.toml</code>.
<em>Handler</em> yang valid dapat dikonfigurasi pada bagian <em>runtime</em>:</p><pre tabindex=0><code>[plugins.&#34;io.containerd.grpc.v1.cri&#34;.containerd.runtimes.${HANDLER_NAME}]
</code></pre><p>Lihat dokumentasi konfigurasi containerd untuk lebih detail:
<a href=https://github.com/containerd/containerd/blob/main/docs/cri/config.md>https://github.com/containerd/containerd/blob/main/docs/cri/config.md</a></p><h4 id=cri-o-https-cri-o-io><a href=https://cri-o.io/>cri-o</a></h4><p><em>Handler runtime</em> dapat diatur menggunakan konfigurasi cri-o pada <code>/etc/crio/crio.conf</code>.
<em>Handler</em> yang valid dapat dikonfigurasi pada <a href=https://github.com/kubernetes-sigs/cri-o/blob/master/docs/crio.conf.5.md#crioruntime-table>tabel crio.runtime</a>:</p><pre tabindex=0><code>[crio.runtime.runtimes.${HANDLER_NAME}]
  runtime_path = &#34;${PATH_TO_BINARY}&#34;
</code></pre><p>Lihat dokumentasi konfigurasi cri-o untuk lebih detail:
<a href=https://github.com/kubernetes-sigs/cri-o/blob/master/cmd/crio/config.go>https://github.com/kubernetes-sigs/cri-o/blob/master/cmd/crio/config.go</a></p><h3 id=memperbarui-runtimeclass-dari-alpha-ke-beta>Memperbarui RuntimeClass dari Alpha ke Beta</h3><p>Fitur Beta pada RuntimeClass memiliki perubahan sebagai berikut:</p><ul><li>Grup API <em>resource</em> <code>node.k8s.io</code> dan <code>runtimeclasses.node.k8s.io</code> telah dimigrasi ke suatu
API <em>built-in</em> dari CustomResourceDefinition.</li><li>Atribut <code>spec</code> telah disederhakan pada definisi RuntimeClass (tidak ada lagi yang namanya
RuntimeClassSpec).</li><li><em>Field</em> <code>runtimeHandler</code> telah berubah nama menjadi <code>handler</code>.</li><li><em>Field</em> <code>handler</code> sekarang bersifat wajib untuk semua versi API. Artinya, <em>field</em> <code>runtimeHandler</code>
pada API Alpha juga bersifat wajib.</li><li><em>Field</em> <code>handler</code> haruslah berupa label DNS valid (<a href=https://tools.ietf.org/html/rfc1123>RFC 1123</a>),
yang artinya tidak bisa berisi karakter <code>.</code> (pada semua versi). <em>Handler</em> valid harus sesuai dengan
<em>regular expression</em> ini: <code>^[a-z0-9]([-a-z0-9]*[a-z0-9])?$</code>.</li></ul><p><strong>Tindakan yang diperlukan:</strong> Tindakan-tindaka berikut ini diperlukan untuk melakukan
pembaruan fitur RuntimeClass dari versi alpha ke versi beta:</p><ul><li><em>Resource</em> RuntimeClass harus dibuat ulang <strong>setelah</strong> diperbarui ke v.1.14, dan
CRD <code>runtimeclasses.node.k8s.io</code> harus dihapus secara manual:<pre tabindex=0><code>kubectl delete customresourcedefinitions.apiextensions.k8s.io runtimeclasses.node.k8s.io
</code></pre></li><li>Fitur Alpha pada RuntimeClass akan menjadi tidak valid, jika <code>runtimeHandler</code> tidak ditentukan atau
kosong atau menggunakan karakter <code>.</code> pada <em>handler</em>. Ini harus dimigrasi ke <em>handler</em> dengan
konfigurasi yang valid (lihat petunjuk di atas).</li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-e6941d969d81540208a3e78bc56f43bc>3.5 - Lifecyle Hook pada Kontainer</h1><p>Laman ini menjelaskan bagaimana semua Kontainer yang diatur kubelet menggunakan <em>framework lifecycle hook</em>
untuk menjalankan kode yang di-<em>trigger</em> oleh <em>event</em> selama <em>lifecycle</em> berlangsung.</p><h2 id=ikhtisar>Ikhtisar</h2><p>Kubernetes menyediakan <em>hook</em> untuk <em>lifecycle</em> Kontainer. Hal ini sejalan dengan <em>framework</em> bahasa
pemrograman pada umumnya yang memiliki <em>hook</em> untuk <em>lifecycle</em> komponen, seperti Angular contohnya.
<em>Hook</em> tersebut digunakan Kontainer untuk selalu siap menerima <em>event</em> selama <em>lifecycle</em> dan
menjalankan kode yang diimplementasi pada suatu <em>handler</em>, ketika <em>hook lifecycle</em> terkait telah dieksekusi.</p><h2 id=jenis-jenis-hook-pada-kontainer>Jenis-jenis <em>hook</em> pada Kontainer</h2><p>Ada dua jenis <em>hook</em> yang diekspos pada Kontainer:</p><p><code>PostStart</code></p><p><em>Hook</em> ini dijalankan segera setelah suatu kontainer dibuat.
Hanya saja, tidak ada jaminan bahwa <em>hook</em> akan tereksekusi sebelum <code>ENTRYPOINT</code> dari kontainer.
Tidak ada parameter yang diberikan pada <em>handler</em>.</p><p><code>PreStop</code></p><p><em>Hook</em> ini akan dipanggil sesaat sebelum kontainer dimatikan, karena suatu <em>request</em> API atau <em>event</em> pengaturan,
contohnya kegagalan pada <em>liveness probe</em>, <em>preemption</em>, perebutan <em>resource</em>, dan lainnya.
Sebuah panggilan untuk <em>hook</em> <code>PreStop</code> akan gagal jika kontainer tersebut telah ada pada <em>state terminate</em> atau <em>complete</em>.
Hal ini bersifat <em>blocking</em>, yang artinya panggilan bersifat sinkron (<em>synchronous</em>), harus menunggu eksekusi selesai, sebelum melakukan panggilan
untuk menghapus kontainer tersebut.
Tidak ada parameter yang diberikan pada <em>handler</em>.</p><p>Penjelasan yang lebih rinci tentang proses terminasi dapat dilihat pada <a href=/id/docs/concepts/workloads/pods/pod/#termination-of-pods>Terminasi Pod</a>.</p><h3 id=implementasi-handler-untuk-hook>Implementasi <em>handler</em> untuk <em>hook</em></h3><p>Kontainer dapat mengakses sebuah <em>hook</em> melalui implementasi dan registrasi sebuah <em>handler</em> untuk <em>hook</em> tersebut.
Ada dua jenis <em>handler</em> untuk <em>hook</em> yang dapat diimplementasikan untuk Kontainer:</p><ul><li>Exec - Mengeksekusi sebuah perintah tertentu, contohnya <code>pre-stop.sh</code>, di dalam cgroups dan <em>namespace</em> suatu Kontainer. <em>Resource</em> yang dikonsumsi oleh perintah tersebut dianggap sebagai bagian dari Kontainer.</li><li>HTTP - Mengeksekusi sebuah <em>request</em> HTTP untuk <em>endpoint</em> tertentu pada Kontainer tersebut.</li></ul><h3 id=eksekusi-handler-untuk-hook>Eksekusi <em>handler</em> untuk <em>hook</em></h3><p>Ketika manajemen <em>hook</em> untuk suatu <em>lifecycle</em> Kontainer dipanggil, sistem manajemen internal pada Kubernetes
akan mengeksekusi <em>handler</em> di dalam Kontainer yang terdaftar untuk <em>hook</em> tersebut.</p><p>Panggilan <em>handler</em> untuk <em>hook</em> semuanya bersifat <em>synchronous</em> di dalam konteks Pod yang
memiliki Kontainer tersebut. Artinya, untuk <em>hook</em> <code>PostStart</code>, Kontainer <code>ENTRYPOINT</code>
dan <em>hook</em> dieksekusi secara <em>asyncrhonous</em>. Akan tetapi, jika <em>hook</em> mengambil waktu terlalu lama,
atau <em>hang</em>, Kontainer tersebut tidak bisa sampai ke <em>state</em> <code>running</code>.</p><p>Perilaku ini mirip dengan yang terjadi pada <em>hook</em> <code>PreStop</code>.
Jika <em>hook</em> terlalu lama atau <em>hang</em> saat dieksekusi, Pod tersebut tetap ada pada <em>state</em> <code>Terminating</code>
dan akan dimatikan setelah <code>terminationGracePeriodSeconds</code> Pod selesai.
Jika sebuah <em>hook</em> <code>PostStart</code> atau <code>PreStop</code> gagal dieksekusi, Kontainer akan dimatikan.</p><p>Para pengguna sangat disarankan membuat <em>handler</em> untuk <em>hook</em> seringan mungkin (<em>lightweight</em>).
Biar bagaimanapun, ada beberapa kasus yang memang membutuhkan waktu lama untuk mengeksekusi
suatu perintah, misalnya saat proses penyimpanan <em>state</em> sebelum Kontainer dimatikan.</p><h3 id=jaminan-pengiriman-hook>Jaminan pengiriman <em>hook</em></h3><p>Proses pengiriman <em>hook</em> akan dilakukan <strong>paling tidak satu kali</strong>.
Artinya suatu <em>hook</em> boleh dipanggil beberapa kali untuk <em>event</em> yang sama,
seperti dalam <code>PostStart</code> atau<code>PreStop</code>.
Namun begitu, implementasi <em>hook</em> masing-masing harus memastikan bagaimana
menangani kasus ini dengan benar.</p><p>Pada umumnya, hanya terjadi satu proses pengiriman.
Jika misalnya sebuah penerima HTTP <em>hook</em> mati atau tidak bisa menerima trafik,
maka tidak ada usaha untuk mengirimkan kembali.
Namun demikian, bisa saja terjadi dua kali proses pengiriman untuk kasus tertentu.
Contohnya, jika kubelet <em>restart</em> saat di tengah proses pengiriman <em>hook</em>,
<em>hook</em> tersebut akan dikirimkan kembali saat kubelet sudah hidup kembali.</p><h3 id=melakukan-debug-handler-untuk-hook>Melakukan <em>debug</em> <em>handler</em> untuk <em>hook</em></h3><p><em>Log</em> untuk suatu <em>handler hook</em> tidak terekspos pada <em>event</em> Pod.
Jika <em>handler</em> gagal dieksekusi untuk alasan tertentu, <em>handler</em> akan melakukan <em>broadcast</em> sebuah <em>event</em>.
Untuk <code>PostStart</code>, akan dilakukan <em>broadcast event</em> <code>FailedPostStartHook</code>,
dan untuk <code>PreStop</code>, akan dilakukan <em>broadcast event</em> <code>FailedPreStopHook</code>.
Kamu dapat melihat <em>event-event</em> ini dengan menjalankan perintah <code>kubectl describe pod &lt;pod_name></code>.
Berikut merupakan contoh keluaran <em>event-event</em> setelah perintah tersebut dijalankan.</p><pre tabindex=0><code>Events:
  FirstSeen  LastSeen  Count  From                                                   SubobjectPath          Type      Reason               Message
  ---------  --------  -----  ----                                                   -------------          --------  ------               -------
  1m         1m        1      {default-scheduler }                                                          Normal    Scheduled            Successfully assigned test-1730497541-cq1d2 to gke-test-cluster-default-pool-a07e5d30-siqd
  1m         1m        1      {kubelet gke-test-cluster-default-pool-a07e5d30-siqd}  spec.containers{main}  Normal    Pulling              pulling image &#34;test:1.0&#34;
  1m         1m        1      {kubelet gke-test-cluster-default-pool-a07e5d30-siqd}  spec.containers{main}  Normal    Created              Created container with docker id 5c6a256a2567; Security:[seccomp=unconfined]
  1m         1m        1      {kubelet gke-test-cluster-default-pool-a07e5d30-siqd}  spec.containers{main}  Normal    Pulled               Successfully pulled image &#34;test:1.0&#34;
  1m         1m        1      {kubelet gke-test-cluster-default-pool-a07e5d30-siqd}  spec.containers{main}  Normal    Started              Started container with docker id 5c6a256a2567
  38s        38s       1      {kubelet gke-test-cluster-default-pool-a07e5d30-siqd}  spec.containers{main}  Normal    Killing              Killing container with docker id 5c6a256a2567: PostStart handler: Error executing in Docker Container: 1
  37s        37s       1      {kubelet gke-test-cluster-default-pool-a07e5d30-siqd}  spec.containers{main}  Normal    Killing              Killing container with docker id 8df9fdfd7054: PostStart handler: Error executing in Docker Container: 1
  38s        37s       2      {kubelet gke-test-cluster-default-pool-a07e5d30-siqd}                         Warning   FailedSync           Error syncing pod, skipping: failed to &#34;StartContainer&#34; for &#34;main&#34; with RunContainerError: &#34;PostStart handler: Error executing in Docker Container: 1&#34;
  1m         22s       2      {kubelet gke-test-cluster-default-pool-a07e5d30-siqd}  spec.containers{main}  Warning   FailedPostStartHook
</code></pre><h2 id=selanjutnya>Selanjutnya</h2><ul><li>Pelajari lebih lanjut tentang <a href=/id/docs/concepts/containers/container-environment-variables/><em>environment</em> Kontainer</a>.</li><li>Pelajari bagaimana caranya
<a href=/docs/tasks/configure-pod-container/attach-handler-lifecycle-event/>melakukan <em>attach handler</em> pada <em>event lifecycle</em> sebuah Kontainer</a>.</li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-d52aadda80edd9f8c514cfe2321363c2>4 - Workloads</h1></div><div class=td-content><h1 id=pg-4d68b0ccf9c683e6368ffdcc40c838d4>4.1 - Pods</h1></div><div class=td-content><h1 id=pg-37afa6c66c74400d1579f10faf55e5b6>4.1.1 - Pengenalan Pod</h1><p>Halaman ini menyajikan ikhtisar dari <code>Pod</code>, objek terkecil yang dapat di <em>deploy</em> di dalam objek model Kubernetes.</p><h2 id=memahami-pod>Memahami Pod</h2><p>Sebuah <em>Pod</em> adalah unit dasar di Kubernetes--unit terkecil dan paling sederhana di dalam objek model Kubernetes yang dapat dibuat dan di <em>deploy</em>. Sebuah <em>Pod</em> merepresentasikan suatu proses yang berjalan di dalam klaster.</p><p><em>Pod</em> membungkus sebuah kontainer (atau, di beberapa kasus, beberapa kontainer), sumber penyimpanan, alamat jaringan <em>IP</em> yang unik, dan opsi yang mengatur bagaimana kontainer harus dijalankan. <em>Pod</em> merupakan representasi dari unit <em>deployment</em>: sebuah <em>instance</em> aplikasi di dalam Kubernetes, yang mungkin terdiri dari satu kontainer atau sekumpulan kontainer yang berbagi <em>resource</em>.</p><p><a href=https://www.docker.com>Docker</a> adalah salah satu kontainer <em>runtime</em> yang paling umum digunakan di Kubernetes <em>Pod</em>, tetapi <em>Pod</em> mendukung kontainer <em>runtime</em> lainnya.</p><p><em>Pod</em> di Kubernetes klaster dapat digunakan dengan dua cara:</p><ul><li><strong>Pod menjalankan satu kontainer</strong>. Model satu kontainer per <em>Pod</em> adalah model yang umum digunakan di Kubernetes; kamu dapat membayangkan sebuah <em>Pod</em> sebagai pembungkus kontainer tersebut, dan Kubernetes tidak mengelola kontainer secara langsung tetapi mengelola <em>Pod</em> tersebut.</li><li><strong>Pod menjalankan beberapa kontainer yang perlu berjalan bersamaan</strong>. Sebuah <em>Pod</em> dapat membungkus sebuah aplikasi yang terdiri dari beberapa kontainer yang perlu berbagi <em>resource</em>. Kontainer yang ditempatkan di dalam satu <em>Pod</em> ini membentuk sebuah layanan. Sebuah kontainer menyajikan berkas dari sumber penyimpanan ke publik, sedangkan kontainer <em>sidecar</em> yang lain melakukan pembaharuan terhadap berkas tersebut. <em>Pod</em> membungkus semua kontainer dan <em>resource</em> penyimpanan sebagai satu kesatuan yang dapat dikelola.</li></ul><p><a href=http://kubernetes.io/blog>Kubernetes Blog</a> menyediakan beberapa informasi tambahan terkait penggunaan <em>Pod</em>. Informasi selengkapnya, kunjungi:</p><ul><li><a href=https://kubernetes.io/blog/2015/06/the-distributed-system-toolkit-patterns>The Distributed System Toolkit: Patterns for Composite Containers</a></li><li><a href=https://kubernetes.io/blog/2016/06/container-design-patterns>Container Design Patterns</a></li></ul><p>Setiap <em>Pod</em> dimaksudkan untuk menjalankan satu <em>instance</em> aplikasi. Jika kamu ingin mengembangkan aplikasi secara horizontal (contoh, banyak <em>instance</em> sekaligus), kamu dapat menggunakan banyak <em>Pod</em>, satu untuk setiap <em>instance</em>. Di Kubernetes, konsep ini umumnya disebut dengan replikasi. <em>Pod</em> yang direplikasi biasanya dibuat dan dikelola sebagai grup oleh objek abstraksi yang disebut kontroler. Lihat <a href=#pod-dan-kontroler>Pod dan Kontroler</a> untuk informasi selengkapnya.</p><h3 id=bagaimana-pod-mengelola-beberapa-kontainer>Bagaimana <em>Pod</em> mengelola beberapa Kontainer</h3><p><em>Pod</em> didesain untuk mendukung banyak proses (sebagai kontainer) yang membentuk sebuah layanan. Kontainer di dalam sebuah <em>Pod</em> akan otomatis ditempatkan bersama di dalam satu mesin fisik atau mesin <em>virtual</em> di dalam klaster. Kontainer tersebut dapat berbagi <em>resource</em> dan dependensi, berkomunikasi satu sama lain, dan berkoordinasi kapan dan bagaimana mereka diterminasi.</p><p>Perhatikan bahwa mengelompokan kontainer di dalam satu <em>Pod</em> merupakan kasus lanjutan. Kamu dapat menggunakan pola ini hanya dalam kasus tertentu. Sebagai contoh, kamu memiliki kontainer yang bertindak sebagai <em>web server</em> yang menyajikan berkas dari <em>resource</em> penyimpanan bersama, dan kontainer <em>sidecar</em> melakukan pembaharuan terhadap berkas tersebut dari sumber lain, seperti dalam diagram <em>Pod</em> berikut:<figure><img src=/images/docs/pod.svg width=50%><figcaption><h4>Pod diagram</h4></figcaption></figure></p><p><em>Pod</em> menyediakan dua jenis <em>resource</em> sebagai penyusun dari kontainer: <em>jaringan</em> dan <em>penyimpanan</em>.</p><h4 id=jaringan>Jaringan</h4><p>Setiap <em>Pod</em> diberikan sebuah alamat <em>IP</em> unik. Setiap kontainer di dalam <em>Pod</em> berbagi <em>network namespace</em>, termasuk alamat <em>IP</em> dan <em>port</em> jaringan. Setiap kontainer di dalam <em>Pod</em> dapat berkomunikasi satu sama lain menggunakan <em>localhost</em>. Saat para kontainer di dalam <em>Pod</em> berkomunikasi dengan entitas lain di luar <em>Pod</em>, mereka harus berkoordinasi satu sama lain bagaimana mereka menggunakan <em>resource</em> jaringan (seperti <em>Port</em>).</p><h4 id=penyimpanan>Penyimpanan</h4><p><em>Pod</em> dapat menentukan penyimpanan bersama yaitu <em>volumes</em>. Semua kontainer di dalam <em>Pod</em> dapat mengakses <em>volumes</em> ini, mengizinkan kontainer untuk berbagi data. <em>Volumes</em> juga memungkinkan data di <em>Pod</em> untuk bertahan jika salah satu kontainer perlu melakukan proses <em>restart</em>. Lihat <em><a href=/id/docs/concepts/storage/volumes/>Volumes</a></em> untuk informasi lebih lanjut bagaimana Kubernetes mengimplementasikan penyimpanan di dalam <em>Pod</em>.</p><h2 id=bekerja-dengan-pod>Bekerja dengan Pod</h2><p>Kamu akan jarang membuat <em>Pod</em> secara langsung di Kubernetes. Ini karena <em>Pod</em> dirancang sebagai entitas sesaat. Saat <em>Pod</em> dibuat (baik oleh kamu, atau secara tidak langsung oleh kontroler), <em>Pod</em> ditempatkan dan dijalankan di sebuah <em>Node</em> di dalam klaster. <em>Pod</em> akan tetap di <em>Node</em> tersebut sampai proses dihentikan, Objek <em>Pod</em> dihapus, <em>Pod</em> dihentikan karena kekurangan <em>resource</em>, atau <em>Node</em> tersebut berhenti berjalan.</p><div class="alert alert-info note callout" role=alert><strong>Catatan:</strong> Tidak perlu bingung untuk membedakan antara menjalankan ulang sebuah kontainer di dalam <em>Pod</em> dan menjalankan ulang <em>Pod</em>. <em>Pod</em> itu sendiri tidak berjalan, tetapi <em>Pod</em> adalah <em>environment</em> kontainer itu berjalan dan akan tetap ada sampai dihapus.</div><p><em>Pod</em> tidak melakukan mekanisme penyembuhan diri sendiri. Jika <em>Pod</em> ditempatkan disebuah <em>Node</em> yang gagal, atau proses penempatan <em>Pod</em> itu sendiri gagal, <em>Pod</em> akan dihapus; demikian juga, <em>Pod</em> tidak akan bertahan jika <em>Node</em> tersebut kehabisan <em>resource</em> atau sedang dalam tahap pemeliharaan. Kubernetes menggunakan abstraksi yang disebut kontroler, yang menangani dan mengelola <em>Pod</em>. Jadi, meskipun <em>Pod</em> dapat dipakai secara langsung di Kubernetes, kontroler merupakan cara umum yang digunakan untuk mengelola <em>Pod</em>. Lihat <a href=#pod-dan-kontroler>Pod dan kontroler</a> untuk informasi lebih lanjut bagaimana Kubernetes menggunakan kontroler untuk mengimpelentasikan mekanisme penyembuhan diri sendiri dan replikasi pada <em>Pod</em>.</p><h3 id=pod-dan-kontroler>Pod dan Kontroler</h3><p>Kontroler dapat membuat dan mengelola banyak <em>Pod</em> untuk kamu, menangani replikasi dan menyediakan kemampuan penyembuhan diri sendiri pada lingkup klaster. Sebagai contoh, jika sebuah <em>Node</em> gagal, kontroler akan otomatis mengganti <em>Pod</em> tersebut dengan menempatkan <em>Pod</em> yang identik di <em>Node</em> yang lain.</p><p>Beberapa contoh kontroler yang berisi satu atau lebih <em>Pod</em> meliputi:</p><ul><li><a href=/id/docs/concepts/workloads/controllers/deployment/>Deployment</a></li><li><a href=/id/docs/concepts/workloads/controllers/statefulset/>StatefulSet</a></li><li><a href=/id/docs/concepts/workloads/controllers/daemonset/>DaemonSet</a></li></ul><p>Secara umum, kontroler menggunakan templat <em>Pod</em> yang kamu sediakan untuk membuat <em>Pod</em>.</p><h2 id=templat-pod>Templat Pod</h2><p>Templat <em>Pod</em> adalah spesifikasi dari <em>Pod</em> yang termasuk di dalam objek lain seperti
<a href=/id/docs/concepts/workloads/controllers/replicationcontroller/>Replication Controllers</a>, <a href=/docs/concepts/jobs/run-to-completion-finite-workloads/>Jobs</a>, dan <a href=/id/docs/concepts/workloads/controllers/daemonset/>DaemonSets</a>. Kontroler menggunakan templat <em>Pod</em> untuk membuat <em>Pod</em>.</p><p>Contoh di bawah merupakan manifestasi sederhana untuk <em>Pod</em> yang berisi kontainer yang membuat sebuah pesan.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>myapp-pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>labels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>app</span>:<span style=color:#bbb> </span>myapp<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>myapp-container<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>busybox<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>command</span>:<span style=color:#bbb> </span>[<span style=color:#b44>&#39;sh&#39;</span>,<span style=color:#bbb> </span><span style=color:#b44>&#39;-c&#39;</span>,<span style=color:#bbb> </span><span style=color:#b44>&#39;echo Hello Kubernetes! &amp;&amp; sleep 3600&#39;</span>]<span style=color:#bbb>
</span></span></span></code></pre></div><p>Perubahan yang terjadi pada templat atau berganti ke templat yang baru tidak memiliki efek langsung pada <em>Pod</em> yang sudah dibuat. <em>Pod</em> yang dibuat oleh <em>replication controller</em> dapat diperbarui secara langsung.</p><h2 id=selanjutnya>Selanjutnya</h2><ul><li>Pelajari lebih lanjut tentang perilaku <em>Pod</em>:<ul><li><a href=/id/docs/concepts/workloads/pods/pod/#termination-of-pods>Terminasi Pod</a></li><li><a href=/id/docs/concepts/workloads/pods/pod-lifecycle/>Lifecycle Pod</a></li></ul></li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-99cce294fe789317ee684a6e1f07f20f>4.1.2 - Pod</h1><p>Pod adalah unit komputasi terkecil yang bisa di-<em>deploy</em> dan dibuat serta dikelola dalam Kubernetes.</p><h2 id=apa-itu-pod>Apa Itu Pod?</h2><p>Sebuah Pod (seperti pod pada paus atau kacang polong) adalah sebuah kelompok yang
terdiri dari satu atau lebih <a class=glossary-tooltip title='Sebuah image yang ringan dan dapat dijalankan yang mengandung perangkat lunak and segala dependensi yang dibutuhkan.' data-toggle=tooltip data-placement=top href=/id/docs/concepts/overview/what-is-kubernetes/#mengapa-kontainer target=_blank aria-label=kontainer>kontainer</a>
(misalnya kontainer Docker), dengan ruang penyimpanan ataupun jaringan yang dipakai bersama,
dan sebuah spesifikasi mengenai bagaimana menjalankan kontainer. Isi dari Pod akan
selalu diletakkan dan dijadwalkan bersama, serta berjalan dalam konteks yang sama.
Sebuah Pod memodelkan <em>"logical host"</em> yang spesifik terhadap aplikasi. Ini mengandung
lebih dari satu kontainer aplikasi yang secara relatif saling terhubung erat. Sebelum
masa kontainer, menjalankan aplikasi dalam mesin fisik atau <em>virtual</em> berarti
menjalankan dalam <em>logical host</em> yang sama.</p><p>Walaupun Kubernetes mendukung lebih banyak <em>runtime</em> kontainer selain Docker,
namun Docker adalah yang paling umum diketahui dan ini membantu dalam menjelaskan
Pod dengan istilah pada Docker.</p><p>Konteks bersama dalam sebuah Pod adalah kumpulan Linux namespace, cgroup dan
kemungkinan segi isolasi lain, hal yang sama yang mengisolasi kontainer Docker.
Dalam sebuah konteks pada Pod, setiap aplikasi bisa menerapkan sub-isolasi lebih lanjut.</p><p>Semua kontainer dalam suatu Pod akan berbagi alamat IP dan <em>port</em> yang sama,
dan bisa saling berkomunikasi melalui <code>localhost</code>. Komunikasi tersebut mengunakan
standar <em>inter-process communications</em> (IPC) seperti SystemV semaphores
atau POSIX shared memory. Kontainer pada Pod yang berbeda memiliki alamat IP
yang berbeda dan tidak dapat berkomunikasi menggunakan IPC tanpa
<a href=/id/docs/concepts/policy/pod-security-policy/>pengaturan khusus</a>. Kontainer ini
biasa berkomunikasi dengan yang lain menggunakan alamat IP setiap Pod.</p><p>Aplikasi dalam suatu Pod juga memiliki akses ke <a class=glossary-tooltip title='Sebuah direktori yang mengandung data, dapat diakses o;eh kontainer-kontainer di dalam pod.' data-toggle=tooltip data-placement=top href=/docs/concepts/storage/volumes/ target=_blank aria-label='ruang penyimpanan'>ruang penyimpanan</a> bersama,
yang didefinisikan sebagai bagian dari Pod dan dibuat bisa diikatkan ke masing-masing
<em>filesystem</em> pada aplikasi.</p><p>Dalam istilah konsep <a href=https://www.docker.com/>Docker</a>, sebuah Pod dimodelkan sebagai
gabungan dari kontainer Docker yang berbagi <em>namespace</em> dan ruang penyimpanan <em>filesystem</em>.</p><p>Layaknya aplikasi dengan kontainer, Pod dianggap sebagai entitas yang relatif tidak kekal
(tidak bertahan lama). Seperti yang didiskusikan dalam
<a href=/id/docs/concepts/workloads/pods/pod-lifecycle/>siklus hidup Pod</a>, Pod dibuat, diberikan
ID unik (UID), dan dijadwalkan pada suatu mesin dan akan tetap disana hingga dihentikan
(bergantung pada aturan <em>restart</em>) atau dihapus. Jika <a class=glossary-tooltip title='A node is a worker machine in Kubernetes.' data-toggle=tooltip data-placement=top href=/docs/concepts/architecture/nodes/ target=_blank aria-label=mesin>mesin</a>
mati, maka semua Pod pada mesin tersebut akan dijadwalkan untuk dihapus, namun setelah
suatu batas waktu. Suatu Pod tertentu (sesuai dengan ID unik) tidak akan dijadwalkan ulang
ke mesin baru, namun akan digantikan oleh Pod yang identik, bahkan jika dibutuhkan bisa
dengan nama yang sama, tapi dengan ID unik yang baru
(baca <a href=/id/docs/concepts/workloads/controllers/replicationcontroller/><em>replication controller</em></a>
untuk info lebih lanjut)</p><p>Ketika sesuatu dikatakan memiliki umur yang sama dengan Pod, misalnya saja ruang penyimpanan,
maka itu berarti akan tetap ada selama Pod tersebut masih ada. Jika Pod dihapus dengan
alasan apapun, sekalipun Pod pengganti yang identik telah dibuat, semua yang berhubungan
(misalnya ruang penyimpanan) akan dihapus dan dibuat ulang.</p><figure><img src=/images/docs/pod.svg width=50%><figcaption><h4>Pod diagram</h4></figcaption></figure><p><em>Sebuah Pod dengan banyak kontainer, yaitu <em>File Puller</em> dan <em>Web Server</em> yang menggunakan
ruang penyimpanan persisten untuk berbagi ruang penyimpanan bersama antara kontainer.</em></p><h2 id=motivasi-suatu-pods>Motivasi suatu Pods</h2><h3 id=pengelolaan>Pengelolaan</h3><p>Pod adalah suatu model dari pola beberapa proses yang bekerja sama dan membentuk
suatu unit layanan yang kohesif. Menyederhanakan proses melakukan <em>deploy</em> dan
pengelolaan aplikasi dengan menyediakan abstraksi tingkat yang lebih tinggi
daripada konstituen aplikasinya. Pod melayani sebagai unit dari <em>deployment</em>,
penskalaan horizontal, dan replikasi. <em>Colocation</em> (<em>co-scheduling</em>), berbagi nasib
(misalnya dimatikan), replikasi terkoordinasi, berbagi sumber daya dan
pengelolaan ketergantungan akan ditangani otomatis untuk kontainer dalam suatu Pod.</p><h3 id=berbagi-sumber-daya-dan-komunikasi>Berbagi sumber daya dan komunikasi</h3><p>Pod memungkinkan berbagi data dan komunikasi diantara konstituennya.</p><p>Semua aplikasi dalam suatu Pod menggunakan <em>namespace</em> jaringan yang sama
(alamat IP dan <em>port</em> yang sama), dan menjadikan bisa saling mencari dan berkomunikasi
dengan menggunakan <code>localhost</code>. Oleh karena itu, aplikasi dalam Pod harus
berkoordinasi mengenai penggunaan <em>port</em>. Setiap Pod memiliki alamat IP
dalam satu jaringan bersama yang bisa berkomunikasi dengan komputer lain
dan Pod lain dalam jaringan yang sama.</p><p>Kontainer dalam suatu Pod melihat <em>hostname</em> sistem sebagai sesuatu yang sama
dengan konfigurasi <code>name</code> pada Pod. Informasi lebih lanjut terdapat dibagian
<a href=/id/docs/concepts/cluster-administration/networking/>jaringan</a>.</p><p>Sebagai tambahan dalam mendefinisikan kontainer aplikasi yang berjalan dalam Pod,
Pod memberikan sepaket sistem penyimpanan bersama. Sistem penyimpanan memungkinkan
data untuk bertahan saat kontainer dijalankan ulang dan dibagikan kepada semua
aplikasi dalam Pod tersebut.</p><h2 id=penggunaan-pod>Penggunaan Pod</h2><p>Pod dapat digunakan untuk menjalankan beberapa aplikasi yang terintegrasi
secara vertikal (misalnya LAMP), namun motivasi utamanya adalah untuk mendukung
berlokasi bersama, mengelola program pembantu, diantaranya adalah:</p><ul><li>sistem pengelolaan konten, pemuat berkas dan data, manajer <em>cache</em> lokal, dll.</li><li>catatan dan <em>checkpoint</em> cadangan, kompresi, rotasi, dll.</li><li>pengamat perubahan data, pengintip catatan, adapter pencatatan dan pemantauan,
penerbit peristiwa, dll.</li><li>proksi, jembatan dan adaptor.</li><li>pengontrol, manajer, konfigurasi dan pembaharu.</li></ul><p>Secara umum, masing-masing Pod tidak dimaksudkan untuk menjalankan beberapa
aplikasi yang sama.</p><p>Penjelasan lebih lengkap bisa melihat <a href=https://kubernetes.io/blog/2015/06/the-distributed-system-toolkit-patterns>The Distributed System ToolKit: Patterns for Composite Containers</a>.</p><h2 id=alternatif-pertimbangan>Alternatif pertimbangan</h2><p>Kenapa tidak menjalankan banyak program dalam satu kontainer (Docker)?</p><ol><li>Transparansi. Membuat kontainer dalam suatu Pod menjadi terlihat dari infrastruktur,
memungkinkan infrastruktur menyediakan servis ke kontainer tersebut, misalnya saja
pengelolaan proses dan pemantauan sumber daya. Ini memfasilitasi sejumlah
kenyamanan untuk pengguna.</li><li>Pemisahan ketergantungan perangkat lunak. Setiap kontainer mungkin memiliki
versi, dibuat dan dijalankan ulang secara independen. Kubernetes mungkin mendukung
pembaharuan secara langsung terhadap suatu kontainer, suatu saat nanti.</li><li>Mudah digunakan. Penguna tidak diharuskan menjalankan manajer prosesnya sendiri,
khawatir dengan sinyal dan propagasi <em>exit-code</em>, dan lain sebagainya.</li><li>Efisiensi. Karena infrastruktur memegang lebih banyak tanggung jawab, kontainer
bisa lebih ringan.</li></ol><p>Kenapa tidak mendukung penjadwalan kontainer berdasarkan <em>affinity</em>?</p><p>Cara itu bisa menyediakan lokasi yang sama, namun tidak memberikan banyak
keuntungan dari Pod, misalnya saja berbagi sumber daya, IPC, jaminan berbagi nasib
dan kemudahan manajemen.</p><h2 id=ketahanan-suatu-pod-atau-kekurangan>Ketahanan suatu Pod (atau kekurangan)</h2><p>Pod tidak dimaksudkan untuk diperlakukan sebagai entitas yang tahan lama.
Mereka tidak akan bertahan dengan kegagalan penjadwalan, kegagalan mesin,
atau <em>eviction</em> (pengusiran), misalnya karena kurangnya sumber daya atau dalam suatu
kasus mesin sedang dalam pemeliharaan.</p><p>Secara umum, pengguna tidak seharusnya butuh membuat Pod secara langsung. Mereka
seharusnya selalu menggunakan pengontrol, sekalipun untuk yang tunggal, misalnya,
<a href=/id/docs/concepts/workloads/controllers/deployment/><em>Deployment</em></a>. Pengontrol
menyediakan penyembuhan diri dengan ruang lingkup kelompok, begitu juga dengan
pengelolaan replikasi dan penluncuran.
Pengontrol seperti <a href=/id/docs/concepts/workloads/controllers/statefulset.md><em>StatefulSet</em></a>
bisa memberikan dukungan terhadap Pod yang <em>stateful</em>.</p><p>Penggunaan API kolektif sebagai <em>user-facing primitive</em> utama adalah hal yang
relatif umum diantara sistem penjadwalan kluster, seperti</p><p><a href=https://research.google.com/pubs/pub43438.html>Borg</a>,
<a href=https://mesosphere.github.io/marathon/docs/rest-api.html>Marathon</a>,
<a href=http://aurora.apache.org/documentation/latest/reference/configuration/#job-schema>Aurora</a>, dan
<a href=https://www.slideshare.net/Docker/aravindnarayanan-facebook140613153626phpapp02-37588997>Tupperware</a>.</p><p>Pod diekspose sebagai <em>primitive</em> untuk memfasilitasi hal berikut:</p><ul><li>penjadwalan dan pengontrol sifat <em>pluggability</em></li><li>mendukung operasi pada level Pod tanpa perlu melakukan proksi melalui API pengontrol</li><li>pemisahan antara umur suatu Pod dan pengontrol, seperti misalnya <em>bootstrapping</em>.</li><li>pemisahan antara pengontrol dan servis, pengontrol <em>endpoint</em> hanya memperhatikan Pod</li><li>komposisi yang bersih antara fungsionalitas dilevel Kubelet dan klaster. Kubelet
secara efektif adalah pengontrol Pod.</li><li>aplikasi dengan ketersediaan tinggi, yang akan mengharapkan Pod akan digantikan
sebelum dihentikan dan tentu saja sebelum dihapus, seperti dalam kasus penggusuran
yang direncanakan atau pengambilan gambar.</li></ul><h2 id=penghentian-pod>Penghentian Pod</h2><p>Karena Pod merepresentasikan proses yang berjalan pada mesin didalam klaster, sangat
penting untuk memperbolehkan proses ini berhenti secara normal ketika sudah tidak
dibutuhkan (dibandingkan dengan dihentikan paksa dengan sinyal KILL dan tidak memiliki
waktu untuk dibersihkan). Pengguna seharusnya dapat meminta untuk menghapus dan tahu
proses penghentiannya, serta dapat memastikan penghentian berjalan sempurna. Ketika
pengguna meminta menghapus Pod, sistem akan mencatat masa tenggang untuk penghentian
secara normal sebelum Pod dipaksa untuk dihentikan, dan sinyal TERM akan dikirim ke
proses utama dalam setiap kontainer. Setelah masa tenggang terlewati, sinyal KILL
akan dikirim ke setiap proses dan Pod akan dihapus dari API server. Jika Kubelet
atau kontainer manajer dijalankan ulang ketika menunggu suatu proses dihentikan,
penghentian tersebut akan diulang dengan mengembalikan masa tenggang senilai semula.</p><p>Contohnya sebagai berikut:</p><ol><li>Pengguna mengirim perintah untuk menghapus Pod, dengan masa tenggang (30 detik)</li><li>Pod dalam API server akan diperbarui dengan waktu dimana Pod dianggap "mati"
bersama dengan masa tenggang.</li><li>Pod ditampilkan dalam status "Terminating" ketika tercantum dalam perintah klien</li><li>(bersamaan dengan poin 3) Ketika Kubelet melihat Pod sudah ditandai sebagai
"Terminating" karena waktu pada poin 2 sudah diatur, ini memulai proses penghentian Pod<ol><li>Jika salah satu kontainer pada Pod memiliki
<a href=/id/docs/concepts/containers/container-lifecycle-hooks/#hook-details>preStop <em>hook</em></a>,
maka akan dipanggil di dalam kontainer. Jika <code>preStop</code> <em>hook</em> masih berjalan
setelah masa tenggang habis, langkah 2 akan dipanggil dengan tambahan masa tenggang
yang sedikit, 2 detik.</li><li>Semua kontainer akan diberikan sinyal TERM. Sebagai catatan, tidak semua kontainer
akan menerima sinyal TERM dalam waktu yang sama dan mungkin butuh waktu untuk
menjalankan <code>preStop</code> <em>hook</em> jika bergantung pada urutan penghentiannya.</li></ol></li><li>(bersamaan dengan poin 3) Pod akan dihapus dari daftar <em>endpoint</em> untuk servis dan
tidak lagi dianggap sebagai bagian dari Pod yang berjalan dalam <em>replication controllers</em>.
Pod yang dihentikan, secara perlahan tidak akan melayani permintaan karena load balancer
(seperti servis proksi) menghapus mereka dari daftar rotasi.</li><li>Ketika masa tenggang sudah lewat, semua proses yang masih berjalan dalam Pod
akan dihentikan dengan sinyal SIGKILL.</li><li>Kubelet akan selesai menghapus Pod dalam API server dengan mengatur masa tenggang
menjadi 0 (langsung menghapus). Pod akan menghilang dari API dan tidak lagi terlihat
oleh klien.</li></ol><p>Secara <em>default</em>, semua penghapusan akan berjalan normal selama 30 detik. Perintah
<code>kubectl delete</code> mendukung opsi <code>--grace-period=&lt;waktu dalam detik></code> yang akan
memperbolehkan pengguna untuk menimpa nilai awal dan memberikan nilai sesuai keinginan
pengguna. Nilai <code>0</code> akan membuat Pod
<a href=/id/docs/concepts/workloads/pods/pod/#force-deletion-of-pods>dihapus paksa</a>.
Kamu harus memberikan opsi tambahan <code>--force</code> bersamaan dengan <code>--grace-period=0</code>
untuk melakukan penghapusan paksa.</p><h3 id=penghapusan-paksa-sebuah-pod>Penghapusan paksa sebuah Pod</h3><p>Penghapusan paksa dari sebuah Pod didefinisikan sebagai penghapusan Pod dari <em>state</em>
klaster dan etcd secara langsung. Ketika penghapusan paksa dilakukan, API server tidak
akan menunggu konfirmasi dari kubelet bahwa Pod sudah dihentikan pada mesin ia berjalan.
Ini menghapus Pod secara langsung dari API, sehingga Pod baru bisa dibuat dengan nama
yang sama. Dalam mesin, Pod yang dihentikan paksa akan tetap diberikan sedikit masa
tenggang sebelum dihentikan paksa.</p><p>Penghentian paksa dapat menyebabkan hal berbahaya pada beberapa Pod dan seharusnya
dilakukan dengan perhatian lebih. Dalam kasus StatefulSet Pods, silakan melihat
dokumentasi untuk <a href=/docs/tasks/run-application/force-delete-stateful-set-pod/>penghentian Pod dari StatefulSet</a>.</p><h2 id=hak-istimewa-untuk-kontainer-pada-pod>Hak istimewa untuk kontainer pada Pod</h2><p>Setiap kontainer dalam Pod dapat mengaktifkan hak istimewa (mode <em>privileged</em>), dengan menggunakan tanda
<code>privileged</code> pada <a href=/id/docs/tasks/configure-pod-container/security-context/>konteks keamanan</a>
pada spesifikasi kontainer. Ini akan berguna untuk kontainer yang ingin menggunakan
kapabilitas Linux seperti memanipulasi jaringan dan mengakses perangkat. Proses dalam
kontainer mendapatkan hak istimewa yang hampir sama dengan proses di luar kontainer.
Dengan hak istimerwa, seharusnya lebih mudah untuk menulis pada jaringan dan <em>plugin</em>
ruang penyimpanan sebagai Pod berbeda yang tidak perlu dikompilasi ke dalam kubelet.</p><div class="alert alert-info note callout" role=alert><strong>Catatan:</strong> <em>Runtime</em> kontainer kamu harus mendukung konsep hak istimewa kontainer untuk membuat
pengaturan ini menjadi relevan.</div><h2 id=api-object>API Object</h2><p>Pod adalah sumber daya tingkat tinggi dalam Kubernetes REST API.
Definisi <a href=/docs/reference/generated/kubernetes-api/v1.25/#pod-v1-core>Objek Pod API</a> menjelaskan mengenai objek secara lengkap.</p></div><div class=td-content style=page-break-before:always><h1 id=pg-c3c2b9cf30915ec9d46c147201da3332>4.1.3 - Siklus Hidup Pod</h1><p></p><p>Halaman ini menjelaskan siklus hidup sebuah Pod</p><h2 id=fase-pod>Fase Pod</h2><p><em>Field</em> <code>status</code> dari sebuah Pod merupakan sebuah objek <a href=/docs/reference/generated/kubernetes-api/v1.25/#podstatus-v1-core>PodStatus</a>, yang memiliki sebuah <em>field</em> <code>phase</code>.</p><p>Fase dari sebuah Pod adalah sesuatu yang sederhana, ringkasan yang lebih tinggi tentang Pod dalam siklus hidupnya. Fase ini tidak ditujukan sebagai sebuah kesimpulan yang luas dari observasi suatu kontainer atau <em>state</em> suatu Pod, serta tidak ditujukan sebagai <em>state machine</em> yang luas.</p><p>Jumlah dan arti dari nilai-nilai fase Pod dijaga ketat. Selain yang ada dalam dokumentasi ini, tidak perlu berasumsi mengenai Pod telah diberikan nilai <code>phase</code>.</p><p>Berikut adalah nilai yang mungkin diberikan untuk suatu <code>phase</code>:</p><table><thead><tr><th style=text-align:left>Nilai</th><th style=text-align:left>Deskripsi</th></tr></thead><tbody><tr><td style=text-align:left><code>Pending</code></td><td style=text-align:left>Pod telah disetujui oleh sistem Kubernetes, tapi ada satu atau lebih <em>image</em> kontainer yang belum terbuat. Ini termasuk saat sebelum dijadwalkan dan juga saat mengunduh <em>image</em> melalui jaringan, yang mungkin butuh beberapa waktu.</td></tr><tr><td style=text-align:left><code>Running</code></td><td style=text-align:left>Pod telah terikat ke suatu node, dan semua kontainer telah terbuat. Setidaknya ada 1 kontainer yang masih berjalan, atau dalam proses memulai atau <em>restart</em>.</td></tr><tr><td style=text-align:left><code>Succeeded</code></td><td style=text-align:left>Semua kontainer di dalam Pod sudah berhasil dihentikan, dan tidak akan dilakukan <em>restart</em>.</td></tr><tr><td style=text-align:left><code>Failed</code></td><td style=text-align:left>Semua kontainer dalan suatu Pod telah dihentikan, dan setidaknya ada satu kontainer yang terhenti karena kegagalan. Itu merupakan kontainer yang keluar dengan kode status bukan 0 atau dihentikan oleh sistem.</td></tr><tr><td style=text-align:left><code>Unknown</code></td><td style=text-align:left><em>State</em> suatu Pod tidak dapat diperoleh karena suatu alasan, biasanya karena kesalahan dalam komunikasi dengan <em>host</em> yang digunakan Pod tersebut.</td></tr></tbody></table><h2 id=kondisi-pod>Kondisi Pod</h2><p>Suatu Pod memiliki sebuah PodStatus, yang merupakan <em>array</em> dari <a href=/docs/reference/generated/kubernetes-api/v1.25/#podcondition-v1-core>PodConditions</a> yang telah atau belum dilewati oleh Pod. Setiap elemen dari <em>array</em> PodConditions mungkin memiliki enam <em>field</em> berikut:</p><ul><li><p><em>Field</em> <code>lastProbeTime</code> memberikan nilai <em>timestamp</em> yang menandakan kapan terakhir kali kondisi kondisi Pod diperiksa.</p></li><li><p><em>Field</em> <code>lastTransitionTime</code> memberikan nilai <em>timestamp</em> yang menandakan kapan terakhir kali Pod berubah status ke status lain.</p></li><li><p><em>Field</em> <code>message</code> adalah pesan yang bisa dibaca manusia yang mengidikasikan detail dari suatu transisi.</p></li><li><p><em>Field</em> <code>reason</code> adalah suatu alasan yang unik, satu kata, ditulis secara <em>CamelCase</em> untuk kondisi transisi terakhir.</p></li><li><p><em>Field</em> <code>status</code> adalah sebuah kata dengan kemungkinan nilainya berupa "<code>True</code>", "<code>False</code>", dan "<code>Unknown</code>".</p></li><li><p><em>Field</em> <code>type</code> adalah sebuah kata yang memiliki kemungkinan nilai sebagai berikut:</p><ul><li><code>PodScheduled</code>: Pod telah dijadwalkan masuk ke node;</li><li><code>Ready</code>: Pod sudah mampu menerima <em>request</em> masuk dan seharusnya sudah ditambahkan ke daftar pembagian beban kerja untuk servis yang sama;</li><li><code>Initialized</code>: Semua <a href=/id/docs/concepts/workloads/pods/init-containers>init containers</a> telah berjalan sempurna.</li><li><code>Unschedulable</code>: <em>scheduler</em> belum dapat menjadwalkan Pod saat ini, sebagai contoh karena kekurangan <em>resources</em> atau ada batasan-batasan lain.</li><li><code>ContainersReady</code>: Semua kontainer di dalam Pod telah siap.</li></ul></li></ul><h2 id=pemeriksaan-kontainer>Pemeriksaan Kontainer</h2><p>Sebuah <a href=/docs/reference/generated/kubernetes-api/v1.25/#probe-v1-core>Probe</a> adalah sebuah diagnosa yang dilakukan secara berkala oleh <a href=/docs/admin/kubelet/>kubelet</a> dalam suatu kontainer. Untuk melakukan diagnosa, kubelet memanggil sebuah <a href=https://godoc.org/k8s.io/kubernetes/pkg/api/v1#Handler>Handler</a> yang diimplementasikan oleh kontainer. Ada 3 tipe <em>Handler</em> yang tersedia, yaitu:</p><ul><li><p><a href=/docs/reference/generated/kubernetes-api/v1.25/#execaction-v1-core>ExecAction</a>: Mengeksekusi perintah tertentu di dalam kontainer. Diagnosa dikatakan berhasil jika perintah selesai dengan kode status 0.</p></li><li><p><a href=/docs/reference/generated/kubernetes-api/v1.25/#tcpsocketaction-v1-core>TCPSocketAction</a>: Melakukan pengecekan TCP terhadap alamat IP kontainer dengan <em>port</em> tertentu. Diagnosa dikatakan berhasil jika <em>port</em> tersebut terbuka.</p></li><li><p><a href=/docs/reference/generated/kubernetes-api/v1.25/#httpgetaction-v1-core>HTTPGetAction</a>: Melakukan sebuah <em>request</em> HTTP Get terhadap alamat IP kontainer dengan <em>port</em> dan <em>path</em> tertentu. Diagnosa dikatakan berhasil jika responnya memiliki kode status lebih besar atau sama dengan 200 dan kurang dari 400.</p></li></ul><p>Setiap pemeriksaan akan menghasilkan salah satu dari tiga hasil berikut:</p><ul><li><em>Success</em>: Kontainer berhasil melakukan diagnosa.</li><li><em>Failure</em>: Kontainer gagal melakukan diagnosa.</li><li><em>Unknown</em>: Gagal melakukan diagnosa, sehingga tidak ada aksi yang harus dilakukan.</li></ul><p><em>Kubelet</em> dapat secara optimal melakukan dan bereaksi terhadap dua jenis pemeriksaan yang sedang berjalan pada kontainer, yaitu:</p><ul><li><p><code>livenessProbe</code>: Ini menunjukkan apakah kontainer sedang berjalan. Jika tidak berhasil melakukan pemeriksaan terhadap <em>liveness</em> dari kontainer, maka kubelet akan mematikan kontainer, dan kontainer akan mengikuti aturan dari <a href=#restart-policy><em>restart policy</em></a>. Jika kontainer tidak menyediakan pemeriksaan terhadap <em>liveness</em>, maka nilai dari <em>state</em> adalah <code>Success</code>.</p></li><li><p><code>readinessProbe</code>: Ini menunjukan apakah kontainer sudah siap melayani <em>request</em>. Jika tidak berhasil melakukan pemeriksaan terhadap kesiapan dari kontainer, maka <em>endpoints controller</em> akan menghapus alamat IP Pod dari daftar semua <em>endpoint</em> untuk servis yang sama dengan Pod. Nilai awal <em>state</em> sebelum jeda awal adalah <code>Failure</code>. Jika kontainer tidak menyediakan pemeriksaan terhadap <em>readiness</em>, maka nilai awal <em>state</em> adalah <code>Success</code>.</p></li></ul><h3 id=kapan-sebaiknya-menggunakan-pemeriksaan-terhadap-liveness-atau-readiness>Kapan sebaiknya menggunakan pemeriksaan terhadap <em>liveness</em> atau <em>readiness</em>?</h3><p>Jika proses dalam kontainer mungkin gagal yang dikarenakan menghadapi suatu masalah
atau menjadi tidak sehat, maka pemeriksaan terhadap <em>liveness</em> tidak diperlukan.
Kubelet akan secara otomatis melakukan aksi yang tepat mengikuti <code>restartPolicy</code> dari Pod.</p><p>Jika kamu ingin kontainer bisa dimatikan dan dijalankan ulang ketika gagal melakukan
pemeriksaan, maka tentukan pemeriksaan <em>liveness</em> dan tentukan nilai <code>restartPolicy</code> sebagai <code>Always</code> atau <code>OnFailure</code>.</p><p>Jika kamu ingin mulai mengirim <em>traffic</em> ke Pod hanya ketika pemeriksaan berhasil,
maka tentukan pemeriksaan <em>readiness</em>. Dalam kasus ini, pemeriksaan <em>readiness</em> mungkin
akan sama dengan pemeriksaan <em>liveness</em>, tapi keberadaan pemeriksaan <em>readiness</em> dalam
<em>spec</em> berarti Pod akan tetap dijalankan tanpa menerima <em>traffic</em> apapun dan akan
mulai menerima <em>traffic</em> ketika pemeriksaan yang dilakukan mulai berhasil.
Jika kontainermu dibutuhkan untuk tetap berjalan ketika <em>loading</em> data yang besar,
<em>file</em> konfigurasi, atau melakukan migrasi ketika <em>startup</em>, maka tentukanlah pemeriksaan <em>readiness</em>.</p><p>Jika kamu ingin kontainermu dalam mematikan dirinya sendiri, kamu dapat menentukan
suatu pemeriksaan <em>readiness</em> yang melakukan pengecekan terhadap <em>endpoint</em> untuk <em>readiness</em>.
<em>endpoint</em> tersebut berbeda dengan <em>endpoint</em> untuk pengecekan <em>liveness</em>.</p><p>Perlu dicatat, jika kamu hanya ingin bisa menutup <em>request</em> ketika Pod sedang dihapus
maka kamu tidak perlu menggunakan pemeriksaan <em>readiness</em>. Dalam penghapusan, Pod akan
secara otomatis mengubah <em>state</em> dirinya menjadi <em>unready</em> tanpa peduli apakah terdapat
pemeriksaan <em>readiness</em> atau tidak. Pod tetap ada pada <em>state unready</em> selama menunggu
kontainer dalam Pod berhenti.</p><p>Untuk informasi lebih lanjut mengenai pengaturan pemeriksaan <em>liveness</em> atau <em>readiness</em>, lihat bagian
<a href=/docs/tasks/configure-pod-container/configure-liveness-readiness-probes/>Konfigurasi <em>Liveness</em> dan <em>Readiness</em> <em>Probe</em></a>.</p><h2 id=status-pod-dan-kontainer>Status Pod dan Kontainer</h2><p>Untuk informasi lebih mendalam mengenai status Pod dan kontainer, silakan lihat
<a href=/docs/reference/generated/kubernetes-api/v1.25/#podstatus-v1-core>PodStatus</a>
dan
<a href=/docs/reference/generated/kubernetes-api/v1.25/#containerstatus-v1-core>ContainerStatus</a>.
Mohon diperhatikan, informasi tentang status Pod bergantung pada
<a href=/docs/reference/generated/kubernetes-api/v1.25/#containerstatus-v1-core>ContainerState</a>.</p><h2 id=state-kontainer>State Kontainer</h2><p>Ketika Pod sudah ditempatkan pada suatu node oleh scheduler, kubelet mulai membuat kontainer menggunakan <em>runtime</em> kontainer.
Ada tiga kemungkinan <em>state</em> untuk suatu kontainer, yaitu Waiting, Running, dan Terminated.
Untuk mengecek <em>state</em> suatu kontainer, kamu bisa menggunakan perintah <code>kubectl describe pod [NAMA_POD]</code>.
<em>State</em> akan ditampilkan untuk masing-masing kontainer dalam Pod tersebut.</p><ul><li><p><code>Waiting</code>: Merupakan <em>state</em> default dari kontainer. Jika <em>state</em> kontainer bukan Running atau Terminated, berarti dalam <em>Wating state</em>.
Suatu kontainer dalam Waiting <em>state</em> akan tetap menjalan operasi-operasi yang dibutuhkan, misalnya mengunduh <em>images</em>, mengaplikasikan Secrets, dsb.
Bersamaan dengan <em>state</em> ini, sebuah pesan dan alasan tentang <em>state</em> akan ditampilkan untuk memberi informasi lebih.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#00f;font-weight:700>...</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>State</span>:<span style=color:#bbb>          </span>Waiting<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>   </span><span style=color:green;font-weight:700>Reason</span>:<span style=color:#bbb>       </span>ErrImagePull<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>...<span style=color:#bbb>
</span></span></span></code></pre></div></li><li><p><code>Running</code>: Menandakan kontainer telah berjalan tanpa masalah. Setelah kontainer masuk ke <em>state</em> Running, jika terdapat <em>hook</em> <code>postStart</code> maka akan dijalankan. <em>State</em> ini juga menampilkan waktu ketika kontainer masuk ke <em>state</em> Running.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#00f;font-weight:700>...</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>   </span><span style=color:green;font-weight:700>State</span>:<span style=color:#bbb>          </span>Running<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>Started</span>:<span style=color:#bbb>      </span>Wed, 30 Jan 2019 16:46:38 +0530<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:#00f;font-weight:700>...</span><span style=color:#bbb>
</span></span></span></code></pre></div></li><li><p><code>Terminated</code>: Menandakan kontainer telah menyelesaikan "tugasnya". Kontainer akan menjadi <em>state</em> ini ketika telah menyelesaikan eksekusi atau terjadi kesalahan. Terlepas dari itu, sebuah alasan dan <em>exit code</em> akan ditampilkan, bersama dengan waktu kontainer mulai dijalankan dan waktu berhenti. Sebelum kontainer masuk ke <em>state</em> Terminated, jika terdapat <code>preStop</code> <em>hook</em> maka akan dijalankan.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#00f;font-weight:700>...</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>   </span><span style=color:green;font-weight:700>State</span>:<span style=color:#bbb>          </span>Terminated<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>     </span><span style=color:green;font-weight:700>Reason</span>:<span style=color:#bbb>       </span>Completed<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>     </span><span style=color:green;font-weight:700>Exit Code</span>:<span style=color:#bbb>    </span><span style=color:#666>0</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>     </span><span style=color:green;font-weight:700>Started</span>:<span style=color:#bbb>      </span>Wed, 30 Jan 2019 11:45:26 +0530<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>     </span><span style=color:green;font-weight:700>Finished</span>:<span style=color:#bbb>     </span>Wed, 30 Jan 2019 11:45:26 +0530<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb> </span>...<span style=color:#bbb>
</span></span></span></code></pre></div></li></ul><h2 id=pod-readiness-gate>Pod readiness gate</h2><div style=margin-top:10px;margin-bottom:10px><b>FEATURE STATE:</b> <code>Kubernetes v1.14 [stable]</code></div><p>Dalam rangka menambahkan ekstensibilitas terhadap kesiapan Pod dengan menggunakan
injeksi umpan balik tambahan atau sinyal ke dalam <code>PodStatus</code>,
Kubernetes 1.11 memperkenalkan sebuah fitur bernama <a href=https://github.com/kubernetes/enhancements/blob/master/keps/sig-network/0007-pod-ready%2B%2B.md>Pod ready++</a>.
Kamu dapat menggunakan <em>field</em> baru <code>ReadinessGate</code> dalam sebuah <code>PodSpec</code> untuk
menunjukan kondisi tambahan yang akan dievaluasi untuk kesiapan Pod. Jika Kubernetes
tidak dapat menemukan kondisi pada <em>field</em> <code>status.conditions</code> dalam suatu Pod,
maka statusnya akan secara otomatis menjadi <code>False</code>. Berikut adalah contoh pemakaiannya:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>Kind</span>:<span style=color:#bbb> </span>Pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:#00f;font-weight:700>...</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>readinessGates</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:green;font-weight:700>conditionType</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;www.example.com/feature-1&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>status</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>conditions</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:green;font-weight:700>type</span>:<span style=color:#bbb> </span>Ready <span style=color:#bbb> </span><span style=color:#080;font-style:italic># ini adalah PodCondition yang telah tersedia</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>status</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;False&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>lastProbeTime</span>:<span style=color:#bbb> </span><span style=color:#a2f;font-weight:700>null</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>lastTransitionTime</span>:<span style=color:#bbb> </span>2018-01-01T00:00:00Z<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:green;font-weight:700>type</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;www.example.com/feature-1&#34;</span><span style=color:#bbb>   </span><span style=color:#080;font-style:italic># sebuah PodCondition tambahan</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>status</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;False&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>lastProbeTime</span>:<span style=color:#bbb> </span><span style=color:#a2f;font-weight:700>null</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>lastTransitionTime</span>:<span style=color:#bbb> </span>2018-01-01T00:00:00Z<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>containerStatuses</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:green;font-weight:700>containerID</span>:<span style=color:#bbb> </span>docker://abcd...<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>ready</span>:<span style=color:#bbb> </span><span style=color:#a2f;font-weight:700>true</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:#00f;font-weight:700>...</span><span style=color:#bbb>
</span></span></span></code></pre></div><p>Kondisi Pod yang baru harus memenuhi <a href=/id/docs/concepts/overview/working-with-objects/labels/#syntax-and-character-set>format label</a> pada Kubernetes.
Sejak perintah <code>kubectl patch</code> belum mendukung perubahan status objek, kondisi Pod yang baru harus mengubah melalui aksi <code>PATCH</code> dengan menggunakan
salah satu dari <a href=/docs/reference/using-api/client-libraries/>KubeClient <em>libraries</em></a>.</p><p>Dengan diperkenalkannya kondisi Pod yang baru, sebuah Pod akan dianggap siap hanya jika memenuhi dua syarat berikut:</p><ul><li>Semua kontainer dalam Pod telah siap.</li><li>Semua kontainer yang diatur dalam <code>ReadinessGates</code> bernilai "<code>True</code>".</li></ul><p>Untuk memfasilitasi perubahan tersebut terhadap evaluasi kesiapan Pod, dibuatkan sebuah kondisi Pod baru yaitu <code>ContainerReady</code>,
untuk dapat menangani kondisi Pod <code>Ready</code> yang sudah ada.</p><p>Dalam K8s 1.11, sebagai fitur <em>alpha</em>, fitur "Pod Ready++" harus diaktifkan melalui pengaturan
<a href=/docs/reference/command-line-tools-reference/feature-gates/>fitur <em>gate</em> pada <code>PodReadinessGates</code></a>.</p><p>Dalam K8s 1.12, fitur tersebut sudah diaktifkan dari awal.</p><h2 id=aturan-menjalankan-ulang>Aturan Menjalankan Ulang</h2><p>Sebuah PodSpec memiliki <em>field</em> <code>restartPolicy</code> dengan kemungkinan nilai berupa Always, OnFailure, dan Never.
Nilai awalnya berupa Always. <code>restartPolicy</code> akan berlaku untuk semua kontainer dalam Pod.
Kontainer yang mati dan dijalankan ulang oleh kubelet akan dijalankan ulang dengan jeda waktu yang ekponensial (10s, 20s, 40s, ...)
dengan batas atas senilai lima menit. Jeda waktu ini akan diatur ulang setelah sukses berjalan selama 10 menit.
Sesuai dengan diskusi pada <a href=/docs/user-guide/pods/#durability-of-pods-or-lack-thereof>dokumen Pod</a>,
setelah masuk ke suatu node, sebuah Pod tidak akan pindah ke node lain.</p><h2 id=umur-pod>Umur Pod</h2><p>Secara umum, Pod tidak hilang sampai ada yang menghapusnya. Ini mungkin dihapus oleh orang atau pengontrol.
Satu pengecualian untuk aturan ini adalah Pod dengan <code>phase</code> bernilai Succeeded atau Failed untuk waktu
beberapa lama yang akan berakhir dan secara otomatis akan dihapus.
(diatur dalam <code>terminated-pod-gc-threshold</code> pada master)</p><p>Tiga tipe pengontrol yang tersedia yaitu:</p><ul><li><p>Menggunakan sebuah <a href=/docs/concepts/jobs/run-to-completion-finite-workloads/>Job</a> untuk Pod yang diharapkan akan berakhir,
sebagai contoh, penghitungan dalam jumlah banyak. Jobs hanyak cocok untuk Pod dengan <code>restartPolicy</code> yang
bernilai OnFailure atau Never.</p></li><li><p>Menggunakan sebuah <a href=/id/docs/concepts/workloads/controllers/replicationcontroller/>ReplicationController</a>,
<a href=/id/docs/concepts/workloads/controllers/replicaset/>ReplicaSet</a>, atau
<a href=/id/docs/concepts/workloads/controllers/deployment/>Deployment</a> untuk Pod yang tidak diharapkan untuk berakhir,
sebagai contoh, <em>web servers</em>. ReplicationControllers hanya cocok digunakan pada Pod dengan <code>restartPolicy</code>
yang bernilai Always.</p></li><li><p>Menggunakan sebuah <a href=/id/docs/concepts/workloads/controllers/daemonset/>DaemonSet</a> untuk Pod yang akan berjalan
hanya satu untuk setiap mesin, karena menyediakan servis yang spesifik untuk suatu mesin.</p></li></ul><p>Ketiga tipe pengontrol ini memiliki sebuah PodTemplate. Direkomdasikan untuk membuat
pengontrol yang sesuai dan membiarkan ini membuat Pod, daripada membuat Pod sendiri secara langsung.
Karena Pod itu sendiri tidak tahan terhadap gagalnya suatu mesin, namun pengontrol tahan.</p><p>Jika node mati atau sambungannya terputus dari klaster, Kubernetes mengatur
<code>phase</code> dari semua Pod pada node yang mati untuk menjadi Failed.</p><h2 id=contoh>Contoh</h2><h3 id=contoh-liveness-probe-tingkat-lanjut>Contoh <em>Liveness Probe</em> tingkat lanjut</h3><p><em>Liveness probe</em> dieksekusi oleh kubelet, jadi semua permintaan akan dilakukan
di dalam <em>namespace</em> jaringan kubelet.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>labels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>test</span>:<span style=color:#bbb> </span>liveness<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>liveness-http<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>args</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- /server<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>k8s.gcr.io/liveness<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>livenessProbe</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>httpGet</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:#080;font-style:italic># ketika &#34;host&#34; tidak ditentukan, &#34;PodIP&#34; akan digunakan</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:#080;font-style:italic># host: my-host</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:#080;font-style:italic># ketika &#34;scheme&#34; tidak ditentukan, _scheme_ &#34;HTTP&#34; akan digunakan. Hanya &#34;HTTP&#34; and &#34;HTTPS&#34; yang diperbolehkan</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:#080;font-style:italic># scheme: HTTPS</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>path</span>:<span style=color:#bbb> </span>/healthz<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>port</span>:<span style=color:#bbb> </span><span style=color:#666>8080</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>httpHeaders</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>X-Custom-Header<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>value</span>:<span style=color:#bbb> </span>Awesome<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>initialDelaySeconds</span>:<span style=color:#bbb> </span><span style=color:#666>15</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>timeoutSeconds</span>:<span style=color:#bbb> </span><span style=color:#666>1</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>liveness<span style=color:#bbb>
</span></span></span></code></pre></div><h3 id=contoh-state>Contoh <em>State</em></h3><ul><li><p>Pod sedang berjalan dan memiliki sebuah kontainer. Kontainer berhenti dengan sukses.</p><ul><li>Mencatat <em>event</em> penyelesaian.</li><li>Jika nilai <code>restartPolicy</code> adalah:<ul><li>Always: Jalankan ulang kontainer; nilai <code>phase</code> Pod akan tetap Running.</li><li>OnFailure: nilai <code>phase</code> Pod akan berubah menjadi Succeeded.</li><li>Never: nilai <code>phase</code> Pod akan berubah menjadi Succeeded.</li></ul></li></ul></li><li><p>Pod sedang berjalan dan memiliki sebuah kontainer. Kontainer berhenti dengan kegagalan.</p><ul><li>Mencatat <em>event</em> kegagalan.</li><li>Jika nilai <code>restartPolicy</code> adalah:<ul><li>Always: Jalankan ulang kontainer, nilai <code>phase</code> Pod akan tetap Running.</li><li>OnFailure: Jalankan ulang kontainer, nilai <code>phase</code> Pod akan tetap Running.</li><li>Never: nilai <code>phase</code> Pod akan menjadi Failed.</li></ul></li></ul></li><li><p>Pod sedang berjalan dan memiliki dua kontainer. Kontainer pertama berhenti dengan kegagalan.</p><ul><li>Mencatat <em>event</em> kegagalan.</li><li>Jika nilai <code>restartPolicy</code> adalah:<ul><li>Always: Jalankan ulang kontainer, nilai <code>phase</code> Pod akan tetap Running.</li><li>OnFailure: Jalankan ulang kontainer, nilai <code>phase</code> Pod akan tetap Running.</li><li>Never: Tidak akan menjalankan ulang kontainer, nilai <code>phase</code> Pod akan tetap Running.</li></ul></li><li>Jika kontainer pertama tidak berjalan dan kontainer kedua berhenti:<ul><li>Mencatat <em>event</em> kegagalan.</li><li>Jika nilai <code>restartPolicy</code> adalah:<ul><li>Always: Jalankan ulang kontainer, nilai <code>phase</code> Pod akan tetap Running.</li><li>OnFailure: Jalankan ulang kontainer, nilai <code>phase</code> Pod akan tetap Running.</li><li>Never: nilai <code>phase</code> Pod akan menjadi Failed.</li></ul></li></ul></li></ul></li><li><p>Pod sedang berjalan dan memiliki satu kontainer. Kontainer berhenti karena kehabisan <em>memory</em>.</p><ul><li>Kontainer diberhentikan dengan kegagalan.</li><li>Mencatat kejadian kehabisan <em>memory</em> (OOM)</li><li>Jika nilai <code>restartPolicy</code> adalah:<ul><li>Always: Jalankan ulang kontainer, nilai <code>phase</code> Pod akan tetap Running.</li><li>OnFailure: Jalankan ulang kontainer, nilai <code>phase</code> Pod akan tetap Running.</li><li>Never: Mencatat kejadian kegagalan, nilai <code>phase</code> Pod akan menjadi Failed.</li></ul></li></ul></li><li><p>Pod sedang berjalan dan sebuah <em>disk</em> mati.</p><ul><li>Menghentikan semua kontainer.</li><li>Mencatat kejadian yang sesuai.</li><li>Nilai <code>phase</code> Pod menjadi Failed.</li><li>Jika berjalan menggunakan pengontrol, maka Pod akan dibuat ulang di tempat lain.</li></ul></li><li><p>Pod sedang berjalan, dan node mengalami <em>segmented out</em>.</p><ul><li>Node pengontrol menunggu sampai suatu batas waktu.</li><li>Node pengontrol mengisi nilai <code>phase</code> Pod menjadi Failed.</li><li>Jika berjalan menggunakan pengontrol, maka Pod akan dibuat ulang di tempat lain.</li></ul></li></ul><h2 id=selanjutnya>Selanjutnya</h2><ul><li><p>Dapatkan pengalaman langsung mengenai
<a href=/docs/tasks/configure-pod-container/attach-handler-lifecycle-event/>penambahan <em>handlers</em> pada kontainer <em>lifecycle events</em></a>.</p></li><li><p>Dapatkan pengalaman langsung mengenai
<a href=/docs/tasks/configure-pod-container/configure-liveness-readiness-probes/>pengaturan <em>liveness</em> dan <em>readiness probes</em></a>.</p></li><li><p>Pelajari lebih lanjut mengenai <a href=/id/docs/concepts/containers/container-lifecycle-hooks/><em>lifecycle hooks</em> pada kontainer</a>.</p></li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-1ccbd4eeded6ab138d98b59175bd557e>4.1.4 - Init Container</h1><p>Halaman ini menyediakan ikhtisar untuk Init Container, yaitu Container khusus yang dijalankan sebelum Container aplikasi dan berisi skrip peralatan atau <em>setup</em> yang tidak tersedia di dalam <em>image</em> dari Container aplikasi.</p><p>Fitur ini telah keluar dari trek Beta sejak versi 1.6. Init Container dapat dispesifikasikan di dalam PodSpec bersama dengan <em>array</em> <code>containers</code> aplikasi. Nilai anotasi <em>beta</em> akan tetap diperhitungkan dan akan menimpa nilai pada PodSpec, tetapi telah ditandai sebagai kedaluarsa pada versi 1.6 dan 1.7. Pada versi 1.8, anotasi <em>beta</em> tidak didukung lagi dan harus diganti menjadi nilai pada PodSpec.</p><h2 id=memahami-init-container>Memahami Init Container</h2><p>Sebuah <a href=/id/docs/concepts/workloads/pods/pod-overview/>Pod</a> dapat memiliki beberapa Container yang berjalan di dalamnya, dan dapat juga memiliki satu atau lebih Init Container, yang akan berjalan sebelum Container aplikasi dijalankan.</p><p>Init Container sama saja seperti Container biasa, kecuali:</p><ul><li>Mereka selalu berjalan hingga selesai.</li><li>Setiap Init Container harus selesai secara sukses sebelum Init Container berikutnya dijalankan.</li></ul><p>Jika sebuah Init Container tidak selesai secara sukses untuk sebuah Pod, Kubernetes akan mengulang kembali Pod tersebut secara terus menerus hingga Init Container selesai secara sukses. Tetapi, jika Pod tersebut memiliki nilai <code>restartPolicy</code> berupa <code>Never</code>, Pod tersebut tidak akan diulang kembali.</p><p>Untuk menspesifikasikan sebuah Container sebagai Init Container, tambahkan kolom <code>initContainers</code> pada PodSpec sebagai sebuah <em>array</em> JSON yang berisi objek dengan tipe <a href=/docs/reference/generated/kubernetes-api/v1.25/#container-v1-core>Container</a>, berdampingan dengan array <code>containers</code> aplikasi.
Status-status dari Init Container dikembalikan di kolom <code>.status.initContainerStatuses</code> sebagai sebuah <em>array</em> dari status-status Container (mirip seperti kolom <code>status.containerStatuses</code>)</p><h3 id=perbedaan-dengan-container-biasa>Perbedaan dengan Container biasa</h3><p>Init Container mendukung semua kolom dan fitur dari Container aplikasi, termasuk konfigurasi <code>limit</code> sumber daya, <code>volume</code>, dan keamanan. Tetapi, <code>request</code> dan <code>limit</code> sumber daya dari sebuah Init Container ditangani dengan cara yang sedikit berbeda, yang didokumentasikan di bagian <a href=#sumber-daya>Sumber Daya</a> di bawah. Juga, Init Container tidak mendukung <em>readiness probe</em> karena mereka harus berjalan hingga selesai sebelum Pod dapat siap.</p><p>Jika beberapa Init Container dispesifikasikan untuk sebuah Pod, Container-container tersebut akan dijalankan satu per satu secara berurutan. Setiap Init Container harus selesai secara sukses sebelum yang berikutnya dapat berjalan.
Saat semua Init Container telah berjalan hingga selesai, Kubernetes akan menginisialisasi Pod dan menjalankan Container aplikasi seperti biasa.</p><h2 id=apa-kegunaan-init-container>Apa kegunaan Init Container?</h2><p>Karena Init Container memiliki <em>image</em> yang berbeda dengan Container aplikasi, mereka memiliki beberapa kelebihan untuk kode yang berhubungan dengan dimulainya Init Container:</p><ul><li>Mereka dapat berisi dan menjalankan skrip peralatan yang tidak diinginkan untuk berada di dalam <em>image</em> Container aplikasi karena alasan keamanan.</li><li>Mereka dapat berisi skrip peralatan atau <em>setup</em> yang tidak tersedia di dalam <em>image</em> aplikasi. Misalnya, kita tidak perlu membuat <em>image</em> dengan instruksi <code>FROM</code> dari <em>image</em> lainnya hanya untuk menggunakan peralatan seperti <code>sed</code>, <code>awk</code>, <code>python</code>, atau <code>dig</code> pada saat <em>setup</em>.</li><li>Peran <em>builder</em> atau <em>deployer</em> dari <em>image</em> dapat bekerja secara independen tanpa harus digabung untuk membuat satu <em>image</em> aplikasi.</li><li>Mereka menggunakan <em>namespace</em> Linux, sehingga mereka dapat memiliki sudut pandang <em>filesystem</em> yang berbeda dengan Container aplikasi. Oleh karenanya, mereka dapat diberikan akses terhadap <code>Secret</code> yang tidak boleh diakses oleh Container aplikasi.</li><li>Mereka berjalan hingga selesai sebelum Container aplikasi manapun dimulai, sedangkan Container aplikasi dijalankan secara paralel, sehingga Init Container menyediakan cara yang mudah untuk menunda dijalankannya Container aplikasi hingga ketentuan-ketentuan yang diinginkan dipenuhi.</li></ul><h3 id=contoh-contoh>Contoh-contoh</h3><p>Berikut beberapa contoh kasus penggunaan Init Container:</p><ul><li><p>Menunggu sebuah Service untuk dibuat dengan perintah <em>shell</em> seperti:</p><pre><code>for i in {1..100}; do sleep 1; if dig myservice; then exit 0; fi; done; exit 1
</code></pre></li><li><p>Mendaftarkan suatu Pod ke sebuah peladen terpisah dari <em>downward API</em> dengan perintah seperti:</p><pre><code>`curl -X POST http://$MANAGEMENT_SERVICE_HOST:$MANAGEMENT_SERVICE_PORT/register -d 'instance=$(&lt;POD_NAME&gt;)&amp;ip=$(&lt;POD_IP&gt;)'`
</code></pre></li><li><p>Menunggu beberapa waktu sebelum menjalankan Container aplikasi dengan perintah seperti <code>sleep 60</code>.</p></li><li><p>Mengklon sebuah <em>git repository</em> ke dalam sebuah <em>volume</em>.</p></li><li><p>Menaruh nilai-nilai tertentu ke dalam sebuah <em>file</em> konfigurasi dan menjalankan peralatan <em>template</em> untuk membuat <em>file</em> konfigurasi secara dinamis untuk Container aplikasi utama. Misalnya, untuk menaruh nilai POD_IP ke dalam sebuah konfigurasi dan membuat konfigurasi aplikasi utama menggunakan Jinja.</p></li></ul><p>Contoh-contoh penggunaan yang lebih detail dapat dilihat pada <a href=/id/docs/concepts/workloads/controllers/statefulset/>dokumentasi StatefulSet</a> dan <a href=/docs/tasks/configure-pod-container/configure-pod-initialization/>petunjuk Produksi Pod</a>.</p><h3 id=menggunakan-init-container>Menggunakan Init Container</h3><p><em>File</em> YAML untuk Kubernetes 1.5 berikut menguraikan sebuah Pod sederhana yang memiliki dua buah Init Container.
Pod pertama menunggu <code>myservice</code> dan yang kedua menunggu <code>mydb</code>. Saat kedua Init Container tersebut sudah selesai, Podnya akan dijalankan.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>myapp-pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>labels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>app</span>:<span style=color:#bbb> </span>myapp<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>annotations</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>pod.beta.kubernetes.io/init-containers</span>:<span style=color:#bbb> </span><span style=color:#b44>&#39;[
</span></span></span><span style=display:flex><span><span style=color:#b44>        {
</span></span></span><span style=display:flex><span><span style=color:#b44>            &#34;name&#34;: &#34;init-myservice&#34;,
</span></span></span><span style=display:flex><span><span style=color:#b44>            &#34;image&#34;: &#34;busybox:1.28&#34;,
</span></span></span><span style=display:flex><span><span style=color:#b44>            &#34;command&#34;: [&#39;</span>sh&#39;, &#39;-c&#39;, &#34;until nslookup myservice.$(cat /var/run/secrets/kubernetes.io/serviceaccount/namespace).svc.cluster.local; do echo waiting for myservice; sleep 2; done&#34;]<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span>},<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span>{<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>            </span><span style=color:green;font-weight:700>&#34;name&#34;: </span><span style=color:#b44>&#34;init-mydb&#34;</span>,<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>            </span><span style=color:green;font-weight:700>&#34;image&#34;: </span><span style=color:#b44>&#34;busybox:1.28&#34;</span>,<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>            </span><span style=color:green;font-weight:700>&#34;command&#34;: </span>[<span style=color:#b44>&#39;sh&#39;</span>,<span style=color:#bbb> </span><span style=color:#b44>&#39;-c&#39;</span>,<span style=color:#bbb> </span><span style=color:#b44>&#34;until nslookup mydb.$(cat /var/run/secrets/kubernetes.io/serviceaccount/namespace).svc.cluster.local; do echo waiting for mydb; sleep 2; done&#34;</span>]<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span>}<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>]<span style=color:#b44>&#39;
</span></span></span><span style=display:flex><span><span style=color:#b44>spec:
</span></span></span><span style=display:flex><span><span style=color:#b44>  containers:
</span></span></span><span style=display:flex><span><span style=color:#b44>  - name: myapp-container
</span></span></span><span style=display:flex><span><span style=color:#b44>    image: busybox:1.28
</span></span></span><span style=display:flex><span><span style=color:#b44>    command: [&#39;</span>sh&#39;, &#39;-c&#39;, &#39;echo The app is running! &amp;&amp; sleep 3600&#39;]<span style=color:#bbb>
</span></span></span></code></pre></div><p>Ada sintaksis baru pada Kubernetes 1.6, walaupun sintaksis anotasi yang lama tetap akan bekerja untuk versi 1.6 dan 1.7. Sintaksis yang baru harus digunakan untuk versi 1.8 ke atas. Deklarasi Init Container dipindahkan ke dalam <code>spec</code>:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>myapp-pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>labels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>app</span>:<span style=color:#bbb> </span>myapp<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>myapp-container<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>busybox:1.28<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>command</span>:<span style=color:#bbb> </span>[<span style=color:#b44>&#39;sh&#39;</span>,<span style=color:#bbb> </span><span style=color:#b44>&#39;-c&#39;</span>,<span style=color:#bbb> </span><span style=color:#b44>&#39;echo The app is running! &amp;&amp; sleep 3600&#39;</span>]<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>initContainers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>init-myservice<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>busybox:1.28<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>command</span>:<span style=color:#bbb> </span>[<span style=color:#b44>&#39;sh&#39;</span>,<span style=color:#bbb> </span><span style=color:#b44>&#39;-c&#39;</span>,<span style=color:#bbb> </span><span style=color:#b44>&#39;until nslookup myservice; do echo waiting for myservice; sleep 2; done;&#39;</span>]<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>init-mydb<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>busybox:1.28<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>command</span>:<span style=color:#bbb> </span>[<span style=color:#b44>&#39;sh&#39;</span>,<span style=color:#bbb> </span><span style=color:#b44>&#39;-c&#39;</span>,<span style=color:#bbb> </span><span style=color:#b44>&#39;until nslookup mydb; do echo waiting for mydb; sleep 2; done;&#39;</span>]<span style=color:#bbb>
</span></span></span></code></pre></div><p>Sintaksis versi 1.5 tetap akan bekerja pada versi 1.6 dan 1.7, tetapi kami menyarankan untuk menggunakan sintaksis versi 1.6. Pada Kubernetes 1.6, Init Container dijadikan sebagai sebuah kolom di dalam API Kubernetes. Anotasi <em>beta</em> tetap akan diperhitungkan pada versi 1.6 dan 1.7, tetapi tidak didukung lagi pada versi 1.8 ke atas.</p><p><em>File</em> YAML di bawah menguraikan Service <code>mydb</code> dan <code>myservice</code>.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Service<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>myservice<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>ports</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>protocol</span>:<span style=color:#bbb> </span>TCP<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>port</span>:<span style=color:#bbb> </span><span style=color:#666>80</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>targetPort</span>:<span style=color:#bbb> </span><span style=color:#666>9376</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:#00f;font-weight:700>---</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Service<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>mydb<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>ports</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>protocol</span>:<span style=color:#bbb> </span>TCP<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>port</span>:<span style=color:#bbb> </span><span style=color:#666>80</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>targetPort</span>:<span style=color:#bbb> </span><span style=color:#666>9377</span><span style=color:#bbb>
</span></span></span></code></pre></div><p>Pod ini dapat dijalankan dan di-<em>debug</em> dengan menggunakan perintah berikut:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl apply -f myapp.yaml
</span></span></code></pre></div><pre tabindex=0><code>pod/myapp-pod created
</code></pre><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get -f myapp.yaml
</span></span></code></pre></div><pre tabindex=0><code>NAME        READY     STATUS     RESTARTS   AGE
myapp-pod   0/1       Init:0/2   0          6m
</code></pre><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl describe -f myapp.yaml
</span></span></code></pre></div><pre tabindex=0><code>Name:          myapp-pod
Namespace:     default
[...]
Labels:        app=myapp
Status:        Pending
[...]
Init Containers:
  init-myservice:
[...]
    State:         Running
[...]
  init-mydb:
[...]
    State:         Waiting
      Reason:      PodInitializing
    Ready:         False
[...]
Containers:
  myapp-container:
[...]
    State:         Waiting
      Reason:      PodInitializing
    Ready:         False
[...]
Events:
  FirstSeen    LastSeen    Count    From                      SubObjectPath                           Type          Reason        Message
  ---------    --------    -----    ----                      -------------                           --------      ------        -------
  16s          16s         1        {default-scheduler }                                              Normal        Scheduled     Successfully assigned myapp-pod to 172.17.4.201
  16s          16s         1        {kubelet 172.17.4.201}    spec.initContainers{init-myservice}     Normal        Pulling       pulling image &#34;busybox&#34;
  13s          13s         1        {kubelet 172.17.4.201}    spec.initContainers{init-myservice}     Normal        Pulled        Successfully pulled image &#34;busybox&#34;
  13s          13s         1        {kubelet 172.17.4.201}    spec.initContainers{init-myservice}     Normal        Created       Created container with docker id 5ced34a04634; Security:[seccomp=unconfined]
  13s          13s         1        {kubelet 172.17.4.201}    spec.initContainers{init-myservice}     Normal        Started       Started container with docker id 5ced34a04634
</code></pre><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl logs myapp-pod -c init-myservice <span style=color:#080;font-style:italic># Memeriksa Init Container pertama</span>
</span></span><span style=display:flex><span>kubectl logs myapp-pod -c init-mydb      <span style=color:#080;font-style:italic># Memeriksa Init Container kedua</span>
</span></span></code></pre></div><p>Saat kita menjalankan Service <code>mydb</code> dan <code>myservice</code>, kita dapat melihat Init Container telah selesai dan <code>myapp-pod</code> pun dibuat:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl apply -f services.yaml
</span></span></code></pre></div><pre tabindex=0><code>service/myservice created
service/mydb created
</code></pre><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get -f myapp.yaml
</span></span><span style=display:flex><span>NAME        READY     STATUS    RESTARTS   AGE
</span></span><span style=display:flex><span>myapp-pod   1/1       Running   <span style=color:#666>0</span>          9m
</span></span></code></pre></div><p>Contoh ini sangat sederhana, tetapi dapat memberikan sedikit petunjuk bagi kamu untuk membuat Init Container sendiri.</p><h2 id=perilaku-mendetail>Perilaku mendetail</h2><p>Saat dimulainya sebuah Pod, Init Container dijalankan secara berurutan, setelah jaringan dan <em>volume</em> telah diinisialisasi. Setiap Init Container harus selesai dan keluar secara berhasil sebelum yang berikutnya dijalankan. Jika ada Init Container yang gagal dijalankan atau keluar secara gagal, dia akan diulang kembali sesuai dengan <code>restartPolicy</code> yang dimiliki Pod. Tetapi, jika <code>restartPolicy</code> Pod disetel dengan nilai <code>Always</code>, Init Container akan menggunakan strategi <code>RestartPolicy</code> <code>OnFailure</code>.</p><p>Sebuah Pod tidak dapat masuk ke status <code>Ready</code> hingga semua Init Container berhasil selesai. <em>Port</em> di sebuah Init Container tidak diagregasikan di dalam sebuah Service. Sebuah Pod yang sedang diinisalisasikan akan masuk ke dalam status <code>Pending</code>, tetapi akan memiliki kondisi <code>Initialized</code> yang disetel menjadi <code>true</code>.</p><p>Jika sebuah Pod diulang <a href=#alasan-pod-diulang-kembali>kembali</a>, semua Init Container harus dijalankan kembali.</p><p>Perubahan pada spesifikasi Init Container dibatasi hanya pada kolom <code>image</code> pada Init Container. Mengganti kolom <code>image</code> sebuah Init Container sama dengan mengulang kembali Pod tersebut.</p><p>Karena Init Container dapat diulang kembali, dicoba ulang, atau dijalankan ulang, Init Container sebaiknya bersifat <em>idempotent</em>. Khususnya, kode yang menulis ke dalam <em>file</em> pada <code>EmptyDir</code> sebaiknya dipersiapkan untuk menangani kemungkinan jika <em>file</em> keluaran yang diharapkan sudah ada di dalam <code>EmptyDir</code> tersebut.</p><p>Init Container memiliki semua kolom yang dimiliki oleh Container aplikasi. Tetapi, Kubernetes melarang penggunaan <code>readinessProbe</code> karena Init Container tidak dapat mendefinisikan/menggunakan <em>readiness probe</em> setelah selesai/keluar secara berhasil. Hal ini dipaksakan saat proses validasi.</p><p>Gunakan <code>activeDeadlineSeconds</code> pada Pod dan <code>livenessProbe</code> pada Container untuk mencegah Init Container gagal terus menerus. Nilai <code>activeDeadlineSeconds</code> berlaku juga terhadap Init Container.</p><p>Nama setiap Container aplikasi dan Init Container pada sebuah Pod haruslah unik; Kesalahan validasi akan terjadi jika ada Container atau Init Container yang memiliki nama yang sama.</p><h3 id=sumber-daya>Sumber Daya</h3><p>Karena eksekusi Init Container yang berurutan, aturan-aturan untuk sumber daya berlaku sebagai berikut:</p><ul><li>Yang tertinggi antara <code>request</code> atau <code>limit</code> sumber daya yang didefinisikan pada <strong>semua Init Container</strong> adalah <strong><code>request</code>/<code>limit</code> inisialisasi yang berlaku</strong>.</li><li><code>request</code>/<code>limit</code> sumber daya Pod yang berlaku adalah yang paling besar diantara:<ul><li>Jumah <code>request</code>/<code>limit</code> semua Container aplikasi untuk suatu sumber daya.</li><li><code>request</code>/<code>limit</code> inisialisasi yang berlaku untuk suatu sumber daya.</li></ul></li><li>Penjadwalan dilakukan berdasarkan <code>request</code>/<code>limit</code> (Pod) yang berlaku, yang berarti bahwa Init Container dapat mengambil sumber daya inisialisasi yang tidak digunakan selama umur Pod tersebut.</li><li><strong>Tingkat QoS yang berlaku</strong> milik Pod adalah sama dengan tingkat QoS untuk Init Container dan Container aplikasi.</li></ul><p><code>ResourceQuota</code> dan <code>limitedResources</code> diberlakukan berdasarkan <code>request</code> dan <code>limit</code> Pod yang berlaku.</p><p>Cgroup pada tingat Pod didasarkan pada <code>request</code> dan <code>limit</code> Pod yang berlaku, sama dengan <em>scheduler</em>.</p><h3 id=alasan-pod-diulang-kembali>Alasan Pod diulang kembali</h3><p>Pod dapat diulang kembali, yang berakibat pada diulangnya eksekusi Init Container, diakibatkan oleh beberapa alasan berikut:</p><ul><li>Seorang pengguna memperbarui <code>PodSpec</code>, mengakibatkan <code>image</code> Init Container berubah. Perubahan apapun pada <code>image</code> Init Container akan mengulang kembali Pod tersebut. Perubahan pada <code>image</code> Container aplikasi hanya mengulang kembali Container aplikasi yang bersangkutan.</li><li>Infrastruktur Container Pod diulang kembali. Hal ini jarang terjadi, dan hanya dapat dilakukan oleh seseorang yang memiliki akses <em>root</em> pada <em>node</em> yang bersangkutan.</li><li>Semua Container di dalam Pod diterminasi, dengan nilai <code>restartPolicy</code> yang disetel sebagai <code>Always</code>, memaksa pengulangan kembali, dan catatan selesainya Init Container telah hilang karena <em>garbage collection</em>.</li></ul><h2 id=dukungan-dan-kompatibilitas>Dukungan dan kompatibilitas</h2><p>Sebuah klaster dengan versi Apiserver 1.6.0 ke atas mendukung Init Container melalui kolom <code>.spec.initContainers</code>. Versi-versi sebelumnya mendukung Init Container melalui anotasi <em>alpha</em> atau <em>beta</em>. Kolom <code>.spec.initContainers</code> juga diduplikasikan dalam bentuk anotasi <em>alpha</em> dan <em>beta</em> agar Kubelet versi 1.3.0 ke atas dapat menjalankan Init Container, dan agar Apiserver versi 1.6 dapat dengan aman dikembalikan ke versi 1.5.x tanpa kehilangan fungsionalitas Pod-pod yang telah dibuat sebelumnya.</p><p>Pada Apiserver dan Kubelet versi 1.8.0 ke atas, dukungan untuk anotasi <em>alpha</em> dan <em>beta</em> telah dihapus, sehingga dibutuhkan konversi (manual) dari anotasi yang telah kedaluwarsa tersebut ke dalam bentuk kolom <code>.spec.initContainers</code>.</p><h2 id=selanjutnya>Selanjutnya</h2><ul><li><a href=/docs/tasks/configure-pod-container/configure-pod-initialization/#creating-a-pod-that-has-an-init-container>Membuat Pod yang memiliki Init Container</a></li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-c8d62295ca703fdcef1aaf89fb4c916a>4.1.5 - Batasan Persebaran Topologi Pod</h1><div style=margin-top:10px;margin-bottom:10px><b>FEATURE STATE:</b> <code>Kubernetes v1.18 [beta]</code></div><p>Kamu dapat menggunakan batasan perseberan topologi (<em>topology spread constraints</em>)
untuk mengatur bagaimana <a class=glossary-tooltip title='Unit Kubernetes yang paling sederhana dan kecil. Sebuah Pod merepresentasikan sebuah set kontainer yang dijalankan pada kluster kamu.' data-toggle=tooltip data-placement=top href=/docs/concepts/workloads/pods/pod-overview/ target=_blank aria-label=Pod>Pod</a> akan disebarkan
pada klaster yang ditetapkan sebagai <em>failure-domains</em>, seperti wilayah, zona, Node dan domain
topologi yang ditentukan oleh pengguna. Ini akan membantu untuk mencapai ketersediaan yang tinggi
dan juga penggunaan sumber daya yang efisien.</p><h2 id=persyaratan>Persyaratan</h2><h3 id=mengaktifkan-gerbang-fitur>Mengaktifkan Gerbang Fitur</h3><p><a href=/docs/reference/command-line-tools-reference/feature-gates/>Gerbang fitur (<em>feature gate</em>)</a>
<code>EvenPodsSpread</code> harus diaktifkan untuk
<a class=glossary-tooltip title='Komponen control plane yang mengekspos API Kubernetes. Merupakan front-end dari control plane Kubernetes.' data-toggle=tooltip data-placement=top href=/docs/reference/generated/kube-apiserver/ target=_blank aria-label='API Server'>API Server</a> <strong>dan</strong>
<a class=glossary-tooltip title='Komponen control plane yang bertugas mengamati Pod baru yang belum ditempatkan di node manapun dan kemudian memilihkan node di mana Pod baru tersebut akan dijalankan.' data-toggle=tooltip data-placement=top href=/docs/reference/generated/kube-scheduler/ target=_blank aria-label='penjadwal (_scheduler_)'>penjadwal (_scheduler_)</a>.</p><h3 id=label-node>Label Node</h3><p>Batasan persebaran topologi bergantung dengan label pada Node untuk menentukan
domain topologi yang memenuhi untuk semua Node. Misalnya saja, sebuah Node bisa memiliki
label sebagai berikut: <code>node=node1,zone=us-east-1a,region=us-east-1</code></p><p>Misalkan kamu memiliki klaster dengan 4 Node dengan label sebagai berikut:</p><pre tabindex=0><code>NAME    STATUS   ROLES    AGE     VERSION   LABELS
node1   Ready    &lt;none&gt;   4m26s   v1.16.0   node=node1,zone=zoneA
node2   Ready    &lt;none&gt;   3m58s   v1.16.0   node=node2,zone=zoneA
node3   Ready    &lt;none&gt;   3m17s   v1.16.0   node=node3,zone=zoneB
node4   Ready    &lt;none&gt;   2m43s   v1.16.0   node=node4,zone=zoneB
</code></pre><p>Maka klaster tersebut secara logika akan dilihat sebagai berikut:</p><pre tabindex=0><code>+---------------+---------------+
|     zoneA     |     zoneB     |
+-------+-------+-------+-------+
| node1 | node2 | node3 | node4 |
+-------+-------+-------+-------+
</code></pre><p>Tanpa harus memberi label secara manual, kamu dapat menggunakan [label ternama]
(/docs/reference/kubernetes-api/labels-annotations-taints/) yang terbuat dan terkumpulkan
secara otomatis pada kebanyakan klaster.</p><h2 id=batasan-persebaran-untuk-pod>Batasan Persebaran untuk Pod</h2><h3 id=api>API</h3><p><em>Field</em> <code>pod.spec.topologySpreadConstraints</code> diperkenalkan pada versi 1.16 sebagai berikut:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>mypod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>topologySpreadConstraints</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>maxSkew</span>:<span style=color:#bbb> </span>&lt;integer&gt;<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>minDomains</span>:<span style=color:#bbb> </span>&lt;integer&gt;<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>topologyKey</span>:<span style=color:#bbb> </span>&lt;string&gt;<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>whenUnsatisfiable</span>:<span style=color:#bbb> </span>&lt;string&gt;<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>labelSelector</span>:<span style=color:#bbb> </span>&lt;object&gt;<span style=color:#bbb>
</span></span></span></code></pre></div><p>Kamu dapat mendefinisikan satu atau lebih <code>topologySpreadConstraint</code> untuk menginstruksikan
kube-scheduler mengenai cara peletakan tiap Pod baru dengan menggunakan kondisi Pod yang
sudah ada dalam klaster kamu. <em>Field</em> yang ada adalah:</p><ul><li><strong>maxSkew</strong> menentukan batasan yang menandakan Pod tidak tersebar secara merata.
Ini merupakan nilai maksimal dari selisih jumlah Pod yang sama untuk setiap 2 domain topologi
yang sama. Nilai ini harus lebih dari 0.</li><li><strong>topologyKey</strong> adalah kunci dari label Node. Jika terdapat dua Node memiliki label dengan
kunci ini dan memiliki nilai yang identik untuk label tersebut, maka penjadwal akan menganggap
kedua Noode dalam topologi yang sama. Penjadwal akan mencoba untuk menyeimbangkan jumlah Pod
dalam setiap domain topologi.</li><li><strong>whenUnsatisfiable</strong> mengindikasikan cara menangani Pod yang tidak memenuhi batasan persebaran:<ul><li><code>DoNotSchedule</code> (<em>default</em>) memberitahukan penjadwal untuk tidak menjadwalkan Pod tersebut.</li><li><code>ScheduleAnyway</code> memberitahukan penjadwal untuk tetap menjadwalkan Pod namun tetap menjaga ketidakseimbangan Node sekecil mungkin.</li></ul></li><li><strong>labelSelector</strong> digunakan untuk mencari Pod yang sesuai. Pod dengan label yang sama dengan ini akan dihitung untuk menentukan jumlah Pod dalam domain topologi yang sesuai. Silakan baca <a href=/id/docs/concepts/overview/working-with-objects/labels/#selektor-label>Label dan Selector</a> untuk lebih detailnya.</li></ul><p>Kamu juga bisa membaca lebih detail mengenai <em>field</em> ini dengan menjalankan perintah
<code>kubectl explain Pod.spec.topologySpreadConstraints</code>.</p><h3 id=contoh-satu-topologyspreadconstraint>Contoh: Satu TopologySpreadConstraint</h3><p>Misalkan kamu memiliki klaster dengan 4 Node dimana 3 Pod berlabel <code>foo:bar</code> terdapat pada node1,
node2 dan node3 (<code>P</code> merepresentasikan Pod):</p><pre tabindex=0><code>+---------------+---------------+
|     zoneA     |     zoneB     |
+-------+-------+-------+-------+
| node1 | node2 | node3 | node4 |
+-------+-------+-------+-------+
|   P   |   P   |   P   |       |
+-------+-------+-------+-------+
</code></pre><p>Jika kita ingin Pod baru akan disebar secara merata berdasarkan Pod yang telah ada pada semua zona,
maka <em>spec</em> bernilai sebagai berikut:</p><div class=highlight><div class=copy-code-icon style=text-align:right><a href=https://raw.githubusercontent.com/kubernetes/website/main/content/id/examples/pods/topology-spread-constraints/one-constraint.yaml download=pods/topology-spread-constraints/one-constraint.yaml><code>pods/topology-spread-constraints/one-constraint.yaml</code></a>
<img src=/images/copycode.svg style=max-height:24px;cursor:pointer onclick='copyCode("pods-topology-spread-constraints-one-constraint-yaml")' title="Copy pods/topology-spread-constraints/one-constraint.yaml to clipboard"></img></div><div class=includecode id=pods-topology-spread-constraints-one-constraint-yaml><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>mypod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>labels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>foo</span>:<span style=color:#bbb> </span>bar<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>topologySpreadConstraints</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>maxSkew</span>:<span style=color:#bbb> </span><span style=color:#666>1</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>topologyKey</span>:<span style=color:#bbb> </span>zone<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>whenUnsatisfiable</span>:<span style=color:#bbb> </span>DoNotSchedule<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>labelSelector</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>matchLabels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>foo</span>:<span style=color:#bbb> </span>bar<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>pause<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>k8s.gcr.io/pause:3.1</span></span></code></pre></div></div></div><p><code>topologyKey: zone</code> berarti persebaran merata hanya akan digunakan pada Node dengan pasangan label
"zone: <nilai apapun>". <code>whenUnsatisfiable: DoNotSchedule</code> memberitahukan penjadwal untuk membiarkan
tetap ditunda jika Pod yang baru tidak memenuhi batasan yang diterapkan.</p><p>Jika penjadwal menempatkan Pod baru pada "zoneA", persebaran Pod akan menjadi [3, 1], menjadikan
ketidakseimbangan menjadi bernilai 2 (3 - 1), yang mana akan melanggar batasan <code>maxSkew: 1</code>.
Dalam contoh ini, Pod baru hanya dapat ditempatkan pada "zoneB":</p><pre tabindex=0><code>+---------------+---------------+      +---------------+---------------+
|     zoneA     |     zoneB     |      |     zoneA     |     zoneB     |
+-------+-------+-------+-------+      +-------+-------+-------+-------+
| node1 | node2 | node3 | node4 |  OR  | node1 | node2 | node3 | node4 |
+-------+-------+-------+-------+      +-------+-------+-------+-------+
|   P   |   P   |   P   |   P   |      |   P   |   P   |  P P  |       |
+-------+-------+-------+-------+      +-------+-------+-------+-------+
</code></pre><p>Kamu dapat mengatur spesifikasi Pod untuk memenuhi beberapa persyaratan berikut:</p><ul><li>Ubah nilai <code>maxSkew</code> menjadi lebih besar, misal "2", sehingga Pod baru dapat ditempatkan pada "zoneA".</li><li>Ubah nilai <code>topologyKey</code> menjadi "node" agar Pod disebarkan secara merata pada semua Node, bukan zona. Pada contoh di atas, jika <code>maxSkew</code> tetap bernilai "1", maka Pod baru hanya akan ditempatkan pada "node4".</li><li>Ubah nilai <code>whenUnsatisfiable: DoNotSchedule</code> menjadi <code>whenUnsatisfiable: ScheduleAnyway</code> untuk
menjamin agar semua Pod baru akan tetap dijadwalkan (misalkan saja API penjadwalan lain tetap
terpenuhi). Namun, ini lebih suka ditempatkan pada domain topologi yang memiliki lebih sedikit
Pod yang sesuai. (Harap diperhatikan bahwa preferensi ini digabungkan bersama dengan prioritas
penjadwalan internal yang lain, seperti rasio penggunaan sumber daya, dan lain sebagainya.)</li></ul><h3 id=contoh-beberapa-topologyspreadconstraint>Contoh: Beberapa TopologySpreadConstraint</h3><p>Ini dibuat berdasarkan contoh sebelumnya. Misalkan kamu memiliki klaster dengan 4 Node dengan
3 Pod berlabel <code>foo:bar</code> yang ditempatkan pada node1, node2 dan node3. (<code>P</code> merepresentasikan Pod):</p><pre tabindex=0><code>+---------------+---------------+
|     zoneA     |     zoneB     |
+-------+-------+-------+-------+
| node1 | node2 | node3 | node4 |
+-------+-------+-------+-------+
|   P   |   P   |   P   |       |
+-------+-------+-------+-------+
</code></pre><p>Kamu dapat menggunakan 2 TopologySpreadConstraint untuk mengatur persebaran Pod pada zona dan Node:</p><div class=highlight><div class=copy-code-icon style=text-align:right><a href=https://raw.githubusercontent.com/kubernetes/website/main/content/id/examples/pods/topology-spread-constraints/two-constraints.yaml download=pods/topology-spread-constraints/two-constraints.yaml><code>pods/topology-spread-constraints/two-constraints.yaml</code></a>
<img src=/images/copycode.svg style=max-height:24px;cursor:pointer onclick='copyCode("pods-topology-spread-constraints-two-constraints-yaml")' title="Copy pods/topology-spread-constraints/two-constraints.yaml to clipboard"></img></div><div class=includecode id=pods-topology-spread-constraints-two-constraints-yaml><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>mypod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>labels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>foo</span>:<span style=color:#bbb> </span>bar<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>topologySpreadConstraints</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>maxSkew</span>:<span style=color:#bbb> </span><span style=color:#666>1</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>topologyKey</span>:<span style=color:#bbb> </span>zone<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>whenUnsatisfiable</span>:<span style=color:#bbb> </span>DoNotSchedule<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>labelSelector</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>matchLabels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>foo</span>:<span style=color:#bbb> </span>bar<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>maxSkew</span>:<span style=color:#bbb> </span><span style=color:#666>1</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>topologyKey</span>:<span style=color:#bbb> </span>node<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>whenUnsatisfiable</span>:<span style=color:#bbb> </span>DoNotSchedule<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>labelSelector</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>matchLabels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>foo</span>:<span style=color:#bbb> </span>bar<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>pause<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>k8s.gcr.io/pause:3.1</span></span></code></pre></div></div></div><p>Dalam contoh ini, untuk memenuhi batasan pertama, Pod yang baru hanya akan ditempatkan pada "zoneB",
sedangkan untuk batasan kedua, Pod yang baru hanya akan ditempatkan pada "node4". Maka hasil dari
2 batasan ini akan digunakan (<em>AND</em>), sehingga opsi untuk menempatkan Pod hanya pada "node4".</p><p>Beberapa batasan dapat berujung pada konflik. Misalnya saja kamu memiliki klaster dengan 3 Node
pada 2 zona berbeda:</p><pre tabindex=0><code>+---------------+-------+
|     zoneA     | zoneB |
+-------+-------+-------+
| node1 | node2 | node3 |
+-------+-------+-------+
|  P P  |   P   |  P P  |
+-------+-------+-------+
</code></pre><p>Jika kamu menerapkan "two-constraints.yaml" pada klaster ini, kamu akan mendapatkan "mypod" tetap
dalam kondisi <code>Pending</code>. Ini dikarenakan oleh: untuk memenuhi batasan pertama, "mypod" hanya dapat
ditempatkan pada "zoneB", sedangkan untuk batasan kedua, "mypod" hanya dapat ditempatkan pada
"node2". Tidak ada hasil penggabungan dari "zoneB" dan "node2".</p><p>Untuk mengatasi situasi ini, kamu bisa menambahkan nilai <code>maxSkew</code> atau mengubah salah satu dari
batasan untuk menggunakan <code>whenUnsatisfiable: ScheduleAnyway</code>.</p><h3 id=konvensi>Konvensi</h3><p>Ada beberapa konvensi implisit yang perlu diperhatikan di sini:</p><ul><li><p>Hanya Pod dengan Namespace yang sama dengan Pod baru yang bisa menjadi kandidat yang cocok.</p></li><li><p>Node tanpa memiliki <code>topologySpreadConstraints[*].topologyKey</code> akan dilewatkan. Ini berarti:</p><ol><li>Pod yang ditempatkan pada Node tersebut tidak berpengaruh pada perhitungan <code>maxSkew</code>. Dalam contoh di atas, misalkan "node1" tidak memiliki label "zone", maka kedua Pod tidak diperhitungkan dan menyebabkan Pod yang baru akan dijadwalkan masuk ke "zoneA".</li><li>Pod yang baru tidak memiliki kesempatan untuk dijadwalkan ke Node tersebut, pada contoh di atas, misalkan terdapat "node5" dengan label <code>{zone-typo: zoneC}</code> bergabung dalam klaster, Node ini akan dilewatkan karena tidak memiliki label dengan kunci "zone".</li></ol></li><li><p>Harap diperhatikan mengenai hal yang terjadi jika nilai <code>topologySpreadConstraints[*].labelSelector</code> pada Pod yang baru tidak sesuai dengan labelnya.
Pada contoh di atas, jika kita menghapus label pada Pod yang baru, maka Pod akan tetap ditempatkan
pada "zoneB" karena batasan yang ada masih terpenuhi. Namun, setelah ditempatkan, nilai
ketidakseimbangan pada klaster masih tetap tidak berubah, zoneA tetap memiliki 2 Pod dengan label
{foo:bar} dan zoneB memiliki 1 Pod dengan label {foo:bar}. Jadi jika ini tidak yang kamu harapkan,
kami menyarankan nilai dari <code>topologySpreadConstraints[*].labelSelector</code> disamakan dengan labelnya.</p></li><li><p>Jika Pod yang baru memiliki <code>spec.nodeSelector</code> atau <code>spec.affinity.nodeAffinity</code>, Node yang tidak
sesuai dengan nilai tersebut akan dilewatkan.</p><p>Misalkan kamu memiliki klaster dengan 5 Node dari zoneA sampai zoneC:</p><pre tabindex=0><code>+---------------+---------------+-------+
|     zoneA     |     zoneB     | zoneC |
+-------+-------+-------+-------+-------+
| node1 | node2 | node3 | node4 | node5 |
+-------+-------+-------+-------+-------+
|   P   |   P   |   P   |       |       |
+-------+-------+-------+-------+-------+
</code></pre><p>dan kamu mengetahui bahwa "zoneC" harus tidak diperhitungkan. Dalam kasus ini, kamu dapat membuat
berkas yaml seperti di bawah, jadi "mypod" akan ditempatkan pada "zoneB", bukan "zoneC".
Demikian juga <code>spec.nodeSelector</code> akan digunakan.</p><div class=highlight><div class=copy-code-icon style=text-align:right><a href=https://raw.githubusercontent.com/kubernetes/website/main/content/id/examples/pods/topology-spread-constraints/one-constraint-with-nodeaffinity.yaml download=pods/topology-spread-constraints/one-constraint-with-nodeaffinity.yaml><code>pods/topology-spread-constraints/one-constraint-with-nodeaffinity.yaml</code></a>
<img src=/images/copycode.svg style=max-height:24px;cursor:pointer onclick='copyCode("pods-topology-spread-constraints-one-constraint-with-nodeaffinity-yaml")' title="Copy pods/topology-spread-constraints/one-constraint-with-nodeaffinity.yaml to clipboard"></img></div><div class=includecode id=pods-topology-spread-constraints-one-constraint-with-nodeaffinity-yaml><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Pod<span style=color:#bbb>
    </span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
    </span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
    </span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>mypod<span style=color:#bbb>
    </span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>labels</span>:<span style=color:#bbb>
    </span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>foo</span>:<span style=color:#bbb> </span>bar<span style=color:#bbb>
    </span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
    </span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>topologySpreadConstraints</span>:<span style=color:#bbb>
    </span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>maxSkew</span>:<span style=color:#bbb> </span><span style=color:#666>1</span><span style=color:#bbb>
    </span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>topologyKey</span>:<span style=color:#bbb> </span>zone<span style=color:#bbb>
    </span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>whenUnsatisfiable</span>:<span style=color:#bbb> </span>DoNotSchedule<span style=color:#bbb>
    </span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>labelSelector</span>:<span style=color:#bbb>
    </span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>matchLabels</span>:<span style=color:#bbb>
    </span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>foo</span>:<span style=color:#bbb> </span>bar<span style=color:#bbb>
    </span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>affinity</span>:<span style=color:#bbb>
    </span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>nodeAffinity</span>:<span style=color:#bbb>
    </span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>requiredDuringSchedulingIgnoredDuringExecution</span>:<span style=color:#bbb>
    </span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>nodeSelectorTerms</span>:<span style=color:#bbb>
    </span></span></span><span style=display:flex><span><span style=color:#bbb>        </span>- <span style=color:green;font-weight:700>matchExpressions</span>:<span style=color:#bbb>
    </span></span></span><span style=display:flex><span><span style=color:#bbb>          </span>- <span style=color:green;font-weight:700>key</span>:<span style=color:#bbb> </span>zone<span style=color:#bbb>
    </span></span></span><span style=display:flex><span><span style=color:#bbb>            </span><span style=color:green;font-weight:700>operator</span>:<span style=color:#bbb> </span>NotIn<span style=color:#bbb>
    </span></span></span><span style=display:flex><span><span style=color:#bbb>            </span><span style=color:green;font-weight:700>values</span>:<span style=color:#bbb>
    </span></span></span><span style=display:flex><span><span style=color:#bbb>            </span>- zoneC<span style=color:#bbb>
    </span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
    </span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>pause<span style=color:#bbb>
    </span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>k8s.gcr.io/pause:3.1</span></span></code></pre></div></div></div></li></ul><h3 id=batasan-default-pada-tingkat-klaster>Batasan <em>default</em> pada tingkat klaster</h3><div style=margin-top:10px;margin-bottom:10px><b>FEATURE STATE:</b> <code>Kubernetes v1.18 [alpha]</code></div><p>Ini memungkinkan untuk mengatur batasan persebaran topologi bawaan untuk klaster.
Batasan persebaran topologi bawaan akan digunakan pada Pod jika dan hanya jika:</p><ul><li>Hal ini tidak mendefinisikan batasan apapun pada <code>.spec.topologySpreadConstraints</code>.</li><li>Hal ini milik sebuah Service, ReplicationController, ReplicaSet atau StatefulSet.</li></ul><p>Batasan bawaan akan diatur sebagai bagian dari argumen pada <em>plugin</em> <code>PodTopologySpread</code>
di dalam sebuah <a href=/docs/reference/scheduling/profiles>profil penjadwalan</a>.
Batasan dispesifikasikan dengan <a href=#api>API yang sama dengan di atas</a>, kecuali bagian <code>labelSelector</code>
harus kosong. <em>selector</em> akan dihitung dari Service, ReplicationController, ReplicaSet atau
StatefulSet yang dimiliki oleh Pod tersebut.</p><p>Sebuah contoh konfigurasi sebagai berikut:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>kubescheduler.config.k8s.io/v1alpha2<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>KubeSchedulerConfiguration<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>profiles</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>pluginConfig</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>PodTopologySpread<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>args</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>defaultConstraints</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>            </span>- <span style=color:green;font-weight:700>maxSkew</span>:<span style=color:#bbb> </span><span style=color:#666>1</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>              </span><span style=color:green;font-weight:700>topologyKey</span>:<span style=color:#bbb> </span>topology.kubernetes.io/zone<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>              </span><span style=color:green;font-weight:700>whenUnsatisfiable</span>:<span style=color:#bbb> </span>ScheduleAnyway<span style=color:#bbb>
</span></span></span></code></pre></div><div class="alert alert-info note callout" role=alert><strong>Catatan:</strong> Nilai yang dihasilkan oleh batasan penjadwalan bawaan mungkin akan konflik dengan
nilai yang dihasilkan oleh
<a href=/docs/reference/scheduling/profiles/#scheduling-plugins><code>DefaultPodTopologySpread</code> plugin</a>.
Direkomendasikan untuk kamu menonaktifkan <em>plugin</em> ini dalam profil penjadwalan ketika
menggunakan batasan <em>default</em> untuk <code>PodTopologySpread</code>.</div><h2 id=perbandingan-dengan-podaffinity-podantiaffinity>Perbandingan dengan PodAffinity/PodAntiAffinity</h2><p>Di Kubernetes, arahan yang terkait dengan "Afinitas" mengontrol bagaimana Pod dijadwalkan -
lebih terkumpul atau lebih tersebar.</p><ul><li>Untuk <code>PodAffinity</code>, kamu dapat mencoba mengumpulkan beberapa Pod ke dalam suatu
domain topologi yang memenuhi syarat.</li><li>Untuk <code>PodAntiAffinity</code>, hanya satu Pod yang dalam dijadwalkan pada sebuah domain topologi.</li></ul><p>Fitur "EvenPodsSpread" memberikan opsi fleksibilas untuk mendistribusikan Pod secara merata
pada domain topologi yang berbeda, untuk meraih ketersediaan yang tinggi atau menghemat biaya.
Ini juga dapat membantu saat perbaruan bergilir dan menaikan jumlah replika dengan lancar.
Silakan baca <a href=https://github.com/kubernetes/enhancements/blob/master/keps/sig-scheduling/20190221-even-pods-spreading.md#motivation>motivasi</a> untuk lebih detail.</p><h2 id=limitasi-yang-diketahui>Limitasi yang diketahui</h2><p>Pada versi 1.18, dimana fitur ini masih Beta, beberapa limitasi yang sudah diketahui:</p><ul><li>Pengurangan jumlah Deployment akan membuat ketidakseimbangan pada persebaran Pod.</li><li>Pod yang cocok pada <em>tainted</em> Node akan dihargai. Lihat <a href=https://github.com/kubernetes/kubernetes/issues/80921>Issue 80921</a></li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-4e9b9cbc9776b12e7335c53da377c9c8>4.1.6 - Pod Preset</h1><p>Halaman ini menyajikan gambaran umum tentang PodPreset, yang merupakan objek untuk memasukkan informasi tertentu ke dalam Pod pada saat waktu penciptaan. Informasi dapat berupa <em>secret</em>, <em>volume</em>, <em>volume mount</em>, dan variabel <em>environment</em>.</p><h2 id=memahami-pod-preset>Memahami Pod Preset</h2><hr><p>Sebuah <code>Pod Preset</code> adalah sebuah <em>resource</em> API untuk memasukkan kebutuhan <em>runtime</em> tambahan ke dalam sebuah Pod pada saat waktu penciptaan. Kamu akan menggunakan <em>label selector</em> untuk menunjuk Pod dimana Pod Preset diterapkan.</p><p>Menggunakan sebuah Pod Preset memungkinkan pembuat templat pod untuk tidak menyediakan secara eksplisit semua informasi untuk setiap pod. Dengan demikian, pembuat templat pod yang mengkonsumsi sebuah <em>service</em> spesifik tidak perlu tahu semua detail-detail tentang <em>service</em> tersebut.</p><p>Untuk informasi lebih lanjut mengenai latar belakang lihat <a href=https://github.com/kubernetes/community/blob/master/contributors/design-proposals/service-catalog/pod-preset.md>proposal desain untuk PodPreset</a>.</p><h2 id=bagaimana-cara-kerja-pod-preset>Bagaimana Cara Kerja Pod Preset</h2><hr><p>Kubernetes menyediakan sebuah <em>admission controller</em> (<code>PodPreset</code>) dimana, ketika diaktifkan, PodPreset diterapkan kepada permintaan penciptaan Pod yang akan datang. Ketika sebuah penciptaan Pod terjadi, sistem melakukan hal-hal berikut:</p><ol><li>Mengambil semua <code>PodPreset</code> yang tersedia untuk digunakan.</li><li>Cek jika <em>label selector</em> dari salah satu <code>PodPreset</code> cocok dengan <em>label</em> pada pod yang sedang diciptakan.</li><li>Usaha untuk menggabungkan berbagai <em>resource</em> didefinisikan oleh <code>PodPreset</code> ke dalam Pod yang sedang diciptakan.</li><li>Ketika terjadi galat, lempar sebuah <em>event</em> yang mendokumentasikan galat penggabungan dalam pod, dan membuat pod tanpa salah satu <em>resource</em> dari <code>PodPreset</code>.</li><li>Anotasikan hasil spesifikasi Pod yang telah dimodifikasi untuk menunjukkan bahwa Pod telah dimodifikasi oleh sebuah PodPreset. Anotasi berupa <code>podpreset.admission.kubernetes.io/podpreset-&lt;nama pod-preset>: "&lt;versi resource>"</code>.</li></ol><p>Tiap Pod akan bisa dipasangkan oleh nol atau lebih PodPreset; dan tiap PodPreset bisa diterapkan ke nol atau lebih Pod. Ketika sebuah PodPreset diterapkan ke satu atau lebih Pod, Kubernetes memodifikasi Pod Spec. Untuk perubahan terhadap <code>Env</code>,<code>EnvFrom</code>, dan <code>VolumeMount</code>, Kubernetes memodifikasi spesifikasi kontainer untuk semua kontainer di dalam Pod; Untuk perubahan terhadap <code>Volume</code>, Kubernetes memodifikasi Pod Spec.</p><div class="alert alert-info note callout" role=alert><strong>Catatan:</strong> Sebuah Pod Preset mampu memodifikasi kolom <code>.spec.containers</code> pada sebuah Pod Spec jika sesuai. Tidak ada definisi resource dari Pod Preset yang akan diterapkan kepada kolom <code>initContainer</code>.</div><h3 id=menonaktifkan-pod-preset-untuk-sebuah-pod-spesifik>Menonaktifkan Pod Preset untuk sebuah Pod Spesifik</h3><p>Mungkin akan ada keadaan dimana kamu menginginkan sebuah Pod tidak bisa diubah oleh sebuah mutasi PodPreset. Pada kasus ini, kamu bisa menambahkan sebuah anotasi pada Pod Spec dalam bentuk: <code>podpreset.admission.kubernetes.io/exclude: "true"</code>.</p><h2 id=mengaktifkan-pod-preset>Mengaktifkan Pod Preset</h2><hr><p>Dalam rangka untuk menggunakan Pod Preset di dalam klaster kamu, kamu harus memastikan hal berikut:</p><ol><li><p>Kamu telah mengaktifkan tipe API <code>settings.k8s.io/v1alpha1/podpreset</code>. Sebagai contoh, ini bisa dilakukan dengan menambahkan <code>settings.k8s.io/v1alpha1=true</code> di dalam opsi <code>--runtime-config</code> untuk API <em>server</em>. Dalam <em>minikube</em> tambahkan argumen berikut <code>--extra-config=apiserver.runtime-config=settings.k8s.io/v1alpha1=true</code> saat menginisialisasi klaster.</p></li><li><p>Kamu telah mengaktifkan <em>admission controller</em> dari <code>PodPreset</code>. Salah satu cara untuk melakukannya adalah dengan menambahkan <code>PodPreset</code> di dalam nilai opsi <code>--enable-admission-plugins</code> yang dispesifikasikan untuk API <em>server</em>. Dalam <em>minikube</em> tambahkan argumen berikut</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>--extra-config<span style=color:#666>=</span>apiserver.enable-admission-plugins<span style=color:#666>=</span>NamespaceLifecycle,LimitRanger,ServiceAccount,DefaultStorageClass,DefaultTolerationSeconds,NodeRestriction,MutatingAdmissionWebhook,ValidatingAdmissionWebhook,ResourceQuota,PodPreset
</span></span></code></pre></div><p>saat menginisialisasi klaster.</p></li><li><p>Kamu telah membuat objek <code>PodPreset</code> pada <em>namespace</em> yang kamu gunakan dengan cara mendefinisikan Pod Preset.</p></li></ol><h2 id=selanjutnya>Selanjutnya</h2><ul><li><a href=/id/docs/concepts/workloads/pods/pod/#injecting-data-into-a-pod-using-podpreset.md>Memasukkan data ke dalam sebuah Pod dengan PodPreset</a></li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-4aaf43c715cd764bc8ed4436f3537e68>4.1.7 - Disrupsi</h1><p>Petunjuk ini ditujukan pada pemilik aplikasi yang meninginkan aplikasinya memiliki ketersediaan yang tinggi, sehingga butuh untuk mengerti jenis-jenis Disrupsi yang dapat terjadi pada Pod-pod.</p><p>Petunjuk ini juga ditujukan pada administrator klaster yang ingin melakukan berbagai tindakan otomasi pada klaster, seperti pembaruan dan <em>autoscaling</em> klaster.</p><h2 id=disrupsi-yang-disengaja-dan-tidak-disengaja>Disrupsi yang Disengaja dan Tidak Disengaja</h2><p>Pod-pod tidak akan terhapus sampai sesuatu (orang ataupun <em>pengendali</em>) menghancurkan mereka atau ada kesalahan perangkat keras maupun perangkat lunak yang tidak dapat dihindari.</p><p>Kita menyebut kasus-kasus yang tidak dapat dihindari sebagai <strong>disrupsi yang tidak disengaja</strong> terhadap aplikasi. Beberapa contohnya adalah sebagai berikut:</p><ul><li>Kesalahan perangkat keras pada mesin yang menjalankan Node</li><li>Administrator klaster menghapus <em>virtual machine</em> secara tidak sengaja</li><li>Kesalahan pada penyedia layanan <em>cloud</em> yang mengakibatkan terhapusnya <em>virtual machine</em></li><li>Sebuah <em>kernel panic</em></li><li>Node menghilang dari klaster karena partisi jaringan klaster</li><li>Pod mengalami <em>eviction</em> karena Node <a href=/docs/tasks/administer-cluster/out-of-resource>kehabisan sumber daya</a></li></ul><p>Dengan pengecualian pada kondisi kehabisan sumber daya, kondisi-kondisi tersebut pada umumnya diketahui oleh kebanyakan pengguna karena kondisi-kondisi tersebut tidak spesifik pada Kubernetes saja.</p><p>Kita menyebut kasus-kasus lainnya sebagai <strong>disrupsi yang disengaja</strong>. Hal ini termasuk tindakan yang dilakukan oleh pemilik aplikasi atau yang dilakukan oleh administrator klaster. Pemilik aplikasi umumnya melakukan hal-hal berikut:</p><ul><li>Menghapus Deployment atau pengendali yang mengatur Pod</li><li>Memperbarui templat Pod yang menyebabkan pengulangan kembali/<em>restart</em></li><li>Menghapus Pod secara langsung</li></ul><p>Administrator klaster umumnya melakukan hal-hal berikut:</p><ul><li><a href=/docs/tasks/administer-cluster/safely-drain-node/>Melakukan <em>drain</em> terhadap Node</a> untuk perbaikan atau pembaruan.</li><li>Melakukan <em>drain</em> terhadap sebuah node dari klaster untuk memperkecil ukuran klaster (untuk lebih lanjutnya, pelajari <a href=/docs/tasks/administer-cluster/cluster-management/#cluster-autoscaler><em>Autoscaling</em> klaster</a>).</li><li>Menghapus sebuah Pod dari node untuk memuat Pod lain ke node tersebut.</li></ul><p>Tindakan-tindakan tersebut dapat dilakukan secara langsung oleh administrator klaster, atau oleh alat otomasi yang dijalankan oleh administrator klaster, atau oleh penyedia layanan Kubernetes kamu.</p><p>Tanyakan administrator klaster atau penyedia layanan <em>cloud</em> kamu, atau lihatlah dokumentasi penyedia layanan Kubernetes kamu untuk mengetahui bila ada sumber-sumber yang berpotensi mengakibatkan disrupsi yang disengaja yang ada pada klastermu. Jika tidak ada, kamu bisa melewatkan pembuatan <em>PodDisruptionBudget</em></p><div class="alert alert-warning caution callout" role=alert><strong>Perhatian:</strong> Tidak semua disrupsi yang disengaja dibatasi oleh Pod Disruption Budget. Contohnya, menghapus Deployment atau Pod dapat mengabaikan PodDisruptionBudget.</div><h2 id=mengatasi-disrupsi>Mengatasi Disrupsi</h2><p>Berikut beberapa cara untuk mengatasi disrupsi yang tidak disengaja:</p><ul><li>Pastikan Pod-pod kamu <a href=/docs/tasks/configure-Pod-container/assign-cpu-ram-container>merinci permintaan sumber daya klaster</a> yang dibutuhkan.</li><li>Replikasikan aplikasimu jika membutuhkan ketersediaan yang tinggi. (Pelajari tentang menjalankan aplikasi
<a href=/docs/tasks/run-application/run-stateless-application-deployment/><em>stateless</em></a> dan <a href=/docs/tasks/run-application/run-replicated-stateful-application/><em>stateful</em></a>).</li><li>Untuk mencapai ketersediaan yang bahkan lebih tinggi lagi saat mereplikasikan aplikasi, sebarkanlah Pod-pod kamu di rak-rak pada <em>data center</em> (menggunakan <a href=/docs/user-guide/node-selection/#inter-Pod-affinity-and-anti-affinity-beta-feature><em>anti-affinity</em></a>) atau di seluruh zona (jika kamu menggunakan <a href=/docs/setup/multiple-zones>klaster pada beberapa zona</a>).</li></ul><p>Frekuensi disrupsi yang disengaja dapat berubah-ubah. Pada klaster Kubernetes yang dasar, tidak ada disrupsi yang disengaja sama sekali. Tetapi, administrator klaster atau penyedia layanan Kubernetes kamu mungkin saja menjalankan beberapa servis tambahan yang dapat mengakibatkan disrupsi yang disengaja. Misalnya, memperbarui perangkat lunak pada node yang dapat mengakibatkan disrupsi yang disengaja. Selain itu, beberapa implementasi <em>autoscaling</em> klaster (atau node) dapat mengakibatkan disrupsi yang disengaja untuk merapikan dan memadatkan node-node pada klaster.
Administrator klaster atau penyedia layanan Kubernetes kamu perlu mendokumentasikan tingkatan disrupsi yang disengaja, jika ada disrupsi yang telah diperkirakan.</p><p>Kubernetes menawarkan fitur-fitur untuk membantu menjalankan aplikasi-aplikasi dengan ketersediaan tinggi bersamaan dengan seringnya disrupsi yang disengaja, fitur-fitur tersebut dinamai <em>Disruption Budget</em>.</p><h2 id=bagaimana-cara-kerja-disruption-budget>Bagaimana cara kerja <em>Disruption Budget</em></h2><p>Pemilik aplikasi dapat membuat objek <code>PodDisruptionBudget</code> (PDB) untuk setiap aplikasi. Sebuah PDB membatasi jumlah Pod yang boleh mati secara bersamaan pada aplikasi yang direplikasi dikarenakan disrupsi yang disengaja.
Misalnya, sebuah aplikasi yang bekerja secara <em>quorum</em> mau memastikan bahwa jumlah replika yang berjalan tidak jatuh ke bawah yang dibutuhkan untuk membentuk sebuah <em>quorum</em>. Contoh lainnya, sebuah <em>front-end</em> web mungkin perlu memastikan bahwa jumlah replika yang melayani trafik tidak pernah turun ke total persentase yang telah ditentukan.</p><p>Administrator klaster dan penyedia layanan Kubernetes sebaiknya menggunakan alat-alat yang menghormati PDB dengan cara berkomunikasi dengan <a href=/docs/tasks/administer-cluster/safely-drain-node/#the-eviction-api>Eviction API</a> dari pada menghapus Pod atau Deployment secara langsung. Contohnya adalah perintah <code>kubectl drain</code> dan skrip pembaruan Kubernetes-on-GCE (<code>cluster/gce/upgrade.sh</code>)</p><p>Saat seorang administrator klaster ingin melakukan <em>drain</em> terhadap sebuah node, ia akan menggunakan perintah <code>kubectl drain</code>. Alat tersebut mencoba untuk "mengusir" semua Pod di node tersebut. Permintaan untuk mengusir Pod tersebut mungkin ditolak untuk sementara, dan alat tersebut akan mencoba ulang permintaannya secara periodik hingga semua Pod dihapus, atau hingga batas waktu yang ditentukan telah dicapai.</p><p>Sebua PDB merinci jumlah replika yang dapat ditoleransi oleh sebuah aplikasi, relatif terhadap berapa banyak yang seharusnya dimiliki oleh aplikasi tersebut. Sebagai contoh, sebuah Deployment yang memiliki rincian <code>.spec.replicas :5</code> diharapkan memiliki 5 Pod pada satu waktu. Jika PDB aplikasi tersebut mengizinkan ada 4 replika pada satu waktu, maka Eviction API akan mengizinkan disrupsi yag disengaja sebanyak satu, tapi tidak mengizinkan dua, pada satu waktu.</p><p>Sebuah kelompok Pod yang mewakili aplikasi dispesifikasikan menggunakan sebuah <em>label selector</em> yang sama dengan yang digunakan oleh pengatur aplikasi tersebut (Deployment, StatefulSet, dsb.)</p><p>Jumlah Pod yang "diharapkan" dihitung dari <code>.spec.replicas</code> dari pengendali Pod tersebut. Pengendali dari sebuah Pod dapat ditemukan di spesifikasi <code>.metadata.ownerReferences</code> objek Pod yang bersangkutan.</p><p>PDB tidak dapat mencegah <a href=#disrupsi-yang-disengaja-dan-tidak-disengaja>disrupsi yang tidak disengaja</a>, tapi disrupsi ini akan dihitung terhadap bujet PDB.</p><p>Pod yang dihapus atau tidak tersetia dikarenakan pembaruan bertahap juga dihitung terhadap bujet PDB, tetapi pengendali (seperti Deployment dan StatefulSet) tidak dibatasi oleh PDB ketika melakukan pembaruan bertahap; Penanganan kerusakan saat pembaruan aplikasi dikonfigurasikan pada spesifikasi pengendali. (Pelajari tentang <a href=/id/docs/concepts/workloads/controllers/deployment/#updating-a-deployment>memperbarui sebuah Deployment</a>.)</p><p>Saat sebuah Pod diusir menggunakan <em>eviction API</em>, Pod tersebut akan dihapus secara <em>graceful</em> (lihat <code>terminationGracePeriodSeconds</code> pada <a href=/docs/reference/generated/kubernetes-api/v1.25/#Podspec-v1-core>PodSpec</a>.))</p><h2 id=contoh-pdb>Contoh PDB</h2><p>Kita ambil contoh sebuah klaster dengan 3 node, <code>node-1</code> hingga <code>node-3</code>.
Klaster tersebut menjalankan beberapa aplikasi. Salah satu dari aplikasi tersebut awalnya memiliki 3 replika, yang akan kita namai <code>Pod-a</code>, <code>Pod-b</code>, dan <code>Pod-c</code>. Sebuah Pod lain yang tidak bersangkutan dan tidak memiliki PDB, dinamai <code>Pod-x</code> juga terlihat. Awalnya, Pod-pod tersebut berada pada node-node sebagai berikut:</p><table><thead><tr><th style=text-align:center>node-1</th><th style=text-align:center>node-2</th><th style=text-align:center>node-3</th></tr></thead><tbody><tr><td style=text-align:center>Pod-a <em>available</em></td><td style=text-align:center>Pod-b <em>available</em></td><td style=text-align:center>Pod-c <em>available</em></td></tr><tr><td style=text-align:center>Pod-x <em>available</em></td><td style=text-align:center></td><td style=text-align:center></td></tr></tbody></table><p>3 Pod <code>Pod-a</code> hingga <code>Pod-c</code> adalah bagian dari sebuah Deployment, dan mereka secara kolektif memiliki sebuah PDB yang mengharuskan ada setidaknya 2 dari 3 Pod untuk tersedia sepanjang waktu.</p><p>Sebagai contoh, asumsikan administrator klaster ingin me-<em>reboot</em> ke dalam versi kernel baru untuk memperbaiki kesalahan di dalam kernel lama. Administator klaster pertama-tama mencoba untuk melakukan <em>drain</em> terhadap <code>node-1</code> menggunakan perintah <code>kubectl drain</code>. Perintah tersebut mencoba untuk mengusir <code>Pod-a</code> dan <code>Pod-x</code>. Hal ini langsung berhasil. Kedua Pod tersebut masuk ke dalam kondisi <code>terminating</code> secara bersamaan. Hal ini mengubah kondisi klaster menjadi sebagai berikut:</p><table><thead><tr><th style=text-align:center>node-1 <em>draining</em></th><th style=text-align:center>node-2</th><th style=text-align:center>node-3</th></tr></thead><tbody><tr><td style=text-align:center>Pod-a <em>terminating</em></td><td style=text-align:center>Pod-b <em>available</em></td><td style=text-align:center>Pod-c <em>available</em></td></tr><tr><td style=text-align:center>Pod-x <em>terminating</em></td><td style=text-align:center></td><td style=text-align:center></td></tr></tbody></table><p>Deployment tersebut melihat bahwa salah satu Pod berada dalam kondisi <code>terminating</code>, sehingga Deployment mencoba untuk membuat penggantinya, <code>Pod-d</code>. Sejak <code>node-1</code> ditutup (karena perintah <code>kubectl-drain</code>), <code>Pod-d</code> masuk ke node lainnya. Sesuatu juga membuat <code>Pod-y</code> sebagai pengganti <code>Pod-x</code></p><p>(Catatan: untuk sebuah StatefulSet, <code>Pod-a</code>, akan dinamai dengan <code>Pod-1</code>, harus diterminasi hingga selesai sebelum penggantinya, yang juga dinamai <code>Pod-1</code> tetapi memiliki UID yang berbeda, akan dibuat. Selain hal ini, seluruh contoh ini juga berlaku untuk StatefulSet.)</p><p>Sekarang, klaster berada pada kondisi berikut:</p><table><thead><tr><th style=text-align:center>node-1 <em>draining</em></th><th style=text-align:center>node-2</th><th style=text-align:center>node-3</th></tr></thead><tbody><tr><td style=text-align:center>Pod-a <em>terminating</em></td><td style=text-align:center>Pod-b <em>available</em></td><td style=text-align:center>Pod-c <em>available</em></td></tr><tr><td style=text-align:center>Pod-x <em>terminating</em></td><td style=text-align:center>Pod-d <em>starting</em></td><td style=text-align:center>Pod-y</td></tr></tbody></table><p>Pada satu waktu, Pod-pod yang diusir pun selesai diterminasi, dan kondisi klaster menjadi seperti berikut:</p><table><thead><tr><th style=text-align:center>node-1 <em>drained</em></th><th style=text-align:center>node-2</th><th style=text-align:center>node-3</th></tr></thead><tbody><tr><td style=text-align:center></td><td style=text-align:center>Pod-b <em>available</em></td><td style=text-align:center>Pod-c <em>available</em></td></tr><tr><td style=text-align:center></td><td style=text-align:center>Pod-d <em>starting</em></td><td style=text-align:center>Pod-y</td></tr></tbody></table><p>Pada titik ini, jika seorang administrator klaster yang tidak sabar mencoba untuk melakukan <em>drain</em> terhadap <code>node-2</code> atau <code>node-3</code>, perintah untuk melakukan <em>drain</em> terhadap node tersebut akan terhalang, karena hanya ada 2 Pod yang tersedia, dan PDB-nya membutuhkan setidaknya ada 2 Pod tersedia. Setelah beberapa waktu, <code>Pod-d</code> menjadi tersedia.</p><p>Kondisi klaster menjadi seperti berikut:</p><table><thead><tr><th style=text-align:center>node-1 <em>drained</em></th><th style=text-align:center>node-2</th><th style=text-align:center>node-3</th></tr></thead><tbody><tr><td style=text-align:center></td><td style=text-align:center>Pod-b <em>available</em></td><td style=text-align:center>Pod-c <em>available</em></td></tr><tr><td style=text-align:center></td><td style=text-align:center>Pod-d <em>available</em></td><td style=text-align:center>Pod-y</td></tr></tbody></table><p>Sekarang, administrator klaster mencoba untuk melakukan <em>drain</em> terhadap <code>node-2</code>. Perintah <em>drain</em> tersebut akan mencoba mengusir Pod-pod tersebut secara berurutan (tidak bersamaan), misalnya <code>Pod-b</code> yang pertama dan diikuti dengan <code>Pod-d</code>. Perintah tersebut akan berhasil mengusir <code>Pod-b</code>. Tetapi, pada saat ia mencoba untuk mengusir <code>Pod-d</code>, hal tersebut akan ditolak karena hal tersebut akan mengakibatkan hanya satu Pod yang tersedia untuk Deployment yang bersangkutan.</p><p>Deployment tersebut membuat pengganti <code>Pod-b</code> yang dinamai <code>Pod-e</code>.
Karena tidak ada sumber daya klaster yang cukup untuk mengalokasikan <code>Pod-e</code>, proses <em>drain</em> akan kembali terhalang.
Klaster mungkin berada pada kondisi berikut:</p><table><thead><tr><th style=text-align:center>node-1 <em>drained</em></th><th style=text-align:center>node-2</th><th style=text-align:center>node-3</th><th style=text-align:center><em>no node</em></th></tr></thead><tbody><tr><td style=text-align:center></td><td style=text-align:center>Pod-b <em>available</em></td><td style=text-align:center>Pod-c <em>available</em></td><td style=text-align:center>Pod-e <em>pending</em></td></tr><tr><td style=text-align:center></td><td style=text-align:center>Pod-d <em>available</em></td><td style=text-align:center>Pod-y</td><td style=text-align:center></td></tr></tbody></table><p>Pada titik ini, administrator klaster mesti menambah sebuah node untuk klaster agar bisa melanjutkan pembaruan klaster.</p><p>Kamu dapat melihat bagaimana frekuensi disrupsi dapat berubah-ubah pada Kubernetes, tergantung pada:</p><ul><li>Berapa banyak replika yang dibutuhkan sebuah aplikasi</li><li>Berapa lama waktu yang dibutuhkan untuk mematikan sebuah Pod secara <em>graceful</em></li><li>Berapa lama waktu yang dibutuhkan untuk memulai sebuah Pod</li><li>Tipe pengendali</li><li>Kapasitas sumber daya klaster</li></ul><h2 id=memisahkan-peran-pemilik-klaster-dan-pemilik-aplikasi>Memisahkan Peran Pemilik Klaster dan Pemilik Aplikasi</h2><p>Seringkali akan bermanfaat untuk berpikir Administrator Klaster dan Pemilik Aplikasi sebagai peran yang terpisah dan dengan pengetahuan yang terbatas satu sama lainnya. Pemisahan ini dapat dimengerti dalam beberapa skenario berikut:</p><ul><li>Saat ada banyak tim aplikasi yang berbagi pakai sebuah klaster Kubernetes, dan ada pembagian peran yang spesifik</li><li>Saat alat atau servis pihak ketiga digunakan untuk melakukan otomasi manajemen klaster.</li></ul><p>PDB mendukung pemisahan peran ini dengan cara menyediakan antarmuka bagi peran-peran tersebut.</p><p>Jika kamu tidak memiliki pemisahan peran seperti ini pada organisasimu, kamu mungkin tidak membutuhkan PDB.</p><h2 id=bagaimana-cara-melakukan-tindakan-disruptif-terhadap-klaster>Bagaimana cara melakukan Tindakan Disruptif terhadap Klaster</h2><p>Jika kamu adalah Administrator Klaster, maka kamu mesti melakukan tindakan disruptif pada setiap node di klastermu, seperti melakukan pembaruan perangkat lunak pada node, berikut beberapa opsinya:</p><ul><li>Menerima <em>downtime</em> pada saat pembaruan node</li><li>Melakukan <em>failover</em> ke replika lengkap klaster lain.<ul><li>Tanpa <em>downtime</em>, tetapi mungkin lebih mahal, baik ongkos duplikasi node-node dan tenaga yang dibutuhkan untuk melakukan <em>failover</em>.</li></ul></li><li>Membuat aplikasi yang toleran terhadap disrupsi, dan gunakan PDB.<ul><li>Tanpa <em>downtime</em>.</li><li>Duplikasi sumber daya yang minimal.</li><li>Mengizinkan lebih banyak otomasi administrasi klaster.</li><li>Membuat aplikasi yang toleran terhadap disrupsi agak rumit, tetapi usaha yang dilakukan untuk menoleransi disrupsi yang disengaja kebanyakan beririsan dengan usaha untuk mendukung <em>autoscaling</em> dan menoleransi disrupsi yang tidak disengaja.</li></ul></li></ul><h2 id=selanjutnya>Selanjutnya</h2><ul><li><p>Ikuti langkah-langkah untuk melindungi aplikasimu dengan <a href=/docs/tasks/run-application/configure-pdb/>membuat sebuah PodDisruptionBudget</a>.</p></li><li><p>Pelajari lebih lanjut mengenai <a href=/docs/tasks/administer-cluster/safely-drain-node/>melakukan <em>drain</em> terhadap node</a>.</p></li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-53a1005011e1bda2ce81819aad7c8b32>4.1.8 - Kontainer Sementara (Ephemeral)</h1><div style=margin-top:10px;margin-bottom:10px><b>FEATURE STATE:</b> <code>Kubernetes v1.16 [alpha]</code></div><p>Halaman ini memberikan gambaran umum tentang kontainer sementara: satu jenis
kontainer khusus yang berjalan sementara pada <a class=glossary-tooltip title='Unit Kubernetes yang paling sederhana dan kecil. Sebuah Pod merepresentasikan sebuah set kontainer yang dijalankan pada kluster kamu.' data-toggle=tooltip data-placement=top href=/docs/concepts/workloads/pods/pod-overview/ target=_blank aria-label=Pod>Pod</a>
yang sudah ada untuk melakukan tindakan yang diinisiasi oleh pengguna seperti
dalam pemecahan masalah. Kamu menggunakan kontainer sementara untuk memeriksa
layanan bukan untuk membangun aplikasi.</p><div class="alert alert-danger warning callout" role=alert><strong>Peringatan:</strong> Kontainer sementara masih berada dalam fase alpha dan tidak cocok untuk
klaster produksi. Kamu harus mengharapkan adanya suatu fitur yang tidak akan
berfungsi dalam beberapa situasi tertentu, seperti saat menargetkan <em>namespace</em>
dari suatu kontainer. Sesuai dengan Kubernetes
<a href=/docs/reference/using-api/deprecation-policy/><em>Deprecation Policy</em></a>, fitur alpha
ini dapat berubah secara signifikan di masa depan atau akan dihapus seluruhnya.</div><h2 id=memahami-kontainer-sementara>Memahami Kontainer Sementara</h2><p><a class=glossary-tooltip title='Unit Kubernetes yang paling sederhana dan kecil. Sebuah Pod merepresentasikan sebuah set kontainer yang dijalankan pada kluster kamu.' data-toggle=tooltip data-placement=top href=/docs/concepts/workloads/pods/pod-overview/ target=_blank aria-label=Pod>Pod</a> adalah blok pembangun
fundamental dalam aplikasi Kubernetes. Karena Pod diharapkan digunakan hanya
sekali dan dapat diganti, sehingga kamu tidak dapat menambahkan kontainer ke
dalam Pod setelah Pod tersebut dibuat. Sebaliknya, kamu biasanya menghapus dan
mengganti beberapa Pod dengan cara yang terkontrol melalui
<a class=glossary-tooltip title='Mengelola aplikasi yang direplikasi di dalam klastermu.' data-toggle=tooltip data-placement=top href=/id/docs/concepts/workloads/controllers/deployment/ target=_blank aria-label=Deployment>Deployment</a>.</p><p>Namun, kadang-kadang perlu juga untuk memeriksa keadaan Pod yang telah ada,
sebagai contoh untuk memecahkan masalah <em>bug</em> yang sulit direproduksi. Dalam
kasus ini, kamu dapat menjalankan sebuah kontainer sementara di dalam suatu Pod
yang sudah ada untuk memeriksa statusnya dan menjalankannya segala macam
perintah.</p><h3 id=apa-itu-kontainer-sementara>Apa itu Kontainer Sementara?</h3><p>Kontainer sementara berbeda dengan kontainer lainnya karena tidak memiliki
jaminan sumber daya maupun akan eksekusi, dan mereka tidak akan pernah secara
otomatis melakukan <em>restart</em>, jadi mereka tidak sesuai untuk membangun aplikasi.
Kontainer sementara dideskripsikan dengan menggunakan ContainerSpec yang sama
dengan kontainer biasa, tetapi banyak bagian yang tidak kompatibel dan tidak
diperbolehkan untuk kontainer sementara.</p><ul><li>Kontainer sementara mungkin tidak memiliki port, sehingga bagian seperti
<code>port</code>, <code>livenessProbe</code>, <code>readinessProbe</code> tidak diperbolehkan.</li><li>Alokasi sumber daya untuk Pod tidak dapat diubah, sehingga pengaturan
sumber daya tidak diperbolehkan.</li><li>Untuk daftar lengkap bagian yang diperbolehkan, dapat di lihat
<a href=/docs/reference/generated/kubernetes-api/v1.25/#ephemeralcontainer-v1-core>referensi dokumentasi Kontainer Sementara</a>.</li></ul><p>Kontainer sementara dibuat dengan menggunakan <em>handler</em> khusus
EphemeralContainers dalam API tanpa menambahkannya langsung ke <code>pod.spec</code>,
sehingga tidak memungkinan untuk menambahkan kontainer sementara dengan
menggunakan <code>kubectl edit</code>.</p><p>Seperti dengan kontainer biasa, kamu tidak dapat mengubah atau menghapus
kontainer sementara setelah kamu memasukkannya ke dalam sebuah Pod.</p><h2 id=penggunaan-kontainer-sementara>Penggunaan Kontainer Sementara</h2><p>Kontainer sementara berguna untuk pemecahan masalah secara interaktif pada saat
<code>kubectl exec</code> tidak mencukupi karena sebuah kontainer telah hancur atau
kontainer <em>image</em> tidak memiliki utilitas untuk <em>debugging</em>.</p><p>Khususnya, untuk <a href=https://github.com/GoogleContainerTools/distroless><em>images_distroless</em></a>
memungkinkan kamu untuk menyebarkan kontainer <em>image</em> minimal yang mengurangi
<em>surface attack</em> dan paparan <em>bug</em> dan <em>vulnerability</em>. Karena
<em>image distroless</em> tidak mempunyai sebuah <em>shell</em> atau utilitas <em>debugging</em> apa
pun, sehingga sulit untuk memecahkan masalah <em>image distroless</em> dengan
menggunakan <code>kubectl exec</code> saja.</p><p>Saat menggunakan kontainer sementara, akan sangat membantu untuk mengaktifkan
<a href=/id/docs/tasks/configure-pod-container/share-process-namespace/><em>process namespace sharing</em></a>
sehingga kamu dapat melihat proses pada kontainer lain.</p><h3 id=contoh>Contoh</h3><div class="alert alert-info note callout" role=alert><strong>Catatan:</strong> Contoh-contoh pada bagian ini membutuhkan <code>EphemeralContainers</code> <a href=/docs/reference/command-line-tools-reference/feature-gates/>feature
gate</a> untuk
diaktifkan, dan membutuhkan Kubernetes klien dan server versi v1.16 atau
yang lebih baru.</div><p>Contoh-contoh pada bagian ini menunjukkan bagaimana kontainer sementara muncul
dalam API. Kamu biasanya dapat menggunakan plugin <code>kubectl</code> untuk mengatasi
masalah untuk mengotomatiskan langkah-langkah ini.</p><p>Kontainer sementara dibuat menggunakan <em>subresource</em> <code>ephemeralcontainers</code>
Pod, yang dapat didemonstrasikan menggunakan <code>kubectl --raw</code>. Pertama-tama
deskripsikan kontainer sementara untuk ditambahkan dalam daftar
<code>EphemeralContainers</code>:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-json data-lang=json><span style=display:flex><span>{
</span></span><span style=display:flex><span>    <span style=color:green;font-weight:700>&#34;apiVersion&#34;</span>: <span style=color:#b44>&#34;v1&#34;</span>,
</span></span><span style=display:flex><span>    <span style=color:green;font-weight:700>&#34;kind&#34;</span>: <span style=color:#b44>&#34;EphemeralContainers&#34;</span>,
</span></span><span style=display:flex><span>    <span style=color:green;font-weight:700>&#34;metadata&#34;</span>: {
</span></span><span style=display:flex><span>        <span style=color:green;font-weight:700>&#34;name&#34;</span>: <span style=color:#b44>&#34;example-pod&#34;</span>
</span></span><span style=display:flex><span>    },
</span></span><span style=display:flex><span>    <span style=color:green;font-weight:700>&#34;ephemeralContainers&#34;</span>: [{
</span></span><span style=display:flex><span>        <span style=color:green;font-weight:700>&#34;command&#34;</span>: [
</span></span><span style=display:flex><span>            <span style=color:#b44>&#34;sh&#34;</span>
</span></span><span style=display:flex><span>        ],
</span></span><span style=display:flex><span>        <span style=color:green;font-weight:700>&#34;image&#34;</span>: <span style=color:#b44>&#34;busybox&#34;</span>,
</span></span><span style=display:flex><span>        <span style=color:green;font-weight:700>&#34;imagePullPolicy&#34;</span>: <span style=color:#b44>&#34;IfNotPresent&#34;</span>,
</span></span><span style=display:flex><span>        <span style=color:green;font-weight:700>&#34;name&#34;</span>: <span style=color:#b44>&#34;debugger&#34;</span>,
</span></span><span style=display:flex><span>        <span style=color:green;font-weight:700>&#34;stdin&#34;</span>: <span style=color:#a2f;font-weight:700>true</span>,
</span></span><span style=display:flex><span>        <span style=color:green;font-weight:700>&#34;tty&#34;</span>: <span style=color:#a2f;font-weight:700>true</span>,
</span></span><span style=display:flex><span>        <span style=color:green;font-weight:700>&#34;terminationMessagePolicy&#34;</span>: <span style=color:#b44>&#34;File&#34;</span>
</span></span><span style=display:flex><span>    }]
</span></span><span style=display:flex><span>}
</span></span></code></pre></div><p>Untuk memperbarui kontainer yang sudah berjalan dalam <code>example-pod</code>:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl replace --raw /api/v1/namespaces/default/pods/example-pod/ephemeralcontainers  -f ec.json
</span></span></code></pre></div><p>Ini akan menampilkan daftar baru dari seluruh kontainer sementara:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-json data-lang=json><span style=display:flex><span>{
</span></span><span style=display:flex><span>   <span style=color:green;font-weight:700>&#34;kind&#34;</span>:<span style=color:#b44>&#34;EphemeralContainers&#34;</span>,
</span></span><span style=display:flex><span>   <span style=color:green;font-weight:700>&#34;apiVersion&#34;</span>:<span style=color:#b44>&#34;v1&#34;</span>,
</span></span><span style=display:flex><span>   <span style=color:green;font-weight:700>&#34;metadata&#34;</span>:{
</span></span><span style=display:flex><span>      <span style=color:green;font-weight:700>&#34;name&#34;</span>:<span style=color:#b44>&#34;example-pod&#34;</span>,
</span></span><span style=display:flex><span>      <span style=color:green;font-weight:700>&#34;namespace&#34;</span>:<span style=color:#b44>&#34;default&#34;</span>,
</span></span><span style=display:flex><span>      <span style=color:green;font-weight:700>&#34;selfLink&#34;</span>:<span style=color:#b44>&#34;/api/v1/namespaces/default/pods/example-pod/ephemeralcontainers&#34;</span>,
</span></span><span style=display:flex><span>      <span style=color:green;font-weight:700>&#34;uid&#34;</span>:<span style=color:#b44>&#34;a14a6d9b-62f2-4119-9d8e-e2ed6bc3a47c&#34;</span>,
</span></span><span style=display:flex><span>      <span style=color:green;font-weight:700>&#34;resourceVersion&#34;</span>:<span style=color:#b44>&#34;15886&#34;</span>,
</span></span><span style=display:flex><span>      <span style=color:green;font-weight:700>&#34;creationTimestamp&#34;</span>:<span style=color:#b44>&#34;2019-08-29T06:41:42Z&#34;</span>
</span></span><span style=display:flex><span>   },
</span></span><span style=display:flex><span>   <span style=color:green;font-weight:700>&#34;ephemeralContainers&#34;</span>:[
</span></span><span style=display:flex><span>      {
</span></span><span style=display:flex><span>         <span style=color:green;font-weight:700>&#34;name&#34;</span>:<span style=color:#b44>&#34;debugger&#34;</span>,
</span></span><span style=display:flex><span>         <span style=color:green;font-weight:700>&#34;image&#34;</span>:<span style=color:#b44>&#34;busybox&#34;</span>,
</span></span><span style=display:flex><span>         <span style=color:green;font-weight:700>&#34;command&#34;</span>:[
</span></span><span style=display:flex><span>            <span style=color:#b44>&#34;sh&#34;</span>
</span></span><span style=display:flex><span>         ],
</span></span><span style=display:flex><span>         <span style=color:green;font-weight:700>&#34;resources&#34;</span>:{
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>         },
</span></span><span style=display:flex><span>         <span style=color:green;font-weight:700>&#34;terminationMessagePolicy&#34;</span>:<span style=color:#b44>&#34;File&#34;</span>,
</span></span><span style=display:flex><span>         <span style=color:green;font-weight:700>&#34;imagePullPolicy&#34;</span>:<span style=color:#b44>&#34;IfNotPresent&#34;</span>,
</span></span><span style=display:flex><span>         <span style=color:green;font-weight:700>&#34;stdin&#34;</span>:<span style=color:#a2f;font-weight:700>true</span>,
</span></span><span style=display:flex><span>         <span style=color:green;font-weight:700>&#34;tty&#34;</span>:<span style=color:#a2f;font-weight:700>true</span>
</span></span><span style=display:flex><span>      }
</span></span><span style=display:flex><span>   ]
</span></span><span style=display:flex><span>}
</span></span></code></pre></div><p>Kamu dapat melihat kondisi kontainer sementara yang baru dibuat dengan
menggunakan <code>kubectl describe</code>:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl describe pod example-pod
</span></span></code></pre></div><pre tabindex=0><code>...
Ephemeral Containers:
  debugger:
    Container ID:  docker://cf81908f149e7e9213d3c3644eda55c72efaff67652a2685c1146f0ce151e80f
    Image:         busybox
    Image ID:      docker-pullable://busybox@sha256:9f1003c480699be56815db0f8146ad2e22efea85129b5b5983d0e0fb52d9ab70
    Port:          &lt;none&gt;
    Host Port:     &lt;none&gt;
    Command:
      sh
    State:          Running
      Started:      Thu, 29 Aug 2019 06:42:21 +0000
    Ready:          False
    Restart Count:  0
    Environment:    &lt;none&gt;
    Mounts:         &lt;none&gt;
...
</code></pre><p>Kamu dapat mengakses kontainer sementara yang baru menggunakan
<code>kubectl attach</code>:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl attach -it example-pod -c debugger
</span></span></code></pre></div><p>Jika proses berbagi <em>namespace</em> diaktifkan, kamu dapat melihat proses dari semua
kontainer dalam Pod tersebut. Misalnya, setelah mengakses, kamu jalankan
<code>ps</code> di kontainer <em>debugger</em>:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span><span style=color:#080;font-style:italic># Jalankan ini pada _shell_ dalam _debugger_ dari kontainer sementara</span>
</span></span><span style=display:flex><span>ps auxww
</span></span></code></pre></div><p>Hasilnya akan seperti ini:</p><pre tabindex=0><code>PID   USER     TIME  COMMAND
    1 root      0:00 /pause
    6 root      0:00 nginx: master process nginx -g daemon off;
   11 101       0:00 nginx: worker process
   12 101       0:00 nginx: worker process
   13 101       0:00 nginx: worker process
   14 101       0:00 nginx: worker process
   15 101       0:00 nginx: worker process
   16 101       0:00 nginx: worker process
   17 101       0:00 nginx: worker process
   18 101       0:00 nginx: worker process
   19 root      0:00 /pause
   24 root      0:00 sh
   29 root      0:00 ps auxww
</code></pre></div><div class=td-content style=page-break-before:always><h1 id=pg-89637410cacae45a36ab1cc278c482eb>4.2 - Controllers</h1></div><div class=td-content><h1 id=pg-d459b930218774655fa7fd1620625539>4.2.1 - ReplicaSet</h1><p>Tujuan dari ReplicaSet adalah untuk memelihara himpunan stabil dari replika Pod yang sedang berjalan pada satu waktu tertentu. Maka dari itu, ReplicaSet seringkali digunakan untuk menjamin ketersediaan dari beberapa Pod identik dalam jumlah tertentu.</p><h2 id=cara-kerja-replicaset>Cara kerja ReplicaSet</h2><p>Sebuah ReplicaSet didefinisikan dengan beberapa <em>field</em> termasuk selektor yang menentukan bagaimana mengidentifikasi Pod yang dapat diakuisisi, jumlah replika yang mengindikasi berapa jumlah Pod yang harus dikelola, dan sebuah templat pod yang menentukan data dari berbagai Pod baru yang harus dibuat untuk memenuhi kriteria jumlah replika. Sebuah ReplicaSet selanjutnya akan memenuhi tujuannya dengan membuat dan menghapus Pod sesuai dengan kebutuhan untuk mencapai jumlah yang diinginkan. Ketika ReplicaSet butuh untuk membuat Pod baru, templat Pod akan digunakan.</p><p>Tautan dari sebuah ReplicaSet terhadap Pod yang dimiliki adalah melalui <em>field</em> <a href=https://kubernetes.io/docs/concepts/workloads/controllers/garbage-collection/#owners-and-dependents>metadata.ownerReferences</a> pada Pod, yang menentukan sumber daya yang dimiliki oleh objek saat ini. Semua Pod yang diakuisisi oleh sebuah ReplicaSet masing-masing memiliki informasi yang mengidentifikasi ReplicaSet dalam <em>field</em> ownerReferences. Melalui tautan ini ReplicaSet dapat mengetahui keadaan dari Pod yang sedang dikelola dan melakukan perencanaan yang sesuai.</p><p>Sebuah ReplicaSet mengidentifikasi Pod baru untuk diakuisisi menggunakan selektornya. Jika terdapat sebuah Pod yang tidak memiliki OwnerReference atau OwnerReference yang dimiliki bukanlah sebuah <a href=https://kubernetes.io/docs/concepts/architecture/controller><em>Controller</em></a> dan sesuai dengan selektor dari ReplicaSet, maka Pod akan langsung diakuisisi oleh ReplicaSet tersebut.</p><h2 id=kapan-menggunakan-replicaset>Kapan menggunakan ReplicaSet</h2><p>Sebuah ReplicaSet memastikan replika-replika pod dalam jumlah yang ditentukan berjalan pada satu waktu tertentu. Namun demikian, sebuah Deployment adalah konsep dengan tingkatan yang lebih tinggi yang mengatur ReplicaSet dan mengubah Pod secara deklaratif serta berbagai fitur bermanfaat lainnya. Maka dari itu, kami merekomendasikan untuk menggunakan Deployment alih-alih menggunakan ReplicaSet secara langsung, kecuali jika kamu membutuhkan orkestrasi pembaruan yang khusus atau tidak membutuhkan pembaruan sama sekali.</p><p>Hal ini berarti kamu boleh jadi tidak akan membutuhkan manipulasi objek ReplicaSet: Gunakan Deployment dan definisikan aplikasi kamu pada bagian <em>spec</em>.</p><h2 id=contoh>Contoh</h2><div class=highlight><div class=copy-code-icon style=text-align:right><a href=https://raw.githubusercontent.com/kubernetes/website/main/content/id/examples/controllers/frontend.yaml download=controllers/frontend.yaml><code>controllers/frontend.yaml</code></a>
<img src=/images/copycode.svg style=max-height:24px;cursor:pointer onclick='copyCode("controllers-frontend-yaml")' title="Copy controllers/frontend.yaml to clipboard"></img></div><div class=includecode id=controllers-frontend-yaml><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>apps/v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>ReplicaSet<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>frontend<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>labels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>app</span>:<span style=color:#bbb> </span>guestbook<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>tier</span>:<span style=color:#bbb> </span>frontend<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:#080;font-style:italic># modify replicas according to your case</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>replicas</span>:<span style=color:#bbb> </span><span style=color:#666>3</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>selector</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>matchLabels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>tier</span>:<span style=color:#bbb> </span>frontend<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>template</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>labels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>tier</span>:<span style=color:#bbb> </span>frontend<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>php-redis<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>gcr.io/google_samples/gb-frontend:v3<span style=color:#bbb>
</span></span></span></code></pre></div></div></div><p>Menyimpan <em>manifest</em> ini dalam <code>frontend.yaml</code> dan mengirimkannya ke klaster Kubernetes akan membuat ReplicaSet yang telah didefinisikan beserta dengan Pod yang dikelola.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl apply -f https://kubernetes.io/examples/controllers/frontend.yaml
</span></span></code></pre></div><p>Selanjutnya kamu bisa mendapatkan ReplicaSet yang sedang di-<em>deploy</em>:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get rs
</span></span></code></pre></div><p>Dan melihat <em>frontend</em> yang telah dibuat:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>NAME       DESIRED   CURRENT   READY   AGE
</span></span><span style=display:flex><span>frontend   <span style=color:#666>3</span>         <span style=color:#666>3</span>         <span style=color:#666>3</span>       6s
</span></span></code></pre></div><p>Kamu juga dapat memeriksa kondisi dari ReplicaSet:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl describe rs/frontend
</span></span></code></pre></div><p>Dan kamu akan melihat keluaran yang serupa dengan:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>Name:		frontend
</span></span><span style=display:flex><span>Namespace:	default
</span></span><span style=display:flex><span>Selector:	<span style=color:#b8860b>tier</span><span style=color:#666>=</span>frontend,tier in <span style=color:#666>(</span>frontend<span style=color:#666>)</span>
</span></span><span style=display:flex><span>Labels:		<span style=color:#b8860b>app</span><span style=color:#666>=</span>guestbook
</span></span><span style=display:flex><span>		<span style=color:#b8860b>tier</span><span style=color:#666>=</span>frontend
</span></span><span style=display:flex><span>Annotations:	&lt;none&gt;
</span></span><span style=display:flex><span>Replicas:	<span style=color:#666>3</span> current / <span style=color:#666>3</span> desired
</span></span><span style=display:flex><span>Pods Status:	<span style=color:#666>3</span> Running / <span style=color:#666>0</span> Waiting / <span style=color:#666>0</span> Succeeded / <span style=color:#666>0</span> Failed
</span></span><span style=display:flex><span>Pod Template:
</span></span><span style=display:flex><span>  Labels:       <span style=color:#b8860b>app</span><span style=color:#666>=</span>guestbook
</span></span><span style=display:flex><span>                <span style=color:#b8860b>tier</span><span style=color:#666>=</span>frontend
</span></span><span style=display:flex><span>  Containers:
</span></span><span style=display:flex><span>   php-redis:
</span></span><span style=display:flex><span>    Image:      gcr.io/google_samples/gb-frontend:v3
</span></span><span style=display:flex><span>    Port:       80/TCP
</span></span><span style=display:flex><span>    Requests:
</span></span><span style=display:flex><span>      cpu:      100m
</span></span><span style=display:flex><span>      memory:   100Mi
</span></span><span style=display:flex><span>    Environment:
</span></span><span style=display:flex><span>      GET_HOSTS_FROM:   dns
</span></span><span style=display:flex><span>    Mounts:             &lt;none&gt;
</span></span><span style=display:flex><span>  Volumes:              &lt;none&gt;
</span></span><span style=display:flex><span>Events:
</span></span><span style=display:flex><span>  FirstSeen    LastSeen    Count    From                SubobjectPath    Type        Reason            Message
</span></span><span style=display:flex><span>  ---------    --------    -----    ----                -------------    --------    ------            -------
</span></span><span style=display:flex><span>  1m           1m          <span style=color:#666>1</span>        <span style=color:#666>{</span>replicaset-controller <span style=color:#666>}</span>             Normal      SuccessfulCreate  Created pod: frontend-qhloh
</span></span><span style=display:flex><span>  1m           1m          <span style=color:#666>1</span>        <span style=color:#666>{</span>replicaset-controller <span style=color:#666>}</span>             Normal      SuccessfulCreate  Created pod: frontend-dnjpy
</span></span><span style=display:flex><span>  1m           1m          <span style=color:#666>1</span>        <span style=color:#666>{</span>replicaset-controller <span style=color:#666>}</span>             Normal      SuccessfulCreate  Created pod: frontend-9si5l
</span></span></code></pre></div><p>Terakhir, kamu dapat memeriksa Pod yang dibawa:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get Pods
</span></span></code></pre></div><p>Kamu akan melihat informasi Pod yang serupa dengan:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>NAME             READY     STATUS    RESTARTS   AGE
</span></span><span style=display:flex><span>frontend-9si5l   1/1       Running   <span style=color:#666>0</span>          1m
</span></span><span style=display:flex><span>frontend-dnjpy   1/1       Running   <span style=color:#666>0</span>          1m
</span></span><span style=display:flex><span>frontend-qhloh   1/1       Running   <span style=color:#666>0</span>          1m
</span></span></code></pre></div><p>Kamu juga dapat memastikan bahwa referensi pemilik dari pod-pod ini telah disesuaikan terhadap ReplicaSet <em>frontend</em>.
Untuk melakukannya, <em>yaml</em> dari Pod yang sedang berjalan bisa didapatkan dengan:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get pods frontend-9si5l -o yaml
</span></span></code></pre></div><p>Keluarannya akan terlihat serupa dengan contoh berikut ini, dengan informasi ReplicaSet <em>frontend</em> yang ditentukan pada <em>field</em> ownerReferences pada bagian metadata:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>apiVersion: v1
</span></span><span style=display:flex><span>kind: Pod
</span></span><span style=display:flex><span>metadata:
</span></span><span style=display:flex><span>  creationTimestamp: 2019-01-31T17:20:41Z
</span></span><span style=display:flex><span>  generateName: frontend-
</span></span><span style=display:flex><span>  labels:
</span></span><span style=display:flex><span>    tier: frontend
</span></span><span style=display:flex><span>  name: frontend-9si5l
</span></span><span style=display:flex><span>  namespace: default
</span></span><span style=display:flex><span>  ownerReferences:
</span></span><span style=display:flex><span>  - apiVersion: extensions/v1beta1
</span></span><span style=display:flex><span>    blockOwnerDeletion: <span style=color:#a2f>true</span>
</span></span><span style=display:flex><span>    controller: <span style=color:#a2f>true</span>
</span></span><span style=display:flex><span>    kind: ReplicaSet
</span></span><span style=display:flex><span>    name: frontend
</span></span><span style=display:flex><span>    uid: 892a2330-257c-11e9-aecd-025000000001
</span></span><span style=display:flex><span>...
</span></span></code></pre></div><h2 id=akuisisi-pod-non-templat>Akuisisi Pod Non-Templat</h2><p>Walaupun kamu bisa membuat Pod biasa tanpa masalah, sangat direkomendasikan untuk memastikan Pod tersebut tidak memiliki label yang sama dengan selektor dari salah satu ReplicaSet yang kamu miliki. Hal in disebabkan sebuah ReplicaSet tidak dibatasi untuk memilki Pod sesuai dengan templatnya -- ReplicaSet dapat mengakuisisi Pod lain dengan cara yang telah dijelaskan pada bagian sebelumnya.</p><p>Mengambil contoh ReplicaSet <em>frontend</em> sebelumnya, dan Pod yang ditentukan pada <em>manifest</em> berikut:</p><div class=highlight><div class=copy-code-icon style=text-align:right><a href=https://raw.githubusercontent.com/kubernetes/website/main/content/id/examples/pods/pod-rs.yaml download=pods/pod-rs.yaml><code>pods/pod-rs.yaml</code></a>
<img src=/images/copycode.svg style=max-height:24px;cursor:pointer onclick='copyCode("pods-pod-rs-yaml")' title="Copy pods/pod-rs.yaml to clipboard"></img></div><div class=includecode id=pods-pod-rs-yaml><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>pod1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>labels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>tier</span>:<span style=color:#bbb> </span>frontend<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>hello1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>gcr.io/google-samples/hello-app:2.0<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:#00f;font-weight:700>---</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>pod2<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>labels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>tier</span>:<span style=color:#bbb> </span>frontend<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>hello2<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>gcr.io/google-samples/hello-app:1.0<span style=color:#bbb>
</span></span></span></code></pre></div></div></div><p>Karena Pod tersebut tidak memiliki Controller (atau objek lain) sebagai referensi pemilik yang sesuai dengan selektor dari ReplicaSet <em>frontend</em>, Pod tersebut akan langsung diakuisisi oleh ReplicaSet.</p><p>Misalkan kamu membuat Pod tersebut setelah ReplicaSet <em>frontend</em> telah di-<em>deploy</em> dan telah mengkonfigurasi replika Pod awal untuk memenuhi kebutuhan jumlah replika:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl apply -f https://kubernetes.io/examples/pods/pod-rs.yaml
</span></span></code></pre></div><p>Pod baru akan diakuisisi oleh ReplicaSet, dan setelah itu langsung diterminasi ketika ReplicaSet melebihi jumlah yang diinginkan.</p><p>Memperoleh Pod:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get Pods
</span></span></code></pre></div><p>Keluaran menunjukkan bahwa Pod baru dalam keaadan telah diterminasi, atau sedang dalam proses terminasi:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>NAME             READY   STATUS        RESTARTS   AGE
</span></span><span style=display:flex><span>frontend-9si5l   1/1     Running       <span style=color:#666>0</span>          1m
</span></span><span style=display:flex><span>frontend-dnjpy   1/1     Running       <span style=color:#666>0</span>          1m
</span></span><span style=display:flex><span>frontend-qhloh   1/1     Running       <span style=color:#666>0</span>          1m
</span></span><span style=display:flex><span>pod2             0/1     Terminating   <span style=color:#666>0</span>          4s
</span></span></code></pre></div><p>Jika kamu membuat Pod terlebih dahulu:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl apply -f https://kubernetes.io/examples/pods/pod-rs.yaml
</span></span></code></pre></div><p>Dan selanjutnya membuat ReplicaSet maka:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl apply -f https://kubernetes.io/examples/controllers/frontend.yaml
</span></span></code></pre></div><p>Kamu akan melihat bahwa ReplicaSet telah mengakuisisi Pod dan hanya membuat Pod yang baru sesuai dengan <code>spec</code> yang ditentukan hingga jumlah dari Pod yang baru dan yang orisinil sesuai dengan jumlah yang diinginkan. Dengan memperoleh Pod:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get Pods
</span></span></code></pre></div><p>Akan diperlihatkan pada keluarannya:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>NAME             READY   STATUS    RESTARTS   AGE
</span></span><span style=display:flex><span>frontend-pxj4r   1/1     Running   <span style=color:#666>0</span>          5s
</span></span><span style=display:flex><span>pod1             1/1     Running   <span style=color:#666>0</span>          13s
</span></span><span style=display:flex><span>pod2             1/1     Running   <span style=color:#666>0</span>          13s
</span></span></code></pre></div><p>Dengan cara ini, sebuah ReplicaSet dapat memiliki himpunan berbagai Pod yang tidak homogen.</p><h2 id=menulis-manifest-replicaset>Menulis <em>manifest</em> ReplicaSet</h2><p>Seperti objek API Kubernetes lainnya, sebuah ReplicaSet membutuhkan <em>field</em> <code>apiVersion</code>, <code>kind</code>, dan <code>metadata</code>. Untuk ReplicaSet, nilai dari <code>kind</code> yang memungkinkan hanyalah ReplicaSet. Pada Kubernetes 1.9 versi API <code>apps/v1</code> pada <code>kind</code> ReplicaSet adalah versi saat ini dan diaktifkan secara <em>default</em>. Versi API <code>apps/v1beta2</code> telah dideprekasi. Lihat baris-baris awal pada contoh <code>frontend.yaml</code> untuk petunjuk.</p><p>Sebuah ReplicaSet juga membutuhkan <a href=https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#spec-and-status>bagian <code>.spec</code></a>.</p><h3 id=templat-pod>Templat Pod</h3><p><code>.spec.template</code> adalah sebuah <a href=/docs/concepts/workloads/Pods/pod-overview/#pod-templates>templat pod</a> yang juga dibutuhkan untuk mempunyai label. Pada contoh <code>frontend.yaml</code> kita memiliki satu label: <code>tier: frontend</code>.
Hati-hati agar tidak tumpang tindih dengan selektor dari <em>controller</em> lain, agar mereka tidak mencoba untuk mengadopsi Pod ini.</p><p>Untuk <em>field</em> <a href=/docs/concepts/workloads/Pods/pod-lifecycle/#restart-policy><em>restart policy</em></a> dari templat, <code>.spec.template.spec.restartPolicy</code>, nilai yang diperbolehkan hanyalah <code>Always</code>, yang merupakan nilai <em>default</em>.</p><h3 id=selektor-pod>Selektor Pod</h3><p><em>Field</em> <code>.spec.selector</code> adalah sebuah <a href=/id/docs/concepts/overview/working-with-objects/labels/>selektor labe</a>. Seperti yang telah dibahas <a href=#how-a-replicaset-works>sebelumnya</a>, <em>field</em> ini adalah label yang digunakan untuk mengidentifikasi Pod yang memungkinkan untuk diakuisisi. Pada contoh <code>frontend.yaml</code>, selektornya adalah:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>matchLabels:
</span></span><span style=display:flex><span>	tier: frontend
</span></span></code></pre></div><p>Pada ReplicaSet, <code>.spec.template.metadata.labels</code> harus memiliki nilai yang sama dengan <code>spec.selector</code>, atau akan ditolak oleh API.</p><div class="alert alert-info note callout" role=alert><strong>Catatan:</strong> Untuk 2 ReplicaSet dengan nilai <code>.spec.selector</code> yang sama tetapi memiliki nilai yang berbeda pada <em>field</em> <code>.spec.template.metadata.labels</code> dan <code>.spec.template.spec</code>, setiap ReplicaSet akan mengabaikan Pod yang dibuat oleh ReplicaSet lain.</div><h3 id=replika>Replika</h3><p>Kamu dapat menentukan jumlah Pod yang seharusnya berjalan secara konkuren dengan mengatur nilai dari <code>.spec.replicas</code>. ReplicaSet akan membuat/menghapus Pod-nya hingga jumlahnya sesuai dengan <em>field</em> ini.</p><p>Jika nilai <code>.spec.replicas</code> tidak ditentukan maka akan diatur ke nilai <em>default</em> 1.</p><h2 id=menggunakan-replicaset>Menggunakan ReplicaSet</h2><h3 id=menghapus-replicaset-dan-pod-nya>Menghapus ReplicaSet dan Pod-nya</h3><p>Untuk menghapus sebuah ReplicaSet beserta dengan Pod-nya, gunakan <a href=/docs/reference/generated/kubectl/kubectl-commands#delete><code>kubectl delete</code></a>. <a href=/id/docs/concepts/workloads/controllers/garbage-collection/><em>Garbage collector</em></a> secara otomatis akan menghapus semua Pod dependen secara <em>default</em>.</p><p>Ketika menggunakan REST API atau <em>library</em> <code>client-go</code>, kamu harus mengatur nilai <code>propagationPolicy</code> menjadi <code>Background</code> atau <code>Foreground</code> pada opsi -d.
Sebagai contoh:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl proxy --port<span style=color:#666>=</span><span style=color:#666>8080</span>
</span></span><span style=display:flex><span>curl -X DELETE  <span style=color:#b44>&#39;localhost:8080/apis/extensions/v1beta1/namespaces/default/replicasets/frontend&#39;</span> <span style=color:#b62;font-weight:700>\
</span></span></span><span style=display:flex><span><span style=color:#b62;font-weight:700></span>&gt; -d <span style=color:#b44>&#39;{&#34;kind&#34;:&#34;DeleteOptions&#34;,&#34;apiVersion&#34;:&#34;v1&#34;,&#34;propagationPolicy&#34;:&#34;Foreground&#34;}&#39;</span> <span style=color:#b62;font-weight:700>\
</span></span></span><span style=display:flex><span><span style=color:#b62;font-weight:700></span>&gt; -H <span style=color:#b44>&#34;Content-Type: application/json&#34;</span>
</span></span></code></pre></div><h3 id=menghapus-hanya-replicaset>Menghapus hanya ReplicaSet</h3><p>Kamu dapat menghapus ReplicaSet tanpa memengaruhi Pod-nya menggunakan <a href=/docs/reference/generated/kubectl/kubectl-commands#delete><code>kubectl delete</code></a> dengan menggunakan opsi <code>--cascade=false</code>.
Ketika menggunakan REST API atau <em>library</em> <code>client-go</code>, kamu harus mengatur nilai <code>propagationPolicy</code> menjadi <code>Orphan</code>.
Sebagai contoh:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl proxy --port<span style=color:#666>=</span><span style=color:#666>8080</span>
</span></span><span style=display:flex><span>curl -X DELETE  <span style=color:#b44>&#39;localhost:8080/apis/extensions/v1beta1/namespaces/default/replicasets/frontend&#39;</span> <span style=color:#b62;font-weight:700>\
</span></span></span><span style=display:flex><span><span style=color:#b62;font-weight:700></span>&gt; -d <span style=color:#b44>&#39;{&#34;kind&#34;:&#34;DeleteOptions&#34;,&#34;apiVersion&#34;:&#34;v1&#34;,&#34;propagationPolicy&#34;:&#34;Orphan&#34;}&#39;</span> <span style=color:#b62;font-weight:700>\
</span></span></span><span style=display:flex><span><span style=color:#b62;font-weight:700></span>&gt; -H <span style=color:#b44>&#34;Content-Type: application/json&#34;</span>
</span></span></code></pre></div><p>Ketika ReplicaSet yang asli telah dihapus, kamu dapat membuat ReplicaSet baru untuk menggantikannya. Selama <em>field</em> <code>.spec.selector</code> yang lama dan baru memilki nilai yang sama, maka ReplicaSet baru akan mengadopsi Pod lama namun tidak serta merta membuat Pod yang sudah ada sama dan sesuai dengan templat Pod yang baru.
Untuk memperbarui Pod dengan <em>spec</em> baru dapat menggunakan <a href=/id/docs/concepts/workloads/controllers/deployment/#creating-a-deployment>Deployment</a> karena ReplicaSet tidak mendukung pembaruan secara langsung.</p><h3 id=mengisolasi-pod-dari-replicaset>Mengisolasi Pod dari ReplicaSet</h3><p>Kamu dapat menghapus Pod dari ReplicaSet dengan mengubah nilai labelnya. Cara ini dapat digunakan untuk menghapus Pod dari servis untuk keperluan <em>debugging</em>, <em>data recovery</em>, dan lainnya. Pod yang dihapus dengan cara ini akan digantikan seecara otomatis (dengan asumsi jumlah replika juga tidak berubah).</p><h3 id=mengatur-jumlah-pod-pada-replicaset>Mengatur jumlah Pod pada ReplicaSet</h3><p>Jumlah Pod pada ReplicaSet dapat diatur dengan mengubah nilai dari <em>field</em> <code>.spec.replicas</code>. Pengatur ReplicaSet akan memastikan Pod dengan jumlah yang telah ditentukan dan dengan nilai selektor yang sama sedang dalam keadaan berjalan.</p><h3 id=pengaturan-jumlah-pod-pada-replicaset-menggunakan-horizontal-pod-autoscaler>Pengaturan jumlah Pod pada ReplicaSet menggunakan Horizontal Pod Autoscaler</h3><p>Pengaturan jumlah Pod pada ReplicaSet juga dapat dilakukan mengunakan <a href=/docs/tasks/run-application/horizontal-pod-autoscale/>Horizontal Pod Autoscalers (HPA)</a>. Berikut adalah contoh HPA terhadap ReplicaSet yang telah dibuat pada contoh sebelumnya.</p><div class=highlight><div class=copy-code-icon style=text-align:right><a href=https://raw.githubusercontent.com/kubernetes/website/main/content/id/examples/controllers/hpa-rs.yaml download=controllers/hpa-rs.yaml><code>controllers/hpa-rs.yaml</code></a>
<img src=/images/copycode.svg style=max-height:24px;cursor:pointer onclick='copyCode("controllers-hpa-rs-yaml")' title="Copy controllers/hpa-rs.yaml to clipboard"></img></div><div class=includecode id=controllers-hpa-rs-yaml><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>autoscaling/v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>HorizontalPodAutoscaler<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>frontend-scaler<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>scaleTargetRef</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>ReplicaSet<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>frontend<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>minReplicas</span>:<span style=color:#bbb> </span><span style=color:#666>3</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>maxReplicas</span>:<span style=color:#bbb> </span><span style=color:#666>10</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>targetCPUUtilizationPercentage</span>:<span style=color:#bbb> </span><span style=color:#666>50</span><span style=color:#bbb>
</span></span></span></code></pre></div></div></div><p>Menyimpan <em>manifest</em> ini dalam <code>hpa-rs.yaml</code> dan mengirimkannya ke klaster Kubernetes akan membuat HPA tersebut yang akan mengatur jumlah Pod pada ReplicaSet yang telah didefinisikan bergantung terhadap penggunaan CPU dari Pod yang direplikasi.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl apply -f https://k8s.io/examples/controllers/hpa-rs.yaml
</span></span></code></pre></div><p>Opsi lainnya adalah dengan menggunakan perintah <code>kubectl autoscale</code> untuk tujuan yang sama.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl autoscale rs frontend --max<span style=color:#666>=</span><span style=color:#666>10</span>
</span></span></code></pre></div><h2 id=alternatif-selain-replicaset>Alternatif selain ReplicaSet</h2><h3 id=deployment-direkomendasikan>Deployment (direkomendasikan)</h3><p><a href=/id/docs/concepts/workloads/controllers/deployment/><code>Deployment</code></a> adalah sebuah objek yang bisa memiliki ReplicaSet dan memperbarui ReplicaSet dan Pod-nya melalui <em>rolling update</em> deklaratif dan <em>server-side</em>.
Walaupun ReplicaSet dapat digunakan secara independen, seringkali ReplicaSet digunakan oleh Deployments sebagai mekanisme untuk mengorkestrasi pembuatan, penghapusan dan pembaruan Pod. Ketika kamu menggunakan Deployments kamu tidak perlu khawatir akan pengaturan dari ReplicaSet yang dibuat. Deployments memiliki dan mengatur ReplicaSet-nya sendiri.
Maka dari itu penggunaan Deployments direkomendasikan jika kamu menginginkan ReplicaSet.</p><h3 id=pod-sederhana>Pod sederhana</h3><p>Tidak seperti pada kasus ketika pengguna secara langsung membuat Pod, ReplicaSet akan menggantikan Pod yang dihapus atau diterminasi dengan alasan apapun, seperti pada kasus dimana terjadi kegagalan <em>node</em> atau pemeliharaan <em>node</em> yang disruptif, seperti pada kasus <em>upgrade</em> kernel. Karena alasan ini kami merekomendasikan kamu untuk menggunakan ReplicaSet walaupun jika aplikasimu membutuhkan hanya satu Pod. Hal ini mirip dengan pengawas proses, hanya saja pada kasus ini mengawasi banyak Pod pada berbagai <em>node</em> alih-alih berbagai proses individu pada sebuah <em>node</em>. ReplicaSet mendelegasikan proses pengulangan kembali dari kontainer lokal kepada agen yang terdapat di <em>node</em> (sebagai contoh, Kubelet atau Docker).</p><h3 id=job>Job</h3><p>Gunakan <a href=/docs/concepts/jobs/run-to-completion-finite-workloads/><code>Job</code></a> alih-alih ReplicaSet untuk Pod yang diharapkan untuk diterminasi secara sendirinya.</p><h3 id=daemonset>DaemonSet</h3><p>Gunakan <a href=/id/docs/concepts/workloads/controllers/daemonset/><code>DaemonSet</code></a> alih-alih ReplicaSet untuk Pod yang menyediakan fungsi pada level mesin, seperti <em>monitoring</em> mesin atau <em>logging</em> mesin. Pod ini memiliki waktu hidup yang bergantung terhadap waktu hidup mesin: Pod perlu untuk berjalan pada mesin sebelum Pod lain dijalankan, dan aman untuk diterminasi ketika mesin siap untuk di-<em>reboot</em> atau dimatikan.</p><h3 id=replicationcontroller>ReplicationController</h3><p>ReplicaSet adalah suksesor dari <a href=/id/docs/concepts/workloads/controllers/replicationcontroller/><em>ReplicationControllers</em></a>. Keduanya memenuhi tujuan yang sama dan memiliki perilaku yang serupa, kecuali bahwa ReplicationController tidak mendukung kebutuhan selektor <em>set-based</em> seperti yang dijelaskan pada <a href=/id/docs/concepts/overview/working-with-objects/labels/#label-selectors>panduan penggunaan label</a>. Pada kasus tersebut, ReplicaSet lebih direkomendasikan dibandingkan ReplicationController.</p></div><div class=td-content style=page-break-before:always><h1 id=pg-27f1331d515d95f76aa1156088b4ad91>4.2.2 - ReplicationController</h1><div class="alert alert-info note callout" role=alert><strong>Catatan:</strong> <a href=/id/docs/concepts/workloads/controllers/deployment/><code>Deployment</code></a> yang mengonfigurasi <a href=/id/docs/concepts/workloads/controllers/replicaset/><code>ReplicaSet</code></a> sekarang menjadi cara yang direkomendasikan untuk melakukan replikasi.</div><p>Sebuah <em>ReplicationController</em> memastikan bahwa terdapat sejumlah Pod yang sedang berjalan dalam suatu waktu tertentu. Dengan kata lain, ReplicationController memastikan bahwa sebuah Pod atau sebuah kumpulan Pod yang homogen selalu berjalan dan tersedia.</p><h2 id=bagaimana-replicationcontroller-bekerja>Bagaimana ReplicationController Bekerja</h2><p>Jika terdapat terlalu banyak Pod, maka ReplicationController akan membatasi dan mematikan Pod-Pod yang berlebih. Jika terdapat terlalu sedikit, maka ReplicationController akan memulai dan menjalankan Pod-Pod baru lainnya. Tidak seperti Pod yang dibuat secara manual, Pod-Pod yang diatur oleh sebuah ReplicationController akan secara otomatis diganti jika mereka gagal, dihapus, ataupun dimatikan.
Sebagai contoh, Pod-Pod yang kamu miliki akan dibuat ulang dalam sebuah Node setelah terjadi proses pemeliharaan seperti pembaruan kernel. Untuk alasan ini, maka kamu sebaiknya memiliki sebuah ReplicationController bahkan ketika aplikasimu hanya membutuhkan satu buah Pod saja. Sebuah ReplicationController memiliki kemiripan dengan sebuah pengawas proses, tetapi alih-alih mengawasi sebuah proses individu pada sebuah Node, ReplicationController banyak Pod yang terdapat pada beberapa Node.</p><p>ReplicationController seringkali disingkat sebagai "rc" dalam diskusi, dan sebagai <em>shortcut</em> dalam perintah kubectl.</p><p>Sebuah contoh sederhana adalah membuat sebuah objek ReplicationController untuk menjalankan sebuah <em>instance</em> Pod secara berkelanjutan. Contoh pemakaian lainnya adalah untuk menjalankan beberapa replika identik dari sebuah servis yang direplikasi, seperti peladen web.</p><h2 id=menjalankan-sebuah-contoh-replicationcontroller>Menjalankan Sebuah Contoh ReplicationController</h2><p>Contoh ReplicationController ini mengonfigurasi tiga salinan dari peladen web nginx.</p><div class=highlight><div class=copy-code-icon style=text-align:right><a href=https://raw.githubusercontent.com/kubernetes/website/main/content/id/examples/controllers/replication.yaml download=controllers/replication.yaml><code>controllers/replication.yaml</code></a>
<img src=/images/copycode.svg style=max-height:24px;cursor:pointer onclick='copyCode("controllers-replication-yaml")' title="Copy controllers/replication.yaml to clipboard"></img></div><div class=includecode id=controllers-replication-yaml><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>ReplicationController<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>nginx<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>replicas</span>:<span style=color:#bbb> </span><span style=color:#666>3</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>selector</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>app</span>:<span style=color:#bbb> </span>nginx<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>template</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>nginx<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>labels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>app</span>:<span style=color:#bbb> </span>nginx<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>nginx<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>nginx<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>ports</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span>- <span style=color:green;font-weight:700>containerPort</span>:<span style=color:#bbb> </span><span style=color:#666>80</span></span></span></code></pre></div></div></div><p>Jalankan contoh di atas dengan mengunduh berkas contoh dan menjalankan perintah ini:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl apply -f https://k8s.io/examples/controllers/replication.yaml
</span></span></code></pre></div><pre tabindex=0><code>replicationcontroller/nginx created
</code></pre><p>Periksa status dari ReplicationController menggunakan perintah ini:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl describe replicationcontrollers/nginx
</span></span></code></pre></div><pre tabindex=0><code>Name:        nginx
Namespace:   default
Selector:    app=nginx
Labels:      app=nginx
Annotations:    &lt;none&gt;
Replicas:    3 current / 3 desired
Pods Status: 0 Running / 3 Waiting / 0 Succeeded / 0 Failed
Pod Template:
  Labels:       app=nginx
  Containers:
   nginx:
    Image:              nginx
    Port:               80/TCP
    Environment:        &lt;none&gt;
    Mounts:             &lt;none&gt;
  Volumes:              &lt;none&gt;
Events:
  FirstSeen       LastSeen     Count    From                        SubobjectPath    Type      Reason              Message
  ---------       --------     -----    ----                        -------------    ----      ------              -------
  20s             20s          1        {replication-controller }                    Normal    SuccessfulCreate    Created pod: nginx-qrm3m
  20s             20s          1        {replication-controller }                    Normal    SuccessfulCreate    Created pod: nginx-3ntk0
  20s             20s          1        {replication-controller }                    Normal    SuccessfulCreate    Created pod: nginx-4ok8v
</code></pre><p>Tiga Pod telah dibuat namun belum ada yang berjalan, kemungkinan karena <em>image</em> yang sedang di-<em>pull</em>.
Beberapa waktu kemudian, perintah yang sama akan menunjukkan:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>Pods Status:    <span style=color:#666>3</span> Running / <span style=color:#666>0</span> Waiting / <span style=color:#666>0</span> Succeeded / <span style=color:#666>0</span> Failed
</span></span></code></pre></div><p>Untuk melihat semua Pod yang dibuat oleh ReplicationController dalam bentuk yang lebih mudah dibaca mesin, kamu dapat menggunakan perintah seperti ini:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span><span style=color:#b8860b>pods</span><span style=color:#666>=</span><span style=color:#a2f;font-weight:700>$(</span>kubectl get pods --selector<span style=color:#666>=</span><span style=color:#b8860b>app</span><span style=color:#666>=</span>nginx --output<span style=color:#666>=</span><span style=color:#b8860b>jsonpath</span><span style=color:#666>={</span>.items..metadata.name<span style=color:#666>}</span><span style=color:#a2f;font-weight:700>)</span>
</span></span><span style=display:flex><span><span style=color:#a2f>echo</span> <span style=color:#b8860b>$pods</span>
</span></span></code></pre></div><pre tabindex=0><code>nginx-3ntk0 nginx-4ok8v nginx-qrm3m
</code></pre><p>Pada perintah di atas, selektor yang dimaksud adalah selektor yang sama dengan yang terdapat pada ReplicationController (yang dapat dilihat pada keluaran <code>kubectl describe</code>), dan dalam bentuk yang berbeda dengan yang terdapat pada <code>replication.yaml</code>. Opsi <code>--output=jsonpath</code> menentukan perintah untuh mendapatkan hanya nama dari setiap Pod yang ada pada daftar hasil.</p><h2 id=menulis-spesifikasi-replicationcontroller>Menulis Spesifikasi ReplicationController</h2><p>Seperti semua konfigurasi Kubernetes lainnya, sebuah ReplicationController membutuhkan <em>field</em> <code>apiVersion</code>, <code>kind</code>, dan <code>metadata</code>.</p><p>Untuk informasi umum mengenai berkas konfigurasi, kamu dapat melihat <a href=/id/docs/concepts/overview/working-with-objects/object-management/>pengaturan objek</a>.</p><p>Sebuah ReplicationController juga membutuhkan <a href=https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#spec-and-status>bagian <code>.spec</code></a>.</p><h3 id=templat-pod>Templat Pod</h3><p><code>.spec.template</code> adalah satu-satunya <em>field</em> yang diwajibkan pada <code>.spec</code>.</p><p><code>.spec.template</code> adalah sebuah <a href=/id/docs/concepts/workloads/pods/pod-overview/#pod-templates>templat Pod</a>. Ia memiliki skema yang sama persis dengan sebuah <a href=/id/docs/concepts/workloads/pods/pod/>Pod</a>, namun dapat berbentuk <em>nested</em> dan tidak memiliki <em>field</em> <code>apiVersion</code> ataupun <code>kind</code>.</p><p>Selain <em>field-field</em> yang diwajibkan untuk sebuah Pod, templat Pod pada ReplicationController harus menentukan label dan kebijakan pengulangan kembali yang tepat. Untuk label, pastikan untuk tidak tumpang tindih dengan kontroler lain. Lihat <a href=#selektor-pod>selektor pod</a>.</p><p>Nilai yang diperbolehkan untuk <a href=/id/docs/concepts/workloads/pods/pod-lifecycle/#restart-policy><code>.spec.template.spec.restartPolicy</code></a> hanyalah <code>Always</code>, yaitu nilai bawaan jika tidak ditentukan.</p><p>Untuk pengulangan kembali dari sebuah kontainer lokal, ReplicationController mendelegasikannya ke agen pada Node, contohnya <a href=/docs/admin/kubelet/>Kubelet</a> atau Docker.</p><h3 id=label-pada-replicationcontroller>Label pada ReplicationController</h3><p>ReplicationController itu sendiri dapat memiliki label (<code>.metadata.labels</code>). Biasanya, kamu akan mengaturnya untuk memiliki nilai yang sama dengan <code>.spec.template.metadata.labels</code>; jika <code>.metadata.labels</code> tidak ditentukan maka akan menggunakan nilai bawaan yaitu <code>.spec.template.metadata.labels</code>. Namun begitu, kedua label ini diperbolehkan untuk memiliki nilai yang berbeda, dan <code>.metadata.labels</code> tidak akan memengaruhi perilaku dari ReplicationController.</p><h3 id=selektor-pod>Selektor Pod</h3><p><em>Field</em> <code>.spec.selector</code> adalah sebuah <a href=/id/docs/concepts/overview/working-with-objects/labels/#label-selectors>selektor label</a>. Sebuah ReplicationController mengatur semua Pod dengan label yang sesuai dengan nilai selektor tersebut. Ia tidak membedakan antara Pod yang ia buat atau hapus atau Pod yang dibuat atau dihapus oleh orang atau proses lain. Hal ini memungkinkan ReplicationController untuk digantikan tanpa memengaruhi Pod-Pod yang sedang berjalan.</p><p>Jika ditentukan, <code>.spec.template.metadata.labels</code> harus memiliki nilai yang sama dengan <code>.spec.selector</code>, atau akan ditolak oleh API. Jika <code>.spec.selector</code> tidak ditentukan, maka akan menggunakan nilai bawaan yaitu <code>.spec.template.metadata.labels</code>.</p><p>Selain itu, kamu juga sebaiknya tidak membuat Pod dengan label yang cocok dengan selektor ini, baik secara langsung, dengan menggunakan ReplicationController lain, ataupun menggunakan kontroler lain seperti Job. Jika kamu melakukannya, ReplicationController akan menganggap bahwa ia telah membuat Pod-Pod lainnya. Kubernetes tidak akan menghentikan kamu untuk melakukan aksi ini.</p><p>Jika kamu pada akhirnya memiliki beberapa kontroler dengan selektor-selektor yang tumpang tindih, kamu harus mengatur penghapusannya sendiri (lihat <a href=#bekerja-dengan-replicationcontroller>di bawah</a>).</p><h3 id=beberapa-replika>Beberapa Replika</h3><p>Kamu dapat menentukan jumlah Pod yang seharusnya berjalan secara bersamaan dengan mengatur nilai <code>.spec.replicas</code> dengan jumlah Pod yang kamu inginkan untuk berjalan secara bersamaan. Jumlah yang berjalan dalam satu satuan waktu dapat lebih tinggi ataupun lebih rendah, seperti jika replika-replika tersebut melewati proses penambahan atau pengurangan, atau jika sebuah Pod melalui proses <em>graceful shutdown</em>, dan penggantinya telah dijalankan terlebih dahulu.</p><p>Jika kamu tidak menentukan nilai dari <code>.spec.replicas</code>, maka akan digunakan nilai bawaan 1.</p><h2 id=bekerja-dengan-replicationcontroller>Bekerja dengan ReplicationController</h2><h3 id=menghapus-sebuah-replicationcontroller-dan-pod-nya>Menghapus Sebuah ReplicationController dan Pod-nya</h3><p>Untuk menghapus sebuah ReplicationController dan Pod-Pod yang berhubungan dengannya, gunakan perintah <a href=/docs/reference/generated/kubectl/kubectl-commands#delete><code>kubectl delete</code></a>. Kubectl akan mengatur ReplicationController ke nol dan menunggunya untuk menghapus setiap Pod sebelum menghapus ReplicationController itu sendiri. Jika perintah kubectl ini terhenti, maka dapat diulang kembali.</p><p>Ketika menggunakan REST API atau <em>library</em> klien go, maka kamu perlu melakukan langkah-langkahnya secara eksplisit (mengatur replika-replika ke 0, menunggu penghapusan Pod, dan barulah menghapus ReplicationController).</p><h3 id=menghapus-hanya-replicationcontroller>Menghapus Hanya ReplicationController</h3><p>Kamu dapat menghapus ReplicationController tanpa memengaruhi Pod-Pod yang berhubungan dengannya.</p><p>Dengan menggunakan kubectl, tentukan opsi <code>--cascade=false</code> ke <a href=/docs/reference/generDeated/kubectl/kubectl-commands#delete><code>kubectl delete</code></a>.</p><p>Ketika menggunakan REST API atau <em>library</em> klien go, cukup hapus objek ReplicationController.</p><p>Ketika ReplicationController yang asli telah dihapus, kamu dapat membuat ReplicationController yang baru sebagai penggantinya. Selama <code>.spec.selector</code> yang lama dan baru memiliki nilai yang sama, maka ReplicationController baru akan mengadopsi Pod-Pod yang lama.
Walaupun begitu, ia tidak akan melakukan usaha apapun untuk membuat Pod-Pod yang telah ada sebelumnya untuk sesuai dengan templat Pod yang baru dan berbeda.
Untuk memperbarui Pod-Pod ke spesifikasi yang baru dengan cara yang terkontrol, gunakan <a href=#pembaruan-bergulir>pembaruan bergulir</a>.</p><h3 id=mengisolasi-pod-dari-replicationcontroller>Mengisolasi Pod dari ReplicationController</h3><p>Pod-Pod dapat dihapus dari kumpulan target sebuah ReplicationController dengan mengganti nilai dari labelnya. Teknik ini dapat digunakan untuk mencopot Pod-Pod dari servis untuk keperluan pengawakutuan (<em>debugging</em>), pemulihan data, dan lainnya. Pod-Pod yang dicopot dengan cara ini dapat digantikan secara otomatis (dengan asumsi bahwa jumlah replika juga tidak berubah).</p><h2 id=pola-penggunaan-umum>Pola penggunaan umum</h2><h3 id=penjadwalan-ulang>Penjadwalan ulang</h3><p>Seperti yang telah disebutkan sebelumnya, baik kamu memiliki hanya 1 Pod untuk tetap dijalankan, ataupun 1000, ReplicationController akan memastikan tersedianya jumlah Pod yang telat ditentukan, bahkan ketika terjadi kegagalan Node atau terminasi Pod (sebagai contoh karena adanya tindakan dari agen kontrol lain).</p><h3 id=penskalaan>Penskalaan</h3><p>ReplicationController memudahkan penskalaan jumlah replika, baik meningkatkan ataupun mengurangi, secara manual ataupun dengan agen kontrol penskalaan otomatis, dengan hanya mengubah nilai dari <em>field</em> <code>replicas</code>.</p><h3 id=pembaruan-bergulir>Pembaruan bergulir</h3><p>ReplicationController didesain untuk memfasilitasi pembaruan bergulir untuk sebuah servis dengan mengganti Pod-Pod satu per satu.</p><p>Seperti yang telah dijelaskan di <a href=http://issue.k8s.io/1353>#1353</a>, pendekatan yang direkomendasikan adalah dengan membuat ReplicationController baru dengan 1 replika, skala kontroler yang baru (+1) atau yang lama (-1) satu per satu, dan kemudian hapus kontroler lama setelah menyentuh angka 0 replika. Hal ini memungkinkan pembaruan dilakukan dengan dapat diprediksi terlepas dari adanya kegagalan yang tak terduga.</p><p>Idealnya, kontroler pembaruan bergulir akan memperhitungkan kesiapan dari aplikasi, dan memastikan cukupnya jumlah Pod yang secara produktif meladen kapanpun.</p><p>Dua ReplicationController diharuskan untuk memiliki setidaknya satu label yang berbeda, seperti <em>tag</em> <em>image</em> dari kontainer utama dari Pod, karena pembaruan bergulir biasanya dilakukan karena adanya pembaruan <em>image</em>.</p><p>Pembaruan bergulir diimplementasikan pada perkakas klien <a href=/docs/reference/generated/kubectl/kubectl-commands#rolling-update><code>kubectl rolling-update</code></a>. Lihat <a href=/docs/tasks/run-application/rolling-update-replication-controller/><code>kubectl rolling-update</code> task</a> untuk contoh-contoh yang lebih konkrit.</p><h3 id=operasi-rilis-majemuk>Operasi rilis majemuk</h3><p>Selain menjalankan beberapa rilis dari sebuah aplikasi ketika proses pembaruan bergulir sedang berjalan, adalah hal yang awam untuk menjalankan beberapa rilis untuk suatu periode waktu tertentu, atau bahkan secara kontinu, menggunakan operasi rilis majemuk. Operasi-operasi ini akan dibedakan menggunakan label.</p><p>Sebagai contoh, sebuah servis dapat menyasar semua Pod dengan <code>tier in (frontend), environment in (prod)</code>. Anggap kamu memiliki 10 Pod tiruan yang membangun <em>tier</em> ini tetapi kamu ingin bisa menggunakan 'canary' terhadap versi baru dari komponen ini. Kamu dapat mengatur sebuah ReplicationController dengan nilai <code>replicas</code> 9 untuk replika-replikanya, dengan label <code>tier=frontend, environment=prod, track=stable</code>, dan ReplicationController lainnya dengan nilai <code>replicas</code> 1 untuk canary, dengan label <code>tier=frontend, environment=prod, track=canary</code>. Sekarang servis sudah mencakup baik canary maupun Pod-Pod yang bukan canary. Kamu juga dapat mencoba-coba ReplicationController secara terpisah untuk melakukan pengujian, mengamati hasilnya, dan lainnya.</p><h3 id=menggunakan-replicationcontroller-dengan-service>Menggunakan ReplicationController dengan Service</h3><p>Beberapa ReplicationController dapat berada di belakang sebuah Service, sedemikian sehingga, sebagai contoh, sebagian <em>traffic</em> dapat ditujukan ke versi lama, dan sebagian lainnya ke versi yang baru.</p><p>Sebuah ReplicationController tidak akan berhenti dengan sendirinya, namun ia tidak diekspektasikan untuk berjalan selama Service-Service yang ada. Service dapat terdiri dari berbagai Pod yang dikontrol beberapa ReplicationController, dan terdapat kemungkinan bahwa beberapa ReplicationController untuk dibuat dan dimatikan dalam jangka waktu hidup Service (contohnya adalah untuk melakukan pembaruan Pod-Pod yang menjalankan Service). Baik Service itu sendiri dan kliennya harus tetap dalam keadaan tidak mempunyai pengetahuan terhadap ReplicationController yang memelihara Pod-Pod dari Service tersebut.</p><h2 id=menulis-program-untuk-replikasi>Menulis program untuk Replikasi</h2><p>Pod-Pod yang dibuat oleh ReplicationController ditujukan untuk dapat sepadan dan memiliki semantik yang identik, walaupun konfigurasi mereka dapat berbeda seiring keberjalanan waktunya. Ini adalah contoh yang cocok untuk peladen <em>stateless</em>, namun ReplicationController juga dapat digunakan untuk memelihara ketersediaan dari aplikasi-aplikasi yang <em>master-elected</em>, <em>sharded</em>, <em>worker-pool</em>. Aplikasi-aplikasi seperti itu sebaiknya menggunakan mekanisme penetapan kerja yang dinamis, seperti <a href=https://www.rabbitmq.com/tutorials/tutorial-two-python.html>antrian kerja RabbitMQ</a>, berlainan dengan pengubahan statis/satu kali dari konfigurasi setiap Pod, yang dipandang sebagai sebuah <em>anti-pattern</em>. Pengubahan apapun yang dilakukan terhadap Pod, seperti <em>auto-sizing</em> vertikal dari sumber daya (misalnya cpu atau memori), sebaiknya dilakukan oleh proses kontroller luring lainnya, dan bukan oleh ReplicationController itu sendiri.</p><h2 id=tanggung-jawab-replicationcontroller>Tanggung Jawab ReplicationController</h2><p>ReplicationController hanya memastikan ketersediaan dari sejumlah Pod yang cocok dengan selektor label dan berjalan dengan baik. Saat ini, hanya Pod yang diterminasi yang dijadikan pengecualian dari penghitungan. Kedepannya, <a href=http://issue.k8s.io/620>kesiapan</a> dan informasi yang ada lainnya dari sistem dapat menjadi pertimbangan, kami dapat meningkatkan kontrol terhadap kebijakan penggantian, dan kami berencana untuk menginformasikan kejadian (<em>event</em>) yang dapat digunakan klien eksternal untuk implementasi penggantian yang sesuai dan/atau kebijakan pengurangan.</p><p>ReplicationController akan selalu dibatasi terhadap tanggung jawab spesifik ini. Ia tidak akan melakukan <em>probe</em> kesiapan atau keaktifan. Daripada melakukan <em>auto-scaling</em>, ia ditujukan untuk dikontrol oleh <em>auto-scaler</em> eksternal (seperti yang didiskusikan pada <a href=http://issue.k8s.io/492>#492</a>), yang akan mengganti <em>field</em> <code>replicas</code>. Kami tidak akan menambahkan kebijakan penjadwalan (contohnya <a href=http://issue.k8s.io/367#issuecomment-48428019><em>spreading</em></a>) untuk ReplicationController. Ia juga tidak seharusnya melakukan verifikasi terhadap Pod-Pod yang sedang dikontrol yang cocok dengan spesifikasi templat saat ini, karena hal itu dapat menghambat <em>auto-sizing</em> dan proses otomatis lainnya. Demikian pula batas waktu penyelesaian, pengurutan <em>dependencies</em>, ekspansi konfigurasi, dan fitur-fitur lain yang seharusnya berada di komponen lain. Kami juga bahkan berencana untuk mengeluarkan mekanisme pembuatan Pod secara serentak (<a href=http://issue.k8s.io/170>#170</a>).</p><p>ReplicationController ditujukan untuk menjadi primitif komponen yang dapat dibangun untuk berbagai kebutuhan. Kami menargetkan API dengan tingkatan yang lebih tinggi dan/atau perkakas-perkakas untuk dibangun di atasnya dan primitif tambahan lainnya untuk kenyamanan pengguna kedepannya. Operasi-operasi makro yang sudah didukung oleh kubectl (<em>run</em>, <em>scale</em>, <em>rolling-update</em>) adalah contoh <em>proof-of-concept</em> dari konsep ini. Sebagai contohnya, kita dapat menganggap sesuatu seperti <a href=http://techblog.netflix.com/2012/06/asgard-web-based-cloud-management-and.html>Asgard</a> yang mengatur beberapa ReplicationController, <em>auto-scaler</em>, servis, kebijakan penjadwalan, canary, dan yang lainnya.</p><h2 id=objek-api>Objek API</h2><p>ReplicationController adalah sebuah sumber daya <em>top-level</em> pada REST API Kubernetes. Detil dari objek API dapat ditemukan di: <a href=/docs/reference/generated/kubernetes-api/v1.25/#replicationcontroller-v1-core>objek API ReplicationController</a>.</p><h2 id=alternatif-untuk-replicationcontroller>Alternatif untuk ReplicationController</h2><h3 id=replicaset>ReplicaSet</h3><p><a href=/id/docs/concepts/workloads/controllers/replicaset/><code>ReplicaSet</code></a> adalah kelanjutan dari ReplicationController yang mendukung selektor <a href=/id/docs/concepts/overview/working-with-objects/labels/#set-based-requirement>selektor label <em>set-based</em></a> yang baru. Umumnya digunakan oleh <a href=/id/docs/concepts/workloads/controllers/deployment/><code>Deployment</code></a> sebagai mekanisme untuk mengorkestrasi pembuatan, penghapusan, dan pembaruan Pod.
Perhatikan bahwa kami merekomendasikan untuk menggunakan Deployment sebagai ganti dari menggunakan ReplicaSet secara langsung, kecuali jika kamu membutuhkan orkestrasi pembaruan khusus atau tidak membutuhkan pembaruan sama sekali.</p><h3 id=deployment-direkomendasikan>Deployment (Direkomendasikan)</h3><p><a href=/id/docs/concepts/workloads/controllers/deployment/><code>Deployment</code></a> adalah objek API tingkat tinggi yang memperbarui ReplicaSet dan Pod-Pod di bawahnya yang mirip dengan cara kerja <code>kubectl rolling-update</code>. Deployment direkomendasikan jika kamu menginginkan fungsionalitas dari pembaruan bergulir ini, karena tidak seperti <code>kubectl rolling-update</code>, Deployment memiliki sifat deklaratif, <em>server-side</em>, dan memiliki beberapa fitur tambahan lainnya.</p><h3 id=pod-sederhana>Pod sederhana</h3><p>Tidak seperti pada kasus ketika pengguna secara langsung membuat Pod, ReplicationController menggantikan Pod-Pod yang dihapus atau dimatikan untuk alasan apapun, seperti pada kasus kegagalan Node atau pemeliharaan Node yang disruptif, seperti pembaruan kernel. Untuk alasan ini, kami merekomendasikan kamu untuk menggunakan ReplicationController bahkan ketika aplikasimu hanya membutuhkan satu Pod saja. Anggap hal ini mirip dengan pengawas proses, hanya pada kasus ini mengawasi banyak Pod yang terdapat pada berbagai Node dan bukan proses-proses tunggal pada satu Node. ReplicationController mendelegasikan pengulangan kontainer lokal ke agen yang terdapat dalam Node (contohnya Kubelet atau Docker).</p><h3 id=job>Job</h3><p>Gunakan <a href=/docs/concepts/jobs/run-to-completion-finite-workloads/><code>Job</code></a> sebagai ganti ReplicationController untuk Pod-Pod yang diharapkan diterminasi dengan sendirinya (seperti <em>batch jobs</em>).</p><h3 id=daemonset>DaemonSet</h3><p>Gunakan <a href=/id/docs/concepts/workloads/controllers/daemonset/><code>DaemonSet</code></a> sebagai ganti ReplicationController untuk Pod-Pod yang menyediakan fungsi pada level mesin, seperti pengamatan mesin atau pencatatan mesin. Pod-Pod ini memiliki waktu hidup yang bergantung dengan waktu hidup mesin: Pod butuh untuk dijalankan di mesin sebelum Pod-Pod lainnya dimulai, dan aman untuk diterminasi ketika mesin sudah siap untuk dinyalakan ulang atau dimatikan.</p><h2 id=informasi-lanjutan>Informasi lanjutan</h2><p>Baca <a href=/docs/tutorials/stateless-application/run-stateless-ap-replication-controller/>Menjalankan Kontroler Replikasi AP <em>Stateless</em></a>.</p></div><div class=td-content style=page-break-before:always><h1 id=pg-a2dc0393e0c4079e1c504b6429844e86>4.2.3 - Deployment</h1><p>Deployment menyediakan pembaruan <a href=/id/docs/concepts/workloads/pods/pod/>Pods</a> dan
<a href=/id/docs/concepts/workloads/controllers/replicaset/>ReplicaSets</a> secara deklaratif.</p><p>Kamu mendeskripsikan sebuah state yang diinginkan dalam Deployment, kemudian Deployment <a class=glossary-tooltip title='Kontrol tertutup yang mengawasi kondisi bersama dari klaster melalui apiserver dan membuat perubahan yang mencoba untuk membawa kondisi saat ini ke kondisi yang diinginkan.' data-toggle=tooltip data-placement=top href=/id/docs/concepts/architecture/controller/ target=_blank aria-label=Pengontrol>Pengontrol</a> mengubah state sekarang menjadi seperti pada deskripsi secara bertahap. Kamu dapat mendefinisikan Deployment untuk membuat ReplicaSets baru atau untuk menghapus Deployment yang sudah ada dan mengadopsi semua resourcenya untuk Deployment baru.</p><div class="alert alert-info note callout" role=alert><strong>Catatan:</strong> Jangan mengganti ReplicaSets milik Deployment. Pertimbangkan untuk membuat isu pada repositori utama Kubernetes jika kasusmu tidak diatasi semua kasus di bawah.</div><h2 id=penggunaan>Penggunaan</h2><p>Berikut adalah penggunaan yang umum pada Deployment:</p><ul><li><a href=#membuat-deployment>Membuat Deployment untuk merilis ReplicaSet</a>. ReplicaSet membuat Pod di belakang layar. Cek status rilis untuk tahu proses rilis sukses atau tidak.</li><li><a href=#membarui-deployment>Mendeklarasikan state baru dari Pods</a> dengan membarui PodTemplateSpec milik Deployment. ReplicaSet baru akan dibuat dan Deployment mengatur perpindahan Pod secara teratur dari ReplicaSet lama ke ReplicaSet baru. Tiap ReplicaSet baru akan mengganti revisi Deployment.</li><li><a href=#membalikkan-deployment>Mengembalikan ke revisi Deployment sebelumnya</a> jika state Deployment sekarang tidak stabil. Tiap pengembalian mengganti revisi Deployment.</li><li><a href=#mengatur-skala-deployment>Memperbesar Deployment untuk memfasilitasi beban yang lebih</a>.</li><li><a href=#menjeda-dan-melanjutkan-deployment>Menjeda Deployment</a> untuk menerapkan perbaikan pada PodTemplateSpec-nya, lalu melanjutkan untuk memulai rilis baru.</li><li><a href=#status-deployment>Memakai status Deployment</a> sebagai indikator ketika rilis tersendat.</li><li><a href=#kebijakan-pembersihan>Membersihkan ReplicaSet lama</a> yang sudah tidak terpakai.</li></ul><h2 id=membuat-deployment>Membuat Deployment</h2><p>Berikut adalah contoh Deployment. Dia membuat ReplicaSet untuk membangkitkan tiga Pod <code>nginx</code>:</p><div class=highlight><div class=copy-code-icon style=text-align:right><a href=https://raw.githubusercontent.com/kubernetes/website/main/content/id/examples/controllers/nginx-deployment.yaml download=controllers/nginx-deployment.yaml><code>controllers/nginx-deployment.yaml</code></a>
<img src=/images/copycode.svg style=max-height:24px;cursor:pointer onclick='copyCode("controllers-nginx-deployment-yaml")' title="Copy controllers/nginx-deployment.yaml to clipboard"></img></div><div class=includecode id=controllers-nginx-deployment-yaml><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>apps/v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Deployment<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>nginx-deployment<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>labels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>app</span>:<span style=color:#bbb> </span>nginx<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>replicas</span>:<span style=color:#bbb> </span><span style=color:#666>3</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>selector</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>matchLabels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>app</span>:<span style=color:#bbb> </span>nginx<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>template</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>labels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>app</span>:<span style=color:#bbb> </span>nginx<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>nginx<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>nginx:1.7.9<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>ports</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span>- <span style=color:green;font-weight:700>containerPort</span>:<span style=color:#bbb> </span><span style=color:#666>80</span><span style=color:#bbb>
</span></span></span></code></pre></div></div></div><p>Dalam contoh ini:</p><ul><li><p>Deployment baru akan dibuat dengan nama <code>nginx-deployment</code>, tertulis pada kolom <code>.metadata.name</code>.</p></li><li><p>Deployment membuat tiga Pod yang direplikasi, ditandai dengan kolom <code>replicas</code>.</p></li><li><p>Kolom <code>selector</code> mendefinisikan bagaimana Deployment menemukan Pod yang diatur.
Dalam kasus ini, kamu hanya perlu memilih sebuah label yang didefinisikan pada templat Pod (<code>app: nginx</code>).
Namun, aturan pemilihan yang lebih canggih mungkin dilakukan asal templat Pod-nya memenuhi aturan.<div class="alert alert-info note callout" role=alert><strong>Catatan:</strong> Kolom <code>matchLabels</code> berbentuk pasangan {key,value}. Sebuah {key,value} dalam <em>map</em> <code>matchLabels</code> ekuivalen dengan
elemen pada <code>matchExpressions</code>, yang mana kolom key adalah "key", operator adalah "In", dan larik values hanya berisi "value".
Semua prasyarat dari <code>matchLabels</code> maupun <code>matchExpressions</code> harus dipenuhi agar dapat dicocokkan.</div></p></li><li><p>Kolom <code>template</code> berisi sub kolom berikut:</p><ul><li>Pod dilabeli <code>app: nginx</code> dengan kolom <code>labels</code>.</li><li>Spesifikasi templat Pod atau kolom <code>.template.spec</code> menandakan bahwa Pod mennjalankan satu kontainer <code>nginx</code>,
yang menjalankan image <code>nginx</code> <a href=https://hub.docker.com/>Docker Hub</a> dengan versi 1.7.9.</li><li>Membuat satu kontainer bernama <code>nginx</code> sesuai kolom <code>name</code>.</li></ul><p>Ikuti langkah-langkah berikut untuk membuat Deployment di atas:</p><p>Sebelum memulai, pastikan klaster Kubernetes sedang menyala dan bekerja.</p><ol><li><p>Buat Deployment dengan menjalankan perintah berikut:</p><div class="alert alert-info note callout" role=alert><strong>Catatan:</strong> Kamu dapat menambahkan argument <code>--record</code> untuk menulis perintah yang dijalankan pada anotasi sumber daya <code>kubernetes.io/change-cause</code>. Ini berguna untuk pemeriksaan di masa depan.
Contohnya yaitu untuk melihat perintah yang dijalankan pada tiap revisi Deployment.</div></li></ol><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl apply -f https://k8s.io/examples/controllers/nginx-deployment.yaml
</span></span></code></pre></div><ol start=2><li>Jalankan <code>kubectl get deployments</code> untuk mengecek apakah Deployment telah dibuat. Jika Deployment masih sedang pembuatan, keluaran akan tampil seperti berikut:</li></ol><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>NAME               DESIRED   CURRENT   UP-TO-DATE   AVAILABLE   AGE
</span></span><span style=display:flex><span>nginx-deployment   <span style=color:#666>3</span>         <span style=color:#666>0</span>         <span style=color:#666>0</span>            <span style=color:#666>0</span>           1s
</span></span></code></pre></div><p>Ketika kamu memeriksa Deployments pada klastermu, kolom berikut akan tampil:</p><pre><code>* `NAME` menampilkan daftar nama Deployment pada klaster.
* `DESIRED` menampilkan jumlah replika aplikasi yang diinginkan sesuai yang didefinisikan saat pembuatan Deployment. Ini adalah _state_ yang diinginkan.
* `CURRENT` menampilkan berapa jumlah replika yang sedang berjalan.
* `UP-TO-DATE` menampilkan jumlah replika yang diperbarui agar sesuai state yang diinginkan.
* `AVAILABLE` menampilkan jumlah replika aplikasi yang dapat diakses pengguna.
* `AGE` menampilkan lama waktu aplikasi telah berjalan.
</code></pre><p>Perhatikan bahwa jumlah replika yang diinginkan adalah tiga sesuai kolom <code>.spec.replicas</code>.</p><ol start=3><li>Untuk melihat status rilis Deployment, jalankan <code>kubectl rollout status deployment.v1.apps/nginx-deployment</code>. Keluaran akan tampil seperti berikut:</li></ol><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>Waiting <span style=color:#a2f;font-weight:700>for</span> rollout to finish: <span style=color:#666>2</span> out of <span style=color:#666>3</span> new replicas have been updated...
</span></span><span style=display:flex><span>deployment <span style=color:#b44>&#34;nginx-deployment&#34;</span> successfully rolled out
</span></span></code></pre></div><ol start=4><li>Jalankan <code>kubectl get deployments</code> lagi beberapa saat kemudian. Keluaran akan tampil seperti berikut:</li></ol><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>NAME               DESIRED   CURRENT   UP-TO-DATE   AVAILABLE   AGE
</span></span><span style=display:flex><span>nginx-deployment   <span style=color:#666>3</span>         <span style=color:#666>3</span>         <span style=color:#666>3</span>            <span style=color:#666>3</span>           18s
</span></span></code></pre></div><p>Perhatikan bahwa Deployment telah membuat ketiga replika dan semua replika sudah merupakan yang terbaru (mereka mengandung pembaruan terakhir templat Pod) dan dapat diakses.</p><ol start=5><li>Untuk melihat ReplicaSet (<code>rs</code>) yang dibuat Deployment, jalankan <code>kubectl get rs</code>. Keluaran akan tampil seperti berikut:</li></ol><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>NAME                          DESIRED   CURRENT   READY   AGE
</span></span><span style=display:flex><span>nginx-deployment-75675f5897   <span style=color:#666>3</span>         <span style=color:#666>3</span>         <span style=color:#666>3</span>       18s
</span></span></code></pre></div><p>Perhatikan bahwa nama ReplicaSet selalu dalam format <code>[NAMA-DEPLOYMENT]-[KATA-ACAK]</code>. Kata acak dibangkitkan secara acak dan menggunakan pod-template-hash sebagai benih.</p><ol start=6><li>Untuk melihat label yang dibangkitkan secara otomatis untuk tiap Pod, jalankan <code>kubectl get pods --show-labels</code>. Perintah akan menghasilkan keluaran berikut:</li></ol><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>NAME                                READY     STATUS    RESTARTS   AGE       LABELS
</span></span><span style=display:flex><span>nginx-deployment-75675f5897-7ci7o   1/1       Running   <span style=color:#666>0</span>          18s       <span style=color:#b8860b>app</span><span style=color:#666>=</span>nginx,pod-template-hash<span style=color:#666>=</span><span style=color:#666>3123191453</span>
</span></span><span style=display:flex><span>nginx-deployment-75675f5897-kzszj   1/1       Running   <span style=color:#666>0</span>          18s       <span style=color:#b8860b>app</span><span style=color:#666>=</span>nginx,pod-template-hash<span style=color:#666>=</span><span style=color:#666>3123191453</span>
</span></span><span style=display:flex><span>nginx-deployment-75675f5897-qqcnn   1/1       Running   <span style=color:#666>0</span>          18s       <span style=color:#b8860b>app</span><span style=color:#666>=</span>nginx,pod-template-hash<span style=color:#666>=</span><span style=color:#666>3123191453</span>
</span></span></code></pre></div><p>ReplicaSet yang dibuat menjamin bahwa ada tiga Pod <code>nginx</code>.</p><div class="alert alert-info note callout" role=alert><strong>Catatan:</strong> Kamu harus memasukkan selektor dan label templat Pod yang benar pada Deployment (dalam kasus ini, <code>app: nginx</code>).
Jangan membuat label atau selektor yang beririsan dengan kontroler lain (termasuk Deployment dan StatefulSet lainnya). Kubernetes tidak akan mencegah adanya label yang beririsan.
Namun, jika beberapa kontroler memiliki selektor yang beririsan, kontroler itu mungkin akan konflik dan berjalan dengan tidak semestinya.</div></li></ul><h3 id=label-pod-template-hash>Label pod-template-hash</h3><div class="alert alert-info note callout" role=alert><strong>Catatan:</strong> Jangan ubah label ini.</div><p>Label <code>pod-template-hash</code> ditambahkan oleh Deployment kontroler pada tiap ReplicaSet yang dibuat atau diadopsi Deployment.</p><p>Label ini menjamin anak-anak ReplicaSet milik Deployment tidak tumpang tindih. Dia dibangkitkan dengan melakukan hash pada <code>PodTemplate</code> milik ReplicaSet dan memakainya sebagai label untuk ditambahkan ke selektor ReplicaSet, label templat Pod, dan Pod apapun yang ReplicaSet miliki.</p><h2 id=membarui-deployment>Membarui Deployment</h2><div class="alert alert-info note callout" role=alert><strong>Catatan:</strong> Rilis Deployment hanya dapat dipicu oleh perubahan templat Pod Deployment (yaitu, <code>.spec.template</code>), contohnya perubahan kolom label atau image container. Yang lain, seperti replika, tidak akan memicu rilis.</div><p>Ikuti langkah-langkah berikut untuk membarui Deployment:</p><ol><li><p>Ganti Pod nginx menjadi image <code>nginx:1.9.1</code> dari image <code>nginx:1.7.9</code>.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl --record deployment.apps/nginx-deployment <span style=color:#a2f>set</span> image deployment.v1.apps/nginx-deployment <span style=color:#b8860b>nginx</span><span style=color:#666>=</span>nginx:1.9.1
</span></span></code></pre></div><p>Keluaran akan tampil seperti berikut:</p><pre tabindex=0><code>deployment.apps/nginx-deployment image updated
</code></pre><p>Alternatif lainnya, kamu dapat <code>edit</code> Deployment dan mengganti <code>.spec.template.spec.containers[0].image</code> dari <code>nginx:1.7.9</code> ke <code>nginx:1.9.1</code>:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl edit deployment.v1.apps/nginx-deployment
</span></span></code></pre></div><p>Keluaran akan tampil seperti berikut:</p><pre tabindex=0><code>deployment.apps/nginx-deployment edited
</code></pre></li><li><p>Untuk melihat status rilis, jalankan:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl rollout status deployment.v1.apps/nginx-deployment
</span></span></code></pre></div><p>Keluaran akan tampil seperti berikut:</p><pre tabindex=0><code>Waiting for rollout to finish: 2 out of 3 new replicas have been updated...
</code></pre><p>atau</p><pre tabindex=0><code>deployment &#34;nginx-deployment&#34; successfully rolled out
</code></pre></li></ol><p>Untuk menampilkan detail lain dari Deployment yang terbaru:</p><ul><li><p>Setelah rilis sukses, kamu dapat melihat Deployment dengan menjalankan <code>kubectl get deployments</code>.
Keluaran akan tampil seperti berikut:</p><pre tabindex=0><code>NAME               DESIRED   CURRENT   UP-TO-DATE   AVAILABLE   AGE
nginx-deployment   3         3         3            3           36s
</code></pre></li><li><p>Jalankan <code>kubectl get rs</code> to see that the Deployment updated the Pods dengan membuat ReplicaSet baru dan
menggandakannya menjadi 3 replika, sembari menghapus ReplicaSet menjadi 0 replika.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get rs
</span></span></code></pre></div><p>Keluaran akan tampil seperti berikut:</p><pre tabindex=0><code>NAME                          DESIRED   CURRENT   READY   AGE
nginx-deployment-1564180365   3         3         3       6s
nginx-deployment-2035384211   0         0         0       36s
</code></pre></li><li><p>Menjalankan <code>get pods</code> sekarang hanya akan menampilkan Pod baru:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get pods
</span></span></code></pre></div><p>Keluaran akan tampil seperti berikut:</p><pre tabindex=0><code>NAME                                READY     STATUS    RESTARTS   AGE
nginx-deployment-1564180365-khku8   1/1       Running   0          14s
nginx-deployment-1564180365-nacti   1/1       Running   0          14s
nginx-deployment-1564180365-z9gth   1/1       Running   0          14s
</code></pre><p>Selanjutnya ketika ingin membarui Pod, kamu hanya perlu mengganti templat Pod Deployment lagi.</p><p>Deployment memastikan hanya ada beberapa Pod yang mati saat pembaruan berlangsung. Umumnya,
dia memastikan paling sedikit ada 75% jumlah Pod yang diinginkan menyala (25% maksimal tidak dapat diakses).</p><p>Deployment juga memastikan hanya ada beberapa Pod yang dibuat melebihi jumlah Pod yang diinginkan.
Umumnya, dia memastikan paling banyak ada 125% jumlah Pod yang diinginkan menyala (25% tambahan maksimal).</p><p>Misalnya, jika kamu lihat Deployment diatas lebih jauh, kamu akan melihat bahwa pertama-tama dia membuat Pod baru,
kemudian menghapus beberapa Pod lama, dan membuat yang baru. Dia tidak akan menghapus Pod lama sampai ada cukup
Pod baru menyala, dan pula tidak membuat Pod baru sampai ada cukup Pod lama telah mati.
Dia memastikan paling sedikit 2 Pod menyala dan paling banyak total 4 Pod menyala.</p></li><li><p>Melihat detil Deployment:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl describe deployments
</span></span></code></pre></div><p>Keluaran akan tampil seperti berikut:</p><pre tabindex=0><code>Name:                   nginx-deployment
Namespace:              default
CreationTimestamp:      Thu, 30 Nov 2017 10:56:25 +0000
Labels:                 app=nginx
Annotations:            deployment.kubernetes.io/revision=2
Selector:               app=nginx
Replicas:               3 desired | 3 updated | 3 total | 3 available | 0 unavailable
StrategyType:           RollingUpdate
MinReadySeconds:        0
RollingUpdateStrategy:  25% max unavailable, 25% max surge
Pod Template:
  Labels:  app=nginx
   Containers:
    nginx:
      Image:        nginx:1.9.1
      Port:         80/TCP
      Environment:  &lt;none&gt;
      Mounts:       &lt;none&gt;
    Volumes:        &lt;none&gt;
  Conditions:
    Type           Status  Reason
    ----           ------  ------
    Available      True    MinimumReplicasAvailable
    Progressing    True    NewReplicaSetAvailable
  OldReplicaSets:  &lt;none&gt;
  NewReplicaSet:   nginx-deployment-1564180365 (3/3 replicas created)
  Events:
    Type    Reason             Age   From                   Message
    ----    ------             ----  ----                   -------
    Normal  ScalingReplicaSet  2m    deployment-controller  Scaled up replica set nginx-deployment-2035384211 to 3
    Normal  ScalingReplicaSet  24s   deployment-controller  Scaled up replica set nginx-deployment-1564180365 to 1
    Normal  ScalingReplicaSet  22s   deployment-controller  Scaled down replica set nginx-deployment-2035384211 to 2
    Normal  ScalingReplicaSet  22s   deployment-controller  Scaled up replica set nginx-deployment-1564180365 to 2
    Normal  ScalingReplicaSet  19s   deployment-controller  Scaled down replica set nginx-deployment-2035384211 to 1
    Normal  ScalingReplicaSet  19s   deployment-controller  Scaled up replica set nginx-deployment-1564180365 to 3
    Normal  ScalingReplicaSet  14s   deployment-controller  Scaled down replica set nginx-deployment-2035384211 to 0
</code></pre><p>Disini bisa dilihat ketika pertama Deployment dibuat, dia membuat ReplicaSet (nginx-deployment-2035384211)
dan langsung menggandakannya menjadi 3 replika. Saat Deployment diperbarui, dia membuat ReplicaSet baru
(nginx-deployment-1564180365) dan menambah 1 replika kemudian mengecilkan ReplicaSet lama menjadi 2,
sehingga paling sedikit 2 Pod menyala dan paling banyak 4 Pod dibuat setiap saat. Dia kemudian lanjut menaik-turunkan
ReplicaSet baru dan ReplicaSet lama, dengan strategi pembaruan rolling yang sama.
Terakhir, kamu akan dapat 3 replika di ReplicaSet baru telah menyala, dan ReplicaSet lama akan hilang (berisi 0).</p></li></ul><h3 id=perpanjangan-alias-banyak-pembaruan-secara-langsung>Perpanjangan (alias banyak pembaruan secara langsung)</h3><p>Setiap kali Deployment baru is teramati oleh Deployment kontroler, ReplicaSet dibuat untuk membangkitkan Pod sesuai keinginan.
Jika Deployment diperbarui, ReplicaSet yang terkait Pod dengan label <code>.spec.selector</code> yang cocok,
namun kolom <code>.spec.template</code> pada templat tidak cocok akan dihapus. Kemudian, ReplicaSet baru akan
digandakan sebanyak <code>.spec.replicas</code> dan semua ReplicaSet lama dihapus.</p><p>Jika kamu mengubah Deployment saat rilis sedang berjalan, Deployment akan membuat ReplicaSet baru
tiap perubahan dan memulai penggandaan. Lalu, dia akan mengganti ReplicaSet yang dibuat sebelumnya
-- mereka ditambahkan ke dalam daftar ReplicaSet lama dan akan mulai dihapus.</p><p>Contohnya, ketika kamu membuat Deployment untuk membangkitkan 5 replika <code>nginx:1.7.9</code>,
kemudian membarui Deployment dengan versi <code>nginx:1.9.1</code> ketika ada 3 replika <code>nginx:1.7.9</code> yang dibuat.
Dalam kasus ini, Deployment akan segera menghapus 3 replika Pod <code>nginx:1.7.9</code> yang telah dibuat, dan mulai membuat
Pod <code>nginx:1.9.1</code>. Dia tidak akan menunggu kelima replika <code>nginx:1.7.9</code> selesai baru menjalankan perubahan.</p><h3 id=mengubah-selektor-label>Mengubah selektor label</h3><p>Umumnya, sekali dibuat, selektor label tidak boleh diubah. Sehingga disarankan untuk direncanakan dengan hati-hati sebelumnya.
Bagaimanapun, jika kamu perlu mengganti selektor label, lakukan dengan seksama dan pastikan kamu tahu segala konsekuensinya.</p><div class="alert alert-info note callout" role=alert><strong>Catatan:</strong> Pada versi API <code>apps/v1</code>, selektor label Deployment tidak bisa diubah ketika selesai dibuat.</div><ul><li>Penambahan selektor mensyaratkan label templat Pod di spek Deployment untuk diganti dengan label baru juga.
Jika tidak, galat validasi akan muncul. Perubahan haruslah tidak tumpang-tindih, dengan kata lain selektor baru tidak mencakup ReplicaSet dan Pod yang dibuat dengan selektor lama. Sehingga, semua ReplicaSet lama akan menggantung sedangkan ReplicaSet baru tetap dibuat.</li><li>Pengubahan selektor mengubah nilai pada kunci selektor -- menghasilkan perilaku yang sama dengan penambahan.</li><li>Penghapusan selektor menghilangkan kunci yang ada pada selektor Deployment -- tidak mensyaratkan perubahan apapun pada label templat Pod.
ReplicaSet yang ada tidak menggantung dan ReplicaSet baru tidak dibuat.
Tapi perhatikan bahwa label yang dihapus masih ada pada Pod dan ReplicaSet masing-masing.</li></ul><h2 id=membalikkan-deployment>Membalikkan Deployment</h2><p>Kadang, kamu mau membalikkan Deployment; misalnya, saat Deployment tidak stabil, seperti crash looping.
Umumnya, semua riwayat rilis Deployment disimpan oleh sistem sehingga kamu dapat kembali kapanpun kamu mau
(kamu dapat mengubahnya dengan mengubah batas riwayat revisi).</p><div class="alert alert-info note callout" role=alert><strong>Catatan:</strong> Revisi Deployment dibuat saat rilis Deployment dipicu. Ini berarti revisi baru dibuat jika dan hanya jika
templat Pod Deployment (<code>.spec.template</code>) berubah, misalnya jika kamu membarui label atau image kontainer pada templat.
Pembaruan lain, seperti penggantian skala Deployment, tidak membuat revisi Deployment, jadi kamu dapat memfasilitasi
penggantian skala secara manual atau otomatis secara simultan. Artinya saat kamu membalikkan ke versi sebelumnya,
hanya bagian templat Pod Deployment yang dibalikkan.</div><ul><li><p>Misal kamu membuat saltik saat mengganti Deployment, dengan memberi nama image dengan <code>nginx:1.91</code> alih-alih <code>nginx:1.9.1</code>:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl <span style=color:#a2f>set</span> image deployment.v1.apps/nginx-deployment <span style=color:#b8860b>nginx</span><span style=color:#666>=</span>nginx:1.91 --record<span style=color:#666>=</span><span style=color:#a2f>true</span>
</span></span></code></pre></div><p>Keluaran akan tampil seperti berikut:</p><pre tabindex=0><code>deployment.apps/nginx-deployment image updated
</code></pre></li><li><p>Rilis akan tersendat. Kamu dapat memeriksanya dengan melihat status rilis:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl rollout status deployment.v1.apps/nginx-deployment
</span></span></code></pre></div><p>Keluaran akan tampil seperti berikut:</p><pre tabindex=0><code>Waiting for rollout to finish: 1 out of 3 new replicas have been updated...
</code></pre></li><li><p>Tekan Ctrl-C untuk menghentikan pemeriksaan status rilis di atas. Untuk info lebih lanjut
tentang rilis tersendat, <a href=#status-deployment>baca disini</a>.</p></li><li><p>Kamu lihat bahwa jumlah replika lama (<code>nginx-deployment-1564180365</code> dan <code>nginx-deployment-2035384211</code>) adalah 2, dan replika baru (nginx-deployment-3066724191) adalah 1.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get rs
</span></span></code></pre></div><p>Keluaran akan tampil seperti berikut:</p><pre tabindex=0><code>NAME                          DESIRED   CURRENT   READY   AGE
nginx-deployment-1564180365   3         3         3       25s
nginx-deployment-2035384211   0         0         0       36s
nginx-deployment-3066724191   1         1         0       6s
</code></pre></li><li><p>Lihat pada Pod yang dibuat. Akan ada 1 Pod dibuat dari ReplicaSet baru tersendat loop(?) ketika penarikan image.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get pods
</span></span></code></pre></div><p>Keluaran akan tampil seperti berikut:</p><pre tabindex=0><code>NAME                                READY     STATUS             RESTARTS   AGE
nginx-deployment-1564180365-70iae   1/1       Running            0          25s
nginx-deployment-1564180365-jbqqo   1/1       Running            0          25s
nginx-deployment-1564180365-hysrc   1/1       Running            0          25s
nginx-deployment-3066724191-08mng   0/1       ImagePullBackOff   0          6s
</code></pre><div class="alert alert-info note callout" role=alert><strong>Catatan:</strong> Controller Deployment menghentikan rilis yang buruk secara otomatis dan juga berhenti meningkatkan ReplicaSet baru.
Ini tergantung pada parameter rollingUpdate (secara khusus <code>maxUnavailable</code>) yang dimasukkan.
Kubernetes umumnya mengatur jumlahnya menjadi 25%.</div></li><li><p>Tampilkan deskripsi Deployment:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl describe deployment
</span></span></code></pre></div><p>Keluaran akan tampil seperti berikut:</p><pre tabindex=0><code>Name:           nginx-deployment
Namespace:      default
CreationTimestamp:  Tue, 15 Mar 2016 14:48:04 -0700
Labels:         app=nginx
Selector:       app=nginx
Replicas:       3 desired | 1 updated | 4 total | 3 available | 1 unavailable
StrategyType:       RollingUpdate
MinReadySeconds:    0
RollingUpdateStrategy:  25% max unavailable, 25% max surge
Pod Template:
  Labels:  app=nginx
  Containers:
   nginx:
    Image:        nginx:1.91
    Port:         80/TCP
    Host Port:    0/TCP
    Environment:  &lt;none&gt;
    Mounts:       &lt;none&gt;
  Volumes:        &lt;none&gt;
Conditions:
  Type           Status  Reason
  ----           ------  ------
  Available      True    MinimumReplicasAvailable
  Progressing    True    ReplicaSetUpdated
OldReplicaSets:     nginx-deployment-1564180365 (3/3 replicas created)
NewReplicaSet:      nginx-deployment-3066724191 (1/1 replicas created)
Events:
  FirstSeen LastSeen    Count   From                    SubobjectPath   Type        Reason              Message
  --------- --------    -----   ----                    -------------   --------    ------              -------
  1m        1m          1       {deployment-controller }                Normal      ScalingReplicaSet   Scaled up replica set nginx-deployment-2035384211 to 3
  22s       22s         1       {deployment-controller }                Normal      ScalingReplicaSet   Scaled up replica set nginx-deployment-1564180365 to 1
  22s       22s         1       {deployment-controller }                Normal      ScalingReplicaSet   Scaled down replica set nginx-deployment-2035384211 to 2
  22s       22s         1       {deployment-controller }                Normal      ScalingReplicaSet   Scaled up replica set nginx-deployment-1564180365 to 2
  21s       21s         1       {deployment-controller }                Normal      ScalingReplicaSet   Scaled down replica set nginx-deployment-2035384211 to 1
  21s       21s         1       {deployment-controller }                Normal      ScalingReplicaSet   Scaled up replica set nginx-deployment-1564180365 to 3
  13s       13s         1       {deployment-controller }                Normal      ScalingReplicaSet   Scaled down replica set nginx-deployment-2035384211 to 0
  13s       13s         1       {deployment-controller }                Normal      ScalingReplicaSet   Scaled up replica set nginx-deployment-3066724191 to 1
</code></pre><p>Untuk memperbaikinya, kamu harus kembali ke revisi Deployment yang sebelumnya stabil.</p></li></ul><h3 id=mengecek-riwayat-rilis-deployment>Mengecek Riwayat Rilis Deployment</h3><p>Ikuti langkah-langkah berikut untuk mengecek riwayat rilis:</p><ol><li><p>Pertama, cek revisi Deployment sekarang:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl rollout <span style=color:#a2f>history</span> deployment.v1.apps/nginx-deployment
</span></span></code></pre></div><p>Keluaran akan tampil seperti berikut:</p><pre tabindex=0><code>deployments &#34;nginx-deployment&#34;
REVISION    CHANGE-CAUSE
1           kubectl apply --filename=https://k8s.io/examples/controllers/nginx-deployment.yaml --record=true
2           kubectl set image deployment.v1.apps/nginx-deployment nginx=nginx:1.9.1 --record=true
3           kubectl set image deployment.v1.apps/nginx-deployment nginx=nginx:1.91 --record=true
</code></pre><p><code>CHANGE-CAUSE</code> disalin dari anotasi Deployment <code>kubernetes.io/change-cause</code> ke revisi saat pembuatan. Kamu dapat menentukan pesan <code>CHANGE-CAUSE</code> dengan:</p><ul><li>Menambahkan anotasi pada Deployment dengan <code>kubectl annotate deployment.v1.apps/nginx-deployment kubernetes.io/change-cause="image updated to 1.9.1"</code></li><li>Menambahkan argumen <code>--record</code> untuk menyimpan perintah <code>kubectl</code> yang menyebabkan perubahan sumber daya.</li><li>Mengganti manifest sumber daya secara manual.</li></ul></li><li><p>Untuk melihat detil tiap revisi, jalankan:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl rollout <span style=color:#a2f>history</span> deployment.v1.apps/nginx-deployment --revision<span style=color:#666>=</span><span style=color:#666>2</span>
</span></span></code></pre></div><p>Keluaran akan tampil seperti berikut:</p><pre tabindex=0><code>deployments &#34;nginx-deployment&#34; revision 2
  Labels:       app=nginx
          pod-template-hash=1159050644
  Annotations:  kubernetes.io/change-cause=kubectl set image deployment.v1.apps/nginx-deployment nginx=nginx:1.9.1 --record=true
  Containers:
   nginx:
    Image:      nginx:1.9.1
    Port:       80/TCP
     QoS Tier:
        cpu:      BestEffort
        memory:   BestEffort
    Environment Variables:      &lt;none&gt;
  No volumes.
</code></pre></li></ol><h3 id=kembali-ke-revisi-sebelumnya>Kembali ke Revisi Sebelumnya</h3><p>Ikuti langkah-langkah berikut untuk membalikkan Deployment dari versi sekarang ke versi sebelumnya, yaitu versi 2.</p><ol><li><p>Sekarang kamu telah menentukan akan mengembalikan rilis sekarang ke sebelumnya:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl rollout undo deployment.v1.apps/nginx-deployment
</span></span></code></pre></div><p>Keluaran akan tampil seperti berikut:</p><pre tabindex=0><code>deployment.apps/nginx-deployment
</code></pre><p>Gantinya, kamu dapat kambali ke revisi tertentu dengan menambahkan argumen <code>--to-revision</code>:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl rollout undo deployment.v1.apps/nginx-deployment --to-revision<span style=color:#666>=</span><span style=color:#666>2</span>
</span></span></code></pre></div><p>Keluaran akan tampil seperti berikut:</p><pre tabindex=0><code>deployment.apps/nginx-deployment
</code></pre><p>Untuk detil lebih lanjut perintah terkait rilis, baca <a href=/docs/reference/generated/kubectl/kubectl-commands#rollout><code>rilis kubectl</code></a>.</p><p>Deployment sekarang dikembalikan ke revisi stabil sebelumnya. Seperti terlihat, ada event <code>DeploymentRollback</code>
yang dibentuk oleh kontroler Deployment untuk pembalikan ke revisi 2.</p></li><li><p>Cek apakah rilis telah sukses dan Deployment berjalan seharusnya, jalankan:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get deployment nginx-deployment
</span></span></code></pre></div><p>Keluaran akan tampil seperti berikut:</p><pre tabindex=0><code>NAME               DESIRED   CURRENT   UP-TO-DATE   AVAILABLE   AGE
nginx-deployment   3         3         3            3           30m
</code></pre></li><li><p>Tampilkan deskripsi Deployment:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl describe deployment nginx-deployment
</span></span></code></pre></div><p>Keluaran akan tampil seperti berikut:</p><pre tabindex=0><code>Name:                   nginx-deployment
Namespace:              default
CreationTimestamp:      Sun, 02 Sep 2018 18:17:55 -0500
Labels:                 app=nginx
Annotations:            deployment.kubernetes.io/revision=4
                        kubernetes.io/change-cause=kubectl set image deployment.v1.apps/nginx-deployment nginx=nginx:1.9.1 --record=true
Selector:               app=nginx
Replicas:               3 desired | 3 updated | 3 total | 3 available | 0 unavailable
StrategyType:           RollingUpdate
MinReadySeconds:        0
RollingUpdateStrategy:  25% max unavailable, 25% max surge
Pod Template:
  Labels:  app=nginx
  Containers:
   nginx:
    Image:        nginx:1.9.1
    Port:         80/TCP
    Host Port:    0/TCP
    Environment:  &lt;none&gt;
    Mounts:       &lt;none&gt;
  Volumes:        &lt;none&gt;
Conditions:
  Type           Status  Reason
  ----           ------  ------
  Available      True    MinimumReplicasAvailable
  Progressing    True    NewReplicaSetAvailable
OldReplicaSets:  &lt;none&gt;
NewReplicaSet:   nginx-deployment-c4747d96c (3/3 replicas created)
Events:
  Type    Reason              Age   From                   Message
  ----    ------              ----  ----                   -------
  Normal  ScalingReplicaSet   12m   deployment-controller  Scaled up replica set nginx-deployment-75675f5897 to 3
  Normal  ScalingReplicaSet   11m   deployment-controller  Scaled up replica set nginx-deployment-c4747d96c to 1
  Normal  ScalingReplicaSet   11m   deployment-controller  Scaled down replica set nginx-deployment-75675f5897 to 2
  Normal  ScalingReplicaSet   11m   deployment-controller  Scaled up replica set nginx-deployment-c4747d96c to 2
  Normal  ScalingReplicaSet   11m   deployment-controller  Scaled down replica set nginx-deployment-75675f5897 to 1
  Normal  ScalingReplicaSet   11m   deployment-controller  Scaled up replica set nginx-deployment-c4747d96c to 3
  Normal  ScalingReplicaSet   11m   deployment-controller  Scaled down replica set nginx-deployment-75675f5897 to 0
  Normal  ScalingReplicaSet   11m   deployment-controller  Scaled up replica set nginx-deployment-595696685f to 1
  Normal  DeploymentRollback  15s   deployment-controller  Rolled back deployment &#34;nginx-deployment&#34; to revision 2
  Normal  ScalingReplicaSet   15s   deployment-controller  Scaled down replica set nginx-deployment-595696685f to 0
</code></pre></li></ol><h2 id=mengatur-skala-deployment>Mengatur Skala Deployment</h2><p>Kamu dapat mengatur skala Deployment dengan perintah berikut:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl scale deployment.v1.apps/nginx-deployment --replicas<span style=color:#666>=</span><span style=color:#666>10</span>
</span></span></code></pre></div><p>Keluaran akan tampil seperti berikut:</p><pre tabindex=0><code>deployment.apps/nginx-deployment scaled
</code></pre><p>Dengan asumsi <a href=/docs/tasks/run-application/horizontal-pod-autoscale-walkthrough/>horizontal Pod autoscaling</a> dalam klaster dinyalakan,
kamu dapat mengatur autoscaler untuk Deployment-mu dan memilih jumlah minimal dan maksimal Pod yang mau dijalankan berdasarkan penggunaan CPU
dari Pod.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl autoscale deployment.v1.apps/nginx-deployment --min<span style=color:#666>=</span><span style=color:#666>10</span> --max<span style=color:#666>=</span><span style=color:#666>15</span> --cpu-percent<span style=color:#666>=</span><span style=color:#666>80</span>
</span></span></code></pre></div><p>Keluaran akan tampil seperti berikut:</p><pre tabindex=0><code>deployment.apps/nginx-deployment scaled
</code></pre><h3 id=pengaturan-skala-proporsional>Pengaturan skala proporsional</h3><p>Deployment RollingUpdate mendukung beberapa versi aplikasi berjalan secara bersamaan. Ketika kamu atau autoscaler
mengubah skala Deployment RollingUpdate yang ada di tengah rilis (yang sedang berjalan maupun terjeda),
kontroler Deployment menyeimbangkan replika tambahan dalam ReplicaSet aktif (ReplicaSet dengan Pod) untuk mencegah resiko.
Ini disebut <em>pengaturan skala proporsional</em>.</p><p>Sebagai contoh, kamu menjalankan Deployment dengan 10 replika, <a href=#max-surge>maxSurge</a>=3, dan <a href=#max-unavailable>maxUnavailable</a>=2.</p><ul><li><p>Pastikan ada 10 replica di Deployment-mu yang berjalan.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get deploy
</span></span></code></pre></div><p>Keluaran akan tampil seperti berikut:</p><pre tabindex=0><code>NAME                 DESIRED   CURRENT   UP-TO-DATE   AVAILABLE   AGE
nginx-deployment     10        10        10           10          50s
</code></pre></li><li><p>Ganti ke image baru yang kebetulan tidak bisa ditemukan dari dalam klaster.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl <span style=color:#a2f>set</span> image deployment.v1.apps/nginx-deployment <span style=color:#b8860b>nginx</span><span style=color:#666>=</span>nginx:sometag
</span></span></code></pre></div><p>Keluaran akan tampil seperti berikut:</p><pre tabindex=0><code>deployment.apps/nginx-deployment image updated
</code></pre></li><li><p>Penggantian image akan memulai rilis baru dengan ReplicaSet nginx-deployment-1989198191, namun dicegah karena
persyaratan <code>maxUnavailable</code> yang disebut di atas. Cek status rilis:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get rs
</span></span></code></pre></div><pre><code>Keluaran akan tampil seperti berikut:
</code></pre><pre tabindex=0><code>NAME                          DESIRED   CURRENT   READY     AGE
nginx-deployment-1989198191   5         5         0         9s
nginx-deployment-618515232    8         8         8         1m
</code></pre></li><li><p>Kemudian, permintaan peningkatan untuk Deployment akan masuk. Autoscaler menambah replika Deployment
menjadi 15. Controller Deployment perlu menentukan dimana 5 replika ini ditambahkan. Jika kamu memakai
pengaturan skala proporsional, kelima replika akan ditambahkan ke ReplicaSet baru. Dengan pengaturan skala proporsional,
kamu menyebarkan replika tambahan ke semua ReplicaSet. Proporsi terbesar ada pada ReplicaSet dengan
replika terbanyak dan proporsi yang lebih kecil untuk replika dengan ReplicaSet yang lebih sedikit.
Sisanya akan diberikan ReplicaSet dengan replika terbanyak. ReplicaSet tanpa replika tidak akan ditingkatkan.</p></li></ul><p>Dalam kasus kita di atas, 3 replika ditambahkan ke ReplicaSet lama dan 2 replika ditambahkan ke ReplicaSet baru.
Proses rilis akan segera memindahkan semua ReplicaSet baru, dengan asumsi semua replika dalam kondisi sehat.
Untuk memastikannya, jalankan:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get deploy
</span></span></code></pre></div><p>Keluaran akan tampil seperti berikut:</p><pre tabindex=0><code>NAME                 DESIRED   CURRENT   UP-TO-DATE   AVAILABLE   AGE
nginx-deployment     15        18        7            8           7m
</code></pre><p>Status rilis mengkonfirmasi bagaimana replika ditambahkan ke tiap ReplicaSet.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get rs
</span></span></code></pre></div><p>Keluaran akan tampil seperti berikut:</p><pre tabindex=0><code>NAME                          DESIRED   CURRENT   READY     AGE
nginx-deployment-1989198191   7         7         0         7m
nginx-deployment-618515232    11        11        11        7m
</code></pre><h2 id=menjeda-dan-melanjutkan-deployment>Menjeda dan Melanjutkan Deployment</h2><p>Kamu dapat menjeda Deployment sebelum memicu satu atau lebih pembaruan kemudian meneruskannya.
Hal ini memungkinkanmu menerapkan beberapa perbaikan selama selang jeda tanpa melakukan rilis yang tidak perlu.</p><ul><li><p>Sebagai contoh, Deployment yang baru dibuat:
Lihat detil Deployment:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get deploy
</span></span></code></pre></div><p>Keluaran akan tampil seperti berikut:</p><pre tabindex=0><code>NAME      DESIRED   CURRENT   UP-TO-DATE   AVAILABLE   AGE
nginx     3         3         3            3           1m
</code></pre><p>Lihat status rilis:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get rs
</span></span></code></pre></div><p>Keluaran akan tampil seperti berikut:</p><pre tabindex=0><code>NAME               DESIRED   CURRENT   READY     AGE
nginx-2142116321   3         3         3         1m
</code></pre></li><li><p>Jeda dengan menjalankan perintah berikut:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl rollout pause deployment.v1.apps/nginx-deployment
</span></span></code></pre></div><p>Keluaran akan tampil seperti berikut:</p><pre tabindex=0><code>deployment.apps/nginx-deployment paused
</code></pre></li><li><p>Lalu ganti kolom image Deployment:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl <span style=color:#a2f>set</span> image deployment.v1.apps/nginx-deployment <span style=color:#b8860b>nginx</span><span style=color:#666>=</span>nginx:1.9.1
</span></span></code></pre></div><p>Keluaran akan tampil seperti berikut:</p><pre tabindex=0><code>deployment.apps/nginx-deployment image updated
</code></pre></li><li><p>Perhatikan tidak ada rilis baru yang muncul:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl rollout <span style=color:#a2f>history</span> deployment.v1.apps/nginx-deployment
</span></span></code></pre></div><p>Keluaran akan tampil seperti berikut:</p><pre tabindex=0><code>deployments &#34;nginx&#34;
REVISION  CHANGE-CAUSE
1   &lt;none&gt;
</code></pre></li><li><p>Lihat status rilis untuk memastikan Deployment berhasil diperbarui:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get rs
</span></span></code></pre></div><p>Keluaran akan tampil seperti berikut:</p><pre tabindex=0><code>NAME               DESIRED   CURRENT   READY     AGE
nginx-2142116321   3         3         3         2m
</code></pre></li><li><p>Kamu bisa membuat pembaruan sebanyak yang kamu mau. Contohnya pembaruan sumber daya yang akan dipakai:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl <span style=color:#a2f>set</span> resources deployment.v1.apps/nginx-deployment -c<span style=color:#666>=</span>nginx --limits<span style=color:#666>=</span><span style=color:#b8860b>cpu</span><span style=color:#666>=</span>200m,memory<span style=color:#666>=</span>512Mi
</span></span></code></pre></div><p>Keluaran akan tampil seperti berikut:</p><pre tabindex=0><code>deployment.apps/nginx-deployment resource requirements updated
</code></pre><p>The state awal Deployment sebelum jeda akan melanjutkan fungsinya, tapi perubahan
Deployment tidak akan berefek apapun selama Deployment masih terjeda.</p></li><li><p>Kemudian, mulai kembali Deployment dan perhatikan ReplicaSet baru akan muncul dengan semua perubahan baru:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl rollout resume deployment.v1.apps/nginx-deployment
</span></span></code></pre></div><p>Keluaran akan tampil seperti berikut:</p><pre tabindex=0><code>deployment.apps/nginx-deployment resumed
</code></pre></li><li><p>Perhatikan status rilis sampai selesai.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get rs -w
</span></span></code></pre></div><p>Keluaran akan tampil seperti berikut:</p><pre tabindex=0><code>NAME               DESIRED   CURRENT   READY     AGE
nginx-2142116321   2         2         2         2m
nginx-3926361531   2         2         0         6s
nginx-3926361531   2         2         1         18s
nginx-2142116321   1         2         2         2m
nginx-2142116321   1         2         2         2m
nginx-3926361531   3         2         1         18s
nginx-3926361531   3         2         1         18s
nginx-2142116321   1         1         1         2m
nginx-3926361531   3         3         1         18s
nginx-3926361531   3         3         2         19s
nginx-2142116321   0         1         1         2m
nginx-2142116321   0         1         1         2m
nginx-2142116321   0         0         0         2m
nginx-3926361531   3         3         3         20s
</code></pre></li><li><p>Lihat status rilis terakhir:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get rs
</span></span></code></pre></div><p>Keluaran akan tampil seperti berikut:</p><pre tabindex=0><code>NAME               DESIRED   CURRENT   READY     AGE
nginx-2142116321   0         0         0         2m
nginx-3926361531   3         3         3         28s
</code></pre></li></ul><div class="alert alert-info note callout" role=alert><strong>Catatan:</strong> Kamu tidak bisa membalikkan Deployment yang terjeda sampai dia diteruskan.</div><h2 id=status-deployment>Status Deployment</h2><p>Deployment melalui berbagai state dalam daur hidupnya. Dia dapat <a href=#deployment-berlangsung>berlangsung</a> selagi merilis ReplicaSet baru, bisa juga <a href=#deployment-selesai>selesai</a>,
atau juga <a href=#deployment-gagal>gagal</a>.</p><h3 id=deployment-berlangsung>Deployment Berlangsung</h3><p>Kubernetes menandai Deployment sebagai <em>progressing</em> saat salah satu tugas di bawah dikerjakan:</p><ul><li>Deployment membuat ReplicaSet baru.</li><li>Deployment menaikkan kapasitas ReplicaSet terbaru.</li><li>Deployment menurunkan kapasitas ReplicaSet yang lebih lama.</li><li>Pod baru menjadi siap atau dapat diakses (siap selama setidaknya <a href=#min-ready-seconds>MinReadySeconds</a>).</li></ul><p>Kamu dapat mengawasi perkembangan Deployment dengan <code>kubectl rollout status</code>.</p><h3 id=deployment-selesai>Deployment Selesai</h3><p>Kubernetes menandai Deployment sebagai <em>complete</em> saat memiliki karakteristik berikut:</p><ul><li>Semua replika terkait Deployment telah diperbarui ke versi terbaru yang dispecify, artinya semua pembaruan yang kamu inginkan telah selesai.</li><li>Semua replika terkait Deployment dapat diakses.</li><li>Tidak ada replika lama untuk Deployment yang berjalan.</li></ul><p>Kamu dapat mengecek apakah Deployment telah selesai dengan <code>kubectl rollout status</code>.
Jika rilis selesai, <code>kubectl rollout status</code> akan mengembalikan nilai balik nol.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl rollout status deployment.v1.apps/nginx-deployment
</span></span></code></pre></div><p>Keluaran akan tampil seperti berikut:</p><pre tabindex=0><code>Waiting for rollout to finish: 2 of 3 updated replicas are available...
deployment &#34;nginx-deployment&#34; successfully rolled out
$ echo $?
0
</code></pre><h3 id=deployment-gagal>Deployment Gagal</h3><p>Deployment-mu bisa saja terhenti saat mencoba deploy ReplicaSet terbaru tanpa pernah selesai.
Ini dapat terjadi karena faktor berikut:</p><ul><li>Kuota tidak mencukupi</li><li>Kegagalan pengecekan kesiapan</li><li>Galat saat mengunduh image</li><li>Tidak memiliki ijin</li><li>Limit ranges</li><li>Konfigurasi runtime aplikasi yang salah</li></ul><p>Salah satu cara untuk mendeteksi kondisi ini adalah untuk menjelaskan parameter tenggat pada spesifikasi Deployment:
(<a href=#progress-deadline-seconds><code>.spec.progressDeadlineSeconds</code></a>). <code>.spec.progressDeadlineSeconds</code> menyatakan
lama kontroler Deployment menunggu sebelum mengindikasikan (pada status Deployment) bahwa kemajuan Deployment
tersendat dalam detik.</p><p>Perintah <code>kubectl</code> berikut menetapkan spek dengan <code>progressDeadlineSeconds</code> untuk membuat kontroler
melaporkan kemajuan Deployment yang sedikit setelah 10 menit:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl patch deployment.v1.apps/nginx-deployment -p <span style=color:#b44>&#39;{&#34;spec&#34;:{&#34;progressDeadlineSeconds&#34;:600}}&#39;</span>
</span></span></code></pre></div><p>Keluaran akan tampil seperti berikut:</p><pre tabindex=0><code>deployment.apps/nginx-deployment patched
</code></pre><p>Ketika tenggat sudah lewat, kontroler Deployment menambah DeploymentCondition dengan atribut
berikut ke <code>.status.conditions</code> milik Deployment:</p><ul><li>Type=Progressing</li><li>Status=False</li><li>Reason=ProgressDeadlineExceeded</li></ul><p>Lihat <a href=https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#typical-status-properties>konvensi Kubernetes API</a> untuk info lebih lanjut tentang kondisi status.</p><div class="alert alert-info note callout" role=alert><strong>Catatan:</strong> Kubernetes tidak melakukan apapun pada Deployment yang tersendat selain melaporkannya sebagai <code>Reason=ProgressDeadlineExceeded</code>.
Orkestrator yang lebih tinggi dapat memanfaatkannya untuk melakukan tindak lanjut. Misalnya, mengembalikan Deployment ke versi sebelumnya.</div><div class="alert alert-info note callout" role=alert><strong>Catatan:</strong> Jika Deployment terjeda, Kubernetes tidak akan mengecek kemajuan pada selang itu.
Kamu dapat menjeda Deployment di tengah rilis dan melanjutkannya dengan aman tanpa memicu kondisi saat tenggat telah lewat.</div><p>Kamu dapat mengalami galat sejenak pada Deployment disebabkan timeout yang dipasang terlalu kecil atau
hal-hal lain yang terjadi sementara. Misalnya, kamu punya kuota yang tidak mencukupi. Jika kamu mendeskripsikan Deployment
kamu akan menjumpai pada bagian ini:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl describe deployment nginx-deployment
</span></span></code></pre></div><p>Keluaran akan tampil seperti berikut:</p><pre tabindex=0><code>&lt;...&gt;
Conditions:
  Type            Status  Reason
  ----            ------  ------
  Available       True    MinimumReplicasAvailable
  Progressing     True    ReplicaSetUpdated
  ReplicaFailure  True    FailedCreate
&lt;...&gt;
</code></pre><p>Jika kamu menjalankan <code>kubectl get deployment nginx-deployment -o yaml</code>, Deployment status akan muncul seperti berikut:</p><pre tabindex=0><code>status:
  availableReplicas: 2
  conditions:
  - lastTransitionTime: 2016-10-04T12:25:39Z
    lastUpdateTime: 2016-10-04T12:25:39Z
    message: Replica set &#34;nginx-deployment-4262182780&#34; is progressing.
    reason: ReplicaSetUpdated
    status: &#34;True&#34;
    type: Progressing
  - lastTransitionTime: 2016-10-04T12:25:42Z
    lastUpdateTime: 2016-10-04T12:25:42Z
    message: Deployment has minimum availability.
    reason: MinimumReplicasAvailable
    status: &#34;True&#34;
    type: Available
  - lastTransitionTime: 2016-10-04T12:25:39Z
    lastUpdateTime: 2016-10-04T12:25:39Z
    message: &#39;Error creating: pods &#34;nginx-deployment-4262182780-&#34; is forbidden: exceeded quota:
      object-counts, requested: pods=1, used: pods=3, limited: pods=2&#39;
    reason: FailedCreate
    status: &#34;True&#34;
    type: ReplicaFailure
  observedGeneration: 3
  replicas: 2
  unavailableReplicas: 2
</code></pre><p>Begitu tenggat kemajuan Deployment terlewat, Kubernetes membarui status dan alasan untuk kondisi Progressing:</p><pre tabindex=0><code>Conditions:
  Type            Status  Reason
  ----            ------  ------
  Available       True    MinimumReplicasAvailable
  Progressing     False   ProgressDeadlineExceeded
  ReplicaFailure  True    FailedCreate
</code></pre><p>Kamu dapat menangani isu keterbatasan kuota dengan menurunkan jumlah Deployment, bisa dengan menghapus kontrolers
yang sedang berjalan, atau dengan meningkatkan kuota pada namespace. Jika kuota tersedia, kemudian kontroler Deployment
akan dapat menyelesaikan rilis Deployment. Kamu akan melihat bahwa status Deployment berubah menjadi kondisi sukses (<code>Status=True</code> dan <code>Reason=NewReplicaSetAvailable</code>).</p><pre tabindex=0><code>Conditions:
  Type          Status  Reason
  ----          ------  ------
  Available     True    MinimumReplicasAvailable
  Progressing   True    NewReplicaSetAvailable
</code></pre><p><code>Type=Available</code> dengan <code>Status=True</code> artinya Deployment-mu punya ketersediaan minimum. Ketersediaan minimum diatur
oleh parameter yang dibuat pada strategi deployment. <code>Type=Progressing</code> dengan <code>Status=True</code> berarti Deployment
sedang dalam rilis dan masih berjalan atau sudah selesai berjalan dan jumlah minimum replika tersedia
(lihat bagian Alasan untuk kondisi tertentu - dalam kasus ini <code>Reason=NewReplicaSetAvailable</code> berarti Deployment telah selesai).</p><p>Kamu dapat mengecek apakah Deployment gagal berkembang dengan perintah <code>kubectl rollout status</code>. <code>kubectl rollout status</code>
mengembalikan nilai selain nol jika Deployment telah melewati tenggat kemajuan.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl rollout status deployment.v1.apps/nginx-deployment
</span></span></code></pre></div><p>Keluaran akan tampil seperti berikut:</p><pre tabindex=0><code>Waiting for rollout to finish: 2 out of 3 new replicas have been updated...
error: deployment &#34;nginx&#34; exceeded its progress deadline
$ echo $?
1
</code></pre><h3 id=menindak-deployment-yang-gagal>Menindak Deployment yang gagal</h3><p>Semua aksi yang dapat diterapkan pada Deployment yang selesai berjalan juga pada Deployment gagal. Kamu dapat menaik/turunkan replika, membalikkan ke versi sebelumnya, atau menjedanya jika kamu perlu menerapkan beberapa perbaikan pada templat Pod Deployment.</p><h2 id=kebijakan-pembersihan>Kebijakan Pembersihan</h2><p>Kamu dapat mengisi kolom <code>.spec.revisionHistoryLimit</code> di Deployment untuk menentukan banyak ReplicaSet
pada Deployment yang ingin dipertahankan. Sisanya akan di garbage-collected di balik layar. Umumnya, nilai kolom berisi 10.</p><div class="alert alert-info note callout" role=alert><strong>Catatan:</strong> Mengisi secara eksplisit dengan nilai 0 akan membuat pembersihan semua riwayat rilis Deployment
sehingga Deployment tidak akan dapat dikembalikan.</div><h2 id=deployment-canary>Deployment Canary</h2><p>Jika kamu ingin merilis ke sebagian pengguna atau server menggunakan Deployment,
kamu dapat membuat beberapa Deployment, satu tiap rilis, dengan mengikuti pola canary yang didesripsikan pada
<a href=/id/docs/concepts/cluster-administration/manage-deployment/#deploy-dengan-canary>mengelola sumber daya</a>.</p><h2 id=menulis-spesifikasi-deployment>Menulis Spesifikasi Deployment</h2><p>Sebagaimana konfigurasi Kubernetes lainnya, Deployment memerlukan kolom <code>apiVersion</code>, <code>kind</code>, dan <code>metadata</code>.
Untuk informasi umum tentang penggunaan berkas konfigurasi, lihat dokumen <a href=/id/docs/tutorials/stateless-application/run-stateless-application-deployment/>deploy aplikasi</a>,
mengatur kontainer, dan <a href=/id/docs/concepts/overview/working-with-objects/object-management/>memakai kubectl untuk mengatur sumber daya</a>.</p><p>Deployment juga perlu <a href=https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#spec-and-status>bagian <code>.spec</code></a>.</p><h3 id=templat-pod>Templat Pod</h3><p>Dalam <code>.spec</code> hanya ada kolom <code>.spec.template</code> dan <code>.spec.selector</code> yang wajib diisi.</p><p><code>.spec.template</code> adalah <a href=/id/docs/concepts/workloads/pods/pod-overview/#templat-pod>templat Pod</a>. Dia memiliki skema yang sama dengan <a href=/id/docs/concepts/workloads/pods/pod/>Pod</a>. Bedanya dia bersarang dan tidak punya <code>apiVersion</code> atau <code>kind</code>.</p><p>Selain kolom wajib untuk Pod, templat Pod pada Deployment harus menentukan label dan aturan menjalankan ulang yang tepat.
Untuk label, pastikaan tidak bertumpang tindih dengan kontroler lainnya. Lihat <a href=#selektor>selektor</a>).</p><p><a href=/id/docs/concepts/workloads/pods/pod-lifecycle/#aturan-menjalankan-ulang><code>.spec.template.spec.restartPolicy</code></a> hanya boleh berisi <code>Always</code>,
yang tidak ditentukan pada bawaan.</p><h3 id=replika>Replika</h3><p><code>.spec.replicas</code> adalah kolom opsional yang mengatur jumlah Pod yang diinginkan. Setelan bawaannya berisi 1.</p><h3 id=selektor>Selektor</h3><p><code>.spec.selector</code> adalah kolom wajib yang mengatur <a href=/id/docs/concepts/overview/working-with-objects/labels/>selektor label</a>
untuk Pod yang dituju oleh Deployment ini.</p><p><code>.spec.selector</code> harus sesuai <code>.spec.template.metadata.labels</code>, atau akan ditolak oleh API.</p><p>Di versi API <code>apps/v1</code>, <code>.spec.selector</code> dan <code>.metadata.labels</code> tidak berisi <code>.spec.template.metadata.labels</code> jika tidak disetel.
Jadi mereka harus disetel secara eksplisit. Perhatikan juga <code>.spec.selector</code> tidak dapat diubah setelah Deployment dibuat pada <code>apps/v1</code>.</p><p>Deployment dapat mematikan Pod yang labelnya cocok dengan selektor jika templatnya berbeda
dari <code>.spec.template</code> atau total jumlah Pod melebihi <code>.spec.replicas</code>. Dia akan membuat Pod baru
dengan <code>.spec.template</code> jika jumlah Pod kurang dari yang diinginkan.</p><div class="alert alert-info note callout" role=alert><strong>Catatan:</strong> Kamu sebaiknya tidak membuat Pod lain yang labelnya cocok dengan selektor ini, baik secara langsung,
melalui Deployment lain, atau membuat kontroler lain seperti ReplicaSet atau ReplicationController.
Kalau kamu melakukannya, Deployment pertama akan mengira dia yang membuat Pod-pod ini.
Kubernetes tidak akan mencegahmu melakukannya.</div><p>Jika kamu punya beberapa kontroler dengan selektor bertindihan, mereka akan saling bertikai
dan tidak akan berjalan semestinya.</p><h3 id=strategi>Strategi</h3><p><code>.spec.strategy</code> mengatur strategi yang dipakai untuk mengganti Pod lama dengan yang baru.
<code>.spec.strategy.type</code> dapat berisi "Recreate" atau "RollingUpdate". Nilai bawaannya adalah "RollingUpdate".</p><h4 id=membuat-ulang-deployment>Membuat Ulang Deployment</h4><p>Semua Pod yang ada dimatikan sebelum yang baru dibuat ketika nilai <code>.spec.strategy.type==Recreate</code>.</p><h4 id=membarui-deployment-secara-bergulir>Membarui Deployment secara Bergulir</h4><p>Deployment membarui Pod secara bergulir
saat <code>.spec.strategy.type==RollingUpdate</code>. Kamu dapat menentukan <code>maxUnavailable</code> dan <code>maxSurge</code> untuk mengatur
proses pembaruan bergulir.</p><h5 id=ketidaktersediaan-maksimum>Ketidaktersediaan Maksimum</h5><p><code>.spec.strategy.rollingUpdate.maxUnavailable</code> adalah kolom opsional yang mengatur jumlah Pod maksimal
yang tidak tersedia selama proses pembaruan. Nilainya bisa berupa angka mutlak (contohnya 5)
atau persentase dari Pod yang diinginkan (contohnya 10%). Angka mutlak dihitung berdasarkan persentase
dengan pembulatan ke bawah. Nilai tidak bisa nol jika <code>.spec.strategy.rollingUpdate.maxSurge</code> juga nol.
Nilai bawaannya yaitu 25%.</p><p>Sebagai contoh, ketika nilai berisi 30%, ReplicaSet lama dapat segera diperkecil menjadi 70% dari Pod
yang diinginkan saat pembaruan bergulir dimulai. Seketika Pod baru siap, ReplicaSet lama dapat lebih diperkecil lagi,
diikuti dengan pembesaran ReplicaSet, menjamin total jumlah Pod yang siap kapanpun ketika pembaruan
paling sedikit 70% dari Pod yang diinginkan.</p><h5 id=kelebihan-maksimum>Kelebihan Maksimum</h5><p><code>.spec.strategy.rollingUpdate.maxSurge</code> adalah kolom opsional yang mengatur jumlah Pod maksimal yang
dapat dibuat melebihi jumlah Pod yang diinginkan. Nilainya bisa berupa angka mutlak (contohnya 5) atau persentase
dari Pod yang diinginkan (contohnya 10%). Nilai tidak bisa nol jika <code>MaxUnavailable</code> juga nol. Angka mutlak
dihitung berdasarkan persentase dengan pembulatan ke bawah. Nilai bawaannya yaitu 25%.</p><p>Sebagai contoh, ketika nilai berisi 30%, ReplicaSet baru dapat segera diperbesar saat pembaruan bergulir dimulai,
sehingga total jumlah Pod yang baru dan lama tidak melebihi 130% dari Pod yang diinginkan.
Saat Pod lama dimatikan, ReplicaSet baru dapat lebih diperbesar lagi, menjamin total jumlah Pod yang siap
kapanpun ketika pembaruan paling banyak 130% dari Pod yang diinginkan.</p><h3 id=tenggat-kemajuan-dalam-detik>Tenggat Kemajuan dalam Detik</h3><p><code>.spec.progressDeadlineSeconds</code> adalah kolom opsional yang mengatur lama tunggu dalam dalam detik untuk Deployment-mu berjalan
sebelum sistem melaporkan lagi bahwa Deployment <a href=#deployment-gagal>gagal</a> - ditunjukkan dengan kondisi <code>Type=Progressing</code>, <code>Status=False</code>,
dan <code>Reason=ProgressDeadlineExceeded</code> pada status sumber daya. Controller Deployment akan tetap mencoba ulang Deployment.
Nantinya begitu pengembalian otomatis diimplementasikan, kontroler Deployment akan membalikkan Deployment segera
saat dia menjumpai kondisi tersebut.</p><p>Jika ditentukan, kolom ini harus lebih besar dari <code>.spec.minReadySeconds</code>.</p><h3 id=lama-minimum-untuk-siap-dalam-detik>Lama Minimum untuk Siap dalam Detik</h3><p><code>.spec.minReadySeconds</code> adalah kolom opsional yang mengatur lama minimal sebuah Pod yang baru dibuat
seharusnya siap tanpa ada kontainer yang rusak, untuk dianggap tersedia, dalam detik.
Nilai bawaannya yaitu 0 (Pod akan dianggap tersedia segera ketika siap). Untuk mempelajari lebih lanjut
kapan Pod dianggap siap, lihat <a href=/id/docs/concepts/workloads/pods/pod-lifecycle/#pemeriksaan-kontainer>Pemeriksaan Kontainer</a>.</p><h3 id=kembali-ke>Kembali Ke</h3><p>Kolom <code>.spec.rollbackTo</code> telah ditinggalkan pada versi API <code>extensions/v1beta1</code> dan <code>apps/v1beta1</code>, dan sudah tidak didukung mulai versi API <code>apps/v1beta2</code>.
Sebagai gantinya, disarankan untuk menggunakan <code>kubectl rollout undo</code> sebagaimana diperkenalkan dalam <a href=#kembali-ke-revisi-sebelumnya>Kembali ke Revisi Sebelumnya</a>.</p><h3 id=batas-riwayat-revisi>Batas Riwayat Revisi</h3><p>Riwayat revisi Deployment disimpan dalam ReplicaSet yang dia kendalikan.</p><p><code>.spec.revisionHistoryLimit</code> adalah kolom opsional yang mengatur jumlah ReplicaSet lama yang dipertahankan
untuk memungkinkan pengembalian. ReplicaSet lama ini mengambil sumber daya dari <code>etcd</code> dan memunculkan keluaran
dari <code>kubectl get rs</code>. Konfigurasi tiap revisi Deployment disimpan pada ReplicaSet-nya; sehingga, begitu ReplicaSet lama dihapus,
kamu tidak mampu lagi membalikkan revisi Deployment-nya. Umumnya, 10 ReplicaSet lama akan dipertahankan,
namun nilai idealnya tergantung pada frekuensi dan stabilitas Deployment-deployment baru.</p><p>Lebih spesifik, mengisi kolom dengan nol berarti semua ReplicaSet lama dengan 0 replika akan dibersihkan.
Dalam kasus ini, rilis Deployment baru tidak dapat dibalikkan, sebab riwayat revisinya telah dibersihkan.</p><h3 id=terjeda>Terjeda</h3><p><code>.spec.paused</code> adalah kolom boolean opsional untuk menjeda dan melanjutkan Deployment. Perbedaan antara Deployment yang terjeda
dan yang tidak hanyalah perubahan apapun pada PodTemplateSpec Deployment terjeda tidak akan memicu rilis baru selama masih terjeda.
Deployment umumnya tidak terjeda saat dibuat.</p><h2 id=alternatif-untuk-deployment>Alternatif untuk Deployment</h2><h3 id=kubectl-rolling-update>kubectl rolling update</h3><p><a href=/id/docs/reference/generated/kubectl/kubectl-commands#rolling-update><code>kubectl rolling update</code></a> membarui Pod dan ReplicationController
dengan cara yang serupa. Namun, Deployments lebih disarankan karena deklaratif, berjalan di sisi server, dan punya fitur tambahan,
seperti pembalikkan ke revisi manapun sebelumnya bahkan setelah pembaruan rolling selesais.</p></div><div class=td-content style=page-break-before:always><h1 id=pg-6d72299952c37ca8cc61b416e5bdbcd4>4.2.4 - StatefulSet</h1><p>StatefulSet merupakan salah satu objek API <em>workload</em> yang digunakan untuk aplikasi <em>stateful</em>.</p><div class="alert alert-info note callout" role=alert><strong>Catatan:</strong> StatefulSet merupakan fitur stabil (GA) sejak versi 1.9.</div><p>Melakukan proses manajemen deployment dan <em>scaling</em> dari sebuah set <a class=glossary-tooltip title='Unit Kubernetes yang paling sederhana dan kecil. Sebuah Pod merepresentasikan sebuah set kontainer yang dijalankan pada kluster kamu.' data-toggle=tooltip data-placement=top href=/docs/concepts/workloads/pods/pod-overview/ target=_blank aria-label=Pods>Pods</a>, <em>serta menjamin mekanisme <em>ordering</em> dan keunikan</em> dari Pod ini.</p><p>Seperti halnya <a class=glossary-tooltip title='Mengelola aplikasi yang direplikasi di dalam klastermu.' data-toggle=tooltip data-placement=top href=/id/docs/concepts/workloads/controllers/deployment/ target=_blank aria-label=Deployment>Deployment</a>, sebuah StatefulSet akan melakukan proses manajemen Pod yang didasarkan pada spec container identik. Meskipun begitu tidak seperti sebuah Deployment, sebuah StatefulSet akan menjamin identitas setiap Pod yang ada. Pod ini akan dibuat berdasarkan spec yang sama, tetapi tidak dapat digantikan satu sama lainnya: setiap Pod memiliki identifier persisten yang akan di-maintain meskipun pod tersebut di (re)schedule.</p><p>Sebuah StatefulSet beroperasi dengan pola yang sama dengan Kontroler lainnya. Kamu dapat mendefinisikan state yang diinginkan pada objek StatefulSet, dan kontroler StatefulSet akan membuat update yang dibutuhkan dari <em>state</em> saat ini.</p><h2 id=menggunakan-statefulset>Menggunakan StatefulSet</h2><p>StatefulSet akan sangat bermanfaat apabila digunakan untuk aplikasi
yang membutuhkan salah satu atau beberapa fungsi berikut.</p><ul><li>Memiliki identitas jaringan unik yang stabil.</li><li>Penyimpanan persisten yang stabil.</li><li>Mekanisme <em>scaling</em> dan <em>deployment</em> yang <em>graceful</em> tertara berdasarkan urutan.</li><li>Mekanisme <em>rolling update</em> yang otomatis berdasarkan urutan.</li></ul><p>Stabil dalam poin-poin di atas memiliki arti yang sama dengan persisten pada
Pod saat dilakukan <em>(re)scheduling</em>. Jika suatu aplikasi tidak membutuhkan
identitas yang stabil atau <em>deployment</em> yang memiliki urutan, penghapusan, atau
mekanisme <em>scaling</em>, kamu harus melakukan <em>deploy</em> aplikasi dengan <em>controller</em> yang menyediakan
replika <em>stateless</em>. <em>Controller</em> seperti <a href=/id/docs/concepts/workloads/controllers/deployment/>Deployment</a> atau
<a href=/id/docs/concepts/workloads/controllers/replicaset/>ReplicaSet</a> akan lebih sesuai dengan kebutuhan kamu.</p><h2 id=keterbatasan>Keterbatasan</h2><ul><li>StatefulSet merupakan sumber daya beta sebelum 1.9 dan tidak tersedia
pada Kubernetes rilis sebelum versi 1.5.</li><li>Penyimpanan untuk sebuah Pod harus terlebih dahulu di-<em>provision</em> dengan menggunakan sebuah <a href=https://github.com/kubernetes/examples/tree/main/staging/persistent-volume-provisioning/README.md>Provisioner PersistentVolume</a> berdasarkan <code>storage class</code> yang dispesifikasikan, atau sudah ditentukan sebelumnya oleh administrator.</li><li>Menghapus dan/atau <em>scaling</em> sebuah StatefulSet <em>tidak akan</em> menghapus volume yang berkaitan dengan StatefulSet tersebut. Hal ini dilakukan untuk menjamin data yang disimpan, yang secara umum dinilai lebih berhaga dibandingkan dengan mekanisme penghapusan data secara otomatis pada sumber daya terkait.</li><li>StatefulSet saat ini membutuhkan sebuah <a href=/id/docs/concepts/services-networking/service/#headless-services>Headless Service</a> yang nantinya akan bertanggung jawab terhadap pada identitas jaringan pada Pod. Kamulah yang bertanggung jawab untuk membuat Service tersebut.</li><li>StatefulSet tidak menjamin terminasi Pod ketika sebuah StatefulSet dihapus. Untuk mendapatkan terminasi Pod yang terurut dan <em>graceful</em> pada StatefulSet, kita dapat melakukan <em>scale down</em> Pod ke 0 sebelum penghapusan.</li><li>Ketika menggunakan <a href=#mekanisme-strategi-update-rolling-update>Rolling Update</a> dengan
<a href=#kebijakan-manajemen-pod>Kebijakan Manajemen Pod</a> (<code>OrderedReady</code>) secara default,
hal ini memungkinkan untuk mendapatkan <em>state</em> yang lebih terperinci yang membutuhkan
<a href=#forced-rollback>mekanisme intervensi manual untuk perbaikan</a>.</li></ul><h2 id=komponen-komponen>Komponen-Komponen</h2><p>Contoh di bawah ini akna menunjukkan komponen-komponen penyusun StatefulSet.</p><ul><li>Sebuah Service Headless, dengan nama nginx, digunakan untuk mengontrol domain jaringan.</li><li>StatefulSet, dengan nama web, memiliki Spek yang mengindikasikan terdapat 3 replika Container yang akan dihidupkan pada Pod yang unik.</li><li><em>Field</em> <code>volumeClaimTemplates</code> akan menyediakan penyimpanan stabil menggunakan <a href=/id/docs/concepts/storage/persistent-volumes/>PersistentVolume</a> yang di-<em>provision</em> oleh sebuah Provisioner PersistentVolume.</li></ul><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Service<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>nginx<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>labels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>app</span>:<span style=color:#bbb> </span>nginx<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>ports</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>port</span>:<span style=color:#bbb> </span><span style=color:#666>80</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>web<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>clusterIP</span>:<span style=color:#bbb> </span>None<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>selector</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>app</span>:<span style=color:#bbb> </span>nginx<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:#00f;font-weight:700>---</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>apps/v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>StatefulSet<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>web<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>selector</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>matchLabels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>app</span>:<span style=color:#bbb> </span>nginx<span style=color:#bbb> </span><span style=color:#080;font-style:italic># harus sesuai dengan .spec.template.metadata.labels</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>serviceName</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;nginx&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>replicas</span>:<span style=color:#bbb> </span><span style=color:#666>3</span><span style=color:#bbb> </span><span style=color:#080;font-style:italic># nilai default-nya adalah 1</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>template</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>labels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>app</span>:<span style=color:#bbb> </span>nginx<span style=color:#bbb> </span><span style=color:#080;font-style:italic># harus sesuai dengan .spec.selector.matchLabels</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>terminationGracePeriodSeconds</span>:<span style=color:#bbb> </span><span style=color:#666>10</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>nginx<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>k8s.gcr.io/nginx-slim:0.8<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>ports</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span>- <span style=color:green;font-weight:700>containerPort</span>:<span style=color:#bbb> </span><span style=color:#666>80</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>web<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>volumeMounts</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>www<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>mountPath</span>:<span style=color:#bbb> </span>/usr/share/nginx/html<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>volumeClaimTemplates</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>www<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>accessModes</span>:<span style=color:#bbb> </span>[<span style=color:#bbb> </span><span style=color:#b44>&#34;ReadWriteOnce&#34;</span><span style=color:#bbb> </span>]<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>storageClassName</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;my-storage-class&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>resources</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>requests</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>storage</span>:<span style=color:#bbb> </span>1Gi<span style=color:#bbb>
</span></span></span></code></pre></div><h2 id=selector-pod><em>Selector</em> Pod</h2><p>Kamu harus menspesifikasikan <em>field</em> <code>.spec.selector</code> dari sebuah StatefulSet untuk menyesuaikan dengan label yang ada pada <code>.spec.template.metadata.labels</code>. Sebelum Kubernetes 1.8, <em>field</em> <code>.spec.selector</code> dapat diabaikan. Sejak versi 1.8 dan versi selanjutnya, apabila tidak terdapat <em>selector</em> Pod yang sesuai maka akan menghasilkan eror pada validasi pembuatan StatefulSet.</p><h2 id=identitas-pod>Identitas Pod</h2><p>Pod pada StatefulSet memiliki identitas unik yang tersusun berdasarkan skala ordinal, sebuah
identitas jaringan yang stabil, serta penyimpanan yang stabil. Identitas yang ada pada Pod
ini akan tetap melekat, meskipun Pod tersebut dilakukan <em>(re)schedule</em> pada Node yang berbeda.</p><h3 id=indeks-ordinal>Indeks Ordinal</h3><p>Untuk sebuah StatefulSet dengan N buah replika, setiap Pod di dalam StatefulSet akan
diberi nama pada suatu indeks ordinal tertentu, dari 0 hingga N-1, yang unik pada Set ini.</p><h3 id=id-jaringan-yang-stabil>ID Jaringan yang Stabil</h3><p>Setiap Pod di dalam StatefulSet memiliki <em>hostname</em> diturunkan dari nama SatetulSet tersebut
serta ordinal Pod tersebut. Pola pada <em>hostname</em> yang terbentuk adalah
<code>$(statefulset name)-$(ordinal)</code>. Contoh di atas akan menghasilkan tiga Pod
dengan nama <code>web-0,web-1,web-2</code>.
Sebuah StatefulSet dapat menggunakan sebuah <a href=/id/docs/concepts/services-networking/service/#headless-services>Service Headless</a>
untuk mengontrol domain dari Pod yang ada. Domain yang diatur oleh Service ini memiliki format:
<code>$(service name).$(namespace).svc.cluster.local</code>, dimana "cluster.local" merupakan
domain klaster.
Seiring dibuatnya setiap Pod, Pod tersebut akan memiliki subdomain DNS-nya sendiri, yang memiliki format:
<code>$(podname).$(governing service domain)</code>, dimana Service yang mengatur didefinisikan oleh
<em>field</em> <code>serviceName</code> pada StatefulSet.</p><p>Seperti sudah disebutkan di dalam bagian <a href=#keterbatasan>keterbatasan</a>, kamulah yang bertanggung jawab
untuk membuat <a href=/id/docs/concepts/services-networking/service/#headless-services>Service Headless</a>
yang bertanggung jawab terhadap identitas jaringan pada Pod.</p><p>Di sini terdapat beberapa contoh penggunaan Domain Klaster, nama Service,
nama StatefulSet, dan bagaimana hal tersebut berdampak pada nama DNS dari Pod StatefulSet.</p><table><thead><tr><th>Domain Klaster</th><th>Service (ns/nama)</th><th>StatefulSet (ns/nama)</th><th>Domain StatefulSet</th><th>DNS Pod</th><th>Hostname Pod</th></tr></thead><tbody><tr><td>cluster.local</td><td>default/nginx</td><td>default/web</td><td>nginx.default.svc.cluster.local</td><td>web-{0..N-1}.nginx.default.svc.cluster.local</td><td>web-{0..N-1}</td></tr><tr><td>cluster.local</td><td>foo/nginx</td><td>foo/web</td><td>nginx.foo.svc.cluster.local</td><td>web-{0..N-1}.nginx.foo.svc.cluster.local</td><td>web-{0..N-1}</td></tr><tr><td>kube.local</td><td>foo/nginx</td><td>foo/web</td><td>nginx.foo.svc.kube.local</td><td>web-{0..N-1}.nginx.foo.svc.kube.local</td><td>web-{0..N-1}</td></tr></tbody></table><div class="alert alert-info note callout" role=alert><strong>Catatan:</strong> Domain klaster akan diatur menjadi <code>cluster.local</code> kecuali
<a href=/id/docs/concepts/services-networking/dns-pod-service/>nilainya dikonfigurasi</a>.</div><h3 id=penyimpanan-stabil>Penyimpanan Stabil</h3><p>Kubernetes membuat sebuah <a href=/id/docs/concepts/storage/persistent-volumes/>PersistentVolume</a> untuk setiap
VolumeClaimTemplate. Pada contoh nginx di atas, setiap Pod akan menerima sebuah PersistentVolume
dengan StorageClass <code>my-storage-class</code> dan penyimpanan senilai 1 Gib yang sudah di-<em>provisioning</em>. Jika tidak ada StorageClass
yang dispesifikasikan, maka StorageClass <em>default</em> akan digunakan. Ketika sebuah Pod dilakukan <em>(re)schedule</em>
pada sebuah Node, <code>volumeMounts</code> akan me-<em>mount</em> PersistentVolumes yang terkait dengan
PersistentVolume Claim-nya. Perhatikan bahwa, PersistentVolume yang terkait dengan
PersistentVolumeClaim dari Pod tidak akan dihapus ketika Pod, atau StatefulSet dihapus.
Penghapusan ini harus dilakukan secara manual.</p><h3 id=label-pod-name>Label <em>Pod Name</em></h3><p>Ketika sebuah <em>controller</em> StatefulSet membuat sebuah Pod, <em>controller</em> ini akan menambahkan label, <code>statefulset.kubernetes.io/pod-name</code>,
yang akan diaktifkan pada nama Pod. Label ini akan mengizinkan kamu untuk meng-<em>attach</em> sebuah Service pada Pod spesifik tertentu.
di StatefulSet.</p><h2 id=jaminan-deployment-dan-mekanisme-scaling>Jaminan Deployment dan Mekanisme <em>Scaling</em></h2><ul><li>Untuk sebuah StatefulSet dengan N buah replika, ketika Pod di-<em>deploy</em>, Pod tersebut akan dibuat secara berurutan dengan urutan nilai {0..N-1}.</li><li>Ketika Pod dihapus, Pod tersebut akan dihentikan dengan urutan terbalik, yaitu {N-1..0}.</li><li>Sebelum operasi <em>scaling</em> diaplikasikan pada sebuah Pod, semua Pod sebelum Pod tersebut haruslah sudah dalam status Running dan Ready.</li><li>Sebelum sebuah Pod dihentikan, semua Pod setelah Pod tersebut haruslah sudah terlebih dahulu dihentikan.</li></ul><p>StatefulSet tidak boleh menspesifikasikan nilai dari <code>pod.Spec.TerminationGracePeriodSeconds</code> menjadi 0. Hal ini tidaklah aman dan tidak disarankan. Untuk penjelasan lebih lanjut, silakan lihat <a href=/docs/tasks/run-application/force-delete-stateful-set-pod/>penghapusan paksa Pod pada StatefulSet</a>.</p><p>Ketika contoh nginx di atas dibuat, tiga Pod akan di-<em>deploy</em> dengan urutan
web-0, web-1, web-2. web-1 tidak akan di-<em>deploy</em> sebelum web-0 berada dalam status
<a href=/docs/user-guide/pod-states/>Running dan Ready</a>, dan web-2 tidak akan di-<em>deploy</em> sebelum
web-1 berada dalam status Running dan Ready. Jika web-0 gagal, setelah web-1 berada dalam status Running and Ready,
tapi sebelum web-2 dibuat, maka web-2 tidak akan dibuat hingga web-0 sukses dibuat ulang dan
berada dalam status Running dan Ready.</p><p>Jika seorang pengguna akan melakukan mekanisme <em>scale</em> pada contoh di atas dengan cara melakukan <em>patch</em>,
pada StatefulSet sehingga <code>replicas=1</code>, maka web-2 akan dihentikan terlebih dahulu.
web-1 tidak akan dihentikan hingga web-2 benar-benar berhenti dan dihapus.
Jika web-0 gagal setelah web-2 diterminasi dan berada dalam status mati,
tetapi sebelum web-1 dihentikan, maka web-1 tidak akan dihentikan hingga
web-0 berada dalam status Running dan Ready.</p><h3 id=kebijakan-manajemen-pod>Kebijakan Manajemen Pod</h3><p>Pada Kubernetes versi 1.7 dan setelahnya, StatefulSet mengizinkan kamu untuk
melakukan mekanisme urutan tadi menjadi lebih fleksibel dengan tetap
menjamin keunikan dan identitas yang ada melalui <em>field</em> <code>.spec.podManagementPolicy</code>.</p><h4 id=manajemen-orderedready-pada-pod>Manajemen OrderedReady pada Pod</h4><p>Manajemen <code>OrderedReady</code> pada Pod merupakan nilai default dari StatefulSet.
Hal ini akan mengimplementasikan perilaku yang dijelaskan <a href=#jaminan-deployment-dan-mekanisme-scaling>di atas</a>.</p><h4 id=manajemen-pod-secara-paralel>Manajemen Pod secara Paralel</h4><p>Manajemen Pod secara <code>paralel</code> akan menyebabkan kontroler StatefulSet untuk
memulai atau menghentikan semua Pod yang ada secara paralel, dan tidak
menunggu Pod berada dalam status Running dan Ready atau sudah dihentikan secara menyeluruh
sebelum me-<em>launch</em> atau menghentikan Pod yang lain. Opsi ini hanya akan memengaruhi operasi
<em>scaling</em>. Operasi pembaruan tidak akan terpengaruh.</p><h2 id=strategi-update>Strategi Update</h2><p>Pada Kubernetes versi 1.7 dan setelahnya, <em>field</em> <code>.spec.updateStrategy</code> pada StatefulSet
memungkinkan-mu untuk melakukan konfigurasi dan menonaktifkan otomatisasi
<em>rolling updates</em> untuk container, label, resource request/limits, dan
annotation pada Pod yang ada di dalam sebuah StatefulSet.</p><h3 id=mekanisme-strategi-update-on-delete>Mekanisme Strategi Update <em>On Delete</em></h3><p>Mekanisme strategi update <code>OnDelete</code> mengimplementasikan perilaku legasi (versi 1.6 dan sebelumnya).
Ketika sebuah <em>field</em> <code>.spec.updateStrategy.type</code> pada StatefulSet diubah menjadi <code>OnDelete</code>
maka kontroler StatefulSet tidak akan secara otomatis melakukan update
pada Pod yang ada di dalam StatefulSet tersebut. Pengguna haruslah secara manual
melakukan penghapusan Pod agar kontroler membuat Pod baru yang mengandung modifikasi
yang dibuat pada <em>field</em> <code>.spec.template</code> StatefulSet.</p><h3 id=mekanisme-strategi-update-rolling-updates>Mekanisme Strategi Update <em>Rolling Updates</em></h3><p>Mekanisme strategi update <code>RollingUpdate</code> mengimplementasikan otomatisasi <em>rolling update</em>
untuk Pod yang ada pada StatefulSet. Strategi inilah yang diterapkan ketika <code>.spec.updateStrategy</code> tidak dispesifikasikan.
Ketika <em>field</em> <code>.spec.updateStrategy.type</code> diubah nilainya menjadi <code>RollingUpdate</code>, maka
kontroler StatefulSet akan menghapus dan membuat setiap Pod di dalam StatefulSet. Kemudian
hal ini akan diterapkan dengan urutan yang sama dengan mekanisme terminasi Pod (dari nilai ordinal terbesar ke terkecil),
yang kemudian akan melakukan update Pod satu per satu. Mekanisme ini akan memastikan sebuah Pod yang di-update
berada dalam status Running dan Ready sebelum meng-update Pod dengan nilai ordinal lebih rendah.</p><h4 id=mekanisme-strategi-update-dengan-partisi>Mekanisme Strategi Update dengan Partisi</h4><p>Mekanisme strategi update <code>RollingUpdate</code> dapat dipartisi, dengan cara menspesifikasikan nilai
dari <code>.spec.updateStrategy.rollingUpdate.partition</code>. Jika nilai dari <em>field</em> ini dispesifikasikan,
maka semua Pod dengan nilai ordinal yang lebih besar atau sama dengan nilai partisi akan diupdate ketika
nilai <code>.spec.template</code> pada StatefulSet diubah. Semua Pod dengan nilai ordinal yang lebih kecil
dari partisi tidak akan diupdate, dan, bahkan setelah Pod tersebut dihapus, Pod ini akan digantikan
dengan Pod versi sebelumnya. Jika nilai <code>.spec.updateStrategy.rollingUpdate.partition</code> lebih besar dari
nilai <code>.spec.replicas</code>, update pada <code>.spec.template</code> tidak akan dipropagasi pada Pod-Pod-nya.
Pada sebagian besar kasus, kamu tidak akan perlu menggunakan partisi, tapi hal tersebut
akan sangat berguna apabila kamu ingin mekakukan mekanisme update <em>canary</em>.</p><h4 id=mekanisme-strategi-update-yang-dipaksa-forced-rollback>Mekanisme Strategi Update yang Dipaksa (<em>Forced Rollback</em>)</h4><p>Ketika menggunakan strategi update <a href=#mekanisme-strategi-update-rolling-updates>Rolling Updates</a> dengan nilai default
<a href=#kebijakan-manajemen-pod>Kebijakan Manajemen Pod</a> (<code>OrderedReady</code>),
hal ini memungkinkan adanya kondisi <em>broken</em> yang membutuhkan intervensi secara manual
agar kondisi ini dapat diperbaiki.</p><p>Jika kamu melakukan update pada template Pod untuk konfigurasi
yang tidak pernah berada dalam status Running dan Ready (sebagai contohnya, apabila terdapat kode <em>binary</em> yang buruk atau error pada konfigurasi di level aplikasi),
maka StatefulSet akan menghentikan proses rollout dan berada dalam status <em>wait</em>.</p><p>Dalam kondisi ini, maka templat Pod tidak akan diubah secara otomatis pada konfigurasi sebelumnya
Hal ini terjadi karena adanya <a href=https://github.com/kubernetes/kubernetes/issues/67250>isu</a>,
StatefulSet akan tetap berada dalam kondisi <em>wait</em> untuk menunggu Pod yang bermasalah untuk menjadi Ready
(yang tidak akan terjadi) dan sebelum StatefulSet ini berusaha untuk melakukan <em>revert</em> pada konfigurasi sebelumnya.</p><p>Setelah melakukan mekanisme <em>revert</em> templat, kamu juga harus menghapus semua Pod di dalam
StatefulSet tersebut yang telah berusaha untuk menggunakan konfigurasi yang <em>broken</em>.
StatefulSet akan mulai membuat Pod dengan templat konfigurasi yang sudah di-<em>revert</em>.</p><h2 id=selanjutnya>Selanjutnya</h2><ul><li>Ikuti contoh yang ada pada <a href=/docs/tutorials/stateful-application/basic-stateful-set/>bagaimana cara melakukan deployi aplikasi stateful</a>.</li><li>Ikuti contoh yang ada pada <a href=/docs/tutorials/stateful-application/cassandra/>bagaimana cara melakukan deploy Cassandra dengan StatefulSets</a>.</li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-41600eb8b6631c88848156f381e9d588>4.2.5 - DaemonSet</h1><p>DaemonSet memastikan semua atau sebagian Node memiliki salinan sebuah Pod.
Ketika Node baru ditambahkan ke klaster, Pod ditambahkan ke Node tersebut.
Ketika Node dihapus dari klaster, Pod akan dibersihkan oleh <em>garbage collector</em>.
Menghapus DaemonSet akan menghapus semua Pod yang ia buat.</p><p>Beberapa penggunaan umum DaemonSet, yaitu:</p><ul><li>menjalankan <em>daemon</em> penyimpanan di klaster, seperti <code>glusterd</code>, <code>ceph</code>, di
setiap Node.</li><li>menjalankan <em>daemon</em> pengumpulan log di semua Node, seperti <code>fluentd</code> atau
<code>logstash</code>.</li><li>menjalankan <em>daemon</em> pemantauan Node di setiap Node, seperti <a href=https://github.com/prometheus/node_exporter>Prometheus Node Exporter</a>, <a href=https://github.com/Flowmill/flowmill-k8s/>Flowmill</a>, <a href=https://docs.sysdig.com>Sysdig Agent</a>, <code>collectd</code>, <a href=https://www.dynatrace.com/technologies/kubernetes-monitoring/>Dynatrace OneAgent</a>, <a href=https://docs.appdynamics.com/display/CLOUD/Container+Visibility+with+Kubernetes>AppDynamics Agent</a>, <a href=https://docs.datadoghq.com/agent/kubernetes/daemonset_setup/>Datadog agent</a>, <a href=https://docs.newrelic.com/docs/integrations/kubernetes-integration/installation/kubernetes-installation-configuration>New Relic agent</a>, Ganglia <code>gmond</code> atau <a href=https://www.instana.com/supported-integrations/kubernetes-monitoring/>Instana Agent</a>.</li></ul><p>Dalam kasus sederhana, satu DaemonSet, mencakup semua Node, akan digunakan untuk
setiap jenis <em>daemon</em>. Pengaturan yang lebih rumit bisa saja menggunakan lebih
dari satu DaemonSet untuk satu jenis <em>daemon</em>, tapi dengan <em>flag</em> dan/atau
permintaan cpu/memori yang berbeda untuk jenis <em>hardware</em> yang berbeda.</p><h2 id=menulis-spek-daemonset>Menulis Spek DaemonSet</h2><h3 id=buat-daemonset>Buat DaemonSet</h3><p>Kamu bisa definisikan DaemonSet dalam berkas YAML. Contohnya, berkas
<code>daemonset.yaml</code> di bawah mendefinisikan DaemonSet yang menjalankan <em>image</em> Docker
fluentd-elasticsearch:</p><div class=highlight><div class=copy-code-icon style=text-align:right><a href=https://raw.githubusercontent.com/kubernetes/website/main/content/id/examples/controllers/daemonset.yaml download=controllers/daemonset.yaml><code>controllers/daemonset.yaml</code></a>
<img src=/images/copycode.svg style=max-height:24px;cursor:pointer onclick='copyCode("controllers-daemonset-yaml")' title="Copy controllers/daemonset.yaml to clipboard"></img></div><div class=includecode id=controllers-daemonset-yaml><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>apps/v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>DaemonSet<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>fluentd-elasticsearch<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>namespace</span>:<span style=color:#bbb> </span>kube-system<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>labels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>k8s-app</span>:<span style=color:#bbb> </span>fluentd-logging<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>selector</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>matchLabels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>fluentd-elasticsearch<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>template</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>labels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>fluentd-elasticsearch<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>tolerations</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- <span style=color:green;font-weight:700>key</span>:<span style=color:#bbb> </span>node-role.kubernetes.io/master<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>operator</span>:<span style=color:#bbb> </span>Exists<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>effect</span>:<span style=color:#bbb> </span>NoSchedule<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>fluentd-elasticsearch<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>quay.io/fluentd_elasticsearch/fluentd:v2.5.2<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>resources</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>limits</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>            </span><span style=color:green;font-weight:700>memory</span>:<span style=color:#bbb> </span>200Mi<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>requests</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>            </span><span style=color:green;font-weight:700>cpu</span>:<span style=color:#bbb> </span>100m<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>            </span><span style=color:green;font-weight:700>memory</span>:<span style=color:#bbb> </span>200Mi<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>volumeMounts</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>varlog<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>mountPath</span>:<span style=color:#bbb> </span>/var/log<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>varlibdockercontainers<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>mountPath</span>:<span style=color:#bbb> </span>/var/lib/docker/containers<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>readOnly</span>:<span style=color:#bbb> </span><span style=color:#a2f;font-weight:700>true</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>terminationGracePeriodSeconds</span>:<span style=color:#bbb> </span><span style=color:#666>30</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>volumes</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>varlog<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>hostPath</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>path</span>:<span style=color:#bbb> </span>/var/log<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>varlibdockercontainers<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>hostPath</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>path</span>:<span style=color:#bbb> </span>/var/lib/docker/containers<span style=color:#bbb>
</span></span></span></code></pre></div></div></div><ul><li>Buat DaemonSet berdasarkan berkas YAML:</li></ul><pre tabindex=0><code>kubectl apply -f https://k8s.io/examples/controllers/daemonset.yaml
</code></pre><h3 id=field-wajib><em>Field</em> Wajib</h3><p>Seperti semua konfigurasi Kubernetes lainnya, DaemonSet membutuhkan <em>field</em>
<code>apiVersion</code>, <code>kind</code>, dan <code>metadata</code>. Untuk informasi umum tentang berkas konfigurasi, lihat dokumen <a href=/docs/user-guide/deploying-applications/>men-<em>deploy</em> aplikasi</a>,
<a href=/docs/tasks/>pengaturan kontainer</a>, dan <a href=/id/docs/concepts/overview/working-with-objects/object-management/>pengelolaan objek dengan kubectl</a>.</p><p>DaemonSet juga membutuhkan bagian <a href=https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#spec-and-status><code>.spec</code></a>.</p><h3 id=templat-pod>Templat Pod</h3><p><code>.spec.template</code> adalah salah satu <em>field</em> wajib di dalam <code>.spec</code>.</p><p><code>.spec.template</code> adalah sebuah <a href=/id/docs/concepts/workloads/pods/pod-overview/#templat-pod>templat Pod</a>. Skemanya benar-benar sama dengan <a href=/id/docs/concepts/workloads/pods/pod/>Pod</a>, kecuali bagian bahwa ia bersarang/<em>nested</em> dan tidak memiliki <code>apiVersion</code> atau <code>kind</code>.</p><p>Selain <em>field</em> wajib untuk Pod, templat Pod di DaemonSet harus
menspesifikasikan label yang sesuai (lihat <a href=#selektor-pod>selektor Pod</a>).</p><p>Templat Pod di DaemonSet harus memiliki <a href=/id/docs/concepts/workloads/pods/pod-lifecycle/#restart-policy><code>RestartPolicy</code></a>
yang bernilai <code>Always</code>, atau tidak dispesifikasikan, sehingga <em>default</em> menjadi <code>Always</code>.
DaemonSet dengan nilai <code>Always</code> membuat Pod akan selalu di-<em>restart</em> saat kontainer
keluar/berhenti atau terjadi <em>crash</em>.</p><h3 id=selektor-pod>Selektor Pod</h3><p><em>Field</em> <code>.spec.selector</code> adalah selektor Pod. Cara kerjanya sama dengan <code>.spec.selector</code> pada <a href=/docs/concepts/jobs/run-to-completion-finite-workloads/>Job</a>.</p><p>Pada Kubernetes 1.8, kamu harus menspesifikasikan selektor Pod yang cocok dengan label pada <code>.spec.template</code>.
Selektor Pod tidak akan lagi diberi nilai <em>default</em> ketika dibiarkan kosong. Nilai <em>default</em> selektor tidak
cocok dengan <code>kubectl apply</code>. Juga, sesudah DaemonSet dibuat, <code>.spec.selector</code> tidak dapat diubah.
Mengubah selektor Pod dapat menyebabkan Pod <em>orphan</em> yang tidak disengaja, dan membingungkan pengguna.</p><p>Objek <code>.spec.selector</code> memiliki dua <em>field</em>:</p><ul><li><code>matchLabels</code> - bekerja seperti <code>.spec.selector</code> pada <a href=/id/docs/concepts/workloads/controllers/replicationcontroller/>ReplicationController</a>.</li><li><code>matchExpressions</code> - bisa digunakan untuk membuat selektor yang lebih canggih
dengan mendefinisikan <em>key</em>, daftar <em>value</em> dan operator yang menyatakan
hubungan antara <em>key</em> dan <em>value</em>.</li></ul><p>Ketika keduanya dispesifikasikan hasilnya diperoleh dari operasi AND.</p><p>Jika <code>.spec.selector</code> dispesifikasikan, nilainya harus cocok dengan <code>.spec.template.metadata.labels</code>. Konfigurasi yang tidak cocok akan ditolak oleh API.</p><p>Selain itu kamu tidak seharusnya membuat Pod apapun yang labelnya cocok dengan
selektor tersebut, entah secara langsung, via DaemonSet lain, atau via <em>workload resource</em> lain seperti ReplicaSet.
Jika kamu coba buat, <a class=glossary-tooltip title='Kontrol tertutup yang mengawasi kondisi bersama dari klaster melalui apiserver dan membuat perubahan yang mencoba untuk membawa kondisi saat ini ke kondisi yang diinginkan.' data-toggle=tooltip data-placement=top href=/id/docs/concepts/architecture/controller/ target=_blank aria-label=Pengontrol>Pengontrol</a> DaemonSet akan
berpikir bahwa Pod tersebut dibuat olehnya. Kubernetes tidak akan menghentikan
kamu melakukannya. Contoh kasus di mana kamu mungkin melakukan ini dengan
membuat Pod dengan nilai yang berbeda di sebuah Node untuk <em>testing</em>.</p><h3 id=menjalankan-pod-di-sebagian-node>Menjalankan Pod di Sebagian Node</h3><p>Jika kamu menspesifikasikan <code>.spec.template.spec.nodeSelector</code>, maka <em>controller</em> DaemonSet akan
membuat Pod pada Node yang cocok dengan <a href=/id/docs/concepts/scheduling-eviction/assign-pod-node/>selektor
Node</a>. Demikian juga, jika kamu menspesifikasikan <code>.spec.template.spec.affinity</code>,
maka <em>controller</em> DaemonSet akan membuat Pod pada Node yang cocok dengan <a href=/id/docs/concepts/scheduling-eviction/assign-pod-node/>Node affinity</a>.
Jika kamu tidak menspesifikasikan sama sekali, maka <em>controller</em> DaemonSet akan
membuat Pod pada semua Node.</p><h2 id=bagaimana-pod-daemon-dijadwalkan>Bagaimana Pod Daemon Dijadwalkan</h2><h3 id=dijadwalkan-oleh-default-scheduler>Dijadwalkan oleh <em>default scheduler</em></h3><div style=margin-top:10px;margin-bottom:10px><b>FEATURE STATE:</b> <code>Kubernetes 1.17 [stable]</code></div><p>DaemonSet memastikan bahwa semua Node yang memenuhi syarat menjalankan salinan
Pod. Normalnya, Node yang menjalankan Pod dipilih oleh <em>scheduler</em> Kubernetes.
Namun, Pod DaemonSet dibuat dan dijadwalkan oleh <em>controller</em> DaemonSet. Hal ini
mendatangkan masalah-masalah berikut:</p><ul><li>Inkonsistensi perilaku Pod: Pod normal yang menunggu dijadwalkan akan dibuat
dalam keadaan <code>Pending</code>, tapi Pod DaemonSet tidak seperti itu. Ini
membingungkan untuk pengguna.</li><li><a href=/id/docs/concepts/configuration/pod-priority-preemption/>Pod preemption</a>
ditangani oleh <em>default scheduler</em>. Ketika <em>preemption</em> dinyalakan,
<em>controller</em> DaemonSet akan membuat keputusan penjadwalan tanpa
memperhitungkan prioritas Pod dan <em>preemption</em>.</li></ul><p><code>ScheduleDaemonSetPods</code> mengizinkan kamu untuk menjadwalkan DaemonSet
menggunakan <em>default scheduler</em> daripada <em>controller</em> DaemonSet, dengan
menambahkan syarat <code>NodeAffinity</code> pada Pod DaemonSet daripada syarat
<code>.spec.nodeName</code>. Kemudian, <em>default scheduler</em> digunakan untuk mengikat Pod ke
host target. Jika afinitas Node dari Pod DaemonSet sudah ada, maka ini
akan diganti. <em>Controller DaemonSet</em> hanya akan melakukan operasi-operasi ini
ketika membuat atau mengubah Pod DaemonSet, dan tidak ada perubahan yang terjadi
pada <code>spec.template</code> DaemonSet.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>nodeAffinity</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>requiredDuringSchedulingIgnoredDuringExecution</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>nodeSelectorTerms</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:green;font-weight:700>matchFields</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- <span style=color:green;font-weight:700>key</span>:<span style=color:#bbb> </span>metadata.name<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>operator</span>:<span style=color:#bbb> </span>In<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>values</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span>- target-host-name<span style=color:#bbb>
</span></span></span></code></pre></div><p>Sebagai tambahan, <em>toleration</em> <code>node.kubernetes.io/unschedulable:NoSchedule</code>
ditambahkan secara otomatis pada Pod DaemonSet. <em>Default scheduler</em> akan
mengabaikan Node <code>unschedulable</code> ketika menjadwalkan Pod DaemonSet.</p><h3 id=taint-dan-toleration><em>Taint</em> dan <em>Toleration</em></h3><p>Meskipun Pod Daemon menghormati
<a href=/id/docs/concepts/configuration/taint-and-toleration>taint dan toleration</a>,
<em>toleration</em> berikut ini akan otomatis ditambahkan ke Pod DaemonSet sesuai
dengan fitur yang bersangkutan.</p><table><thead><tr><th><em>Toleration Key</em></th><th><em>Effect</em></th><th>Versi</th><th>Deskripsi</th></tr></thead><tbody><tr><td><code>node.kubernetes.io/not-ready</code></td><td>NoExecute</td><td>1.13+</td><td>Pod DaemonSet tidak akan menjadi <em>evicted</em> ketika ada masalah Node seperti partisi jaringan.</td></tr><tr><td><code>node.kubernetes.io/unreachable</code></td><td>NoExecute</td><td>1.13+</td><td>Pod DaemonSet tidak akan menjadi <em>evicted</em> ketika ada masalah Node seperti partisi jaringan.</td></tr><tr><td><code>node.kubernetes.io/disk-pressure</code></td><td>NoSchedule</td><td>1.8+</td><td></td></tr><tr><td><code>node.kubernetes.io/memory-pressure</code></td><td>NoSchedule</td><td>1.8+</td><td></td></tr><tr><td><code>node.kubernetes.io/unschedulable</code></td><td>NoSchedule</td><td>1.12+</td><td>Pod DaemonSet mentoleransi atribut <code>unschedulable</code> <em>default scheduler</em>.</td></tr><tr><td><code>node.kubernetes.io/network-unavailable</code></td><td>NoSchedule</td><td>1.12+</td><td>Pod DaemonSet yang menggunakan jaringan host mentoleransi atribut <code>network-unavailable</code> <em>default scheduler</em>.</td></tr></tbody></table><h2 id=berkomunikasi-dengan-pod-daemon>Berkomunikasi dengan Pod Daemon</h2><p>Beberapa pola yang mungkin digunakan untuk berkomunikasi dengan Pod dalam DaemonSet, yaitu:</p><ul><li><strong>Push</strong>: Pod dalam DaemonSet diatur untuk mengirim pembaruan status ke servis lain,
contohnya <em>stats database</em>. Pod ini tidak memiliki klien.</li><li><strong>IP Node dan Konvensi Port</strong>: Pod dalam DaemonSet dapat menggunakan <code>hostPort</code>, sehingga Pod dapat diakses menggunakan IP Node. Klien tahu daftar IP Node dengan suatu cara, dan tahu port berdasarkan konvensi.</li><li><strong>DNS</strong>: Buat <a href=/id/docs/concepts/services-networking/service/#headless-services>headless service</a> dengan Pod selektor yang sama,
dan temukan DaemonSet menggunakan <em>resource</em> <code>endpoints</code> atau mengambil beberapa A <em>record</em> dari DNS.</li><li><strong>Service</strong>: Buat Servis dengan Pod selektor yang sama, dan gunakan Servis untuk mengakses <em>daemon</em> pada
Node random. (Tidak ada cara mengakses spesifik Node)</li></ul><h2 id=melakukan-pembaruan-daemonset>Melakukan Pembaruan DaemonSet</h2><p>Jika label Node berubah, DaemonSet akan menambahkan Pod ke Node cocok yang baru dan menghapus Pod dari
Node tidak cocok yang baru.</p><p>Kamu bisa mengubah Pod yang dibuat DaemonSet. Namun, Pod tidak membolehkan perubahan semua <em>field</em>.
Perlu diingat, <em>controller</em> DaemonSet akan menggunakan templat yang asli di waktu selanjutnya
Node baru (bahkan dengan nama yang sama) dibuat.</p><p>Kamu bisa menghapus DaemonSet. Jika kamu spesifikasikan <code>--cascade=false</code> dengan <code>kubectl</code>, maka
Pod akan dibiarkan pada Node. Jika kamu pada waktu kemudian membuat DaemonSet baru dengan selektor
yang sama, DaemonSet yang baru akan mengadopsi Pod yang sudah ada. Jika ada Pod yang perlu diganti,
DaemonSet akan mengganti sesuai dengan <code>updateStrategy</code>.</p><p>Kamu bisa <a href=/docs/tasks/manage-daemon/update-daemon-set/>melakukan rolling update</a> pada DaemonSet.</p><h2 id=alternatif-daemonset>Alternatif DaemonSet</h2><h3 id=init-scripts><em>Init Scripts</em></h3><p>Kamu mungkin menjalankan proses <em>daemon</em> dengan cara menjalankan mereka langsung pada Node (e.g.
menggunakan <code>init</code>, <code>upstartd</code>, atau <code>systemd</code>). Tidak ada salahnya seperti itu. Namun, ada beberapa
keuntungan menjalankan proses <em>daemon</em> via DaemonSet.</p><ul><li>Kemampuan memantau dan mengatur log <em>daemon</em> dengan cara yang sama dengan aplikasi.</li><li>Bahasa dan alat Konfigurasi yang sama (e.g. Templat Pod, <code>kubectl</code>) untuk <em>daemon</em> dan aplikasi.</li><li>Menjalankan <em>daemon</em> dalam kontainer dengan batasan <em>resource</em> meningkatkan isolasi antar <em>daemon</em> dari
kontainer aplikasi. Namun, hal ini juga bisa didapat dengan menjalankan <em>daemon</em> dalam kontainer tapi
tanpa Pod (e.g. dijalankan langsung via Docker).</li></ul><h3 id=pod-polosan>Pod Polosan</h3><p>Dimungkinkan untuk membuat Pod langsung dengan menspesifikasikan Node mana untuk dijalankan. Namun,
DaemonSet akan menggantikan Pod yang untuk suatu alasan dihapus atau dihentikan, seperti pada saat
kerusakan Node atau pemeliharaan Node yang mengganggu seperti pembaruan <em>kernel</em>. Oleh karena itu, kamu
perlu menggunakan DaemonSet daripada membuat Pod satu per satu.</p><h3 id=pod-statis>Pod Statis</h3><p>Dimungkinkan untuk membuat Pod dengan menulis sebuah berkas ke direktori tertentu yang di-<em>watch</em> oleh Kubelet.
Pod ini disebut dengan istilah <a href=/docs/concepts/cluster-administration/static-pod/>Pod statis</a>.
Berbeda dengan DaemonSet, Pod statis tidak dapat dikelola menggunakan kubectl atau klien API Kubernetes
yang lain. Pod statis tidak bergantung kepada apiserver, membuat Pod statis berguna pada kasus-kasus
<em>bootstrapping</em> klaster.</p><h3 id=deployment>Deployment</h3><p>DaemonSet mirip dengan <a href=/id/docs/concepts/workloads/controllers/deployment/>Deployment</a> sebab mereka
sama-sama membuat Pod, dan Pod yang mereka buat punya proses yang seharusnya tidak berhenti (e.g. peladen web,
peladen penyimpanan)</p><p>Gunakan Deployment untuk layanan <em>stateless</em>, seperti <em>frontend</em>, di mana proses <em>scaling</em> naik
dan turun jumlah replika dan <em>rolling update</em> lebih penting daripada mengatur secara tepat di
host mana Pod berjalan. Gunakan DaemonSet ketika penting untuk satu salinan Pod
selalu berjalan di semua atau sebagian host, dan ketika Pod perlu berjalan
sebelum Pod lainnya.</p></div><div class=td-content style=page-break-before:always><h1 id=pg-9add0d2120634b63073ad08dc8683bd6>4.2.6 - Garbage Collection</h1><p>Peran daripada <em>garbage collector</em> Kubernetes adalah untuk menghapus objek tertentu yang sebelumnya mempunyai pemilik, tetapi tidak lagi mempunyai pemilik.</p><h2 id=pemilik-dan-dependen>Pemilik dan dependen</h2><p>Beberapa objek Kubernetes adalah pemilik dari objek lainnya. Sebagai contoh, sebuah ReplicaSet adalah pemilik dari sekumpulan Pod. Objek-objek yang dimiliki disebut <em>dependen</em> dari objek pemilik. Setiap objek dependen memiliki sebuah kolom <code>metadata.ownerReferences</code> yang menunjuk ke objek pemilik.</p><p>Terkadang, Kubernetes menentukan nilai dari <code>ownerReference</code> secara otomatis. Sebagai contoh, ketika kamu membuat sebuah ReplicaSet, Kubernetes secara otomatis akan menentukan tiap kolom <code>ownerReference</code> dari tiap Pod di dalam ReplicaSet. Pada versi 1.8, Kubernetes secara otomatis menentukan nilai dari <code>ownerReference</code> untuk objek yang diciptakan atau diadopsi oleh ReplicationController, ReplicaSet, StatefulSet, DaemonSet, Deployment, Job dan CronJob.</p><p>Kamu juga bisa menspesifikasikan hubungan antara pemilik dan dependen dengan cara menentukan kolom <code>ownerReference</code> secara manual.</p><p>Berikut adalah berkas untuk sebuah ReplicaSet yang memiliki tiga Pod:</p><div class=highlight><div class=copy-code-icon style=text-align:right><a href=https://raw.githubusercontent.com/kubernetes/website/main/content/id/examples/controllers/replicaset.yaml download=controllers/replicaset.yaml><code>controllers/replicaset.yaml</code></a>
<img src=/images/copycode.svg style=max-height:24px;cursor:pointer onclick='copyCode("controllers-replicaset-yaml")' title="Copy controllers/replicaset.yaml to clipboard"></img></div><div class=includecode id=controllers-replicaset-yaml><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>apps/v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>ReplicaSet<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>my-repset<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>replicas</span>:<span style=color:#bbb> </span><span style=color:#666>3</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>selector</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>matchLabels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>pod-is-for</span>:<span style=color:#bbb> </span>garbage-collection-example<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>template</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>labels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>pod-is-for</span>:<span style=color:#bbb> </span>garbage-collection-example<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>nginx<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>nginx</span></span></code></pre></div></div></div><p>Jika kamu membuat ReplicaSet tersebut dan kemudian melihat metadata Pod, kamu akan melihat kolom OwnerReferences:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl apply -f https://k8s.io/examples/controllers/replicaset.yaml
</span></span><span style=display:flex><span>kubectl get pods --output<span style=color:#666>=</span>yaml
</span></span></code></pre></div><p>Keluaran menunjukkan bahwa pemilik Pod adalah sebuah ReplicaSet bernama <code>my-repset</code>:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>apiVersion: v1
</span></span><span style=display:flex><span>kind: Pod
</span></span><span style=display:flex><span>metadata:
</span></span><span style=display:flex><span>  ...
</span></span><span style=display:flex><span>  ownerReferences:
</span></span><span style=display:flex><span>  - apiVersion: apps/v1
</span></span><span style=display:flex><span>    controller: <span style=color:#a2f>true</span>
</span></span><span style=display:flex><span>    blockOwnerDeletion: <span style=color:#a2f>true</span>
</span></span><span style=display:flex><span>    kind: ReplicaSet
</span></span><span style=display:flex><span>    name: my-repset
</span></span><span style=display:flex><span>    uid: d9607e19-f88f-11e6-a518-42010a800195
</span></span><span style=display:flex><span>  ...
</span></span></code></pre></div><div class="alert alert-info note callout" role=alert><strong>Catatan:</strong><p>Referensi pemilik lintas <em>namespace</em> tidak diperbolehkan oleh desain. Artinya:</p><ol><li>Dependen dengan cakupan <em>namespace</em> hanya bisa menspesifikasikan pemilik jika berada di <em>namespace</em> yang sama, dan pemilik memiliki cakupan klaster.</li><li>Dependen dengan cakupan klaster hanya bisa menspesifikasikan pemilik yang memiliki cakupan klaster, tetapi tidak berlaku untuk pemilik yang memiliki cakupan klaster.</li></ol></div><h2 id=mengontrol-bagaimana-garbage-collector-menghapus-dependen>Mengontrol bagaimana <em>garbage collector</em> menghapus dependen</h2><p>Ketika kamu menghapus sebuah objek, kamu bisa menspesifikasi apakah dependen objek tersebut juga dihapus secara otomatis. Menghapus dependen secara otomatis disebut <em>cascading deletion</em>. <em>Cascading deletion</em> memiliki dua mode: <em>background</em> dan <em>foreground</em>.</p><h3 id=foreground-cascading-deletion>Foreground cascading deletion</h3><p>Pada <em>foreground cascading deletion</em>, pertama objek utama akan memasuki keadaan "<em>deletion in progress</em>". Pada saat keadaan "<em>deletion in progress</em>", kondisi-kondisi berikut bernilai benar:</p><ul><li>Objek masih terlihat via REST API</li><li><code>deletionTimestamp</code> objek telah ditentukan</li><li><code>metadata.finalizers</code> objek memiliki nilai <code>foregroundDeletion</code>.</li></ul><p>Ketika dalam keadaan "<em>deletion in progress</em>", <em>garbage collector</em> menghapus dependen dari objek. Ketika <em>garbage collector</em> telah menghapus semua "<em>blocking</em>" dependen (objek dengan <code>ownerReference.blockOwnerDeleteion=true</code>), <em>garbage collector</em> menghapus objek pemilik.</p><p>Jika kolom <code>ownerReferences</code> sebuah objek ditentukan oleh sebuah <em>controller</em> (seperti Deployment atau Replicaset), <code>blockOwnerDeletion</code> akan ditentukan secara otomatis dan kamu tidak perlu memodifikasi kolom ini secara manual.</p><h3 id=background-cascading-deletion>Background cascading deletion</h3><p>Pada <em>background cascading deletion</em>, Kubernetes segera menghapus objek pemilik dan <em>garbage collector</em> kemudian menghapus dependen pada <em>background</em>.</p><h3 id=mengatur-kebijakan-cascading-deletion>Mengatur kebijakan <em>cascading deletion</em></h3><p>Untuk mengatur kebijakan <em>cascading deletion</em>, tambahkan kolom <code>propagationPolicy</code> pada argumen <code>deleteOptions</code> ketika menghapus sebuah Object. Nilai yang dapat digunakan adalah "Orphan", "Foreground", atau "Background".</p><p>Sebelum Kubernetes 1.9, kebijakan <em>default</em> dari <em>garbage collection</em> untuk banyak <em>resource controller</em> adalah <strong>orphan</strong>. Ini meliputi ReplicationController, ReplicaSet, StatefulSet, DaemonSet, dan Deployment. Untuk jenis pada kelompok versi <code>extensions/v1beta1</code>, <code>apps/v1beta1</code>, dan <code>apps/v1beta2</code>, kecuali kamu menspesifikasikan dengan cara lain, objek dependen adalah <em>orphan</em> secara <em>default</em>. Pada Kubernetes 1.9, untuk semua jenis pada kelompok versi <code>apps/v1</code>, objek dependen dihapus secara <em>default</em>.</p><p>Berikut sebuah contoh yang menghapus dependen di <em>background</em>:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl proxy --port<span style=color:#666>=</span><span style=color:#666>8080</span>
</span></span><span style=display:flex><span>curl -X DELETE localhost:8080/apis/apps/v1/namespaces/default/replicasets/my-repset <span style=color:#b62;font-weight:700>\
</span></span></span><span style=display:flex><span><span style=color:#b62;font-weight:700></span>-d <span style=color:#b44>&#39;{&#34;kind&#34;:&#34;DeleteOptions&#34;,&#34;apiVersion&#34;:&#34;v1&#34;,&#34;propagationPolicy&#34;:&#34;Background&#34;}&#39;</span> <span style=color:#b62;font-weight:700>\
</span></span></span><span style=display:flex><span><span style=color:#b62;font-weight:700></span>-H <span style=color:#b44>&#34;Content-Type: application/json&#34;</span>
</span></span></code></pre></div><p>Berikut adalah sebuah contoh yang mengapus dependen di <em>foreground</em>:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl proxy --port<span style=color:#666>=</span><span style=color:#666>8080</span>
</span></span><span style=display:flex><span>curl -X DELETE localhost:8080/apis/apps/v1/namespaces/default/replicasets/my-repset <span style=color:#b62;font-weight:700>\
</span></span></span><span style=display:flex><span><span style=color:#b62;font-weight:700></span>-d <span style=color:#b44>&#39;{&#34;kind&#34;:&#34;DeleteOptions&#34;,&#34;apiVersion&#34;:&#34;v1&#34;,&#34;propagationPolicy&#34;:&#34;Foreground&#34;}&#39;</span> <span style=color:#b62;font-weight:700>\
</span></span></span><span style=display:flex><span><span style=color:#b62;font-weight:700></span>-H <span style=color:#b44>&#34;Content-Type: application/json&#34;</span>
</span></span></code></pre></div><p>Berikut adalah contoh <em>orphan</em> yang dependen:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl proxy --port<span style=color:#666>=</span><span style=color:#666>8080</span>
</span></span><span style=display:flex><span>curl -X DELETE localhost:8080/apis/apps/v1/namespaces/default/replicasets/my-repset <span style=color:#b62;font-weight:700>\
</span></span></span><span style=display:flex><span><span style=color:#b62;font-weight:700></span>-d <span style=color:#b44>&#39;{&#34;kind&#34;:&#34;DeleteOptions&#34;,&#34;apiVersion&#34;:&#34;v1&#34;,&#34;propagationPolicy&#34;:&#34;Orphan&#34;}&#39;</span> <span style=color:#b62;font-weight:700>\
</span></span></span><span style=display:flex><span><span style=color:#b62;font-weight:700></span>-H <span style=color:#b44>&#34;Content-Type: application/json&#34;</span>
</span></span></code></pre></div><p>kubectl juga mendukung <em>cascading deletion</em>. Untuk menghapus dependen secara otomatis dengan menggunakan kubectl, Ubah nilai <code>--cascade</code> menjadi <em>true</em>. Untuk <em>orphan</em> yang dependen, ubah nilai <code>--cascade</code> menjadi <em>false</em>. Nilai <em>default</em> untuk <code>--cascade</code> adalah <em>true</em>.</p><p>Berikut adalah contoh yang membuat dependen ReplicaSet menjadi <em>orphan</em>:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl delete replicaset my-repset --cascade<span style=color:#666>=</span><span style=color:#a2f>false</span>
</span></span></code></pre></div><h3 id=catatan-tambahan-untuk-deployment>Catatan tambahan untuk Deployment</h3><p>Sebelum versi 1.7, ketika menggunakan <em>cascading delete</em> dengan Deployment, kamu <em>harus</em> menggunakan <code>propagationPolicy: Foreground</code> untuk menghapus tidak hanya ReplicaSet yang telah diciptakan, tetapi juga Pod yang mereka miliki. Jika tipe <em>propagationPolicy</em> tidak digunakan, hanya ReplicaSet yag akan dihapus, dan Pod akan menjadi <em>orphan</em>. Lihat <a href=https://github.com/kubernetes/kubeadm/issues/149#issuecomment-284766613>kubeadm/#149</a> untuk informasi lebih lanjut.</p><h2 id=isu-yang-diketahui>Isu yang diketahui</h2><p>Ditemukan pada <a href=https://github.com/kubernetes/kubernetes/issues/26120>#26120</a></p><h2 id=selanjutnya>Selanjutnya</h2><p><a href=https://git.k8s.io/community/contributors/design-proposals/api-machinery/garbage-collection.md>Dokumen Desain 1</a></p><p><a href=https://git.k8s.io/community/contributors/design-proposals/api-machinery/synchronous-garbage-collection.md>Dokumen Desain 2</a></p></div><div class=td-content style=page-break-before:always><h1 id=pg-4de50a37ebb6f2340484192126cb7a04>4.2.7 - Pengendali TTL untuk Sumber Daya yang Telah Selesai Digunakan</h1><div style=margin-top:10px;margin-bottom:10px><b>FEATURE STATE:</b> <code>Kubernetes v1.12 [alpha]</code></div><p>Pengendali TTL menyediakan mekanisme TTL yang membatasi umur dari suatu
objek sumber daya yang telah selesai digunakan. Pengendali TTL untuk saat ini hanya menangani
<a class=glossary-tooltip title='Tugas terbatas atau bertumpuk (batch) yang berjalan sampai selesai.' data-toggle=tooltip data-placement=top href=/docs/concepts/workloads/controllers/job/ target=_blank aria-label=Jobs>Jobs</a>,
dan nantinya bisa saja digunakan untuk sumber daya lain yang telah selesai digunakan
misalnya saja Pod atau sumber daya khusus (<em>custom resource</em>) lainnya.</p><p>Peringatan Fitur Alpha: fitur ini tergolong datam fitur alpha dan dapat diaktifkan dengan
<a href=/docs/reference/command-line-tools-reference/feature-gates/><em>feature gate</em></a>
<code>TTLAfterFinished</code>.</p><h2 id=pengendali-ttl>Pengendali TTL</h2><p>Pengendali TTL untuk saat ini hanya mendukung Job. Sebuah operator klaster
dapat menggunakan fitur ini untuk membersihkan Job yang telah dieksekusi (baik
<code>Complete</code> atau <code>Failed</code>) secara otomatis dengan menentukan <em>field</em>
<code>.spec.ttlSecondsAfterFinished</code> pada Job, seperti yang tertera di
<a href=/id/docs/concepts/workloads/controllers/job/#clean-up-finished-jobs-automatically>contoh</a>.
Pengendali TTL akan berasumsi bahwa sebuah sumber daya dapat dihapus apabila
TTL dari sumber daya tersebut telah habis. Proses dihapusnya sumber daya ini
dilakukan secara berantai, dimana sumber daya lain yang
berkaitan akan ikut terhapus. Perhatikan bahwa ketika sebuah sumber daya dihapus,
siklus hidup yang ada akan menjaga bahwa <em>finalizer</em> akan tetap dijalankan sebagaimana mestinya.</p><p>Waktu TTL dalam detik dapat diatur kapan pun. Terdapat beberapa contoh untuk mengaktifkan <em>field</em>
<code>.spec.ttlSecondsAfterFinished</code> pada suatu Job:</p><ul><li>Spesifikasikan <em>field</em> ini pada <em>manifest</em> sumber daya, sehingga Job akan
dihapus secara otomatis beberapa saat setelah selesai dieksekusi.</li><li>Aktifkan <em>field</em> ini pada sumber daya yang sudah selesai dieksekusi untuk
menerapkan fitur ini.</li><li>Gunakan sebuah
<a href=/docs/reference/access-authn-authz/extensible-admission-controllers/#admission-webhooks>mengubah (<em>mutating</em>) _admission)</a>
untuk mengaktifkan <em>field</em> ini secara dinamis pada saat pembuatan sumber daya.
Administrator klaster dapat menggunakan hal ini untuk menjamin kebijakan (<em>policy</em>) TTL pada
sumber daya yang telah selesai digunakan.</li><li>Gunakan sebuah
<a href=/docs/reference/access-authn-authz/extensible-admission-controllers/#admission-webhooks>mengubah (<em>mutating</em>) _admission</a>
untuk mengaktifkan <em>field</em> ini secara dinamis setelah sumber daya
selesai digunakan dan TTL didefinisikan sesuai dengan status, label, atau hal lain
yang diinginkan.</li></ul><h2 id=peringatan>Peringatan</h2><h3 id=mengubah-ttl-detik>Mengubah TTL Detik</h3><p>Perhatikan bahwa periode TTL, yaitu <em>field</em> <code>.spec.ttlSecondsAfterFinished</code> pada Job,
dapat dimodifikasi baik setelah sumber daya dibuat atau setelah selesai digunakan.
Meskipun begitu, setelah Job dapat dihapus (TTL sudah habis), sistem tidak akan
menjamin Job tersebut akan tetap ada, meskipun nilai TTL berhasil diubah.</p><h3 id=time-skew><em>Time Skew</em></h3><p>Karena pengendali TTL menggunakan cap waktu (<em>timestamp</em>) yang disimpan di sumber daya
Kubernetes untuk menentukan apakah TTL sudah habis atau belum, fitur ini tidak sensitif
terhadap <em>time skew</em> yang ada pada klaster dan bisa saja menghapus objek pada waktu yang salah
bagi objek tersebut akibat adanya <em>time skew</em>.</p><p>Pada Kubernetes, NTP haruslah dilakukan pada semua node untuk mecegah adanya <em>time skew</em>
(lihat <a href=https://github.com/kubernetes/kubernetes/issues/6159#issuecomment-93844058>#6159</a>).
<em>Clock</em> tidak akan selalu tepat, meskipun begitu perbedaan yang ada haruslah diminimalisasi.
Perhatikan bahwa hal ini dapat terjadi apabila TTL diaktifkan dengan nilai selain 0.</p><h2 id=selanjutnya>Selanjutnya</h2><p><a href=/id/docs/concepts/workloads/controllers/jobs-run-to-completion/#clean-up-finished-jobs-automatically>Membersikan Job secara Otomatis</a></p><p><a href=https://github.com/kubernetes/enhancements/blob/master/keps/sig-apps/592-ttl-after-finish/README.md>Dokumentasi Rancangan</a></p></div><div class=td-content style=page-break-before:always><h1 id=pg-cc7cc3c4907039d9f863162e20bfbbef>4.2.8 - Jobs</h1><p>Sebuah Job membuat satu atau beberapa Pod dan menjamin bahwa jumlah Pod yang telah dispesifikasikan sebelumnya
berhasil dijalankan. Pada saat Pod telah dihentikan, Job akan menandainya sebagai Job yang sudah berhasil dijalankan.
Ketika jumlah sukses yang dispesifikasikan sebelumnya sudah terpenuhi, maka Job tersebut dianggap selesai.
Menghapus sebuah Job akan menghapus semua Pod yang dibuat oleh Job tersebut.</p><p>Sebuah kasus sederhana yang dapat diberikan adalah membuat sebuah objek Job untuk menjamin
sebuah Pod dijalankan hingga selesai. Objek Job ini akan membuat sebuah Pod baru apabila
Pod pertama gagal atau dihapus (salah satu contohnya adalah akibat adanya kegagalan pada
perangkat keras atau terjadinya <em>reboot</em> pada Node).</p><p>Kamu juga dapat menggunakan Job untuk menjalankan beberapa Pod secara paralel.</p><h2 id=menjalankan-contoh-job>Menjalankan Contoh Job</h2><p>Berikut merupakan contoh konfigurasi Job. Job ini melakukan komputasi π hingga
digit ke 2000 kemudian memberikan hasilnya sebagai keluaran. Job tersebut memerlukan
waktu 10 detik untuk dapat diselesaikan.</p><div class=highlight><div class=copy-code-icon style=text-align:right><a href=https://raw.githubusercontent.com/kubernetes/website/main/content/id/examples/controllers/job.yaml download=controllers/job.yaml><code>controllers/job.yaml</code></a>
<img src=/images/copycode.svg style=max-height:24px;cursor:pointer onclick='copyCode("controllers-job-yaml")' title="Copy controllers/job.yaml to clipboard"></img></div><div class=includecode id=controllers-job-yaml><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>batch/v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Job<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>pi<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>template</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>pi<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>perl<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>command</span>:<span style=color:#bbb> </span>[<span style=color:#b44>&#34;perl&#34;</span>,<span style=color:#bbb>  </span><span style=color:#b44>&#34;-Mbignum=bpi&#34;</span>,<span style=color:#bbb> </span><span style=color:#b44>&#34;-wle&#34;</span>,<span style=color:#bbb> </span><span style=color:#b44>&#34;print bpi(2000)&#34;</span>]<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>restartPolicy</span>:<span style=color:#bbb> </span>Never<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>backoffLimit</span>:<span style=color:#bbb> </span><span style=color:#666>4</span><span style=color:#bbb>
</span></span></span></code></pre></div></div></div><p>Kamu dapat menjalankan contoh tersebut dengan menjalankan perintah berikut:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl apply -f https://k8s.io/examples/controllers/job.yaml
</span></span></code></pre></div><pre tabindex=0><code>job &#34;pi&#34; created
</code></pre><p>Perhatikan status dari Job yang baru dibuat dengan menggunakan perintah<code>kubectl</code>:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl describe jobs/pi
</span></span></code></pre></div><pre tabindex=0><code>Name:             pi
Namespace:        default
Selector:         controller-uid=b1db589a-2c8d-11e6-b324-0209dc45a495
Labels:           controller-uid=b1db589a-2c8d-11e6-b324-0209dc45a495
                  job-name=pi
Annotations:      &lt;none&gt;
Parallelism:      1
Completions:      1
Start Time:       Tue, 07 Jun 2016 10:56:16 +0200
Pods Statuses:    0 Running / 1 Succeeded / 0 Failed
Pod Template:
  Labels:       controller-uid=b1db589a-2c8d-11e6-b324-0209dc45a495
                job-name=pi
  Containers:
   pi:
    Image:      perl
    Port:
    Command:
      perl
      -Mbignum=bpi
      -wle
      print bpi(2000)
    Environment:        &lt;none&gt;
    Mounts:             &lt;none&gt;
  Volumes:              &lt;none&gt;
Events:
  FirstSeen    LastSeen    Count    From            SubobjectPath    Type        Reason            Message
  ---------    --------    -----    ----            -------------    --------    ------            -------
  1m           1m          1        {job-controller }                Normal      SuccessfulCreate  Created pod: pi-dtn4q
</code></pre><p>Untuk melihat Pod yang sudah selesai dari sebuah Job, kamu dapat menggunakan perintah <code>kubectl get pods</code>.</p><p>Untuk menampilkan semua Pod yang merupakan bagian dari suatu Job di mesin kamu dalam bentuk
yang mudah dipahami, kamu dapat menggunakan perintah berikut ini:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span><span style=color:#b8860b>pods</span><span style=color:#666>=</span><span style=color:#a2f;font-weight:700>$(</span>kubectl get pods --selector<span style=color:#666>=</span>job-name<span style=color:#666>=</span>pi --output<span style=color:#666>=</span><span style=color:#b8860b>jsonpath</span><span style=color:#666>=</span><span style=color:#b44>&#39;{.items[*].metadata.name}&#39;</span><span style=color:#a2f;font-weight:700>)</span>
</span></span><span style=display:flex><span><span style=color:#a2f>echo</span> <span style=color:#b8860b>$pods</span>
</span></span></code></pre></div><pre tabindex=0><code>pi-aiw0a
</code></pre><p>Disini, selektor yang ada merupakan selektor yang sama dengan yang ada pada Job.
Opsi <code>--output=jsonpath</code> menspesifikasikan bahwa ekspresi yang hanya
menampilkan nama dari setiap Pod pada <em>list</em> yang dikembalikan.</p><p>Untuk melihat keluaran standar dari salah satu pod:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl logs <span style=color:#b8860b>$pods</span>
</span></span></code></pre></div><p>Keluaran yang dihasilkan akan sama dengan:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>3.1415926535897932384626433832795028841971693993751058209749445923078164062862089986280348253421170679821480865132823066470938446095505822317253594081284811174502841027019385211055596446229489549303819644288109756659334461284756482337867831652712019091456485669234603486104543266482133936072602491412737245870066063155881748815209209628292540917153643678925903600113305305488204665213841469519415116094330572703657595919530921861173819326117931051185480744623799627495673518857527248912279381830119491298336733624406566430860213949463952247371907021798609437027705392171762931767523846748184676694051320005681271452635608277857713427577896091736371787214684409012249534301465495853710507922796892589235420199561121290219608640344181598136297747713099605187072113499999983729780499510597317328160963185950244594553469083026425223082533446850352619311881710100031378387528865875332083814206171776691473035982534904287554687311595628638823537875937519577818577805321712268066130019278766111959092164201989380952572010654858632788659361533818279682303019520353018529689957736225994138912497217752834791315155748572424541506959508295331168617278558890750983817546374649393192550604009277016711390098488240128583616035637076601047101819429555961989467678374494482553797747268471040475346462080466842590694912933136770289891521047521620569660240580381501935112533824300355876402474964732639141992726042699227967823547816360093417216412199245863150302861829745557067498385054945885869269956909272107975093029553211653449872027559602364806654991198818347977535663698074265425278625518184175746728909777727938000816470600161452491921732172147723501414419735685481613611573525521334757418494684385233239073941433345477624168625189835694855620992192221842725502542568876717904946016534668049886272327917860857843838279679766814541009538837863609506800642251252051173929848960841284886269456042419652850222106611863067442786220391949450471237137869609563643719172874677646575739624138908658326459958133904780275901
</span></span></code></pre></div><h2 id=menulis-spek-job>Menulis Spek Job</h2><p>Sama halnya dengan konfigurasi Kubernetes lainnya, sebuah Job memerlukan <em>field</em>
<code>apiVersion</code>, <code>kind</code>, dan <code>metadata</code>.</p><p>Sebuah Job juga membutuhkan sebuah <a href=https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#spec-and-status>bagian <code>.spec</code></a>.</p><h3 id=templat-pod>Templat Pod</h3><p><em>Field</em> <code>.spec.template</code> merupakan satu-satunya <em>field</em> wajib pada <code>.spec</code>.</p><p><em>Field</em> <code>.spec.template</code> merupakan sebuah <a href=/id/docs/concepts/workloads/pods/pod-overview/#pod-templates>templat Pod</a>. <em>Field</em> ini memiliki skema yang sama dengan yang ada pada <a href=/docs/user-guide/pods>Pod</a>,
kecuali <em>field</em> ini bersifat <em>nested</em> dan tidak memiliki <em>field</em> <code>apiVersion</code> atau <em>field</em> <code>kind</code>.</p><p>Sebagai tambahan dari <em>field</em> wajib pada sebuah Job, sebuah tempat pod pada Job
haruslah menspesifikasikan label yang sesuai (perhatikan <a href=#pod-selektor>selektor pod</a>)
dan sebuah mekanisme <em>restart</em> yang sesuai.</p><p>Hanya sebuah <a href=/id/docs/concepts/workloads/pods/pod-lifecycle/#restart-policy><code>RestartPolicy</code></a> yang sesuai dengan <code>Never</code> atau <code>OnFailure</code> yang bersifat valid.</p><h3 id=selektor-pod>Selektor Pod</h3><p><em>Field</em> <code>.spec.selector</code> bersifat opsional. Dan dalam sebagian besar kasus, kamu tidak perlu memberikan
spesifikasi untuk hal ini. Perhatikan bagian <a href=#menspesifikasikan-selektor-pod-kamu-sendiri>menspesifikasikan selektor Pod kamu sendiri</a>.</p><h3 id=job-paralel>Job Paralel</h3><p>Terdapat tiga jenis utama dari <em>task</em> yang sesuai untuk dijalankan sebagai sebuah Job:</p><ol><li>Job non-paralel</li></ol><ul><li>secara umum, hanya sebuah Pod yang dimulai, kecuali jika Pod tersebut gagal.</li><li>Job akan dianggap sudah selesai dikerjakan apabila Pod dari Job tersebut sudah selesai dijalankan dan mengalami terminasi dengan status sukses.</li></ul><ol><li>Job paralel dengan <em>jumlah nilai penyelesaian tetap</em>:</li></ol><ul><li>berikan spesifikasi pada <code>.spec.completions</code> dengan nilai non-negatif.</li><li>Job yang ada merupakan representasi dari <em>task</em> yang dikerjakan, dan akan dianggap selesai apabila terdapat lebih dari satu Pod yang sukses untuk setiap nilai yang ada dalam jangkauan 1 hingga <code>.spec.completions</code>.</li><li><strong>belum diimplementasikan saat ini:</strong> Setiap Pod diberikan nilai indeks yang berbeda di dalam jangkauan 1 hingga <code>.spec.completions</code>.</li></ul><ol><li>Job paralel dengan sebuah <em><em>work queue</em></em>:</li></ol><ul><li>jangan berikan spesifikasi pada <code>.spec.completions</code>, nilai <em>default</em>-nya merupakan <code>.spec.parallelism</code>.</li><li>Pod yang ada haruslah dapat berkoordinasi satu sama lain atau dengan Service eksternal lain untuk menentukan apa yang setiap Pod tadi perlu lakukan. Sebagai contohnya, sebuah Pod bisa saja melakukan <em>fetch</em> job <em>batch</em> hingga N kali pada <em>work queue</em></li><li>setiap Pod secara independen mampu menentukan apakah Pod lainnya telah menyelesaikan tugasnya dengan baik atau belum, dengan kata lain suatu Job telah dikatakan selesai</li><li>ketika Pod mana pun dari sebuah Job berhenti dalam keadaan sukses, maka tidak ada Pod lain yang akan dibuat untuk Job tersebut.</li><li>apabila salah satu Pod sudah dihentikan sekali dalam keadaan sukses, maka Job akan ditandai sebagai sukses.</li><li>apabila sebuah Pod sudah dihentikan dalam keadaan sukses, tidak boleh ada Pod lain yang mengerjakan <em>task</em> tersebut. Dengan kata lain, semua Pod tersebut haruslah dalam keadaan akan dihentikan.</li></ul><p>Untuk sebuah Job yang non-paralel, kamu tidak perlu menspesifikasikan <em>field</em> <code>.spec.completions</code> dan <code>.spec.parallelism</code>. Ketika kedua <em>field</em> tersebut
dalam keadaan tidak dispesifikasikan, maka nilai <em>defult</em>-nya akan diubah menjadi 1.</p><p>Untuk sebuah Job dengan jumlah nilai penyelesaian tetap, kamu harus memberikan spesifikasi nilai
dari <code>.spec.completions</code> dengan nilai yang diinginkan. Kamu dapat menspesifikasikan <code>.spec.parallelism</code>,
atau jika kamu tidak melakukannya nilai dari <em>field</em> ini akan memiliki nilai default 1.</p><p>Untuk sebuah Job <em>work queue</em>, kamu harus meninggalkan spesifikasi <em>field</em> <code>.spec.completions</code> menjadi kosong, serta
memberikan nilai pada <code>.spec.parallelism</code> menjadi sebuah bilangan bulat non negatif.</p><p>Untuk informasi lebih lanjut mengenai bagaimana menggunakan Job dengan jenis yang berbeda, kamu
dapat melihat bagian <a href=#pola-job>pola job</a>.</p><h4 id=mengendalikan-paralelisme>Mengendalikan Paralelisme</h4><p>Paralelisme yang diminta (<code>.spec.parallelism</code>) dapat diaktifkan dengan cara
memberikan nilai bilangan bulat non-negatif. Jika tidak dispesifikasikan maka nilainya akan
secara default yaitu 1. Jika dispesifikasikan sebagai 0, maka Job akan secara otomatis dihentikan sementara
hingga nilainya dinaikkan.</p><p>Paralelisme yang sebenarnya (jumlah Pod yang dijalankan pada satu waktu tertentu)
bisa saja lebih atau kurang dari nilai yang diharapkan karena adanya alasan berikut:</p><ul><li>Untuk Job <em>fixed completion count</em>, nilai sebenarnya dari jumlah Pod yang dijalankan secara paralel tidak akan melebihi jumlah<br><em>completion</em> yang tersisa. Nilai yang lebih tinggi dari <code>.spec.parallelism</code> secara efektif, akan diabaikan.</li><li>Untuk Job <em>work queue</em>, tidak akan ada Pod yang dimulai setelah ada Pod yang berhasil -- meskipun begitu, sisa Pod yang ada akan diizinkan untuk menyelesaikan tugasnya.</li><li>Jika sebuah <a class=glossary-tooltip title='Kontrol tertutup yang mengawasi kondisi bersama dari klaster melalui apiserver dan membuat perubahan yang mencoba untuk membawa kondisi saat ini ke kondisi yang diinginkan.' data-toggle=tooltip data-placement=top href=/id/docs/concepts/architecture/controller/ target=_blank aria-label=Pengontrol>Pengontrol</a> Job tidak memiliki waktu untuk memberikan reaksi.</li><li>Jika sebuah <em>controller</em> Job gagal membuat Pod dengan alasan apa pun (kurangnya <code>ResourceQuota</code>, kurangnya <em>permission</em>, dkk.),
maka bisa saja terdapat lebih sedikit Pod dari yang diminta.</li><li>Jika <em>controller</em> Job melakukan <em>throttle</em> pembuatan Pod karena terdapat gagalnya pembuatan Pod yang berlebihan sebelumnya pada Job yang sama.</li><li>Ketika sebuah Pod dihentikan secara <em>graceful</em>, maka Pod tersebut akan membutuhkan waktu untuk berhenti.</li></ul><h2 id=mengatasi-kegagalan-pod-dan-container>Mengatasi Kegagalan Pod dan Container</h2><p>Sebuah Container pada sebuah Pod bisa saja mengalami kegagalan karena berbagai alasan
yang berbeda, misalnya saja karena proses yang ada di dalamnya berakhir dengan <em>exit code</em>
yang tidak sama dengan nol, atau Container yang ada di-<em>kill</em> karena menyalahi batasan memori, dkk.
Jika hal ini terjadi, dan <code>.spec.template.spec.restartPolicy = "OnFailure"</code>, maka Pod
akan tetap ada di dalam node, tetapi Container tersebut akan dijalankan kembali. Dengan demikian,
program kamu harus dapat mengatasi kasus dimana program tersebut di-<em>restart</em> secara lokal, atau jika
tidak maka spesifikasikan <code>.spec.template.spec.restartPolicy = "Never"</code>. Perhatikan
<a href=/id/docs/concepts/workloads/pods/pod-lifecycle/#example-states><em>lifecycle</em> pod</a> untuk informasi lebih lanjut mengenai <code>restartPolicy</code>.</p><p>Sebuah Pod juga dapat gagal secara menyeluruh, untuk beberapa alasan yang mungkin, misalnya saja,
ketika Pod tersebut dipindahkan dari Node (ketika Node diperbarui, di-<em>restart</em>, dihapus, dsb.), atau
jika sebuah Container dalam Pod gagal dan <code>.spec.template.spec.restartPolicy = "Never"</code>. Ketika
sebuah Pod gagal, maka <em>controller</em> Job akan membuat sebuah Pod baru. Ini berarti aplikasi kamu haruslah
bisa mengatasi kasus dimana aplikasimu dimulai pada Pod yang baru. Secara khusus apabila aplikasi kamu
berurusan dengan berkas temporer, <em>locks</em>, keluaran yang tak lengkap dan hal-hal terkait dengan
program yang dijalankan sebelumnya.</p><p>Perhatikan bahwa bahakan apabila kamu menspesifikasikan <code>.spec.parallelism = 1</code> dan <code>.spec.completions = 1</code> dan
<code>.spec.template.spec.restartPolicy = "Never"</code>, program yang sama bisa saja tetap dijalankan lebih dari sekali.</p><p>Jika kamu menspesifikasikan <code>.spec.parallelism</code> dan <code>.spec.completions</code> dengan nilai yang lebih besar dari 1,
maka bisa saja terdapat keadaan dimana terdapat beberapa Pod yang dijalankan pada waktu yang sama.
Dengan demikian, Pod kamu haruslah fleksibel terhadap adanya konkurensi.</p><h3 id=mekanisme-kebijakan-backoff-apabila-terjadi-kegagalan>Mekanisme Kebijakan <em>Backoff</em> apabila Terjadi Kegagalan</h3><p>Terdapat situasi dimana kamu ingin membuat suatu Job gagal
setelah dijalankan mekanisme <em>retry</em> beberapa kali akibat adanya kesalahan pada konfigurasi
dsb. Untuk melakukan hal tersebut, spesifikasikan <code>.spec.backoffLimit</code> dengan nilai <em>retry</em> yang diinginkan
sebelum menerjemahkan Job dalam keadaan gagal. Secara default, nilai dari <em>field</em> tersebut adalah 6.
Pod yang gagal dijalankan dan terkait dengan suatu Job tertentu akan dibuat kembali oleh
<em>controller</em> Job dengan <em>delay</em> <em>back-off</em> eksponensial (10 detik, 20 detik, 40 detik ...)
yang dibatasi pada 6 menit. Penghitungan <em>back-off</em> akan diulang jika tidak terdapat Pod baru yang gagal
sebelum siklus pengecekan status Job selanjutnya.</p><p><div class="alert alert-info note callout" role=alert><strong>Catatan:</strong> Isu <a href=https://github.com/kubernetes/kubernetes/issues/54870>#54870</a> masih ada untuk versi Kubernetes sebelum 1.12.</div><div class="alert alert-info note callout" role=alert><strong>Catatan:</strong> Jika Job yang kamu miliki memiliki <code>restartPolicy = "OnFailure"</code>, perhatikan bahwa Container kamu yang menjalankan
Job tersebut akan dihentikan ketika limit <em>back-off</em> telah dicapai. Hal ini akan membuat proses <em>debugging</em> semakin sulit.
Dengan demikian, kami memberikan saran untuk menspesifikasikan <code>restartPolicy = "Never"</code> ketika melakukan
proses <em>debugging</em> atau menggunakan mekanisme <em>logging</em> untuk menjamin keluaran
dari Job yang gagal agar tidak terus menerus hilang.</div></p><h2 id=terminasi-dan-clean-up-job>Terminasi dan <em>Clean Up</em> Job</h2><p>Ketika sebuah Job selesai dijalankan, tidak akan ada lagi Pod yang dibuat,
meskipun begitu Pod yang ada juga tidak akan dihapus. Dengan demikian kamu masih bisa mengakses log
yang ada dari Pod yang sudah dalam status <em>complete</em> untuk mengecek apabila terjadi eror, <em>warning</em>, atau hal-hal
yang dapat digunakan untuk proses pelaporan dan identifikasi. Objek Job itu sendiri akan tetap ada,
sehingga kamu tetap bisa melihat statusnya. Penghapusan objek akan diserahkan sepenuhnya pada pengguna
apabila Job tidak lagi digunakan. Penghapusan Job dengan perintah <code>kubectl</code> (misalnya, <code>kubectl delete jobs/pi</code> atau <code>kubectl delete -f ./job.yaml</code>).
Ketika kamu menghapus Job menggunakan perintah <code>kubectl</code>, semua Pod yang terkait dengan Job tersebut akan ikut dihapus.</p><p>Secara <em>default</em>, sebuah Job akan dijalankan tanpa adanya interupsi kecuali terdapat Pod yang gagal, (<code>restartPolicy=Never</code>) atau terdapat
Container yang dihentikan dalam kondisi error (<code>restartPolicy=OnFailure</code>), suatu keadaan dimana Job akan dijalankan dengan mekanisme
yang dijelaskan di atas berdasarkan pada <code>.spec.backoffLimit</code>.
Apabila <code>.spec.backoffLimit</code> telah mencapai limit, maka Job akan ditandai sebagai gagal dan Pod yang saat ini sedang dijalankan juga akan dihentikan.</p><p>Cara lain untuk menghentikan sebuah Job adalah dengan mengatur <em>deadline</em> aktif.
Untuk melakukannya kamu dapat menspesifikasikan <em>field</em> <code>.spec.activeDeadlineSeconds</code>
dari sebuah Job dengan suatu angka dalam satuan detik. <em>Field</em> <code>activeDeadlineSeconds</code>
diterapkan pada durasi dari sebuah Job, tidak peduli seberapa banyak Pod yang dibuat.
Setelah sebuah Job mencapai limit <code>activeDeadlineSeconds</code>, semua Pod yang dijalankan akan dihentikan
dan status dari Job tersebut akan berubah menjadi <code>type: Failed</code> dengan <code>reason: DeadlineExceeded</code>.</p><p>Perhatikan bahwa <em>field</em> <code>.spec.activeDeadlineSeconds</code> pada Job memiliki tingkat
presedensi di atas <code>.spec.backoffLimit</code>. Dengan demikian, sebuah Job
yang sedang mencoba melakukan <em>restart</em> pada suatu Pod-nya tidak akan melakukan
pembuatan Pod yang baru apabila Job tersebut telah mencapai limit yang didefinisikan pada
<code>activeDeadlineSeconds</code>, bahkan apabila nilai dari <code>backoffLimit</code> belum tercapai.</p><p>Contoh:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>batch/v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Job<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>pi-with-timeout<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>backoffLimit</span>:<span style=color:#bbb> </span><span style=color:#666>5</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>activeDeadlineSeconds</span>:<span style=color:#bbb> </span><span style=color:#666>100</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>template</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>Containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>pi<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>perl<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>command</span>:<span style=color:#bbb> </span>[<span style=color:#b44>&#34;perl&#34;</span>,<span style=color:#bbb>  </span><span style=color:#b44>&#34;-Mbignum=bpi&#34;</span>,<span style=color:#bbb> </span><span style=color:#b44>&#34;-wle&#34;</span>,<span style=color:#bbb> </span><span style=color:#b44>&#34;print bpi(2000)&#34;</span>]<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>restartPolicy</span>:<span style=color:#bbb> </span>Never<span style=color:#bbb>
</span></span></span></code></pre></div><p>Perhatikan bahwa baik spek Job dan <a href=/docs/concepts/workloads/pods/init-Containers/#detailed-behavior>spek templat Pod</a> di dalam Job memiliki <em>field</em> <code>activeDeadlineSeconds</code>.
Pastikan kamu telah menspesifikasikan nilai tersebut pada level yang dibutuhkan.</p><h2 id=mekanisme-clean-up-otomatis-pada-job-yang-sudah-selesai>Mekanisme <em>Clean Up</em> Otomatis pada Job yang Sudah Selesai</h2><p>Job yang sudah selesai biasanya tidak lagi dibutuhkan di dalam sistem. Tetap menjaga keberadaan
objek-objek tersebut di dalam sistem akan memberikan tekanan tambahan pada API server. Jika sebuah Job
yang diatur secara langsung oleh <em>controller</em> dengan level yang lebih tinggi, seperti
<a href=/id/docs/concepts/workloads/controllers/cron-jobs/>CronJob</a>, maka Job ini dapat
di-<em>clean up</em> oleh CronJob berdasarkan <em>policy</em> berbasis kapasitas yang dispesifikasikan.</p><h3 id=mekanisme-ttl-untuk-job-yang-telah-selesai-dijalankan>Mekanisme TTL untuk Job yang Telah Selesai Dijalankan</h3><div style=margin-top:10px;margin-bottom:10px><b>FEATURE STATE:</b> <code>Kubernetes v1.12 [alpha]</code></div><p>Salah satu cara untuk melakukan <em>clean up</em> Job yang telah selesai dijalankan
(baik dengan status <code>Complete</code> atau <code>Failed</code>) secara otomatis adalah dengan
menerapkan mekanisme TTL yang disediakan oleh
<a href=/id/docs/concepts/workloads/controllers/ttlafterfinished/><em>controller</em> TTL</a> untuk
sumber daya yang telah selesai digunakan, dengan cara menspesifikasikan
<em>field</em> <code>.spec.ttlSecondsAfterFinished</code> dari Job tersebut.</p><p>Ketika <em>controller</em> TTL melakukan proses <em>clean up</em> pada Job,
maka <em>controller</em> tersebut akan menghapus objek-objek terkait seperti Pod, serta Job itu sendiri.
Perhatikan bahwa ketika suatu Job dihapus, maka <em>lifecycle</em>-nya akan menjamin, mekanisme
<em>finalizer</em> yang ada akan tetap dihargai.</p><p>Sebagai contoh:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>batch/v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Job<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>pi-with-ttl<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>ttlSecondsAfterFinished</span>:<span style=color:#bbb> </span><span style=color:#666>100</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>template</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>Containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>pi<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>perl<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>command</span>:<span style=color:#bbb> </span>[<span style=color:#b44>&#34;perl&#34;</span>,<span style=color:#bbb>  </span><span style=color:#b44>&#34;-Mbignum=bpi&#34;</span>,<span style=color:#bbb> </span><span style=color:#b44>&#34;-wle&#34;</span>,<span style=color:#bbb> </span><span style=color:#b44>&#34;print bpi(2000)&#34;</span>]<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>restartPolicy</span>:<span style=color:#bbb> </span>Never<span style=color:#bbb>
</span></span></span></code></pre></div><p>Job <code>pi-with-ttl</code> akan dihapus secara otomatis, dalam jangka waktu <code>100</code>
detik setelah Job tersebut selesai dijalankan.</p><p>Jika <em>field</em> ini dispesifikasikan sebagai <code>0</code>, maka Job akan secara otomatis dihapus
segera setelah Job tersebut selesai dijalankan. Jika <em>field</em> tersebut tidak dispesifikasikan,
maka Job ini tidak akan dihapus oleh <em>controller</em> TTL setelah Job ini selesai dijalankan.</p><p>Perhatikan bahwa mekanisme TTL ini merupakan fitur alpha, dengan gerbang fitur <code>TTLAfterFinished</code>.
Untuk informasi lebih lanjut, kamu dapat membaca dokumentasi untuk
<a href=/id/docs/concepts/workloads/controllers/ttlafterfinished/><em>controller</em> TTL</a> untuk
sumber daya yang telah selesai dijalankan.</p><h2 id=pola-job>Pola Job</h2><p>Sebuah objek Job dapat digunakan untuk mendukung eksekusi paralel yang dapat diandalkan pada Pod.
Objek Job tidak di-desain untuk mendukung proses paralel bersifat <em>closely-communicating</em>,
seperti yang secara umum ditemukan dalam komputasi ilmiah. Meskipun begitu objek ini mendukung
set <em>work item</em> yang independen namun saling terkait satu sama lainnya. Ini termasuk surel yang harus dikirim,
<em>frame</em> yang harus di-<em>render</em>, berkas yang harus di-<em>transcoded</em>, jangkauan <em>key</em> yang ada
di dalam basis data NoSQL, dsb.</p><p>Pada suatu sistem yang kompleks, terdapat beberapa set <em>work item</em> yang berbeda.
Di sini, kami hanya mempertimbangkan <em>work item</em> yang ingin digunakan oleh pengguna
untuk melakukan manajemen secara bersamaan — sebuah <em>batch job</em>.</p><p>Terdapat beberapa perbedaan pola pada komputasi paralel,
setiap pola memiliki kelebihan dan kekurangannya masing-masing. Kekurangan dan kelebihan ini
dijabarkan sebagai berikut:</p><ul><li>Satu objek Job untuk setiap <em>work item</em>, atau sebuah Job untuk semua <em>work item</em>. Pilihan kedua akan lebih baik apabila digunakan untuk jumlah <em>work item</em> yang lebih besar.
Sementara itu, pilihan pertama akan mengakibatkan <em>overhead</em> bagi pengguna dan juga sistem
untuk mengaur jumlah objek Job yang cukup banyak.</li><li>Jumlah Pod yang dibuat sesuai dengan jumlah <em>work item</em> atau setiap Pod dapat memproses beberapa <em>work item</em> sekaligus.
Pilihan pertama secara umum memerlukan modifikasi lebih sedikit untuk kode dan Container yang suda ada. Pilihan kedua
akan lebih baik jika digunakan untuk jumlah <em>work item</em> yang lebih banyak, untuk alasan yang sama dengan poin sebelumnya.</li><li>Beberapa pendekatan menggunakan prinsip <em>work queue</em>. Hal ini membutuhkan sebuah <em>service queue</em> yang dijalankan,
serta modifikasi untuk program atau Container yang sudah ada untuk mengizinkannya menggunakan <em>working queue</em>.
Pendekatan lain akan lebih mudah untuk digunakan bagi aplikasi yang sudah ada.</li></ul><p><em>Tradeoff</em> yang dirangkum di sini, dengan kolom 2 dan 4 berkaitan dengan <em>tradeoff</em> yang dijelaskan di atas.
Nama dari pola yang ada juga terkait dengan contoh dan deskripsi lebih lanjut.</p><table><thead><tr><th>Pola</th><th style=text-align:center>Objek dengan satu Job</th><th style=text-align:center>Pod yang lebih sedikit tadi <em>work items</em>?</th><th style=text-align:center>Penggunaan app tanpa modifikasi?</th><th style=text-align:center>Dapat dijalankan pada Kube versi 1.1?</th></tr></thead><tbody><tr><td><a href=/docs/tasks/job/parallel-processing-expansion/>Perluasan Templat Job</a></td><td style=text-align:center></td><td style=text-align:center></td><td style=text-align:center>✓</td><td style=text-align:center>✓</td></tr><tr><td><a href=/docs/tasks/job/coarse-parallel-processing-work-queue/>Queue dengan Pod untuk setiap <em>Work Item</em></a></td><td style=text-align:center>✓</td><td style=text-align:center></td><td style=text-align:center>sometimes</td><td style=text-align:center>✓</td></tr><tr><td><a href=/docs/tasks/job/fine-parallel-processing-work-queue/>Queue dengan Variabel <em>Pod Count</em></a></td><td style=text-align:center>✓</td><td style=text-align:center>✓</td><td style=text-align:center></td><td style=text-align:center>✓</td></tr><tr><td>Job Single dengan penempatan Kerja Statis</td><td style=text-align:center>✓</td><td style=text-align:center></td><td style=text-align:center>✓</td><td style=text-align:center></td></tr></tbody></table><p>Ketika kamu menspesifikasikan <em>completion</em> dengan <code>.spec.completions</code>, setiap Pod yang dibuat oleh <em>controller</em> Job
memiliki <a href=https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#spec-and-status><code>spec</code></a> yang identik. Artinya
semua Pod untuk sebuah <em>task</em> akan memiliki perintah yang sama serta <em>image</em>, volume, serta variabel <em>environment</em> yang (hampir) sama.
Pola ini merupakan salah satu cara berbeda yang diterapkan untuk mengatur Pod agar dapat bekerja untuk hal yang berbeda-beda.</p><p>Tabel ini menunjukkan pengaturan yang dibutuhkan untuk <code>.spec.parallelism</code> dan <code>.spec.completions</code> bagi setiap pola.
Disini, <code>W</code> merupakan jumlah dari <em>work item</em>.</p><table><thead><tr><th>Pattern</th><th style=text-align:center><code>.spec.completions</code></th><th style=text-align:center><code>.spec.parallelism</code></th></tr></thead><tbody><tr><td><a href=/docs/tasks/job/parallel-processing-expansion/>Job Template Expansion</a></td><td style=text-align:center>1</td><td style=text-align:center>should be 1</td></tr><tr><td><a href=/docs/tasks/job/coarse-parallel-processing-work-queue/>Queue with Pod Per Work Item</a></td><td style=text-align:center>W</td><td style=text-align:center>any</td></tr><tr><td><a href=/docs/tasks/job/fine-parallel-processing-work-queue/>Queue with Variable Pod Count</a></td><td style=text-align:center>1</td><td style=text-align:center>any</td></tr><tr><td>Single Job with Static Work Assignment</td><td style=text-align:center>W</td><td style=text-align:center>any</td></tr></tbody></table><h2 id=penggunaan-tingkat-lanjut>Penggunaan Tingkat Lanjut</h2><h3 id=menspesifikasikan-selektor-pod-kamu-sendiri>Menspesifikasikan Selektor Pod Kamu Sendiri</h3><p>Secara umum, ketika kamu membuat sebuah objek Job, kamu
tidak menspesifikasikan <code>.spec.selector</code>. Sistem akan memberikan nilai
default pada <em>field</em> ini ketika Job dibuat. Sistem akan memilih nilai dari selektor yang ada
dan memastikan nilainya tidak akan beririsan dengan Job lainnya.</p><p>Meskipun demikian, pada beberapa kasus, kamu bisa saja memiliki kebutuhan untuk meng-<em>override</em>
nilai dari selektor ini. Untuk melakukannya, kamu dapat menspesifikasikan <code>.spec.selector</code>
dari Job.</p><p>Berhati-hatilah ketika kamu melakukan proses ini. Jika kamu menspesifikasikan sebuah label
selektor yang tidak unik pada Pod yang ada di dalam Job tersebut, serta sesuai dengan Pod yang tidak
terkait dengan Job tadi, maka Pod dari Job yang tidak terkait dengan Job tadi akna dihapus, atau Job ini
akan menghitung <em>completion</em> dari Pod lain sebagai tolak ukur suksesnya Job tersebut, atau bisa saja salah satu
atau kedua Job tidak dapat membuat Pod baru yang digunakan untuk menyelesaikan Job tersebut.
Jika selektor yang tidak unik dipilih, maka <em>controller</em> lain (misalnya ReplicationController) dan Pod
yang ada di dalamnya bisa saja memiliki perilaku yang tidak dapat diprediksi. Kubernetes tidak akan
mencegah kemungkinan terjadinya hal ini ketika kamu menspesifikasikan nilai <code>.spec.selector</code>.</p><p>Berikut merupakan contoh skenario dimana kamu ingin menggunakan fitur ini.</p><p>Misalnya saja Job dengan nama <code>old</code> sudah dijalankan.
Dan kamu ingin Pod yang sudah dijalankan untuk tetap berada pada state tersebut,
tapi kamu juga ingin Pod selanjutnya yang dibuat untuk menggunakan templat Pod yang berbeda dan agar
Job tersebut memiliki nama yang berbeda. Kamu tidak dapat mengubah Job karena <em>field</em> ini
merupakan nilai yang tidak bisa diubah. Dengan demikian, kamu menghapus Job <code>old</code>
tetapi tetap membiarkan Pod yang ada untuk jalan, menggunakan perintah <code>kubectl delete jobs/old --cascade=false</code>.
Sebelum menghapus Job tadi, kamu mencatat selektor yang digunakan oleh Job tadi:</p><pre tabindex=0><code>kubectl get job old -o yaml
</code></pre><pre tabindex=0><code>kind: Job
metadata:
  name: old
  ...
spec:
  selector:
    matchLabels:
      controller-uid: a8f3d00d-c6d2-11e5-9f87-42010af00002
  ...
</code></pre><p>Kemudian kamu membuat sebuah Job baru dengan nama <code>new</code>
dan kamu secara eksplisit menspesifikasikan selektor yang sama.
Karena Pod dengan selektor yang sama memiliki label <code>controller-uid=a8f3d00d-c6d2-11e5-9f87-42010af00002</code>,
maka Pod-Pod lama tadi dikendalikan juga oleh Job <code>new</code>.</p><p>Kamu harus menspesifikasikan <code>manualSelector: true</code> pada Job yang baru
karena kamu tidak menggunakan selektor yang diberikan secara default oleh sistem.</p><pre tabindex=0><code>kind: Job
metadata:
  name: new
  ...
spec:
  manualSelector: true
  selector:
    matchLabels:
      controller-uid: a8f3d00d-c6d2-11e5-9f87-42010af00002
  ...
</code></pre><p>Job yang baru tadi kemudian akan memiliki uid yang berbeda dari <code>a8f3d00d-c6d2-11e5-9f87-42010af00002</code>. Pengaturan
<code>manualSelector: true</code> memberikan perintah pada sistem bahwa kamu mengetahui apa yang kamu lakukan
dan untuk mengizikan ketidaksesuaian ini untuk terjadi.</p><h2 id=alternatif>Alternatif</h2><h3 id=pod-polosan><em>Pod Polosan</em></h3><p>Ketika node dimana Pod dijalankan berada dalam kondisi <em>reboot</em> atau gagal, Pod tadi akan dihentikan
dan tidak akan di-restart. Meskipun demikian, sebuah Job akan membuat Pod baru yang menggantikan
Pod lama yang dihentikan. Untuk alasan inilah, kami memberikan rekomendasi agar kamu menggunakan sebuah Job dibandingkan dengan
Pod yang biasa, bahkan jika aplikasi yang kamu gunakan hanya memerlukan sebuah Pod.</p><h3 id=replication-controller>Replication Controller</h3><p>Job merupakan komplemen dari <a href=/docs/user-guide/replication-controller>Replication Controller</a>.
Sebuah Replication Controller mengatur Pod yang diharapkan untuk tidak dihentikan (misalnya, <em>web server</em>), dan sebuah Job
mengatur Pod yang diharapkan untuk berhenti (misalnya, <em>batch task</em>).</p><p>Seperti yang sudah dibahas pada <a href=/id/docs/concepts/workloads/pods/pod-lifecycle/><em>Lifecycle</em> Pod</a>, <code>Job</code> <em>hanya</em> pantas
digunakan untuk Pod dengan <code>RestartPolicy</code> yang sama dengan <code>OnFailure</code> atau <code>Never</code>.
(Perhatikan bahwa: Jika <code>RestartPolicy</code> tidak dispesifikasikan, nilai defaultnya adalah <code>Always</code>.)</p><h3 id=job-tunggal-akan-menginisiasi-kontroller-pod>Job Tunggal akan menginisiasi Kontroller Pod</h3><p>Pola lain yang mungkin diterapkan adalah untuk sebuah Job tunggal untuk membuat
sebuah Pod yang kemudian akan membuat Pod lainnya, bersifat selayaknya <em>controller</em> kustom
bagi Pod tersebut. Hal ini mengizinkan fleksibilitas optimal, tetapi cukup kompleks untuk digunakan
dan memiliki integrasi terbatas dengan Kubernetes.</p><p>Salah satu contoh dari pola ini adalah sebuah Job yang akan menginisiasi sebuah Pod
yang menjalankan <em>script</em> yang kemudian akan
menjalankan <em>controller</em> master Spark (kamu dapat melihatnya di <a href=https://github.com/kubernetes/examples/tree/main/staging/spark/README.md>contoh Spark</a>),
yang menjalankan <em>driver</em> Spark, dan kemudian melakukan mekanisme <em>clean up</em>.</p><p>Keuntungan dari pendekatan ini adalah proses keseluruhan yang memiliki jaminan <em>completion</em>
dari sebuah Job, tetapi kontrol secara mutlak atas Pod yang dibuat serta tugas yang diberikan pada Pod tersebut.</p><h2 id=cron-jobs>CronJob</h2><p>Kamu dapat menggunakan <a href=/id/docs/concepts/workloads/controllers/cron-jobs/><code>CronJob</code></a> untuk membuat Job yang akan
dijalankan pada waktu/tanggal yang spesifik, mirip dengan perangkat lunak <code>cron</code> yang ada pada Unix.</p></div><div class=td-content style=page-break-before:always><h1 id=pg-2e4cec01c525b45eccd6010e21cc76d9>4.2.9 - CronJob</h1><p>Suatu CronJob menciptakan <a href=/id/docs/concepts/workloads/controllers/jobs-run-to-completion/>Job</a> yang dijadwalkan berdasarkan waktu tertentu.</p><p>Satu objek CronJob sepadan dengan satu baris pada <em>file</em> <em>crontab</em> (<em>cron table</em>). CronJob tersebut menjalankan suatu pekerjaan secara berkala
pada waktu tertentu, dituliskan dalam format <a href=https://en.wikipedia.org/wiki/Cron>Cron</a>.</p><div class="alert alert-info note callout" role=alert><strong>Catatan:</strong> Seluruh waktu <code>schedule:</code> pada <em><strong>CronJob</strong></em> mengikuti zona waktu dari <em>master</em> di mana Job diinisiasi.</div><p>Untuk panduan dalam berkreasi dengan <em>cron job</em>, dan contoh <em>spec file</em> untuk suatu <em>cron job</em>, lihat <a href=/id/docs/tasks/job/automated-tasks-with-cron-jobs>Menjalankan otomasi <em>task</em> dengan <em>cron job</em></a>.</p><h2 id=limitasi-cron-job>Limitasi <em>Cron Job</em></h2><p>Suatu <em>cron job</em> menciptakan <em>kurang lebih</em> satu objek Job setiap penjadwalan. Istilah yang digunakan adalah "<em>kurang lebih</em>" karena
terdapat beberapa kasus yang menyebabkan dua Job terbuat, atau tidak ada Job sama sekali yang terbuat. Kemungkinan-kemungkinan
seperti itu memang diusahakan untuk tidak sering terjadi, tapi tidak ada jaminan kemungkinan-kemungkinan tersebut tidak akan pernah terjadi.
Oleh karena itu, Job sudah sepantasnya memiliki sifat idempoten.</p><p>Jika pengaturan <code>startingDeadlineSeconds</code> menggunakan nilai yang besar atau tidak diatur (menggunakan nilai <em>default</em>)
dan jika pengaturan <code>concurrencyPolicy</code> dijadikan <code>Allow</code>, Job yang terbuat akan dijalankan paling tidak satu kali.</p><p>CronJob <em>controller</em> memeriksa berapa banyak jadwal yang terlewatkan sejak waktu terakhir eksekusi hingga saat ini. Jika terdapat lebih dari 100 jadwal yang terlewat, maka CronJob <em>controller</em> tidak memulai Job dan mencatat kesalahan:</p><pre tabindex=0><code>Cannot determine if job needs to be started. Too many missed start time (&gt; 100). Set or decrease .spec.startingDeadlineSeconds or check clock skew.
</code></pre><p>Perlu diingat bahwa jika pengaturan <code>startingDeadlineSeconds</code> memiliki suatu nilai (bukan <code>nil</code>), CronJob <em>controller</em> akan menghitung berapa banyak Job yang terlewatkan dari sejak <code>startingDeadlineSeconds</code> hingga sekarang dan bukan sejak waktu terakhir eksekusi. Misalnya: Jika <code>startingDeadlineSeconds</code> memiliki nilai <code>200</code>, CronJob <em>controller</em> akan menghitung berapa banyak Job yang terlewatkan dalam 200 detik terakhir.</p><p>Suatu CronJob dianggap terlewat jika ia gagal diciptakan pada waktu yang semestinya. Misalnya: Jika pengaturan <code>concurrencyPolicy</code> dijadikan <code>Forbid</code>
dan suatu CronJob dicoba dijadwalkan saat masih ada penjadwalan sebelumnya yang masih berjalan, maka ia akan dianggap terlewat.</p><p>Contoh: Suatu CronJob akan menjadwalkan Job baru tiap satu menit dimulai sejak <code>08:30:00</code>, dan <code>startingDeadlineSeconds</code> tidak diatur.
Jika CronJob <em>controller</em> tidak aktif dari <code>08:29:00</code> sampai <code>10:21:00</code>, Job tidak akan dijalankan karena jumlah Job yang terlewat
sudah lebih dari 100.</p><p>Sebagai ilustrasi lebih lanjut, misalkan suatu CronJob diatur untuk menjadwalkan Job baru setiap satu menit dimulai sejak <code>08:30:00</code>,
dan <code>startingDeadlineSeconds</code> memiliki nilai <code>200</code>. Jika CronJob <em>controller</em> tidak aktif seperti pada contoh sebelumnya (<code>08:29:00</code> sampai <code>10:21:00</code>),
Job akan tetap dijalankan pada 10:22:00. Hal ini terjadi karena CronJob <em>controller</em> memeriksa banyaknya jadwal yang terlewatkan pada 200 detik terakhir
(dalam kasus ini: 3 jadwal terlewat), dan bukan dari sejak waktu eksekusi terakhir.</p><p>CronJob hanya bertanggung-jawab untuk menciptakan Job yang sesuai dengan jadwalnya sendiri,
dan Job tersebut bertanggung jawab terhadap pengelolaan Pod yang direpresentasikan olehnya.</p></div><div class=td-content style=page-break-before:always><h1 id=pg-0a0a7eca3e302a3c08f8c85e15d337fd>5 - Services, Load Balancing, dan Jaringan</h1></div><div class=td-content><h1 id=pg-5701136fd2ce258047b6ddc389112352>5.1 - Service</h1><p><a href=/id/docs/concepts/workloads/pods/pod/><code>Pod</code></a> pada Kubernetes bersifat <em>mortal</em>.
Artinya apabila <em>pod-pod</em> tersebut dibuat dan kemudian mati, <em>pod-pod</em> tersebut
tidak akan dihidupkan kembali. <a href=/id/docs/concepts/workloads/controllers/replicaset/><code>ReplicaSets</code></a> secara
khusus bertugas membuat dan menghapus <code>Pod</code> secara dinamis (misalnya, pada proses <em>scaling out</em> atau <em>scaling in</em>).
Meskipun setiap <code>Pod</code> memiliki alamat IP-nya masing-masing, kamu tidak dapat mengandalkan alamat IP
yang diberikan pada <em>pod-pod</em> tersebut, karena alamat IP yang diberikan tidak stabil.
Hal ini kemudian menimbulkan pertanyaan baru: apabila sebuah sekumpulan <code>Pod</code> (yang selanjutnya kita sebut <em>backend</em>)
menyediakan <em>service</em> bagi sebuah sekumpulan <code>Pod</code> lain (yang selanjutnya kita sebut <em>frontend</em>) di dalam
klaster Kubernetes, bagaimana cara <em>frontend</em> menemukan <em>backend</em> mana yang digunakan?</p><p>Inilah alasan kenapa <code>Service</code> ada.</p><p>Sebuah <code>Service</code> pada Kubernetes adalah sebuah abstraksi yang memberikan definisi
set logis yang terdiri beberapa <code>Pod</code> serta <em>policy</em> bagaimana cara kamu mengakses sekumpulan <code>Pod</code> tadi - seringkali disebut sebagai <em>microservices</em>.
Set <code>Pod</code> yang dirujuk oleh suatu <code>Service</code> (biasanya) ditentukan oleh sebuah <a href=/id/docs/concepts/overview/working-with-objects/labels/#label-selectors><code>Label Selector</code></a>
(lihat penjelasan di bawah untuk mengetahui alasan kenapa kamu mungkin saja membutuhkan <code>Service</code> tanpa
sebuah <em>selector</em>).</p><p>Sebagai contoh, misalnya terdapat sebuah <em>backend</em> yang menyediakan fungsionalitas <em>image-processing</em>
yang memiliki 3 buah <em>replica</em>. <em>Replica-replica</em> tadi sifatnya sepadan - dengan kata lain <em>frontend</em>
tidak peduli <em>backend</em> manakah yang digunakan. Meskipun <code>Pod</code> penyusun sekumpulan <em>backend</em> bisa berubah,
<em>frontend</em> tidak perlu peduli bagaimana proses ini dijalankan atau menyimpan <em>list</em> dari <em>backend-backend</em>
yang ada saat itu. <code>Service</code> memiliki tujuan untuk <em>decouple</em> mekanisme ini.</p><p>Untuk aplikasi yang dijalankan di atas Kubernetes, Kubernetes menyediakan API <em>endpoint</em> sederhana
yang terus diubah apabila <em>state</em> sebuah sekumpulan <code>Pod</code> di dalam suatu <code>Service</code> berubah. Untuk
aplikasi <em>non-native</em>, Kubernetes menyediakan <em>bridge</em> yang berbasis <em>virtual-IP</em> bagi <code>Service</code>
yang diarahkan pada <code>Pod</code> <em>backend</em>.</p><h2 id=mendefinisikan-sebuah-service>Mendefinisikan sebuah <code>Service</code></h2><p>Sebuah <code>Service</code> di Kubernetes adalah sebuah objek REST, layaknya sebuah <code>Pod</code>. Seperti semua
objek <em>REST</em>, definisi <code>Service</code> dapat dikirim dengan <em>method POST</em> pada <em>apiserver</em> untuk membuat
sebuah instans baru. Sebagai contoh, misalnya saja kamu memiliki satu sekumpulan <code>Pod</code> yang mengekspos <em>port</em>
9376 dan memiliki <em>label</em> <code>"app=MyApp"</code>.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Service<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>my-service<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>selector</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>app</span>:<span style=color:#bbb> </span>MyApp<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>ports</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>protocol</span>:<span style=color:#bbb> </span>TCP<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>port</span>:<span style=color:#bbb> </span><span style=color:#666>80</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>targetPort</span>:<span style=color:#bbb> </span><span style=color:#666>9376</span><span style=color:#bbb>
</span></span></span></code></pre></div><p>Spesifikasi ini akan ditranslasikan sebagai sebuah objek <code>Service</code> baru dengan nama <code>"my-service"</code>
dengan <em>target port</em> 9376 pada setiap <code>Pod</code> yang memiliki <em>label</em> <code>"app=MyApp"</code>. <code>Service</code> ini
juga akan memiliki alamat IP tersendiri (yang terkadang disebut sebagai <em>"cluster IP"</em>), yang nantinya
akan digunakan oleh <em>service proxy</em> (lihat di bagian bawah). <em>Selector</em> pada <code>Service</code> akan selalu dievaluasi
dan hasilnya akan kembali dikirim dengan menggunakan <em>method POST</em> ke objek <code>Endpoints</code>
yang juga disebut <code>"my-service"</code>.</p><p>Perhatikan bahwa sebuah <code>Service</code> dapat melakukan pemetaan setiap <em>incoming port</em> pada <code>targetPort</code>
mana pun. Secara <em>default</em>, <em>field</em> <code>targetPort</code> akan memiliki <em>value</em> yang sama dengan <em>value</em> dari <em>field</em> <code>port</code>.
Hal menarik lainnya adalah <em>value</em> dari <code>targetPort</code> bisa saja berupa string yang merujuk pada nama
dari <em>port</em> yang didefinisikan pada <code>Pod</code> <em>backend</em>. Nomor <em>port</em> yang diberikan pada <em>port</em> dengan nama
tadi bisa saja memiliki nilai yang berbeda di setiap <code>Pod</code> <em>backend</em>. Hal ini memberikan fleksibilitas
pada saat kamu melakukan <em>deploy</em> atau melakukan perubahan terhadap <code>Service</code>. Misalnya saja suatu saat
kamu ingin mengubah nomor <em>port</em> yang ada pada <code>Pod</code> <em>backend</em> pada rilis selanjutnya tanpa menyebabkan
permasalahan pada sisi klien.</p><p>Secara <em>default</em>, protokol yang digunakan pada <em>service</em> adalah <code>TCP</code>, tapi kamu bisa saja menggunakan
<a href=#protokol-yang-tersedia>protokol yang tersedia</a>. Karena banyak <code>Service</code> memiliki kebutuhan untuk
mengekspos lebih dari sebuah <em>port</em>, Kubernetes menawarkan definisi <em>multiple</em> <em>port</em> pada sebuah objek
<em>Service</em>. Setiap definisi <em>port</em> dapat memiliki protokol yang berbeda.</p><h3 id=service-tanpa-selector><code>Service</code> tanpa <em>selector</em></h3><p>Secara umum, <code>Service</code> memberikan abstraksi mekanisme yang dilakukan untuk mengakses <code>Pod</code>, tapi
mereka juga melakukan abstraksi bagi <em>backend</em> lainnya. Misalnya saja:</p><ul><li>Kamu ingin memiliki sebuah basis data eksternal di <em>environment</em> <em>production</em> tapi pada tahap <em>test</em>,
kamu ingin menggunakan basis datamu sendiri.</li><li>Kamu ingin merujuk <em>service</em> kamu pada <em>service</em> lainnya yang berada pada
<a href=/id/docs/concepts/overview/working-with-objects/namespaces/><em>Namespace</em></a> yang berbeda atau bahkan klaster yang berbeda.</li><li>Kamu melakukan migrasi <em>workloads</em> ke Kubernetes dan beberapa <em>backend</em> yang kamu miliki masih
berada di luar klaster Kubernetes.</li></ul><p>Berdasarkan skenario-skenario di atas, kamu dapat membuat sebuah <code>Service</code> tanpa <em>selector</em>:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Service<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>my-service<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>ports</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>protocol</span>:<span style=color:#bbb> </span>TCP<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>port</span>:<span style=color:#bbb> </span><span style=color:#666>80</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>targetPort</span>:<span style=color:#bbb> </span><span style=color:#666>9376</span><span style=color:#bbb>
</span></span></span></code></pre></div><p>Karena <code>Service</code> ini tidak memiliki <em>selector</em>, objek <code>Endpoints</code> bagi <code>Service</code> ini tidak akan dibuat.
Dengan demikian, kamu bisa membuat <code>Endpoints</code> yang kamu inginkan:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Endpoints<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>my-service<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>subsets</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>addresses</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- <span style=color:green;font-weight:700>ip</span>:<span style=color:#bbb> </span><span style=color:#666>1.2.3.4</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>ports</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- <span style=color:green;font-weight:700>port</span>:<span style=color:#bbb> </span><span style=color:#666>9376</span><span style=color:#bbb>
</span></span></span></code></pre></div><div class="alert alert-info note callout" role=alert><strong>Catatan:</strong> Perhatikan bahwa alamat IP yang kamu buat untuk <code>Endpoints</code> tidak boleh berupa
<em>loopback</em> (127.0.0.0/8), <em>link-local</em> (169.254.0.0/16), atau <em>link-local multicast</em> (224.0.0.0/24).
Alamat IP tersebut juga tidak boleh berupa <em>cluster IP</em> dari <code>Service</code> Kubernetes lainnya,
karena <code>kube-proxy</code> belum menyediakan dukungan IP virtual sebagai <em>destination</em>.</div><p>Cara mengakses suatu <code>Service</code> tanpa <em>selector</em> sama saja dengan mengakses suatu <code>Service</code>
dengan <em>selector</em>. Trafik yang ada akan di-<em>route</em> ke <code>Endpoints</code> yang dispesifikasikan oleh
pengguna (dalam contoh kali ini adalah <code>1.2.3.4:9376</code>).</p><p>Sebuah <code>ExternalName</code> <code>Service</code> merupakan kasus spesial dari <code>Service</code>
dimana <code>Service</code> tidak memiliki <em>selector</em> dan menggunakan penamaan <em>DNS</em>. Untuk
informasi lebih lanjut silahkan baca bagian <a href=#externalname>ExternalName</a>.</p><h2 id=ip-virtual-dan-proxy-service>IP Virtual dan <em>proxy</em> <code>Service</code></h2><p>Setiap <em>node</em> di klaster Kubernetes menjalankan <code>kube-proxy</code>. <code>kube-proxy</code>
bertanggung jawab terhadap implementasi IP virtual bagi <em>Services</em> dengan tipe
selain <a href=#externalname><code>ExternalName</code></a>.</p><p>Pada Kubernetes versi v1.0, <em>Services</em> adalah "layer 4" (TCP/UDP pada IP), <em>proxy</em>
yang digunakan murni berada pada <em>userspace</em>. Pada Kubernetes v1.1, API <code>Ingress</code>
ditambahkan untuk merepresentasikan "layer 7"(HTTP), <em>proxy</em> <code>iptables</code> juga ditambahkan
dan menjadi mode operasi <em>default</em> sejak Kubernetes v1.2. Pada Kubernetes v1.8.0-beta.0,
<em>proxy</em> <em>ipvs</em> juga ditambahkan.</p><h3 id=mode-proxy-userspace>Mode <em>Proxy</em>: <em>userspace</em></h3><p>Pada mode ini, <code>kube-proxy</code> mengamati master Kubernetes apabila terjadi penambahan
atau penghapusan objek <code>Service</code> dan <code>Endpoints</code>. Untuk setiap <code>Service</code>, <code>kube-proxy</code>
akan membuka sebuah <em>port</em> (yang dipilih secara acak) pada <em>node</em> lokal. Koneksi
pada <em>"proxy port"</em> ini akan dihubungkan pada salah satu <code>Pod</code> <em>backend</em> dari <code>Service</code>
(yang tercatat pada <code>Endpoints</code>). <code>Pod</code> <em>backend</em> yang akan digunakan akan diputuskan berdasarkan
<code>SessionAffinity</code> pada <code>Service</code>. Langkah terakhir yang dilakukan oleh <code>kube-proxy</code>
adalah melakukan instalasi <em>rules</em> <code>iptables</code> yang akan mengarahkan trafik yang ada pada
<code>clusterIP</code> (IP virtual) dan <em>port</em> dari <code>Service</code> serta melakukan <em>redirect</em> trafik ke <em>proxy</em>
yang memproksikan <code>Pod</code> <em>backend</em>. Secara <em>default</em>, mekanisme <em>routing</em> yang dipakai adalah
<em>round robin</em>.</p><p><img src=/images/docs/services-userspace-overview.svg alt="Ikhtisar diagram Services pada proxy userspace"></p><h3 id=mode-proxy-iptables>Mode <em>Proxy</em>: iptables</h3><p>Pada mode ini, <code>kube-proxy</code> mengamati master Kubernetes apabila terjadi penambahan
atau penghapusan objek <code>Service</code> dan <code>Endpoints</code>. Untuk setiap <code>Service</code>,
<code>kube-proxy</code> akan melakukan instalasi <em>rules</em> <code>iptables</code> yang akan mengarahkan
trafik ke <code>clusterIP</code> (IP virtual) dan <em>port</em> dari <code>Service</code>. Untuk setiap objek <code>Endpoints</code>,
<code>kube-proxy</code> akan melakukan instalasi <em>rules</em> <code>iptables</code> yang akan memilih satu buah <code>Pod</code>
<em>backend</em>. Secara <em>default</em>, pemilihan <em>backend</em> ini dilakukan secara acak.</p><p>Tentu saja, <code>iptables</code> yang digunakan tidak boleh melakukan <em>switching</em>
antara <em>userspace</em> dan <em>kernelspace</em>, mekanisme ini harus lebih kokoh dan lebih cepat
dibandingkan dengan <em>userspace</em> <em>proxy</em>. Meskipun begitu, berbeda dengan mekanisme
<em>proxy</em> <em>userspace</em>, <em>proxy</em> <code>iptables</code> tidak bisa secara langsung menjalankan mekanisme
<em>retry</em> ke <code>Pod</code> lain apabila <code>Pod</code> yang sudah dipilih sebelumnya tidak memberikan respons,
dengan kata lain hal ini akan sangat bergantung pada
<a href=/docs/tasks/configure-pod-container/configure-liveness-readiness-probes/#defining-readiness-probes>readiness probes</a>.</p><p><img src=/images/docs/services-iptables-overview.svg alt="Ikhtisar diagram Services pada proxy iptables"></p><h3 id=mode-proxy-ipvs>Mode <em>Proxy</em>: ipvs</h3><div style=margin-top:10px;margin-bottom:10px><b>FEATURE STATE:</b> <code>Kubernetes v1.9 [beta]</code></div><p>Pada mode ini, <code>kube-proxy</code> mengamati <em>Services</em> dan <code>Endpoints</code>, kemudian memanggil
<em>interface</em> <em>netlink</em> untuk membuat <em>rules</em> <em>ipvs</em> yang sesuai serta melakukan sinkronisasi
<em>rules</em> <em>ipvs</em> dengan <em>Services</em> dan <code>Endpoints</code> Kubernetes secara periodik, untuk memastikan
status <em>ipvs</em> konsisten dengan apa yang diharapkan. Ketika sebuah <em>Services</em> diakses,
trafik yang ada akan diarahkan ke salah satu <code>Pod</code> <em>backend</em>.</p><p>Sama halnya dengan <code>iptables</code>, <em>ipvs</em> juga berdasarkan pada fungsi <em>hook</em> <em>netfilter</em>,
bedanya adalah <em>ipvs</em> menggunakan struktur data <em>hash table</em> dan bekerja di <em>kernelspace</em>.
Dengan kata lain <em>ipvs</em> melakukan <em>redirect</em> trafik dengan lebih cepat dan dengan performa yang lebih
baik ketika melakukan sinkronisasi <em>rules</em> <em>proxy</em>. Selain itu, <em>ipvs</em> juga menyediakan
lebih banyak opsi algoritma <em>load balancing</em>:</p><ul><li><code>rr</code>: round-robin</li><li><code>lc</code>: least connection</li><li><code>dh</code>: destination hashing</li><li><code>sh</code>: source hashing</li><li><code>sed</code>: shortest expected delay</li><li><code>nq</code>: never queue</li></ul><div class="alert alert-info note callout" role=alert><strong>Catatan:</strong> Mode <em>ipvs</em> menggunakan <em>module</em> <em>IPVS</em> <em>kernel</em> yang diinstal pada <em>node</em>
sebelum <code>kube-proxy</code> dijalankan. Ketika <code>kube-proxy</code> dijalankan dengan mode <em>proxy</em> <em>ipvs</em>,
<code>kube-proxy</code> akan melakukan proses validasi, apakah <em>module</em> <em>IPVS</em> sudah diinstal di <em>node</em>,
jika <em>module</em> tersebut belum diinstal, maka <code>kube-proxy</code> akan menggunakan mode <code>iptables</code>.</div><p><img src=/images/docs/services-ipvs-overview.svg alt="Ikhtisar diagram Services pada proxy ipvs"></p><p>Dari sekian model <em>proxy</em> yang ada, trafik <em>inbound</em> apa pun yang ada diterima oleh <em>IP:Port</em> pada <code>Service</code>
akan dilanjutkan melalui <em>proxy</em> pada <em>backend</em> yang sesuai, dan klien tidak perlu mengetahui
apa informasi mendetail soal Kubernetes, <code>Service</code>, atau <code>Pod</code>. afinitas <em>session</em> (<em>session affinity</em>) berbasis
<em>Client-IP</em> dapat dipilih dengan cara menerapkan nilai <em>"ClientIP"</em> pada <code>service.spec.sessionAffinity</code>
(nilai <em>default</em> untuk hal ini adalah <em>"None"</em>), kamu juga dapat mengatur nilai maximum <em>session</em>
<em>timeout</em> yang ada dengan mengatur opsi <code>service.spec.sessionAffinityConfig.clientIP.timeoutSeconds</code> jika
sebelumnya kamu sudah menerapkan nilai <em>"ClusterIP"</em> pada <code>service.spec.sessionAffinity</code>
(nilai <em>default</em> untuk opsi ini adalah <em>"10800"</em>).</p><h2 id=multi-port-services><em>Multi-Port Services</em></h2><p>Banyak <em>Services</em> dengan kebutuhan untuk mengekspos lebih dari satu <em>port</em>.
Untuk kebutuhan inilah, Kubernetes mendukung <em>multiple</em> <em>port</em> <em>definitions</em> pada objek <code>Service</code>.
Ketika menggunakan <em>multiple</em> <em>port</em>, kamu harus memberikan nama pada setiap <em>port</em> yang didefinisikan,
sehingga <em>Endpoint</em> yang dibentuk tidak ambigu. Contoh:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Service<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>my-service<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>selector</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>app</span>:<span style=color:#bbb> </span>MyApp<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>ports</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>http<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>protocol</span>:<span style=color:#bbb> </span>TCP<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>port</span>:<span style=color:#bbb> </span><span style=color:#666>80</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>targetPort</span>:<span style=color:#bbb> </span><span style=color:#666>9376</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>https<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>protocol</span>:<span style=color:#bbb> </span>TCP<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>port</span>:<span style=color:#bbb> </span><span style=color:#666>443</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>targetPort</span>:<span style=color:#bbb> </span><span style=color:#666>9377</span><span style=color:#bbb>
</span></span></span></code></pre></div><p>Perhatikan bahwa penamaan <em>port</em> hanya boleh terdiri dari karakter <em>alphanumeric</em> <em>lowercase</em>
dan <em>-</em>, serta harus dimulai dan diakhiri dengan karakter <em>alphanumeric</em>, misalnya saja <code>123-abc</code> dan <code>web</code>
merupakan penamaan yang valid, tapi <code>123_abc</code> dan <code>-web</code> bukan merupakan penamaan yang valid.</p><h2 id=memilih-sendiri-alamat-ip-yang-kamu-inginkan>Memilih sendiri alamat IP yang kamu inginkan</h2><p>Kamu dapat memberikan spesifikasi alamat <em>cluster IP</em> yang kamu inginkan
sebagai bagian dari <em>request</em> pembuatan objek <code>Service</code>. Untuk melakukan hal ini,
kamu harus mengisi <em>fields</em> <code>.spec.clusterIP</code> field. Contoh penggunaannya adalah sebagai berikut,
misalnya saja kamu sudah memiliki <em>entry</em> DNS yang ingin kamu gunakan kembali,
atau sebuah sistem <em>legacy</em> yang sudah diatur pada alamat IP spesifik
dan sulit untuk diubah. Alamat IP yang ingin digunakan pengguna haruslah merupakan alamat IP
yang valid dan berada di dalam <em>range</em> <em>CIDR</em> <code>service-cluster-ip-range</code> yang dispesifikasikan di dalam
penanda yang diberikan <em>apiserver</em>. Jika <em>value</em> yang diberikan tidak valid, <em>apiserver</em> akan
mengembalikan <em>response</em> <em>code</em> HTTP <em>422</em> yang mengindikasikan <em>value</em> yang diberikan tidak valid.</p><h3 id=mengapa-tidak-menggunakan-dns-round-robin>Mengapa tidak menggunakan DNS <em>round-robin</em>?</h3><p>Pertanyaan yang selalu muncul adalah kenapa kita menggunakan IP virtual dan bukan
DNS <em>round-robin</em> standar? Terdapat beberapa alasan dibalik semua itu:</p><ul><li>Terdapat sejarah panjang dimana <em>library</em> DNS tidak mengikuti <em>TTL</em> DNS dan
melakukan <em>caching</em> hasil dari <em>lookup</em> yang dilakukan.</li><li>Banyak aplikasi yang melakukan <em>lookup</em> DNS hanya sekali dan kemudian melakukan <em>cache</em> hasil yang diperoleh.</li><li>Bahkan apabila aplikasi dan <em>library</em> melakukan resolusi ulang yang <em>proper</em>, <em>load</em> dari setiap
klien yang melakukan resolusi ulang DNS akan sulit untuk di <em>manage</em>.</li></ul><p>Kami berusaha untuk mengurangi ketertarikan pengguna untuk melakukan yang mungkin akan menyusahkan pengguna.
Dengan demikian, apabila terdapat justifikasi yang cukup kuat, kami mungkin saja memberikan implementasi
alternatif yang ada.</p><h2 id=discovering-services><em>Discovering services</em></h2><p>Kubernetes mendukung 2 buah mode primer untuk melakukan <code>Service</code> - variabel <em>environment</em> dan DNS.</p><h3 id=variabel-environment>Variabel <em>Environment</em></h3><p>Ketika sebuah <code>Pod</code> dijalankan pada <em>node</em>, <em>kubelet</em> menambahkan seperangkat variabel <em>environment</em>
untuk setiap <code>Service</code> yang aktif. <em>Environment</em> yang didukung adalah <a href=https://docs.docker.com/userguide/dockerlinks/>Docker links compatible</a> variabel (perhatikan
<a href=http://releases.k8s.io/main/pkg/kubelet/envvars/envvars.go#L49>makeLinkVariables</a>)
dan variabel <code>{SVCNAME}_SERVICE_HOST</code> dan <code>{SVCNAME}_SERVICE_PORT</code>, dinama nama <code>Service</code> akan diubah
menjadi huruf kapital dan tanda <em>minus</em> akan diubah menjadi <em>underscore</em>.</p><p>Sebagai contoh, <code>Service</code> <code>"redis-master"</code> yang mengekspos <em>port</em> TCP 6379 serta <em>alamat</em>
<em>cluster IP</em> <em>10.0.0.11</em> akan memiliki <em>environment</em> sebagai berikut:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span><span style=color:#b8860b>REDIS_MASTER_SERVICE_HOST</span><span style=color:#666>=</span>10.0.0.11
</span></span><span style=display:flex><span><span style=color:#b8860b>REDIS_MASTER_SERVICE_PORT</span><span style=color:#666>=</span><span style=color:#666>6379</span>
</span></span><span style=display:flex><span><span style=color:#b8860b>REDIS_MASTER_PORT</span><span style=color:#666>=</span>tcp://10.0.0.11:6379
</span></span><span style=display:flex><span><span style=color:#b8860b>REDIS_MASTER_PORT_6379_TCP</span><span style=color:#666>=</span>tcp://10.0.0.11:6379
</span></span><span style=display:flex><span><span style=color:#b8860b>REDIS_MASTER_PORT_6379_TCP_PROTO</span><span style=color:#666>=</span>tcp
</span></span><span style=display:flex><span><span style=color:#b8860b>REDIS_MASTER_PORT_6379_TCP_PORT</span><span style=color:#666>=</span><span style=color:#666>6379</span>
</span></span><span style=display:flex><span><span style=color:#b8860b>REDIS_MASTER_PORT_6379_TCP_ADDR</span><span style=color:#666>=</span>10.0.0.11
</span></span></code></pre></div><p>Hal ini merupakan kebutuhan yang urutannya harus diperhatikan - <code>Service</code> apa pun yang
akan diakses oleh sebuah <code>Pod</code> harus dibuat sebelum <code>Pod</code> tersebut dibuat,
jika tidak variabel <em>environment</em> tidak akan diinisiasi.
Meskipun begitu, DNS tidak memiliki keterbatasan ini.</p><h3 id=dns>DNS</h3><p>Salah satu <a href=/id/docs/concepts/cluster-administration/addons/><em>add-on</em></a> opsional
(meskipun sangat dianjurkan) adalah server DNS. Server DNS bertugas untuk mengamati apakah
terdapat objek <code>Service</code> baru yang dibuat dan kemudian bertugas menyediakan DNS baru untuk
<em>Service</em> tersebut. Jika DNS ini diaktifkan untuk seluruh klaster, maka semua <code>Pod</code> akan secara otomatis
dapat melakukan resolusi DNS.</p><p>Sebagai contoh, apabila kamu memiliki sebuah <code>Service</code> dengan nama <code>"my-service"</code> pada <em>Namespace</em>
<em>"my-ns"</em>, maka <em>record</em> DNS <code>"my-service.my-ns"</code> akan dibuat. <code>Pod</code> yang berada di dalam
<em>Namespace</em> <em>"my-ns"</em> dapat langsung melakukan <em>lookup</em> dengan hanya menggunakan <code>"my-service"</code>.
Sedangkan <code>Pod</code> yang berada di luar <em>Namespace</em> <em>my-ns"</em> harus menggunakan <code>"my-service.my-ns"</code>.
Hasil dari resolusi ini menrupakan <em>cluster IP</em>.</p><p>Kubernetes juga menyediakan <em>record</em> DNS SRV (service) untuk <em>named ports</em>. Jika
<em>Service</em> <code>"my-service.my-ns"</code> memiliki <em>port</em> dengan nama <code>"http"</code> dengan protokol <code>TCP</code>,
kamu dapat melakukan <em>query</em> DNS SRV untuk <code>"_http._tcp.my-service.my-ns"</code> untuk mengetahui
nomor <em>port</em> yang digunakan oleh <em>http</em>.</p><p>Server DNS Kubernetes adalah satu-satunya cara untuk mengakses
<em>Service</em> dengan tipe <code>ExternalName</code>. Informasi lebih lanjut tersedia di
<a href=/id/docs/concepts/services-networking/dns-pod-service/>DNS <em>Pods</em> dan <em>Services</em></a>.</p><h2 id=service-headless><code>Service</code> <em>headless</em></h2><p>Terkadang kamu tidak membutuhkan mekanisme <em>load-balancing</em> dan sebuah <em>single</em> IP <em>Sevice</em>.
Dalam kasus ini, kamu dapat membuat <em>"headless"</em> <code>Service</code> dengan cara memberikan spesifikasi
<em>None</em> pada <em>cluster IP</em> (<code>.spec.clusterIP</code>).</p><p>Opsi ini memungkinkan pengguna mengurangi ketergantungan terhadap sistem Kubernetes
dengan cara memberikan kebebasan untuk mekanisme <em>service discovery</em>. Aplikasi akan
tetap membutuhkan mekanisme <em>self-registration</em> dan <em>adapter service discovery</em>
lain yang dapat digunakan berdasarkan API ini.</p><p>Untuk <code>Service</code> <em>"headless"</em> alokasi <em>cluster IP</em> tidak dilakukan dan <code>kube-proxy</code>
tidak me-<em>manage</em> <em>Service-Service</em>, serta tidak terdapat mekanisme <em>load balancing</em>
yang dilakukan. Bagaimana konfigurasi otomatis bagi DNS dilakukan bergantung pada
apakah <code>Service</code> tersebut memiliki <em>selector</em> yang dispesifikasikan.</p><h3 id=dengan-selector>Dengan <em>selector</em></h3><p>Untuk <code>Service</code> <em>"headless"</em> dengan <em>selector</em>, kontroler <code>Endpoints</code> akan membuat suatu
<em>record</em> <code>Endpoints</code> di API, serta melakukan modifikasi konfigurasi DNS untuk mengembalikan
<em>A records (alamat)</em> yang merujuk secara langsung pada <code>Pod</code> <em>backend</em>.</p><h3 id=tanpa-selector>Tanpa <em>selector</em></h3><p>Untuk <code>Service</code> <em>"headless"</em> tanpa <em>selector</em>, kontroler <code>Endpoints</code>
tidak akan membuat <em>record</em> <em>Enpoints</em>. Meskipun demikian,
sistem DNS tetap melakukan konfigurasi salah satu dari:</p><ul><li><em>record</em> CNAME untuk <a href=#externalname><code>ExternalName</code></a>-tipe services.</li><li><em>record</em> untuk semua <code>Endpoints</code> yang memiliki nama <code>Service</code> yang sama, untuk
tipe lainnya.</li></ul><h2 id=mekanisme-publish-service-jenis-jenis-service>Mekanisme <em>publish</em> <code>Service</code> - jenis-jenis <code>Service</code></h2><p>Untuk beberapa bagian dari aplikasi yang kamu miliki (misalnya saja, <em>frontend</em>),
bisa saja kamu memiliki kebutuhan untuk mengekspos <code>Service</code> yang kamu miliki
ke alamat IP eksternal (di luar klaster Kubernetes).</p><p><code>ServiceTypes</code> yang ada pada Kubernetes memungkinkan kamu untuk menentukan
jenis <code>Service</code> apakah yang kamu butuhkan. Secara <em>default</em>, jenis <code>Service</code>
yang diberikan adalah <code>ClusterIP</code>.</p><p><em>Value</em> dan perilaku dari tipe <code>Service</code> dijelaskan sebagai berikut:</p><ul><li><code>ClusterIP</code>: Mengekspos <code>Service</code> ke <em>range</em> alamat IP di dalam klaster. Apabila kamu memilih <em>value</em> ini
<code>Service</code> yang kamu miliki hanya dapat diakses secara internal. tipe ini adalah
<em>default</em> <em>value</em> dari <em>ServiceType</em>.</li><li><a href=#type-nodeport><code>NodePort</code></a>: Mengekspos <code>Service</code> pada setiap IP <em>node</em> pada <em>port</em> statis
atau <em>port</em> yang sama. Sebuah <code>Service</code> <code>ClusterIP</code>, yang mana <code>Service</code> <code>NodePort</code> akan di-<em>route</em>
, dibuat secara otomatis. Kamu dapat mengakses <code>Service</code> dengan tipe ini,
dari luar klaster melalui <code>&lt;NodeIP>:&lt;NodePort></code>.</li><li><a href=#loadbalancer><code>LoadBalancer</code></a>: Mengekspos <code>Service</code> secara eksternal dengan menggunakan <code>LoadBalancer</code>
yang disediakan oleh penyedia layanan <em>cloud</em>. <code>Service</code> dengan tipe <code>NodePort</code> dan <code>ClusterIP</code>,
dimana trafik akan di-<em>route</em>, akan dibuat secara otomatis.</li><li><a href=#externalname><code>ExternalName</code></a>: Melakukan pemetaan <code>Service</code> ke konten
dari <em>field</em> <code>externalName</code> (misalnya: <code>foo.bar.example.com</code>), dengan cara mengembalikan
catatan <code>CNAME</code> beserta <em>value</em>-nya. Tidak ada metode <em>proxy</em> apa pun yang diaktifkan. Mekanisme ini
setidaknya membutuhkan <code>kube-dns</code> versi 1.7.</li></ul><h3 id=type-nodeport>Type NodePort</h3><p>Jika kamu menerapkan <em>value</em> <code>NodePort</code> pada <em>field</em> <em>type</em>, master Kubernetes akan mengalokasikan
<em>port</em> dari <em>range</em> yang dispesifikasikan oleh penanda <code>--service-node-port-range</code> (secara <em>default</em>, 30000-32767)
dan setiap <em>Node</em> akan memproksikan <em>port</em> tersebut (setiap <em>Node</em> akan memiliki nomor <em>port</em> yang sama) ke <code>Service</code>
yang kamu miliki. <code>Port</code> tersebut akan dilaporkan pada <em>field</em> <code>.spec.ports[*].nodePort</code> di <code>Service</code> kamu.</p><p>Jika kamu ingin memberikan spesifikasi IP tertentu untuk melakukan <em>poxy</em> pada <em>port</em>.
kamu dapat mengatur penanda <code>--nodeport-addresses</code> pada <code>kube-proxy</code> untuk <em>range</em> alamat IP
tertentu (mekanisme ini didukung sejak v1.10). Sebuah daftar yang dipisahkan koma (misalnya, <em>10.0.0.0/8</em>, <em>1.2.3.4/32</em>)
digunakan untuk mem-<em>filter</em> alamat IP lokal ke <em>node</em> ini. Misalnya saja kamu memulai <code>kube-proxy</code> dengan penanda
<code>--nodeport-addresses=127.0.0.0/8</code>, maka <code>kube-proxy</code> hanya akan memilih <em>interface</em> <em>loopback</em> untuk <code>Service</code> dengan tipe
<code>NodePort</code>. Penanda <code>--nodeport-addresses</code> memiliki nilai <em>default</em> kosong (<code>[]</code>), yang artinya akan memilih semua <em>interface</em> yang ada
dan sesuai dengan perilaku <code>NodePort</code> <em>default</em>.</p><p>Jika kamu menginginkan nomor <em>port</em> yang berbeda, kamu dapat memberikan spesifikasi
<em>value</em> dari <em>field</em> <em>nodePort</em>, dan sistem yang ada akan mengalokasikan <em>port</em> tersebut untuk kamu,
jika <em>port</em> tersebut belum digunakan (perhatikan bahwa jika kamu menggunakan teknik ini, kamu perlu
mempertimbangkan <em>collision</em> yang mungkin terjadi dan bagaimana cara mengatasi hal tersebut)
atau transaksi API yang dilakukan akan gagal.</p><p>Hal ini memberikan kebebasan bagi pengembang untuk memilih <em>load balancer</em> yang akan digunakan, terutama apabila
<em>load balancer</em> yang ingin digunakan belum didukung sepenuhnya oleh Kubernetes.</p><p>Perhatikan bahwa <code>Service</code> dapat diakses baik dengan menggunakan <code>&lt;NodeIP>:spec.ports[*].nodePort</code>
atau <code>.spec.clusterIP:spec.ports[*].port</code>. (Jika penanda <code>--nodeport-addresses</code> diterapkan, <nodeip>dapat di-<em>filter</em> dengan salah satu atau lebih <em>NodeIP</em>.)</p><h3 id=loadbalancer>Type LoadBalancer</h3><p>Pada penyedia layanan <em>cloud</em> yang menyediakan pilihan <em>load balancer</em> eksternal, pengaturan <em>field</em> <em>type</em>
ke <code>LoadBalancer</code> akan secara otomatis melakukan proses <em>provision</em> <em>load balancer</em> untuk <code>Service</code> yang kamu buat.
Informasi mengenai <em>load balancer</em> yang dibuat akan ditampilkan pada <em>field</em> <code>.status.loadBalancer</code>
pada <code>Service</code> kamu. Contohnya:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Service<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>my-service<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>selector</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>app</span>:<span style=color:#bbb> </span>MyApp<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>ports</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>protocol</span>:<span style=color:#bbb> </span>TCP<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>port</span>:<span style=color:#bbb> </span><span style=color:#666>80</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>targetPort</span>:<span style=color:#bbb> </span><span style=color:#666>9376</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>clusterIP</span>:<span style=color:#bbb> </span><span style=color:#666>10.0.171.239</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>loadBalancerIP</span>:<span style=color:#bbb> </span><span style=color:#666>78.11.24.19</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>type</span>:<span style=color:#bbb> </span>LoadBalancer<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>status</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>loadBalancer</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>ingress</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:green;font-weight:700>ip</span>:<span style=color:#bbb> </span><span style=color:#666>146.148.47.155</span><span style=color:#bbb>
</span></span></span></code></pre></div><p>Trafik dari <em>load balancer</em> eksternal akan diarahkan pada <code>Pod</code> <em>backend</em>, meskipun mekanisme
bagaimana hal ini dilakukan bergantung pada penyedia layanan <em>cloud</em>. Beberapa penyedia layanan
<em>cloud</em> mengizinkan konfigurasi untuk <em>value</em> <code>loadBalancerIP</code>. Dalam kasus tersebut, <em>load balancer</em> akan dibuat
dengan <em>loadbalancerIP</em> yang dispesifikasikan. Jika <em>value</em> dari <code>loadBalancerIP</code> tidak dispesifikasikan.
sebuah IP sementara akan diberikan pada <em>loadBalancer</em>. Jika <code>loadBalancerIP</code> dispesifikasikan,
tetapi penyedia layanan <em>cloud</em> tidak mendukung hal ini, maka <em>field</em> yang ada akan diabaikan.</p><p><strong>Catatan Khusus untuk Azure</strong>: Untuk spesifikasi <code>loadBalancerIP</code> publik yang didefinisikan oleh pengguna,
sebuah alamat IP statis publik akan disediakan terlebih dahulu, dan alamat IP tersebut harus berada di
<em>resource group</em> dari <em>resource</em> yang secara otomatis dibuat oleh klaster. Misalnya saja, <code>MC_myResourceGroup_myAKSCluster_eastus</code>.
Berikan spesifikasi alamat IP sebagai <code>loadBalancerIP</code>. Pastikan kamu sudah melakukan <em>update</em> pada
<em>securityGroupName</em> pada <em>file</em> konfigurasi penyedia layanan <em>cloud</em>.
Untuk informasi lebih lanjut mengenai <em>permission</em> untuk <code>CreatingLoadBalancerFailed</code> kamu dapat membaca <em>troubleshooting</em> untuk
<a href=https://docs.microsoft.com/en-us/azure/aks/static-ip>Penggunaan alamat IP statis pada <em>load balancer</em> Azure Kubernetes Service (AKS)</a> atau
<a href=https://github.com/Azure/AKS/issues/357><em>CreatingLoadBalancerFailed</em> pada klaster AKS dengan <em>advanced networking</em></a>.</p><div class="alert alert-info note callout" role=alert><strong>Catatan:</strong> Dukungan untuk SCTP <em>load balancer</em> dari penyedia layanan <em>cloud</em> bergantung pada
implementasi <em>load balancer</em> yang disediakan oleh penyedia layanan <em>cloud</em> tersebut.
Jika SCTP tidak didukung oleh <em>load balancer</em> penyedia layanan publik maka <em>request</em> pembuatan <code>Service</code>
akan tetap diterima, meskipun proses pembuatan <em>load balancer</em> itu sendiri gagal.</div><h4 id=load-balancer-internal><em>Load balancer</em> internal</h4><p>Di dalam <em>environment</em>, terkadang terdapat kebutuhan untuk melakukan <em>route</em> trafik antar
<em>Service</em> yang berada di dalam satu VPC.</p><p>Di dalam <em>environment</em> <em>split-horizon DNS</em> kamu akan membutuhkan dua <em>service</em> yang mampu
melakukan mekanisme <em>route</em> trafik eskternal maupun internal ke <em>endpoints</em> yang kamu miliki.</p><p>Hal ini dapat diraih dengan cara menambahkan anotasi berikut untuk <em>service</em> yang disediakan oleh
penyedia layanan <em>cloud</em>.</p><ul class="nav nav-tabs" id=service-tabs role=tablist><li class=nav-item><a data-toggle=tab class="nav-link active" href=#service-tabs-0 role=tab aria-controls=service-tabs-0 aria-selected=true>Default</a></li><li class=nav-item><a data-toggle=tab class=nav-link href=#service-tabs-1 role=tab aria-controls=service-tabs-1>GCP</a></li><li class=nav-item><a data-toggle=tab class=nav-link href=#service-tabs-2 role=tab aria-controls=service-tabs-2>AWS</a></li><li class=nav-item><a data-toggle=tab class=nav-link href=#service-tabs-3 role=tab aria-controls=service-tabs-3>Azure</a></li><li class=nav-item><a data-toggle=tab class=nav-link href=#service-tabs-4 role=tab aria-controls=service-tabs-4>OpenStack</a></li><li class=nav-item><a data-toggle=tab class=nav-link href=#service-tabs-5 role=tab aria-controls=service-tabs-5>Baidu Cloud</a></li></ul><div class=tab-content id=service-tabs><div id=service-tabs-0 class="tab-pane show active" role=tabpanel aria-labelledby=service-tabs-0><p><p>Pilih salah satu <em>tab</em>.</p></div><div id=service-tabs-1 class=tab-pane role=tabpanel aria-labelledby=service-tabs-1><p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span>[...]<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>my-service<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>annotations</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>cloud.google.com/load-balancer-type</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;Internal&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span>[...]<span style=color:#bbb>
</span></span></span></code></pre></div><p>Gunakan <em>cloud.google.com/load-balancer-type: "internal"</em> untuk master dengan versi 1.7.0 to 1.7.3.
Untuk informasi lebih lanjut, dilahkan baca <a href=https://cloud.google.com/kubernetes-engine/docs/internal-load-balancing>dokumentasi</a>.</p></div><div id=service-tabs-2 class=tab-pane role=tabpanel aria-labelledby=service-tabs-2><p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span>[...]<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>my-service<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>annotations</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>service.beta.kubernetes.io/aws-load-balancer-internal</span>:<span style=color:#bbb> </span><span style=color:#666>0.0.0.0</span>/0<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span>[...]<span style=color:#bbb>
</span></span></span></code></pre></div></div><div id=service-tabs-3 class=tab-pane role=tabpanel aria-labelledby=service-tabs-3><p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span>[...]<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>my-service<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>annotations</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>service.beta.kubernetes.io/azure-load-balancer-internal</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;true&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span>[...]<span style=color:#bbb>
</span></span></span></code></pre></div></div><div id=service-tabs-4 class=tab-pane role=tabpanel aria-labelledby=service-tabs-4><p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span>[...]<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>my-service<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>annotations</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>service.beta.kubernetes.io/openstack-internal-load-balancer</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;true&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span>[...]<span style=color:#bbb>
</span></span></span></code></pre></div></div><div id=service-tabs-5 class=tab-pane role=tabpanel aria-labelledby=service-tabs-5><p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span>[...]<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>my-service<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>annotations</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>service.beta.kubernetes.io/cce-load-balancer-internal-vpc</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;true&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span>[...]<span style=color:#bbb>
</span></span></span></code></pre></div></div></div><h4 id=dukungan-untuk-ssl-di-aws>Dukungan untuk SSL di AWS</h4><p>Dukungan parsial untuk SSL bagi klaster yang dijalankan di AWS mulai diterapkan,
mulai versi 1.3 terdapat 3 anotasi yang dapat ditambahkan pada <code>Service</code> dengan tipe
<code>LoadBalancer</code>:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>my-service<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>annotations</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>service.beta.kubernetes.io/aws-load-balancer-ssl-cert</span>:<span style=color:#bbb> </span>arn:aws:acm:us-east-1:123456789012:certificate/12345678-1234-1234-1234-123456789012<span style=color:#bbb>
</span></span></span></code></pre></div><p>Anotasi pertama memberikan spesifikasi ARN dari sertifikat yang akan digunakan.
Sertifikat yang digunakan bisa saja berasal dari <em>third party</em> yang diunggah ke IAM atau
sertifikat yang dibuat secara langsung dengan menggunakan sertifikat manajer AWS.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>my-service<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>annotations</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>service.beta.kubernetes.io/aws-load-balancer-backend-protocol</span>:<span style=color:#bbb> </span>(https|http|ssl|tcp)<span style=color:#bbb>
</span></span></span></code></pre></div><p>Anotasi kedua memberikan spesifikasi bagi protokol yang digunakan oleh <code>Pod</code> untuk saling berkomunikasi.
Untuk HTTPS dan SSL, ELB membutuhkan <code>Pod</code> untuk melakukan autentikasi terhadap dirinya sendiri melalui
koneksi yang dienkripsi.</p><p>Protokol HTTP dan HTTPS akan memilih mekanisme <em>proxy</em> di tingkatan ke-7:
ELB akan melakukan terminasi koneksi dengan pengguna, melakukan proses <em>parsing</em> <em>headers</em>, serta
memasukkan <em>value</em> bagi <em>header</em> <code>X-Forwarded-For</code> dengan alamat IP pengguna (<em>Pod</em> hanya dapat melihat
alamat IP dari ELB pada akhir koneksi yang diberikan) ketika melakukan <em>forwarding</em> suatu <em>request</em>.</p><p>Protokol TCP dan SSL akan memilih mekanisme <em>proxy</em> pada tingkatan 4: ELB akan melakukan <em>forwarding</em> trafik
tanpa melakukan modifikasi <em>headers</em>.</p><p>Pada <em>environment</em> campuran dimana beberapa <em>port</em> diamankan sementara <em>port</em> lainnya dalam kondisi tidak dienkripsi,
anotasi-anotasi berikut dapat digunakan:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>my-service<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>annotations</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>service.beta.kubernetes.io/aws-load-balancer-backend-protocol</span>:<span style=color:#bbb> </span>http<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>service.beta.kubernetes.io/aws-load-balancer-ssl-ports</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;443,8443&#34;</span><span style=color:#bbb>
</span></span></span></code></pre></div><p>Pada contoh di atas, jika <code>Service</code> memiliki 3 buah <em>port</em>, yaitu: <code>80</code>, <code>443</code>, dan
<code>8443</code>, maka <code>443</code> adan <code>8443</code> akan menggunakan sertifikat SSL, tetapi <code>80</code> hanya akan
di-<em>proxy</em> menggunakan protokol HTTP.</p><p>Mulai versi 1.9, <code>Service</code> juga dapat menggunakan <a href=http://docs.aws.amazon.com/elasticloadbalancing/latest/classic/elb-security-policy-table.html><em>predefined</em> <em>policy</em></a>
untuk HTTPS atau <em>listener</em> SSL. Untuk melihat <em>policy</em> apa saja yang dapat digunakan, kamu dapat menjalankan perintah <em>awscli</em>:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>aws elb describe-load-balancer-policies --query <span style=color:#b44>&#39;PolicyDescriptions[].PolicyName&#39;</span>
</span></span></code></pre></div><p><em>Policy</em> ini kemudian dapat dispesifikasikan menggunakan anotasi
"<em>service.beta.kubernetes.io/aws-load-balancer-ssl-negotiation-policy</em>", contohnya:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>my-service<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>annotations</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>service.beta.kubernetes.io/aws-load-balancer-ssl-negotiation-policy</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;ELBSecurityPolicy-TLS-1-2-2017-01&#34;</span><span style=color:#bbb>
</span></span></span></code></pre></div><h4 id=protokol-proxy-pada-aws>Protokol PROXY pada AWS</h4><p>Untuk mengaktifkan dukungan <a href=https://www.haproxy.org/download/1.8/doc/proxy-protocol.txt>protokol PROXY</a>
untuk klaster yang dijalankan di AWS, kamu dapat menggunakan anotasi di bawah ini:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>my-service<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>annotations</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>service.beta.kubernetes.io/aws-load-balancer-proxy-protocol</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;*&#34;</span><span style=color:#bbb>
</span></span></span></code></pre></div><p>Sejak versi 1.3.0, penggunaan anotasi berlaku untuk semua <em>port</em> yang diproksi oleh ELB
dan tidak dapat diatur sebaliknya.</p><h4 id=akses-log-elb-pada-aws>Akses <em>Log</em> ELB pada AWS</h4><p>Terdapat beberapa anotasi yang digunakan untuk melakukan manajemen
akses <em>log</em> untuk ELB pada AWS.</p><p>Anotasi <code>service.beta.kubernetes.io/aws-load-balancer-access-log-enabled</code>
mengatur akses <em>log</em> mana sajakah yang diaktifkan.</p><p>Anotasi <code>service.beta.kubernetes.io/aws-load-balancer-access-log-emit-interval</code>
mengatur interval (dalam menit) publikasi akses <em>log</em>. Kamu dapat memberikan spesifikasi interval
diantara <em>range</em> 5-60 menit.</p><p>Anotasi <code>service.beta.kubernetes.io/aws-load-balancer-access-log-s3-bucket-name</code>
mengatur nama <em>bucket</em> Amazon S3 dimana akses <em>log</em> <em>load balancer</em> disimpan.</p><p>Anotasi <code>service.beta.kubernetes.io/aws-load-balancer-access-log-s3-bucket-prefix</code>
memberikan spesifikasi hierarki logis yang kamu buat untuk <em>bucket</em> Amazon S3 yang kamu buat.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>my-service<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>annotations</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>service.beta.kubernetes.io/aws-load-balancer-access-log-enabled</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;true&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:#080;font-style:italic># Specifies whether access logs are enabled for the load balancer</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>service.beta.kubernetes.io/aws-load-balancer-access-log-emit-interval</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;60&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:#080;font-style:italic># The interval for publishing the access logs. You can specify an interval of either 5 or 60 (minutes).</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>service.beta.kubernetes.io/aws-load-balancer-access-log-s3-bucket-name</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;my-bucket&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:#080;font-style:italic># The name of the Amazon S3 bucket where the access logs are stored</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>service.beta.kubernetes.io/aws-load-balancer-access-log-s3-bucket-prefix</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;my-bucket-prefix/prod&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:#080;font-style:italic># The logical hierarchy you created for your Amazon S3 bucket, for example _my-bucket-prefix/prod_</span><span style=color:#bbb>
</span></span></span></code></pre></div><h4 id=mekanisme-draining-koneksi-pada-aws>Mekanisme <em>Draining</em> Koneksi pada AWS</h4><p>Mekanisme <em>draining</em> untuk ELB klasik dapat dilakukan dengan menggunakan anotasi
<code>service.beta.kubernetes.io/aws-load-balancer-connection-draining-enabled</code> serta mengatur
<em>value</em>-nya menjadi <code>"true"</code>. Anotasi
<code>service.beta.kubernetes.io/aws-load-balancer-connection-draining-timeout</code> juga
dapat digunakan untuk mengatur <em>maximum time</em> (dalam detik), untuk menjaga koneksi yang ada
agar selalu terbuka sebelum melakukan <em>deregistering</em> <em>instance</em>.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>my-service<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>annotations</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>service.beta.kubernetes.io/aws-load-balancer-connection-draining-enabled</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;true&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>service.beta.kubernetes.io/aws-load-balancer-connection-draining-timeout</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;60&#34;</span><span style=color:#bbb>
</span></span></span></code></pre></div><h4 id=anotasi-elb-lainnya>Anotasi ELB lainnya</h4><p>Terdapat beberapa anotasi lain yang dapat digunakan untuk mengatur ELB klasik
sebagaimana dijelaskan seperti di bawah ini:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>my-service<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>annotations</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>service.beta.kubernetes.io/aws-load-balancer-connection-idle-timeout</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;60&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:#080;font-style:italic># The time, in seconds, that the connection is allowed to be idle (no data has been sent over the connection) before it is closed by the load balancer</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>service.beta.kubernetes.io/aws-load-balancer-cross-zone-load-balancing-enabled</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;true&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:#080;font-style:italic># Specifies whether cross-zone load balancing is enabled for the load balancer</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>service.beta.kubernetes.io/aws-load-balancer-additional-resource-tags</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;environment=prod,owner=devops&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:#080;font-style:italic># A comma-separated list of key-value pairs which will be recorded as</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:#080;font-style:italic># additional tags in the ELB.</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>service.beta.kubernetes.io/aws-load-balancer-healthcheck-healthy-threshold</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:#080;font-style:italic># The number of successive successful health checks required for a backend to</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:#080;font-style:italic># be considered healthy for traffic. Defaults to 2, must be between 2 and 10</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>service.beta.kubernetes.io/aws-load-balancer-healthcheck-unhealthy-threshold</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;3&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:#080;font-style:italic># The number of unsuccessful health checks required for a backend to be</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:#080;font-style:italic># considered unhealthy for traffic. Defaults to 6, must be between 2 and 10</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>service.beta.kubernetes.io/aws-load-balancer-healthcheck-interval</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;20&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:#080;font-style:italic># The approximate interval, in seconds, between health checks of an</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:#080;font-style:italic># individual instance. Defaults to 10, must be between 5 and 300</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>service.beta.kubernetes.io/aws-load-balancer-healthcheck-timeout</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;5&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:#080;font-style:italic># The amount of time, in seconds, during which no response means a failed</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:#080;font-style:italic># health check. This value must be less than the service.beta.kubernetes.io/aws-load-balancer-healthcheck-interval</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:#080;font-style:italic># value. Defaults to 5, must be between 2 and 60</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>service.beta.kubernetes.io/aws-load-balancer-extra-security-groups</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;sg-53fae93f,sg-42efd82e&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:#080;font-style:italic># A list of additional security groups to be added to ELB</span><span style=color:#bbb>
</span></span></span></code></pre></div><h4 id=dukungan-network-load-balancer-nlb-pada-aws-alpha>Dukungan <em>Network Load Balancer</em> (NLB) pada AWS [alpha]</h4><div class="alert alert-danger warning callout" role=alert><strong>Peringatan:</strong> Ini merupakan tingkatan <em>alpha</em> dan tidak direkomendasikan untuk digunakan pada <em>environment</em> <em>production</em>.</div><p>Sejak versi 1.9.0, Kubernetes mendukung <em>Network Load Balancer</em> (NLB). Untuk
menggunakan NLB pada AWS, gunakan anotasi <code>service.beta.kubernetes.io/aws-load-balancer-type</code>
dan atur <em>value</em>-nya dengan <code>nlb</code>.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>my-service<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>annotations</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>service.beta.kubernetes.io/aws-load-balancer-type</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;nlb&#34;</span><span style=color:#bbb>
</span></span></span></code></pre></div><p>Tidak seperti ELB klasik, NLB, melakukan <em>forwarding</em> IP klien melalui <em>node</em>.
Jika <em>field</em> <code>.spec.externalTrafficPolicy</code> diatur <em>value</em>-nya menjadi <code>Cluster</code>, maka
alamat IP klien tidak akan diteruskan pada <code>Pod</code>.</p><p>Dengan mengatur <em>value</em> dari <em>field</em> <code>.spec.externalTrafficPolicy</code> ke <code>Local</code>,
alamat IP klien akan diteruskan ke <code>Pod</code>, tapi hal ini bisa menyebabkan distribusi trafik
yang tidak merata. <em>Node</em> yang tidak memiliki <code>Pod</code> untuk <code>Service</code> dengan tipe <code>LoadBalancer</code>
akan menyebabkan kegagalan <em>health check</em> <em>NLB Target</em> pada tahapan <em>auto-assigned</em> <code>.spec.healthCheckNodePort</code>
dan tidak akan menerima trafik apa pun.</p><p>Untuk menghasilkan distribusi trafik yang merata, kamu dapat menggunakan
<em>DaemonSet</em> atau melakukan spesifikasi
<a href=/id/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity-beta-feature>pod anti-affinity</a>
agar <code>Pod</code> tidak di-<em>assign</em> ke <em>node</em> yang sama.</p><p>NLB juga dapat digunakan dengan anotasi <a href=/id/docs/concepts/services-networking/service/#internal-load-balancer>internal load balancer</a>.</p><p>Agar trafik klien berhasil mencapai <em>instances</em> dibelakang ELB,
<em>security group</em> dari <em>node</em> akan diberikan <em>rules</em> IP sebagai berikut:</p><table><thead><tr><th><em>Rule</em></th><th>Protokol</th><th><code>Port</code></th><th><em>IpRange(s)</em></th><th>Deskripsi <em>IpRange</em></th></tr></thead><tbody><tr><td><em>Health Check</em></td><td>TCP</td><td>NodePort(s) (<code>.spec.healthCheckNodePort</code> for <em>.spec.externalTrafficPolicy = Local</em>)</td><td>VPC CIDR</td><td>kubernetes.io/rule/nlb/health=&lt;loadBalancerName></td></tr><tr><td><em>Client Traffic</em></td><td>TCP</td><td>NodePort(s)</td><td><code>.spec.loadBalancerSourceRanges</code> (defaults to <code>0.0.0.0/0</code>)</td><td>kubernetes.io/rule/nlb/client=&lt;loadBalancerName></td></tr><tr><td><em>MTU Discovery</em></td><td>ICMP</td><td>3,4</td><td><code>.spec.loadBalancerSourceRanges</code> (defaults to <code>0.0.0.0/0</code>)</td><td>kubernetes.io/rule/nlb/mtu=&lt;loadBalancerName></td></tr></tbody></table><p>Perhatikan bahwa jika <code>.spec.loadBalancerSourceRanges</code> tidak dispesifikasikan,
Kubernetes akan mengizinkan trafik dari <code>0.0.0.0/0</code> ke <em>Node Security Group</em>.
Jika <em>node</em> memiliki akses publik, maka kamu harus memperhatikan tersebut karena trafik yang tidak berasal
dari NLB juga dapat mengakses semua <em>instance</em> di <em>security group</em> tersebut.</p><p>Untuk membatasi klien IP mana yang dapat mengakses NLB,
kamu harus memberikan spesifikasi <em>loadBalancerSourceRanges</em>.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>loadBalancerSourceRanges</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:#b44>&#34;143.231.0.0/16&#34;</span><span style=color:#bbb>
</span></span></span></code></pre></div><div class="alert alert-info note callout" role=alert><strong>Catatan:</strong> NLB hanya dapat digunakan dengan beberapa kelas <em>instance</em> tertentu baca <a href=http://docs.aws.amazon.com/elasticloadbalancing/latest/network/target-group-register-targets.html#register-deregister-targets>dokumentasi AWS</a>
untuk mengetahui lebih lanjut <em>intance</em> apa saja yang didukung.</div><h3 id=externalname>Tipe ExternalName</h3><p>Service dengan tipe <code>ExternalName</code> melakukan pemetaan antara <code>Service</code> dan DNS, dan bukan
ke <em>selector</em> seperti <code>my-service</code> atau <code>cassandra</code>. Kamu memberikan spesifikasi <code>spec.externalName</code>
pada <code>Service</code> tersebut.</p><p>Definisi <code>Service</code> ini, sebagai contoh, melaukan pemetaan
<code>Service</code> <code>my-service</code> pada <em>namespace</em> <code>prod</code> ke DNS <code>my.database.example.com</code>:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Service<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>my-service<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>namespace</span>:<span style=color:#bbb> </span>prod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>type</span>:<span style=color:#bbb> </span>ExternalName<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>externalName</span>:<span style=color:#bbb> </span>my.database.example.com<span style=color:#bbb>
</span></span></span></code></pre></div><div class="alert alert-info note callout" role=alert><strong>Catatan:</strong> <code>ExternalName</code> menerima alamat IPv4 dalam bentuk string,
tapi karena DNS tersusun atas angka dan bukan sebagai alamat IP.
<code>ExternalName</code> yang menyerupai alamat IPv4 tidak bisa di-<em>resolve</em> oleh <em>CoreDNS</em>
atau <em>ingress-nginx</em> karena <code>ExternalName</code> memang ditujukan bagi penamaan <em>canonical</em> DNS.
Untuk melakukan <em>hardcode</em> alamat IP, kamu dapat menggunakan <em>headless</em> <code>Service</code> sebagai alternatif.</div><p>Ketika melakukan pencarian <em>host</em> <code>my-service.prod.svc.cluster.local</code>,
servis DNS klaster akan mengembalikan <em>record</em> <code>CNAME</code> dengan <em>value</em> <code>my.database.example.com</code>.
Mekanisme akses pada <code>my-service</code> bekerja dengan cara yang sama dengan
<code>Service</code> pada umumnya, perbedaan yang krusial untuk hal ini adalah mekanisme <em>redirection</em>
terjadi pada tingkatan DNS dan bukan melalui <em>proxy forward</em>. Apabila kamu berniat memindahkan basis data
yang kamu pakai ke dalam klaster, kamu hanya perlu mengganti instans basis data kamu dan menjalankannya
di dalam <code>Pod</code>, menambahkan <em>selector</em> atau <em>endpoint</em> yang sesuai, serta mengupah <em>type</em> dari
<em>Service</em> yang kamu gunakan.</p><div class="alert alert-info note callout" role=alert><strong>Catatan:</strong> Bagian ini berasal dari tulisan <a href=https://akomljen.com/kubernetes-tips-part-1/>Tips Kubernetes - Bagian
1</a> oleh <a href=https://akomljen.com/>Alen Komljen</a>.</div><h3 id=ip-eksternal>IP Eksternal</h3><p>Jika terdapat sebuah alamat IP eksternal yang melakukan mekanisme <em>route</em> ke satu atau lebih <em>node</em> yang ada di klaster, <code>Service</code> Kubernetes dapat diekspos
dengan menggunakan <code>externalIP</code>. Trafik yang diarahkan ke klaster dengan IP eksternal
(sebagai destinasi IP), pada <em>port</em> <code>Service</code> akan di-<em>route</em> ke salah satu <em>endpoint</em> <code>Service</code>.
<em>Value</em> dari <code>externalIP</code> tidak diatur oleh Kubernetes dan merupakan tanggung jawab
dari administrator klaster.</p><p>Pada <em>ServiceSpec</em>, kamu dapat memberikan spesifikasi <code>externalIP</code> dan <code>ServiceTypes</code>.
Pada contoh di bawah ini. <code>"my-service"</code> dapat diakses oleh klien pada "<code>80.11.12.10:80</code>" (<code>externalIP:port</code>).</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Service<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>my-service<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>selector</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>app</span>:<span style=color:#bbb> </span>MyApp<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>ports</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>http<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>protocol</span>:<span style=color:#bbb> </span>TCP<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>port</span>:<span style=color:#bbb> </span><span style=color:#666>80</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>targetPort</span>:<span style=color:#bbb> </span><span style=color:#666>9376</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>externalIPs</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:#666>80.11.12.10</span><span style=color:#bbb>
</span></span></span></code></pre></div><h2 id=kekurangan>Kekurangan</h2><p>Penggunaan <em>proxy</em> <em>userspace</em> untuk VIP dapat digunakan untuk skala kecil hingga menengah,
meski begitu hal ini tidak <em>scalable</em> untuk klaster yang sangat besar dan memiliki ribuan <code>Service</code>.
Perhatikan <a href=http://issue.k8s.io/1107>Desain proposal orisinil untuk <em>portal</em></a> untuk informasi
lebih lanjut.</p><p>Penggunaan <em>proxy</em> <em>userspace</em> menghilangkan <em>source-IP</em> dari <em>packet</em> yang mengakses
sebuah <code>Service</code>. Hal ini membuat mekanisme <em>firewall</em> menjadi sulit untuk diterapkan.
<em>Proxy</em> <code>iptables</code> tidak menghilangkan <em>source IP</em> yang berasal dari dalam klaster,
meski begitu, hal ini masih berimbas pada klien yang berasal dari <code>Service</code> dengan tipe
<em>load-balancer</em> atau <em>node-port</em>.</p><p><em>Field</em> tipe didesain sebagai fungsionalitas yang berantai - setiap tingkatan
menambahkan tambahan pada tingkatansebelumnya. Hal ini tidak selalu berlaku bagi
semua penyedia layanan <em>cloud</em> (misalnya saja Google Compute Engine tidak perlu
melakukan alokasi <code>NodePort</code> untuk membuat <code>LoadBalancer</code> bekerja sebagaimana mestinya,
hal ini berbeda dengan AWS yang memerlukan hal ini, setidaknya untuk API yang mereka miliki
saat ini).</p><h2 id=pengerjaan-lebih-lanjut>Pengerjaan lebih lanjut</h2><p>Di masa mendatang, kami berencana untuk membuat <em>policy</em> <em>proxy</em> menjadi lebih
bervariasi dan bukan hanya <em>round robin</em>, misalnya saja <em>master-elected</em> atau <em>sharded</em>.
Kami juga berharap bahwa beberapa <code>Service</code> bisa saja memiliki <em>load balancer</em> yang sebenarnya,
suatu kasus dimana VIP akan secara langsung mengantarkan paket.</p><p>Kami ingin meningkatkan dukungan lebih lanjut untuk <code>Service</code> dengan tingkatan <code>Service</code> L7(HTTP).</p><p>Kami ingin memiliki mode <em>ingress</em> yang lebih fleksibel untuk <code>Service</code> yang
mencakup mode <code>ClusterIP</code>, <code>NodePort</code>, dan <code>LoadBalancer</code> dan banyak lagi.</p><h2 id=detail-mendalam-mengenai-ip-virtual>Detail mendalam mengenai IP virtual</h2><p>Informasi sebelumnya sudah cukup bagi sebagian orang yang hanya ingin menggunakan
<em>Service</em>. Meskipun begitu, terdapat banyak hal yang sebenarnya terjadi dan akan
sangat bermanfaat untuk dipelajari lebih lanjut.</p><h3 id=menghindari-collison>Menghindari <em>collison</em></h3><p>Salah satu filosofi Kubernetes adalah pengguna tidak mungkin menghadapi situasi
dimana apa yang mereka mengalami kegagalan tanpa adanya alasan yang jelas. Dalam kasus ini,
kita akan coba memahami lebih lanjut mengenai <em>network port</em> - pengguna tidak seharusnya memilih
nomor <em>port</em> jika hal itu memungkinkan terjadinya <em>collision</em> dengan pengguna lainnya. Hal ini
merupakan mekanisme isolasi kegagalan.</p><p>Agar pengguna dapat menentukan nomor <em>port</em> bagi <code>Service</code> mereka, kita harus
memastikan bahwa tidak ada dua <code>Service</code> yang mengalami <em>collision</em>. Kita melakukan
hal tersebut dengan cara melakukan alokasi alamat IP pada setiap <code>Service</code>.</p><p>Untuk memastikan setiap <code>Service</code> memiliki alamat IP yang unik, sebuah <em>allocator</em>
internal akan secara atomik melakukan pemetaan alokasi global di dalam <em>etcd</em> ketika
membuat sebuah <code>Service</code> baru. Pemetaan objek harus tersedia pada <em>registry</em> <code>Service</code>
dimana <code>Service</code> akan diberikan sebuah IP, jika tidak, proses pembuatan <code>Service</code> akan gagal
dan sebuah pesan akan memberikan informasi bahwa alamat IP tidak dapat dialokasikan.
Sebuah <em>backgroud</em> <em>controller</em> bertanggung jawab terhadap mekanisme pemetaan tersebut (migrasi
dari versi Kubernetes yang digunakan dalam <em>memory locking</em>) sekaligus melakukan pengecekan
terhadap <em>assignment</em> yang tidak valid yang terjadi akibat intervensi administrator dan melakukan
penghapusan daftar IP yang dialokasikan tapi tidak digunakan oleh <code>Service</code> mana pun.</p><h3 id=ip-dan-vip>IP dan VIP</h3><p>Tidak seperti alamat IP <code>Pod</code>, yang akan di <em>route</em> ke destinasi yang "pasti",
IP <code>Service</code> tidak mengarahkan <em>request</em> hanya pada satu <em>host</em>. Sebagai gantinya,
kita mneggunakan <code>iptables</code> (logika pemrosesan paket pada Linux) untuk melakukan definisi
alamat IP virtual yang secara transparan akan diarahkan sesuai kebutuhan. Ketika klien
dihubungkan pada VIP, trafik yang ada akan secara otomatis dialihkan pada <em>endpoint</em> yang sesuai.
Variabel <em>environment</em> dan DNS untuk <code>Service</code> terdiri dalam bentuk VIP dan <em>port</em>.</p><p>Kami mendukung tiga jenis mode <em>proxy</em> - <em>userspace</em>, <code>iptables</code>, dan <em>ipvs</em> yang memiliki
perbedaan cara kerja satu sama lainnya.</p><h4 id=userspace><em>Userspace</em></h4><p>Sebagai contoh, anggaplah kita memiliki aplikasi <em>image processing</em> seperti yang sudah
disebutkan di atas. Ketika <code>Service</code> <em>backend</em> dibuat, <em>master</em> Kubernetes akan mengalokasikan
sebuah alamat IP virtual, misalnya 10.0.0.1. Dengan asumsi <em>port</em> dari <code>Service</code> tersebut adalah <em>1234</em>,
maka <code>Service</code> tersebut akan diamati oleh semua <em>instance</em> <code>kube-proxy</code> yang ada di klaster.
Ketika sebuah <em>proxy</em> mendapati sebuah <code>Service</code> baru, <em>proxy</em> tersebut akan membuka sebuah <em>port</em>
<em>acak</em>, menyediakan <code>iptables</code> yang mengarahkan VIP pada <em>port</em> yang baru saja dibuat, dan mulai
koneksi pada <em>port</em> tersebut.</p><p>Ketika sebuah klien terhubung ke VIP dan terdapat <em>rules</em> <code>iptables</code>
yang diterapkan, paket akan diarahkan ke <em>port</em> dari <em>proxy</em> <code>Service</code> itu sendiri.
<em>Proxy</em> <code>Service</code> akan memilih sebuah <em>backend</em>, dan mulai melakukan mekanisme <em>proxy</em>
trafik dari klien ke <em>backend</em>.</p><p>Dengan demikian, pemilik <code>Service</code> dapat memilih <em>port</em> mana pun yang dia inginkan
tanpa adanya kemungkinan terjadinya <em>collision</em>. Klien dapat dengan mudah mengakses IP dan <em>port</em>,
tanpa harus mengetahui <code>Pod</code> mana yang sebenarnya diakses.</p><h4 id=iptables><em>Iptables</em></h4><p>Kembali, bayangkan apabila kita memiliki aplikasi <em>image processing</em> seperti yang sudah
disebutkan di atas. Ketika <code>Service</code> <em>backend</em> dibuat, <em>master</em> Kubernetes akan mengalokasikan
sebuah alamat IP virtual, misalnya 10.0.0.1. Dengan asumsi <em>port</em> dari <code>Service</code> tersebut adalah <em>1234</em>,
maka <code>Service</code> tersebut akan diamati oleh semua <em>instance</em> <code>kube-proxy</code> yang ada di klaster.
Ketika sebuah <em>proxy</em> mendapati sebuah <code>Service</code> baru, <em>proxy</em> tersebut akan melakukan instalasi
serangkaian <em>rules</em> <code>iptables</code> yang akan melakukan <em>redirect</em> VIP ke <em>rules</em> tiap <code>Service</code>. <em>Rules</em>
untuk tiap <code>Service</code> ini terkait dengan <em>rules</em> tiap <code>Endpoints</code> yang mengarahkan (destinasi NAT)
ke <em>backend</em>.</p><p>Ketika sebuah klien terhubung ke VIP dan terdapat _rules _iptables
yang diterapkan. Sebuah <em>backend</em> akan dipilih (hal ini dapat dilakukan berdasarkan <em>session affinity</em>
maupun secara <em>acak</em>) dan paket-paket yang ada akan diarahkan ke <em>backend</em>. Tidak seperti mekanisme
yang terjadi di <em>userspace</em>, paket-paket yang ada tidak pernah disalin ke <em>userspace</em>, <code>kube-proxy</code>
tidak harus aktif untuk menjamin kerja VIP, serta IP klien juga tidak perlu diubah.</p><p>Tahapan yang dijalankan sama dengan tahapan yang dijalankan ketika trafik masuk melalui sebuah <em>node-port</em>
atau <em>load-balancer</em>, meskipun pada dua kasus di atas klien IP tidak akan mengalami perubahan.</p><h4 id=ipvs><em>Ipvs</em></h4><p>Operasi <code>iptables</code> berlangsung secara lambat pada klaster dengan skala besar (lebih dari 10.000 <code>Service</code>).
<em>IPVS</em> didesain untuk mekanisme <em>load balance</em> dan berbasis pada <em>hash tables</em> yang berada di dalam <em>kernel</em>.
Dengan demikian kita dapat mendapatkan performa yang konsisten pada jumlah <code>Service</code> yang cukup besar dengan
menggunakan <code>kube-proxy</code> berbasis <em>ipvs</em>. Sementara itu, <code>kube-proxy</code> berbasis <em>ipvs</em> memiliki algoritma
<em>load balance</em> yang lebih bervariasi (misalnya saja <em>least conns</em>, <em>locality</em>, <em>weighted</em>, <em>persistence</em>).</p><h2 id=objek-api>Objek API</h2><p><em>Service</em> merupakan <em>resource</em> <em>top-level</em> pada API Kubernetes.
Penjelasan lebih lanjut mengenai objek API dapat ditemukan pada:
<a href=/docs/reference/generated/kubernetes-api/v1.25/#service-v1-core>objek API <code>Service</code></a>.</p><h2 id=protokol-yang-tersedia>Protokol yang didukung</h2><h3 id=tcp>TCP</h3><div style=margin-top:10px;margin-bottom:10px><b>FEATURE STATE:</b> <code>Kubernetes v1.0 [stable]</code></div><p>Kamu dapat menggunakan TCP untuk <code>Service</code> dengan <em>type</em> apa pun, dan protokol ini merupakan
protokol <em>default</em> yang digunakan.</p><h3 id=udp>UDP</h3><div style=margin-top:10px;margin-bottom:10px><b>FEATURE STATE:</b> <code>Kubernetes v1.0 [stable]</code></div><p>Kamu dapat menggunakan UDP untuk sebagian besar <code>Service</code>.
Untuk <code>Service</code> dengan <em>type=LoadBalancer</em>, dukungan terhadap UDP
bergantung pada penyedia layanan <em>cloud</em> yang kamu gunakan.</p><h3 id=http>HTTP</h3><div style=margin-top:10px;margin-bottom:10px><b>FEATURE STATE:</b> <code>Kubernetes v1.1 [stable]</code></div><p>Apabila penyedia layanan <em>cloud</em> yang kamu gunakan mendukung, kamu dapat menggunakan
<em>Service</em> dengan <em>type</em> <code>LoadBalancer</code> untuk melakukan mekanisme <em>reverse</em> <em>proxy</em>
bagi HTTP/HTTPS, dan melakukan <em>forwarding</em> ke <code>Endpoints</code> dari _Service.</p><div class="alert alert-info note callout" role=alert><strong>Catatan:</strong> Kamu juga dapat menggunakan <a class=glossary-tooltip title='Sebuah obyek API yang mengatur akses eksternal terhadap Service yang ada di dalam klaster, biasanya dalam bentuk request HTTP.' data-toggle=tooltip data-placement=top href=/docs/concepts/services-networking/ingress/ target=_blank aria-label=Ingress>Ingress</a> sebagai salah satu
alternatif penggunaan <code>Service</code> untuk HTTP/HTTPS.</div><h3 id=protokol-proxy>Protokol PROXY</h3><div style=margin-top:10px;margin-bottom:10px><b>FEATURE STATE:</b> <code>Kubernetes v1.1 [stable]</code></div><p>Apabila penyedia layanan <em>cloud</em> yang kamu gunakan mendukung, (misalnya saja, <a href=/id/docs/concepts/cluster-administration/cloud-providers/#aws>AWS</a>),
<em>Service</em> dengan <em>type</em> <code>LoadBalancer</code> untuk melakukan konfigurasi <em>load balancer</em>
di luar Kubernetes sendiri, serta akan melakukan <em>forwarding</em> koneksi yang memiliki prefiks
<a href=https://www.haproxy.org/download/1.8/doc/proxy-protocol.txt>protokol PROXY</a>.</p><p><em>Load balancer</em> akan melakukan serangkaian inisiasi <em>octet</em> yang memberikan
deskripsi koneksi yang datang, dengan bentuk yang menyerupai:</p><pre tabindex=0><code>PROXY TCP4 192.0.2.202 10.0.42.7 12345 7\r\n
</code></pre><p>yang kemudian diikuti data dari klien.</p><h3 id=sctp>SCTP</h3><div style=margin-top:10px;margin-bottom:10px><b>FEATURE STATE:</b> <code>Kubernetes v1.12 [alpha]</code></div><p>Kubernetes memberikan dukungan bagi SCTP sebagai <em>value</em> dari <em>definition</em> yang ada pada
<em>Service</em>, <code>Endpoints</code>, <code>NetworkPolicy</code> dan <code>Pod</code> sebagai fitur <em>alpha</em>. Untuk mengaktifkan fitur ini,
administrator klaster harus mengaktifkan <em>feature gate</em> <em>SCTPSupport</em> pada <em>apiserver</em>, contohnya
<code>“--feature-gates=SCTPSupport=true,...”</code>. Ketika <em>fature gate</em> ini diaktifkan, pengguna dapat
memberikan <em>value</em> SCTP pada <em>field</em> <em>protocol</em> <code>Service</code>, <code>Endpoints</code>, <code>NetworkPolicy</code> dan <code>Pod</code>.
Kubernetes kemudian akan melakukan pengaturan agar jaringan yang digunakan agar jaringan tersebut menggunakan SCTP,
seperti halnya Kubernetes mengatur jaringan agar menggunakan TCP.</p><h4 id=kelemahan-penggunaan-sctp>Perhatian</h4><h5 id=kelemahan-sctp-multihomed>Dukungan untuk asoasiasi <em>multihomed</em> SCTP</h5><p>Dukungan untuk asosiasi <em>multihomed</em> SCTP membutuhkan <em>plugin</em> CNI yang dapat memberikan
pengalokasian <em>multiple interface</em> serta alamat IP pada sebuah <code>Pod</code>.</p><p>NAT untuk asosiasi <em>multihomed</em> SCTP membutuhkan logika khusus pada modul kernel terkait.</p><h5 id=kelemahan-sctp-loadbalancer-service-type><code>Service</code> dengan <em>type=LoadBalancer</em></h5><p>Sebuah <code>Service</code> dengan <em>type</em> <code>LoadBalancer</code> dan protokol SCTP dapat dibuat
hanya jika implementasi <em>load balancer</em> penyedia layanan <em>cloud</em> menyediakan dukungan
bagi protokol SCTP. Apabila hal ini tidak terpenuhi, maka <em>request</em> pembuatan <em>Servixe</em> ini akan ditolak.
<em>Load balancer</em> yang disediakan oleh penyedia layanan <em>cloud</em> yang ada saat ini (<em>Azure</em>, <em>AWS</em>, <em>CloudStack</em>, <em>GCE</em>, <em>OpenStack</em>) tidak mendukung SCTP.</p><h5 id=kelemahan-sctp-windows-os>Windows</h5><p>SCTP tidak didukung pada <em>node</em> berbasis Windows.</p><h5 id=kelemahan-sctp-kube-proxy-userspace><em>Kube-proxy</em> <em>userspace</em></h5><p><em>Kube-proxy</em> tidak mendukung manajemen asosiasi SCTP ketika hal ini dilakukan pada mode
<em>userspace</em></p><h2 id=selanjutnya>Selanjutnya</h2><p>Baca <a href=/docs/tasks/access-application-cluster/connecting-frontend-backend/>Bagaimana cara menghubungkan <em>Front End</em> ke <em>Back End</em> menggunakan sebuah <code>Service</code></a>.</p></div><div class=td-content style=page-break-before:always><h1 id=pg-3a38878244d862dfdb8d7adb32f77584>5.2 - Topologi Service (Service Topology)</h1><div style=margin-top:10px;margin-bottom:10px><b>FEATURE STATE:</b> <code>Kubernetes v1.17 [alpha]</code></div><p>Topologi Service memungkinkan Service untuk
merutekan lalu lintas jaringan berdasarkan topologi Node dalam klaster. Misalnya, suatu
layanan dapat menentukan lalu lintas jaringan yang lebih diutamakan untuk dirutekan ke
beberapa <em>endpoint</em> yang berada pada Node yang sama dengan klien, atau pada
<em>availability zone</em> yang sama.</p><h2 id=pengantar>Pengantar</h2><p>Secara bawaan lalu lintas jaringan yang dikirim ke <code>ClusterIP</code> atau <code>NodePort</code> dari Service
dapat dialihkan ke alamat <em>backend</em> untuk Service tersebut. Sejak Kubernetes 1.7
dimungkinkan untuk merutekan lalu lintas jaringan "eksternal" ke Pod yang berjalan di
Node yang menerima lalu lintas jaringan, tetapi fitur ini tidak didukung untuk <code>ClusterIP</code> dari
Service, dan topologi yang lebih kompleks — seperti rute zonasi —
belum memungkinkan. Fitur topologi Service mengatasi kekurangan ini dengan
mengizinkan pembuat layanan untuk mendefinisikan kebijakan dalam merutekan lalu lintas jaringan
berdasarkan label Node untuk Node-Node asal dan tujuan.</p><p>Dengan menggunakan label Node yang sesuai antara asal dan tujuan, operator dapat
menunjuk kelompok Node mana yang "lebih dekat" dan mana yang "lebih jauh" antara satu sama lain,
dengan menggunakan metrik apa pun yang masuk akal untuk memenuhi persyaratan
dari operator itu. Untuk sebagian besar operator di publik <em>cloud</em>, misalnya, ada
preferensi untuk menjaga layanan lalu lintas jaringan dalam zona yang sama, karena lalu lintas jaringan
antar zona memiliki biaya yang dibebankan, sementara lalu lintas jaringan
dalam zona yang sama tidak ada biaya. Kebutuhan umum lainnya termasuk kemampuan untuk merutekan
lalu lintas jaringan ke Pod lokal yang dikelola oleh sebuah DaemonSet, atau menjaga lalu lintas jaringan ke
Node yang terhubung ke <em>top-of-rack switch</em> yang sama untuk mendapatkan
latensi yang terendah.</p><h2 id=menggunakan-topologi-service>Menggunakan Topologi Service</h2><p>Jika klaster kamu mengaktifkan topologi Service kamu dapat mengontrol rute lalu lintas jaringan Service
dengan mengatur bagian <code>topologyKeys</code> pada spesifikasi Service. Bagian ini
adalah daftar urutan label-label Node yang akan digunakan untuk mengurutkan <em>endpoint</em>
saat mengakses Service ini. Lalu lintas jaringan akan diarahkan ke Node yang nilai
label pertamanya cocok dengan nilai dari Node asal untuk label yang sama. Jika
tidak ada <em>backend</em> untuk Service pada Node yang sesuai, maka label kedua akan
dipertimbangkan, dan seterusnya, sampai tidak ada label yang tersisa.</p><p>Jika tidak ditemukan kecocokan, lalu lintas jaringan akan ditolak, sama seperti jika tidak ada
sama sekali <em>backend</em> untuk Service tersebut. Artinya, <em>endpoint</em> dipilih
berdasarkan kunci topologi yang pertama yang tersedia pada <em>backend</em>. Jika dalam
bagian ini ditentukan dan semua entri tidak memiliki <em>backend</em> yang sesuai dengan
topologi klien, maka Service tidak memiliki <em>backend</em> untuk klien dan koneksi harus
digagalkan. Nilai khusus <code>"*"</code> dapat digunakan untuk mengartikan "topologi
apa saja". Nilai <em>catch-all</em> ini, jika digunakan, maka hanya sebagai
nilai terakhir dalam daftar.</p><p>Jika <code>topologyKeys</code> tidak ditentukan atau kosong, tidak ada batasan topologi
yang akan diterapkan.</p><p>Seandainya sebuah klaster dengan Node yang dilabeli dengan nama <em>host</em> ,
nama zona, dan nama wilayah mereka, maka kamu dapat mengatur nilai
<code>topologyKeys</code> dari sebuah Service untuk mengarahkan lalu lintas jaringan seperti berikut ini.</p><ul><li>Hanya ke <em>endpoint</em> dalam Node yang sama, gagal jika tidak ada <em>endpoint</em> pada Node: <code>["kubernetes.io/hostname"]</code>.</li><li>Lebih memilih ke <em>endpoint</em> dalam Node yang sama, jika tidak ditemukan maka ke <em>endpoint</em> pada zona yang sama, diikuti oleh wilayah yang sama, dan selain itu akan gagal: <code>["kubernetes.io/hostname ", "topology.kubernetes.io/zone", "topology.kubernetes.io/region"]</code>. Ini mungkin berguna, misalnya, dalam kasus di mana lokalitas data sangatlah penting.</li><li>Lebih memilih ke <em>endpoint</em> dalam zona yang sama, tetapi memilih <em>endpoint</em> mana saja yang tersedia apabila tidak ada yang tersedia dalam zona ini: <code>["topology.kubernetes.io/zone ","*"]</code>.</li></ul><h2 id=batasan>Batasan</h2><ul><li>Topologi Service tidak kompatibel dengan <code>externalTrafficPolicy=Local</code>, dan karena itu Service tidak dapat menggunakan kedua fitur ini sekaligus. Dimungkinkan untuk menggunakan kedua fitur pada klaster yang sama untuk Service yang berbeda, bukan untuk Service yang sama.</li><li>Untuk saat ini kunci topologi yang valid hanya terbatas pada <code>kubernetes.io/hostname</code>, <code>topology.kubernetes.io/zone</code>, dan <code>topology.kubernetes.io/region</code>, tetapi akan digeneralisasikan ke label Node yang lain di masa depan.</li><li>Kunci topologi harus merupakan kunci label yang valid dan paling banyak hanya 16 kunci yang dapat ditentukan.</li><li>Nilai <em>catch-all</em>, <code>"*"</code>, harus menjadi nilai terakhir pada kunci topologi, jika nilai itu digunakan.</li></ul><h2 id=contoh>Contoh</h2><p>Berikut ini adalah contoh umum penggunaan fitur topologi Service.</p><h3 id=hanya-pada-endpoint-pada-node-lokal>Hanya pada <em>endpoint</em> pada Node lokal</h3><p>Service yang hanya merutekan ke <em>endpoint</em> pada Node lokal. Jika tidak ada <em>endpoint</em> pada Node, lalu lintas jaringan akan dihentikan:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Service<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>my-service<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>selector</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>app</span>:<span style=color:#bbb> </span>my-app<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>ports</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:green;font-weight:700>protocol</span>:<span style=color:#bbb> </span>TCP<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>port</span>:<span style=color:#bbb> </span><span style=color:#666>80</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>targetPort</span>:<span style=color:#bbb> </span><span style=color:#666>9376</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>topologyKeys</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:#b44>&#34;kubernetes.io/hostname&#34;</span><span style=color:#bbb>
</span></span></span></code></pre></div><h3 id=lebih-memilih-endpoint-pada-node-lokal>Lebih memilih <em>endpoint</em> pada Node lokal</h3><p>Service yang lebih memilih <em>endpoint</em> pada Node lokal, namun akan memilih ke <em>endpoint</em>
dalam klaster jika <em>endpoint</em> pada Node lokal tidak ada:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Service<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>my-service<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>selector</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>app</span>:<span style=color:#bbb> </span>my-app<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>ports</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:green;font-weight:700>protocol</span>:<span style=color:#bbb> </span>TCP<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>port</span>:<span style=color:#bbb> </span><span style=color:#666>80</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>targetPort</span>:<span style=color:#bbb> </span><span style=color:#666>9376</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>topologyKeys</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:#b44>&#34;kubernetes.io/hostname&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:#b44>&#34;*&#34;</span><span style=color:#bbb>
</span></span></span></code></pre></div><h3 id=hanya-untuk-endpoint-pada-zona-atau-wilayah-yang-sama>Hanya untuk <em>endpoint</em> pada zona atau wilayah yang sama</h3><p>Service yang lebih memilih <em>endpoint</em> dalam zona yang sama daripada wilayah yang sama. Jika tidak ada <em>endpoint</em> pada<br>keduanya, maka lalu lintas jaringan akan dihentikan.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Service<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>my-service<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>selector</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>app</span>:<span style=color:#bbb> </span>my-app<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>ports</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:green;font-weight:700>protocol</span>:<span style=color:#bbb> </span>TCP<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>port</span>:<span style=color:#bbb> </span><span style=color:#666>80</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>targetPort</span>:<span style=color:#bbb> </span><span style=color:#666>9376</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>topologyKeys</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:#b44>&#34;topology.kubernetes.io/zone&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:#b44>&#34;topology.kubernetes.io/region&#34;</span><span style=color:#bbb>
</span></span></span></code></pre></div><h3 id=lebih-memilih-endpoint-pada-node-lokal-zona-yang-sama-dan-kemudian-wilayah-yang-sama>Lebih memilih <em>endpoint</em> pada Node lokal, zona yang sama, dan kemudian wilayah yang sama</h3><p>Service yang lebih memilih <em>endpoint</em> pada Node lokal, zona yang sama, dan kemudian baru wilayah yang sama,
namun jika tetap tidak ditemukan maka akan memilih <em>endpoint</em> diseluruh klaster.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Service<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>my-service<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>selector</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>app</span>:<span style=color:#bbb> </span>my-app<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>ports</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:green;font-weight:700>protocol</span>:<span style=color:#bbb> </span>TCP<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>port</span>:<span style=color:#bbb> </span><span style=color:#666>80</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>targetPort</span>:<span style=color:#bbb> </span><span style=color:#666>9376</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>topologyKeys</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:#b44>&#34;kubernetes.io/hostname&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:#b44>&#34;topology.kubernetes.io/zone&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:#b44>&#34;topology.kubernetes.io/region&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:#b44>&#34;*&#34;</span><span style=color:#bbb>
</span></span></span></code></pre></div><h2 id=selanjutnya>Selanjutnya</h2><ul><li>Baca tentang <a href=/docs/tasks/administer-cluster/enabling-service-topology>mengaktifkan topologi Service</a></li><li>Baca <a href=/id/docs/concepts/services-networking/connect-applications-service/>menghubungkan aplikasi dengan Service</a></li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-f51db1097575de8072afe1f5b156a70c>5.3 - EndpointSlice</h1><div style=margin-top:10px;margin-bottom:10px><b>FEATURE STATE:</b> <code>Kubernetes v1.17 [beta]</code></div><p>EndpointSlice menyediakan sebuah cara yang mudah untuk melacak <em>endpoint</em> jaringan dalam sebuah
klaster Kubernetes. EndpointSlice memberikan alternatif yang lebih <em>scalable</em> dan lebih dapat diperluas dibandingkan dengan Endpoints.</p><h2 id=motivasi>Motivasi</h2><p>Endpoints API telah menyediakan sebuah cara yang mudah dan sederhana untuk
melacak <em>endpoint</em> jaringan pada Kubernetes. Sayangnya, seiring dengan besarnya klaster Kubernetes
dan Service, batasan-batasan yang dimiliki API tersebut semakin terlihat.
Terutama, hal tersebut termasuk kendala-kendala mengenai proses <em>scaling</em> <em>endpoint</em> jaringan
dalam jumlah yang besar.</p><p>Karena semua <em>endpoint</em> jaringan untuk sebuah Service disimpan dalam satu sumber daya
Endpoints, sumber daya tersebut dapat menjadi cukup besar. Hal itu dapat mempengaruhi kinerja
dari komponen-komponen Kubernetes (terutama <em>master control plane</em>) dan menyebabkan
lalu lintas jaringan dan pemrosesan yang cukup besar ketika Endpoints berubah.
EndpointSlice membantu kamu menghindari masalah-masalah tersebut dan juga menyediakan platform
yang dapat diperluas untuk fitur-fitur tambahan seperti <em>topological routing</em>.</p><h2 id=sumber-daya-endpointslice>Sumber daya EndpointSlice</h2><p>Pada Kubernetes, sebuah EndpointSlice memiliki referensi-referensi terhadap sekumpulan <em>endpoint</em>
jaringan. <em>Controller</em> EndpointSlice secara otomatis membuat EndpointSlice
untuk sebuah Service Kubernetes ketika sebuah <a class=glossary-tooltip title='Allows users to filter a list of resources based on labels.' data-toggle=tooltip data-placement=top href=/docs/concepts/overview/working-with-objects/labels/ target=_blank aria-label=selektor>selektor</a> dituliskan. EndpointSlice tersebut akan memiliki
referensi-referensi menuju Pod manapun yang cocok dengan selektor pada Service tersebut. EndpointSlice mengelompokkan
<em>endpoint</em> jaringan berdasarkan kombinasi Service dan Port yang unik.
Nama dari sebuah objek EndpointSlice haruslah berupa
<a href=/id/docs/concepts/overview/working-with-objects/names#dns-subdomain-names>nama subdomain DNS</a> yang sah.</p><p>Sebagai contoh, berikut merupakan sampel sumber daya EndpointSlice untuk sebuah Service Kubernetes
yang bernama <code>example</code>.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>discovery.k8s.io/v1beta1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>EndpointSlice<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>example-abc<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>labels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>kubernetes.io/service-name</span>:<span style=color:#bbb> </span>example<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>addressType</span>:<span style=color:#bbb> </span>IPv4<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>ports</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>http<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>protocol</span>:<span style=color:#bbb> </span>TCP<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>port</span>:<span style=color:#bbb> </span><span style=color:#666>80</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>endpoints</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>addresses</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- <span style=color:#b44>&#34;10.1.2.3&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>conditions</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>ready</span>:<span style=color:#bbb> </span><span style=color:#a2f;font-weight:700>true</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>hostname</span>:<span style=color:#bbb> </span>pod-1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>topology</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>kubernetes.io/hostname</span>:<span style=color:#bbb> </span>node-1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>topology.kubernetes.io/zone</span>:<span style=color:#bbb> </span>us-west2-a<span style=color:#bbb>
</span></span></span></code></pre></div><p>Secara bawaan, setiap EndpointSlice yang dikelola oleh <em>controller</em> EndpointSlice tidak akan memiliki
lebih dari 100 <em>endpoint</em>. Di bawah skala tersebut, EndpointSlice akan memetakan 1:1
dengan Endpoints dan Service dan akan memiliki kinerja yang sama.</p><p>EndpointSlice dapat bertindak sebagai sumber kebenaran untuk kube-proxy sebagai acuan mengenai
bagaimana cara untuk merutekan lalu lintas jaringan internal. Ketika diaktifkan, EndpointSlice semestinya memberikan peningkatan
kinerja untuk Service yang memiliki Endpoints dalam jumlah besar.</p><h3 id=tipe-tipe-alamat>Tipe-tipe Alamat</h3><p>EndpointSlice mendukung tiga tipe alamat:</p><ul><li>IPv4</li><li>IPv6</li><li>FQDN (<em>Fully Qualified Domain Name</em>)</li></ul><h3 id=topologi>Topologi</h3><p>Setiap <em>endpoint</em> pada EndpointSlice dapat memiliki informasi topologi yang relevan.
Hal ini digunakan untuk mengindikasikan di mana <em>endpoint</em> berada, berisi informasi mengenai
Node yang bersangkutan, zona, dan wilayah. Ketika nilai-nilai tersebut tersedia,
label-label Topology berikut akan ditambahkan oleh <em>controller</em> EndpointSlice:</p><ul><li><code>kubernetes.io/hostname</code> - Nama dari Node tempat <em>endpoint</em> berada.</li><li><code>topology.kubernetes.io/zone</code> - Zona tempat <em>endpoint</em> berada.</li><li><code>topology.kubernetes.io/region</code> - Region tempat <em>endpoint</em> berada.</li></ul><p>Nilai-nilai dari label-label berikut berasal dari sumber daya yang diasosiasikan dengan tiap
<em>endpoint</em> pada sebuah <em>slice</em>. Label <em>hostname</em> merepresentasikan nilai dari kolom NodeName
pada Pod yang bersangkutan. Label zona dan wilayah merepresentasikan nilai
dari label-label dengan nama yang sama pada Node yang bersangkutan.</p><h3 id=pengelolaan>Pengelolaan</h3><p>Secara bawaan, EndpointSlice dibuat dan dikelola oleh <em>controller</em>
EndpointSlice. Ada berbagai macam kasus lain untuk EndpointSlice, seperti
implementasi <em>service mesh</em>, yang memungkinkan adanya entitas atau <em>controller</em> lain
yang dapat mengelola beberapa EndpointSlice sekaligus. Untuk memastikan beberapa entitas dapat
mengelola EndpointSlice tanpa mengganggu satu sama lain, sebuah
label <code>endpointslice.kubernetes.io/managed-by</code> digunakan untuk mengindikasikan entitas
yang mengelola sebuah EndpointSlice. <em>Controller</em> EndpointSlice akan menambahkan
<code>endpointslice-controller.k8s.io</code> sebagai nilai dari label tersebut pada seluruh
EndpointSlice yang dikelolanya. Entitas lain yang mengelola EndpointSlice juga diharuskan untuk
menambahkan nilai yang unik untuk label tersebut.</p><h3 id=kepemilikan>Kepemilikan</h3><p>Pada kebanyakan kasus, EndpointSlice akan dimiliki oleh Service yang diikutinya. Hal ini diindikasikan dengan referensi pemilik pada tiap EndpointSlice dan
juga label <code>kubernetes.io/service-name</code> yang memudahkan pencarian seluruh
EndpointSlice yang dimiliki oleh sebuah Service.</p><h2 id=controller-endpointslice><em>Controller</em> EndpointSlice</h2><p><em>Controller</em> EndpointSlice mengamati Service dan Pod untuk memastikan EndpointSlice
yang bersangkutan berada dalam kondisi terkini. <em>Controller</em> EndpointSlice akan mengelola EndpointSlice untuk
setiap Service yang memiliki selektor. Ini akan merepresentasikan IP dari Pod
yang cocok dengan selektor dari Service tersebut.</p><h3 id=ukuran-endpointslice>Ukuran EndpointSlice</h3><p>Secara bawaan, jumlah <em>endpoint</em> yang dapat dimiliki tiap EndpointSlice dibatasi sebanyak 100 <em>endpoint</em>. Kamu dapat
mengaturnya melalui opsi <code>--max-endpoints-per-slice</code> <a class=glossary-tooltip title='Komponen control plane yang menjalankan pengontrol.' data-toggle=tooltip data-placement=top href=/docs/reference/generated/kube-controller-manager/ target=_blank aria-label=kube-controller-manager>kube-controller-manager</a> sampai dengan
jumlah maksimum sebanyak 1000 <em>endpoint</em>.</p><h3 id=distribusi-endpointslice>Distribusi EndpointSlice</h3><p>Tiap EndpointSlice memiliki sekumpulan <em>port</em> yang berlaku untuk seluruh <em>endpoint</em> dalam sebuah sumber daya. Ketika nama <em>port</em> digunakan untuk sebuah Service, Pod mungkin mendapatkan
nomor target <em>port</em> yang berbeda-beda untuk nama <em>port</em> yang sama, sehingga membutuhkan
EndpointSlice yang berbeda. Hal ini mirip dengan logika mengenai bagaimana <em>subset</em> dikelompokkan
dengan Endpoints.</p><p><em>Controller EndpointSlice</em> akan mencoba untuk mengisi EndpointSlice sebanyak mungkin, tetapi tidak
secara aktif melakukan <em>rebalance</em> terhadap EndpointSlice tersebut. Logika dari <em>controller</em> cukup sederhana:</p><ol><li>Melakukan iterasi terhadap EndpointSlice yang sudah ada, menghapus <em>endpoint</em> yang sudah tidak lagi
dibutuhkan dan memperbarui <em>endpoint</em> yang sesuai yang mungkin telah berubah.</li><li>Melakukan iterasi terhadap EndpointSlice yang sudah dimodifikasi pada langkah pertama dan
mengisinya dengan <em>endpoint</em> baru yang dibutuhkan.</li><li>Jika masih tersisa <em>endpoint</em> baru untuk ditambahkan, mencoba untuk menambahkannya pada
<em>slice</em> yang tidak berubah sebelumnya dan/atau membuat <em>slice</em> yang baru.</li></ol><p>Terlebih penting, langkah ketiga memprioritaskan untuk membatasi pembaruan EndpointSlice terhadap
distribusi dari EndpointSlice yang benar-benar penuh. Sebagai contoh, jika ada 10
<em>endpoint</em> baru untuk ditambahkan dan ada 2 EndpointSlice yang masing-masing memiliki ruang untuk 5 <em>endpoint</em> baru,
pendekatan ini akan membuat sebuah EndpointSlice baru daripada mengisi 2
EndpointSlice yang sudah ada. Dengan kata lain, pembuatan sebuah EndpointSlice
lebih diutamakan daripada pembaruan beberapa EndpointSlice.</p><p>Dengan kube-proxy yang berjalan pada tiap Node dan mengamati EndpointSlice, setiap perubahan
pada sebuah EndpointSlice menjadi sangat mahal karena hal tersebut akan dikirimkan ke
setiap Node dalam klaster. Pendekatan ini ditujukan untuk membatasi jumlah
perubahan yang perlu dikirimkan ke setiap Node, meskipun hal tersebut berdampak pada banyaknya
EndpointSlice yang tidak penuh.</p><p>Pada praktiknya, distribusi yang kurang ideal seperti ini akan jarang ditemukan. Kebanyakan perubahan yang diproses oleh <em>controller</em> EndpointSlice akan cukup kecil untuk dapat masuk pada
EndpointSlice yang sudah ada, dan jika tidak, cepat atau lambat sebuah EndpointSlice baru
akan segera dibutuhkan. Pembaruan bertahap (<em>rolling update</em>) dari Deployment juga menyediakan sebuah proses
pengemasan ulang EndpointSlice yang natural seiring dengan digantikannya seluruh Pod dan <em>endpoint</em> yang
bersangkutan.</p><h2 id=selanjutnya>Selanjutnya</h2><ul><li><a href=/docs/tasks/administer-cluster/enabling-endpointslices>Mengaktifkan EndpointSlice</a></li><li>Baca <a href=/id/docs/concepts/services-networking/connect-applications-service/>Menghubungkan Aplikasi dengan Service</a></li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-91cb8a4438b003df11bc1c426a81b756>5.4 - DNS untuk Service dan Pod</h1><p>Laman ini menyediakan ikhtisar dari dukungan DNS oleh Kubernetes.</p><h2 id=pendahuluan>Pendahuluan</h2><p>Kubernetes DNS melakukan <em>scheduling</em> DNS Pod dan Service yang ada pada klaster, serta
melakukan konfigurasi kubelet untuk memberikan informasi bagi setiap Container
untuk menggunakan DNS Service IP untuk melakukan resolusi DNS.</p><h3 id=apa-sajakah-yang-mendapatkan-nama-dns>Apa Sajakah yang Mendapatkan Nama DNS?</h3><p>Setiap Service yang didefinisikan di dalam klaster (termasuk server DNS itu sendiri)
memiliki nama DNS. Secara default, sebuah <em>list</em> pencarian DNS pada Pod klien
akan mencantumkan <em>namespace</em> Pod itu sendiri serta domain <em>default</em> klaster. Hal ini dapat diilustrasikan
dengan contoh berikut:</p><p>Asumsikan sebuah Service dengan nama <code>foo</code> pada Kubernetes dengan <em>namespace</em> <code>bar</code>.
Sebuah Pod yang dijalankan di <em>namespace</em> <code>bar</code> dapat melakukan resolusi
terhadap Service ini dengan melakukan <em>query</em> DNS
untuk <code>foo</code>. Sebuah Pod yang dijalankan pada namespace <code>quux</code> dapat melakukan
resolusi Service ini dengan melakukan <em>query</em> DNS untuk <code>foo.bar</code>.</p><p>Bagian di bawah ini akan menampilkan detail tipe rekaman serta <em>layout</em> yang didukung.
<em>Layout</em> atau nama <em>query</em> lain yang dapat digunakan dianggap sebagai detail implementasi
yang bisa saja berubah tanpa adanya pemberitahuan sebelumnya. Untuk informasi spesifikasi
terbaru kamu dapat membaca <a href=https://github.com/kubernetes/dns/blob/master/docs/specification.md>Service Discovery pada Kubernetes berbasis DNS</a>.</p><h2 id=service>Service</h2><h3 id=a-record>A record</h3><p>Service "Normal" (bukan <em>headless</em>) akan diberikan sebuah A <em>record</em> untuk sebuah nama dalam bentuk
<code>my-svc.my-namespace.svc.cluster-domain.example</code>. Inilah yang kemudian digunakan untuk melakukan
resolusi IP klaster dari Service tersebut.</p><p>Service "Headless" (tanpa IP klaster) juga memiliki sebuah A <em>record</em> DNS dengan format
<code>my-svc.my-namespace.svc.cluster-domain.example</code>. Tidak seperti halnya Service normal,
DNS ini akan melakukan resolusi pada serangkauan IP dari Pod yang dipilih oleh Service tadi.
Klien diharapkan untuk mengkonsumsi serangkaian IP ini atau cara lain yang digunakan adalah pemilihan
menggunakan penjadwalan Round-Robin dari set yang ada.</p><h3 id=srv-record>SRV <em>record</em></h3><p>SRV <em>record</em> dibuat untuk port bernama yang merupakan bagian dari Service normal maupun <a href=/id/docs/concepts/services-networking/service/#headless-services>Headless
Services</a>.
Untuk setiap port bernama, SRV <em>record</em> akan memiliki format
<code>_my-port-name._my-port-protocol.my-svc.my-namespace.svc.cluster-domain.example</code>.
Untuk sebuah Service normal, ini akan melakukan resolusi pada nomor port dan
nama domain: <code>my-svc.my-namespace.svc.cluster-domain.example</code>.
Untuk Service headless, ini akan melakukan resolusi pada serangkaian Pod yang merupakan <em>backend</em> dari Service
tersebut yang memiliki format: <code>auto-generated-name.my-svc.my-namespace.svc.cluster-domain.example</code>.</p><h2 id=pod>Pod</h2><h3 id=hostname-pod-dan-field-subdomain>Hostname Pod dan <em>Field</em> Subdomain</h3><p>Saat ini ketika sebuah Pod dibuat, <em>hostname</em>-nya adalah nilai dari <code>metadata.name</code>.</p><p>Spek Pod memiliki <em>field</em> opsional <code>hostname</code>, yang dapat digunakan untuk menspesifikasikan
<em>hostname</em> Pod. Ketika dispesifikasikan, maka nama ini akan didahulukan di atas nama Pod .
Misalnya, sebuah Pod dengan <code>hostname</code> yang diberikan nilai "<code>my-host</code>", maka <em>hostname</em> Pod tersebut akan menjadi "<code>my-host</code>".</p><p>Spek Pod juga memiliki <em>field</em> opsional <code>subdomain</code> yang dapat digunakan untuk menspesifikasikan
subdomain Pod tersebut. Misalnya saja sebuah Pod dengan <code>hostname</code> yang diberi nilai "<code>foo</code>", dan <code>subdomain</code>
yang diberi nilai "<code>bar</code>", pada <em>namespace</em> "<code>my-namespace</code>", akan memiliki <em>fully qualified
domain name</em> (FQDN) "<code>foo.bar.my-namespace.svc.cluster-domain.example</code>".</p><p>Contoh:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Service<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>default-subdomain<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>selector</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>busybox<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>clusterIP</span>:<span style=color:#bbb> </span>None<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>ports</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>foo<span style=color:#bbb> </span><span style=color:#080;font-style:italic># Actually, no port is needed.</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>port</span>:<span style=color:#bbb> </span><span style=color:#666>1234</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>targetPort</span>:<span style=color:#bbb> </span><span style=color:#666>1234</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:#00f;font-weight:700>---</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>busybox1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>labels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>busybox<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>hostname</span>:<span style=color:#bbb> </span>busybox-1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>subdomain</span>:<span style=color:#bbb> </span>default-subdomain<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>busybox:1.28<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>command</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- sleep<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- <span style=color:#b44>&#34;3600&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>busybox<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:#00f;font-weight:700>---</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>busybox2<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>labels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>busybox<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>hostname</span>:<span style=color:#bbb> </span>busybox-2<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>subdomain</span>:<span style=color:#bbb> </span>default-subdomain<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>busybox:1.28<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>command</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- sleep<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- <span style=color:#b44>&#34;3600&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>busybox<span style=color:#bbb>
</span></span></span></code></pre></div><p>Jika terdapat sebuah Service <em>headless</em> memiliki nama yang sama dengan
subdomain dari suatu Pod pada <em>namespace</em> yang sama, server KubeDNS klaster akan mengembalikan
A <em>record</em> untuk FQDN Pod.
Sebagai contoh, misalnya terdapat sebuah Pod dengan <em>hostname</em> "<code>busybox-1</code>" dan
subdomain "<code>default-subdomain</code>", serta sebuah Service <em>headless</em> dengan nama "<code>default-subdomain</code>"<br>berada pada suatu <em>namespace</em> yang sama, maka Pod tersebut akan menerima FQDN dirinya sendiri
sebagai "<code>busybox-1.default-subdomain.my-namespace.svc.cluster-domain.example</code>". DNS mengembalikan
A <em>record</em> pada nama tersebut dan mengarahkannya pada IP Pod. Baik Pod "<code>busybox1</code>" dan
"<code>busybox2</code>" bisa saja memiliki A <em>record</em> yang berbeda.</p><p>Objek Endpoint dapat menspesifikasikan <code>hostname</code> untuk alamat <em>endpoint</em> manapun
beserta dengan alamat IP-nya.</p><div class="alert alert-info note callout" role=alert><strong>Catatan:</strong> Karena A <em>record</em> tidak dibuat untuk sebuah Pod, maka <code>hostname</code> diperlukan
agar sebuah Pod memiliki A <em>record</em>. Sebuah Pod yang tidak memiliki <code>hostname</code>
tetapi memiliki <code>subdomain</code> hanya akan membuat sebuah A <em>record</em> untuk Service <em>headless</em>
(<code>default-subdomain.my-namespace.svc.cluster-domain.example</code>), yang merujuk pada IP dari
Pod tersebut. Pod juga harus dalam status <em>ready</em> agar dapat memiliki A <em>record</em> kecuali
<em>field</em> <code>publishNotReadyAddresses=True</code> diaktifkan pada Service.</div><h3 id=kebijakan-dns-pod>Kebijakan DNS Pod</h3><p>Kebijakan DNS dapat diaktifkan untuk setiap Pod. Kubernetes saat ini mendukung
kebijakan DNS spesifik Pod (<em>pod-specific DNS policies</em>). Kebijakan ini
dispesifikasikan pada <em>field</em> <code>dnsPolicy</code> yang ada pada spek Pod.</p><ul><li>"<code>Default</code>": Pod akan mewarisi konfigurasi resolusi yang berasal dari Node
dimana Pod tersebut dijalankan.
Silakan baca <a href=/docs/tasks/administer-cluster/dns-custom-nameservers/#inheriting-dns-from-the-node>diskusi terkait</a>
untuk detailnya.</li><li>"<code>ClusterFirst</code>": <em>Query</em> DNS apa pun yang tidak sesuai dengan sufiks domain klaster yang sudah dikonfigurasi
misalnya "<code>www.kubernetes.io</code>", akan di-<em>forward</em> ke <em>nameserver</em> <em>upstream</em> yang diwarisi dari Node.
Administrator klaster bisa saja memiliki <em>stub-domain</em> atau DNS <em>usptream</em> lain yang sudah dikonfigurasi.
Silakan lihat <a href=/docs/tasks/administer-cluster/dns-custom-nameservers/#impacts-on-pods>diskusi terkait</a>
untuk detail lebih lanjut mengenai bagaimana <em>query</em> DNS melakukan hal tersebut.</li><li>"<code>ClusterFirstWithHostNet</code>": Untuk Pod yang dijalankan dengan menggunakan <code>hostNetwork</code>, kamu harus
secara eksplisit mengaktifkan kebijakan DNS-nya menjadi "<code>ClusterFirstWithHostNet</code>".</li><li>"<code>None</code>": Hal ini mengisikan sebuah Pod untuk mengabaikan konfigurasi DNS dari <em>environment</em> Kubernetes
Semua pengaturan DNS disediakan menngunakan <em>field</em> <code>dnsConfig</code> yang ada pada spek Pod.
Silakan lihat <a href=#konfigurasi-dns-pod>konfigurasi DNS Pod</a> di bawah.</li></ul><div class="alert alert-info note callout" role=alert><strong>Catatan:</strong> "Default" bukan merupakan nilai <em>default</em> kebijakan DNS.
Jika <code>dnsPolicy</code> tidak secara eksplisit dispesifikasikan, maka “ClusterFirst” akan digunakan.</div><p>Contoh di bawah ini menunjukkan sebuah Pod dengan kebijakan
DNS yang diubah menjadi "<code>ClusterFirstWithHostNet</code>" karena <em>field</em> <code>hostNetwork</code>
diubah menjadi <code>true</code>.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>busybox<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>namespace</span>:<span style=color:#bbb> </span>default<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>busybox:1.28<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>command</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- sleep<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- <span style=color:#b44>&#34;3600&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>imagePullPolicy</span>:<span style=color:#bbb> </span>IfNotPresent<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>busybox<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>restartPolicy</span>:<span style=color:#bbb> </span>Always<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>hostNetwork</span>:<span style=color:#bbb> </span><span style=color:#a2f;font-weight:700>true</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>dnsPolicy</span>:<span style=color:#bbb> </span>ClusterFirstWithHostNet<span style=color:#bbb>
</span></span></span></code></pre></div><h3 id=konfigurasi-dns-pod>Konfigurasi DNS Pod</h3><p>Konfigurasi DNS Pod mengizinkan pengguna untuk memiliki
lebih banyak kontrol terhadap pengaturan DNS pada Pod.</p><p><em>Field</em> <code>dnsConfig</code> bersifat opsional dan dapat digunakan dengan
pengaturan <code>dnsPolicy</code> apa pun.
Meskipun begitu, ketika <em>field</em> <code>dnsPolicy</code> pada sebuah Pod diubah menjadi "<code>None</code>",
maka <em>field</em> <code>dnsConfig</code> harus dispesifikasikan.</p><p>Berikut merupakan properti yang dapat dispesifikasikan oleh pengguna
pada <em>field</em> <code>dnsConfig</code>:</p><ul><li><code>nameservers</code>: serangkaian alamat IP yang akan digunakan sebagai server DNS bagi Pod.
Jumlah maksimum dari IP yang dapat didaftarkan pada <em>field</em> ini adalah tiga buah IP.
Ketika sebuah <code>dnsPolicy</code> pada Pod diubah menjadi "<code>None</code>", maka list ini setidaknya
harus mengandung sebuah alamat IP, selain kasus tersebut properti ini bersifat opsional.
Server yang didaftarkan akan digabungkan di dalam <em>nameserver</em> dasar yang dihasilkan dari
kebijakan DNS yang dispesifikasikan, apabila terdapat duplikat terhadap alamat yang didaftarkan
maka alamat tersebut akan dihapus.</li><li><code>searches</code>: merupakan serangkaian domain pencarian DNS yang digunakan untuk proses <em>lookup</em> pada Pod.
Properti ini bersifat opsional. Ketika dispesifikasikan, list yang disediakan akan digabungkan dengan
nama domain pencarian dasar yang dihasilkan dari kebijakan DNS yang dipilih. Alamat yang duplikat akan dihapus.
Nilai maksimum domain pencarian yang dapat didaftarkan adalah 6 domain.</li><li><code>options</code>: merupakan sebuah list opsional yang berisikan objek dimana setiap objek
bisa saja memiliki properti <code>name</code> (yang bersifat wajib). Isi dari properti ini
akan digabungkan dengan opsi yang dihasilkan kebijakan DNS yang digunakan.
Alamat yang duplikat akan dihapus.</li></ul><p>Di bawah ini merupakan contoh sebuah Pod dengan pengaturan DNS kustom:</p><div class=highlight><div class=copy-code-icon style=text-align:right><a href=https://raw.githubusercontent.com/kubernetes/website/main/content/id/examples/service/networking/custom-dns.yaml download=service/networking/custom-dns.yaml><code>service/networking/custom-dns.yaml</code></a>
<img src=/images/copycode.svg style=max-height:24px;cursor:pointer onclick='copyCode("service-networking-custom-dns-yaml")' title="Copy service/networking/custom-dns.yaml to clipboard"></img></div><div class=includecode id=service-networking-custom-dns-yaml><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>namespace</span>:<span style=color:#bbb> </span>default<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>dns-example<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>test<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>nginx<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>dnsPolicy</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;None&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>dnsConfig</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>nameservers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:#666>1.2.3.4</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>searches</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- ns1.svc.cluster-domain.example<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- my.dns.search.suffix<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>options</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>ndots<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>value</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;2&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>edns0<span style=color:#bbb>
</span></span></span></code></pre></div></div></div><p>Ketika Pod diatas dibuat, maka Container <code>test</code>
memiliki isi berkas <code>/etc/resolv.conf</code> sebagai berikut:</p><pre tabindex=0><code>nameserver 1.2.3.4
search ns1.svc.cluster-domain.example my.dns.search.suffix
options ndots:2 edns0
</code></pre><p>Untuk pengaturan IPv6, <em>path</em> pencarian dan name server harus dispesifikasikan sebagai berikut:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl <span style=color:#a2f>exec</span> -it dns-example -- cat /etc/resolv.conf
</span></span></code></pre></div><p>Keluaran yang dihasilkan akan menyerupai:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>nameserver fd00:79:30::a
</span></span><span style=display:flex><span>search default.svc.cluster-domain.example svc.cluster-domain.example cluster-domain.example
</span></span><span style=display:flex><span>options ndots:5
</span></span></code></pre></div><h3 id=keberadaan-fitur>Keberadaan Fitur (<em>Feature Availability</em>)</h3><p>Keberadaan Pod DNS Config dan DNS Policy "<code>None</code>"" diilustrasikan pada tabel di bawah ini.</p><table><thead><tr><th style=text-align:center>versi k8s</th><th style=text-align:center>Dukungan Fitur</th></tr></thead><tbody><tr><td style=text-align:center>1.14</td><td style=text-align:center>Stable</td></tr><tr><td style=text-align:center>1.10</td><td style=text-align:center>Beta (aktif secara default)</td></tr><tr><td style=text-align:center>1.9</td><td style=text-align:center>Alpha</td></tr></tbody></table><h2 id=selanjutnya>Selanjutnya</h2><p>Untuk petunjuk lebih lanjut mengenai administrasi konfigurasi DNS, kamu dapat membaca
<a href=/docs/tasks/administer-cluster/dns-custom-nameservers/>Cara Melakukan Konfigurasi Service DNS</a></p></div><div class=td-content style=page-break-before:always><h1 id=pg-f804ac0532fcade3966ea2e3769ca031>5.5 - Menghubungkan aplikasi dengan Service</h1><h2 id=model-kubernetes-untuk-menghubungkan-kontainer>Model Kubernetes untuk menghubungkan kontainer</h2><p>Sekarang kamu memiliki aplikasi yang telah direplikasi, kamu dapat mengeksposnya di jaringan. Sebelum membahas pendekatan jaringan di Kubernetes, akan lebih baik jika kamu paham bagaimana jaringan bekerja di dalam <em>Docker</em>.</p><p>Secara <em>default</em>, <em>Docker</em> menggunakan jaringan <em>host</em>, jadi kontainer dapat berkomunikasi dengan kontainer lainnya jika mereka berada di dalam <em>node</em> yang sama. Agar kontainer <em>Docker</em> dapat berkomunikasi antar <em>node</em>, masing-masing kontainer tersebut harus diberikan <em>port</em> yang berbeda di alamat IP <em>node</em> tersebut, yang akan diteruskan (<em>proxied</em>) ke dalam kontainer. Artinya adalah para kontainer di dalam sebuah <em>node</em> harus berkoordinasi <em>port</em> mana yang akan digunakan atau dialokasikan secara otomatis.</p><p>Akan sulit untuk mengkoordinasikan <em>port</em> yang digunakan oleh banyak pengembang. Kubernetes mengasumsikan bahwa <em>Pod</em> dapat berkomunikasi dengan <em>Pod</em> lain, terlepas di <em>Node</em> mana <em>Pod</em> tersebut di <em>deploy</em>. Kubernetes memberikan setiap <em>Pod</em> alamat <em>ClusterIP</em> sehingga kamu tidak perlu secara explisit membuat jalur antara <em>Pod</em> ataupun memetakan <em>port</em> kontainer ke dalam <em>port</em> di dalam <em>Node</em> tersebut. Ini berarti kontainer di dalam sebuah <em>Pod</em> dapat berkomunikasi dengan <em>localhost</em> via <em>port</em>, dan setiap <em>Pod</em> di dalam klaster dapat berkomunikasi tanpa <em>NAT</em>. Panduan ini akan membahas bagaimana kamu dapat menjalankan sebuah layanan atau aplikasi di dalam model jaringan di atas.</p><p>Panduan ini menggunakan server <em>nginx</em> sederhana untuk mendemonstrasikan konsepnya. Konsep yang sama juga ditulis lebih lengkap di <a href=https://kubernetes.io/blog/2015/07/strong-simple-ssl-for-kubernetes>Aplikasi Jenkins CI</a>.</p><h2 id=mengekspos-pod-ke-dalam-klaster>Mengekspos Pod ke dalam klaster</h2><p>Kita melakukan ini di beberapa contoh sebelumnya, tetapi mari kita lakukan sekali lagi dan berfokus pada prespektif jaringannya. Buat sebuah <em>nginx Pod</em>, dan perhatikan bahwa templat tersebut mempunyai spesifikasi <em>port</em> kontainer:</p><div class=highlight><div class=copy-code-icon style=text-align:right><a href=https://raw.githubusercontent.com/kubernetes/website/main/content/id/examples/service/networking/run-my-nginx.yaml download=service/networking/run-my-nginx.yaml><code>service/networking/run-my-nginx.yaml</code></a>
<img src=/images/copycode.svg style=max-height:24px;cursor:pointer onclick='copyCode("service-networking-run-my-nginx-yaml")' title="Copy service/networking/run-my-nginx.yaml to clipboard"></img></div><div class=includecode id=service-networking-run-my-nginx-yaml><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>apps/v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Deployment<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>my-nginx<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>selector</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>matchLabels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>run</span>:<span style=color:#bbb> </span>my-nginx<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>replicas</span>:<span style=color:#bbb> </span><span style=color:#666>2</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>template</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>labels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>run</span>:<span style=color:#bbb> </span>my-nginx<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>my-nginx<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>nginx<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>ports</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span>- <span style=color:green;font-weight:700>containerPort</span>:<span style=color:#bbb> </span><span style=color:#666>80</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>
</span></span></span></code></pre></div></div></div><p>Ini membuat aplikasi tersebut dapat diakses dari <em>node</em> manapun di dalam klaster kamu. Cek lokasi <em>node</em> dimana <em>Pod</em> tersebut berjalan:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl apply -f ./run-my-nginx.yaml
</span></span><span style=display:flex><span>kubectl get pods -l <span style=color:#b8860b>run</span><span style=color:#666>=</span>my-nginx -o wide
</span></span></code></pre></div><pre tabindex=0><code>NAME                        READY     STATUS    RESTARTS   AGE       IP            NODE
my-nginx-3800858182-jr4a2   1/1       Running   0          13s       10.244.3.4    kubernetes-minion-905m
my-nginx-3800858182-kna2y   1/1       Running   0          13s       10.244.2.5    kubernetes-minion-ljyd
</code></pre><p>Cek IP dari <em>Pod</em> kamu:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get pods -l <span style=color:#b8860b>run</span><span style=color:#666>=</span>my-nginx -o yaml | grep podIP
</span></span><span style=display:flex><span>    podIP: 10.244.3.4
</span></span><span style=display:flex><span>    podIP: 10.244.2.5
</span></span></code></pre></div><p>Kamu dapat melakukan akses dengan <em>ssh</em> ke dalam <em>node</em> di dalam klaster dan mengakses IP <em>Pod</em> tersebut menggunakan <em>curl</em>. Perlu dicatat bahwa kontainer tersebut tidak menggunakan <em>port</em> 80 di dalam <em>node</em>, atau aturan <em>NAT</em> khusus untuk merutekan trafik ke dalam <em>Pod</em>. Ini berarti kamu dapat menjalankan banyak <em>nginx Pod</em> di <em>node</em> yang sama dimana setiap <em>Pod</em> dapat menggunakan <em>containerPort</em> yang sama, kamu dapat mengakses semua itu dari <em>Pod</em> lain ataupun dari <em>node</em> di dalam klaster menggunakan IP. Seperti <em>Docker</em>, <em>port</em> masih dapat di publikasi ke dalam * interface node*, tetapi kebutuhan seperti ini sudah berkurang karena model jaringannya.</p><p>Kamu dapat membaca lebih detail <a href=/id/docs/concepts/cluster-administration/networking/#how-to-achieve-this>bagaimana kita melakukan ini</a> jika kamu penasaran.</p><h2 id=membuat-service>Membuat Service</h2><p>Kita mempunyai <em>Pod</em> yang menjalankan <em>nginx</em> di dalam klaster. Teorinya, kamu dapat berkomunikasi ke <em>Pod</em> tersebut secara langsung, tapi apa yang terjadi jika sebuah <em>node</em> mati? <em>Pod</em> di dalam <em>node</em> tersebut ikut mati, dan <em>Deployment</em> akan membuat <em>Pod</em> baru, dengan IP yang berbeda. Ini adalah masalah yang <em>Service</em> selesaikan.</p><p><em>Service</em> Kubernetes adalah sebuah abstraksi yang mendefinisikan sekumpulan <em>Pod</em> yang menyediakan fungsi yang sama dan berjalan di dalam klaster. Saat dibuat, setiap <em>Service</em> diberikan sebuah alamat IP (disebut juga <em>ClusterIP</em>). Alamat ini akan terus ada, dan tidak akan pernah berubah selama <em>Service</em> hidup. <em>Pod</em> dapat berkomunikasi dengan <em>Service</em> dan trafik yang menuju <em>Service</em> tersebut akan otomatis dilakukan mekanisme <em>load balancing</em> ke <em>Pod</em> yang merupakan anggota dari <em>Service</em> tersebut.</p><p>Kamu dapat membuat <em>Service</em> untuk replika 2 <em>nginx</em> dengan <code>kubectl explose</code>:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl expose deployment/my-nginx
</span></span></code></pre></div><pre tabindex=0><code>service/my-nginx exposed
</code></pre><p>Perintah di atas sama dengan <code>kubectl apply -f</code> dengan <em>yaml</em> sebagai berikut:</p><div class=highlight><div class=copy-code-icon style=text-align:right><a href=https://raw.githubusercontent.com/kubernetes/website/main/content/id/examples/service/networking/nginx-svc.yaml download=service/networking/nginx-svc.yaml><code>service/networking/nginx-svc.yaml</code></a>
<img src=/images/copycode.svg style=max-height:24px;cursor:pointer onclick='copyCode("service-networking-nginx-svc-yaml")' title="Copy service/networking/nginx-svc.yaml to clipboard"></img></div><div class=includecode id=service-networking-nginx-svc-yaml><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Service<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>my-nginx<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>labels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>run</span>:<span style=color:#bbb> </span>my-nginx<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>ports</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>port</span>:<span style=color:#bbb> </span><span style=color:#666>80</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>protocol</span>:<span style=color:#bbb> </span>TCP<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>selector</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>run</span>:<span style=color:#bbb> </span>my-nginx<span style=color:#bbb>
</span></span></span></code></pre></div></div></div><p>Spesifikasi ini akan membuat <em>Service</em> yang membuka <em>TCP port 80</em> di setiap <em>Pod</em> dengan label <code>run: my-nginx</code> dan mengeksposnya ke dalam <em>port Service</em> (<code>targetPort</code>: adalah port kontainer yang menerima trafik, <code>port</code> adalah <em>service port</em> yang dapat berupa <em>port</em> apapun yang digunakan <em>Pod</em> lain untuk mengakses <em>Service</em>).</p><p>Lihat <a href=/docs/reference/generated/kubernetes-api/v1.25/#service-v1-core>Service</a>
objek <em>API</em> untuk melihat daftar <em>field</em> apa saja yang didukung di definisi <em>Service</em>. Cek <em>Service</em> kamu:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get svc my-nginx
</span></span></code></pre></div><pre tabindex=0><code>NAME       TYPE        CLUSTER-IP     EXTERNAL-IP   PORT(S)   AGE
my-nginx   ClusterIP   10.0.162.149   &lt;none&gt;        80/TCP    21s
</code></pre><p>Seperti yang disebutkan sebelumnya, sebuah <em>Service</em> berisi sekumpulan <em>Pod</em>. <em>Pod</em> diekspos melalui <code>endpoints</code>. <em>Service selector</em> akan mengecek <em>Pod</em> secara terus-menerus dan hasilnya akan dikirim (<em>POSTed</em>) ke objek <em>endpoint</em> yang bernama <code>my-nginx</code>. Saat sebuah <em>Pod</em> mati, <em>IP Pod</em> di dalam <em>endpoint</em> tersebut akan otomatis dihapus, dan <em>Pod</em> baru yang sesuai dengan <em>Service selector</em> akan otomatis ditambahkan ke dalam <em>endpoint</em>. Cek <em>endpoint</em> dan perhatikan bahwa IP sama dengan <em>Pod</em> yang dibuat di langkah pertama:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl describe svc my-nginx
</span></span></code></pre></div><pre tabindex=0><code>Name:                my-nginx
Namespace:           default
Labels:              run=my-nginx
Annotations:         &lt;none&gt;
Selector:            run=my-nginx
Type:                ClusterIP
IP:                  10.0.162.149
Port:                &lt;unset&gt; 80/TCP
Endpoints:           10.244.2.5:80,10.244.3.4:80
Session Affinity:    None
Events:              &lt;none&gt;
</code></pre><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get ep my-nginx
</span></span></code></pre></div><pre tabindex=0><code>NAME       ENDPOINTS                     AGE
my-nginx   10.244.2.5:80,10.244.3.4:80   1m
</code></pre><p>Kamu sekarang dapat melakukan <em>curl</em> ke dalam <em>nginx Service</em> di <code>&lt;CLUSTER-IP>:&lt;PORT></code> dari <em>node</em> manapun di klaster. Perlu dicatat bahwa <em>Service IP</em> adalah IP virtual, IP tersebut tidak pernah ada di <em>interface node</em> manapun. Jika kamu penasaran bagaimana konsep ini bekerja, kamu dapat membaca lebih lanjut tentang <a href=/id/docs/concepts/services-networking/service/#virtual-ips-and-service-proxies>service proxy</a>.</p><h2 id=mengakses-service>Mengakses Service</h2><p>Kubernetes mendukung 2 mode utama untuk menemukan sebuah <em>Service</em> - variabel <em>environment</em> dan <em>DNS</em>.
<em>DNS</em> membutuhkan <a href=http://releases.k8s.io/main/cluster/addons/dns/coredns>tambahan CoreDNS di dalam klaster</a>.</p><h3 id=variabel-environment>Variabel Environment</h3><p>Saat sebuah <em>Pod</em> berjalan di <em>Node</em>, <em>kubelet</em> akan menambahkan variabel <em>environment</em> untuk setiap <em>Service</em> yang aktif ke dalam <em>Pod</em>. Ini menimbulkan beberapa masalah. Untuk melihatnya, periksa <em>environment</em> dari <em>Pod nginx</em> yang telah kamu buat (nama <em>Pod</em>-mu akan berbeda-beda):</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl <span style=color:#a2f>exec</span> my-nginx-3800858182-jr4a2 -- printenv | grep SERVICE
</span></span></code></pre></div><pre tabindex=0><code>KUBERNETES_SERVICE_HOST=10.0.0.1
KUBERNETES_SERVICE_PORT=443
KUBERNETES_SERVICE_PORT_HTTPS=443
</code></pre><p>Perlu dicatat tidak ada variabel <em>environment</em> yang menunjukan <em>Service</em> yang kamu buat. Ini terjadi karena kamu membuat replika terlebih dahulu sebelum membuat <em>Service</em>. Kerugian lain ditimbulkan adalah bahwa komponen <em>scheduler</em> mungkin saja bisa menempatkan semua <em>Pod</em> di dalam satu <em>Node</em>, yang akan membuat keseluruhan <em>Service</em> mati jika <em>Node</em> tersebut mati. Kita dapat menyelesaikan masalah ini dengan menghapus 2 <em>Pod</em> tersebut dan menunggu <em>Deployment</em> untuk membuat <em>Pod</em> kembali. Kali ini <em>Service</em> ada sebelum replika <em>Pod</em> tersebut ada. Ini akan memberikan kamu <em>scheduler-level Service</em> (jika semua <em>Node</em> kamu mempunyai kapasitas yang sama), serta variabel <em>environment</em> yang benar:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl scale deployment my-nginx --replicas<span style=color:#666>=</span>0; kubectl scale deployment my-nginx --replicas<span style=color:#666>=</span>2;
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>kubectl get pods -l <span style=color:#b8860b>run</span><span style=color:#666>=</span>my-nginx -o wide
</span></span></code></pre></div><pre tabindex=0><code>NAME                        READY     STATUS    RESTARTS   AGE     IP            NODE
my-nginx-3800858182-e9ihh   1/1       Running   0          5s      10.244.2.7    kubernetes-minion-ljyd
my-nginx-3800858182-j4rm4   1/1       Running   0          5s      10.244.3.8    kubernetes-minion-905m
</code></pre><p>Kamu mungkin saja melihat <em>Pod</em> dengan nama yang berbeda, hal ini terjadi karena <em>Pod-Pod</em> itu dihapus dan dibuat ulang.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl <span style=color:#a2f>exec</span> my-nginx-3800858182-e9ihh -- printenv | grep SERVICE
</span></span></code></pre></div><pre tabindex=0><code>KUBERNETES_SERVICE_PORT=443
MY_NGINX_SERVICE_HOST=10.0.162.149
KUBERNETES_SERVICE_HOST=10.0.0.1
MY_NGINX_SERVICE_PORT=80
KUBERNETES_SERVICE_PORT_HTTPS=443
</code></pre><h3 id=dns>DNS</h3><p>Kubernetes menawarkan sebuah layanan <em>DNS</em> klaster tambahan yang secara otomatis memberikan sebuah nama <em>dns</em> pada <em>Service</em>. Kamu dapat mengecek jika <em>DNS</em> berjalan di dalam klaster Kubernetes:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get services kube-dns --namespace<span style=color:#666>=</span>kube-system
</span></span></code></pre></div><pre tabindex=0><code>NAME       TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)         AGE
kube-dns   ClusterIP   10.0.0.10    &lt;none&gt;        53/UDP,53/TCP   8m
</code></pre><p>Jika <em>DNS</em> belum berjalan, kamu dapat <a href=http://releases.k8s.io/main/cluster/addons/dns/kube-dns/README.md#how-do-i-configure-it>mengaktifkannya</a>.</p><p>Sisa panduan ini mengasumsikan kamu mempunyai <em>Service</em> dengan IP (my-nginx), dan sebuah server <em>DNS</em> yang memberikan nama ke dalam IP tersebut (CoreDNS klaster), jadi kamu dapat berkomunikasi dengan <em>Service</em> dari <em>Pod</em> lain di dalam klaster menggunakan metode standar (contohnya <em>gethostbyname</em>). Jalankan aplikasi <em>curl</em> lain untuk melakukan pengujian ini:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl run curl --image<span style=color:#666>=</span>radial/busyboxplus:curl -i --tty
</span></span></code></pre></div><pre tabindex=0><code>Waiting for pod default/curl-131556218-9fnch to be running, status is Pending, pod ready: false
Hit enter for command prompt
</code></pre><p>Lalu tekan <em>enter</em> dan jalankan <code>nslookup my-nginx</code>:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span><span style=color:#666>[</span> root@curl-131556218-9fnch:/ <span style=color:#666>]</span>$ nslookup my-nginx
</span></span><span style=display:flex><span>Server:    10.0.0.10
</span></span><span style=display:flex><span>Address 1: 10.0.0.10
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>Name:      my-nginx
</span></span><span style=display:flex><span>Address 1: 10.0.162.149
</span></span></code></pre></div><h2 id=mengamankan-service>Mengamankan Service</h2><p>Hingga sekarang kita hanya mengakses <em>nginx</em> server dari dalam klaster. Sebelum mengekspos <em>Service</em> ke internet, kamu harus memastikan bahwa kanal komunikasi aman. Untuk melakukan hal tersebut, kamu membutuhkan:</p><ul><li><em>Self signed certificates</em> untuk <em>https</em> (kecuali jika kamu sudah mempunyai <em>identity certificate</em>)</li><li>Sebuah server <em>nginx</em> yang terkonfigurasi untuk menggunakan <em>certificate</em> tersebut</li><li>Sebuah <a href=/id/docs/concepts/configuration/secret/>secret</a> yang membuat setifikat tersebut dapat diakses oleh <em>pod</em></li></ul><p>Kamu dapat melihat semua itu di <a href=https://github.com/kubernetes/examples/tree/main/staging/https-nginx/>contoh nginx https</a>. Contoh ini mengaharuskan kamu melakukan instalasi <em>go</em> dan <em>make</em>. Jika kamu tidak ingin melakukan instalasi tersebut, ikuti langkah-langkah manualnya nanti, singkatnya:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>make keys <span style=color:#b8860b>KEY</span><span style=color:#666>=</span>/tmp/nginx.key <span style=color:#b8860b>CERT</span><span style=color:#666>=</span>/tmp/nginx.crt
</span></span><span style=display:flex><span>kubectl create secret tls nginxsecret --key /tmp/nginx.key --cert /tmp/nginx.crt
</span></span></code></pre></div><pre tabindex=0><code>secret/nginxsecret created
</code></pre><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get secrets
</span></span></code></pre></div><pre tabindex=0><code>NAME                  TYPE                                  DATA      AGE
default-token-il9rc   kubernetes.io/service-account-token   1         1d
nginxsecret           Opaque                                2         1m
</code></pre><p>Berikut ini adalah langkah-langkah manual yang harus diikuti jika kamu mengalami masalah menjalankan <em>make</em> (pada windows contohnya):</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span><span style=color:#080;font-style:italic>#membuat sebuah key-pair public private</span>
</span></span><span style=display:flex><span>openssl req -x509 -nodes -days <span style=color:#666>365</span> -newkey rsa:2048 -keyout /d/tmp/nginx.key -out /d/tmp/nginx.crt -subj <span style=color:#b44>&#34;/CN=my-nginx/O=my-nginx&#34;</span>
</span></span><span style=display:flex><span><span style=color:#080;font-style:italic>#rubah key tersebut ke dalam pengkodean base64</span>
</span></span><span style=display:flex><span>cat /d/tmp/nginx.crt | base64
</span></span><span style=display:flex><span>cat /d/tmp/nginx.key | base64
</span></span></code></pre></div><p>Gunakan hasil keluaran dari perintah sebelumnya untuk membuat sebuah file <em>yaml</em> seperti berikut. Nilai yang dikodekan <em>base64</em> harus berada di dalam satu baris.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;v1&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;Secret&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;nginxsecret&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>namespace</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;default&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>data</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>nginx.crt</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSURIekNDQWdlZ0F3SUJBZ0lKQUp5M3lQK0pzMlpJTUEwR0NTcUdTSWIzRFFFQkJRVUFNQ1l4RVRBUEJnTlYKQkFNVENHNW5hVzU0YzNaak1SRXdEd1lEVlFRS0V3aHVaMmx1ZUhOMll6QWVGdzB4TnpFd01qWXdOekEzTVRKYQpGdzB4T0RFd01qWXdOekEzTVRKYU1DWXhFVEFQQmdOVkJBTVRDRzVuYVc1NGMzWmpNUkV3RHdZRFZRUUtFd2h1CloybHVlSE4yWXpDQ0FTSXdEUVlKS29aSWh2Y05BUUVCQlFBRGdnRVBBRENDQVFvQ2dnRUJBSjFxSU1SOVdWM0IKMlZIQlRMRmtobDRONXljMEJxYUhIQktMSnJMcy8vdzZhU3hRS29GbHlJSU94NGUrMlN5ajBFcndCLzlYTnBwbQppeW1CL3JkRldkOXg5UWhBQUxCZkVaTmNiV3NsTVFVcnhBZW50VWt1dk1vLzgvMHRpbGhjc3paenJEYVJ4NEo5Ci82UVRtVVI3a0ZTWUpOWTVQZkR3cGc3dlVvaDZmZ1Voam92VG42eHNVR0M2QURVODBpNXFlZWhNeVI1N2lmU2YKNHZpaXdIY3hnL3lZR1JBRS9mRTRqakxCdmdONjc2SU90S01rZXV3R0ljNDFhd05tNnNTSzRqYUNGeGpYSnZaZQp2by9kTlEybHhHWCtKT2l3SEhXbXNhdGp4WTRaNVk3R1ZoK0QrWnYvcW1mMFgvbVY0Rmo1NzV3ajFMWVBocWtsCmdhSXZYRyt4U1FVQ0F3RUFBYU5RTUU0d0hRWURWUjBPQkJZRUZPNG9OWkI3YXc1OUlsYkROMzhIYkduYnhFVjcKTUI4R0ExVWRJd1FZTUJhQUZPNG9OWkI3YXc1OUlsYkROMzhIYkduYnhFVjdNQXdHQTFVZEV3UUZNQU1CQWY4dwpEUVlKS29aSWh2Y05BUUVGQlFBRGdnRUJBRVhTMW9FU0lFaXdyMDhWcVA0K2NwTHI3TW5FMTducDBvMm14alFvCjRGb0RvRjdRZnZqeE04Tzd2TjB0clcxb2pGSW0vWDE4ZnZaL3k4ZzVaWG40Vm8zc3hKVmRBcStNZC9jTStzUGEKNmJjTkNUekZqeFpUV0UrKzE5NS9zb2dmOUZ3VDVDK3U2Q3B5N0M3MTZvUXRUakViV05VdEt4cXI0Nk1OZWNCMApwRFhWZmdWQTRadkR4NFo3S2RiZDY5eXM3OVFHYmg5ZW1PZ05NZFlsSUswSGt0ejF5WU4vbVpmK3FqTkJqbWZjCkNnMnlwbGQ0Wi8rUUNQZjl3SkoybFIrY2FnT0R4elBWcGxNSEcybzgvTHFDdnh6elZPUDUxeXdLZEtxaUMwSVEKQ0I5T2wwWW5scE9UNEh1b2hSUzBPOStlMm9KdFZsNUIyczRpbDlhZ3RTVXFxUlU9Ci0tLS0tRU5EIENFUlRJRklDQVRFLS0tLS0K&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>nginx.key</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;LS0tLS1CRUdJTiBQUklWQVRFIEtFWS0tLS0tCk1JSUV2UUlCQURBTkJna3Foa2lHOXcwQkFRRUZBQVNDQktjd2dnU2pBZ0VBQW9JQkFRQ2RhaURFZlZsZHdkbFIKd1V5eFpJWmVEZWNuTkFhbWh4d1NpeWF5N1AvOE9ta3NVQ3FCWmNpQ0RzZUh2dGtzbzlCSzhBZi9WemFhWm9zcApnZjYzUlZuZmNmVUlRQUN3WHhHVFhHMXJKVEVGSzhRSHA3VkpMcnpLUC9QOUxZcFlYTE0yYzZ3MmtjZUNmZitrCkU1bEVlNUJVbUNUV09UM3c4S1lPNzFLSWVuNEZJWTZMMDUrc2JGQmd1Z0ExUE5JdWFubm9UTWtlZTRuMG4rTDQKb3NCM01ZUDhtQmtRQlAzeE9JNHl3YjREZXUraURyU2pKSHJzQmlIT05Xc0RadXJFaXVJMmdoY1kxeWIyWHI2UAozVFVOcGNSbC9pVG9zQngxcHJHclk4V09HZVdPeGxZZmcvbWIvNnBuOUYvNWxlQlkrZStjSTlTMkQ0YXBKWUdpCkwxeHZzVWtGQWdNQkFBRUNnZ0VBZFhCK0xkbk8ySElOTGo5bWRsb25IUGlHWWVzZ294RGQwci9hQ1Zkank4dlEKTjIwL3FQWkUxek1yall6Ry9kVGhTMmMwc0QxaTBXSjdwR1lGb0xtdXlWTjltY0FXUTM5SjM0VHZaU2FFSWZWNgo5TE1jUHhNTmFsNjRLMFRVbUFQZytGam9QSFlhUUxLOERLOUtnNXNrSE5pOWNzMlY5ckd6VWlVZWtBL0RBUlBTClI3L2ZjUFBacDRuRWVBZmI3WTk1R1llb1p5V21SU3VKdlNyblBESGtUdW1vVlVWdkxMRHRzaG9reUxiTWVtN3oKMmJzVmpwSW1GTHJqbGtmQXlpNHg0WjJrV3YyMFRrdWtsZU1jaVlMbjk4QWxiRi9DSmRLM3QraTRoMTVlR2ZQegpoTnh3bk9QdlVTaDR2Q0o3c2Q5TmtEUGJvS2JneVVHOXBYamZhRGR2UVFLQmdRRFFLM01nUkhkQ1pKNVFqZWFKClFGdXF4cHdnNzhZTjQyL1NwenlUYmtGcVFoQWtyczJxWGx1MDZBRzhrZzIzQkswaHkzaE9zSGgxcXRVK3NHZVAKOWRERHBsUWV0ODZsY2FlR3hoc0V0L1R6cEdtNGFKSm5oNzVVaTVGZk9QTDhPTm1FZ3MxMVRhUldhNzZxelRyMgphRlpjQ2pWV1g0YnRSTHVwSkgrMjZnY0FhUUtCZ1FEQmxVSUUzTnNVOFBBZEYvL25sQVB5VWs1T3lDdWc3dmVyClUycXlrdXFzYnBkSi9hODViT1JhM05IVmpVM25uRGpHVHBWaE9JeXg5TEFrc2RwZEFjVmxvcG9HODhXYk9lMTAKMUdqbnkySmdDK3JVWUZiRGtpUGx1K09IYnRnOXFYcGJMSHBzUVpsMGhucDBYSFNYVm9CMUliQndnMGEyOFVadApCbFBtWmc2d1BRS0JnRHVIUVV2SDZHYTNDVUsxNFdmOFhIcFFnMU16M2VvWTBPQm5iSDRvZUZKZmcraEppSXlnCm9RN3hqWldVR3BIc3AyblRtcHErQWlSNzdyRVhsdlhtOElVU2FsbkNiRGlKY01Pc29RdFBZNS9NczJMRm5LQTQKaENmL0pWb2FtZm1nZEN0ZGtFMXNINE9MR2lJVHdEbTRpb0dWZGIwMllnbzFyb2htNUpLMUI3MkpBb0dBUW01UQpHNDhXOTVhL0w1eSt5dCsyZ3YvUHM2VnBvMjZlTzRNQ3lJazJVem9ZWE9IYnNkODJkaC8xT2sybGdHZlI2K3VuCnc1YytZUXRSTHlhQmd3MUtpbGhFZDBKTWU3cGpUSVpnQWJ0LzVPbnlDak9OVXN2aDJjS2lrQ1Z2dTZsZlBjNkQKckliT2ZIaHhxV0RZK2Q1TGN1YSt2NzJ0RkxhenJsSlBsRzlOZHhrQ2dZRUF5elIzT3UyMDNRVVV6bUlCRkwzZAp4Wm5XZ0JLSEo3TnNxcGFWb2RjL0d5aGVycjFDZzE2MmJaSjJDV2RsZkI0VEdtUjZZdmxTZEFOOFRwUWhFbUtKCnFBLzVzdHdxNWd0WGVLOVJmMWxXK29xNThRNTBxMmk1NVdUTThoSDZhTjlaMTltZ0FGdE5VdGNqQUx2dFYxdEYKWSs4WFJkSHJaRnBIWll2NWkwVW1VbGc9Ci0tLS0tRU5EIFBSSVZBVEUgS0VZLS0tLS0K&#34;</span><span style=color:#bbb>
</span></span></span></code></pre></div><p>Sekarang buat <em>secrets</em> menggunakan file tersebut:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl apply -f nginxsecrets.yaml
</span></span><span style=display:flex><span>kubectl get secrets
</span></span></code></pre></div><pre tabindex=0><code>NAME                  TYPE                                  DATA      AGE
default-token-il9rc   kubernetes.io/service-account-token   1         1d
nginxsecret           Opaque                                2         1m
</code></pre><p>Sekarang modifikasi replika <em>nginx</em> untuk menjalankan server <em>https</em> menggunakan <em>certificate</em> di dalam <em>secret</em> dan <em>Service</em> untuk mengekspos semua <em>port</em> (80 dan 443):</p><div class=highlight><div class=copy-code-icon style=text-align:right><a href=https://raw.githubusercontent.com/kubernetes/website/main/content/id/examples/service/networking/nginx-secure-app.yaml download=service/networking/nginx-secure-app.yaml><code>service/networking/nginx-secure-app.yaml</code></a>
<img src=/images/copycode.svg style=max-height:24px;cursor:pointer onclick='copyCode("service-networking-nginx-secure-app-yaml")' title="Copy service/networking/nginx-secure-app.yaml to clipboard"></img></div><div class=includecode id=service-networking-nginx-secure-app-yaml><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Service<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>my-nginx<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>labels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>run</span>:<span style=color:#bbb> </span>my-nginx<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>type</span>:<span style=color:#bbb> </span>NodePort<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>ports</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>port</span>:<span style=color:#bbb> </span><span style=color:#666>8080</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>targetPort</span>:<span style=color:#bbb> </span><span style=color:#666>80</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>protocol</span>:<span style=color:#bbb> </span>TCP<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>http<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>port</span>:<span style=color:#bbb> </span><span style=color:#666>443</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>protocol</span>:<span style=color:#bbb> </span>TCP<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>https<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>selector</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>run</span>:<span style=color:#bbb> </span>my-nginx<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:#00f;font-weight:700>---</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>apps/v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Deployment<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>my-nginx<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>selector</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>matchLabels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>run</span>:<span style=color:#bbb> </span>my-nginx<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>replicas</span>:<span style=color:#bbb> </span><span style=color:#666>1</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>template</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>labels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>run</span>:<span style=color:#bbb> </span>my-nginx<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>volumes</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>secret-volume<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>secret</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>secretName</span>:<span style=color:#bbb> </span>nginxsecret<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>nginxhttps<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>bprashanth/nginxhttps:1.0<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>ports</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span>- <span style=color:green;font-weight:700>containerPort</span>:<span style=color:#bbb> </span><span style=color:#666>443</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span>- <span style=color:green;font-weight:700>containerPort</span>:<span style=color:#bbb> </span><span style=color:#666>80</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>volumeMounts</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span>- <span style=color:green;font-weight:700>mountPath</span>:<span style=color:#bbb> </span>/etc/nginx/ssl<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>secret-volume<span style=color:#bbb>
</span></span></span></code></pre></div></div></div><p>Berikut catatan penting tentang manifes <em>nginx-secure-app</em>:</p><ul><li>di dalam file tersebut, ada spesifikasi <em>Deployment</em> dan <em>Service</em></li><li>ada <a href=https://github.com/kubernetes/examples/tree/main/staging/https-nginx/default.conf>server nginx</a> yang melayani trafik <em>HTTP</em> di <em>port</em> 80 dan trafik <em>HTTPS</em> di <em>port</em> 443, dan <em>Service nginx</em> yang mengekspos kedua <em>port</em> tersebut.</li><li>Setiap kontainer mempunyai akses ke <em>key</em> melalui <em>volume</em> yang di <em>mount</em> pada <code>/etc/nginx/ssl</code>. Ini adalah konfigurasi sebelum server <em>nginx</em> dijalankan.</li></ul><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl delete deployments,svc my-nginx; kubectl create -f ./nginx-secure-app.yaml
</span></span></code></pre></div><p>Pada tahapan ini, kamu dapat berkomunikasi dengan server <em>nginx</em> dari <em>node</em> manapun.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get pods -l <span style=color:#b8860b>run</span><span style=color:#666>=</span>my-nginx -o custom-columns<span style=color:#666>=</span>POD_IP:.status.podIPs
</span></span><span style=display:flex><span>    POD_IP
</span></span><span style=display:flex><span>    <span style=color:#666>[</span>map<span style=color:#666>[</span>ip:10.244.3.5<span style=color:#666>]]</span>
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>node $ curl -k https://10.244.3.5
</span></span><span style=display:flex><span>...
</span></span><span style=display:flex><span>&lt;h1&gt;Welcome to nginx!&lt;/h1&gt;
</span></span></code></pre></div><p>Perlu dicatat bahwa kita menggunakan parameter <code>-k</code> saat menggunakan <em>curl</em>, ini karena kita tidak tau apapun tentang <em>Pod</em> yang menjalankan <em>nginx</em> saat pembuatan seritifikat, jadi kita harus memberitahu <em>curl</em> untuk mengabaikan ketidakcocokan <em>CName</em>. Dengan membuat <em>Service</em>, kita menghubungkan <em>CName</em> yang digunakan pada <em>certificate</em> dengan nama pada <em>DNS</em> yang digunakan <em>Pod</em>. Lakukan pengujian dari sebuah <em>Pod</em> (<em>secret</em> yang sama digunakan untuk agar mudah, <em>Pod</em> tersebut hanya membutuhkan <em>nginx.crt</em> untuk mengakses <em>Service</em>)</p><div class=highlight><div class=copy-code-icon style=text-align:right><a href=https://raw.githubusercontent.com/kubernetes/website/main/content/id/examples/service/networking/curlpod.yaml download=service/networking/curlpod.yaml><code>service/networking/curlpod.yaml</code></a>
<img src=/images/copycode.svg style=max-height:24px;cursor:pointer onclick='copyCode("service-networking-curlpod-yaml")' title="Copy service/networking/curlpod.yaml to clipboard"></img></div><div class=includecode id=service-networking-curlpod-yaml><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>apps/v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Deployment<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>curl-deployment<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>selector</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>matchLabels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>app</span>:<span style=color:#bbb> </span>curlpod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>replicas</span>:<span style=color:#bbb> </span><span style=color:#666>1</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>template</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>labels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>app</span>:<span style=color:#bbb> </span>curlpod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>volumes</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>secret-volume<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>secret</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>secretName</span>:<span style=color:#bbb> </span>nginxsecret<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>curlpod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>command</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span>- sh<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span>- -c<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span>- while true; do sleep 1; done<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>radial/busyboxplus:curl<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>volumeMounts</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span>- <span style=color:green;font-weight:700>mountPath</span>:<span style=color:#bbb> </span>/etc/nginx/ssl<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>secret-volume<span style=color:#bbb>
</span></span></span></code></pre></div></div></div><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl apply -f ./curlpod.yaml
</span></span><span style=display:flex><span>kubectl get pods -l <span style=color:#b8860b>app</span><span style=color:#666>=</span>curlpod
</span></span></code></pre></div><pre tabindex=0><code>NAME                               READY     STATUS    RESTARTS   AGE
curl-deployment-1515033274-1410r   1/1       Running   0          1m
</code></pre><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl <span style=color:#a2f>exec</span> curl-deployment-1515033274-1410r -- curl https://my-nginx --cacert /etc/nginx/ssl/nginx.crt
</span></span><span style=display:flex><span>...
</span></span><span style=display:flex><span>&lt;title&gt;Welcome to nginx!&lt;/title&gt;
</span></span><span style=display:flex><span>...
</span></span></code></pre></div><h2 id=mengekspos-service>Mengekspos Service</h2><p>Kamu mungkin ingin mengekspos <em>Service</em> ke alamat IP eksternal. Kubernetes mendukung dua cara untuk melakukan ini: <em>NodePort</em> dan <em>LoadBalancer</em>. <em>Service</em> yang dibuat tadi sudah menggunakan <code>NodePort</code>, jadi replika <em>nginx</em> sudah siap untuk menerima trafik dari internet jika <em>Node</em> kamu mempunyai IP publik.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get svc my-nginx -o yaml | grep nodePort -C <span style=color:#666>5</span>
</span></span><span style=display:flex><span>  uid: 07191fb3-f61a-11e5-8ae5-42010af00002
</span></span><span style=display:flex><span>spec:
</span></span><span style=display:flex><span>  clusterIP: 10.0.162.149
</span></span><span style=display:flex><span>  ports:
</span></span><span style=display:flex><span>  - name: http
</span></span><span style=display:flex><span>    nodePort: <span style=color:#666>31704</span>
</span></span><span style=display:flex><span>    port: <span style=color:#666>8080</span>
</span></span><span style=display:flex><span>    protocol: TCP
</span></span><span style=display:flex><span>    targetPort: <span style=color:#666>80</span>
</span></span><span style=display:flex><span>  - name: https
</span></span><span style=display:flex><span>    nodePort: <span style=color:#666>32453</span>
</span></span><span style=display:flex><span>    port: <span style=color:#666>443</span>
</span></span><span style=display:flex><span>    protocol: TCP
</span></span><span style=display:flex><span>    targetPort: <span style=color:#666>443</span>
</span></span><span style=display:flex><span>  selector:
</span></span><span style=display:flex><span>    run: my-nginx
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get nodes -o yaml | grep ExternalIP -C <span style=color:#666>1</span>
</span></span><span style=display:flex><span>    - address: 104.197.41.11
</span></span><span style=display:flex><span>      type: ExternalIP
</span></span><span style=display:flex><span>    allocatable:
</span></span><span style=display:flex><span>--
</span></span><span style=display:flex><span>    - address: 23.251.152.56
</span></span><span style=display:flex><span>      type: ExternalIP
</span></span><span style=display:flex><span>    allocatable:
</span></span><span style=display:flex><span>...
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>$ curl https://&lt;EXTERNAL-IP&gt;:&lt;NODE-PORT&gt; -k
</span></span><span style=display:flex><span>...
</span></span><span style=display:flex><span>&lt;h1&gt;Welcome to nginx!&lt;/h1&gt;
</span></span></code></pre></div><p>Mari coba membuat ulang <em>Service</em> menggunakan <em>cloud load balancer</em>, ubah saja <code>type</code> <em>Service</em> <code>my-nginx</code> dari <code>NodePort</code> ke <code>LoadBalancer</code>:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl edit svc my-nginx
</span></span><span style=display:flex><span>kubectl get svc my-nginx
</span></span></code></pre></div><pre tabindex=0><code>NAME       TYPE        CLUSTER-IP     EXTERNAL-IP        PORT(S)               AGE
my-nginx   ClusterIP   10.0.162.149   162.222.184.144    80/TCP,81/TCP,82/TCP  21s
</code></pre><pre tabindex=0><code>curl https://&lt;EXTERNAL-IP&gt; -k
...
&lt;title&gt;Welcome to nginx!&lt;/title&gt;
</code></pre><p>IP address pada kolom <code>EXTERNAL-IP</code> menunjukan IP yang tersedia di internet. Sedangkan kolom <code>CLUSTER-IP</code> merupakan IP yang hanya tersedia di dalam klaster kamu (<em>IP private</em>).</p><p>Perhatikan pada <em>AWS</em>, tipe <code>LoadBalancer</code> membuat sebuah <em>ELB</em>, yang menggunakan <em>hostname</em> yang panjang, bukan IP. Karena tidak semua keluar pada standar keluaran <code>kubectl get svc</code>. Jadi kamu harus menggunakan <code>kubectl describe service my-nginx</code> untuk melihatnya. Kamu akan melihat seperti ini:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl describe service my-nginx
</span></span><span style=display:flex><span>...
</span></span><span style=display:flex><span>LoadBalancer Ingress:   a320587ffd19711e5a37606cf4a74574-1142138393.us-east-1.elb.amazonaws.com
</span></span><span style=display:flex><span>...
</span></span></code></pre></div><h2 id=selanjutnya>Selanjutnya</h2><p>Kubernetes juga mendukung <em>Federated Service</em>, yang bisa mempengaruhi banyak klaster dan penyedia layanan <em>cloud</em>, untuk meningkatkan ketersediaan, peningkatan toleransi kesalahan, dan pengembangan dari <em>Service</em> kamu. Lihat <a href=/id/docs/concepts/cluster-administration/federation-service-discovery/>Panduan Federated Service</a> untuk informasi lebih lanjut.</p></div><div class=td-content style=page-break-before:always><h1 id=pg-199bcc92443dbc9bed44819467d7eb75>5.6 - Ingress</h1><p>Sebuah obyek API yang mengatur akses eksternal terhadap <em>Service</em> yang ada di dalam klaster, biasanya dalam bentuk <em>request</em> HTTP.</p><p>Ingress juga menyediakan <em>load balancing</em>, terminasi SSL, serta <em>name-based virtual hosting</em>.</p><h2 id=terminologi>Terminologi</h2><p>Untuk memudahkan, di awal akan dijelaskan beberapa terminologi yang sering dipakai:</p><ul><li>Node: Sebuah mesin fisik atau virtual yang berada di dalam klaster Kubernetes.</li><li>Klaster: Sekelompok node yang merupakan <em>resource</em> komputasi primer yang diatur oleh Kubernetes, biasanya diproteksi dari internet dengan menggunakan <em>firewall</em>.</li><li><em>Edge router</em>: Sebuah <em>router</em> mengatur <em>policy firewall</em> pada klaster kamu. <em>Router</em> ini bisa saja berupa <em>gateway</em> yang diatur oleh penyedia layanan <em>cloud</em> maupun perangkat keras.</li><li>Jaringan klaster: Seperangkat <em>links</em> baik logis maupus fisik, yang memfasilitasi komunikasi di dalam klaster berdasarkan <a href=/id/docs/concepts/cluster-administration/networking/>model jaringan Kubernetes</a>.</li><li><em>Service</em>: Sebuah <a href=/id/docs/concepts/services-networking/service/><em>Service</em></a> yang mengidentifikasi beberapa <em>Pod</em> dengan menggunakan <em>selector label</em>. Secara umum, semua <em>Service</em> diasumsikan hanya memiliki IP virtual yang hanya dapat diakses dari dalam jaringan klaster.</li></ul><h2 id=apakah-ingress-itu>Apakah <em>Ingress</em> itu?</h2><p>Ingress ditambahkan sejak Kubernetes v1.1, mengekspos rute HTTP dan HTTPS ke berbagai
<a href=/docs/concepts/services-networking/service/ target=_blank>services</a> di dalam klaster.
Mekanisme <em>routing</em> trafik dikendalikan oleh aturan-aturan yang didefinisikan pada <em>Ingress</em>.</p><pre tabindex=0><code class=language-none data-lang=none>    internet
        |
   [ Ingress ]
   --|-----|--
   [ Services ]
</code></pre><p>Sebuah <em>Ingress</em> dapat dikonfigurasi agar berbagai <em>Service</em> memiliki URL yang dapat diakses dari eksternal (luar klaster), melakukan <em>load balance</em> pada trafik, terminasi SSL, serta Virtual Host berbasis Nama.
Sebuah <a href=/id/docs/concepts/services-networking/ingress-controllers>kontroler Ingress</a> bertanggung jawab untuk menjalankan fungsi Ingress yaitu sebagai <em>loadbalancer</em>, meskipun dapat juga digunakan untuk mengatur <em>edge router</em> atau <em>frontend</em> tambahan untuk menerima trafik.</p><p>Sebuah <em>Ingress</em> tidak mengekspos sembarang <em>port</em> atau protokol. Mengekspos <em>Service</em> untuk protokol selain HTTP ke HTTPS internet biasanya dilakukan dengan menggunakan
<em>service</em> dengan tipe <a href=/id/docs/concepts/services-networking/service/#nodeport>Service.Type=NodePort</a> atau
<a href=/id/docs/concepts/services-networking/service/#loadbalancer>Service.Type=LoadBalancer</a>.</p><h2 id=prasyarat>Prasyarat</h2><div style=margin-top:10px;margin-bottom:10px><b>FEATURE STATE:</b> <code>Kubernetes v1.1 [beta]</code></div><p>Sebelum kamu mulai menggunakan <em>Ingress</em>, ada beberapa hal yang perlu kamu ketahui sebelumnya. <em>Ingress</em> merupakan <em>resource</em> dengan tipe beta.</p><div class="alert alert-info note callout" role=alert><strong>Catatan:</strong> Kamu harus terlebih dahulu memiliki <a href=/id/docs/concepts/services-networking/ingress-controllers>kontroler Ingress</a> untuk dapat memenuhi <em>Ingress</em>. Membuat sebuah <em>Ingress</em> tanpa adanya kontroler <em>Ingres</em> tidak akan berdampak apa pun.</div><p>GCE/Google Kubernetes Engine melakukan deploy kontroler <em>Ingress</em> pada <em>master</em>. Perhatikan laman berikut
<a href=https://github.com/kubernetes/ingress-gce/blob/master/BETA_LIMITATIONS.md#glbc-beta-limitations>keterbatasan versi beta</a>
kontroler ini jika kamu menggunakan GCE/GKE.</p><p>Jika kamu menggunakan <em>environment</em> selain GCE/Google Kubernetes Engine, kemungkinan besar kamu harus
<a href=https://kubernetes.github.io/ingress-nginx/deploy/>melakukan proses deploy kontroler ingress kamu sendiri</a>. Terdapat beberapa jenis
<a href=/id/docs/concepts/services-networking/ingress-controllers>kontroler Ingress</a> yang bisa kamu pilih.</p><h3 id=sebelum-kamu-memulai>Sebelum kamu memulai</h3><p>Secara ideal, semua kontroler Ingress harus memenuhi spesifikasi ini, tetapi beberapa
kontroler beroperasi sedikit berbeda satu sama lain.</p><div class="alert alert-info note callout" role=alert><strong>Catatan:</strong> Pastikan kamu sudah terlebih dahulu memahami dokumentasi kontroler Ingress yang akan kamu pakai sebelum memutuskan untuk memakai kontroler tersebut.</div><h2 id=resource-ingress><em>Resource</em> Ingress</h2><p>Berikut ini merupakan salah satu contoh konfigurasi Ingress yang minimum:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>networking.k8s.io/v1beta1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Ingress<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>test-ingress<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>annotations</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>nginx.ingress.kubernetes.io/rewrite-target</span>:<span style=color:#bbb> </span>/<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>rules</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>http</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>paths</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- <span style=color:green;font-weight:700>path</span>:<span style=color:#bbb> </span>/testpath<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>backend</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>serviceName</span>:<span style=color:#bbb> </span>test<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>servicePort</span>:<span style=color:#bbb> </span><span style=color:#666>80</span><span style=color:#bbb>
</span></span></span></code></pre></div><p>Seperti layaknya <em>resource</em> Kubernetes yang lain, sebuah Ingress membutuhkan <em>field</em> <code>apiVersion</code>, <code>kind</code>, dan <code>metadata</code>.
Untuk informasi umum soal bagaimana cara bekerja dengan menggunakan berkas konfigurasi, silahkan merujuk pada <a href=/docs/tasks/run-application/run-stateless-application-deployment/>melakukan deploy aplikasi</a>, <a href=/id/docs/tasks/configure-pod-container/configure-pod-configmap/>konfigurasi kontainer</a>, <a href=/id/docs/concepts/cluster-administration/manage-deployment/>mengatur <em>resource</em></a>.
Ingress seringkali menggunakan anotasi untuk melakukan konfigurasi beberapa opsi yang ada bergantung pada kontroler Ingress yang digunakan, sebagai contohnya
adalah <a href=https://github.com/kubernetes/ingress-nginx/blob/master/docs/examples/rewrite/README.md>anotasi rewrite-target</a>.
<a href=/id/docs/concepts/services-networking/ingress-controllers>Kontroler Ingress</a> yang berbeda memiliki jenis anotasi yang berbeda. Pastikan kamu sudah terlebih dahulu memahami dokumentasi
kontroler Ingress yang akan kamu pakai untuk mengetahui jenis anotasi apa sajakah yang disediakan.</p><p><a href=https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#spec-and-status>Spesifikasi</a> Ingress
memiliki segala informasi yang dibutuhkan untuk melakukan proses konfigurasi <em>loadbalancer</em> atau server proxy. Hal yang terpenting adalah
bagian inilah yang mengandung semua <em>rules</em> yang nantinya akan digunakan untuk menyesuaikan trafik yang masuk. <em>Resource</em> Ingress hanya menyediakan
fitur <em>rules</em> untuk mengarahkan trafik dengan protokol HTTP.</p><h3 id=rule-ingress><em>Rule</em> Ingress</h3><p>Setiap <em>rule</em> HTTP mengandung informasi berikut:</p><ul><li><em>Host</em> opsional. Di dalam contoh ini, tidak ada <em>host</em> yang diberikan, dengan kata lain, semua <em>rules</em> berlaku untuk <em>inbound</em>
trafik HTTP bagi alamat IP yang dispesifikasikan. JIka sebuah <em>host</em> dispesifikasikan (misalnya saja,
foo.bar.com), maka <em>rules</em> yang ada akan berlaku bagi <em>host</em> tersebut.</li><li>Sederetan <em>path</em> (misalnya, /testpath), setiap <em>path</em> ini akan memiliki pasangan berupa sebuah <em>backend</em> yang didefinisikan dengan <code>serviceName</code>
dan <code>servicePort</code>. Baik <em>host</em> dan <em>path</em> harus sesuai dengan konten dari <em>request</em> yang masuk sebelum
<em>loadbalancer</em> akan mengarahkan trafik pada <em>service</em> yang sesuai.</li><li>Suatu <em>backend</em> adalah kombinasi <em>service</em> dan <em>port</em> seperti yang dideskripsikan di
<a href=/id/docs/concepts/services-networking/service/>dokumentasi <em>Service</em></a>. <em>Request</em> HTTP (dan HTTPS) yang sesuai dengan
<em>host</em> dan <em>path</em> yang ada pada <em>rule</em> akan diteruskan pada <em>backend</em> terkait.</li></ul><p><em>Backend default</em> seringkali dikonfigurasi pada kontroler kontroler Ingress, tugas <em>backend default</em> ini adalah
mengarahkan <em>request</em> yang tidak sesuai dengan <em>path</em> yang tersedia pada spesifikasi.</p><h3 id=backend-default><em>Backend Default</em></h3><p>Sebuah Ingress yang tidak memiliki <em>rules</em> akan mengarahkan semua trafik pada sebuah <em>backend default</em>. <em>Backend default</em> inilah yang
biasanya bisa dimasukkan sebagai salah satu opsi konfigurasi dari <a href=/id/docs/concepts/services-networking/ingress-controllers>kontroler Ingress</a> dan tidak dimasukkan dalam spesifikasi <em>resource</em> Ingress.</p><p>Jika tidak ada <em>host</em> atau <em>path</em> yang sesuai dengan <em>request</em> HTTP pada objek Ingress, maka trafik tersebut
akan diarahkan pada <em>backend default</em>.</p><h2 id=jenis-ingress>Jenis Ingress</h2><h3 id=ingress-dengan-satu-service>Ingress dengan satu Service</h3><p>Terdapat konsep Kubernetes yang memungkinkan kamu untuk mengekspos sebuah Service, lihat <a href=#alternatif-lain>alternatif lain</a>.
Kamu juga bisa membuat spesifikasi Ingress dengan <em>backend default</em> yang tidak memiliki <em>rules</em>.</p><div class=highlight><div class=copy-code-icon style=text-align:right><a href=https://raw.githubusercontent.com/kubernetes/website/main/content/id/examples/service/networking/ingress.yaml download=service/networking/ingress.yaml><code>service/networking/ingress.yaml</code></a>
<img src=/images/copycode.svg style=max-height:24px;cursor:pointer onclick='copyCode("service-networking-ingress-yaml")' title="Copy service/networking/ingress.yaml to clipboard"></img></div><div class=includecode id=service-networking-ingress-yaml><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>networking.k8s.io/v1beta1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Ingress<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>test-ingress<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>backend</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>serviceName</span>:<span style=color:#bbb> </span>testsvc<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>servicePort</span>:<span style=color:#bbb> </span><span style=color:#666>80</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>
</span></span></span></code></pre></div></div></div><p>Jika kamu menggunakan <code>kubectl apply -f</code> kamu dapat melihat:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get ingress test-ingress
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>NAME           HOSTS     ADDRESS           PORTS     AGE
</span></span><span style=display:flex><span>test-ingress   *         107.178.254.228   <span style=color:#666>80</span>        59s
</span></span></code></pre></div><p>Dimana <code>107.178.254.228</code> merupakan alamat IP yang dialokasikan oleh kontroler Ingress untuk
memenuhi Ingress ini.</p><div class="alert alert-info note callout" role=alert><strong>Catatan:</strong> Kontroler Ingress dan <em>load balancer</em> membutuhkan waktu sekitar satu hingga dua menit untuk mengalokasikan alamat IP.
Hingga alamat IP berhasil dialokasikan, kamu akan melihat tampilan kolom <code>ADDRESS</code> sebagai <code>&lt;pending></code>.</div><h3 id=fanout-sederhana><em>Fanout</em> sederhana</h3><p>Sebuah konfigurasi fanout akan melakukan <em>route</em> trafik dari sebuah alamat IP ke banyak Service,
berdasarkan URI HTTP yang diberikan. Sebuah Ingress memungkinkan kamu untuk memiliki jumlah <em>loadbalancer</em> minimum.
Contohnya, konfigurasi seperti di bawah ini:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>foo.bar.com -&gt; 178.91.123.132 -&gt; / foo    service1:4200
</span></span><span style=display:flex><span>                                 / bar    service2:8080
</span></span></code></pre></div><p>akan memerlukan konfigurasi Ingress seperti:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>networking.k8s.io/v1beta1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Ingress<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>simple-fanout-example<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>annotations</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>nginx.ingress.kubernetes.io/rewrite-target</span>:<span style=color:#bbb> </span>/<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>rules</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>host</span>:<span style=color:#bbb> </span>foo.bar.com<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>http</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>paths</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- <span style=color:green;font-weight:700>path</span>:<span style=color:#bbb> </span>/foo<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>backend</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>serviceName</span>:<span style=color:#bbb> </span>service1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>servicePort</span>:<span style=color:#bbb> </span><span style=color:#666>4200</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- <span style=color:green;font-weight:700>path</span>:<span style=color:#bbb> </span>/bar<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>backend</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>serviceName</span>:<span style=color:#bbb> </span>service2<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>servicePort</span>:<span style=color:#bbb> </span><span style=color:#666>8080</span><span style=color:#bbb>
</span></span></span></code></pre></div><p>Ketika kamu membuat Ingress dengan perintah <code>kubectl apply -f</code>:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl describe ingress simple-fanout-example
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>Name:             simple-fanout-example
</span></span><span style=display:flex><span>Namespace:        default
</span></span><span style=display:flex><span>Address:          178.91.123.132
</span></span><span style=display:flex><span>Default backend:  default-http-backend:80 <span style=color:#666>(</span>10.8.2.3:8080<span style=color:#666>)</span>
</span></span><span style=display:flex><span>Rules:
</span></span><span style=display:flex><span>  Host         Path  Backends
</span></span><span style=display:flex><span>  ----         ----  --------
</span></span><span style=display:flex><span>  foo.bar.com
</span></span><span style=display:flex><span>               /foo   service1:4200 <span style=color:#666>(</span>10.8.0.90:4200<span style=color:#666>)</span>
</span></span><span style=display:flex><span>               /bar   service2:8080 <span style=color:#666>(</span>10.8.0.91:8080<span style=color:#666>)</span>
</span></span><span style=display:flex><span>Annotations:
</span></span><span style=display:flex><span>  nginx.ingress.kubernetes.io/rewrite-target:  /
</span></span><span style=display:flex><span>Events:
</span></span><span style=display:flex><span>  Type     Reason  Age                From                     Message
</span></span><span style=display:flex><span>  ----     ------  ----               ----                     -------
</span></span><span style=display:flex><span>  Normal   ADD     22s                loadbalancer-controller  default/test
</span></span></code></pre></div><p>Kontroler Ingress akan menyediakan <em>loadbalancer</em> (implementasinya tergantung dari jenis Ingress yang digunakan), selama <em>service-service</em> yang didefinisikan (<code>s1</code>, <code>s2</code>) ada.
Apabila <em>Ingress</em> selesai dibuat, maka kamu dapat melihat alamat IP dari berbagai <em>loadbalancer</em>
pada kolom <code>address</code>.</p><div class="alert alert-info note callout" role=alert><strong>Catatan:</strong> Kamu mungkin saja membutuhkan konfigurasi default-http-backend <a href=/id/docs/concepts/services-networking/service/>Service</a>
bergantung pada <a href=/id/docs/concepts/services-networking/ingress-controllers>kontroler Ingress</a> yang kamu pakai.</div><h3 id=virtual-host-berbasis-nama>Virtual Host berbasis Nama</h3><p>Virtual Host berbasis Nama memungkinkan mekanisme <em>routing</em> berdasarkan trafik HTTP ke beberapa <em>host name</em> dengan alamat IP yang sama.</p><pre tabindex=0><code class=language-none data-lang=none>foo.bar.com --|                 |-&gt; foo.bar.com s1:80
              | 178.91.123.132  |
bar.foo.com --|                 |-&gt; bar.foo.com s2:80
</code></pre><p>Ingress di bawah ini memberikan perintah pada <em>loadbalancer</em> untuk melakukan mekanisme <em>routing</em> berdasarkan
<a href=https://tools.ietf.org/html/rfc7230#section-5.4>header host</a>.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>networking.k8s.io/v1beta1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Ingress<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>name-virtual-host-ingress<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>rules</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>host</span>:<span style=color:#bbb> </span>foo.bar.com<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>http</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>paths</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- <span style=color:green;font-weight:700>backend</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>serviceName</span>:<span style=color:#bbb> </span>service1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>servicePort</span>:<span style=color:#bbb> </span><span style=color:#666>80</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>host</span>:<span style=color:#bbb> </span>bar.foo.com<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>http</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>paths</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- <span style=color:green;font-weight:700>backend</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>serviceName</span>:<span style=color:#bbb> </span>service2<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>servicePort</span>:<span style=color:#bbb> </span><span style=color:#666>80</span><span style=color:#bbb>
</span></span></span></code></pre></div><p>Jika kamu membuat sebuah Ingress tanpa mendefinisikan <em>host</em> apa pun, maka
trafik web ke alamat IP dari kontroler Ingress tetap dapat dilakukan tanpa harus
menyesuaikan aturan <em>name based virtual host</em>. Sebagai contoh,
<em>resource</em> Ingress di bawah ini akan melakukan pemetaan trafik
dari <code>first.bar.com</code> ke <code>service1</code>, <code>second.foo.com</code> ke <code>service2</code>, dan trafik lain
ke alamat IP tanpa <em>host name</em> yang didefinisikan di dalam <em>request</em> (yang tidak memiliki <em>request header</em>) ke <code>service3</code>.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>networking.k8s.io/v1beta1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Ingress<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>name-virtual-host-ingress<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>rules</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>host</span>:<span style=color:#bbb> </span>first.bar.com<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>http</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>paths</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- <span style=color:green;font-weight:700>backend</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>serviceName</span>:<span style=color:#bbb> </span>service1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>servicePort</span>:<span style=color:#bbb> </span><span style=color:#666>80</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>host</span>:<span style=color:#bbb> </span>second.foo.com<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>http</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>paths</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- <span style=color:green;font-weight:700>backend</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>serviceName</span>:<span style=color:#bbb> </span>service2<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>servicePort</span>:<span style=color:#bbb> </span><span style=color:#666>80</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>http</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>paths</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- <span style=color:green;font-weight:700>backend</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>serviceName</span>:<span style=color:#bbb> </span>service3<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>servicePort</span>:<span style=color:#bbb> </span><span style=color:#666>80</span><span style=color:#bbb>
</span></span></span></code></pre></div><h3 id=tls>TLS</h3><p>Kamu dapat mengamankan <em>Ingress</em> yang kamu miliki dengan memberikan spesifikasi <a href=/id/docs/concepts/configuration/secret>secret</a>
yang mengandung <em>private key</em> dan sertifikat TLS. Saat ini, Ingress hanya
memiliki fitur untuk melakukan konfigurasi <em>single TLS port</em>, yaitu 443, serta melakukan terminasi TLS.
Jika <em>section</em> TLS pada Ingress memiliki spesifikasi <em>host</em> yang berbeda,
<em>rules</em> yang ada akan dimultiplekskan pada <em>port</em> yang sama berdasarkan
<em>hostname</em> yang dispesifikasikan melalui ekstensi TLS SNI. <em>Secret</em> TLS harus memiliki
<code>key</code> bernama <code>tls.crt</code> dan <code>tls.key</code> yang mengandung <em>private key</em> dan sertifikat TLS, contohnya:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>data</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>tls.crt</span>:<span style=color:#bbb> </span>base64 encoded cert<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>tls.key</span>:<span style=color:#bbb> </span>base64 encoded key<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Secret<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>testsecret-tls<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>namespace</span>:<span style=color:#bbb> </span>default<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>type</span>:<span style=color:#bbb> </span>kubernetes.io/tls<span style=color:#bbb>
</span></span></span></code></pre></div><p>Ketika kamu menambahkan <em>secret</em> pada Ingress maka kontroler Ingress akan memberikan perintah untuk
memproteksi <em>channel</em> dari klien ke <em>loadbalancer</em> menggunakan TLS.
Kamu harus memastikan <em>secret</em> TLS yang digunakan memiliki sertifikat yang mengandung
CN untuk <code>sslexample.foo.com</code>.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>networking.k8s.io/v1beta1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Ingress<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>tls-example-ingress<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>tls</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>hosts</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- sslexample.foo.com<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>secretName</span>:<span style=color:#bbb> </span>testsecret-tls<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>rules</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:green;font-weight:700>host</span>:<span style=color:#bbb> </span>sslexample.foo.com<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>http</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>paths</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span>- <span style=color:green;font-weight:700>path</span>:<span style=color:#bbb> </span>/<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>backend</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>            </span><span style=color:green;font-weight:700>serviceName</span>:<span style=color:#bbb> </span>service1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>            </span><span style=color:green;font-weight:700>servicePort</span>:<span style=color:#bbb> </span><span style=color:#666>80</span><span style=color:#bbb>
</span></span></span></code></pre></div><div class="alert alert-info note callout" role=alert><strong>Catatan:</strong> Terdapat perbedaan di antara beberapa fitur TLS
yang disediakan oleh berbagai kontroler Ingress. Perhatikan dokumentasi
<a href=https://git.k8s.io/ingress-nginx/README.md#https>nginx</a>,
<a href=https://git.k8s.io/ingress-gce/README.md#frontend-https>GCE</a>, atau
kontroler Ingress spesifik <em>platform</em> lainnya untuk memahami cara kerja TLS
pada <strong>environment</strong> yang kamu miliki.</div><h3 id=loadbalancing><em>Loadbalancing</em></h3><p>Sebuah kontroler Ingress sudah dibekali dengan beberapa <em>policy</em> terkait mekanisme <em>load balance</em>
yang nantinya akan diterapkan pada semua Ingress, misalnya saja algoritma <em>load balancing</em>, <em>backend
weight scheme</em>, dan lain sebagainya. Beberapa konsep <em>load balance</em> yang lebih <em>advance</em>
(misalnya saja <em>persistent sessions</em>, <em>dynamic weights</em>) belum diekspos melalui Ingress.
Meskipun begitu, kamu masih bisa menggunakan fitur ini melalui
<a href=https://github.com/kubernetes/ingress-nginx>loadbalancer service</a>.</p><p>Perlu diketahui bahwa meskipun <em>health check</em> tidak diekspos secara langsung
melalui Ingress, terdapat beberapa konsep di Kubernetes yang sejalan dengan hal ini, misalnya
<a href=/docs/tasks/configure-pod-container/configure-liveness-readiness-probes/>readiness probes</a>
yang memungkinkan kamu untuk memperoleh hasil yang sama. Silahkan pelajari lebih lanjut dokumentasi
kontroler yang kamu pakai untuk mengetahui bagaimana implementasi <em>health checks</em> pada kontroler yang kamu pilih (<a href=https://git.k8s.io/ingress-nginx/README.md>nginx</a>,
<a href=https://git.k8s.io/ingress-gce/README.md#health-checks>GCE</a>).</p><h2 id=mengubah-ingress>Mengubah Ingress</h2><p>Untuk mengubah Ingress yang sudah ada dan menambahkan <em>host</em> baru, kamu dapat mengubahnya dengan mode <em>edit</em>:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl describe ingress <span style=color:#a2f>test</span>
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>Name:             <span style=color:#a2f>test</span>
</span></span><span style=display:flex><span>Namespace:        default
</span></span><span style=display:flex><span>Address:          178.91.123.132
</span></span><span style=display:flex><span>Default backend:  default-http-backend:80 <span style=color:#666>(</span>10.8.2.3:8080<span style=color:#666>)</span>
</span></span><span style=display:flex><span>Rules:
</span></span><span style=display:flex><span>  Host         Path  Backends
</span></span><span style=display:flex><span>  ----         ----  --------
</span></span><span style=display:flex><span>  foo.bar.com
</span></span><span style=display:flex><span>               /foo   s1:80 <span style=color:#666>(</span>10.8.0.90:80<span style=color:#666>)</span>
</span></span><span style=display:flex><span>Annotations:
</span></span><span style=display:flex><span>  nginx.ingress.kubernetes.io/rewrite-target:  /
</span></span><span style=display:flex><span>Events:
</span></span><span style=display:flex><span>  Type     Reason  Age                From                     Message
</span></span><span style=display:flex><span>  ----     ------  ----               ----                     -------
</span></span><span style=display:flex><span>  Normal   ADD     35s                loadbalancer-controller  default/test
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl edit ingress <span style=color:#a2f>test</span>
</span></span></code></pre></div><p>Sebuah editor akan muncul dan menampilkan konfigurasi Ingress kamu
dalam format YAML apabila kamu telah menjalankan perintah di atas.
Ubah untuk menambahkan <em>host</em>:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>rules</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>host</span>:<span style=color:#bbb> </span>foo.bar.com<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>http</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>paths</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- <span style=color:green;font-weight:700>backend</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>serviceName</span>:<span style=color:#bbb> </span>s1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>servicePort</span>:<span style=color:#bbb> </span><span style=color:#666>80</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>path</span>:<span style=color:#bbb> </span>/foo<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>host</span>:<span style=color:#bbb> </span>bar.baz.com<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>http</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>paths</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- <span style=color:green;font-weight:700>backend</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>serviceName</span>:<span style=color:#bbb> </span>s2<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>servicePort</span>:<span style=color:#bbb> </span><span style=color:#666>80</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>path</span>:<span style=color:#bbb> </span>/foo<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span>..<span style=color:#bbb>
</span></span></span></code></pre></div><p>Menyimpan konfigurasi dalam bentuk YAML ini akan mengubah <em>resource</em> pada API server,
yang kemudian akan memberi tahu kontroler Ingress untuk mengubah konfigurasi <em>loadbalancer</em>.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl describe ingress <span style=color:#a2f>test</span>
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>Name:             <span style=color:#a2f>test</span>
</span></span><span style=display:flex><span>Namespace:        default
</span></span><span style=display:flex><span>Address:          178.91.123.132
</span></span><span style=display:flex><span>Default backend:  default-http-backend:80 <span style=color:#666>(</span>10.8.2.3:8080<span style=color:#666>)</span>
</span></span><span style=display:flex><span>Rules:
</span></span><span style=display:flex><span>  Host         Path  Backends
</span></span><span style=display:flex><span>  ----         ----  --------
</span></span><span style=display:flex><span>  foo.bar.com
</span></span><span style=display:flex><span>               /foo   s1:80 <span style=color:#666>(</span>10.8.0.90:80<span style=color:#666>)</span>
</span></span><span style=display:flex><span>  bar.baz.com
</span></span><span style=display:flex><span>               /foo   s2:80 <span style=color:#666>(</span>10.8.0.91:80<span style=color:#666>)</span>
</span></span><span style=display:flex><span>Annotations:
</span></span><span style=display:flex><span>  nginx.ingress.kubernetes.io/rewrite-target:  /
</span></span><span style=display:flex><span>Events:
</span></span><span style=display:flex><span>  Type     Reason  Age                From                     Message
</span></span><span style=display:flex><span>  ----     ------  ----               ----                     -------
</span></span><span style=display:flex><span>  Normal   ADD     45s                loadbalancer-controller  default/test
</span></span></code></pre></div><p>Kamu juga dapat mengubah Ingress dengan menggunakan perintah <code>kubectl replace -f</code> pada berkas konfigurasi
Ingress yang ingin diubah.</p><h2 id=mekanisme-failing-pada-beberapa-zona-availability>Mekanisme <em>failing</em> pada beberapa zona <em>availability</em></h2><p>Teknik untuk menyeimbangkan persebaran trafik pada <em>failure domain</em> berbeda antar penyedia layanan <em>cloud</em>.
Kamu dapat mempelajari dokumentasi yang relevan bagi <a href=/id/docs/concepts/services-networking/ingress-controllers>kontoler Ingress</a>
untuk informasi yang lebih detail. Kamu juga dapat mempelajari <a href=/id/docs/concepts/cluster-administration/federation/>dokumentasi federasi</a>
untuk informasi lebih detail soal bagaimana melakukan <em>deploy</em> untuk federasi klaster.</p><h2 id=pengembangan-selanjutnya>Pengembangan selanjutnya</h2><p>Silahkan amati <a href=https://github.com/kubernetes/community/tree/master/sig-network>SIG Network</a>
untuk detail lebih lanjut mengenai perubahan Ingress dan <em>resource</em> terkait lainnya. Kamu juga bisa melihat
<a href=https://github.com/kubernetes/ingress/tree/master>repositori Ingress</a> untuk informasi yang lebih detail
soal perubahan berbagai kontroler.</p><h2 id=alternatif-lain>Alternatif lain</h2><p>Kamu dapat mengekspos sebuah <em>Service</em> dalam berbagai cara, tanpa harus menggunakan <em>resource</em> Ingress, dengan menggunakan:</p><ul><li><a href=/id/docs/concepts/services-networking/service/#loadbalancer>Service.Type=LoadBalancer</a></li><li><a href=/id/docs/concepts/services-networking/service/#nodeport>Service.Type=NodePort</a></li><li><a href=https://git.k8s.io/contrib/for-demos/proxy-to-service>Port Proxy</a></li></ul><h2 id=selanjutnya>Selanjutnya</h2><ul><li><a href=/docs/tasks/access-application-cluster/ingress-minikube>Melakukan konfigurasi Ingress pada Minikube dengan kontroler NGINX</a></li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-5a8edeb1f2dc8e38cd6d561bb08b0d78>5.7 - Kontroler Ingress</h1><p>Agar Ingress dapat bekerja sebagaimana mestinya,
sebuah klaster harus memiliki paling tidak sebuah kontroler Ingress.</p><p>Berbeda dengan kontroler-kontroler lainnya yang dijalankan
sebagai bagian dari <em>binary</em> <code>kube-controller-manager</code>, kontroler Ingress
tidak secara otomatis dijalankan di dalam klaster. Kamu bisa menggunakan
laman ini untuk memilih implementasi kontroler Ingress yang kamu pikir
paling sesuai dengan kebutuhan kamu.</p><p>Kubernetes sebagai sebuah proyek, saat ini, mendukung dan memaintain kontroler-kontroler <a href=https://git.k8s.io/ingress-gce/README.md>GCE</a> dan
<a href=https://git.k8s.io/ingress-nginx/README.md>nginx</a>.</p><h2 id=kontroler-kontroler-lainnya>Kontroler-kontroler lainnya</h2><ul><li><a href=https://www.getambassador.io/>Ambassador</a> <em>API Gateway</em> merupakan ingress berbasis <a href=https://www.envoyproxy.io>Envoy</a>
kontroler dengan dukungan <a href=https://www.getambassador.io/docs>komunitas</a> atau
<a href=https://www.getambassador.io/pro/>komersial</a> dari <a href=https://www.datawire.io/>Datawire</a>.</li><li><a href=https://appscode.com>AppsCode Inc.</a> menawarkan dukungan dan pemeliharaan untuk ingress berbasis <a href=http://www.haproxy.org/>HAProxy</a>, <a href=https://appscode.com/products/voyager>Voyager</a>.</li><li><a href=https://projectcontour.io/>Contour</a> merupakan ingress berbasis <a href=https://www.envoyproxy.io/>Envoy</a>
yang disediakan dan didukung oleh VMware.</li><li>Citrix menyediakan sebuah <a href=https://github.com/citrix/citrix-k8s-ingress-controller>kontroler Ingress</a> untuk perangkat keras (MPX), virtualisasi (VPX) dan <a href=https://www.citrix.com/products/citrix-adc/cpx-express.html>kontainerisasi cuma-cuma (CPX) ADC</a> untuk mesin <a href=https://github.com/citrix/citrix-k8s-ingress-controller/tree/master/deployment/baremetal><em>baremetal</em></a> dan penyedia layanan <a href=https://github.com/citrix/citrix-k8s-ingress-controller/tree/master/deployment><em>cloud</em></a> deployments.</li><li>F5 Networks menyediakan <a href=https://support.f5.com/csp/article/K86859508>dukungan dan pemeliharaan</a>
untuk <a href=http://clouddocs.f5.com/products/connectors/k8s-bigip-ctlr/latest>kontroler F5 BIG-IP bagi Kubernetes</a>.</li><li><a href=https://gloo.solo.io>Gloo</a> adalah sebuah proyek kontroler Ingress <em>open source</em> berbasis <a href=https://www.envoyproxy.io>Envoy</a> yang menawarkan fungsionalitas <em>API Gateway</em> dengan dukungan <em>enterprise</em> dari <a href=https://www.solo.io>solo.io</a>.</li><li>Kontroler Ingress berbasis <a href=http://www.haproxy.org/>HAProxy</a>
<a href=https://github.com/jcmoraisjr/haproxy-ingress>jcmoraisjr/haproxy-ingress</a> yang disebutkan di dalam artikel
<a href=https://www.haproxy.com/blog/haproxy_ingress_controller_for_kubernetes/>HAProxy Ingress Controller for Kubernetes</a>.
<a href=https://www.haproxy.com/>HAProxy Technologies</a> menawarkan dukungan dan pemeliharaan bagi HAProxy Enterprise dan
Ingress kontroler <a href=https://github.com/jcmoraisjr/haproxy-ingress>jcmoraisjr/haproxy-ingress</a>.</li><li>Kontroler Ingress berbasis <a href=https://istio.io/>Istio</a>
<a href=https://istio.io/docs/tasks/traffic-management/ingress/>Control Ingress Traffic</a>.</li><li><a href=https://konghq.com/>Kong</a> menawarkan dukungan dan pemeliharaan <a href=https://discuss.konghq.com/c/kubernetes>komunitas</a> atau
<a href=https://konghq.com/kong-enterprise/>komersial</a>
<a href=https://github.com/Kong/kubernetes-ingress-controller>Kontroler Ingress untuk Kubernetes</a>.</li><li><a href=https://www.nginx.com/>NGINX, Inc.</a> menawarkan dukungan dan pemeliharaan <a href=https://www.nginx.com/products/nginx/kubernetes-ingress-controller>Kontroler Ingress NGINX untuk Kubernetes</a>.</li><li><a href=https://github.com/containous/traefik>Traefik</a> adalah sebuah kontroler Ingress yang menyediakan semua fitur secara lengkap (fully featured)
(<a href=https://letsencrypt.org>Let's Encrypt</a>, <em>secrets</em>, <em>http2</em>, <em>websocket</em>), dengan tambahan dukungan
komersial oleh <a href=https://containo.us/services>Containous</a>.</li></ul><h2 id=menggunakan-beberapa-jenis-kontroler-ingress-sekaligus>Menggunakan beberapa jenis kontroler Ingress sekaligus</h2><p>Kamu dapat melakukan <em>deploy</em> <a href=https://git.k8s.io/ingress-nginx/docs/user-guide/multiple-ingress.md#multiple-ingress-controllers>berapa pun banyaknya kontroler Ingress</a>
dalam sebuah klaster. Jika kamu ingin membuat Ingress, kamu tinggal memberikan anotasi setiap Ingress sesuai dengan
<a href=https://git.k8s.io/ingress-gce/docs/faq/README.md#how-do-i-run-multiple-ingress-controllers-in-the-same-cluster><code>ingress.class</code></a>
yang sesuai untuk menandai kontroler Ingress mana yang digunakan jika terdapat lebih dari satu kontroler Ingress yang ada di
klaster kamu.</p><p>Apabila kamu tidak mendefinisikan <code>class</code> yang dipakai, penyedia layanan <em>cloud</em> kamu akan menggunakan kontroler Ingress <em>default</em> yang mereka miliki.</p><p>Idealnya, semua ingress harus memenuhi spesifikasi ini, tetapi berbagai jenis
kontroler Ingress bisa saja memiliki sedikit perbedaan cara kerja.</p><div class="alert alert-info note callout" role=alert><strong>Catatan:</strong> Pastikan kamu sudah terlebih dahulu memahami dokumentasi kontroler Ingress yang akan kamu pakai sebelum memutuskan untuk memakai kontroler tersebut.</div><h2 id=selanjutnya>Selanjutnya</h2><ul><li>Pelajari <a href=/id/docs/concepts/services-networking/ingress/>Ingress</a> lebih lanjut.</li><li><a href=/docs/tasks/access-application-cluster/ingress-minikube>Melakukan konfigurasi Ingress pada Minikube dengan kontroler NGINX</a></li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-ded1daafdcd293023ee333728007ca61>5.8 - NetworkPolicy</h1><nav id=TableOfContents><ul><li><a href=#prasyarat>Prasyarat</a></li><li><a href=#pod-yang-terisolasi-dan-tidak-terisolasi>Pod yang terisolasi dan tidak terisolasi</a></li><li><a href=#resource-networkpolicy><em>Resource</em> <code>NetworkPolicy</code></a></li><li><a href=#perilaku-selektor-to-dan-from>Perilaku selektor <code>to</code> dan <code>from</code></a></li><li><a href=#policy-default><em>Policy</em> <em>Default</em></a><ul><li><a href=#default-tolak-semua-trafik-ingress><em>Default</em>: tolak semua trafik <em>ingress</em></a></li><li><a href=#default-izinkan-semua-trafik-ingress><em>Default</em>: izinkan semua trafik <em>ingress</em></a></li><li><a href=#default-tolak-semua-trafik-egress><em>Default</em>: tolak semua trafik <em>egress</em></a></li><li><a href=#default-izinkan-semua-trafik-egress><em>Default</em>: izinkan semua trafik <em>egress</em></a></li><li><a href=#default-tolak-semua-trafik-ingress-dan-egress><em>Default</em>: tolak semua trafik <em>ingress</em> dan <em>egress</em></a></li></ul></li><li><a href=#dukungan-terhadap-sctp>Dukungan terhadap SCTP</a></li><li><a href=#selanjutnya>Selanjutnya</a></li></ul></nav><p>Sebuah NetworkPolicy adalah spesifikasi dari sekelompok Pod atau <em>endpoint</em> yang diizinkan untuk saling berkomunikasi.</p><p><code>NetworkPolicy</code> menggunakan label untuk memilih Pod serta mendefinisikan serangkaian <em>rule</em> yang digunakan
untuk mendefinisikan trafik yang diizinkan untuk suatu Pod tertentu.</p><h2 id=prasyarat>Prasyarat</h2><p>NetworkPolicy diimplementasikan dengan menggunakan <em>plugin</em> jaringan,
dengan demikian kamu harus memiliki penyedia jaringan yang mendukung <code>NetworkPolicy</code> -
membuat <em>resource</em> tanpa adanya <em>controller</em> tidak akan berdampak apa pun.</p><h2 id=pod-yang-terisolasi-dan-tidak-terisolasi>Pod yang terisolasi dan tidak terisolasi</h2><p>Secara <em>default</em>, Pod bersifat tidak terisolasi; Pod-Pod tersebut
menerima trafik dari <em>resource</em> apa pun.</p><p>Pod menjadi terisolasi apabila terdapat <code>NetworkPolicy</code> yang dikenakan pada Pod-Pod tersebut.
Apabila terdapat <code>NetworkPolicy</code> di dalam <em>namespace</em> yang dikenakan pada suatu Pod, Pod tersebut
akan menolak koneksi yang tidak diizinkan <code>NetworkPolicy</code>. (Pod lain dalam <em>namespace</em>
yang tidak dikenakan <code>NetworkPolicy</code> akan tetap menerima trafik dari semua <em>resource</em>.)</p><h2 id=resource-networkpolicy><em>Resource</em> <code>NetworkPolicy</code></h2><p>Lihat <a href=/docs/reference/generated/kubernetes-api/v1.25/#networkpolicy-v1-networking-k8s-io><code>NetworkPolicy</code></a> untuk definisi lengkap <em>resource</em>.</p><p>Sebuah contoh <code>NetworkPolicy</code> akan terlihat seperti berikut:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>networking.k8s.io/v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>NetworkPolicy<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>test-network-policy<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>namespace</span>:<span style=color:#bbb> </span>default<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>podSelector</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>matchLabels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>role</span>:<span style=color:#bbb> </span>db<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>policyTypes</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- Ingress<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- Egress<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>ingress</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>from</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:green;font-weight:700>ipBlock</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>cidr</span>:<span style=color:#bbb> </span><span style=color:#666>172.17.0.0</span>/16<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>except</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span>- <span style=color:#666>172.17.1.0</span>/24<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:green;font-weight:700>namespaceSelector</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>matchLabels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>project</span>:<span style=color:#bbb> </span>myproject<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:green;font-weight:700>podSelector</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>matchLabels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>role</span>:<span style=color:#bbb> </span>frontend<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>ports</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:green;font-weight:700>protocol</span>:<span style=color:#bbb> </span>TCP<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>port</span>:<span style=color:#bbb> </span><span style=color:#666>6379</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>egress</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>to</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:green;font-weight:700>ipBlock</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>cidr</span>:<span style=color:#bbb> </span><span style=color:#666>10.0.0.0</span>/24<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>ports</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:green;font-weight:700>protocol</span>:<span style=color:#bbb> </span>TCP<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>port</span>:<span style=color:#bbb> </span><span style=color:#666>5978</span><span style=color:#bbb>
</span></span></span></code></pre></div><p>Mengirimkan ini ke API server dengan metode POST tidak akan berdampak apa pun
kecuali penyedia jaringan mendukung network policy.</p><p><strong><em>Field-field</em> yang bersifat wajib</strong>: Sama dengan seluruh <em>config</em> Kubernetes lainnya, sebuah <code>NetworkPolicy</code>
membutuhkan <em>field-field</em> <code>apiVersion</code>, <code>kind</code>, dan <code>metadata</code>. Informasi generik mengenai
bagaimana bekerja dengan <em>file</em> <code>config</code>, dapat dilihat di
<a href=/id/docs/tasks/configure-pod-container/configure-pod-configmap/>Konfigurasi Kontainer menggunakan <code>ConfigMap</code></a>,
serta <a href=/id/docs/tasks/manage-kubernetes-objects/>Manajemen Objek</a>.</p><p><strong>spec</strong>: <code>NetworkPolicy</code> <a href=https://github.com/kubernetes/community/blob/master/contributors/devel/sig-architecture/api-conventions.md#spec-and-status>spec</a> memiliki semua informasi yang harus diberikan untuk memberikan definisi <em>network policy</em> yang ada pada <em>namespace</em> tertentu.</p><p><strong>podSelector</strong>: Setiap <code>NetworkPolicy</code> memiliki sebuah <code>podSelector</code> yang bertugas memfilter Pod-Pod yang dikenai <em>policy</em> tersebut. Contoh yang ada memfilter Pod dengan label <code>"role=db"</code>. Sebuah <code>podSelector</code> yang empty akan memilih semua Pod yang ada di dalam <em>namespace</em>.</p><p><strong>policyTypes</strong>: Setiap <code>NetworkPolicy</code> memiliki sebuah daftar <code>policyTypes</code> yang dapat berupa <code>Ingress</code>, <code>Egress</code>, atau keduanya. <em>Field</em> <code>policyTypes</code> mengindikasikan apakah suatu <em>policy</em> diberikan pada trafik <em>ingress</em>, <em>egress</em>, atau camputan <em>ingress</em> dan <em>egress</em> pada Pod tertentu. Jika tidak ada <code>policyTypes</code> tyang diberikan pada <code>NetworkPolicy</code> maka <code>Ingress</code> <em>default</em> akan diterapkan dan <code>Egress</code> akan diterapkan apabila <em>policy</em> tersebut memberikan spesifikasi <em>egress</em>.</p><p><strong>ingress</strong>: Setiap <code>NetworkPolicy</code> bisa saja memberikan serangkaian whitelist <em>rule-rule</em> <code>ingress</code>. Setiap <em>rule</em> mengizinkan trafik yang sesuai dengan <em>section</em> <code>from</code> dan <code>ports</code>. Contoh <em>policy</em> yang diberikan memiliki sebuah <em>rule</em>, yang sesuai dengan trafik pada sebuah <code>port</code> <em>single</em>, bagian pertama dispesifikasikan melalui <code>ipBlock</code>, yang kedua melalui <code>namespaceSelector</code> dan yang ketiga melalui <code>podSelector</code>.</p><p><strong>egress</strong>: Setiap <code>NetworkPolicy</code> bisa saja meliputi serangkaian <em>whitelist</em> <em>rule-rule</em> <code>egress</code>. Setiap <em>rule</em> mengizinkan trafik yang sesuai dengan <em>section</em> <code>to</code> dan <code>ports</code>. Contoh <em>policy</em> yang diberikan memiliki sebuah <em>rule</em>, yang sesuai dengan <code>port</code> <em>single</em> pada destinasi <code>10.0.0.0/24</code>.</p><p>Pada contoh, <code>NetworkPolicy</code> melakukan hal berikut:</p><ol><li><p>Mengisolasi Pod-Pod dengan label <code>"role=db"</code> pada <em>namespace</em> <code>"default"</code> baik untuk <code>ingress</code> atau <code>egress</code>.</p></li><li><p>(<em>Rule</em> <code>Ingress</code>) mengizinkan koneksi ke semua Pod pada <em>namespace</em> <code>“default”</code> dengan label <code>“role=db”</code> untuk protokol TCP <code>port</code> <code>6379</code> dari:</p><ul><li>semua Pod pada <em>namespace</em> <code>"default"</code> dengan label <code>"role=frontend"</code></li><li>semua Pod dalam sebuah <em>namespace</em> dengan label <code>"project=myproject"</code></li><li>alamat IP pada <em>range</em> <code>172.17.0.0–172.17.0.255</code> dan <code>172.17.2.0–172.17.255.255</code> (yaitu, semua <code>172.17.0.0/16</code> kecuali <code>172.17.1.0/24</code>)</li></ul></li><li><p>(<em>Rule</em> Egress) mengizinkan koneksi dari semua Pod pada <em>namespace</em> <code>"default"</code> dengan label <code>"role=db"</code> ke CIDR <code>10.0.0.0/24</code> untuk protokol TCP pada <code>port</code> <code>5978</code></p></li></ol><p>Lihat mekanisme <a href=/docs/tasks/administer-cluster/declare-network-policy/>Deklarasi <em>Network Policy</em></a> untuk penjelasan lebih mendalam.</p><h2 id=perilaku-selektor-to-dan-from>Perilaku selektor <code>to</code> dan <code>from</code></h2><p>Terdapat empat jenis selektor yang dapat dispesifikasikan dalam <code>section</code> <code>ingress</code> <code>from</code> atau <code>section</code> <code>egress</code> <code>to</code>:</p><p><strong>podSelector</strong>: Ini digunakan untuk memfilter Pod tertentu pada <em>namespace</em> dimana <code>NetworkPolicy</code> berada yang akan mengatur destinasi <em>ingress</em> atau <em>egress</em>.</p><p><strong>namespaceSelector</strong>: Ini digunakan untuk memfilter <em>namespace</em> tertentu dimana semua Pod diperbolehkan sebagai <em>source</em> <code>ingress</code> atau destinasi <code>egress</code>.</p><p><strong>namespaceSelector</strong> <em>and</em> <strong>podSelector</strong>: Sebuah entri <code>to</code>/<code>from</code> yang memberikan spesifikasi <code>namespaceSelector</code> dan <code>podSelector</code> serta memilih Pod-Pod tertentu yang ada di dalam <em>namespace</em>. Pastikan kamu menggunakan sintaks YAML yang tepat; <code>policy</code> ini:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#bbb>  </span>...<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>ingress</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>from</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:green;font-weight:700>namespaceSelector</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>matchLabels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>user</span>:<span style=color:#bbb> </span>alice<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>podSelector</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>matchLabels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>role</span>:<span style=color:#bbb> </span>client<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>...<span style=color:#bbb>
</span></span></span></code></pre></div><p>mengandung sebuah elemen <code>from</code> yang mengizinkan koneksi dari Pod-Pod dengan label <code>role=client</code> di <em>namespace</em> dengan label <code>user=alice</code>. Akan tetapi, <em>policy</em> <em>ini</em>:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#bbb>  </span>...<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>ingress</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>from</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:green;font-weight:700>namespaceSelector</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>matchLabels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>user</span>:<span style=color:#bbb> </span>alice<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:green;font-weight:700>podSelector</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>matchLabels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>role</span>:<span style=color:#bbb> </span>client<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>...<span style=color:#bbb>
</span></span></span></code></pre></div><p>mengandung dua elemen pada <em>array</em> <code>from</code>, dan mengizinkan koneksi dari Pod pada Namespace lokal dengan label
<code>role=client</code>, <em>atau</em> dari Pod di <em>namespace</em> apa pun dengan label <code>user=alice</code>.</p><p>Ketika kamu merasa ragu, gunakan <code>kubectl describe</code> untuk melihat bagaimana Kubernetes
menginterpretasikan <em>policy</em> tersebut.</p><p><strong>ipBlock</strong>: Ini digunakan untuk memilih <em>range</em> IP CIDR tertentu untuk berperan sebagai
<em>source</em> <em>ingress</em> atau destinasi <em>egress</em>. Alamat yang digunakan harus merupakan
alamat IP eksternal klaster, karena alamat IP Pod bersifat <em>ephemeral</em> dan tidak dapat ditebak.</p><p>Mekanisme <em>ingress</em> dan <em>egress</em> klaster seringkali membutuhkan mekanisme <em>rewrite</em> alamat IP <em>source</em> dan destinasi
paket. Pada kasus-kasus dimana hal ini, tidak dapat dipastikan bahwa apakah hal ini
terjadi sebelum atau setelah pemrosesan <code>NetworkPolicy</code>, dan perilaku yang ada mungkin saja berbeda
untuk kombinasi <em>plugin</em> jaringan, penyedia layanan <em>cloud</em>, serta implementasi <code>Service</code> yang berbeda.</p><p>Pada <em>ingress</em>, artinya bisa saja kamu melakukan <em>filter</em> paket yang masuk berdasarkan <code>source IP</code>,
sementara di kasus lain "source IP" yang digunakan oleh Network Policy adalah alamat IP <code>LoadBalancer</code>,
<em>node</em> dimana Pod berada, dsb.</p><p>Pada <em>egress</em>, bisa saja sebuah koneksi dari Pod ke IP <code>Service</code> di-<em>rewrite</em> ke IP eksternal klaster
atau bahkan tidak termasuk di dalam <code>ipBlock</code> <em>policy</em>.</p><h2 id=policy-default><em>Policy</em> <em>Default</em></h2><p>Secara <em>default</em>, jika tidak ada <em>policy</em> yang ada dalam suatu <em>namespace</em>, maka semua trafik <em>ingress</em> dan <em>egress</em> yang diizinkan ke atau dari Pod dalam <em>namespace</em>.
Contoh di bawah ini akan memberikan gambaran bagaimana kamu dapat mengubah perilaku <em>default</em> pada sebuah <em>namespace</em>.</p><h3 id=default-tolak-semua-trafik-ingress><em>Default</em>: tolak semua trafik <em>ingress</em></h3><p>Kamu dapat membuat <em>policy</em> isolasi <code>"default"</code> untuk sebuah <em>namespace</em>
dengan membuat sebuah <code>NetworkPolicy</code> yang memilih semua Pod tapi tidak mengizinkan
trafik <em>ingress</em> masuk ke Pod-Pod tersebut.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>networking.k8s.io/v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>NetworkPolicy<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>default-deny<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>podSelector</span>:<span style=color:#bbb> </span>{}<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>policyTypes</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- Ingress<span style=color:#bbb>
</span></span></span></code></pre></div><p>Hal ini menjamin bahwa bahkan Pod yang tidak dipilih oleh <code>NetworkPolicy</code> lain masih terisolasi.
<em>Policy</em> ini tidak mengubah perilaku <em>default</em> dari <em>egress</em>.</p><h3 id=default-izinkan-semua-trafik-ingress><em>Default</em>: izinkan semua trafik <em>ingress</em></h3><p>Jika kamu ingin mengizinkan semua trafik <em>ingress</em> pada semua Pod dalam sebuah <em>namespace</em>
(bahkan jika <em>policy</em> ditambahkan dan menyebabkan beberapa Pod menjadi terisolasi), kamu
dapat secara eksplisit mengizinkan semua trafik bagi <em>namespace</em> tersebut.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>networking.k8s.io/v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>NetworkPolicy<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>allow-all<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>podSelector</span>:<span style=color:#bbb> </span>{}<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>ingress</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- {}<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>policyTypes</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- Ingress<span style=color:#bbb>
</span></span></span></code></pre></div><h3 id=default-tolak-semua-trafik-egress><em>Default</em>: tolak semua trafik <em>egress</em></h3><p>Kamu dapat membuat <em>policy</em> isolasi <code>"default"</code> untuk sebuah <em>namespace</em>
dengan membuat sebuah <code>NetworkPolicy</code> yang memilih semua Pod tapi tidak mengizinkan
trafik <em>egress</em> keluar dari Pod-Pod tersebut.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>networking.k8s.io/v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>NetworkPolicy<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>default-deny<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>podSelector</span>:<span style=color:#bbb> </span>{}<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>policyTypes</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- Egress<span style=color:#bbb>
</span></span></span></code></pre></div><p>Hal ini menjamin bahwa bahkan Pod yang tidak dipilih oleh <code>NetworkPolicy</code> lain masih terisolasi.
<em>Policy</em> ini tidak mengubah perilaku <em>default</em> dari <em>ingress</em>.</p><h3 id=default-izinkan-semua-trafik-egress><em>Default</em>: izinkan semua trafik <em>egress</em></h3><p>Jika kamu ingin mengizinkan semua trafik <em>egress</em> pada semua Pod dalam sebuah <em>namespace</em>
(bahkan jika <em>policy</em> ditambahkan dan menyebabkan beberapa Pod menjadi terisolasi), kamu
dapat secara eksplisit mengizinkan semua trafik bagi <em>namespace</em> tersebut.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>networking.k8s.io/v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>NetworkPolicy<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>allow-all<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>podSelector</span>:<span style=color:#bbb> </span>{}<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>egress</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- {}<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>policyTypes</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- Egress<span style=color:#bbb>
</span></span></span></code></pre></div><h3 id=default-tolak-semua-trafik-ingress-dan-egress><em>Default</em>: tolak semua trafik <em>ingress</em> dan <em>egress</em></h3><p>Kamu dapat membuat sebuah <em>policy</em> <em>"default"</em> jika kamu ingin menolak semua trafik <em>ingress</em> maupun <em>egress</em> pada semua Pod dalam sebuah <em>namespace</em>.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>networking.k8s.io/v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>NetworkPolicy<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>default-deny<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>podSelector</span>:<span style=color:#bbb> </span>{}<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>policyTypes</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- Ingress<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- Egress<span style=color:#bbb>
</span></span></span></code></pre></div><p>Hal ini menjamin bahwa bahkan Pod yang tidak dipilih oleh <code>NetworkPolicy</code> tidak akan mengizinkan trafik <em>ingress</em> atau <em>egress</em>.</p><h2 id=dukungan-terhadap-sctp>Dukungan terhadap SCTP</h2><div style=margin-top:10px;margin-bottom:10px><b>FEATURE STATE:</b> <code>Kubernetes v1.12 [alpha]</code></div><p>Kubernetes mendukung SCTP sebagai <em>value</em> <code>protocol</code> pada definisi <code>NetworkPolicy</code> sebagai fitur alpha. Untuk mengaktifkan fitur ini, administrator klaster harus mengaktifkan gerbang fitur <code>SCTPSupport</code> pada <code>apiserver</code>, contohnya <code>“--feature-gates=SCTPSupport=true,...”</code>. Ketika gerbang fitur ini diaktifkan, pengguna dapat menerapkan <code>value</code> dari <em>field</em> <code>protocol</code> pada <code>NetworkPolicy</code> menjadi <code>SCTP</code>. Kubernetes akan mengatur jaringan sesuai dengan SCTP, seperti halnya koneksi TCP.</p><p><em>Plugin</em> CNI harus mendukung SCTP sebagai <em>value</em> dari <code>protocol</code> pada <code>NetworkPolicy</code>.</p><h2 id=selanjutnya>Selanjutnya</h2><ul><li>Lihat <a href=/docs/tasks/administer-cluster/declare-network-policy/>Deklarasi <em>Network Policy</em></a> untuk melihat lebih banyak contoh penggunaan.</li><li>Baca lebih lanjut soal <a href=https://github.com/ahmetb/kubernetes-network-policy-recipes>panduan</a> bagi skenario generik <em>resource</em> <code>NetworkPolicy</code>.</li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-509638b5ca0e420fa426f14f34e2d3b1>5.9 - Menambahkan Entry pada /etc/hosts Pod dengan HostAliases</h1><nav id=TableOfContents><ul><li><a href=#isi-default-pada-berkas-hosts>Isi Default pada Berkas <code>Hosts</code></a></li><li><a href=#menambahkan-entri-tambahan-dengan-hostaliases>Menambahkan Entri Tambahan dengan HostAliases</a></li><li><a href=#kenapa-kubelet-melakukan-mekanisme-manajemen-berkas-hosts>Kenapa Kubelet Melakukan Mekanisme Manajemen Berkas <code>Hosts</code>?</a></li></ul></nav><p>Menambahkan entri pada berkas /etc/hosts Pod akan melakukan <em>override</em>
resolusi <em>hostname</em> pada level Pod ketika DNS dan opsi lainnya tidak tersedia.
Pada versi 1.7, pengguna dapat menambahkan entri yang diinginkan beserta <em>field</em> HostAliases
pada PodSpec.</p><p>Modifikasi yang dilakukan tanpa menggunakan HostAliases tidaklah disarankan
karena berkas ini diatur oleh Kubelet dan dapat di-<em>override</em> ketika Pod dibuat/di-<em>restart</em>.</p><h2 id=isi-default-pada-berkas-hosts>Isi Default pada Berkas <code>Hosts</code></h2><p>Misalnya saja kamu mempunyai sebuah Pod Nginx yang memiliki sebuah IP Pod:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl run nginx --image nginx --generator<span style=color:#666>=</span>run-pod/v1
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>pod/nginx created
</span></span></code></pre></div><p>Perhatikan IP Pod tersebut:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get pods --output<span style=color:#666>=</span>wide
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>NAME     READY     STATUS    RESTARTS   AGE    IP           NODE
</span></span><span style=display:flex><span>nginx    1/1       Running   <span style=color:#666>0</span>          13s    10.200.0.4   worker0
</span></span></code></pre></div><p><em>File</em> <code>hosts</code> yang ada akan tampak sebagai berikut:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl <span style=color:#a2f>exec</span> nginx -- cat /etc/hosts
</span></span></code></pre></div><pre tabindex=0><code class=language-none data-lang=none># Berkas hosts yang dikelola Kubernetes
127.0.0.1	localhost
::1	localhost ip6-localhost ip6-loopback
fe00::0	ip6-localnet
fe00::0	ip6-mcastprefix
fe00::1	ip6-allnodes
fe00::2	ip6-allrouters
10.200.0.4	nginx
</code></pre><p>Secara default, berkas <code>hosts</code> hanya berisikan <em>boilerplate</em> alamat IP IPv4 and IPv6 seperti
<code>localhost</code> dan hostname dari Pod itu sendiri.</p><h2 id=menambahkan-entri-tambahan-dengan-hostaliases>Menambahkan Entri Tambahan dengan HostAliases</h2><p>Selain <em>boilerplate default</em>, kita dapat menambahkan entri pada berkas
<code>hosts</code> untuk melakukan resolusi <code>foo.local</code>, <code>bar.local</code> pada <code>127.0.0.1</code> dan <code>foo.remote</code>,
<code>bar.remote</code> pada <code>10.1.2.3</code>, kita dapat melakukannya dengan cara menambahkan
HostAliases pada Pod di bawah <em>field</em> <code>.spec.hostAliases</code>:</p><div class=highlight><div class=copy-code-icon style=text-align:right><a href=https://raw.githubusercontent.com/kubernetes/website/main/content/id/examples/service/networking/hostaliases-pod.yaml download=service/networking/hostaliases-pod.yaml><code>service/networking/hostaliases-pod.yaml</code></a>
<img src=/images/copycode.svg style=max-height:24px;cursor:pointer onclick='copyCode("service-networking-hostaliases-pod-yaml")' title="Copy service/networking/hostaliases-pod.yaml to clipboard"></img></div><div class=includecode id=service-networking-hostaliases-pod-yaml><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>hostaliases-pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>restartPolicy</span>:<span style=color:#bbb> </span>Never<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>hostAliases</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>ip</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;127.0.0.1&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>hostnames</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:#b44>&#34;foo.local&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:#b44>&#34;bar.local&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>ip</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;10.1.2.3&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>hostnames</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:#b44>&#34;foo.remote&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:#b44>&#34;bar.remote&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>cat-hosts<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>busybox<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>command</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- cat<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>args</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:#b44>&#34;/etc/hosts&#34;</span><span style=color:#bbb>
</span></span></span></code></pre></div></div></div><p>Pod ini kemudian dapat dihidupkan dengan perintah berikut:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl apply -f hostaliases-pod.yaml
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>pod/hostaliases-pod created
</span></span></code></pre></div><p>Perhatikan IP dan status Pod tersebut:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get pod --output<span style=color:#666>=</span>wide
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>NAME                           READY     STATUS      RESTARTS   AGE       IP              NODE
</span></span><span style=display:flex><span>hostaliases-pod                0/1       Completed   <span style=color:#666>0</span>          6s        10.200.0.5      worker0
</span></span></code></pre></div><p><em>File</em> <code>hosts</code> yang ada akan tampak sebagai berikut:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl logs hostaliases-pod
</span></span></code></pre></div><pre tabindex=0><code class=language-none data-lang=none># Berkas hosts yang dikelola Kubernetes
127.0.0.1	localhost
::1	localhost ip6-localhost ip6-loopback
fe00::0	ip6-localnet
fe00::0	ip6-mcastprefix
fe00::1	ip6-allnodes
fe00::2	ip6-allrouters
10.200.0.5	hostaliases-pod

# Entries added by HostAliases.
127.0.0.1	foo.local	bar.local
10.1.2.3	foo.remote	bar.remote
</code></pre><p>Dengan tambahan entri yang telah dispesifikasikan sebelumnya.</p><h2 id=kenapa-kubelet-melakukan-mekanisme-manajemen-berkas-hosts>Kenapa Kubelet Melakukan Mekanisme Manajemen Berkas <code>Hosts</code>?</h2><p>Kubelet <a href=https://github.com/kubernetes/kubernetes/issues/14633>melakukan proses manajemen</a>
berkas <code>hosts</code> untuk setiap container yang ada pada Pod untuk mencegah Docker melakukan
<a href=https://github.com/moby/moby/issues/17190>modifikasi</a> pada berkas tersebut
setelah kontainer dihidupkan.</p><p>Karena sifat dari berkas tersebut yang secara otomatis di-<em>manage</em>,
semua hal yang didefinisikan oleh pengguna akan ditimpa (<em>overwrite</em>) ketika berkas
<code>hosts</code> di-<em>mount</em> kembali oleh Kubelet ketika ada kontainer yang di-<em>restart</em>
atau Pod di-<em>schedule</em> ulang. Dengan demikian tidak dianjurkan untuk
memodifikasi berkas tersebut secara langsung.</p></div><div class=td-content style=page-break-before:always><h1 id=pg-21f8d19c60c33914baab66224c3d46a7>5.10 - Dual-stack IPv4/IPv6</h1><div style=margin-top:10px;margin-bottom:10px><b>FEATURE STATE:</b> <code>Kubernetes v1.16 [alpha]</code></div><p><em>Dual-stack</em> IPv4/IPv6 memungkinkan pengalokasian alamat IPv4 dan IPv6 untuk
<a class=glossary-tooltip title='Unit Kubernetes yang paling sederhana dan kecil. Sebuah Pod merepresentasikan sebuah set kontainer yang dijalankan pada kluster kamu.' data-toggle=tooltip data-placement=top href=/docs/concepts/workloads/pods/pod-overview/ target=_blank aria-label=Pod>Pod</a> dan <a class=glossary-tooltip title='Sebuah Cara untuk mengekspos aplikasi yang berjalan pada sebuah kumpulan Pod sebagai layanan jaringan.' data-toggle=tooltip data-placement=top href=/docs/concepts/services-networking/service/ target=_blank aria-label=Service>Service</a>.</p><p>Jika kamu mengaktifkan jaringan <em>dual-stack</em> IPv4/IPv6 untuk klaster Kubernetes
kamu, klaster akan mendukung pengalokasian kedua alamat IPv4 dan IPv6 secara
bersamaan.</p><h2 id=fitur-fitur-yang-didukung>Fitur-fitur yang didukung</h2><p>Mengaktifkan <em>dual-stack</em> IPv4 / IPv6 pada klaster Kubernetes kamu untuk
menyediakan fitur-fitur berikut ini:</p><ul><li>Jaringan Pod <em>dual-stack</em> (pengalokasian sebuah alamat IPv4 dan IPv6 untuk setiap Pod)</li><li>Service yang mendukung IPv4 dan IPv6 (setiap Service hanya untuk satu keluarga alamat)</li><li>Perutean Pod ke luar klaster (misalnya Internet) melalui antarmuka IPv4 dan IPv6</li></ul><h2 id=prasyarat>Prasyarat</h2><p>Prasyarat berikut diperlukan untuk menggunakan <em>dual-stack</em> IPv4/IPv6 pada
klaster Kubernetes :</p><ul><li>Kubernetes versi 1.16 atau yang lebih baru</li><li>Dukungan dari penyedia layanan untuk jaringan <em>dual-stack</em> (Penyedia layanan <em>cloud</em> atau yang lainnya harus dapat menyediakan antarmuka jaringan IPv4/IPv6 yang dapat dirutekan) untuk Node Kubernetes</li><li>Sebuah <em>plugin</em> jaringan yang mendukung <em>dual-stack</em> (seperti Kubenet atau Calico)</li><li>Kube-proxy yang berjalan dalam mode IPVS</li></ul><h2 id=mengaktifkan-dual-stack-ipv4-ipv6>Mengaktifkan <em>dual-stack</em> IPv4/IPv6</h2><p>Untuk mengaktifkan <em>dual-stack</em> IPv4/IPv6, aktifkan <a href=/docs/reference/command-line-tools-reference/feature-gates/>gerbang fitur (<em>feature gate</em>)</a> <code>IPv6DualStack</code>
untuk komponen-komponen yang relevan dari klaster kamu, dan tetapkan jaringan
<em>dual-stack</em> pada klaster:</p><ul><li>kube-controller-manager:<ul><li><code>--feature-gates="IPv6DualStack=true"</code></li><li><code>--cluster-cidr=&lt;IPv4 CIDR>,&lt;IPv6 CIDR></code> misalnya <code>--cluster-cidr=10.244.0.0/16,fc00::/24</code></li><li><code>--service-cluster-ip-range=&lt;IPv4 CIDR>,&lt;IPv6 CIDR></code></li><li><code>--node-cidr-mask-size-ipv4|--node-cidr-mask-size-ipv6</code> nilai bawaannya adalah /24
untuk IPv4 dan /64 untuk IPv6</li></ul></li><li>kubelet:<ul><li><code>--feature-gates="IPv6DualStack=true"</code></li></ul></li><li>kube-proxy:<ul><li><code>--proxy-mode=ipvs</code></li><li><code>--cluster-cidr=&lt;IPv4 CIDR>,&lt;IPv6 CIDR></code></li><li><code>--feature-gates="IPv6DualStack=true"</code></li></ul></li></ul><div class="alert alert-warning caution callout" role=alert><strong>Perhatian:</strong> Jika kamu menentukan blok alamat IPv6 yang lebih besar dari /24 melalui
<code>--cluster-cidr</code> pada baris perintah, maka penetapan tersebut akan gagal.</div><h2 id=service>Service</h2><p>Jika klaster kamu mengaktifkan jaringan <em>dual-stack</em> IPv4/IPv6, maka kamu dapat
membuat <a class=glossary-tooltip title='Sebuah Cara untuk mengekspos aplikasi yang berjalan pada sebuah kumpulan Pod sebagai layanan jaringan.' data-toggle=tooltip data-placement=top href=/docs/concepts/services-networking/service/ target=_blank aria-label=Service>Service</a> dengan
alamat IPv4 atau IPv6. Kamu dapat memilih keluarga alamat untuk clusterIP<br>Service kamu dengan mengatur bagian, <code>.spec.ipFamily</code>, pada Service tersebut.
Kamu hanya dapat mengatur bagian ini saat membuat Service baru. Mengatur bagian
<code>.spec.ipFamily</code> bersifat opsional dan hanya boleh digunakan jika kamu berencana
untuk mengaktifkan <a class=glossary-tooltip title='Sebuah Cara untuk mengekspos aplikasi yang berjalan pada sebuah kumpulan Pod sebagai layanan jaringan.' data-toggle=tooltip data-placement=top href=/docs/concepts/services-networking/service/ target=_blank aria-label='Service '>Service</a>
dan <a class=glossary-tooltip title='Sebuah obyek API yang mengatur akses eksternal terhadap Service yang ada di dalam klaster, biasanya dalam bentuk request HTTP.' data-toggle=tooltip data-placement=top href=/docs/concepts/services-networking/ingress/ target=_blank aria-label='Ingress '>Ingress</a> IPv4 dan IPv6
pada klaster kamu. Konfigurasi bagian ini bukanlah syarat untuk lalu lintas
[<em>egress</em>] (#lalu-lintas-egress).</p><div class="alert alert-info note callout" role=alert><strong>Catatan:</strong> Keluarga alamat bawaan untuk klaster kamu adalah keluarga alamat dari rentang
clusterIP Service pertama yang dikonfigurasi melalui opsi
<code>--service-cluster-ip-range</code> pada kube-controller-manager.</div><p>Kamu dapat mengatur <code>.spec.ipFamily</code> menjadi salah satu dari:</p><ul><li><code>IPv4</code>: Dimana server API akan mengalokasikan IP dari <code>service-cluster-ip-range</code> yaitu <code>ipv4</code></li><li><code>IPv6</code>: Dimana server API akan mengalokasikan IP dari <code>service-cluster-ip-range</code> yaitu <code>ipv6</code></li></ul><p>Spesifikasi Service berikut ini tidak memasukkan bagian <code>ipFamily</code>.
Kubernetes akan mengalokasikan alamat IP (atau yang dikenal juga sebagai
"<em>cluster IP</em>") dari <code>service-cluster-ip-range</code> yang dikonfigurasi pertama kali
untuk Service ini.</p><div class=highlight><div class=copy-code-icon style=text-align:right><a href=https://raw.githubusercontent.com/kubernetes/website/main/content/id/examples/service/networking/dual-stack-default-svc.yaml download=service/networking/dual-stack-default-svc.yaml><code>service/networking/dual-stack-default-svc.yaml</code></a>
<img src=/images/copycode.svg style=max-height:24px;cursor:pointer onclick='copyCode("service-networking-dual-stack-default-svc-yaml")' title="Copy service/networking/dual-stack-default-svc.yaml to clipboard"></img></div><div class=includecode id=service-networking-dual-stack-default-svc-yaml><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Service<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>my-service<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>selector</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>app</span>:<span style=color:#bbb> </span>MyApp<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>ports</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:green;font-weight:700>protocol</span>:<span style=color:#bbb> </span>TCP<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>port</span>:<span style=color:#bbb> </span><span style=color:#666>80</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>targetPort</span>:<span style=color:#bbb> </span><span style=color:#666>9376</span></span></span></code></pre></div></div></div><p>Spesifikasi Service berikut memasukkan bagian <code>ipFamily</code>. Sehingga Kubernetes
akan mengalokasikan alamat IPv6 (atau yang dikenal juga sebagai "<em>cluster IP</em>")
dari <code>service-cluster-ip-range</code> yang dikonfigurasi untuk Service ini.</p><div class=highlight><div class=copy-code-icon style=text-align:right><a href=https://raw.githubusercontent.com/kubernetes/website/main/content/id/examples/service/networking/dual-stack-ipv6-svc.yaml download=service/networking/dual-stack-ipv6-svc.yaml><code>service/networking/dual-stack-ipv6-svc.yaml</code></a>
<img src=/images/copycode.svg style=max-height:24px;cursor:pointer onclick='copyCode("service-networking-dual-stack-ipv6-svc-yaml")' title="Copy service/networking/dual-stack-ipv6-svc.yaml to clipboard"></img></div><div class=includecode id=service-networking-dual-stack-ipv6-svc-yaml><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Service<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>my-service<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>ipFamily</span>:<span style=color:#bbb> </span>IPv6<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>selector</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>app</span>:<span style=color:#bbb> </span>MyApp<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>ports</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:green;font-weight:700>protocol</span>:<span style=color:#bbb> </span>TCP<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>port</span>:<span style=color:#bbb> </span><span style=color:#666>80</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>targetPort</span>:<span style=color:#bbb> </span><span style=color:#666>9376</span></span></span></code></pre></div></div></div><p>Sebagai perbandingan, spesifikasi Service berikut ini akan dialokasikan sebuah alamat
IPv4 (atau yang dikenal juga sebagai "<em>cluster IP</em>") dari <code>service-cluster-ip-range</code>
yang dikonfigurasi untuk Service ini.</p><div class=highlight><div class=copy-code-icon style=text-align:right><a href=https://raw.githubusercontent.com/kubernetes/website/main/content/id/examples/service/networking/dual-stack-ipv4-svc.yaml download=service/networking/dual-stack-ipv4-svc.yaml><code>service/networking/dual-stack-ipv4-svc.yaml</code></a>
<img src=/images/copycode.svg style=max-height:24px;cursor:pointer onclick='copyCode("service-networking-dual-stack-ipv4-svc-yaml")' title="Copy service/networking/dual-stack-ipv4-svc.yaml to clipboard"></img></div><div class=includecode id=service-networking-dual-stack-ipv4-svc-yaml><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Service<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>my-service<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>ipFamily</span>:<span style=color:#bbb> </span>IPv4<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>selector</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>app</span>:<span style=color:#bbb> </span>MyApp<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>ports</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:green;font-weight:700>protocol</span>:<span style=color:#bbb> </span>TCP<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>port</span>:<span style=color:#bbb> </span><span style=color:#666>80</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>targetPort</span>:<span style=color:#bbb> </span><span style=color:#666>9376</span></span></span></code></pre></div></div></div><h3 id=tipe-loadbalancer>Tipe <em>LoadBalancer</em></h3><p>Penyedia layanan <em>cloud</em> yang mendukung IPv6 untuk pengaturan beban eksternal,
Mengatur bagian <code>type</code> menjadi <code>LoadBalancer</code> sebagai tambahan terhadap mengatur bagian
<code>ipFamily</code> menjadi <code>IPv6</code> menyediakan sebuah <em>cloud load balancer</em> untuk Service kamu.</p><h2 id=lalu-lintas-egress>Lalu lintas <em>egress</em></h2><p>Penggunaan blok alamat IPv6 yang dapat dirutekan dan yang tidak dapat dirutekan
secara publik diperbolehkan selama <a class=glossary-tooltip title='Container network interface (CNI) plugins are a type of Network plugin that adheres to the appc/CNI specification.' data-toggle=tooltip data-placement=top href=/docs/concepts/extend-kubernetes/compute-storage-net/network-plugins/ target=_blank aria-label=CNI>CNI</a>
dari penyedia layanan dapat mengimplementasikan transportasinya. Jika kamu memiliki
Pod yang menggunakan IPv6 yang dapat dirutekan secara publik dan ingin agar Pod
mencapai tujuan di luar klaster (misalnya Internet publik), kamu harus mengatur
IP samaran untuk lalu lintas keluar dan balasannya. <a href=https://github.com/kubernetes-incubator/ip-masq-agent><em>ip-masq-agent</em></a>
bersifat <em>dual-stack aware</em>, jadi kamu bisa menggunakan ip-masq-agent untuk
<em>masquerading</em> IP dari klaster <em>dual-stack</em>.</p><h2 id=masalah-masalah-yang-diketahui>Masalah-masalah yang diketahui</h2><ul><li>Kubenet memaksa pelaporan posisi IP untuk IPv4,IPv6 IP (--cluster-cidr)</li></ul><h2 id=selanjutnya>Selanjutnya</h2><ul><li><a href=/docs/tasks/network/validate-dual-stack>Validasi jaringan <em>dual-stack</em> IPv4/IPv6</a></li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-f018f568c6723865753f150c3c59bdda>6 - Storage</h1></div><div class=td-content><h1 id=pg-27795584640a03bd2024f1fe3b3ab754>6.1 - Volume</h1><p>Berkas-berkas yang disimpan di <em>disk</em> di dalam Container bersifat tidak permanen (akan terhapus seiring dengan dihapusnya Container/Pod), yang menimbulkan beberapa masalah untuk aplikasi biasa saat berjalan di dalam Container. Pertama, saat sebuah Container mengalami kegagalan, Kubelet akan memulai kembali Container tersebut, tetapi semua berkas di dalamnya akan hilang - Container berjalan dalam kondisi yang bersih. Kedua, saat menjalankan banyak Container bersamaan di dalam sebuah <code>Pod</code>, biasanya diperlukan untuk saling berbagi berkas-berkas di antara Container-container tersebut. Kedua masalah tersebut dipecahkan oleh abstraksi <code>Volume</code> pada Kubernetes.</p><p>Pengetahuan tentang <a href=/docs/user-guide/pods>Pod</a> disarankan.</p><h2 id=latar-belakang>Latar Belakang</h2><p>Docker juga memiliki konsep <em><a href=https://docs.docker.com/storage/>volume</a></em>, walaupun konsepnya Docker agak lebih fleksibel dan kurang dikelola. Pada Docker, sebuah volume adalah sesederhana sebuah direktori pada <em>disk</em> atau di dalam Container lainnya. <em>Lifetime</em> tidak dikelola dan hingga baru-baru ini hanya ada volume yang didukung <em>disk</em> lokal. Docker sekarang menyediakan <em>driver</em> untuk volume, namun fungsionalitasnya masih sangat terbatas (misalnya hingga Docker 1.7 hanya ada satu <em>driver</em> volume yang diizinkan untuk setiap Container, dan tidak ada cara untuk menyampaikan parameter kepada volume).</p><p>Sebaliknya, sebuah Volume Kubernetes memiliki <em>lifetime</em> yang gamblang - sama dengan <em>lifetime</em> Pod yang berisi Volume tersebut. Oleh karena itu, sebuah Volume bertahan lebih lama dari Container-container yang berjalan di dalam Pod tersebut, dan data di Volum tersebut juga dipertahankan melewati diulangnya Container. Tentu saja, saat sebuah Pod berakhir, Volume tersebut juga akan berakhir/terhapus. Dan mungkin lebih penting lagi, Kubernetes mendukung banyak jenis Volume, dan sebuah Pod dapat menggunakan sebanyak apapun Volume secara bersamaan.</p><p>Pada intinya, sebuah volume hanyalah sebuah direktori, dan mungkin berisi data, yang dapat diakses oleh Container-container di dalam Pod. Bagaimana direktori tersebut dibuat, medium yang menyokongnya, dan isinya ditentukan oleh jenis volume yang digunakan.</p><p>Untuk menggunakan sebuah volume, sebuah Pod memerinci volume-volume yang akan disediakan untuk Pod tersebut (kolom <code>.spec.volumes</code>) dan di mana volume-volume tersebut akan ditambatkan (di-<em>mount</em>) di dalam Container-container di Pod (kolom <code>.spec.containers.volumeMounts</code>).</p><p>Sebuah proses di dalam Container memiliki sudut pandang <em>filesystem</em> yang disusun dari <em>image</em> dan volume Dockernya. <a href=https://docs.docker.com/userguide/dockerimages/>Docker Image</a> berada pada bagian teratas hierarki <em>filesystem</em>, dan volume manapun yang ditambatkan pada <em>path</em> yang diperinci di dalam Image tersebut. Volume tidak dapat ditambatkan pada volume lain atau memiliki <em>hard link</em> ke volume lain. Setiap Container di dalam Pod harus secara independen memerinci di mana tiap Volume ditambatkan.</p><h2 id=jenis-jenis-volume>Jenis-jenis Volume</h2><p>Kubernetes mendukung beberapa jenis Volume:</p><ul><li><a href=#awselasticblockstore>awsElasticBlockStore</a></li><li><a href=#azuredisk>azureDisk</a></li><li><a href=#azurefile>azureFile</a></li><li><a href=#cephfs>cephfs</a></li><li><a href=#cinder>cinder</a></li><li><a href=#configmap>configMap</a></li><li><a href=#csi>csi</a></li><li><a href=#downwardapi>downwardAPI</a></li><li><a href=#emptydir>emptyDir</a></li><li><a href=#fc>fc (fibre channel)</a></li><li><a href=#flexVolume>flexVolume</a></li><li><a href=#flocker>flocker</a></li><li><a href=#gcepersistentdisk>gcePersistentDisk</a></li><li><a href=#gitrepo>gitRepo (deprecated)</a></li><li><a href=#glusterfs>glusterfs</a></li><li><a href=#hostpath>hostPath</a></li><li><a href=#iscsi>iscsi</a></li><li><a href=#local>local</a></li><li><a href=#nfs>nfs</a></li><li><a href=#persistentvolumeclaim>persistentVolumeClaim</a></li><li><a href=#projected>projected</a></li><li><a href=#portworxvolume>portworxVolume</a></li><li><a href=#quobyte>quobyte</a></li><li><a href=#rbd>rbd</a></li><li><a href=#scaleio>scaleIO</a></li><li><a href=#secret>secret</a></li><li><a href=#storageos>storageos</a></li><li><a href=#vspherevolume>vsphereVolume</a></li></ul><p>Kami menyambut kontribusi tambahan.</p><h3 id=awselasticblockstore>awsElasticBlockStore</h3><p>Sebuah Volume <code>awsElasticBlockStore</code> menambatkan sebuah <a href=http://aws.amazon.com/ebs>Volume EBS</a> Amazon Web Services (AWS) ke dalam Pod kamu. Hal ini berarti bahwa sebuah Volume EBS dapat sebelumnya diisi terlebih dahulu dengan data, dan data dapat "dipindahkan" diantara banyak Pod.</p><div class="alert alert-warning caution callout" role=alert><strong>Perhatian:</strong> Kamu harus membuat sebuah volume EBS menggunakan <code>awscli</code> dengan perintah <code>aws ec2 create-volume</code> atau menggunakan AWS API sebelum kamu dapat menggunakannya.</div><p>Ada beberapa batasan saat menggunakan Volume <code>awsElasticBlockStore</code>:</p><ul><li>Node di mana Pod berjalan haruslah merupakan <em>instance</em> AWS EC2.</li><li><em>Instance</em> tersebut mesti berada pada <em>region</em> <strong>dan</strong> <em>availability-zone</em> yang sama dengan volume EBS.</li><li>EBS hanya mendukung penambatan pada satu <em>instance</em> EC2 pada saat yang bersamaan.</li></ul><h4 id=membuat-sebuah-volume-ebs>Membuat sebuah Volume EBS</h4><p>Sebelum kamu dapat menggunakan sebuah volume EBS pada sebuah Pod, kamu harus membuatnya pada AWS terlebih dahulu.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>aws ec2 create-volume --availability-zone<span style=color:#666>=</span>eu-west-1a --size<span style=color:#666>=</span><span style=color:#666>10</span> --volume-type<span style=color:#666>=</span>gp2
</span></span></code></pre></div><p>Pastikan <em>availability zone</em> yang kamu masukkan sama dengan <em>availability zone</em> klaster kamu. (Dan pastikan juga ukuran dan jenis EBSnya sesuai dengan penggunaan yang kamu butuhkan!)</p><h4 id=contoh-konfigurasi-aws-ebs>Contoh Konfigurasi AWS EBS</h4><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>test-ebs<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>k8s.gcr.io/test-webserver<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>test-container<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>volumeMounts</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:green;font-weight:700>mountPath</span>:<span style=color:#bbb> </span>/test-ebs<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>test-volume<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>volumes</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>test-volume<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:#080;font-style:italic># volume EBS ini harus sudah dibuat di AWS</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>awsElasticBlockStore</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>volumeID</span>:<span style=color:#bbb> </span>&lt;volume-id&gt;<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>fsType</span>:<span style=color:#bbb> </span>ext4<span style=color:#bbb>
</span></span></span></code></pre></div><h4 id=migrasi-csi-awselasticblocstore>Migrasi CSI awsElasticBlocStore</h4><div style=margin-top:10px;margin-bottom:10px><b>FEATURE STATE:</b> <code>Kubernetes v1.14 [alpha]</code></div><p>Pada saat fitur migrasi CSI (Container Storage Interface) untuk <code>awsElasticBlockStore</code> diaktifkan, fitur ini akan menterjemahkan semua operasi <em>plugin</em> dari <em>plugin</em> yang sudah ada di kode inti Kubernetes ke bentuk Driver CSI <code>ebs.csi.aws.com</code>. Untuk menggunakan fitur ini, <a href=https://github.com/kubernetes-sigs/aws-ebs-csi-driver>Driver CSI AWS EBS</a> harus dinstal di klaster dan fitur Alpha <code>CSIMigration</code> serta <code>CSIMigrationAWS</code> harus diaktifkan.</p><h3 id=azuredisk>azureDisk</h3><p>Sebuah <code>azureDisk</code> digunakan untuk menambatkan sebuah <a href=https://azure.microsoft.com/en-us/documentation/articles/virtual-machines-linux-about-disks-vhds/>Data Disk</a> Microsoft Azure ke dalam sebuah Pod.</p><p>Selengkapnya dapat ditemukan <a href=https://github.com/kubernetes/examples/tree/main/staging/volumes/azure_disk/README.md>di sini</a>.</p><h4 id=migrasi-csi-azuredisk>Migrasi CSI azureDisk</h4><div style=margin-top:10px;margin-bottom:10px><b>FEATURE STATE:</b> <code>Kubernetes v1.15 [alpha]</code></div><p>Pada saat fitur migrasi CSI untuk <code>azureDisk</code> diaktifkan, fitur ini akan menterjemahkan semua operasi <em>plugin</em> dari <em>plugin</em> yang sudah ada di kode inti Kubernetes ke bentuk Driver CSI <code>disk.csi.azure.com</code>. Untuk menggunakan fitur ini, <a href=https://github.com/kubernetes-sigs/azuredisk-csi-driver>Driver CSI Azure Disk</a> harus dinstal di klaster dan fitur Alpha <code>CSIMigration</code> serta <code>CSIMigrationAzureDisk</code> harus diaktifkan.</p><h3 id=azurefile>azureFile</h3><p>Sebuah <code>azureFile</code> digunakan untuk menambatkan sebuah Microsoft Azure File Volume (SMB 2.1 dan 3.0) ke dalam sebuah Pod.</p><p>Selengkapnya dapat ditemukan <a href=https://github.com/kubernetes/examples/tree/main/staging/volumes/azure_file/README.md>di sini</a>.</p><h4 id=migrasi-csi-azurefile>Migrasi CSI azureFile</h4><div style=margin-top:10px;margin-bottom:10px><b>FEATURE STATE:</b> <code>Kubernetes v1.15 [alpha]</code></div><p>Pada saat fitur migrasi CSI untuk <code>azureFile</code> diaktifkan, fitur ini akan menterjemahkan semua operasi <em>plugin</em> dari <em>plugin</em> yang sudah ada di kode inti Kubernetes ke bentuk Driver CSI <code>file.csi.azure.com</code>. Untuk menggunakan fitur ini, <a href=https://github.com/kubernetes-sigs/azuredisk-csi-driver>Driver CSI Azure File</a> harus dinstal di klaster dan fitur Alpha <code>CSIMigration</code> serta <code>CSIMigrationAzureFile</code> harus diaktifkan.</p><h3 id=cephfs>cephfs</h3><p>Sebuah Volume <code>cephfs</code> memungkinkan sebuah volume CephFS yang sudah ada untuk ditambatkan ke dalam Pod kamu. Berbeda dengan <code>emptyDir</code>, yang juga ikut dihapus saat Pod dihapus, isi data di dalam sebuah volume CephFS akan dipertahankan dan Volume tersebut hanya dilepaskan tambatannya (<em>mount</em>-nya). Hal ini berarti bahwa sebuah Volume CephFS dapat sebelumnya diisi terlebih dahulu dengan data, dan data dapat "dipindahkan" diantara banyak Pod.</p><div class="alert alert-warning caution callout" role=alert><strong>Perhatian:</strong> Kamu harus memiliki server Ceph sendiri dan mengekspor <em>share</em>-nya sebelum kamu dapat menggunakannya.</div><p>Selengkapnya, lihat <a href=https://github.com/kubernetes/examples/tree/main/staging/volumes/cephfs/>contoh CephFS</a>.</p><h3 id=cinder>cinder</h3><div class="alert alert-info note callout" role=alert><strong>Catatan:</strong> Prasyarat: Kubernetes dengan penyedia layanan <em>cloud</em> OpenStack yang telah dikonfigurasikan. Untuk konfigurasi penyedia layanan <em>cloud</em>, silahkan lihat <a href=https://kubernetes.io/docs/concepts/cluster-administration/cloud-providers/#openstack>penyedia layanan cloud openstack</a>.</div><p><code>cinder</code> digunakan untuk menambatkan Volume Cinder ke dalam Pod kamu.</p><h4 id=contoh-konfigurasi-volume-cinder>Contoh Konfigurasi Volume Cinder</h4><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>test-cinder<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>k8s.gcr.io/test-webserver<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>test-cinder-container<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>volumeMounts</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:green;font-weight:700>mountPath</span>:<span style=color:#bbb> </span>/test-cinder<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>test-volume<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>volumes</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>test-volume<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:#080;font-style:italic># Volume OpenStack ini harus sudah ada sebelumnya.</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>cinder</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>volumeID</span>:<span style=color:#bbb> </span>&lt;volume-id&gt;<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>fsType</span>:<span style=color:#bbb> </span>ext4<span style=color:#bbb>
</span></span></span></code></pre></div><h4 id=migrasi-csi-cinder>Migrasi CSI Cinder</h4><div style=margin-top:10px;margin-bottom:10px><b>FEATURE STATE:</b> <code>Kubernetes v1.14 [alpha]</code></div><p>Pada saat fitur migrasi CSI untuk Cinder diaktifkan, fitur ini akan menterjemahkan semua operasi <em>plugin</em> dari <em>plugin</em> yang sudah ada di kode inti Kubernetes ke bentuk Driver CSI <code>cinder.csi.openstack.com</code>. Untuk menggunakan fitur ini, <a href=https://github.com/kubernetes/cloud-provider-openstack/blob/master/docs/using-cinder-csi-plugin.md>Driver CSI Openstack Cinder</a> harus dinstal di klaster dan fitur Alpha <code>CSIMigration</code> serta <code>CSIMigrationOpenStack</code> harus diaktifkan.</p><h3 id=configmap>configMap</h3><p>Sumber daya <a href=/id/docs/tasks/configure-pod-container/configure-pod-configmap/><code>configMap</code></a> memungkinkan kamu untuk menyuntikkan data konfigurasi ke dalam Pod.
Data yang ditaruh di dalam sebuah objek <code>ConfigMap</code> dapat dirujuk dalam sebuah Volume dengan tipe <code>configMap</code> dan kemudian digunakan oleh aplikasi/container yang berjalan di dalam sebuah Pod.</p><p>Saat mereferensikan sebuah objek <code>configMap</code>, kamu tinggal memasukkan nama ConfigMap tersebut ke dalam rincian Volume yang bersangkutan. Kamu juga dapat mengganti <em>path</em> spesifik yang akan digunakan pada ConfigMap. Misalnya, untuk menambatkan ConfigMap <code>log-config</code> pada Pod yang diberi nama <code>configmap-pod</code>, kamu dapat menggunakan YAML ini:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>configmap-pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>test<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>busybox<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>volumeMounts</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>config-vol<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>mountPath</span>:<span style=color:#bbb> </span>/etc/config<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>volumes</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>config-vol<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>configMap</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>log-config<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>items</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span>- <span style=color:green;font-weight:700>key</span>:<span style=color:#bbb> </span>log_level<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>            </span><span style=color:green;font-weight:700>path</span>:<span style=color:#bbb> </span>log_level<span style=color:#bbb>
</span></span></span></code></pre></div><p>ConfigMap <code>log-config</code> ditambatkan sebagai sebuah Volume, dan semua isinya yang ditaruh di dalam entri <code>log_level</code>-nya ditambatkan dalam Pod tersebut pada <em>path</em> "<code>/etc/config/log_level</code>".
Perlu dicatat bahwa <em>path</em> tersebut berasal dari isian <code>mountPath</code> pada Volume, dan <code>path</code> yang ditunjuk dengan <code>key</code> bernama <code>log_level</code>.</p><div class="alert alert-warning caution callout" role=alert><strong>Perhatian:</strong> Kamu harus membuat sebuah <a href=/id/docs/tasks/configure-pod-container/configure-pod-configmap/>ConfigMap</a> sebelum kamu dapat menggunakannya.</div><div class="alert alert-info note callout" role=alert><strong>Catatan:</strong> Sebuah Container yang menggunakan sebuah ConfigMap sebagai tambatan Volume <a href=#menggunakan-subpath>subPath</a> tidak akan menerima pembaruan ConfigMap.</div><h3 id=downwardapi>downwardAPI</h3><p>Sebuah Volume <code>downwardAPI</code> digunakan untuk menyediakan data <code>downward API</code> kepada aplikasi.
Volume ini menambatkan sebuah direktori dan menulis data yang diminta pada berkas-berkas teks biasa.</p><div class="alert alert-info note callout" role=alert><strong>Catatan:</strong> Sebuah Container yang menggunakan Downward API sebagai tambatan Volume <a href=#menggunakan-subpath>subPath</a> tidak akan menerima pembaruan Downward API.</div><p>Lihat <a href=/docs/tasks/inject-data-application/downward-api-volume-expose-pod-information/>contoh Volume <code>downwardAPI</code></a> untuk lebih detilnya.</p><h3 id=emptydir>emptyDir</h3><p>Sebuah Volume <code>emptyDir</code> pertama kali dibuat saat sebuah Pod dimasukkan ke dalam sebuah Node, dan akan terus ada selama Pod tersebut berjalan di Node tersebut. Sesuai dengan namanya, Volume ini awalnya kosong. Container-container di dalam Pod dapat membaca dan menulis berkas-berkas yang sama di dalam Volume <code>emptyDir</code>, walaupun Volume tersebut dapat ditambatkan pada <code>path</code> yang sama maupun berbeda pada setiap Container. Saat sebuah Pod dihapus dari sebuah Node untuk alasan apapun, data di dalam <code>emptyDir</code> tersebut dihapus untuk selamanya.</p><div class="alert alert-info note callout" role=alert><strong>Catatan:</strong> Sebuah Container yang gagal <em>TIDAK AKAN</em> menghapus sebuah Pod dari sebuah Node, sehingga data di dalam sebuah <code>emptyDir</code> akan aman jika Container di dalam Podnya gagal.</div><p>Beberapa kegunaan <code>emptyDir</code> adalah sebagai berikut:</p><ul><li><em>Scratch space</em>, misalnya untuk <em>merge sort</em> menggunakan berkas-berkas di <em>disk</em></li><li><em>Checkpointing</em> untuk komputasi panjang yang dipulihkan dari proses yang sebelumnya mengalami kegagalan</li><li>Menyimpan berkas-berkas yang diambil oleh Container aplikasi <em>Content Manager</em> saat sebuah peladen web melayani data tersebut</li></ul><p>Secara bawaan, <code>emptyDir</code> ditaruh pada media penyimpanan apapun yang menyokong Node yang bersangkuta - mungkin sebuah <em>disk</em> atau SSD atau penyimpanan berbasis jaringan, tergantung lingkungan Node yang kamu miliki. Tetapi, kamu juga dapat menyetel bagian <code>emptyDir.medium</code> menjadi <code>"Memory"</code> untuk memberitahukan pada Kubernetes untuk menggunakan sebuah <code>tmpfs</code> (<em>filesystem</em> berbasis RAM) sebagai gantinya. <code>tmpfs</code> memang sangan cepat, tetapi kamu harus sadar bahwa ia tidak seperti <em>disk</em>, data di <code>tmpfs</code> akan terhapus saat Node tersebut diulang kembali. Selain itu, berkas apapun yang kamu tulis akan dihitung terhadap <code>limit</code> <code>memory</code> milik Container kamu.</p><h4 id=contoh-pod>Contoh Pod</h4><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>test-pd<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>k8s.gcr.io/test-webserver<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>test-container<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>volumeMounts</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:green;font-weight:700>mountPath</span>:<span style=color:#bbb> </span>/cache<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>cache-volume<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>volumes</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>cache-volume<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>emptyDir</span>:<span style=color:#bbb> </span>{}<span style=color:#bbb>
</span></span></span></code></pre></div><h3 id=fc>fc (fibre channel)</h3><p>Sebuah Volume <code>fc</code> memunginkan sebuah <em>volume</em> <em>fibre channel</em> yang sudah ada untuk ditambatkan ke sebuah Pod.
Kamu dapat menentukan satu atau banyak target <em>World Wide Names</em> menggunakan parameter <code>targetWWNs</code> pada konfigurasi Volume kamu. Jika banyak WWN ditentukan, maka <code>targetWWNs</code> mengharapkan bahwa WWN tersebut berasal dari koneksi <em>multi-path</em>.</p><div class="alert alert-warning caution callout" role=alert><strong>Perhatian:</strong> Sebelumnya, kamu harus mengkonfigurasikan <em>FC SAN Zoning</em> untuk mengalokasikan dan melakukan <em>masking</em> terhadap LUN (<em>volume</em>) tersebut terhadap target WWN sehingga Node-node Kubernetes dapat mengakses mereka.</div><p>Lihat <a href=https://github.com/kubernetes/examples/tree/main/staging/volumes/fibre_channel>Contoh FC</a> untuk lebih detilnya.</p><h3 id=flocker>flocker</h3><p><a href=https://github.com/ClusterHQ/flocker>Flocker</a> adalah sebuah proyek <em>open-source</em> yg berfungsi sebagai pengatur <em>volume</em> data Container yang diklasterkan. Flocker menyediakan pengelolaan dan orkestrasi <em>volume</em> yang disokong oleh banyak jenis media penyimpanan.</p><p>Sebuah Volume <code>flockere</code> memungkinkan sebuah <em>dataset</em> Flocker untuk ditambatkan ke dalam sebuah Pod. Jika <em>dataset</em> tersebut belum ada di dalam Flocker, maka ia harus dibuat terlebih dahulu dengan menggunakan Flocker CLI atau menggunakan Flocker API. Jika <em>dataset</em> tersebut sudah ada, ia akan ditambatkan kembali oleh Flocker ke Node di mana Pod tersebut dijadwalkan. Hal ini berarti data dapat dioper diantara Pod-pod sesuai dengan kebutuhan.</p><div class="alert alert-warning caution callout" role=alert><strong>Perhatian:</strong> Kamu harus memiliki instalasi Flocker yang sudah berjalan sebelum kamu dapat menggunakannya.</div><p>Lihat <a href=https://github.com/kubernetes/examples/tree/main/staging/volumes/flocker>Contoh Flocker</a> untuk lebih detil.</p><h3 id=gcepersistentdisk>gcePersistentDisk</h3><p>Sebuah <em>volume</em> <code>gcePersistentDisk</code> menambatkan sebuah <a href=http://cloud.google.com/compute/docs/disks>PersistentDisk</a> Google Compute Engine (GCE) ke dalam Pod kamu. Tidak seperti <code>emptyDir</code> yang ikut dihapus saat Pod dihapus, isi dari sebuah PD dipertahankan dan <em>volume</em>-nya hanya dilepaskan tambatannya. Hal ini berarti sebuah PD dapat diisi terlebih dahulu dengan data, dan data tersebut dapat "dioper" diantara Pod-pod.</p><div class="alert alert-warning caution callout" role=alert><strong>Perhatian:</strong> Kamu harus membuat sebuah PD menggunakan <code>gcloud</code> atau GCE API atau GCP UI sebelum kamu dapat menggunakannya.</div><p>Ada beberapa batasan saat menggunakan sebuah <code>gcePersistentDisk</code>:</p><ul><li>Node-node di mana Pod-pod berjalan haruslah GCE VM.</li><li>VM tersebut harus berada pada proyek GCE yang sama dan <em>zone</em> yang sama dengan PD tersebut</li></ul><p>Sebuah fitur PD yaitu mereka dapat ditambatkan sebagai <em>read-only</em> secara bersamaan oleh beberapa pengguna. Hal ini berarti kamu dapat mengisi data terlebih dahulu dan menyediakan data tersebut secara paralel untuk sebanyak apapun Pod yang kamu butuhkan. Sayangnya, PD hanya dapat ditambatkan kepada satu pengguna saja pada mode <em>read-write</em> - yaitu, tidak boleh ada banyak penulis secara bersamaan.</p><p>Menggunakan sebuah PD pada sebuah Pod yang diatur oleh sebuah <code>ReplicationController</code> akan gagal, kecuali jika PD tersebut berada pada mode <code>read-only</code>, atau jumlah <code>replica</code>-nya adalah 0 atau 1.</p><h4 id=membuat-sebuah-pd>Membuat sebuah PD</h4><p>Sebelum kamu dapat menggunakan sebuah PD dengan sebuah Pod, kamu harus membuat PD tersebut terlebih dahulu.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>gcloud compute disks create --size<span style=color:#666>=</span>500GB --zone<span style=color:#666>=</span>us-central1-a my-data-disk
</span></span></code></pre></div><h4 id=contoh-pod-1>Contoh Pod</h4><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>test-pd<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>k8s.gcr.io/test-webserver<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>test-container<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>volumeMounts</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:green;font-weight:700>mountPath</span>:<span style=color:#bbb> </span>/test-pd<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>test-volume<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>volumes</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>test-volume<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:#080;font-style:italic># GCE PD ini harus sudah ada.</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>gcePersistentDisk</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>pdName</span>:<span style=color:#bbb> </span>my-data-disk<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>fsType</span>:<span style=color:#bbb> </span>ext4<span style=color:#bbb>
</span></span></span></code></pre></div><h4 id=regional-persistent-disks>Regional Persistent Disks</h4><div style=margin-top:10px;margin-bottom:10px><b>FEATURE STATE:</b> <code>Kubernetes v1.10 [beta]</code></div><p>Fitur <a href=https://cloud.google.com/compute/docs/disks/#repds>Regional Persistent Disks</a> memungkinkan pembuatan Persistent Disk yang berada pada beberapa <em>zone</em> pada <em>region</em> yang sama. Untuk menggunakan fitur ini, Volume tersebut harus dibuat sebagai sebuah PersistentVolume; mereferensikan Volume tersebut langsung dari sebuah Pod tidak didukung.</p><h4 id=menyediakan-sebuah-regional-pd-persistentvolume-secara-manual>Menyediakan sebuah Regional PD PersistentVolume Secara Manual</h4><p>Penyediaan secara dinamis mungkin dilakukan dengan sebuah <a href=/id/docs/concepts/storage/storage-classes/#gce-pd>StorageClass untuk GCE PD</a>.
Sebelum membuat sebuah PersistentVolume, kamu harus membuat PD-nya:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>gcloud beta compute disks create --size<span style=color:#666>=</span>500GB my-data-disk
</span></span><span style=display:flex><span>    --region us-central1
</span></span><span style=display:flex><span>    --replica-zones us-central1-a,us-central1-b
</span></span></code></pre></div><p>Contoh spesifikasi PersistentVolume:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>PersistentVolume<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>test-volume<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>labels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>failure-domain.beta.kubernetes.io/zone</span>:<span style=color:#bbb> </span>us-central1-a__us-central1-b<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>capacity</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>storage</span>:<span style=color:#bbb> </span>400Gi<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>accessModes</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- ReadWriteOnce<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>gcePersistentDisk</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>pdName</span>:<span style=color:#bbb> </span>my-data-disk<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>fsType</span>:<span style=color:#bbb> </span>ext4<span style=color:#bbb>
</span></span></span></code></pre></div><h4 id=migrasi-csi-gce-pd>Migrasi CSI GCE PD</h4><div style=margin-top:10px;margin-bottom:10px><b>FEATURE STATE:</b> <code>Kubernetes v1.14 [alpha]</code></div><p>Pada saat fitur migrasi CSI untuk GCE PD diaktifkan, fitur ini akan menterjemahkan semua operasi <em>plugin</em> dari <em>plugin</em> yang sudah ada di kode inti Kubernetes ke bentuk Driver CSI <code>pd.csi.storage.gke.io</code>. Untuk menggunakan fitur ini, <a href=https://github.com/kubernetes-sigs/gcp-compute-persistent-disk-csi-driver>Driver CSI GCE PD</a> harus dinstal di klaster dan fitur Alpha <code>CSIMigration</code> serta <code>CSIMigrationGCE</code> harus diaktifkan.</p><h3 id=gitrepo>gitRepo (kedaluwarsa)</h3><div class="alert alert-danger warning callout" role=alert><strong>Peringatan:</strong> Tipe Volume <code>gitRepo</code> telah kedaluwarsa. Untuk membuat sebuah Container dengan sebuah <em>git repo</em>, tambatkan sebuah <a href=#emptydir>EmptyDir</a> ke dalam sebuah InitContainer yang akan mengklon <em>repo</em> tersebut menggunakan git, dan kemudian tambatkan <a href=#emptydir>EmptyDir</a> tersebut ke dalam Container Pod tersebut.</div><p>Sebuah Volume <code>gitRepo</code> adalah sebuah percontohan yang menunjukkan apa yang dapat dilakukan dengan <em>plugin</em> volume. Ia menambatkan sebuah direktori kosong dan mengklon sebuah <em>repository</em> git ke dalamnya untuk digunakan oleh Pod kamu. Ke depannya, Volume seperti ini dapat dipindahkan ke model yang bahkan lebih terpisah, daripada melakukan ekstensi pada Kubernetes API untuk setiap kasus serupa.</p><p>Berikut sebuah contoh Volume gitRepo:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>server<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>nginx<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>nginx<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>volumeMounts</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:green;font-weight:700>mountPath</span>:<span style=color:#bbb> </span>/mypath<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>git-volume<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>volumes</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>git-volume<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>gitRepo</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>repository</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;git@somewhere:me/my-git-repository.git&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>revision</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;22f1d8406d464b0c0874075539c1f2e96c253775&#34;</span><span style=color:#bbb>
</span></span></span></code></pre></div><h3 id=glusterfs>glusterfs</h3><p>Sebuah Volume <code>glusterfs</code> memungkinkan sebuah volume <a href=http://www.gluster.org>Glusterfs</a> (sebuah proyek <em>open-source</em> <em>filesystem</em> berbasis jaringan) untuk ditambatkan ke dalam Pod kamu.
Tidak seperti <code>emptyDir</code> yang ikut dihapus saat Pod dihapus, isi dari sebuah <code>glusterfs</code> dipertahankan dan <em>volume</em>-nya hanya dilepaskan tambatannya. Hal ini berarti sebuah <code>glusterfs</code> dapat diisi terlebih dahulu dengan data, dan data tersebut dapat "dioper" diantara Pod-pod. GlusterFS dapat ditambatkan kepada beberapa penulis secara bersamaan.</p><div class="alert alert-warning caution callout" role=alert><strong>Perhatian:</strong> Kamu harus mempunyai instalasi GlusterFS terlebih dahulu sebelum dapat kamu gunakan.</div><p>Lihat <a href=https://github.com/kubernetes/examples/tree/main/staging/volumes/glusterfs>contoh GlusterFS</a> untuk lebih detil.</p><h3 id=hostpath>hostPath</h3><p>Sebuah Volume <code>hostPath</code> menambatkan sebuah berkas atau direktori dari <em>filesystem</em> Node di mana Pod kamu berjalan ke dalam Pod kamu.
Hal ini bukanlah sesuatu yang dibutuhkan oleh sebagian besar Pod kamu, tetapi hal ini menawarkan sebuah mekanisme pintu darurat untuk beberapa aplikasi.</p><p>Contohnya, beberapa kegunaan <code>hostPath</code> adalah sebagai berikut:</p><ul><li>Menjalankan sebuah Container yang membutuhkan akses terhadap sistem dalaman Docker; misalnya menggunakan <code>hostPath</code> dari <code>/var/lib/docker</code></li><li>Menjalankan cAdvisor di dalam sebuah Container; menggunakan <code>hostPath</code> dari <code>/sys</code></li><li>Memungkinkan sebuah Pod untuk merinci apakah <code>hostPath</code> harus sudah ada sebelum dijalankannya Pod, apakah ia harus dibuat, dan sebagai apa ia harus dibuat.</li></ul><p>Sebagai tambahan pada <code>path</code> yang dibutuhkan, pengguna dapat secara opsional merinci <code>type</code> untuk sebuah <code>hostPath</code>.</p><p>Nilai yang didukung untuk kolom <code>type</code> adalah:`</p><table><thead><tr><th style=text-align:left>Nilai</th><th style=text-align:left>Perilaku</th></tr></thead><tbody><tr><td style=text-align:left></td><td style=text-align:left>String kosong (bawaan) adalah untuk kecocokan dengan versi-versi bawah, yang berarti bahwa tidak ada pemeriksaan yang dilakukan sebelum menambatkan Volume hostPath.</td></tr><tr><td style=text-align:left><code>DirectoryOrCreate</code></td><td style=text-align:left>Jika tidak ada yang tersedia pada <code>path</code> yang dirinci, sebuah direktori kosong akan dibuat sesuai kebutuhan, dengan <em>permission</em> yang disetel menjadi 0755, dan mempunyai grup dan kepemilikan yang sama dengan Kubelet.</td></tr><tr><td style=text-align:left><code>Directory</code></td><td style=text-align:left>Sebuah direktori harus sudah tersedia pada <code>path</code> yang dirinci</td></tr><tr><td style=text-align:left><code>FileOrCreate</code></td><td style=text-align:left>Jika tidak ada yang tersedia pada <code>path</code> yang dirinci, maka sebuah berkas kosong akan dibuat sesuai kebutuhan dengan <em>permission</em> yang disetel menjadi 0644, dan mempunyai grup dan kepemilikan yang sama dengan Kubelet.</td></tr><tr><td style=text-align:left><code>File</code></td><td style=text-align:left>Sebuah berkas harus sudah tersedia pada <code>path</code> yang dirinci</td></tr><tr><td style=text-align:left><code>Socket</code></td><td style=text-align:left>Sebuah <em>socket</em> UNIX harus sudah tersedia pada <code>path</code> yang dirinci</td></tr><tr><td style=text-align:left><code>CharDevice</code></td><td style=text-align:left>Sebuah <em>character device</em> sudah tersedia pada <code>path</code> yang dirinci</td></tr><tr><td style=text-align:left><code>BlockDevice</code></td><td style=text-align:left>Sebuah <em>block device</em> harus sudah tersedia pada <code>path</code> yang dirinci</td></tr></tbody></table><p>Berhati-hatilah saat menggunakan tipe volume ini, karena:</p><ul><li>Pod-pod dengan konfigurasi identik (misalnya dibuat dari podTemplate) mungkin berperilaku berbeda pada Node-node yang berbeda oleh karena berkas-berkas yang berbeda pada Node-node tersebut.</li><li>Saat Kubernetes menambahkan penjadwalan yang sadar terhadap sumber-daya klaster, sesuai yang telah direncanakan, ia tidak dapat melakukan perhitungan terhadap sumber daya yang digunakan oleh sebuah <code>hostPath</code></li><li>Berkas-berkas atau direktori-direktori yang dibuat pada <em>host-host</em> bersangkutan hanya dapat ditulis oleh <code>root</code>. Kamu butuh antara menjalankan proses aplikasi kamu sebagai <code>root</code> pada sebuah <a href=/docs/user-guide/security-context>privileged Container</a> atau mengubah <em>permission</em> berkas kamu pada <em>host</em> tersebut agar dapat menulis pada Volume <code>hostPath</code></li></ul><h4 id=contoh-pod-2>Contoh Pod</h4><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>test-pd<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>k8s.gcr.io/test-webserver<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>test-container<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>volumeMounts</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:green;font-weight:700>mountPath</span>:<span style=color:#bbb> </span>/test-pd<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>test-volume<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>volumes</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>test-volume<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>hostPath</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:#080;font-style:italic># Lokasi direktori pada host</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>path</span>:<span style=color:#bbb> </span>/data<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:#080;font-style:italic># kolom ini bersifat opsional</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>type</span>:<span style=color:#bbb> </span>Directory<span style=color:#bbb>
</span></span></span></code></pre></div><h3 id=iscsi>iscsi</h3><p>Sebuah Volume <code>iscsi</code> memungkinkan sebuah volume iSCSI (<em>SCSI over IP</em>) yang sudah ada untuk ditambatkan ke dalam Pod kamu.
Tidak seperti <code>emptyDir</code> yang ikut dihapus saat Pod dihapus, isi dari sebuah <code>iscsi</code> dipertahankan dan <em>volume</em>-nya hanya dilepaskan tambatannya. Hal ini berarti sebuah <code>iscsi</code> dapat diisi terlebih dahulu dengan data, dan data tersebut dapat "dioper" diantara Pod-pod.</p><div class="alert alert-warning caution callout" role=alert><strong>Perhatian:</strong> Kamu harus memiliki peladen iSCSI yang berjalan dengan volume iSCSI yang telah dibuat terlebih dahulu untuk dapat menggunakannya.</div><p>Salah satu fitur iSCSI yaitu mereka dapat ditambatkan sebagai <em>read-only</em> secara bersamaan oleh beberapa pengguna. Hal ini berarti kamu dapat mengisi data terlebih dahulu dan menyediakan data tersebut secara paralel untuk sebanyak apapun Pod yang kamu butuhkan. Sayangnya, iSCSI hanya dapat ditambatkan kepada satu pengguna saja pada mode <em>read-write</em> - yaitu, tidak boleh ada banyak penulis secara bersamaan.</p><p>Lihat <a href=https://github.com/kubernetes/examples/tree/main/staging/volumes/iscsi>contoh iSCSI</a> untuk lebih detil.</p><h3 id=local>local</h3><div style=margin-top:10px;margin-bottom:10px><b>FEATURE STATE:</b> <code>Kubernetes v1.14 [stable]</code></div><p>Sebuah Volume <code>local</code> merepresentasikan sebuah media penyimpanan lokal yang ditambatkan, seperti <em>disk</em>, partisi, atau direktori.</p><p>Volume <code>local</code> hanya dapat digunakan sebagai PersistentVolume yang dibuat secara statis. <em>Dynamic provisioning</em> belum didukung untuk Volume <code>local</code>.</p><p>Dibandingkan dengan Volume <code>hostPath</code>, Volume <code>local</code> dapat digunakan secara <em>durable</em> dan portabel tanpa harus menjadwalkan Pod ke Node secara manual, dikarenakan sistem mengetahui pembatasan yang berlaku terhadap Volume pada Node tersebut, dengan cara melihat <code>node affinity</code> pada PersistentVolume-nya.</p><p>Tetapi, Volume <code>local</code> masih bergantung pada ketersediaan Node yang bersangkutan, dan tidak semua aplikasi cocok menggunakannya. Jika sebuah Node tiba-tiba gagal, maka Volume <code>local</code> pada Node tersebut menjadi tidak dapat diakses juga, dan Pod yang menggunakannya tidak dapat dijalankan. Aplikasi yang menggunakan Volume<code>local</code> harus dapat mentoleransi hal ini dan juga potensi kehilangan data, tergantung pada karakteristik ketahanan <em>disk</em> yang digunakan.</p><p>Berikut sebuah contoh spesifikasi PersistentVolume menggunakan sebuah Volume <code>local</code> dan <code>nodeAffinity</code>:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>PersistentVolume<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>example-pv<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>capacity</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>storage</span>:<span style=color:#bbb> </span>100Gi<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:#080;font-style:italic># kolom volumeMode membutuhkan diaktifkannya feature gate Alpha</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>volumeMode</span>:<span style=color:#bbb> </span>Filesystem<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>accessModes</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- ReadWriteOnce<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>persistentVolumeReclaimPolicy</span>:<span style=color:#bbb> </span>Delete<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>storageClassName</span>:<span style=color:#bbb> </span>local-storage<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>local</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>path</span>:<span style=color:#bbb> </span>/mnt/disks/ssd1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>nodeAffinity</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>required</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>nodeSelectorTerms</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- <span style=color:green;font-weight:700>matchExpressions</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span>- <span style=color:green;font-weight:700>key</span>:<span style=color:#bbb> </span>kubernetes.io/hostname<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>operator</span>:<span style=color:#bbb> </span>In<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>values</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span>- example-node<span style=color:#bbb>
</span></span></span></code></pre></div><p>Kolom <code>nodeAffinity</code> ada PersistentVolue dibutuhkan saat menggunakan Volume <code>local</code>. Ia memungkinkan Kubernetes Scheduler untuk menjadwalkan Pod-pod dengan tepat menggunakan Volume <code>local</code> pada Node yang tepat.</p><p>Kolom <code>volumeMode</code> pada PersistentVolume sekarang dapat disetel menjadi "Block" (menggantikan nilai bawaan "Filesystem") untuk membuka Volume <code>local</code> tersebut sebagai media penyimpanan blok mentah. Hal ini membutuhkan diaktifkannya <em>Alpha feature gate</em> <code>BlockVolume</code>.</p><p>Saat menggunakan Volume <code>local</code>, disarankan untuk membuat sebuah StorageClass dengan <code>volumeBindingMode</code> yang disetel menjadi <code>WaitForFirstConsumer</code>. Lihat<a href=/id/docs/concepts/storage/storage-classes/#local>contohnya</a>. Menunda pengikatan Volume memastikan bahwa keputusan pengikatan PersistentVolumeClaim juga akan dievaluasi terhadap batasan-batasan Node yang berlaku pada Pod, seperti kebutuhan sumber daya Node, <code>nodeSelector</code>, <code>podAffinity</code>, dan <code>podAntiAffinity</code>.</p><p>Sebuah penyedia statis eksternal dapat berjalan secara terpisah untuk memperbaik pengaturan siklus hidup Volume <code>local</code>. Perlu dicatat bahwa penyedia ini belum mendukung <em>dynamic provisioning</em>. Untuk contoh bagaimana menjalankan penyedia Volume <code>local</code> eksternal, lihat <a href=https://github.com/kubernetes-sigs/sig-storage-local-static-provisioner>petunjuk penggunaannya</a>.</p><div class="alert alert-info note callout" role=alert><strong>Catatan:</strong> PersistentVolume lokal membutuhkan pembersihan dan penghapusan secara manual oleh pengguna jika penyedia eksternal tidak digunakan untuk mengatur siklus hidup Volume <code>lokal</code> tersebut.</div><h3 id=nfs>nfs</h3><p>Sebuah Volume <code>nfs</code> memungkinkan sebuah NFS (Network File System) yang sudah ada untuk ditambatkan ke dalam Pod kamu.
Tidak seperti <code>emptyDir</code> yang ikut dihapus saat Pod dihapus, isi dari sebuah <code>nfs</code> dipertahankan dan <em>volume</em>-nya hanya dilepaskan tambatannya. Hal ini berarti sebuah <code>nfs</code> dapat diisi terlebih dahulu dengan data, dan data tersebut dapat "dioper" diantara Pod-pod. NFS juga dapat ditambatkan oleh beberapa penulis secara sekaligus.</p><div class="alert alert-warning caution callout" role=alert><strong>Perhatian:</strong> Kamu harus memiliki peladen NFS yang berjalan dengan <em>share</em> yang diekspor sebelum kamu dapat menggunakannya.</div><p>Lihat <a href=https://github.com/kubernetes/examples/tree/main/staging/volumes/nfs>contoh NFS</a> untuk lebih lanjut.</p><h3 id=persistentvolumeclaim>persistentVolumeClaim</h3><p>Sebuah Volume <code>persistentVolumeClaim</code> digunakan untuk menambatkan sebuah <a href=/id/docs/concepts/storage/persistent-volumes/>PersistentVolume</a> ke dalam sebuag Pod. PersistentVolume adalah sebuah cara bagi pengguna untuk "mengklaim" penyimpanan yang <em>durable</em> (seperti sebuah GCE PD atau sebuah volume iSCSI) tanpa mengetahui detil lingkungan <em>cloud</em> yang bersangkutan.</p><p>Lihat <a href=/id/docs/concepts/storage/persistent-volumes/>contoh PersistentVolumes</a> untuk lebih lanjut.</p><h3 id=projected>projected</h3><p>Sebuah Volume <code>projected</code> memetakan beberapa sumber Volume yang sudah ada ke dalam direktori yang sama.</p><p>Saat ini, tipe-tipe sumber Volume berikut dapat diproyeksikan:</p><ul><li><a href=#secret><code>secret</code></a></li><li><a href=#downwardapi><code>downwardAPI</code></a></li><li><a href=#configmap><code>configMap</code></a></li><li><code>serviceAccountToken</code></li></ul><p>Semua sumber harus berada pada <code>namespace</code> yang sama dengan Pod yang menggunakannya. Untuk lebih lanjut, lihat <a href=https://github.com/kubernetes/community/blob/main/contributors/design-proposals/node/all-in-one-volume.md>dokumen desain Volume</a>.</p><p>Proyeksi <code>serviceAccountToken</code> adalah fitur yang diperkenalkan pada Kubernetes 1.11 dan dipromosikan menjadi Beta pada 1.12.
Untuk mengaktifkan fitur inipada 1.11, kamu harus menyetel <a href=/docs/reference/command-line-tools-reference/feature-gates/>feature gate</a> <code>TokenRequestProjection</code> secara eksplisit menjadi <code>True</code>.</p><h4 id=contoh-pod-dengan-sebuah-secret-downward-api-dan-configmap>Contoh Pod dengan sebuah Secret, Downward API, dan ConfigMap.</h4><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>volume-test<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>container-test<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>busybox<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>volumeMounts</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>all-in-one<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>mountPath</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;/projected-volume&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>readOnly</span>:<span style=color:#bbb> </span><span style=color:#a2f;font-weight:700>true</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>volumes</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>all-in-one<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>projected</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>sources</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- <span style=color:green;font-weight:700>secret</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>mysecret<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>items</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>            </span>- <span style=color:green;font-weight:700>key</span>:<span style=color:#bbb> </span>username<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>              </span><span style=color:green;font-weight:700>path</span>:<span style=color:#bbb> </span>my-group/my-username<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- <span style=color:green;font-weight:700>downwardAPI</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>items</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>            </span>- <span style=color:green;font-weight:700>path</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;labels&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>              </span><span style=color:green;font-weight:700>fieldRef</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>                </span><span style=color:green;font-weight:700>fieldPath</span>:<span style=color:#bbb> </span>metadata.labels<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>            </span>- <span style=color:green;font-weight:700>path</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;cpu_limit&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>              </span><span style=color:green;font-weight:700>resourceFieldRef</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>                </span><span style=color:green;font-weight:700>containerName</span>:<span style=color:#bbb> </span>container-test<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>                </span><span style=color:green;font-weight:700>resource</span>:<span style=color:#bbb> </span>limits.cpu<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- <span style=color:green;font-weight:700>configMap</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>myconfigmap<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>items</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>            </span>- <span style=color:green;font-weight:700>key</span>:<span style=color:#bbb> </span>config<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>              </span><span style=color:green;font-weight:700>path</span>:<span style=color:#bbb> </span>my-group/my-config<span style=color:#bbb>
</span></span></span></code></pre></div><h4 id=contoh-pod-dengan-banyak-secret-dengan-mode-permission-bukan-bawaan>Contoh Pod dengan banyak Secret dengan mode permission bukan bawaan</h4><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>volume-test<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>container-test<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>busybox<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>volumeMounts</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>all-in-one<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>mountPath</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;/projected-volume&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>readOnly</span>:<span style=color:#bbb> </span><span style=color:#a2f;font-weight:700>true</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>volumes</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>all-in-one<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>projected</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>sources</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- <span style=color:green;font-weight:700>secret</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>mysecret<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>items</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>            </span>- <span style=color:green;font-weight:700>key</span>:<span style=color:#bbb> </span>username<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>              </span><span style=color:green;font-weight:700>path</span>:<span style=color:#bbb> </span>my-group/my-username<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- <span style=color:green;font-weight:700>secret</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>mysecret2<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>items</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>            </span>- <span style=color:green;font-weight:700>key</span>:<span style=color:#bbb> </span>password<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>              </span><span style=color:green;font-weight:700>path</span>:<span style=color:#bbb> </span>my-group/my-password<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>              </span><span style=color:green;font-weight:700>mode</span>:<span style=color:#bbb> </span><span style=color:#666>511</span><span style=color:#bbb>
</span></span></span></code></pre></div><p>Setiap sumber Volume <code>projected</code> terdaftar pada spesifikasi di kolom <code>sources</code>. Parameter-parameter tersebut hampir sama persis dengan dua pengecualian berikut:</p><ul><li>Untuk Secret, kolom <code>secretName</code> telah diganti menjadi <code>name</code> agar konsisten dengan penamaan ConfigMap.</li><li>Kolom <code>defaultMode</code> hanya dapat dispesifikasikan pada tingkat <code>projected</code> dan tidak untuk setiap sumber Volume. Tetapi, seperti yang ditunjukkan di atas, kamu dapat secara eksplisit menyetel <code>mode</code> untuk setiap proyeksi.</li></ul><p>Saat fitur <code>TokenRequestProjection</code> diaktifkan, kamu dapat menyuntikkan <em>token</em> untuk <a href=/docs/reference/access-authn-authz/authentication/#service-account-tokens>ServiceAccount</a> yang bersangkutan ke dalam Pod pada <code>path</code> yang diinginkan. Berikut contohnya:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>sa-token-test<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>container-test<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>busybox<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>volumeMounts</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>token-vol<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>mountPath</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;/service-account&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>readOnly</span>:<span style=color:#bbb> </span><span style=color:#a2f;font-weight:700>true</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>volumes</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>token-vol<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>projected</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>sources</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- <span style=color:green;font-weight:700>serviceAccountToken</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>audience</span>:<span style=color:#bbb> </span>api<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>expirationSeconds</span>:<span style=color:#bbb> </span><span style=color:#666>3600</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>path</span>:<span style=color:#bbb> </span>token<span style=color:#bbb>
</span></span></span></code></pre></div><p>Contoh Pod tersebut memiliki Volume <code>projected</code> yang berisi token ServiceAccount yang disuntikkan. Token ini dapat digunakan oleh Container dalam Pod untuk mengakses Kubernetes API Server misalnya. Kolom <code>audience</code> berisi audiensi token yang dituju. Sebuah penerima token tersebut harus mengidentifikasikan dirinya dengan tanda pengenal yang dispesifikasikan pada <code>audience</code> token tersebut, atau jika tidak, harus menolak token tersebut. Kolom ini bersifat opsional dan secara bawaan akan berisi tanda pengenal API Server.</p><p>Kolom <code>expirationSeconds</code> adalah masa berlaku yang diinginkan untuk token ServiceAccount tersebut. Secara bawaan, nilainya adalah 1 jam dan harus paling singkat bernilai 10 menit (600 detik). Seorang administrator juga dapat membatasi nilai maksimumnya dengan menyetel opsi <code>--service-account-max-token-expiration</code> pada API Server. Kolom <code>path</code> menunjukkan <em>relative path</em> untuk menambatkan Volume <code>projected</code> tersebut.</p><div class="alert alert-info note callout" role=alert><strong>Catatan:</strong> Sebuah Container yang menggunakan sebuah sumber Volume <code>projected</code> sebagai tambatan Volume <a href=#menggunakan-subpath>subPath</a> tidak akan menerima pembaruan pada sumber Volume tersebut.</div><h3 id=portworxvolume>portworxVolume</h3><p>Sebuah <code>portworxVolume</code> adalah sebuah penyimpanan blok elastis yang berjalan secara <em>hyperconverged</em> dengan Kubernetes. <a href=https://portworx.com/use-case/kubernetes-storage/>Portworx</a> mengambil sidik jari media penyimpanan pada sebuah <em>server</em>, mengklasifikasikannya berdasarkan kemampuannya, dan mengagregasikan kapasitasnya di banyak <em>server</em>. Portworx berjalan secara <em>in-guest</em> pada mesin virtual atau pada Node Linux <em>bare metal</em>.</p><p>Sebuah <code>portworxVolume</code> dapat dibuat secara dinamis melalui Kubernetes, atau ia juga dapat disediakan terlebih dahulu dan dirujuk dari dalam Pod Kubernetes. Berikut contoh sebuah Pod yang mereferensikan PortworxVolume yang telah disediakan terlebih dahulu:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>test-portworx-volume-pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>k8s.gcr.io/test-webserver<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>test-container<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>volumeMounts</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:green;font-weight:700>mountPath</span>:<span style=color:#bbb> </span>/mnt<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>pxvol<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>volumes</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>pxvol<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:#080;font-style:italic># Volume Portworx ini harus sudah tersedia.</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>portworxVolume</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>volumeID</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;pxvol&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>fsType</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;&lt;fs-type&gt;&#34;</span><span style=color:#bbb>
</span></span></span></code></pre></div><div class="alert alert-warning caution callout" role=alert><strong>Perhatian:</strong> Pastikan kamu sudah memiliki PortworxVolume dengan nama <code>pxvol</code> sebelum dapat menggunakannya pada Pod.</div><p>Lihat <a href=https://github.com/kubernetes/examples/tree/main/staging/volumes/portworx/README.md>di sini</a> untuk lebih lanjut.</p><h3 id=quobyte>quobyte</h3><p>Sebuah Volume <code>quobyte</code> memungkinkan sebuah volume <a href=http://www.quobyte.com>Quobyte</a> yang sudah tersedia untuk ditambatkan ke dalam Pod kamu.</p><div class="alert alert-warning caution callout" role=alert><strong>Perhatian:</strong> Kamu harus sudah memiliki instalasi Quobyte dengan volume yang sudah disediakan terlebih dahulu untuk dapat menggunakannya.</div><p>Quobyte mendukung <a class=glossary-tooltip title='The Container Storage Interface (CSI) defines a standard interface to expose storage systems to containers.' data-toggle=tooltip data-placement=top href=/docs/concepts/storage/volumes/#csi target=_blank aria-label='Container Storage Interface'>Container Storage Interface</a>.
CSI adalah <em>plugin</em> yang direkomendasikan untuk menggunakan Volume Quobyte di dalam Kubernetes. Ada <a href=https://github.com/quobyte/quobyte-csi#quobyte-csi>petunjuk dan contoh</a> untuk menggunakan Quobyte menggunakan CSI pada proyek GitHub Quobyte.j</p><h3 id=rbd>rbd</h3><p>Sebuah Volume <code>rbd</code> memungkinkan sebuah volume <a href=http://ceph.com/docs/master/rbd/rbd/>Rados Block Device</a> ditambatkan ke dalam Pod kamu.
Tidak seperti <code>emptyDir</code> yang ikut dihapus saat Pod dihapus, isi dari sebuah <code>rbd</code> dipertahankan dan <em>volume</em>-nya hanya dilepaskan tambatannya. Hal ini berarti sebuah <code>rbd</code> dapat diisi terlebih dahulu dengan data, dan data tersebut dapat "dioper" diantara Pod-pod.</p><div class="alert alert-warning caution callout" role=alert><strong>Perhatian:</strong> Kamu harus memiliki instalasi Ceph yang berjalan sebelum kamu dapat menggunakan RBD.</div><p>Sebuah fitur RBD yaitu mereka dapat ditambatkan sebagai <em>read-only</em> secara bersamaan oleh beberapa pengguna. Hal ini berarti kamu dapat mengisi data terlebih dahulu dan menyediakan data tersebut secara paralel untuk sebanyak apapun Pod yang kamu butuhkan. Sayangnya, RBD hanya dapat ditambatkan kepada satu pengguna saja pada mode <em>read-write</em> - yaitu, tidak boleh ada banyak penulis secara bersamaan.</p><p>Lihat <a href=https://github.com/kubernetes/examples/tree/main/staging/volumes/rbd>contoh RBD</a> untuk lebih lanjut.</p><h3 id=scaleio>scaleIO</h3><p>ScaleIO adalah <em>platform</em> penyimpanan berbasis perangkat lunak yang dapat menggunakan perangkat keras yang sudah tersedia untuk membuat klaster-klaster media penyimpanan terhubung jaringan yang <em>scalable</em>. <em>Plugin</em> Volume <code>scaleIO</code> memungkinkan Pod-pod yang di-<em>deploy</em> untuk mengakses Volume-volume ScaleIO yang telah tersedia (atau dapat menyediakan volume-volume untuk PersistentVolumeClaim secara dinamis, lihat <a href=/id/docs/concepts/storage/persistent-volumes/#scaleio>Persistent Volume ScaleIO</a>).</p><div class="alert alert-warning caution callout" role=alert><strong>Perhatian:</strong> Kamu harus memiliki klaster ScaleIO yang berjalan dengan volume-volume yang sudah dibuat sebelum kamu dapat menggunakannya.</div><p>Berikut contoh konfigurasi sebuah Pod yang menggunakan ScaleIO:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>pod-0<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>k8s.gcr.io/test-webserver<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>pod-0<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>volumeMounts</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:green;font-weight:700>mountPath</span>:<span style=color:#bbb> </span>/test-pd<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>vol-0<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>volumes</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>vol-0<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>scaleIO</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>gateway</span>:<span style=color:#bbb> </span>https://localhost:443/api<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>system</span>:<span style=color:#bbb> </span>scaleio<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>protectionDomain</span>:<span style=color:#bbb> </span>sd0<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>storagePool</span>:<span style=color:#bbb> </span>sp1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>volumeName</span>:<span style=color:#bbb> </span>vol-0<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>secretRef</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>sio-secret<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>fsType</span>:<span style=color:#bbb> </span>xfs<span style=color:#bbb>
</span></span></span></code></pre></div><p>Lihat <a href=https://github.com/kubernetes/examples/tree/main/staging/volumes/scaleio>contoh ScaleIO</a> untuk lebih lanjut.</p><h3 id=secret>secret</h3><p>Sebuah Volume <code>secret</code> digunakan untuk memberikan informasi yang bersifat sensitif, seperti kata sandi, kepada Pod-pod. Kamu dapat menaruh <code>secret</code> dalam Kubernetes API dan menambatkan mereka sebagai berkas-berkas untuk digunakan oleh Pod-pod tanpa harus terikat pada Kubernetes secara langsung. Volume <code>secret</code> didukung oleh tmpfs (<em>filesystem</em> yang didukung oleh RAM) sehingga mereka tidak pernah ditulis pada media penyimpanan yang <em>non-volatile</em>.</p><div class="alert alert-warning caution callout" role=alert><strong>Perhatian:</strong> Kamu harus membuat sebuah <code>secret</code> di dalam Kubernetes API sebelum kamu dapat menggunakannya.</div><div class="alert alert-info note callout" role=alert><strong>Catatan:</strong> Sebuah Container yang menggunakan sebuah Secret sebagai sebuah Volume <a href=#menggunakan-subpath>subPath</a> tidak akan mendapatkan pembaruan terhadap Secret.</div><p>Secret dijelaskan lebih lanjut <a href=/docs/user-guide/secrets>di sini</a>.</p><h3 id=storageos>storageOS</h3><p>Sebuah Volume <code>storageos</code> memungkinkan volume <a href=https://www.storageos.com>StorageOS</a> yang sudah tersedia untuk ditambatkan ke dalam Pod kamu.</p><p>StorageOS berjalan sebagai sebuah COntainer di dalam lingkungan Kubernetes kamu, membuat penyimpanan yang lokal atau penyimpanan yang sedang dipasang untuk diakses dari Node manapun di dalam klaster Kubernetes.
Data dapat direplikasikan untuk melindungi dari kegagalan Node. <em>Thin provisioning</em> dan kompresi dapat meningkatkan utilisasi dan mengurangi biaya.</p><p>Di dalam intinya, StorageOS menyediakan penyimpanan blok kepada Container-container, yang dapat diakses melalui sebuah <em>filesystem</em>.</p><p>Container StorageOS membutuhkan Linux 64-bit dan tidak memiliki ketergantungan tambahan apapun.
Tersedia pula sebuah lisensi gratis untuk <em>developer</em>.</p><div class="alert alert-warning caution callout" role=alert><strong>Perhatian:</strong> Kamu harus menjalankan Container StorageOS pada setiap Node yang ingin mengakses volume-volume StorageOS atau yang akan berkontribusi pada kapasitas penyimpanan di klaster StorageOS. Untuk petunjuk instalasi, lihat <a href=https://docs.storageos.com>dokumentasi StorageOS</a>.</div><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>labels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>redis<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>role</span>:<span style=color:#bbb> </span>master<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>test-storageos-redis<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>master<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>kubernetes/redis:v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>env</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>MASTER<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>value</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;true&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>ports</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span>- <span style=color:green;font-weight:700>containerPort</span>:<span style=color:#bbb> </span><span style=color:#666>6379</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>volumeMounts</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span>- <span style=color:green;font-weight:700>mountPath</span>:<span style=color:#bbb> </span>/redis-master-data<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>redis-data<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>volumes</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>redis-data<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>storageos</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:#080;font-style:italic># Volume `redis-vol01` harus sudah tersedia di dalam StorageOS pada Namespace `default`</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>volumeName</span>:<span style=color:#bbb> </span>redis-vol01<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>fsType</span>:<span style=color:#bbb> </span>ext4<span style=color:#bbb>
</span></span></span></code></pre></div><p>Untuk lebih lanjut, termasuk Dynamic Provisioning dan Persistent Volume Claim, lihat <a href=https://github.com/kubernetes/examples/blob/master/staging/volumes/storageos>contoh-contoh StorageOS</a>.</p><h3 id=vspherevolume>vsphereVolume</h3><div class="alert alert-info note callout" role=alert><strong>Catatan:</strong> Prasyarat: Kubernetes dengan Cloud Provider vSphere yang telah dikonfigurasikan. Untuk konfigurasi cloudprovider, silahkan lihat <a href=https://vmware.github.io/vsphere-storage-for-kubernetes/documentation/>petunjuk memulai vSphere</a>.</div><p>Sebuah <code>vsphereVolume</code> digunakan untuk menambatkan sebuah Volume VMDK vSphere ke dalam Pod kamu. Isi dari sebuah volume dipertahankan pada saat tambatannya dilepas. Ia mendukung penyimpanan data VMFS dan VSAN.</p><div class="alert alert-warning caution callout" role=alert><strong>Perhatian:</strong> Kamu harus membuat VMDK menggunakan satu dari cara-cara berikut sebelum menggunakannya dengan Pod.</div><h4 id=membuat-sebuah-volume-vmdk>Membuat sebuah Volume VMDK</h4><p>Pilih satu dari beberapa cara berikut untuk membuat sebuah VMDK.</p><ul class="nav nav-tabs" id=tabs-volumes role=tablist><li class=nav-item><a data-toggle=tab class="nav-link active" href=#tabs-volumes-0 role=tab aria-controls=tabs-volumes-0 aria-selected=true>Create using vmkfstools</a></li><li class=nav-item><a data-toggle=tab class=nav-link href=#tabs-volumes-1 role=tab aria-controls=tabs-volumes-1>Create using vmware-vdiskmanager</a></li></ul><div class=tab-content id=tabs-volumes><div id=tabs-volumes-0 class="tab-pane show active" role=tabpanel aria-labelledby=tabs-volumes-0><p><p>Pertama-tama, ssh ke dalam ESX, kemudian gunakan perintah berikut untuk membuat sebuah VMDK:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>vmkfstools -c 2G /vmfs/volumes/DatastoreName/volumes/myDisk.vmdk
</span></span></code></pre></div></div><div id=tabs-volumes-1 class=tab-pane role=tabpanel aria-labelledby=tabs-volumes-1><p><p>Gunakan perintah berikut untuk membuat sebuah VMDK:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>vmware-vdiskmanager -c -t <span style=color:#666>0</span> -s 40GB -a lsilogic myDisk.vmdk
</span></span></code></pre></div></div></div><h4 id=contoh-konfigurasi-vsphere-vmdk>Contoh Konfigurasi vSphere VMDK</h4><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>test-vmdk<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>k8s.gcr.io/test-webserver<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>test-container<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>volumeMounts</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:green;font-weight:700>mountPath</span>:<span style=color:#bbb> </span>/test-vmdk<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>test-volume<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>volumes</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>test-volume<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:#080;font-style:italic># Volume VMDK ini harus sudah tersedia.</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>vsphereVolume</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>volumePath</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;[DatastoreName] volumes/myDisk&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>fsType</span>:<span style=color:#bbb> </span>ext4<span style=color:#bbb>
</span></span></span></code></pre></div><p>Lebih banyak contoh dapat ditemukan <a href=https://github.com/kubernetes/examples/tree/master/staging/volumes/vsphere>di sini</a>.</p><h2 id=menggunakan-subpath>Menggunakan subPath</h2><p>Terkadang, diperlukan untuk membagi sebuah Volume untuk banyak kegunaan berbeda pada sebuah Pod. Kolom <code>volumeMounts.subPath</code> dapat digunakan untuk merinci sebuah <em>sub-path</em> di dalam Volume yang dimaksud, menggantikan <em>root path</em>-nya.</p><p>Berikut contoh sebuah Pod dengan <em>stack</em> LAMP (Linux Apache Mysql PHP) menggunakan sebuah Volume yang dibagi-bagi.
Isi HTML-nya dipetakan ke dalam direktori <code>html</code>-nya, dan <em>database</em>-nya akan disimpan di dalam direktori <code>mysql</code>-nya.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>my-lamp-site<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>mysql<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>mysql<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>env</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>MYSQL_ROOT_PASSWORD<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>value</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;rootpasswd&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>volumeMounts</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- <span style=color:green;font-weight:700>mountPath</span>:<span style=color:#bbb> </span>/var/lib/mysql<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>site-data<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>subPath</span>:<span style=color:#bbb> </span>mysql<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>php<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>php:7.0-apache<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>volumeMounts</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- <span style=color:green;font-weight:700>mountPath</span>:<span style=color:#bbb> </span>/var/www/html<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>site-data<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>subPath</span>:<span style=color:#bbb> </span>html<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>volumes</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>site-data<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>persistentVolumeClaim</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>claimName</span>:<span style=color:#bbb> </span>my-lamp-site-data<span style=color:#bbb>
</span></span></span></code></pre></div><h3 id=menggunakan-subpath-dengan-environment-variable-yang-diekspansi>Menggunakan subPath dengan <em>environment variable</em> yang diekspansi</h3><div style=margin-top:10px;margin-bottom:10px><b>FEATURE STATE:</b> <code>Kubernetes v1.15 [beta]</code></div><p>Gunakan kolom <code>subPathExpr</code> untuk membuat nama-nama direktori <code>subPath</code> dari <em>environment variable</em> Downward API.
Sebelum kamu menggunakan fitur ini, kamu harus mengaktifkan <em>feature gate</em> <code>VolumeSubpathEnvExpansion</code>. Kolom <code>subPath</code> dan <code>subPathExpr</code> bersifat <em>mutually exclusive</em>.</p><p>Pada contoh ini, sebuah Pod menggunakan <code>subPathExpr</code> untuk membuat sebuah direktori <code>pod1</code> di dalam Volume hostPath <code>/var/log/pods</code>, menggunakan nama Pod dari Downward API. Direktori <em>host</em> <code>/var/log/pods/pod1</code> ditambatkan pada <code>/logs</code> di dalam Container-nya.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>pod1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>container1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>env</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>POD_NAME<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>valueFrom</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>fieldRef</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>fieldPath</span>:<span style=color:#bbb> </span>metadata.name<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>busybox<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>command</span>:<span style=color:#bbb> </span>[<span style=color:#bbb> </span><span style=color:#b44>&#34;sh&#34;</span>,<span style=color:#bbb> </span><span style=color:#b44>&#34;-c&#34;</span>,<span style=color:#bbb> </span><span style=color:#b44>&#34;while [ true ]; do echo &#39;Hello&#39;; sleep 10; done | tee -a /logs/hello.txt&#34;</span><span style=color:#bbb> </span>]<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>volumeMounts</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>workdir1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>mountPath</span>:<span style=color:#bbb> </span>/logs<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>subPathExpr</span>:<span style=color:#bbb> </span>$(POD_NAME)<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>restartPolicy</span>:<span style=color:#bbb> </span>Never<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>volumes</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>workdir1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>hostPath</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>path</span>:<span style=color:#bbb> </span>/var/log/pods<span style=color:#bbb>
</span></span></span></code></pre></div><h2 id=sumber-sumber>Sumber-sumber</h2><p>Media penyimpanan (Disk, SSD, dll.) dari sebuah Volume <code>emptyDir</code> ditentukan oleh medium dari <em>filesystem</em> yang menyimpan direktori <em>root</em> dari Kubelet (biasanya <code>/var/lib/kubelet</code>). Tidak ada batasan berapa banyak ruang yang dapat digunakan oleh Volume <code>emptyDir</code> dan <code>hostPath</code>, dan tidak ada isolasi antara Container-container atau antara Pod-pod.</p><p>Ke depannya, kita mengharapkan Volume <code>emptyDir</code> dan <code>hostPath</code> akan dapat meminta jumlah ruangan penyimpanan tertentu dengan mengunakan spesifikasi [resource]<a href=/docs/user-guide/compute-resources>resource</a>, dan memilih tipe media penyimpanan yang akan digunakan, untuk klaster yang memiliki beberapa jenis media penyimpanan.</p><h2 id=plugin-volume-yang-out-of-tree><em>Plugin</em> Volume yang Out-of-Tree</h2><p><em>Plugin</em> Volume yang Out-of-tree termasuk Container Storage Interface (CSI) dan Flexvolume. Mereka memungkinkan <em>vendor</em> penyimpanan untuk membuat plugin penyimpanan buatan tanpa perlu menambahkannya pada <em>repository</em> Kubernetes.</p><p>Sebelum dikenalkannya CSI dan Flexvolume, semua <em>plugin</em> volume (seperti jenis-jenis volume yang terdaftar di atas) berada pada "in-tree", yang berarti bahwa mereka dibangun, di-<em>link</em>, di-<em>compile</em>, dan didistribusikan bersama-sama dengan kode inti Kubernetes dan mengekstensi inti dari Kubernetes API. Hal ini berarti menambah sistem penyimpanan baru ke dalam Kubernetes (sebuah <em>plugin</em> volume) membutukan penambahan kode tersebut ke dalam <em>repository</em> kode inti Kubernetes.</p><p>CSI dan Flexvolume memungkinkan <em>plugin</em> volume untuk dikembangkan secara terpisah dari kode inti Kubernetes, dan diinstal pada klaster Kubernetes sebagai ekstensi.</p><p>Bagi <em>vendor-vendor</em> penyimpanan yang ingin membuat sebuah <em>plugin</em> volume yang out-of-tree, lihat <a href=https://github.com/kubernetes/community/blob/master/sig-storage/volume-plugin-faq.md>FAQ ini</a>.</p><h3 id=csi>CSI</h3><p><a href=https://github.com/container-storage-interface/spec/blob/master/spec.md>Container Storage Interface</a> (CSI) mendefinisikan standar antarmuka untuk sistem orkestrasi (seperti Kubernetes) untuk mengekspos sistem penyimpanan apapun ke dalam beban kerja Container mereka.</p><p>Silahkan lihat <a href=https://github.com/kubernetes/community/blob/master/contributors/design-proposals/storage/container-storage-interface.md>proposal desain CSI</a> untuk lebih lanjut.</p><p>Dukungan untuk CSI dikenalkan sebagai Alpha pada Kubernetes v1.9, dan menjadi Beta pada Kubernetes v1.10, dan menjadi GA pada Kubernetes v1.13.</p><div class="alert alert-info note callout" role=alert><strong>Catatan:</strong> Dukungan untuk spesifikasi CSI pada versi 0.2 dan 0.3 telah kedaluwarsa pada Kubernetes v1.13 dan akan dihapus pada rilis-rilis di masa depan.</div><div class="alert alert-info note callout" role=alert><strong>Catatan:</strong> <em>Driver-driver</em> CSI mungkin tidak cocok pada semua rilis Kubernetes.
Silahkan lihat dokumentasi <em>driver</em> CSI yang bersangkutan untuk petunjuk penggunaan yang didukung untuk setiap rilis Kubernetes, dan untuk melihat matriks kompabilitasnya.</div><p>Saat sebuah <em>driver</em> volume CSI dipasang pada klaster Kubernetes, pengguna dapat menggunakan tipe Volume <code>csi</code> untuk menambatkan volume-volume yang diekspos oleh <em>driver</em> CSI tersebut.</p><p>Tipe Volume <code>csi</code> tidak mendukung referensi secara langsung dari Pod dan hanya dapat dirujuk di dalam sebuah Pod melalui sebuah objek <code>PersistentVolumeClaim</code>.</p><p>Kolom-kolom berikut tersedia untuk administrator-administrator penyimpanan untuk mengkonfigurasi sebuah Persistent Volume CSI.</p><ul><li><code>driver</code>: Sebuah nilai string yang merinci nama dari <em>driver</em> volume yang akan digunakan.
Nilai ini harus sesuai dengan nilai yang dikembalikan oleh <code>GetPluginInfoResponse</code> dari _driver_CSI seperti yang didefinisikan pada <a href=https://github.com/container-storage-interface/spec/blob/master/spec.md#getplugininfo>spesifikasi CSI</a>.
Ia digunakan oleh Kubernetes untuk mengidentifikasikan <em>driver</em> CSI mana yang akan dipanggil, dan oleh komponen <em>driver</em> CSI untuk mengidentifikasikan objek PersistentVolume mana yang dimiliki oleh <em>driver</em> CSI tersebut.</li><li><code>volumeHandle</code>: Sebuah nilai string yang secara unik mengidentifikasikan volume tersebut.
Nilai ini harus sesuai dengan nilai yang dikembalikan oleh kolom <code>volume.id</code> dari <code>CreateVolumeResponse</code> dari <em>driver</em> CSI seperti yang didefinisikan pada <a href=https://github.com/container-storage-interface/spec/blob/master/spec.md#createvolume>spesifikasi CSI</a>.
Nilai tersebut dioper sebagai <code>volume_id</code> pada semua panggilan terhadap <em>driver</em> volume CSI saat mereferensikan volume yang bersangkutan.</li><li><code>readOnly</code>: Sebuah nilai boolean bersifat opsional yang mengindikasikan jika sebuah volume akan dijadikan sebagai "ControllerPublished" (ditambatkan) sebagai <em>read-only</em>.
Nilai bawaannya adalah <code>false</code>. Nilai ini dioper ke <em>driver</em> CSI melalui kolom <code>readonly</code> pada <code>ControllerPublishVolumeRequest</code>.</li><li><code>fsType</code>: Jika nilai <code>VolumeMode</code> milik PV adalah <code>FileSystem</code>, maka kolom ini dapat digunakan untuk menunjukkan <em>filesystem</em> yang akan digunakan untu menambatkan volume tersebut.
Jika volume tersebut belum diformat dan memformat tidak didukung, maka nilai ini akan digunakan untuk memformat volume tersebut. Nilai ini dioper kepada <em>driver</em> CSI melalui kolom <code>VolumeCapability</code> dari <code>ControllerPublishVolumeRequest</code>, <code>NodeStageVolumeRequest</code>, dan <code>NodePublishVolumeRequest</code>.</li><li><code>volumeAttributes</code>: Sebuah <em>map</em> dari string kepada string yang merinci properti statis dari sebuah volume.
Nilai <em>map</em> ini harus sesuai dengan <em>map</em> yang dikembalikan di dalam kolom <code>volume.attributes</code> pada <code>CreateVolumeResponse</code> dari <em>driver</em> CSI seperti yang didefinisikan pada <a href=https://github.com/container-storage-interface/spec/blob/master/spec.md#createvolume>spesifikasi CSI</a>.
<em>Map</em> tersebut dioper kepada <em>driver</em> CSI melalui kolom <code>volume_attributes</code> pada<code>ControllerPublishVolumeRequest</code>, <code>NodeStageVolumeRequests</code>, dan <code>NodePublishVolumeRequest</code>.</li><li><code>controllerPublishSecretRef</code>: Sebuah referensi ke objek Secret yang berisi informasi sensitif untuk diberikan pada <em>driver</em> CSI untuk menyelesaikan panggilan <code>ControllerPublishVolume</code> dan <code>ControllerUnpublishVolume</code>.
Kolom ini bersifat opsional, dan dapat bernilai kosong jika tidak ada Secret yang dibutuhkan. Jika objek Secret berisi lebih dari satu <em>secret</em>, maka semua <em>secret</em> tersebut akan diberikan.</li><li><code>nodeStageSecretRef</code>: Sebuah referensi ke objek Secret yang berisi informasi sensitif untuk diberikan pada <em>driver</em> CSI untuk menyelesaikan panggilan <code>NodeStageVolume</code>. Kolom ini bersifat opsional, dan dapat bernilai kosong jika tidak ada Secret yang dibutuhkan. Jika objek Secret berisi lebih dari satu <em>secret</em>, maka semua <em>secret</em> tersebut akan diberikan.</li><li><code>nodePublishSecretRef</code>: Sebuah referensi ke objek Secret yang berisi informasi sensitif untuk diberikan pada <em>driver</em> CSI untuk menyelesaikan panggilan <code>NodePublishVolume</code>. Kolom ini bersifat opsional, dan dapat bernilai kosong jika tidak ada Secret yang dibutuhkan. Jika objek Secret berisi lebih dari satu <em>secret</em>, maka semua <em>secret</em> tersebut akan diberikan.</li></ul><h4 id=dukungan-csi-untuk-volume-blok-raw>Dukungan CSI untuk volume blok <em>raw</em></h4><div style=margin-top:10px;margin-bottom:10px><b>FEATURE STATE:</b> <code>Kubernetes v1.14 [beta]</code></div><p>Dimulai pada versi 1.11, CSI memperkenalkan dukungak untuk volume blok <em>raw</em>, yang bergantung pada fitur volume blok <em>raw</em> yang dikenalkan pada versi Kubernetes sebelumnya. Fitur ini akan memungkinkan <em>vendor-vendor</em> dengan <em>driver</em> CSI eksternal untuk mengimplementasi dukungan volume blok <em>raw</em> pada beban kerja Kubernetes.</p><p>Dukungan untuk volume blok CSI bersifat <em>feature-gate</em>, tapi secara bawaan diaktifkan. Kedua <em>feature-gate</em> yang harus diaktifkan adalah <code>BlockVolume</code> dan <code>CSIBlockVolume</code>.</p><p>Pelajari cara <a href=/id/docs/concepts/storage/persistent-volumes/#raw-block-volume-support>menyiapkan PV/PVC dengan dukungan volume blok <em>raw</em></a>.</p><h4 id=volume-csi-sementara>Volume CSI Sementara</h4><div style=margin-top:10px;margin-bottom:10px><b>FEATURE STATE:</b> <code>Kubernetes v1.15 [alpha]</code></div><p>FItur ini memungkinkan volume CSI untuk dipasang secara langsung pada spesifikasi Pod, menggantikan spesifikasi pada PersistentVolume. Volume yang dirinci melalui cara ini bersifat sementara tidak akan dipertahankan saat Pod diulang kembali.</p><p>Contoh:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>my-csi-app<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>my-frontend<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>busybox<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>volumeMounts</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- <span style=color:green;font-weight:700>mountPath</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;/data&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>my-csi-inline-vol<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>command</span>:<span style=color:#bbb> </span>[<span style=color:#bbb> </span><span style=color:#b44>&#34;sleep&#34;</span>,<span style=color:#bbb> </span><span style=color:#b44>&#34;1000000&#34;</span><span style=color:#bbb> </span>]<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>volumes</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>my-csi-inline-vol<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>csi</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>driver</span>:<span style=color:#bbb> </span>inline.storage.kubernetes.io<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>volumeAttributes</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>              </span><span style=color:green;font-weight:700>foo</span>:<span style=color:#bbb> </span>bar<span style=color:#bbb>
</span></span></span></code></pre></div><p>Fitur ini memerlukan diaktifkannya <em>feature-gate</em> CSIInlineVolume:</p><pre tabindex=0><code>--feature-gates=CSIInlineVolume=true
</code></pre><p>Volume CSI sementara hanya didukung oleh sebagian dari <em>driver-driver</em> CSI. Silahkan lihat daftar <em>driver</em> CSI <a href=https://kubernetes-csi.github.io/docs/drivers.html>di sini</a>.</p><h1 id=sumber-sumber-untuk-developer>Sumber-sumber untuk <em>developer</em></h1><p>Untuk informasi bagaimana mengembangkan sebuah <em>driver</em> CSI, lihat <a href=https://kubernetes-csi.github.io/docs/>dokumentasi kubernetes-csi</a>.</p><h4 id=migrasi-ke-driver-driver-csi-dari-plugin-in-tree>Migrasi ke <em>driver-driver</em> CSI dari <em>plugin</em> in-tree</h4><h4 id=migrating-to-csi-drivers-from-in-tree-plugins>Migrating to CSI drivers from in-tree plugins</h4><div style=margin-top:10px;margin-bottom:10px><b>FEATURE STATE:</b> <code>Kubernetes v1.14 [alpha]</code></div><p>Fitur CSI Migration, saat diaktifkan, akan mengarahkan operasi-operasi terhadap <em>plugin-plugin</em> in-tree yang sudah ada ke <em>plugin-plugin</em> CSI yang sesuai (yang diharap sudah dipasang dan dikonfigurasi). Fitur ini mengimplementasi logika translasi dan terjemahan yang dibutuhkan untuk mengarahkan ulang operasi-operasi bersangkutan dengan mulus. Hasilnya, operator-operator tidak perlu membuat perubahan konfigurasi apapun pada StorageClass, PV, atau PVC yang sudah ada (mengacu pada <em>plugin</em> in-tree) saat melakukan transisi pada <em>driver</em> CSI yang menggantikan <em>plugin</em> in-tree yang bersangkutan.</p><p>Pada keadaan Alpha, operasi-operasi dan fitur-fitur yang didukung termasuk <em>provisioning/delete</em>, <em>attach/detach</em>, <em>mount/unmount</em>, dan mengubah ukuran volume-volume.</p><p><em>Plugin-plugin</em> in-tree yang mendukung CSI Migration dan mempunyai <em>driver</em> CSI yang sesuai yang telah diimplementasikan terdaftar pada bagian "Jenis-jenis Volume" di atas.</p><h3 id=flexVolume>Flexvolume</h3><p>Flexvolume adalah antarmuka <em>plugin</em> out-of-tree yang telah ada sejak Kubernetes versi 1.2 (sebelum CSI). Ia menggunakan model berbasis <em>exec</em> untuk berhubungan dengan <em>driver-driver</em>. Program <em>driver</em> Flexvolume harus dipasan pada <em>volume plugin path</em> yang telah didefinisikan sebelumnya pada setiap Node (dan pada beberapa kasus, di Master).</p><p>Pod-pod berinteraksi dengan <em>driver-driver</em> Flexvolume melalui <em>plugin</em> in-tree <code>flexvolume</code>.
Untuk lebih lanjut, dapat ditemukan <a href=https://github.com/kubernetes/community/blob/master/contributors/devel/sig-storage/flexvolume.md>di sini</a>.</p><h2 id=mount-propagation><em>Mount Propagation</em></h2><p><em>Mount propagation</em> memungkinkan berbagi volume-volume yang ditambatkan oleh sebuah Container kepada Container-container lain di dalam Pod yang sama, atau bahkan pada Pod lainnya di dalam Node yang sama.</p><p><em>Mount propagation</em> dari sebuah volume diatur oleh kolom <code>mountPropagation</code> di dalam <code>Container.volumeMounts</code>.
Nilai-nilainya adalah sebagai berikut:</p><ul><li><p><code>None</code> - Tambatan volume ini tidak akan menerima apapun tambatan selanjutnya yang ditambatkan pada volume ini atau apapun sub-direktori yang dimilikinya oleh <em>host</em>.
Dengan cara yang sama, tidak ada tambatan yang dibuat oleh Container yang dapat terlihat pada <em>host</em>. Ini adalah mode bawaan.</p><p>Mode ini setara dengan <em>mount propagation</em> <code>private</code>, seperti yang dideskripsikan pada <a href=https://www.kernel.org/doc/Documentation/filesystems/sharedsubtree.txt>dokumentasi kernel Linux</a></p></li><li><p><code>HostToContainer</code> - Tambatan volume ini akan menerima semua tambatan selanjutnya yang ditambatkan pada volume ini atau pada apapun sub-direktori yang dimilikinya.</p><p>Dalam kata lain, jika <em>host</em> yang bersangkutan menambatkan apapun di dalam tambatan volume, Container akan melihatnya ditambatkan di sana.</p><p>Secara serupa, jika ada Pod dengan <em>mount propagation</em> <code>Bidirectional</code> terhadap volume yang sama menambatkan apapun ke situ, maka Container dengan <em>mount propagation</em> <code>HostToContainer</code> akan melihatnya.</p><p>Mode ini setara dengan <em>mount propagation</em> <code>rslave</code>, seperti yang dideskripsikan pada <a href=https://www.kernel.org/doc/Documentation/filesystems/sharedsubtree.txt>dokumentasi kernel Linux</a></p></li><li><p><code>Bidirectional</code> - Tambatan volume ini memiliki perilaku yang sama dengan tambatan <code>HostToContainer</code>.
Sebagai tambahannya, semua tambatan volume yang dibuat oleh Container akan dipropagasi kembali kepada <em>host</em> yang bersangkutan dan ke semua Container dari semua Pod yang menggunakan volume yang sama.</p><p>Contoh kasus umum untuk mode ini adalah Pod dengan sebuah Flexvolume atau <em>driver</em> CSI atau sebuah Pod yang perlu menambatkan sesuatu pada <em>host</em>-nya dengan menggunakan Volume <code>hostPath</code>.</p><p>Mode ini setara dengan <em>mount propagation</em> <code>rshared</code>, seperti yang dideskripsikan pada <a href=https://www.kernel.org/doc/Documentation/filesystems/sharedsubtree.txt>dokumentasi kernel Linux</a></p></li></ul><div class="alert alert-warning caution callout" role=alert><strong>Perhatian:</strong> <em>Mount propagation</em> <code>Bidirectional</code> bisa jadi berbahaya. Ia dapat merusak sistem operasi <em>host</em>-nya, sehingga hanya diizinkan pada Container yang <em>privileged</em>. Keterbiasaan dengan perilaku kernel Linux sangat dianjurkan.
Sebagai tambahan, tambatan volume apapun yang dibuat oleh Container-container di dalam Pod-pod harus dihancurkan (dilepaskan tambatannya) oleh Container-container pada saat terminasi.</div><h3 id=konfigurasi>Konfigurasi</h3><p>Sebelum <em>mount propagation</em> dapat bekerja dengan baik pada beberapa instalasi (CoreOS, RedHat/Centos, Ubuntu), <em>mount share</em> harus dikonfigurasi dengan benar pada Docker, seperti yang ditunjukkan di bawah.</p><p>Sunting berkas servis <code>systemd</code> Docker kamu. Setel <code>MountFlags</code> sebagai berikut:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span><span style=color:#b8860b>MountFlags</span><span style=color:#666>=</span>shared
</span></span></code></pre></div><p>Atau, hapus <code>MountFlags=slave</code> jika ada. Kemudian, ulang kembali <em>daemon</em> Docker-nya:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>sudo systemctl daemon-reload
</span></span><span style=display:flex><span>sudo systemctl restart docker
</span></span></code></pre></div><h2 id=selanjutnya>Selanjutnya</h2><ul><li>Ikuti contoh <a href=/docs/tutorials/stateful-application/mysql-wordpress-persistent-volume/>memasang WordPress dan MySQL dengan Persistent Volume</a>.</li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-ffd12528a12882b282e1bd19e29f9e75>6.2 - Persistent Volume</h1><p>Dokumen ini menjelaskan kondisi terkini dari <code>PersistentVolumes</code> pada Kubernetes. Disarankan telah memiliki familiaritas dengan <a href=/id/docs/concepts/storage/volumes/>volume</a>.</p><h2 id=pengenalan>Pengenalan</h2><p>Mengelola penyimpanan adalah hal yang berbeda dengan mengelola komputasi. Sub-sistem <code>PersistentVolume</code> (PV) menyediakan API untuk para pengguna dan administrator yang mengabstraksi detail-detail tentang bagaimana penyimpanan disediakan dari bagaimana penyimpanan dikonsumsi. Untuk melakukan ini, kami mengenalkan dua sumber daya API baru: <code>PersistentVolume</code> (PV) dan <code>PersistentVolumeClaim</code> (PVC).</p><p>Sebuah <code>PersistentVolume</code> (PV) adalah suatu bagian dari penyimpanan pada klaster yang telah disediakan oleh seorang administrator. PV merupakan sebuah sumber daya pada klaster sama halnya dengan <em>node</em> yang juga merupakan sumber daya klaster. PV adalah <em>volume plugin</em> seperti <em>Volumes</em>, tetapi memiliki siklus hidup yang independen dari <em>pod</em> individual yang menggunakan PV tersebut. Objek API ini menangkap detail-detail implementasi dari penyimpanan, seperti NFS, iSCSI, atau sistem penyimpanan yang spesifik pada penyedia layanan <em>cloud</em>.</p><p>Sebuah <code>PersistentVolumeClaim</code> (PVC) merupakan permintaan penyimpanan oleh pengguna. PVC mirip dengan sebuah <em>pod</em>. <em>Pod</em> mengonsumsi sumber daya <em>node</em> dan PVC mengonsumsi sumber daya PV. <em>Pods</em> dapat meminta taraf-taraf spesifik dari sumber daya (CPU dan Memory). Klaim dapat meminta ukuran dan mode akses yang spesifik (seperti, dapat dipasang sekali sebagai <em>read/write</em> atau lain kali sebagai <em>read-only</em>).</p><p>Meskipun <code>PersistentVolumeClaims</code> mengizinkan pengguna untuk mengkonsumsi sumber daya penyimpanan
abstrak, pada umumnya para pengguna membutuhkan <code>PersistentVolumes</code> dengan properti yang
bermacam-macam, seperti performa, untuk mengatasi masalah yang berbeda. Para administrator klaster
harus dapat menawarkan berbagai macam <code>PersistentVolumes</code> yang berbeda tidak hanya pada ukuran dan
mode akses, tanpa memaparkan detail-detail bagaimana cara volume tersebut diimplementasikan
kepada para pengguna. Untuk mengatasi hal ini maka dibutuhkan sumber daya
<code>StorageClass</code>.</p><p>Silakan lihat <a href=/id/docs/tasks/configure-pod-container/configure-persistent-volume-storage/>panduan mendetail dengan contoh-contoh yang sudah berjalan</a>.</p><h2 id=siklus-hidup-dari-sebuah-volume-dan-klaim>Siklus hidup dari sebuah volume dan klaim</h2><p>PV adalah sumber daya dalam sebuah klaster. PVC adalah permintaan terhadap sumber daya tersebut dan juga berperan sebagai pemeriksaan klaim dari sumber daya yang diminta. Interaksi antara PV dan PVC mengikuti siklus hidup berikut ini:</p><h3 id=penyediaan>Penyediaan</h3><p>Ada dua cara untuk menyediakan PV: secara statis atau dinamis.</p><h4 id=statis>Statis</h4><p>Seorang administrator klaster membuat beberapa PV. PV yang telah dibuat membawa detail-detail dari penyimpanan yang sesungguhnya tersedia untuk digunakan oleh pengguna klaster. PV tersebut ada pada Kubernetes API dan siap untuk digunakan.</p><h4 id=dinamis>Dinamis</h4><p>Ketika tidak ada PV statis yang dibuat oleh administrator yang sesuai dengan <code>PersistentVolumeClaim</code> (PVC) yang dibuat oleh pengguna, klaster akan mencoba untuk menyediakan volume khusus sesuai permintaan PVC.
Penyediaan dinamis ini berbasis <code>StorageClass</code>: artinya PVC harus meminta sebuah <em>storage class</em> dan <em>storage class</em> tersebut harus sudah dibuat dan dikonfigurasi oleh administrator agar penyediaan dinamis bisa terjadi. Klaim yang meminta PV dengan <em>storage class</em> <code>""</code> secara efektif telah menonaktifkan penyediaan dinamis.</p><p>Untuk mengaktifkan penyediaan <em>storage</em> dinamis berdasarkan <em>storage class</em>, administrator klaster harus mengaktifkan <a href=/docs/reference/access-authn-authz/admission-controllers/#defaultstorageclass><em>admission controller</em></a>
<code>DefaultStorageClass</code> pada API <em>server</em>. Hal ini dapat dilakukan, dengan cara memastikan <code>DefaultStorageClass</code> ada di antara urutan daftar <em>value</em> yang dibatasi koma untuk <em>flag</em> <code>--enable-admission-plugins</code> pada komponen API <em>server</em>. Untuk informasi lebih lanjut mengenai <em>flag</em> perintah pada API <em>server</em>, silakan cek dokumentasi,
<a href=/docs/admin/kube-apiserver/>kube-apiserver</a>.</p><h3 id=pengikatan>Pengikatan</h3><p>Seorang pengguna membuat, atau telah membuat (dalam kasus penyediaan dinamis), sebuah <code>PersistentVolumeClaim</code> (PVC) dengan jumlah penyimpanan spesifik yang diminta dan dengan mode akses tertentu. Sebuah <em>control loop</em> pada <em>master</em> akan melihat adanya PVC baru, mencari PV yang cocok (jika memungkinkan), dan mengikat PVC dengan PV tersebut. Jika sebuah PV disediakan secara dinamis untuk sebuah PVC baru, <em>loop</em> tersebut akan selalu mengikat PV tersebut pada PVC yang baru dibuat itu. Jika tidak, pengguna akan selalu mendapatkan setidaknya apa yang dimintanya, tetapi volume tersebut mungkin lebih dari apa yang diminta sebelumnya. Setelah terikat, ikatan <code>PersistentVolumeClaim</code> (PVC) bersifat eksklusif, terlepas dari bagaimana caranya mereka bisa terikat. Sebuah ikatan PVC ke PV merupakan pemetaan satu ke satu.</p><p>Klaim akan berada dalam kondisi tidak terikat tanpa kepastian jika tidak ada volume yang cocok. Klaim akan terikat dengan volume yang cocok ketika ada volume yang cocok. Sebagai contoh, sebuah klaster yang sudah menyediakan banyak PV berukuran 50Gi tidak akan cocok dengan PVC yang meminta 100Gi. PVC hanya akan terikat ketika ada PV 100Gi yang ditambahkan ke klaster.</p><h3 id=penggunaan>Penggunaan</h3><p><em>Pod</em> menggunakan klaim sebagai volume. Klaster menginspeksi klaim untuk menemukan volume yang terikat dengan klaim tersebut dan memasangkan volume tersebut ke pada <em>pod</em>. Untuk volume yang mendukung banyak mode akses, pengguna yang menentukan mode yang diinginkan ketika menggunakan klaim sebagai volume dalam sebuah <em>pod</em>.</p><p>Ketika pengguna memiliki klaim dan klaim tersebut telah terikat, PV yang terikat menjadi hak penggunanya selama yang dibutuhkan. Pengguna menjadwalkan <em>pod</em> dan mengakses PV yang sudah diklaim dengan menambahkan <code>persistentVolumeClaim</code> pada blok volume pada <em>Pod</em> miliknya. <a href=#claims-as-volumes>Lihat pranala di bawah untuk detail-detail mengenai sintaks</a>.</p><h3 id=object-penyimpanan-dalam-perlindungan-penggunaan>Object Penyimpanan dalam Perlindungan Penggunaan</h3><p>Tujuan dari Objek Penyimpanan dalam Perlindungan Penggunan adalah untuk memastikan <em>Persistent Volume Claim</em> (PVC) yang sedang aktif digunakan oleh sebuah <em>pod</em> dan <em>Persistent Volume</em> (PV) yang terikat pada PVC tersebut tidak dihapus dari sistem karena hal ini dapat menyebabkan kehilangan data.</p><div class="alert alert-info note callout" role=alert><strong>Catatan:</strong> PVC dikatakan aktif digunakan oleh sebuah <em>pod</em> ketika sebuah objek <em>pod</em> ada yang menggunakan PVC tersebut.</div><p>Jika seorang pengguna menghapus PVC yang sedang aktif digunakan oleh sebuah <em>pod</em>, PVC tersebut tidak akan langsung dihapus. Penghapusan PVC akan ditunda sampai PVC tidak lagi aktif digunakan oleh <em>pod</em> manapun, dan juga ketika admin menghapus sebuah PV yang terikat dengan sebuah PVC, PV tersebut tidak akan langsung dihapus. Penghapusan PV akan ditunda sampai PV tidak lagi terikat dengan sebuah PVC.</p><p>Kamu dapat melihat PVC yang dilindungi ketika status PVC berisi <code>Terminating</code> dan daftar <code>Finalizers</code> meliputi <code>kubernetes.io/pvc-protection</code>:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl describe pvc hostpath
</span></span><span style=display:flex><span>Name:          hostpath
</span></span><span style=display:flex><span>Namespace:     default
</span></span><span style=display:flex><span>StorageClass:  example-hostpath
</span></span><span style=display:flex><span>Status:        Terminating
</span></span><span style=display:flex><span>Volume:
</span></span><span style=display:flex><span>Labels:        &lt;none&gt;
</span></span><span style=display:flex><span>Annotations:   volume.beta.kubernetes.io/storage-class<span style=color:#666>=</span>example-hostpath
</span></span><span style=display:flex><span>               volume.beta.kubernetes.io/storage-provisioner<span style=color:#666>=</span>example.com/hostpath
</span></span><span style=display:flex><span>Finalizers:    <span style=color:#666>[</span>kubernetes.io/pvc-protection<span style=color:#666>]</span>
</span></span><span style=display:flex><span>...
</span></span></code></pre></div><p>Kamu dapat melihat sebuah PV dilindungi ketika status PV berisi <code>Terminating</code> dan daftar <code>Finalizers</code> juga meliputi <code>kubernetes.io/pv-protection</code>:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl describe pv task-pv-volume
</span></span><span style=display:flex><span>Name:            task-pv-volume
</span></span><span style=display:flex><span>Labels:          <span style=color:#b8860b>type</span><span style=color:#666>=</span><span style=color:#a2f>local</span>
</span></span><span style=display:flex><span>Annotations:     &lt;none&gt;
</span></span><span style=display:flex><span>Finalizers:      <span style=color:#666>[</span>kubernetes.io/pv-protection<span style=color:#666>]</span>
</span></span><span style=display:flex><span>StorageClass:    standard
</span></span><span style=display:flex><span>Status:          Available
</span></span><span style=display:flex><span>Claim:
</span></span><span style=display:flex><span>Reclaim Policy:  Delete
</span></span><span style=display:flex><span>Access Modes:    RWO
</span></span><span style=display:flex><span>Capacity:        1Gi
</span></span><span style=display:flex><span>Message:
</span></span><span style=display:flex><span>Source:
</span></span><span style=display:flex><span>    Type:          HostPath <span style=color:#666>(</span>bare host directory volume<span style=color:#666>)</span>
</span></span><span style=display:flex><span>    Path:          /tmp/data
</span></span><span style=display:flex><span>    HostPathType:
</span></span><span style=display:flex><span>Events:            &lt;none&gt;
</span></span></code></pre></div><h3 id=melakukan-reklaim>Melakukan Reklaim</h3><p>Ketika seorang pengguna telah selesai dengan volumenya, ia dapat menghapus objek PVC dari API yang memungkinkan untuk reklamasi dari sumber daya tersebut. Kebijakan reklaim dari sebuah <code>PersistentVolume</code> (PV) menyatakan apa yang dilakukan klaster setelah volume dilepaskan dari klaimnya. Saat ini, volume dapat dipertahankan (<em>Retained</em>), didaur ulang (<em>Recycled</em>), atau dihapus (<em>Deleted</em>).</p><h4 id=retain><em>Retain</em></h4><p><code>Retain</code> merupakan kebijakan reklaim yang mengizinkan reklamasi manual dari sebuah sumber daya. Ketika <code>PersistentVolumeClaim</code> (PVC) dihapus, <code>PersistentVolume</code> (PV) masih akan tetap ada dan volume tersebut dianggap "terlepas" . Tetapi PV tersebut belum tersedia untuk klaim lainnya karena data milik pengklaim sebelumnya masih terdapat pada volume. Seorang administrator dapat mereklaim volume secara manual melalui beberapa langkah.</p><ol><li>Menghapus <code>PersistentVolume</code> (PV). Aset <em>storage</em> yang terasosiasi dengan infrastruktur eksternal (seperti AWS EBS, GCE PD, Azure Disk, atau Cinder Volume) akan tetap ada setelah PV dihapus.</li><li>Secara manual membersihkan data pada aset <em>storage</em> terkait.</li><li>Secara manual menghapus aset <em>storage</em>, atau jika kamu ingin menggunakan aset <em>storage</em> yang sama, buatlah sebuah <code>PersistentVolume</code> baru dengan definisi aset <em>storage</em> tersebut.</li></ol><h4 id=delete><em>Delete</em></h4><p>Untuk <em>volume plugin</em> yang mendukung kebijakan reklaim <code>Delete</code>, penghapusan akan menghilangkan kedua objek dari Kubernetes, <code>PersistentVolume</code> (PV) dan juga aset <em>storage</em> yang terasosiasi pada infrastruktur eksternal seperti, AWS EBS, GCE PD, Azure Disk, atau Cinder Volume. Volume yang disediakan secara dinamis mewarisi <a href=#reclaim-policy>kebijakan reklaim dari <code>StorageClass</code> miliknya</a>, yang secara bawaan adalah <code>Delete</code>. Administrator harus mengkonfigurasi <code>StorageClass</code> sesuai ekspektasi pengguna, jika tidak maka PV tersebut harus diubah atau ditambal setelah dibuat nanti. Lihat <a href=/docs/tasks/administer-cluster/change-pv-reclaim-policy/>Mengganti Kebijakan Reklaim pada PersistentVolume</a>.</p><h4 id=recycle><em>Recycle</em></h4><div class="alert alert-danger warning callout" role=alert><strong>Peringatan:</strong> Kebijakan reklaim <code>Recycle</code> sudah ditinggalkan. Sebagai gantinya, pendekatan yang direkomendasikan adalah menggunakan penyediaan dinamis.</div><p>Jika didukung oleh <em>plugin volume</em> yang berada di baliknya, kebijakan reklaim <code>Recycle</code> melakukan penghapusan dasar (<code>rm -rf /thevolume/*</code>) pada volume dan membuatnya kembali tersedia untuk klaim baru.</p><p>Namun, seorang administrator dapat mengkonfigurasi templat <em>recycler pod</em> kustom menggunakan argumen baris perintah <em>controller manager</em> Kubernetes sebagaimana dijelaskan <a href=/docs/admin/kube-controller-manager/>di sini</a>. Templat <em>reycler pod</em> kustom harus memiliki spesifikasi <code>volumes</code>, seperti yang ditunjukkan pada contoh di bawah:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>pv-recycler<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>namespace</span>:<span style=color:#bbb> </span>default<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>restartPolicy</span>:<span style=color:#bbb> </span>Never<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>volumes</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>vol<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>hostPath</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>path</span>:<span style=color:#bbb> </span>/any/path/it/will/be/replaced<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>pv-recycler<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;k8s.gcr.io/busybox&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>command</span>:<span style=color:#bbb> </span>[<span style=color:#b44>&#34;/bin/sh&#34;</span>,<span style=color:#bbb> </span><span style=color:#b44>&#34;-c&#34;</span>,<span style=color:#bbb> </span><span style=color:#b44>&#34;test -e /scrub &amp;&amp; rm -rf /scrub/..?* /scrub/.[!.]* /scrub/*  &amp;&amp; test -z \&#34;$(ls -A /scrub)\&#34; || exit 1&#34;</span>]<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>volumeMounts</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>vol<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>mountPath</span>:<span style=color:#bbb> </span>/scrub<span style=color:#bbb>
</span></span></span></code></pre></div><p>Namun, alamat yang dispesifikasikan pada templat <em>recycler pod</em> kustom pada bagian <code>volumes</code> diganti dengan alamat pada volume yang akan didaur ulang.</p><h3 id=memperluas-persistent-volumes-claim>Memperluas <em>Persistent Volumes Claim</em></h3><div style=margin-top:10px;margin-bottom:10px><b>FEATURE STATE:</b> <code>Kubernetes v1.11 [beta]</code></div><p>Dukungan untuk memperluas PersistentVolumeClaim (PVC) sekarang sudah diaktifkan sejak awal. Kamu dapat memperluas
tipe-tipe volume berikut:</p><ul><li>gcePersistentDisk</li><li>awsElasticBlockStore</li><li>Cinder</li><li>glusterfs</li><li>rbd</li><li>Azure File</li><li>Azure Disk</li><li>Portworx</li><li>FlexVolumes</li><li>CSI</li></ul><p>Kamu hanya dapat memperluas sebuah PVC jika kolom <code>allowVolumeExpansion</code> dipasang sebagai benar pada <em>storage class</em> miliknya.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>storage.k8s.io/v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>StorageClass<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>gluster-vol-default<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>provisioner</span>:<span style=color:#bbb> </span>kubernetes.io/glusterfs<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>parameters</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>resturl</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;http://192.168.10.100:8080&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>restuser</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>secretNamespace</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>secretName</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>allowVolumeExpansion</span>:<span style=color:#bbb> </span><span style=color:#a2f;font-weight:700>true</span><span style=color:#bbb>
</span></span></span></code></pre></div><p>Untuk meminta volume yang lebih besar pada sebuah PVC, ubah objek PVC dan spesifikasikan ukuran yang lebih
besar. Hal ini akan memicu perluasan dari volume yang berada di balik <code>PersistentVolume</code> (PV). Sebuah
<code>PersistentVolume</code> (PV) baru tidak akan dibuat untuk memenuhi klaim tersebut. Sebaliknya, volume yang sudah ada akan diatur ulang ukurannya.</p><h4 id=perluasan-volume-csi>Perluasan Volume CSI</h4><div style=margin-top:10px;margin-bottom:10px><b>FEATURE STATE:</b> <code>Kubernetes v1.14 [alpha]</code></div><p>Perluasan volume CSI mengharuskan kamu untuk mengaktifkan gerbang fitur <code>ExpandCSIVolumes</code> dan juga membutuhkan <em>driver</em> CSI yang spesifik untuk mendukung perluasan volume. Silakan merujuk pada dokumentasi <em>driver</em> spesifik CSI untuk informasi lebih lanjut.</p><h4 id=mengubah-ukuran-sebuah-volume-yang-memiliki-file-system>Mengubah ukuran sebuah volume yang memiliki <em>file system</em></h4><p>Kamu hanya dapat mengubah ukuran volume yang memiliki <em>file system</em> jika <em>file system</em> tersebut adalah XFS, Ext3, atau Ext4.</p><p>Ketika sebuah volume memiliki <em>file system</em>, <em>file system</em> tersebut hanya akan diubah ukurannya ketika sebuah <em>pod</em> baru dinyalakan menggunakan
<code>PersistentVolumeClaim</code> (PVC) dalam mode <em>ReadWrite</em>. Maka dari itu, jika sebuah <em>pod</em> atau <em>deployment</em> menggunakan sebuah volume dan
kamu ingin memperluasnya, kamu harus menghapus atau membuat ulang <em>pod</em> tersebut setelah volume selesai diperluas oleh penyedia <em>cloud</em> dalam <em>controller-manager</em>. Kamu dapat melihat status dari operasi pengubahan ukuran dengan menjalankan perintah <code>kubectl describe pvc</code>:</p><pre tabindex=0><code>kubectl describe pvc &lt;pvc_name&gt;
</code></pre><p>Jika <code>PersistentVolumeClaim</code> (PVC) memiliki status <code>FileSystemResizePending</code>, maka berarti aman untuk membuat ulang <em>pod</em> menggunakan PersistentVolumeClaim (PVC) tersebut.</p><p>FlexVolumes mengizinkan pengubahan ukuran jika <em>driver</em> diatur dengan kapabilitas <code>RequiresFSResize</code> menjadi "<em>true</em>".
FlexVolume dapat diubah ukurannya pada saat <em>pod</em> mengalami <em>restart</em>.</p><div style=margin-top:10px;margin-bottom:10px><b>FEATURE STATE:</b> <code>Kubernetes v1.11 [alpha]</code></div><h4 id=mengubah-ukuran-persistentvolumeclaim-pvc-yang-sedang-digunakan>Mengubah ukuran PersistentVolumeClaim (PVC) yang sedang digunakan</h4><p>Memperluas PVC yang sedang digunakan merupakan fitur alfa. Untuk menggunakannya, aktifkan gerbang fitur <code>ExpandInUsePersistentVolumes</code>.
Pada kasus ini, kamu tidak perlu menghapus dan membuat ulang sebuah <em>Pod</em> atau <em>deployment</em> yang menggunakan PVC yang telah ada.
PVC manapun yang sedang digunakan secara otomatis menjadi tersedia untuk <em>pod</em> yang menggunakannya segera setelah <em>file system</em> miliknya diperluas.
Fitur ini tidak memiliki efek pada PVC yang tidak sedang digunakan oleh <em>Pod</em> atau <em>deployment</em>. Kamu harus membuat sebuah <em>Pod</em> yang
menggunakan PVC sebelum perluasan dapat selesai dilakukan.</p><p>Memperluas PVC yang sedang digunakan sudah ditambahkan pada rilis 1.13. Untuk mengaktifkan fitur ini gunakan <code>ExpandInUsePersistentVolumes</code> dan gerbang fitur <code>ExpandPersistentVolumes</code>. Gerbang fitur <code>ExpandPersistentVolumes</code> sudah diaktifkan sejak awal. Jika <code>ExpandInUsePersistentVolumes</code> sudah terpasang, FlexVolume dapat diubah ukurannya secara langsung tanpa perlu melakukan <em>restart</em> pada <em>pod</em>.</p><div class="alert alert-info note callout" role=alert><strong>Catatan:</strong> Pengubahan ukuran FlexVolume hanya mungkin dilakukan ketika <em>driver</em> yang menjalankannya mendukung pengubahan ukuran.</div><div class="alert alert-info note callout" role=alert><strong>Catatan:</strong> Memperluas volume EBS merupakan operasi yang memakan waktu. Terlebih lagi, ada kuota per volume untuk satu kali modifikasi setiap 6 jam.</div><h2 id=tipe-tipe-persistent-volume>Tipe-tipe <em>Persistent Volume</em></h2><p>Tipe-tipe <code>PersistentVolume</code> (PV) diimplementasikan sebagai <em>plugin</em>. Kubernetes saat ini mendukung <em>plugin</em> berikut:</p><ul><li>GCEPersistentDisk</li><li>AWSElasticBlockStore</li><li>AzureFile</li><li>AzureDisk</li><li>FC (Fibre Channel)</li><li>FlexVolume</li><li>Flocker</li><li>NFS</li><li>iSCSI</li><li>RBD (Ceph Block Device)</li><li>CephFS</li><li>Cinder (OpenStack block storage)</li><li>Glusterfs</li><li>VsphereVolume</li><li>Quobyte Volumes</li><li>HostPath (Hanya untuk pengujian <em>single node</em> -- penyimpanan lokal tidak didukung dan TIDAK AKAN BEKERJA pada klaster <em>multi-node</em>)</li><li>Portworx Volumes</li><li>ScaleIO Volumes</li><li>StorageOS</li></ul><h2 id=persistent-volume><em>Persistent Volume</em></h2><p>Setiap PV memiliki sebuah <em>spec</em> dan status, yang merupakan spesifikasi dan status dari volume tersebut.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>PersistentVolume<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>pv0003<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>capacity</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>storage</span>:<span style=color:#bbb> </span>5Gi<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>volumeMode</span>:<span style=color:#bbb> </span>Filesystem<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>accessModes</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- ReadWriteOnce<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>persistentVolumeReclaimPolicy</span>:<span style=color:#bbb> </span>Recycle<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>storageClassName</span>:<span style=color:#bbb> </span>slow<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>mountOptions</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- hard<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- nfsvers=4.1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>nfs</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>path</span>:<span style=color:#bbb> </span>/tmp<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>server</span>:<span style=color:#bbb> </span><span style=color:#666>172.17.0.2</span><span style=color:#bbb>
</span></span></span></code></pre></div><div class="alert alert-info note callout" role=alert><strong>Catatan:</strong> Program pembantu yang berkaitan dengan tipe volume bisa saja diperlukan untuk mengonsumsi sebuah PersistentVolume di dalam klaster. Contoh ini menggunakan PersistentVolume dengan tipe NFS dan program pembantu /sbin/mount.nfs diperlukan untuk mendukung proses mounting sistem berkas (filesystem) NFS.</div><h3 id=kapasitas>Kapasitas</h3><p>Secara umum, sebuah PV akan memiliki kapasitas <em>storage</em> tertentu. Hal ini ditentukan menggunakan atribut <code>capacity</code> pada PV. Lihat <a href=https://git.k8s.io/community/contributors/design-proposals/scheduling/resources.md>Model Sumber Daya</a> Kubernetes untuk memahami satuan yang diharapkan pada atribut <code>capacity</code>.</p><p>Saat ini, ukuran <em>storage</em> merupakan satu-satunya sumber daya yang dapat ditentukan atau diminta. Atribut-atribut lainnya di masa depan dapat mencakup IOPS, <em>throughput</em>, dsb.</p><h3 id=mode-volume>Mode Volume</h3><div style=margin-top:10px;margin-bottom:10px><b>FEATURE STATE:</b> <code>Kubernetes v1.13 [beta]</code></div><p>Sebelum Kubernetes 1.9, semua <em>volume plugin</em> akan membuat sebuah <em>filesystem</em> pada PersistentVolume (PV).
Sekarang, kamu dapat menentukan nilai dari <code>volumeMode</code> menjadi <code>block</code> untuk menggunakan perangkat <em>raw block</em>, atau <code>filesystem</code>
untuk menggunakan sebuah <em>filesystem</em>. <code>filesystem</code> menjadi standar yang digunakan jika nilainya dihilangkan. Hal ini merupakan parameter API
opsional.</p><h3 id=mode-akses>Mode Akses</h3><p>Sebuah <code>PersistentVolume</code> (PV) dapat dipasangkan pada sebuah <em>host</em> dengan cara apapun yang didukung oleh penyedia sumber daya. Seperti ditunjukkan pada tabel di bawah, para penyedia akan memiliki kapabilitas yang berbeda-beda dan setiap mode akses PV akan ditentukan menjadi mode-mode spesifik yang didukung oleh tiap volume tersebut. Sebagai contoh, NFS dapat mendukung banyak klien <em>read/write</em>, tetapi sebuah NFS PV tertentu mungkin diekspor pada server sebagai <em>read-only</em>. Setiap PV memilik seperangkat mode aksesnya sendiri yang menjelaskan kapabilitas dari PV tersebut.</p><p>Beberapa mode akses tersebut antara lain:</p><ul><li>ReadWriteOnce -- volume dapat dipasang sebagai <em>read-write</em> oleh satu <em>node</em></li><li>ReadOnlyMany -- volume dapat dipasang sebagai <em>read-only</em> oleh banyak <em>node</em></li><li>ReadWriteMany -- volume dapat dipasang sebagai <em>read-write</em> oleh banyak <em>node</em></li></ul><p>Pada CLI, mode-mode akses tersebut disingkat menjadi:</p><ul><li>RWO - ReadWriteOnce</li><li>ROX - ReadOnlyMany</li><li>RWX - ReadWriteMany</li></ul><blockquote><p><strong>Penting!</strong> Sebuah volume hanya dapat dipasang menggunakan satu mode akses dalam satu waktu, meskipun volume tersebut mendukung banyak mode. Sebagai contoh, sebuah GCEPersistentDisk dapat dipasangkan sebagai ReadWriteOnce oleh satu <em>node</em> atau ReadOnlyMany oleh banyak node, tetapi tidak dalam waktu yang bersamaan.</p></blockquote><table><thead><tr><th style=text-align:left>Volume Plugin</th><th style=text-align:center>ReadWriteOnce</th><th style=text-align:center>ReadOnlyMany</th><th style=text-align:center>ReadWriteMany</th></tr></thead><tbody><tr><td style=text-align:left>AWSElasticBlockStore</td><td style=text-align:center>✓</td><td style=text-align:center>-</td><td style=text-align:center>-</td></tr><tr><td style=text-align:left>AzureFile</td><td style=text-align:center>✓</td><td style=text-align:center>✓</td><td style=text-align:center>✓</td></tr><tr><td style=text-align:left>AzureDisk</td><td style=text-align:center>✓</td><td style=text-align:center>-</td><td style=text-align:center>-</td></tr><tr><td style=text-align:left>CephFS</td><td style=text-align:center>✓</td><td style=text-align:center>✓</td><td style=text-align:center>✓</td></tr><tr><td style=text-align:left>Cinder</td><td style=text-align:center>✓</td><td style=text-align:center>-</td><td style=text-align:center>-</td></tr><tr><td style=text-align:left>FC</td><td style=text-align:center>✓</td><td style=text-align:center>✓</td><td style=text-align:center>-</td></tr><tr><td style=text-align:left>FlexVolume</td><td style=text-align:center>✓</td><td style=text-align:center>✓</td><td style=text-align:center>depends on the driver</td></tr><tr><td style=text-align:left>Flocker</td><td style=text-align:center>✓</td><td style=text-align:center>-</td><td style=text-align:center>-</td></tr><tr><td style=text-align:left>GCEPersistentDisk</td><td style=text-align:center>✓</td><td style=text-align:center>✓</td><td style=text-align:center>-</td></tr><tr><td style=text-align:left>Glusterfs</td><td style=text-align:center>✓</td><td style=text-align:center>✓</td><td style=text-align:center>✓</td></tr><tr><td style=text-align:left>HostPath</td><td style=text-align:center>✓</td><td style=text-align:center>-</td><td style=text-align:center>-</td></tr><tr><td style=text-align:left>iSCSI</td><td style=text-align:center>✓</td><td style=text-align:center>✓</td><td style=text-align:center>-</td></tr><tr><td style=text-align:left>Quobyte</td><td style=text-align:center>✓</td><td style=text-align:center>✓</td><td style=text-align:center>✓</td></tr><tr><td style=text-align:left>NFS</td><td style=text-align:center>✓</td><td style=text-align:center>✓</td><td style=text-align:center>✓</td></tr><tr><td style=text-align:left>RBD</td><td style=text-align:center>✓</td><td style=text-align:center>✓</td><td style=text-align:center>-</td></tr><tr><td style=text-align:left>VsphereVolume</td><td style=text-align:center>✓</td><td style=text-align:center>-</td><td style=text-align:center>- (works when pods are collocated)</td></tr><tr><td style=text-align:left>PortworxVolume</td><td style=text-align:center>✓</td><td style=text-align:center>-</td><td style=text-align:center>✓</td></tr><tr><td style=text-align:left>ScaleIO</td><td style=text-align:center>✓</td><td style=text-align:center>✓</td><td style=text-align:center>-</td></tr><tr><td style=text-align:left>StorageOS</td><td style=text-align:center>✓</td><td style=text-align:center>-</td><td style=text-align:center>-</td></tr></tbody></table><h3 id=kelas>Kelas</h3><p>Sebuah PV bisa memiliki sebuah kelas, yang dispesifikasi dalam pengaturan atribut
<code>storageClassName</code> menjadi nama
<a href=/id/docs/concepts/storage/storage-classes/>StorageClass</a>.
Sebuah PV dari kelas tertentu hanya dapat terikat dengan PVC yang meminta
kelas tersebut. Sebuah PV tanpa <code>storageClassName</code> tidak memiliki kelas dan hanya dapat terikat
dengan PVC yang tidak meminta kelas tertentu.</p><p>Dahulu, anotasi <code>volume.beta.kubernetes.io/storage-class</code> digunakan sebagai ganti
atribut <code>storageClassName</code>. Anotasi ini masih dapat bekerja, namun
akan dihilangkan sepenuhnya pada rilis Kubernetes mendatang.</p><h3 id=kebijakan-reklaim>Kebijakan Reklaim</h3><p>Kebijakan-kebijakan reklaim saat ini antara lain:</p><ul><li>Retain -- reklamasi manual</li><li>Recycle -- penghapusan dasar (<code>rm -rf /thevolume/*</code>)</li><li>Delete -- aset <em>storage</em> terasosiasi seperti AWS EBS, GCE PD, Azure Disk, atau OpenStack Cinder volume akan dihapus</li></ul><p>Saat ini, hanya NFS dan HostPath yang mendukung daur ulang. AWS EBS, GCE PD, Azure Disk, dan Cinder Volume mendukung penghapusan.</p><h3 id=opsi-pemasangan>Opsi Pemasangan</h3><p>Seorang administrator Kubernetes dapat menspesifikasi opsi pemasangan tambahan untuk ketika sebuah <em>Persistent Volume</em> dipasangkan pada sebuah <em>node</em>.</p><div class="alert alert-info note callout" role=alert><strong>Catatan:</strong> Tidak semua tipe <em>Persistent Volume</em> mendukung opsi pemasanagan.</div><p>Tipe-tipe volume yang mendukung opsi pemasangan antara lain:</p><ul><li>AWSElasticBlockStore</li><li>AzureDisk</li><li>AzureFile</li><li>CephFS</li><li>Cinder (OpenStack block storage)</li><li>GCEPersistentDisk</li><li>Glusterfs</li><li>NFS</li><li>Quobyte Volumes</li><li>RBD (Ceph Block Device)</li><li>StorageOS</li><li>VsphereVolume</li><li>iSCSI</li></ul><p>Opsi pemasangan tidak divalidasi, sehingga pemasangan akan gagal jika salah satunya tidak valid.</p><p>Dahulu, anotasi <code>volume.beta.kubernetes.io/mount-options</code> digunakan sebagai ganti
atribut <code>mountOptions</code>. Anotasi ini masih dapat bekerja, namun
akan dihilangkan sepenuhnya pada rilis Kubernetes mendatang.</p><h3 id=afinitas-node>Afinitas Node</h3><div class="alert alert-info note callout" role=alert><strong>Catatan:</strong> Untuk kebanyakan tipe volume, kamu tidak perlu memasang kolom ini. Kolom ini secara otomatis terisi untuk tipe blok volume <a href=/id/docs/concepts/storage/volumes/#awselasticblockstore>AWS EBS</a>, <a href=/id/docs/concepts/storage/volumes/#gcepersistentdisk>GCE PD</a> dan <a href=/id/docs/concepts/storage/volumes/#azuredisk>Azure Disk</a>. Kamu harus mengaturnya secara eksplisit untuk volume <a href=/id/docs/concepts/storage/volumes/#local>lokal</a>.</div><p>Sebuah PV dapat menspesifikasi <a href=/docs/reference/generated/kubernetes-api/v1.25/#volumenodeaffinity-v1-core>afinitas node</a> untuk mendefinisikan batasan yang membatasi <em>node</em> mana saja yang dapat mengakses volume tersebut. <em>Pod</em> yang menggunakan sebuah PV hanya akan bisa dijadwalkan ke <em>node</em> yang dipilih oleh afinitas <em>node</em>.</p><h3 id=fase>Fase</h3><p>Sebuah volume akan berada dalam salah satu fase di bawah ini:</p><ul><li>Available -- sumber daya bebas yang belum terikat dengan sebuah klaim</li><li>Bound -- volume sudah terikat dengan sebuah klaim</li><li>Released -- klaim sudah dihapus, tetapi sumber daya masih belum direklaim oleh klaster</li><li>Failed -- volume gagal menjalankan reklamasi otomatis</li></ul><p>CLI akan menunjukkan nama dari PVC yang terikat pada PV.</p><h2 id=persistentvolumeclaims>PersistentVolumeClaims</h2><p>Setiap PVC memiliki <em>spec</em> dan status, yang merupakan spesifikasi dan status dari klaim.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>PersistentVolumeClaim<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>myclaim<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>accessModes</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- ReadWriteOnce<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>volumeMode</span>:<span style=color:#bbb> </span>Filesystem<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>resources</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>requests</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>storage</span>:<span style=color:#bbb> </span>8Gi<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>storageClassName</span>:<span style=color:#bbb> </span>slow<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>selector</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>matchLabels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>release</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;stable&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>matchExpressions</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- {<span style=color:green;font-weight:700>key: environment, operator: In, values</span>:<span style=color:#bbb> </span>[dev]}<span style=color:#bbb>
</span></span></span></code></pre></div><h3 id=mode-akses-1>Mode Akses</h3><p>Klaim menggunakan penulisan yang sama dengan volume ketika meminta <em>storage</em> dengan mode akses tertentu.</p><h3 id=mode-volume-1>Mode Volume</h3><p>Klaim menggunakan penulisan yang sama dengan volume untuk mengindikasikan konsumsi dari volume sebagai <em>filesystem</em> ataupun perangkat <em>block</em>.</p><h3 id=sumber-daya>Sumber daya</h3><p>Klaim, seperti <em>pod</em>, bisa meminta sumber daya dengan jumlah tertentu. Pada kasus ini, permintaan untuk <em>storage</em>. <a href=https://git.k8s.io/community/contributors/design-proposals/scheduling/resources.md>Model sumber daya</a> yang sama berlaku untuk baik volume maupun klaim.</p><h3 id=selector><em>Selector</em></h3><p>Klaim dapat menspesifikasi <a href=/id/docs/concepts/overview/working-with-objects/labels/#label-selectors><em>label selector</em></a> untuk memilih serangkaian volume lebih jauh. Hanya volume yang cocok labelnya dengan <em>selector</em> yang dapat terikat dengan klaim. <em>Selector</em> dapat terdiri dari dua kolom:</p><ul><li><code>matchLabels</code> - volume harus memiliki label dengan nilai ini</li><li><code>matchExpressions</code> - daftar dari persyaratan yang dibuat dengan menentukan kunci, daftar nilai, dan operator yang menghubungkan kunci dengan nilai. Operator yang valid meliputi In, NotIn, Exists, dan DoesNotExist.</li></ul><p>Semua persyaratan tersebut, dari <code>matchLabels</code> dan <code>matchExpressions</code> akan dilakukan operasi AND bersama – semuanya harus dipenuhi untuk mendapatkan kecocokan.</p><h3 id=kelas-1>Kelas</h3><p>Sebuah klaim dapat meminta kelas tertentu dengan menspesifikasi nama dari
<a href=/id/docs/concepts/storage/storage-classes/>StorageClass</a>
menggunakan atribut <code>storageClassName</code>.
Hanya PV dari kelas yang diminta, yang memiliki <code>storageClassName</code> yang sama dengan PVC, yang dapat
terikat dengan PVC.</p><p>PVC tidak harus meminta sebuah kelas. Sebuah PVC dengan <code>storageClassName</code> miliknya bernilai
<code>""</code> akan selalu diinterpretasikan sebagai meminta PV tanpa kelas, jadi PVC
hanya bisa terikat ke PV tanpa kelas (tanpa anotasi atau bernilai
<code>""</code>). Sebuah PVC tanpa <code>storageClassName</code> tidaklah sama dan diperlakukan berbeda
oleh klaster tergantung apakah
<a href=/docs/reference/access-authn-authz/admission-controllers/#defaultstorageclass><em>admission plugin</em> <code>DefaultStorageClass</code></a>
dinyalakan.</p><ul><li>Jika <em>admission plugin</em> dinyalakan, administrator bisa menspesifikasi
<code>StorageClass</code> standar. Seluruh PVC yang tidak memiliki <code>storageClassName</code> dapat terikat hanya ke
PVs standar. Menspesifikasikan <code>StorageClass</code> standar dapat dilakukan dengan mengatur
anotasi <code>storageclass.kubernetes.io/is-default-class</code> menjadi "<em>true</em>" pada
sebuah objek <code>StorageClass</code>. Jika administrator tidak menspesifikasikan standar apapun,
klaster menanggapi pembuatan PVC sekan-akan <em>admission plugin</em> dimatikan. Jika
ada lebih dari satu setelan standar dispesifikasikan, <em>admission plugin</em> melarang pembuatan seluruh
PVC.</li><li>Jika <em>admission plugin</em> dimatikan, tidak ada pilihan menggunakan
<code>StorageClass</code> standar. Semua PVC yang tidak memiliki <code>storageClassName</code> hanya dapat diikat ke PV yang
tidak memiliki kelas. Pada kasus ini, PVC yang tidak memiliki <code>storageClassName</code> diperlakukan
sama seperti PVC yang memiliki <code>storageClassName</code> bernilai <code>""</code>.</li></ul><p>Tergantung metode instalasi, sebuah StorageClass dari setelan standar dapat dibuat
ke klaster Kubernetes oleh <em>addon manager</em> pada saat instalasi.</p><p>Ketika sebuah PVC menspesifikasi sebuah <code>selector</code> selain meminta <code>StorageClass</code>,
kebutuhan tersebut akan digabungkan dengan operasi AND bersama: hanya PV dari kelas yang diminta dan dengan
label yang diminta yang dapat terikat ke PVC.</p><div class="alert alert-info note callout" role=alert><strong>Catatan:</strong> Saat ini, sebuah PVC dengan <code>selector</code> yang tak kosong tidak dapat memiliki PV yang disediakan secara dinamis untuknya.</div><p>Dahulu, anotasi <code>volume.beta.kubernetes.io/storage-class</code> digunakan sebagai ganti
atribut <code>storageClassName</code>. Anotasi ini masih dapat bekerja, namun
akan dihilangkan sepenuhnya pada rilis Kubernetes mendatang.</p><h2 id=klaim-sebagai-volume>Klaim sebagai Volume</h2><p><em>Pod</em> mengakses <em>storage</em> dengan menggunakan klaim sebagai volume. Klaim harus berada pada <em>namespace</em> yang sama dengan <em>pod</em> yang menggunakan klaim tersebut. Klaster menemukan klaim pada <em>namespace</em> yang sama dengan <em>pod</em> dan menggunakannya untuk mendapatkan <code>PersistentVolume</code> (PV) yang ada di baliknya. Volume tersebut kemudian dipasangkan ke <em>host</em> dan lalu ke <em>pod</em>.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>mypod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>myfrontend<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>nginx<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>volumeMounts</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- <span style=color:green;font-weight:700>mountPath</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;/var/www/html&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>mypd<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>volumes</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>mypd<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>persistentVolumeClaim</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>claimName</span>:<span style=color:#bbb> </span>myclaim<span style=color:#bbb>
</span></span></span></code></pre></div><h3 id=catatan-mengenai-namespace>Catatan Mengenai <em>Namespace</em></h3><p>Ikatan <code>PersistentVolumes</code> bersifat eksklusif, dan karena <code>PersistentVolumeClaims</code> merupakan objek yang berada pada <em>namespace</em>, pemasangan klaim dengan "banyak" mode (<code>ROX</code>, <code>RWX</code>) hanya dimungkinkan jika berada dalam satu <em>namespace</em> yang sama.</p><h2 id=dukungan-volume-raw-block>Dukungan Volume <em>Raw Block</em></h2><div style=margin-top:10px;margin-bottom:10px><b>FEATURE STATE:</b> <code>Kubernetes v1.13 [beta]</code></div><p><em>Volume plugins</em> berikut mendukung volume <em>raw block</em>, termasuk penyediaan dinamis jika
mungkin diterapkan.</p><ul><li>AWSElasticBlockStore</li><li>AzureDisk</li><li>FC (Fibre Channel)</li><li>GCEPersistentDisk</li><li>iSCSI</li><li>Local volume</li><li>RBD (Ceph Block Device)</li><li>VsphereVolume (alpha)</li></ul><div class="alert alert-info note callout" role=alert><strong>Catatan:</strong> Hanya FC dan volume iSCSI yang mendukung volume <em>raw block</em> pada Kubernetes 1.9.
Dukungan untuk <em>plugin</em> lainnya ditambahkan pada 1.10.</div><h3 id=persistent-volume-menggunakan-volume-raw-block><em>Persistent Volume</em> menggunakan Volume <em>Raw Block</em></h3><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>PersistentVolume<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>block-pv<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>capacity</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>storage</span>:<span style=color:#bbb> </span>10Gi<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>accessModes</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- ReadWriteOnce<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>volumeMode</span>:<span style=color:#bbb> </span>Block<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>persistentVolumeReclaimPolicy</span>:<span style=color:#bbb> </span>Retain<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>fc</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>targetWWNs</span>:<span style=color:#bbb> </span>[<span style=color:#b44>&#34;50060e801049cfd1&#34;</span>]<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>lun</span>:<span style=color:#bbb> </span><span style=color:#666>0</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>readOnly</span>:<span style=color:#bbb> </span><span style=color:#a2f;font-weight:700>false</span><span style=color:#bbb>
</span></span></span></code></pre></div><h3 id=persistent-volume-claim-meminta-volume-raw-block><em>Persistent Volume Claim</em> meminta Volume <em>Raw Block</em></h3><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>PersistentVolumeClaim<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>block-pvc<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>accessModes</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- ReadWriteOnce<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>volumeMode</span>:<span style=color:#bbb> </span>Block<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>resources</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>requests</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>storage</span>:<span style=color:#bbb> </span>10Gi<span style=color:#bbb>
</span></span></span></code></pre></div><h3 id=spesifikasi-pod-yang-menambahkan-alamat-perangkat-raw-block-pada-kontainer>Spesifikasi <em>Pod</em> yang menambahkan alamat Perangkat <em>Raw Block</em> pada kontainer</h3><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>pod-with-block-volume<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>fc-container<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>fedora:26<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>command</span>:<span style=color:#bbb> </span>[<span style=color:#b44>&#34;/bin/sh&#34;</span>,<span style=color:#bbb> </span><span style=color:#b44>&#34;-c&#34;</span>]<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>args</span>:<span style=color:#bbb> </span>[<span style=color:#bbb> </span><span style=color:#b44>&#34;tail -f /dev/null&#34;</span><span style=color:#bbb> </span>]<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>volumeDevices</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>data<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>devicePath</span>:<span style=color:#bbb> </span>/dev/xvda<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>volumes</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>data<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>persistentVolumeClaim</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>claimName</span>:<span style=color:#bbb> </span>block-pvc<span style=color:#bbb>
</span></span></span></code></pre></div><div class="alert alert-info note callout" role=alert><strong>Catatan:</strong> Ketika menambahkan sebuah perangkat <em>raw block</em> untuk sebuah <em>Pod</em>, kita menspesifikasi alamat perangkat dalam kontainer alih-alih alamat pemasangan.</div><h3 id=mengikat-block-volume>Mengikat <em>Block Volume</em></h3><p>Jika seorang pengguna meminta sebuah volume <em>raw block</em> dengan mengindikasikannya menggunakan kolom <code>volumeMode</code> pada <em>spec</em> <code>PersistentVolumeClaim</code> (PVC), aturan pengikatannya sedikit berbeda dibanding rilis-rilis sebelumnya yang tidak memerhatikan mode ini sebagai bagian dari <em>spec</em>.
Di bawah merupakan tabel dari kemungkinan kombinasi yang pengguna dan admin dapat spesifikasikan untuk meminta sebuah perangkat <em>raw block</em>. Tabel tersebut mengindikasikan apakah volume akan terikat atau tidak jika dikombinasikan dengan cara tertentu:
Matriks pengikatan volume untuk volume yang disediakan secara statis:</p><table><thead><tr><th>PV volumeMode</th><th style=text-align:center>PVC volumeMode</th><th style=text-align:right>Hasil</th></tr></thead><tbody><tr><td>unspecified</td><td style=text-align:center>unspecified</td><td style=text-align:right>TERIKAT</td></tr><tr><td>unspecified</td><td style=text-align:center>Block</td><td style=text-align:right>TIDAK TERIKAT</td></tr><tr><td>unspecified</td><td style=text-align:center>Filesystem</td><td style=text-align:right>TERIKAT</td></tr><tr><td>Block</td><td style=text-align:center>unspecified</td><td style=text-align:right>TIDAK TERIKAT</td></tr><tr><td>Block</td><td style=text-align:center>Block</td><td style=text-align:right>TERIKAT</td></tr><tr><td>Block</td><td style=text-align:center>Filesystem</td><td style=text-align:right>TIDAK TERIKAT</td></tr><tr><td>Filesystem</td><td style=text-align:center>Filesystem</td><td style=text-align:right>TERIKAT</td></tr><tr><td>Filesystem</td><td style=text-align:center>Block</td><td style=text-align:right>TIDAK TERIKAT</td></tr><tr><td>Filesystem</td><td style=text-align:center>unspecified</td><td style=text-align:right>TERIKAT</td></tr></tbody></table><div class="alert alert-info note callout" role=alert><strong>Catatan:</strong> Hanya volume yang disediakan secara statis yang didukung untuk rilis alfa. Administrator harus memperhatikan nilai-nilai tersebut ketika mengerjakan perangkat-perangkat <em>raw block</em>.</div><h2 id=volume-snapshot-dan-dukungan-pemulihan-volume-dari-snapshot><em>Volume Snapshot</em> dan Dukungan Pemulihan Volume dari <em>Snapshot</em></h2><div style=margin-top:10px;margin-bottom:10px><b>FEATURE STATE:</b> <code>Kubernetes v1.12 [alpha]</code></div><p>Fitur <em>volume snapshot</em> ditambahkan hanya untuk mendukung <em>CSI Volume Plugins</em>. Untuk lebih detail, lihat <a href=/id/docs/concepts/storage/volume-snapshots/><em>volume snapshots</em></a>.</p><p>Untuk mengaktifkan dukungan pemulihan sebuah volume dari sebuah sumber data <em>volume snapshot</em>, aktifkan
gerbang fitur <code>VolumeSnapshotDataSource</code> pada apiserver dan <em>controller-manager</em>.</p><h3 id=membuat-persistent-volume-claim-dari-volume-snapshot>Membuat <em>Persistent Volume Claim</em> dari <em>Volume Snapshot</em></h3><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>PersistentVolumeClaim<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>restore-pvc<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>storageClassName</span>:<span style=color:#bbb> </span>csi-hostpath-sc<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>dataSource</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>new-snapshot-test<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>VolumeSnapshot<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>apiGroup</span>:<span style=color:#bbb> </span>snapshot.storage.k8s.io<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>accessModes</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- ReadWriteOnce<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>resources</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>requests</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>storage</span>:<span style=color:#bbb> </span>10Gi<span style=color:#bbb>
</span></span></span></code></pre></div><h2 id=menulis-konfigurasi-portabel>Menulis Konfigurasi Portabel</h2><p>Jika kamu menulis templat konfigurasi atau contoh yang dapat berjalan pada berbagai macam klaster
dan membutuhkan <em>persistent storage</em>, kami merekomendasikan agar kamu menggunakan pola berikut:</p><ul><li>Masukkan objek PersistentVolumeClaim (PVC) pada kumpulan <em>config</em> (bersamaan dengan
Deployments, ConfigMaps, dsb).</li><li>Jangan memasukkan objek PersistentVolume (PV) pada <em>config</em>, karena pengguna yang menginstantiasi
<em>config</em> tersebut kemungkinan tidak memiliki izin untuk membuat PersistentVolume (PV).</li><li>Berikan pengguna opsi untuk menyediakan nama <em>storage class</em> ketika menginstantiasi
templat.<ul><li>Jika pengguna menyediakan nama <em>storage class</em>, taruh nilai tersebut pada
kolom <code>persistentVolumeClaim.storageClassName</code>.
Hal ini akan membuat PVC agar sesuai dengan <em>storage class</em>
yang tepat jika klaster memiliki banyak StorageClass yang diaktifkan oleh admin.</li><li>Jika pengguna tidak menyediakan nama <em>storage class</em>, biarkan
kolom <code>persistentVolumeClaim.storageClassName</code> kosong.<ul><li>Hal ini kakan membuat sebuah PV disediakan secara otomatis untuk pengguna dengan
StorageClass standar pada klaster. Banyak lingkungan klaster memiliki
StorageClass standar yang sudah terpasang, atau administrator dapat membuat
StorageClass standar sendiri.</li></ul></li></ul></li><li>Dalam pembuatan, perhatikan PVC yang tidak kunjung terikat setelah beberapa lama
dan beritahukan hal ini pada pengguna, karena hal ini dapat mengindikasikan klaster tidak
memiliki dukungan penyimpanan dinamis (di mana pengguna harus membuat PV yang sesuai)
atau klaster tidak memiliki sistem penyimpanan (di mana penggun tidak dapat membuat
PVC yang membutuhkan <em>config</em>).</li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-c262af210c6828dec445d2f55a1d877a>6.3 - VolumeSnapshot</h1><p><div style=margin-top:10px;margin-bottom:10px><b>FEATURE STATE:</b> <code>Kubernetes v1.12 [alpha]</code></div>Laman ini menjelaskan tentang fitur VolumeSnapshot pada Kubernetes. Sebelum lanjut membaca, sangat disarankan untuk memahami <a href=/id/docs/concepts/storage/persistent-volumes/>PersistentVolume</a> terlebih dahulu.</p><h2 id=pengenalan>Pengenalan</h2><p>Seperti halnya sumber daya API PersistentVolume dan PersistentVolumeClaim yang digunakan oleh para pengguna dan administrator untuk menyediakan volume, sumber daya API VolumeSnapshotContent dan VolumeSnapshot digunakan mereka untuk membuat <em>snapshot</em> volume.</p><p>VolumeSnapshotContent merupakan suatu <em>snapshot</em> yang diambil dari sebuah volume dari dalam klaster yang telah disediakan oleh administrator. Sepert layaknya PersistentVolume, VolumeSnapshotContent juga merupakan bagian dari sumber daya klaster.</p><p>VolumeSnapshot merupakan suatu permintaan <em>snapshot</em> dari volume oleh pengguna. Mirip seperti halnya PersistentVolumeClaim.</p><p>Walaupun VolumeSnapshot membuat pengguna bisa mengonsumsi abstraksi dari sumber daya penyimpanan, administrator klaster tetap perlu
menawarkan berbagai macam tipe VolumeSnapshotContent, tanpa perlu mengekspos pengguna pada detail bagaimana <em>snapshot</em>
volume tersebut harus tersediakan. Bagi yang memerlukan hal ini, ada yang namanya sumber daya VolumeSnapshotClass.</p><p>Para pengguna tetap perlu mengetahui beberapa hal di bawah ketika menggunakan fitur ini:</p><ul><li>Objek API VolumeSnapshot, VolumeSnapshotContent, dan VolumeSnapshotClass adalah CRD, bukan bagian dari API inti.</li><li>Fitur VolumeSnapshot hanya tersedia untuk CSI <em>driver</em>.</li><li>Sebagai bagian dari proses <em>deploy</em>, tim Kubernetes menyediakan Container <em>sidecar</em> bantuan untuk <em>controller snapshot</em> berrnama <code>external-snapshotter</code>. Container ini melakukan <em>watch</em> pada objek VolumeSnapshot dan memicu operasi CreateSnapshot dan DeleteSnapshot terhadap sebuah <em>endpoint</em> CSI.</li><li><em>Driver</em> CSI ada yang telah implementasi fitur VolumeSnapshot, ada juga yang belum. <em>Driver</em> CSI yang telah menyediakan dukungan terhadap fitur VolumeSnapshot kemungkinan besar menggunakan <code>external-snapshotter</code>.</li><li><em>Driver</em> CSI yang mendukung VolumeSnapshot akan secara otomatis melakukan instalasi CRD untuk VolumeSnapshot.</li></ul><h2 id=siklus-hidup-volumesnapshot-dan-volumesnapshotcontent>Siklus hidup VolumeSnapshot dan VolumeSnapshotContent</h2><p>VolumeSnapshotContent merupakan bagian dari sumber daya klaster. VolumeSnapshot merupakan permintaan terhadap sumber daya tersebut. Interaksi antara VolumeSnapshotContent dan VolumeSnapshot mengikuti siklus hidup berikut ini:</p><h3 id=penyediaan-volumesnapshot>Penyediaan VolumeSnapshot</h3><p>Ada dua cara untuk menyediakan <em>snapshot</em>: secara statis maupun dinamis.</p><h4 id=statis>Statis</h4><p>Seorang administrator klaster membuat beberapa VolumeSnapshotContent, yang masing-masing memiliki detail tentang penyimpanan sebenarnya yang dapat dipergunakan oleh para pengguna. VolumeSnapshotContent tersebut dapat dikonsumsi melalui API Kubernetes.</p><h4 id=dinamis>Dinamis</h4><p>Ketika VolumeSnapshotContent yang dibuat oleh administrator tidak ada yang sesuai dengan VolumeSnapshot yang dibuat pengguna, klaster bisa saja
mencoba untuk menyediakan sebuah VolumeSnapshot secara dinamis, khususnya untuk objek VolumeSnapshot.
Proses penyediaan ini berdasarkan VolumeSnapshotClasses: VolumeSnapshot harus meminta sebuah <a href=/id/docs/concepts/storage/volume-snapshot-classes/>VolumeSnapshotClass</a>
dan administrator harus membuat serta mengatur <em>class</em> tersebut supaya penyediaan dinamis bisa terjadi.</p><h3 id=ikatan-binding>Ikatan (<em>Binding</em>)</h3><p>Seorang pengguna akan membuat (atau telah membuat, dalam kasus penyediaan dinamis) sebuah VolumeSnapshot dengan ukuran penyimpanan yang diminta beserta mode akses tertentu. Suatu <em>loop</em> kontrol melakukan <em>watch</em> terhadap VolumeSnapshot baru, mencari VolumeSnapshotContent yang sesuai (jika memungkinkan), dan mengikat (<em>bind</em>) keduanya. Jika VolumeSnapshotContent secara dinamis disediakan untuk VolumeSnapshot yang baru,
<em>loop</em> akan terus mengikat VolumeSnapshotContent dengan VolumeSnapshot. Ketika telah terikat (<em>bound</em>), VolumeSnapshot <em>bind</em> bersifat eksklusif, terlepas dari bagaimana proses <em>bind</em> dilakukan. Ikatan (<em>binding</em>) antara suatu VolumeSnapshot dengan VolumeSnapshotContent bersifat 1:1 <em>mapping</em>.</p><p>VolumeSnapshot akan tetap tidak terikat (<em>unbound</em>) tanpa ada batas waktu, jika VolumeSnapshotContent yang sesuai tidak ditemukan. VolumeSnapshot akan menjadi terikat (<em>bound</em>) ketika VolumeSnapshotContent yang sesuai menjadi ada.</p><h3 id=persistentvolumeclaim-dengan-in-use-protection>PersistentVolumeClaim dengan <em>in-Use Protection</em></h3><p>Tujuan dari objek PersistentVolumeClaim dengan fitur <em>in Use Protection</em> adalah memastikan objek API PVC yang masih dalam penggunaan (<em>in-use</em>) tidak akan dihilangkan dari sistem (penghilangan akan menyebabkan hilangnya data).</p><p>Jika sebuah PVC sedang digunakan secara aktif oleh proses <em>snapshot</em> yang digunakan sebagai sumbernya (<em>source</em>), artinya PVC sedang dalam penggunaan (<em>in-use</em>). Jika seorang pengguna menghapus suatu objek API PVC saat dalam penggunaan sebagai sumber <em>snapshot</em>, objek PVC tidak akan dihilangkan segera. Namun, penghapusan objek PVC akan ditunda sampai PVCC tidak lagi secara aktif digunakan oleh proses <em>snapshot</em> manapun. Suatu PVC tidak lagi diguunakan sebagai suumber <em>snapshot</em> ketika <code>ReadyToUse</code> dari <code>Status</code> <em>snapshot</em> menjadi <code>true</code>.</p><h3 id=penghapusan>Penghapusan</h3><p>Proses penghapusan akan menghilangkan objek VolumeSnapshot dari API Kubernetes, beserta aset penyimpanan terkait pada infrastruktur eksternal.</p><h2 id=volumesnapshotcontent>VolumeSnapshotContent</h2><p>Setiap VolumeSnapshotContent memiliki sebuah <em>spec</em>, yang merepresentasikan spesifikasi dari <em>snapshot</em> volume tersebut.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>snapshot.storage.k8s.io/v1alpha1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>VolumeSnapshotContent<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>new-snapshot-content-test<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>snapshotClassName</span>:<span style=color:#bbb> </span>csi-hostpath-snapclass<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>source</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>pvc-test<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>PersistentVolumeClaim<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>volumeSnapshotSource</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>csiVolumeSnapshotSource</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>creationTime</span>:<span style=color:#bbb>    </span><span style=color:#666>1535478900692119403</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>driver</span>:<span style=color:#bbb>          </span>csi-hostpath<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>restoreSize</span>:<span style=color:#bbb>     </span>10Gi<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>snapshotHandle</span>:<span style=color:#bbb>  </span>7bdd0de3-aaeb-11e8-9aae-0242ac110002<span style=color:#bbb>
</span></span></span></code></pre></div><h3 id=class><em>Class</em></h3><p>Suatu VolumeSnapshotContent dapat memiliki suatu <em>class</em>, yang didapat dengan mengatur atribut
<code>snapshotClassName</code> dengan nama dari <a href=/id/docs/concepts/storage/volume-snapshot-classes/>VolumeSnapshotClass</a>.
VolumeSnapshotContent dari <em>class</em> tertentu hanya dapat terikat (<em>bound</em>) dengan VolumeSnapshot yang
"meminta" <em>class</em> tersebut. VolumeSnapshotContent tanpa <code>snapshotClassName</code> tidak memiliki <em>class</em> dan hanya dapat
terikat (<em>bound</em>) dengan VolumeSnapshot yang "meminta" untuk tidak menggunakan <em>class</em>.</p><h2 id=volumesnapshot>VolumeSnapshot</h2><p>Masing-masing VolumeSnapshot memiliki sebuah <em>spec</em> dan status, yang merepresentasikan spesifikasi dan status dari <em>snapshot</em> volume tersebut.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>snapshot.storage.k8s.io/v1alpha1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>VolumeSnapshot<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>new-snapshot-test<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>snapshotClassName</span>:<span style=color:#bbb> </span>csi-hostpath-snapclass<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>source</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>pvc-test<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>PersistentVolumeClaim<span style=color:#bbb>
</span></span></span></code></pre></div><h3 id=class-1><em>Class</em></h3><p>Suatu VolumeSnapshot dapat meminta sebuah <em>class</em> tertentu dengan mengatur nama dari
<a href=/id/docs/concepts/storage/volume-snapshot-classes/>VolumeSnapshotClass</a>
menggunakan atribut <code>snapshotClassName</code>.
Hanya VolumeSnapshotContent dari <em>class</em> yang diminta, memiliki <code>snapshotClassName</code> yang sama
dengan VolumeSnapshot, dapat terikat (<em>bound</em>) dengan VolumeSnapshot tersebut.</p><h2 id=penyediaan-provisioning-volume-dari-snapshot>Penyediaan (<em>Provisioning</em>) Volume dari <em>Snapshot</em></h2><p>Kamu dapat menyediakan sebuah volume baru, yang telah terisi dengan data dari suatu <em>snapshot</em>, dengan
menggunakan <em>field</em> <code>dataSource</code> pada objek PersistentVolumeClaim.</p><p>Untuk detailnya bisa dilihat pada <a href=/id/docs/concepts/storage/persistent-volumes/#volume-snapshot-and-restore-volume-from-snapshot-support>VolumeSnapshot and Mengembalikan Volume dari <em>Snapshot</em></a>.</p></div><div class=td-content style=page-break-before:always><h1 id=pg-707ca81a34eb1ca202f34692e9917d1e>6.4 - Pengklonaan Volume CSI</h1><p><div style=margin-top:10px;margin-bottom:10px><b>FEATURE STATE:</b> <code>Kubernetes v1.16 [beta]</code></div>Dokumen ini mendeskripsikan konsep pengklonaan Volume CSI yang telah tersedia di dalam Kubernetes. Pengetahuan tentang <a href=/id/docs/concepts/storage/volumes>Volume</a> disarankan.</p><h2 id=introduction>Introduction</h2><p>Fitur <a class=glossary-tooltip title='The Container Storage Interface (CSI) defines a standard interface to expose storage systems to containers.' data-toggle=tooltip data-placement=top href=/docs/concepts/storage/volumes/#csi target=_blank aria-label=CSI>CSI</a> Volume Cloning menambahkan dukungan untuk merinci <a class=glossary-tooltip title='Mengklaim sumber daya penyimpanan yang didefinisikan di dalam suatu PersistentVolume, sehingga PersistentVolume tersebut dapat dipasang (mounted) sebagai sebuah volume pada suatu Container.' data-toggle=tooltip data-placement=top href=/id/docs/concepts/storage/persistent-volumes/#persistentvolumeclaims target=_blank aria-label=PVC>PVC</a> yang telah tersedia pada kolom <code>dataSource</code> untuk mengindikasikan bahwa seorang pengguna ingin melakukan pengklonaan terhadap sebuah <a class=glossary-tooltip title='Sebuah direktori yang mengandung data, dapat diakses o;eh kontainer-kontainer di dalam pod.' data-toggle=tooltip data-placement=top href=/docs/concepts/storage/volumes/ target=_blank aria-label=Volume>Volume</a>.</p><p>Sebuah klona didefinisikan sebagai sebuah duplikat dari sebuah Volume Kubernetes yang telah tersedia yang dapat digunakan sebagai sebuah Volume standar. Perbedaannya hanyalah pada saat penyediaannya, daripada membuat sebuah Volume kosong yang "baru", peranti penyokongnya membuat sebuah duplikat sama persis dari Volume yang dirinci.</p><p>Implementasi dari pengklonaan, dari sudut pandang API Kubernetes, secara sederhana menambahkan kemampuan untuk merinci sebuah PVC yang telah tersedia sebagai sebuah dataSource saat pembuatan PVC. PVC sumber harus tertambat (<em>bound</em>) dan tersedia (tidak sedang digunakan).</p><p>Pengguna-pengguna mesti menyadari hal-hal berikut saat menggunakan fitur ini:</p><ul><li>Dukungan pengklonaan (<code>VolumePVCDataSource</code>) hanya tersedia untuk <em>driver-driver</em> CSI.</li><li>Dukungan pengklonaan hanya tersedia untuk penyedia-penyedia dinamis.</li><li><em>Driver-driver</em> CSI mungkin telah atau belum mengimplementasi fungsi pengklonaan Volume.</li><li>Kamu hanya dapat mengklonakan sebuah PVC saat ia tersedia pada Namespace yang sama dengan PVC tujuan (sumber dan tujuan harus berada pada Namespace yang sama).</li><li>Pengklonaan hanya didukung pada Storage Class yang sama.<ul><li>Volume tujuan harus memiliki Storage Class yang sama dengan sumbernya.</li><li>Storage Class bawaan dapat digunakan dan <code>storageClassName</code> dihilangkan dari <code>spec</code></li></ul></li></ul><h2 id=penyediaan>Penyediaan</h2><p>Klona-klona disediakan sama seperti PVC lainnya dengan pengecualian dengan penambahan sebuah <code>dataSource</code> yang merujuk pada sebuah PVC yang telah tersedia pada Namespace yang sama.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>PersistentVolumeClaim<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>clone-of-pvc-1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>namespace</span>:<span style=color:#bbb> </span>myns<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>accessModes</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- ReadWriteOnce<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>storageClassName</span>:<span style=color:#bbb> </span>cloning<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>resources</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>requests</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>storage</span>:<span style=color:#bbb> </span>5Gi<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>dataSource</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>PersistentVolumeClaim<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>pvc-1<span style=color:#bbb>
</span></span></span></code></pre></div><p>Hasilnya adalah sebuah PVC baru dengan nama <code>clone-of-pvc-1</code> yang memiliki isi yang sama dengan sumber yang dirinci <code>pvc-1</code>.</p><h2 id=penggunaan>Penggunaan</h2><p>Setelah tersedianya PVC baru tersebut, PVC baru yang diklonakan tersebut digunakan sama seperti PVC lainnya. Juga diharapkan pada titik ini bahwa PVC baru tersebut adalah sebuah objek terpisah yang independen. Ia dapat digunakan, diklonakan, di-<em>snapshot</em>, atau dihapus secara terpisah dan tanpa perlu memikirkan PVC dataSource aslinya. Hal ini juga berarti bahwa sumber tidak terikat sama sekali dengan klona yang baru dibuat tersebut, dan dapat diubah atau dihapus tanpa memengaruhi klona yang baru dibuat tersebut.</p></div><div class=td-content style=page-break-before:always><h1 id=pg-f0276d05eef111249272a1c932a91e2c>6.5 - StorageClass</h1><p>Dokumen ini mendeskripsikan konsep StorageClass yang ada pada Kubernetes.
Sebelum lanjut membaca, sangat dianjurkan untuk memiliki pengetahuan terhadap
<a href=/id/docs/concepts/storage/volumes/>volumes</a> dan
<a href=/id/docs/concepts/storage/persistent-volumes>peristent volume</a> terlebih dahulu.</p><h2 id=pengenalan>Pengenalan</h2><p>Sebuah StorageClass menyediakan cara bagi administrator untuk
mendeskripsikan "kelas" dari penyimpanan yang mereka sediakan.
Kelas yang berbeda bisa saja memiliki perbedaan dari segi kualitas
servis yang disediakan, pemulihan (<em>backup</em>) kebijakan, atau kebijakan lain yang ditentukan
oleh administrator klaster. Kubernetes sendiri tidak dipengaruhi oleh
kelas apakah yang digunakan pada mekanisme penyimpanan yang digunakan.
Mekanisme ini seringkali disebut sebagai <em>"profiles"</em> pada sistem penyimpanan
yang lain.</p><h2 id=sumber-daya-storageclass>Sumber daya StorageClass</h2><p>Setiap StorageClass (kelas penyimpanan) memiliki <em>field-field</em> mendasar seperti
<code>provisioner</code>, <code>parameters</code>, dan <code>reclaimPolicy</code>, yang digunakan ketika
<code>PersistentVolume</code> yang dimiliki oleh kelas tersebut perlu disediakan (di-<em>provision</em>).</p><p>Nama yang digunakan oleh suatu StorageClass sifatnya penting, karena
ini merupakan cara yang digunakan oleh pengguna untuk meminta
penyimpanan dengan kelas tertentu. Administrator dapat menentukan
nama dan parameter lain dari suatu kelas ketika membuat suatu objek <code>StorageClass</code>,
dan objek yang sudah dibuat tidak dapat diubah lagi definisinya.</p><p>Administrator dapat memberikan spesifikasi StorageClass <em>default</em> bagi
PVC yang tidak membutuhkan kelas tertentu untuk dapat melakukan mekanisme <em>bind</em>:
kamu dapat membaca <a href=/id/docs/concepts/storage/persistent-volumes/#persistentvolumeclaims>bagian <code>PersistentVolumeClaim</code></a>
untuk penjelasan lebih lanjut.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>storage.k8s.io/v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>StorageClass<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>standard<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>provisioner</span>:<span style=color:#bbb> </span>kubernetes.io/aws-ebs<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>parameters</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>type</span>:<span style=color:#bbb> </span>gp2<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>reclaimPolicy</span>:<span style=color:#bbb> </span>Retain<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>mountOptions</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- debug<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>volumeBindingMode</span>:<span style=color:#bbb> </span>Immediate<span style=color:#bbb>
</span></span></span></code></pre></div><h3 id=provisioner><em>Provisioner</em></h3><p>Setiap kelas penyimpanan (<em>storage class</em>) memiliki sebuah <em>provisioner</em> yang
menentukan <em>plugin</em> manakah yang digunakan ketika sebuah PV disediakan (di-<em>provision</em>).
<em>Field</em> ini haruslah didefinisikan.</p><table><thead><tr><th style=text-align:left>Plugin Volume</th><th style=text-align:center>Provisioner Internal</th><th style=text-align:center>Contoh Konfigurasi</th></tr></thead><tbody><tr><td style=text-align:left>AWSElasticBlockStore</td><td style=text-align:center>✓</td><td style=text-align:center><a href=#aws-ebs>AWS EBS</a></td></tr><tr><td style=text-align:left>AzureFile</td><td style=text-align:center>✓</td><td style=text-align:center><a href=#azure-file>Azure File</a></td></tr><tr><td style=text-align:left>AzureDisk</td><td style=text-align:center>✓</td><td style=text-align:center><a href=#azure-disk>Azure Disk</a></td></tr><tr><td style=text-align:left>CephFS</td><td style=text-align:center>-</td><td style=text-align:center>-</td></tr><tr><td style=text-align:left>Cinder</td><td style=text-align:center>✓</td><td style=text-align:center><a href=#openstack-cinder>OpenStack Cinder</a></td></tr><tr><td style=text-align:left>FC</td><td style=text-align:center>-</td><td style=text-align:center>-</td></tr><tr><td style=text-align:left>Flexvolume</td><td style=text-align:center>-</td><td style=text-align:center>-</td></tr><tr><td style=text-align:left>Flocker</td><td style=text-align:center>✓</td><td style=text-align:center>-</td></tr><tr><td style=text-align:left>GCEPersistentDisk</td><td style=text-align:center>✓</td><td style=text-align:center><a href=#gce-pd>GCE PD</a></td></tr><tr><td style=text-align:left>Glusterfs</td><td style=text-align:center>✓</td><td style=text-align:center><a href=#glusterfs>Glusterfs</a></td></tr><tr><td style=text-align:left>iSCSI</td><td style=text-align:center>-</td><td style=text-align:center>-</td></tr><tr><td style=text-align:left>Quobyte</td><td style=text-align:center>✓</td><td style=text-align:center><a href=#quobyte>Quobyte</a></td></tr><tr><td style=text-align:left>NFS</td><td style=text-align:center>-</td><td style=text-align:center>-</td></tr><tr><td style=text-align:left>RBD</td><td style=text-align:center>✓</td><td style=text-align:center><a href=#ceph-rbd>Ceph RBD</a></td></tr><tr><td style=text-align:left>VsphereVolume</td><td style=text-align:center>✓</td><td style=text-align:center><a href=#vsphere>vSphere</a></td></tr><tr><td style=text-align:left>PortworxVolume</td><td style=text-align:center>✓</td><td style=text-align:center><a href=#portworx-volume>Portworx Volume</a></td></tr><tr><td style=text-align:left>ScaleIO</td><td style=text-align:center>✓</td><td style=text-align:center><a href=#scaleio>ScaleIO</a></td></tr><tr><td style=text-align:left>StorageOS</td><td style=text-align:center>✓</td><td style=text-align:center><a href=#storageos>StorageOS</a></td></tr><tr><td style=text-align:left>Local</td><td style=text-align:center>-</td><td style=text-align:center><a href=#local>Local</a></td></tr></tbody></table><p>Kamu tidak dibatasi untuk hanya menggunakan <em>provisioner</em> internal yang disediakan
pada list yang tersedia (yang memiliki nama dengan prefix "kubernetes.io" dan
didistribusikan bersamaan dengan Kubernetes). Kamu juga dapat menjalankan dan
mendefinisikan <em>provisioner</em> eksternal yang merupakan program independen selama
program tersebut menerapkan <a href=https://github.com/kubernetes/design-proposals-archive/blob/main/storage/volume-provisioning.md>spesifikasi</a>
yang didefinisikan oleh Kubernetes. Penulis dari <em>provisioner</em> eksternal Kubernetes
memiliki kuasa penuh akan tempat dimana kode sumber yang mereka tulis, bagaimana
mekanisme penyediaan (<em>provisioning</em>) dilakukan, serta bagaimana hal tersebut dapat dijalankan,
serta <em>plugin</em> volume apakah yang digunakan (termasuk Flex), dkk.
Repositori <a href=https://github.com/kubernetes-incubator/external-storage>kubernetes-incubator/external-storage</a>
menyimpan <em>library</em> yang dibutukan untuk menulis <em>provisioner</em> eksternal
yang mengimplementasi spesifikasi serta beberapa <em>provisioner</em> eksternal yang
dipelihara oleh komunitas.</p><p>Sebagai contoh, NFS tidak menyediakan <em>provisioner</em> internal, tetapi
sebuah <em>provisioner</em> eksternal dapat digunakan. Beberapa <em>provisioner</em> eksternal
dapat ditemukan di bawah repositori <a href=https://github.com/kubernetes-incubator/external-storage>kubernetes-incubator/external-storage</a>.
Di sana juga terdapat beberapa kasus dimana vendor penyimpanan <em>3rd party</em>
menyediakan <em>provisioner</em> eksternal yang mereka sediakan sendiri.</p><h3 id=perolehan-kembali-untuk-kebijakan-reclaim-policy>Perolehan Kembali untuk Kebijakan (<em>Reclaim Policy</em>)</h3><p><em>Persistent Volumes</em> yang secara dinamis dibuat oleh sebuah kelas penyimpanan
akan memiliki <em>reclaim policy</em> yang didefinisikan di dalam <em>field</em> <code>reclaimPolicy</code>
dari kelas tersebut, yang nilainya dapat diisi dengan <code>Delete</code> atau <code>Retain</code>.
Jika tidak terdapat <code>reclaimPolicy</code> yang dispesifikasikan ketika sebuah objek
StorageClass dibuat, maka nilai default bagi kelas tersebut adalah <code>Delete</code>.</p><p>PersistentVolume yang dibuat secara manual dan diatur dengan menggunakan
kelas penyimpanan akan menggunakan <em>reclaim policy</em> apapun yang diberikan
pada saat objek tersebut dibuat.</p><h3 id=pilihan-mount>Pilihan <em>Mount</em></h3><p>PersistentVolume yang secara dinamis dibuat oleh sebuah kelas penyimpanan
akan memiliki pilihan <em>mount</em> yang dapat dispesifikasikan pada <em>field</em>
<code>mountOptions</code> dari kelas tersebut.</p><p>Jika sebuah <em>plugin</em> volume tidak mendukung pilihan <em>mount</em>
yang dispesifikasikan, mekanisme penyediaan (<em>provision</em>) akan digagalkan. Pilihan <em>mount</em>
yang akan divalidasi pada kelas penyimpanan maupun PV, maka <em>mount</em> tersebut
akan gagal apabila salah satu dari keduanya bersifat invalid.</p><h3 id=mode-volume-binding>Mode Volume <em>Binding</em></h3><p><em>Field</em> <code>volumeBindingMode</code> mengontrol kapan mekanisme <a href=/id/docs/concepts/storage/persistent-volumes/#provisioning><em>binding</em> volume dan
<em>provisioning</em> dinamis</a>
harus dilakukan.</p><p>Secara <em>default</em>, ketika mode <code>Immediate</code> yang mengindikasikan
terjadinya volume <em>binding</em> dan <em>provisioning</em> dinamis terjadi ketika
PersistentVolumeClaim dibuat. Untuk <em>backend</em> penyimpanan yang dibatasi oleh
topologi tertentu dan tidak dapat diakses secara global dari semua Node
yang ada di klaster, PersistentVolume akan di-<em>bound</em> atau di-<em>provision</em>
tanpa perlu memenuhi persyaratan <em>scheduling</em> dari Pod. Hal ini dapat menyebabkan
adanya Pod yang tidak mendapatkan mekanisme <em>scheduling</em>.</p><p>Seorang administrator klaster dapat mengatasi hal tersebut dengan cara memberikan
spesifikasi mode <code>WaitForFirstConsumer</code> yang akan memperlambat mekanisme <em>provisioning</em>
dan <em>binding</em> dari sebuah PersistentVolume hingga sebuah Pod yang menggunakan
PersistentVolumeClaim dibuat. PersistentVolume akan dipilih atau di-<em>provisioning</em>
sesuai dengan topologi yang dispesifikasikan oleh limitasi yang diberikan
oleh mekanisme <em>scheduling</em> Pod. Hal ini termasuk, tetapi tidak hanya terbatas pada,
<a href=/id/docs/concepts/configuration/manage-compute-resources-container>persyaratan sumber daya</a>,
<a href=/id/docs/concepts/scheduling-eviction/assign-pod-node/#nodeselector><em>node selector</em></a>,
<a href=/id/docs/concepts/scheduling-evictionassign-pod-node/#affinity-and-anti-affinity>afinitas dan
anti-afinitas Pod</a>,
serta <a href=/id/docs/concepts/scheduling-eviction/taint-and-toleration><em>taint</em> dan <em>toleration</em></a>.</p><p>Beberapa <em>plugin</em> di bawah ini mendukung <code>WaitForFirstConsumer</code> dengan <em>provisioning</em>
dinamis:</p><ul><li><a href=#aws-ebs>AWSElasticBlockStore</a></li><li><a href=#gce-pd>GCEPersistentDisk</a></li><li><a href=#azure-disk>AzureDisk</a></li></ul><p>Beberapa <em>plugin</em> di bawah ini mendukung <code>WaitForFirstConsumer</code> dengan <em>binding</em>
PersistentVolume yang terlebih dahulu dibuat:</p><ul><li>Semua hal di atas</li><li><a href=#lokal>Lokal</a></li></ul><p><div style=margin-top:10px;margin-bottom:10px><b>FEATURE STATE:</b> <code>Kubernetes 1.14 [beta]</code></div><a href=/id/docs/concepts/storage/volumes/#csi>Volume-volume CSI</a> juga didukung
dengan adanya <em>provisioning</em> dinamis serta PV yang telah terlebih dahulu dibuat,
meskipun demikian, akan lebih baik apabila kamu melihat dokumentasi
untuk driver spesifik CSI untuk melihat topologi <em>key</em> yang didukung
beserta contoh penggunaannya. <em>Feature gate</em> <code>CSINodeInfo</code> haruslah diaktifkan.</p><h3 id=topologi-yang-diizinkan>Topologi yang Diizinkan</h3><p>Ketika sebuah operator klaster memberikan spesifikasi <code>WaitForFirstConsumer</code> pada
mode <code>binding</code> volume, mekanisme pembatasan (restriksi) <code>provisioning</code> tidak lagi dibutuhkan
pada sebagian besar kasus. Meskipun begitu, apabila hal tersebut masih dibutuhkan,
<code>field</code> <code>allowedTopologies</code> dapat dispesifikasikan.</p><p>Contoh ini memberikan demonstrasi bagaimana cara membatasi topologi
dari volume yang di-<em>provision</em> pada suatu zona spesifik serta harus digunakan
sebagai pengganti parameter <code>zone</code> dam <code>zones</code> untuk <code>plugin</code> yang akan digunakan.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>storage.k8s.io/v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>StorageClass<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>standard<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>provisioner</span>:<span style=color:#bbb> </span>kubernetes.io/gce-pd<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>parameters</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>type</span>:<span style=color:#bbb> </span>pd-standard<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>volumeBindingMode</span>:<span style=color:#bbb> </span>WaitForFirstConsumer<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>allowedTopologies</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span>- <span style=color:green;font-weight:700>matchLabelExpressions</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>key</span>:<span style=color:#bbb> </span>failure-domain.beta.kubernetes.io/zone<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>values</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- us-central-1a<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- us-central-1b<span style=color:#bbb>
</span></span></span></code></pre></div><h2 id=parameter-parameter>Parameter-Parameter</h2><p>Kelas-kelas penyimpanan memiliki parameter yang mendeskripsikan
volume yang dimiliki oleh kelas penyimpanan tersebut. Parameter yang berbeda
bisa saja diterima bergantung pada <code>provisioner</code>. Sebagai contohnya, nilai <code>io1</code>,
untuk parameter <code>type</code>, dan parameter <code>iopsPerGB</code> spesifik terhadap EBS.
Ketika sebuah parameter diabaikan, beberapa nilai <em>default</em> akan digunakan sebagai
gantinya.</p><h3 id=aws-ebs>AWS EBS</h3><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>storage.k8s.io/v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>StorageClass<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>slow<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>provisioner</span>:<span style=color:#bbb> </span>kubernetes.io/aws-ebs<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>parameters</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>type</span>:<span style=color:#bbb> </span>io1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>iopsPerGB</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;10&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>fsType</span>:<span style=color:#bbb> </span>ext4<span style=color:#bbb>
</span></span></span></code></pre></div><ul><li><code>type</code>: <code>io1</code>, <code>gp2</code>, <code>sc1</code>, <code>st1</code>. Lihat
<a href=http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/EBSVolumeTypes.html>dokumentasi AWS</a>
untuk detail lebih lanjut. Nilai <em>default</em>: <code>gp2</code>.</li><li><code>zone</code> (<em>deprecated</em>): zona AWS. Jika tidak terdapat nilai <code>zone</code> atau <code>zones</code>
yang dispesifikasikan, volume secara generik dijadwalkan dengan menggunakan
penjadwalan <code>round-robin-ed</code> pada semua zona aktif yang ada pada klaster Kubernetes
yang memiliki <em>node</em>.</li><li><code>zones</code> (<em>deprecated</em>): Nilai terpisahkan koma yang merupakan barisan zona pada AWS.
Jika tidak terdapat nilai <code>zone</code> atau <code>zones</code> yang dispesifikasikan,
volume secara generik dijadwalkan dengan menggunakan penjadwalan
<code>round-robin-ed</code> pada semua zona aktif yang ada pada klaster Kubernetes
yang memiliki <em>node</em>.</li><li><code>iopsPerGB</code>: hanya untuk volume <code>io1</code>. Operasi per detik per GiB. Volume <em>plugin</em>
AWS mengalikan nilai ini dengan ukuran volume yang dibutuhkan untuk menghitung IOPS
dari volume (nilai maksimum yang didukung adalah 20,000 IOPS baca <a href=http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/EBSVolumeTypes.html>dokumentasi
AWS</a>.
Nilai masukan yang diharapkan merupakan string, misalnya <code>"10"</code>, bukan <code>10</code>.</li><li><code>fsType</code>: fsType yang didukung oleh Kubernetes. Nilai <em>default</em>-nya adalah: <code>"ext4"</code>.</li><li><code>encrypted</code>: menyatakan dimana volume EBS harus dienkripsi atau tidak.
Nilai yang valid adalah <code>"true"</code> atau <code>"false"</code> (dalam string bukan boolean i.e. <code>"true"</code>, bukan <code>true</code>).</li><li><code>kmsKeyId</code>: opsional. Merupakan nama dari Amazon Resource Name dari <em>key</em> yang digunakan
untuk melakukan enkripsi volume. Jika nilai ini tidak disediakan tetapi nilai dari
<em>field</em> <code>encrypted</code> adalah <em>true</em>, sebuah <em>key</em> akan dibuat oleh AWS. Perhatikan dokumentasi AWS
untuk mengetahui nilai yang valid bagi ARN.</li></ul><div class="alert alert-info note callout" role=alert><strong>Catatan:</strong> Parameter <code>zone</code> dan <code>zones</code> sudah terdeprekasi dan digantikan oleh
<a href=#topologi-yang-diizinkan>allowedTopologies</a></div><h3 id=pd-gce>PD GCE</h3><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>storage.k8s.io/v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>StorageClass<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>slow<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>provisioner</span>:<span style=color:#bbb> </span>kubernetes.io/gce-pd<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>parameters</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>type</span>:<span style=color:#bbb> </span>pd-standard<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>replication-type</span>:<span style=color:#bbb> </span>none<span style=color:#bbb>
</span></span></span></code></pre></div><ul><li><code>type</code>: <code>pd-standard</code> atau <code>pd-ssd</code>. Nilai <em>default</em>: <code>pd-standard</code></li><li><code>zone</code> (<em>deprecated</em>): zona GCE. Jika tidak terdapat nilai <code>zone</code> atau <code>zones</code>
yang dispesifikasikan, volume secara generik dijadwalkan dengan menggunakan
penjadwalan <code>round-robin-ed</code> pada semua zona aktif yang ada pada klaster Kubernetes
yang memiliki <em>node</em>.</li><li><code>zones</code> (<em>deprecated</em>): Nilai terpisahkan koma yang merupakan barisan zona.
Jika tidak terdapat nilai <code>zone</code> atau <code>zones</code> yang dispesifikasikan,
volume secara generik dijadwalkan dengan menggunakan penjadwalan
<code>round-robin-ed</code> pada semua zona aktif yang ada pada klaster Kubernetes
yang memiliki <em>node</em>.</li><li><code>replication-type</code>: <code>none</code> atau <code>regional-pd</code>. Nilai <em>default</em>: <code>none</code>.</li></ul><p>Jika <code>replication-type</code> diubah menjadi <code>none</code>, sebuah PD reguler (zonal) akan
di-<em>provisioning</em>.</p><p>Jika <code>replication-type</code> diubah menjadi <code>regional-pd</code>, sebuah
<a href=https://cloud.google.com/compute/docs/disks/#repds><em>Persistent</em> Disk Regional (PD Regional)</a>
akan di-<em>provisioning</em>. Pada kasus ini, pengguna harus menggunakan <code>zones</code>
dan bukan <code>zone</code> untuk menspesifikasikan zona replikasi yang diinginkan. Jika terdapat
tepat dua zona yang dispesifikasikan, PD Regional akan di-<em>provisioning</em> pada
zona replikasi yang diinginkan. Jika terdapat lebih dari 2 zona yang dispesifikasikan,
Kubernetes akan memilih secara acak zona dari zona-zona yang dispesifikasikan. Jika
parameter <code>zones</code> tidak diinisialisasi, Kubernetes akan memilih secara acak dari
zona yang diatur oleh klaster Kubernetes.</p><div class="alert alert-info note callout" role=alert><strong>Catatan:</strong> Parameter <code>zone</code> dan <code>zones</code> sudah <em>deprecated</em> dan digantikan oleh
<a href=#topologi-yang-diizinkan>allowedTopologies</a></div><h3 id=glusterfs>Glusterfs</h3><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>storage.k8s.io/v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>StorageClass<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>slow<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>provisioner</span>:<span style=color:#bbb> </span>kubernetes.io/glusterfs<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>parameters</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>resturl</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;http://127.0.0.1:8081&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>clusterid</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;630372ccdc720a92c681fb928f27b53f&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>restauthenabled</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;true&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>restuser</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;admin&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>secretNamespace</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;default&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>secretName</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;heketi-secret&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>gidMin</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;40000&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>gidMax</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;50000&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>volumetype</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;replicate:3&#34;</span><span style=color:#bbb>
</span></span></span></code></pre></div><ul><li><p><code>resturl</code>: Servis REST Gluster/URL servis Heketi yang digunakan untuk
melakukan <em>provisioning</em> volume gluster sesuai dengan kebutuhan. Format secara umum
haruslah dalam bentuk <code>IPaddress:Port</code> dan hal ini merupakan parameter wajib untuk
<em>provisioner</em> dinamis GlusterFS. Jika servis Heketi diekspos sebagai servis yang dapat
melakukan <em>routing</em> pada pengaturan openshift/kubernetes, ini dapat memiliki
format yang sesuai dengan <code>http://heketi-storage-project.cloudapps.mystorage.com</code>
dimana fqdn yang ada merupakan URL servis Heketi yang dapat di-<em>resolve</em>.</p></li><li><p><code>restauthenabled</code> : Servis REST Gluster menyediakan nilai boolean yang dapat digunakan
untuk mengajukan <code>authentication</code> untuk server REST yang ada. Jika nilai yang disediakan
adalah <code>"true"</code>, dengan kondisi dimana <code>restuser</code> dan <code>restuserkey</code> atau <code>secretNamespace</code> + <code>secretName</code>
harus diisi. Opsi ini sudah_deprecated_, mekanisme otentikasi akan diizinkan apabila
salah satu dari <em>field</em> <code>restuser</code>, <code>restuserkey</code>, <code>secretName</code> atau <code>secretNamespace</code> diterapkan.</p></li><li><p><code>restuser</code> : Pengguna servis REST Gluster/Heketi yang memiliki akses
untuk membuat volume di dalam Trusted Pool Gluster.</p></li><li><p><code>restuserkey</code> : Password pengguna servis REST Gluster/Heketi
yang digunakan untuk mekanisme otentikasi server REST. Parameter ini <em>deprecated</em>
dan digantikan dengan parameter <code>secretNamespace</code> + <code>secretName</code>.</p></li><li><p><code>secretNamespace</code>, <code>secretName</code> : Identifikasi instans Secret yang mengandung
password pengguna yang digunakan untuk berkomunikasi dengan servis REST Gluster.
Parameter ini dianggap opsional, password kosong dapat digunakan ketika
nilai dari <code>secretNamespace</code> dan <code>secretName</code> tidak dispesifikasikan.
Secret yang disediakan haruslah memiliki tipe <code>"kubernetes.io/glusterfs"</code>,
yang dapat dibuat dengan menggunakan mekanisme dibawah ini:</p><pre tabindex=0><code>kubectl create secret generic heketi-secret \
  --type=&#34;kubernetes.io/glusterfs&#34; --from-literal=key=&#39;opensesame&#39; \
  --namespace=default
</code></pre><p>Contoh Secret dapat ditemukan pada berkas berikut
<a href=https://github.com/kubernetes/examples/tree/master/staging/persistent-volume-provisioning/glusterfs/glusterfs-secret.yaml>glusterfs-provisioning-secret.yaml</a>.</p></li><li><p><code>clusterid</code>: <code>630372ccdc720a92c681fb928f27b53f</code> merupakan ID dari klaster
yang akan digunakan oleh Heketi ketikan melakukan <em>provisioning</em> volume. ID ini juga
dapat berupa serangkaian list, misalnya: <code>"8452344e2becec931ece4e33c4674e4e,42982310de6c63381718ccfa6d8cf397"</code>.
Parameter ini merupakan parameter opsional.</p></li><li><p><code>gidMin</code>, <code>gidMax</code> : Nilai minimum dan maksimum dari GID untuk kelas penyimpanan (<em>storage class</em>).
Sebuah nilai unik dari GID di dalam <em>range</em> ( gidMin-gidMax ) ini akan digunakan untuk melakukan
<em>provisioning</em> volume secara dinamis. Nilai ini bersifat opsional. Jika tidak dispesifikasikan,
volume akan secara default di-<em>provisioning</em> dalam <em>range</em> 2000-2147483647 yang merupakan nilai default
dari gidMin dan gidMax.</p></li><li><p><code>volumetype</code> : Tipe volume beserta paremeter-nya dapat diatur dengan menggunakan nilai opsional
berikut. Jika tipe dari volume tidak dispesifikasikan, maka <em>provisioner</em> akan memutuskan tipe
volume apakah yang akan digunakan.</p><p>Sebagai contoh:</p><ul><li><p>Volume replika: <code>volumetype: replicate:3</code> dimana '3' merupakan jumlah replika.</p></li><li><p>Persebaran (<em>Disperse</em>)/EC volume: <code>volumetype: disperse:4:2</code> dimana'4' merupakan data dan '2' merupakan jumlah redundansi.</p></li><li><p>Distribusi volume: <code>volumetype: none</code></p></li></ul><p>Untuk tipe volume apa saja yang tersedia dan berbagai opsi administrasi yang ada, kamu dapat membaca
<a href=https://access.redhat.com/documentation/en-us/red_hat_gluster_storage/>Petunjuk Administrasi</a>.</p><p>Untuk informasi lebih lanjut, kamu dapat membaca
<a href=https://github.com/heketi/heketi/wiki/Setting-up-the-topology>Bagaimana Cara Mengatur Heketi</a>.</p><p>Ketika PersistentVolume di-<em>provisioning</em> secara dinamis, plugin Gluster secara otomatis
akan membuat <em>endpoint</em> serta sebuah servis <em>headless</em> dengan nama <code>gluster-dynamic-&lt;claimname></code>.
<em>Endpoint</em> dinamis dan servis secara otomatis akan dihapus ketika PVC dihapus.</p></li></ul><h3 id=openstack-cinder>OpenStack Cinder</h3><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>storage.k8s.io/v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>StorageClass<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>gold<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>provisioner</span>:<span style=color:#bbb> </span>kubernetes.io/cinder<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>parameters</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>availability</span>:<span style=color:#bbb> </span>nova<span style=color:#bbb>
</span></span></span></code></pre></div><ul><li><code>availability</code>: Zona <em>Availability</em>. Jika tidak dispesifikasikan, secara umum volume akan
diatur dengan menggunakan algoritma <em>round-robin</em> pada semua zona aktif
dimana klaster Kubernetes memiliki sebuah node.</li></ul><div class="alert alert-info note callout" role=alert><strong>Catatan:</strong><div style=margin-top:10px;margin-bottom:10px><b>FEATURE STATE:</b> <code>Kubernetes 1.11 [deprecated]</code></div><p><em>Provisioner</em> internal OpenStack ini sudah <em>deprecated</em>. Kamu dapat menggunakan <a href=https://github.com/kubernetes/cloud-provider-openstack><em>provider</em> eksternal penyedia layanan <em>cloud</em> untuk OpenStack</a>.</div><h3 id=vsphere>vSphere</h3><ol><li><p>Buatlah sebuah StorageClass dengan menggunakan sebuah format disk yang dispesifikasikan oleh pengguna.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>storage.k8s.io/v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>StorageClass<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>fast<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>provisioner</span>:<span style=color:#bbb> </span>kubernetes.io/vsphere-volume<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>parameters</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>diskformat</span>:<span style=color:#bbb> </span>zeroedthick<span style=color:#bbb>
</span></span></span></code></pre></div><p><code>diskformat</code>: <code>thin</code>, <code>zeroedthick</code> dan <code>eagerzeroedthick</code>. Nilai default: <code>"thin"</code>.</p></li><li><p>Buatlah sebuah StorageClass dengan menggunakan sebuah format disk pada <em>datastore</em> yang dispesifikasikan oleh pengguna.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>storage.k8s.io/v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>StorageClass<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>fast<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>provisioner</span>:<span style=color:#bbb> </span>kubernetes.io/vsphere-volume<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>parameters</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>diskformat</span>:<span style=color:#bbb> </span>zeroedthick<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>datastore</span>:<span style=color:#bbb> </span>VSANDatastore<span style=color:#bbb>
</span></span></span></code></pre></div><p><code>datastore</code>: Pengguna juga dapat menspesifikasikan <em>datastore</em> pada StorageClass.
Volume akan dibuat pada datastore yang dispesifikasikan pada kelas penyimpanan,
dalam hal ini adalah <code>VSANDatastore</code>. <em>Field</em> ini bersifat opsional. Jika <em>datastore</em>
tidak dispesifikasikan, maka volume akan dibuat dengan menggunakan <em>datastore</em> yang dispesifikasikan
pada berkas konfigurasi vSphere yang digunakan untuk menginisialisasi penyedia layanan cloud vSphere.</p></li><li><p>Manajemen Kebijakan Penyimpanan di dalam Kubernetes</p><ul><li><p>Menggunakan kebijakan (<em>policy</em>) yang ada pada vCenter</p><p>Salah satu dari fitur paling penting yang ada pada vSphere untuk manajemen penyimpanan
adalah manajemen bebasis <em>policy</em>. Storage Policy Based Management (SPBM) adalah <em>framework</em>
yang menyediakan sebuah <em>control plane</em> terpadu pada <em>data service</em> yang meluas dan
solusi penyimpanannya yang tersedia. SPBM memungkinkan administrator vSphere menghadapi
permasalahan yang mungkin muncul seperti <em>capacity planning</em>, membedakan level servis, dan
melakukan manajemen <em>headroom capacity</em>.</p><p><em>Policy</em> SPBM dapat dispesifikasikan pada StorageClass menggunakan parameter
<code>storagePolicyName</code>.</p></li><li><p>Dukungan <em>policy</em> SAN virtual di dalam Kubernetes</p><p>Administrator <em>Vsphere Infrastructure</em> (VI) akan memiliki kemampuan
untuk menspesifikasikan Virtual SAN Storage Capabilities khusus
selama masa <em>provisioning</em> volume secara dinamis. Persyaratan kapabilitas
penyimpanan diubah menjadi sebuah <em>policy</em> Virtual SAN yang nantinya akan
dimasukkan ke dalam lapisan Virtual SAN ketika sebuah <em>persitent volume</em> (penyimpanan
virtual) dibuat. Penyimpanan virtual kemudian akan didistribusikan pada semua
<em>datastore</em> Virtual SAN untuk memenuhi kebutuhan ini.</p><p>Kamu dapat melihat <a href=https://vmware.github.io/vsphere-storage-for-kubernetes/documentation/policy-based-mgmt.html><em>Policy</em> Penyimpanan Berdasarkan Manajemen untuk <em>Provisioning</em> Dinamis Volume</a>
untuk detil lebih lanjut mengenai penggunaan <em>policy</em> penyimpanan untuk manajemen <em>persistent volume</em>.</p></li></ul></li></ol><p>Terdapat beberapa
<a href=https://github.com/kubernetes/examples/tree/master/staging/volumes/vsphere>contoh vSphere</a>
yang dapat kamu gunakan untuk mencoba manajemen <em>persistent volume</em> di dalam Kubernetes untuk vSpehere.</p><h3 id=rbd-ceph>RBD Ceph</h3><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>storage.k8s.io/v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>StorageClass<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>fast<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>provisioner</span>:<span style=color:#bbb> </span>kubernetes.io/rbd<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>parameters</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>monitors</span>:<span style=color:#bbb> </span><span style=color:#666>10.16.153.105</span>:<span style=color:#666>6789</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>adminId</span>:<span style=color:#bbb> </span>kube<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>adminSecretName</span>:<span style=color:#bbb> </span>ceph-secret<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>adminSecretNamespace</span>:<span style=color:#bbb> </span>kube-system<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>pool</span>:<span style=color:#bbb> </span>kube<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>userId</span>:<span style=color:#bbb> </span>kube<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>userSecretName</span>:<span style=color:#bbb> </span>ceph-secret-user<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>userSecretNamespace</span>:<span style=color:#bbb> </span>default<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>fsType</span>:<span style=color:#bbb> </span>ext4<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>imageFormat</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;2&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>imageFeatures</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;layering&#34;</span><span style=color:#bbb>
</span></span></span></code></pre></div><ul><li><p><code>monitors</code>: Monitor Ceph, merupakan nilai yang dipisahkan oleh koma (csv). Parameter ini dibutuhkan.</p></li><li><p><code>adminId</code>: ID klien Ceph yang dapat digunakan untuk membuat images di dalam pool.
Nilai <em>default</em>-nya adalah "admin".</p></li><li><p><code>adminSecretName</code>: Nama Secret untuk <code>adminId</code>. Parameter ini dibutuhkan.
Secret yang dibutuhkan haruslah memiliki tipe "kubernetes.io/rbd".</p></li><li><p><code>adminSecretNamespace</code>: Namespace untuk <code>adminSecretName</code>. Nilai <em>default</em>-nya adalah "default".</p></li><li><p><code>pool</code>: Pool Ceph RBD. Nilai <em>default</em>-nya adalah "rbd".</p></li><li><p><code>userId</code>: Klien ID Ceph yang digunakan untuk melakukan pemetaan image RBD. Nilai <em>default</em>-nya sama dengan
<code>adminId</code>.</p></li><li><p><code>userSecretName</code>: Nama Secret Ceph untuk <code>userId</code> yang digunakan untuk memetakan image RBD.
Secret ini harus berada pada namespace yang sama dengan PVC. Parameter ini dibutuhkan.
Secret yang disediakan haruslah memiliki tipe "kubernetes.io/rbd", dibuat dengan cara:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl create secret generic ceph-secret --type<span style=color:#666>=</span><span style=color:#b44>&#34;kubernetes.io/rbd&#34;</span> <span style=color:#b62;font-weight:700>\
</span></span></span><span style=display:flex><span><span style=color:#b62;font-weight:700></span>  --from-literal<span style=color:#666>=</span><span style=color:#b8860b>key</span><span style=color:#666>=</span><span style=color:#b44>&#39;QVFEQ1pMdFhPUnQrSmhBQUFYaERWNHJsZ3BsMmNjcDR6RFZST0E9PQ==&#39;</span> <span style=color:#b62;font-weight:700>\
</span></span></span><span style=display:flex><span><span style=color:#b62;font-weight:700></span>  --namespace<span style=color:#666>=</span>kube-system
</span></span></code></pre></div></li><li><p><code>userSecretNamespace</code>: Namespace untuk <code>userSecretName</code>.</p></li><li><p><code>fsType</code>: fsType yang didukung oleh kubernetes. Nilai <em>default</em>-nya adalah: <code>"ext4"</code>.</p></li><li><p><code>imageFormat</code>: Format image Ceph RBD, nilai yang mungkin adalah "1" atau "2". Nilai <em>default</em>-nya adalah "2".</p></li><li><p><code>imageFeatures</code>: Parameter ini bersifat opsional dan hanya dapat digunakan jika kamu mengganti nilai
dari <code>imageFormat</code> ke "2". Saat ini fitur yang didukung hanyalah <code>layering</code>.
Nilai <em>default</em>-nya adalah "", dan tidak ada fitur yang diaktifkan.</p></li></ul><h3 id=quobyte>Quobyte</h3><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>storage.k8s.io/v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>StorageClass<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>   </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>slow<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>provisioner</span>:<span style=color:#bbb> </span>kubernetes.io/quobyte<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>parameters</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>quobyteAPIServer</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;http://138.68.74.142:7860&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>registry</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;138.68.74.142:7861&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>adminSecretName</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;quobyte-admin-secret&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>adminSecretNamespace</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;kube-system&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>user</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;root&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>group</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;root&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>quobyteConfig</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;BASE&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>quobyteTenant</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;DEFAULT&#34;</span><span style=color:#bbb>
</span></span></span></code></pre></div><ul><li><p><code>quobyteAPIServer</code>: API Server dari Quobyte dalam format
<code>"http(s)://api-server:7860"</code></p></li><li><p><code>registry</code>: Registri Quobyte yang digunakan untuk melakukan <em>mount</em> volume. Kamu dapat menspesifikasikan
registri yang kamu inginkan dengan format pasangan <code>&lt;host>:&lt;port></code> atau jika kamu ingin mendefinisikan
beberapa registri sekaligus kamu dapat menempatkan koma diantara setiap pasangan <code>&lt;host>:&lt;port></code> yang ada,
misalnya <code>&lt;host1>:&lt;port>,&lt;host2>:&lt;port>,&lt;host3>:&lt;port></code>.
Host dapat berupa alamat IP atau DNS.</p></li><li><p><code>adminSecretNamespace</code>: Namespace <code>adminSecretName</code>. Nilai default-nya adalah "default".</p></li><li><p><code>adminSecretName</code>: Secret yang mengandung informasi mengenai pengguna Quobyte dan
password yang digunakan untuk melakukan otentikasi API server. Secret yang digunakan
haruslah memiliki tipe "kubernetes.io/quobyte", yang dibuat dengan mekanisme berikut:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl create secret generic quobyte-admin-secret <span style=color:#b62;font-weight:700>\
</span></span></span><span style=display:flex><span><span style=color:#b62;font-weight:700></span>  --type<span style=color:#666>=</span><span style=color:#b44>&#34;kubernetes.io/quobyte&#34;</span> --from-literal<span style=color:#666>=</span><span style=color:#b8860b>key</span><span style=color:#666>=</span><span style=color:#b44>&#39;opensesame&#39;</span> <span style=color:#b62;font-weight:700>\
</span></span></span><span style=display:flex><span><span style=color:#b62;font-weight:700></span>  --namespace<span style=color:#666>=</span>kube-system
</span></span></code></pre></div></li><li><p><code>user</code>: Melakukan pemetaan terhadap semua akses yang dimiliki pengguna.
Nilai <em>default</em>-nya adalah "root".</p></li><li><p><code>group</code>: Melakukan pemetaan terhadap semua group. Nilai <em>default</em>-nya adalah "nfsnobody".</p></li><li><p><code>quobyteConfig</code>: Menggunakan konfigurasi spesifik untuk membuat volume.
Kamu dapat membuat sebuah file konfigurasi atau melakukan modifikasi terhadap konfigurasi yang sudah ada
dengan menggunakan tatap muka Web atau CLI quobyte. Nilai <em>default</em>-nya adalah "BASE".</p></li><li><p><code>quobyteTenant</code>: Menggunakan ID tenant yang dispesifikasikan untuk membuat/menghapus volume.
<em>Tenant</em> Quobyte haruslah sudah berada di dalam Quobyte. Nilai <em>default</em>-nya adalah "DEFAULT".</p></li></ul><h3 id=azure-disk>Azure Disk</h3><h4 id=kelas-penyimpanan-disk-azure-yang-tidak-dikelola>Kelas Penyimpanan Disk Azure yang Tidak Dikelola</h4><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>storage.k8s.io/v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>StorageClass<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>slow<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>provisioner</span>:<span style=color:#bbb> </span>kubernetes.io/azure-disk<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>parameters</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>skuName</span>:<span style=color:#bbb> </span>Standard_LRS<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>location</span>:<span style=color:#bbb> </span>eastus<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>storageAccount</span>:<span style=color:#bbb> </span>azure_storage_account_name<span style=color:#bbb>
</span></span></span></code></pre></div><ul><li><code>skuName</code>: Akun penyimpanan Azure yang ada pada tingkatan Sku. Nilai <em>default</em>-nya adalah kosong.</li><li><code>location</code>: Lokasi akun penyimpanan Azure. Nilai <em>default</em>-nya adalah kosong.</li><li><code>storageAccount</code>: Nama akun penyimpanan Azure. Jika sebuan akun penyimpanan disediakan,
akun tersebut haruslah berada pada grup sumber daya yang ada dengan klaster,
dan <code>location</code> akan diabaikan. Jika sebuah akun penyimpanan tidak disediakan, sebuah akun penyimpanan
baru akan dibuat pada grup sumber daya yang ada dengan klaster.</li></ul><h4 id=kelas-penyimpanan-disk-azure-yang-baru-mulai-versi-v1-7-2>Kelas Penyimpanan Disk Azure yang Baru (mulai versi v1.7.2)</h4><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>storage.k8s.io/v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>StorageClass<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>slow<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>provisioner</span>:<span style=color:#bbb> </span>kubernetes.io/azure-disk<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>parameters</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>storageaccounttype</span>:<span style=color:#bbb> </span>Standard_LRS<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>managed<span style=color:#bbb>
</span></span></span></code></pre></div><ul><li><code>storageaccounttype</code>: Akun penyimpanan Azure yang ada pada tingkatan Sku. Nilai <em>default</em>-nya adalah kosong.</li><li><code>kind</code>: Nilai yang mungkin adalah <code>shared</code>, <code>dedicated</code>, dan <code>managed</code> (default).
Ketika <code>kind</code> yang digunakan adalah <code>shared</code>, semua disk yang tidak di-<em>manage</em> akan
dibuat pada beberapa akun penyimpanan yang ada pada grup sumber daya yang sama dengan klaster.
Ketika <code>kind</code> yang digunakan adalah <code>dedicated</code>, sebuah akun penyimpanan
baru akan dibuat pada grup sumber daya yang ada dengan klaster. Ketika <code>kind</code> yang digunakan adalah
<code>managed</code>, semua disk yang dikelola akan dibuat pada grup sumber daya yang ada dengan klaster.</li></ul><ul><li>VM premium dapat di-<em>attach</em> baik pada Standard_LRS dan Premium_LRS disks, sementara Standard
VM hanya dapat di-<em>attach</em> pada disk Standard_LRS.</li><li>VM yang dikelola hanya dapat meng-<em>attach</em> disk yang dikelola dan VM yang tidak dikelola hanya dapat
meng-<em>attach</em> disk yang tidak dikelola.</li></ul><h3 id=berkas-azure>Berkas Azure</h3><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>storage.k8s.io/v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>StorageClass<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>azurefile<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>provisioner</span>:<span style=color:#bbb> </span>kubernetes.io/azure-file<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>parameters</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>skuName</span>:<span style=color:#bbb> </span>Standard_LRS<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>location</span>:<span style=color:#bbb> </span>eastus<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>storageAccount</span>:<span style=color:#bbb> </span>azure_storage_account_name<span style=color:#bbb>
</span></span></span></code></pre></div><ul><li><code>skuName</code>: Akun penyimpanan Azure yang ada pada tingkatan Sku. Nilai <em>default</em>-nya adalah kosong.</li><li><code>location</code>: Lokasi akun penyimpanan Azure. Nilai <em>default</em>-nya adalah kosong.</li><li><code>storageAccount</code>: Nama akun penyimpanan Azure. Nilai <em>default</em>-nya adalah kosong. Jika sebuah penyimpanan
tidak memiliki sebuah akun yang disediakan, semua akun penyimpanan yang diasosiasikan dengan
grup sumber daya yang ada dan kemudian melakukan pencarian terhadap akun yang sesuai dengan
<code>skuName</code> dan <code>location</code>. Jika sebuah akun penyimpanan disediakan, akun tersebut haruslah berada
di dalam grup sumber daya yang sama dengan klaster, serta <code>skuName</code> dan <code>location</code> akan diabaikan.</li></ul><p>Selama <em>provision</em>, sebuah secret dibuat untuk menyimpan <em>credentials</em>. Jika klaster
menggunakan konsep <a href=/id/docs/reference/access-authn-authz/rbac/>RBAC</a> dan
<a href=/id/docs/reference/access-authn-authz/rbac/#controller-roles><em>Roles</em> Controller</a>,
menambahkan kapabilitas <code>create</code> untuk sumber daya <code>secret</code> bagi clusterrole
<code>system:controller:persistent-volume-binder</code>.</p><h3 id=volume-portworx>Volume Portworx</h3><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>storage.k8s.io/v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>StorageClass<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>portworx-io-priority-high<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>provisioner</span>:<span style=color:#bbb> </span>kubernetes.io/portworx-volume<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>parameters</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>repl</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;1&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>snap_interval</span>:<span style=color:#bbb>   </span><span style=color:#b44>&#34;70&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>io_priority</span>:<span style=color:#bbb>  </span><span style=color:#b44>&#34;high&#34;</span><span style=color:#bbb>
</span></span></span></code></pre></div><ul><li><code>fs</code>: filesystem yang akan digunakan: <code>none/xfs/ext4</code> (nilai default-nya: <code>ext4</code>).</li><li><code>block_size</code>: ukuran block dalam Kbytes (nilai <em>default</em>-nya: <code>32</code>).</li><li><code>repl</code>: jumlah replika <em>synchronous</em> yang dapat disediakan dalam bentuk
faktor replikasi <code>1..3</code> (nilai <em>default</em>-nya: <code>1</code>) Nilai yang diharapkan dalam bentuk String
<code>"1"</code> dan bukan <code>1</code>.</li><li><code>io_priority</code>: menentukan apakah volume yang dibuat akan dari penyimpanan dengan kualitas
tinggi atau rendah dengan urutan prioritas <code>high/medium/low</code> (nilai <em>default</em>-nya: <code>low</code>).</li><li><code>snap_interval</code>: interval waktu dalam menit yang digunakan untuk melakukan <em>trigger</em> <em>snapshots</em>.
<em>Snapshots</em> dibuat secara inkremen berdasarkan perbedaan yang ada dengan <em>snapshot</em> yang dibuat sebelumnya,
nilai perbedaan 0 akan menonaktifkan pembuatan <em>snapshot</em> (nilai default-nya: <code>0</code>). Sebuah string merupakan nilai
yang diharapkan <code>"70"</code> dan bukan <code>70</code>.</li><li><code>aggregation_level</code>: menspesifikasikan jumlah <em>chunks</em> dimana volume akan didistribusikan,
0 mengindikasikan volume yang <em>non-aggregate</em> (nilai default-nya: <code>0</code>). Sebuah string merupakan nilai
yang diharapkan <code>"0"</code> dan bukan <code>0</code>.</li><li><code>ephemeral</code>: menentukan apakah volume harus dihapus setelah di-<em>unmount</em>
atau harus tetap ada. Penggunaan <code>emptyDir</code> dapat diubah menjadi true dan penggunaan
<code>persistent volumes</code> untuk basisdata seperti Cassandra harus diubah menjadi false<code>, true/false</code> (nilai default-nya: <code>false</code>). Sebuah string merupakan nilai
yang diharapkan <code>"true"</code> dan bukan <code>true</code>.</li></ul><h3 id=scaleio>ScaleIO</h3><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>storage.k8s.io/v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>StorageClass<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>slow<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>provisioner</span>:<span style=color:#bbb> </span>kubernetes.io/scaleio<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>parameters</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>gateway</span>:<span style=color:#bbb> </span>https://192.168.99.200:443/api<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>system</span>:<span style=color:#bbb> </span>scaleio<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>protectionDomain</span>:<span style=color:#bbb> </span>pd0<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>storagePool</span>:<span style=color:#bbb> </span>sp1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>storageMode</span>:<span style=color:#bbb> </span>ThinProvisioned<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>secretRef</span>:<span style=color:#bbb> </span>sio-secret<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>readOnly</span>:<span style=color:#bbb> </span><span style=color:#a2f;font-weight:700>false</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>fsType</span>:<span style=color:#bbb> </span>xfs<span style=color:#bbb>
</span></span></span></code></pre></div><ul><li><code>provisioner</code>: atribut yang nilainya merupakan <code>kubernetes.io/scaleio</code></li><li><code>gateway</code>: alamat <em>gateway</em> ScaleIO (wajib)</li><li><code>system</code>: nama sistem ScaleIO (wajib)</li><li><code>protectionDomain</code>: nama domain proteksi ScaleIO (wajib)</li><li><code>storagePool</code>: nama pool volume penyimpanan (wajib)</li><li><code>storageMode</code>: mode <em>provisioning</em> penyimpanan: <code>ThinProvisioned</code> (default) atau
<code>ThickProvisioned</code></li><li><code>secretRef</code>: penunjuk pada objek Secret yang dikonfigurasi (wajib)</li><li><code>readOnly</code>: menentukan mode akses terhadap volume yang di-<em>mount</em> (nilai default-nya: false)</li><li><code>fsType</code>: filesystem yang digunakan untuk volume (nilai default-nya: ext4)</li></ul><p>Plugin volume ScaleIO Kubernetes membutuhkan objek Secret yang suda dikonfigurasi sebelumnya.
Secret ini harus dibuat dengan tipe <code>kubernetes.io/scaleio</code> dan menggunakan namespace yang sama
dengan PVC yang dirujuk, seperti ditunjukkan pada contoh yang ada:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl create secret generic sio-secret --type<span style=color:#666>=</span><span style=color:#b44>&#34;kubernetes.io/scaleio&#34;</span> <span style=color:#b62;font-weight:700>\
</span></span></span><span style=display:flex><span><span style=color:#b62;font-weight:700></span>--from-literal<span style=color:#666>=</span><span style=color:#b8860b>username</span><span style=color:#666>=</span>sioadmin --from-literal<span style=color:#666>=</span><span style=color:#b8860b>password</span><span style=color:#666>=</span><span style=color:#b8860b>d2NABDNjMA</span><span style=color:#666>==</span> <span style=color:#b62;font-weight:700>\
</span></span></span><span style=display:flex><span><span style=color:#b62;font-weight:700></span>--namespace<span style=color:#666>=</span>default
</span></span></code></pre></div><h3 id=storageos>StorageOS</h3><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>storage.k8s.io/v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>StorageClass<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>fast<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>provisioner</span>:<span style=color:#bbb> </span>kubernetes.io/storageos<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>parameters</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>pool</span>:<span style=color:#bbb> </span>default<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>description</span>:<span style=color:#bbb> </span>Kubernetes volume<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>fsType</span>:<span style=color:#bbb> </span>ext4<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>adminSecretNamespace</span>:<span style=color:#bbb> </span>default<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>adminSecretName</span>:<span style=color:#bbb> </span>storageos-secret<span style=color:#bbb>
</span></span></span></code></pre></div><ul><li><code>pool</code>: Nama kapasitas distribusi StorageOS yang digunakan untuk melakukan
<em>provisioning</em> volume. <em>Pool</em> default akan digunakan apabila nilainya tidak dispesifikasikan.</li><li><code>description</code>: Deskripsi untuk melakukan <em>assignment</em> volume yang baru dibuat secara dinamis.
Semua deskripsi volume akan bernilai sama untuk kelas penyimpanan yang sama, meskipun begitu
kelas penyimpanan yang berbeda dapat digunakan untuk membuat deskripsi yang berbeda untuk penggunaan
yang berbeda. Nilai default-nya adalah <code>Kubernetes volume</code>.</li><li><code>fsType</code>: Tipe filesystem default yang digunakan. Perhatikan bahwa aturan
yang didefinisikan oleh pengguna di dalam StirageOS dapat meng-<em>override</em> nilai ini.
Nilai default-nya adalah <code>ext4</code>.</li><li><code>adminSecretNamespace</code>: Namespace dimana konfigurasi secret API berada. Hal ini bersifat wajib
apabila adminSecretName diaktifkan.</li><li><code>adminSecretName</code>: Nama secret yang digunakan untuk memperoleh <em>credentials</em> StorageOS
API. Jika tidak dispesifikasikan, nilaidefault akan digunakan.</li></ul><p>Plugin volume dapat menggunakan objek Secret untuk menspesifikasikan
endpoint dan kredensial yang digunakan untuk mengakses API StorageOS.
Hal ini hanya akan dibutuhkan apabila terdapat perubahan pada nilai <em>default</em>.
Secret ini harus dibuat dengan tipe <code>kubernetes.io/storageos</code>,
seperti ditunjukkan pada contoh yang ada:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl create secret generic storageos-secret <span style=color:#b62;font-weight:700>\
</span></span></span><span style=display:flex><span><span style=color:#b62;font-weight:700></span>--type<span style=color:#666>=</span><span style=color:#b44>&#34;kubernetes.io/storageos&#34;</span> <span style=color:#b62;font-weight:700>\
</span></span></span><span style=display:flex><span><span style=color:#b62;font-weight:700></span>--from-literal<span style=color:#666>=</span><span style=color:#b8860b>apiAddress</span><span style=color:#666>=</span>tcp://localhost:5705 <span style=color:#b62;font-weight:700>\
</span></span></span><span style=display:flex><span><span style=color:#b62;font-weight:700></span>--from-literal<span style=color:#666>=</span><span style=color:#b8860b>apiUsername</span><span style=color:#666>=</span>storageos <span style=color:#b62;font-weight:700>\
</span></span></span><span style=display:flex><span><span style=color:#b62;font-weight:700></span>--from-literal<span style=color:#666>=</span><span style=color:#b8860b>apiPassword</span><span style=color:#666>=</span>storageos <span style=color:#b62;font-weight:700>\
</span></span></span><span style=display:flex><span><span style=color:#b62;font-weight:700></span>--namespace<span style=color:#666>=</span>default
</span></span></code></pre></div><p>Secret yang digunakan untuk melakukan <em>provisioning</em> volume secara dinamis
dapat dibuat di namespace apapun dan dirujuk dengan menggunakan parameter <code>adminSecretNamespace</code>.
Secret yang digunakan oleh volume yang sedang di-<em>provisioning</em> harus dibuat pada namespace yang sama
dengan PVC yang merujuk secret tersebut.</p><h3 id=lokal>Lokal</h3><div style=margin-top:10px;margin-bottom:10px><b>FEATURE STATE:</b> <code>Kubernetes v1.14 [stable]</code></div><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>storage.k8s.io/v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>StorageClass<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>local-storage<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>provisioner</span>:<span style=color:#bbb> </span>kubernetes.io/no-provisioner<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>volumeBindingMode</span>:<span style=color:#bbb> </span>WaitForFirstConsumer<span style=color:#bbb>
</span></span></span></code></pre></div><p>Volume lokal tidak mendukung adanya <em>provisioning</em> secara dinamis,
meskipun begitu sebuah StorageClass akan tetap dibuat untuk mencegah terjadinya <em>bind</em> volume
sampai <em>scheduling</em> pod dilakukan. Hal ini dispesifikasikan oleh mode <em>binding</em> volume
<code>WaitForFirstConsumer</code>.</p><p>Memperlambat <em>binding</em> volume mengizinkan <em>scheduler</em> untuk memastikan
batasan <em>scheduling</em> semua pod ketika memilih PersistentVolume untuk sebuah PersistentVolumeClaim.</p></div><div class=td-content style=page-break-before:always><h1 id=pg-4d00116c86dade62bdd5be7dc2afa1ca>6.6 - VolumeSnapshotClass</h1><p>Laman ini menjelaskan tentang konsep VolumeSnapshotClass pada Kubernetes. Sebelum melanjutkan,
sangat disarankan untuk membaca <a href=/id/docs/concepts/storage/volume-snapshots/><em>snapshot</em> volume</a>
dan <a href=/id/docs/concepts/storage/storage-classes>kelas penyimpanan (<em>storage class</em>)</a> terlebih dahulu.</p><h2 id=pengenalan>Pengenalan</h2><p>Seperti halnya StorageClass yang menyediakan cara bagi admin untuk mendefinisikan
"kelas" penyimpanan yang mereka tawarkan saat proses penyediaan sebuah volume, VolumeSnapshotClass
menyediakan cara untuk mendefinisikan "kelas" penyimpanan saat menyediakan <em>snapshot</em> volume.</p><h2 id=sumber-daya-volumesnapshotclass>Sumber Daya VolumeSnapshotClass</h2><p>Masing-masing VolumeSnapshotClass terdiri dari <em>field</em> <code>snapshotter</code> dan <code>parameters</code>,
yang digunakan saat sebuah VolumeSnapshot yang dimiliki kelas tersebut perlu untuk
disediakan secara dinamis.</p><p>Nama yang dimiliki suatu objek VolumeSnapshotClass sangatlah penting, karena digunakan
oleh pengguna saat meminta sebuah kelas tertentu. Admin dapat mengatur nama dan parameter
lainnya dari sebuah kelas saat pertama kali membuat objek VolumeSnapshotClass. Objek
tidak dapat diubah setelah dibuat.</p><p>Admin dapat mengatur VolumeSnapshotClass <em>default</em> untuk VolumeSnapshot yang tidak
memiliki spesifikasi kelas apapun.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>snapshot.storage.k8s.io/v1alpha1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>VolumeSnapshotClass<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>csi-hostpath-snapclass<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>snapshotter</span>:<span style=color:#bbb> </span>csi-hostpath<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>parameters</span>:<span style=color:#bbb>
</span></span></span></code></pre></div><h3 id=snapshotter><code>snapshotter</code></h3><p>VolumeSnapshotClass memiliki sebuah <code>snapshotter</code> yang menentukan plugin volume CSI
apa yang digunakan untuk penyediaan VolumeSnapshot. <em>Field</em> ini wajib diatur.</p><h3 id=parameters><code>parameters</code></h3><p>VolumeSnapshotClass memiliki parameter-parameter yang menggambarkan <em>snapshot</em> volume
di dalam VolumeSnapshotClass. Parameter-parameter yang berbeda diperbolehkan tergantung
dari <code>shapshotter</code>.</p></div><div class=td-content style=page-break-before:always><h1 id=pg-018f0a7fc6e2f6d16da37702fc39b4f3>6.7 - Penyediaan Volume Dinamis</h1><p>Penyediaan volume dinamis memungkinkan volume penyimpanan untuk dibuat sesuai permintaan (<em>on-demand</em>).
Tanpa adanya penyediaan dinamis (<em>dynamic provisioning</em>), untuk membuat volume penyimpanan baru, admin klaster secara manual harus
memanggil penyedia layanan cloud atau layanan penyimpanan, dan kemudian membuat <a href=/id/docs/concepts/storage/persistent-volumes/>objek PersistentVolume</a>
sebagai representasi di Kubernetes. Fitur penyediaan dinamis menghilangkan kebutuhan admin klaster untuk menyediakan
penyimpanan sebelumnya (<em>pre-provision</em>). Dengan demikian, penyimpanan akan tersedia secara otomatis
ketika diminta oleh pengguna.</p><h2 id=latar-belakang>Latar Belakang</h2><p>Penyediaan volume dinamis diimplementasi berdasarkan objek API StorageClass dari
grup API <code>storage.k8s.io</code>. Seorang admin klaster dapat mendefinisikan berbagai macam
objek StorageClass sesuai kebutuhan, masing-masing menentukan <em>plugin volume</em> (disebut
juga <em>provisioner</em>) yang menyediakan sebuah volume beserta kumpulan parameter untuk
diteruskan oleh <em>provisioner</em> ketika proses penyediaan.</p><p>Seorang klaster admin dapat mendefinisikan dan mengekspos berbagai templat penyimpanan
(dari sistem penyimpanan yang sama maupun berbeda) di dalam klaster, masing-masing dengan
kumpulan parameter tertentu. Desain ini memastikan bahwa pengguna tidak perlu khawatir betapa
rumitnya mekanisme penyediaan penyimpanan, tapi tetap memiliki kemampuan untuk
memilih berbagai macam pilihan penyimpanan.</p><p>Info lebih lanjut mengenai <em>storage class</em> dapat dilihat <a href=/id/docs/concepts/storage/storage-classes/>di sini</a>.</p><h2 id=mengaktifkan-penyediaan-dinamis-dynamic-provisioning>Mengaktifkan Penyediaan Dinamis (<em>Dynamic Provisioning</em>)</h2><p>Untuk mengaktifkan penyediaan dinamis, seorang admin klaster perlu untuk
terlebih dahulu membuat (<em>pre-create</em>) satu atau beberapa objek StorageClass
untuk pengguna.
Objek StorageClass mendefinisikan <em>provisioner</em> mana yang seharusnya digunakan
dan parameter apa yang seharusnya diberikan pada <em>provisioner</em> tersebut saat
penyediaan dinamis dipanggil.
Manifestasi berikut ini membuat sebuah StorageClass "slow" yang
menyediakan <em>persistent</em> disk standar.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>storage.k8s.io/v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>StorageClass<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>slow<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>provisioner</span>:<span style=color:#bbb> </span>kubernetes.io/gce-pd<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>parameters</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>type</span>:<span style=color:#bbb> </span>pd-standard<span style=color:#bbb>
</span></span></span></code></pre></div><p>Manifestasi berikut ini membuat sebuah StorageClass "fast" yang menyediakan
SSD <em>persistent</em> disk.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>storage.k8s.io/v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>StorageClass<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>fast<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>provisioner</span>:<span style=color:#bbb> </span>kubernetes.io/gce-pd<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>parameters</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>type</span>:<span style=color:#bbb> </span>pd-ssd<span style=color:#bbb>
</span></span></span></code></pre></div><h2 id=menggunakan-penyediaan-dinamis>Menggunakan Penyediaan Dinamis</h2><p>Pengguna dapat melakukan permintaan untuk penyediaan penyimpanan dinamis dengan
memasukkan StorageClass di dalam PersistentVolumeClaim. Sebelum Kubernetes v1.6,
ini dapat dilakukan melalui anotasi <code>volume.beta.kubernetes.io/storage-class</code>.
Hanya saja, anotasi ini sudah usang sejak v1.6. Pengguna sekarang dapat dan seharusnya
menggunakan <em>field</em> <code>storageClassName</code> dari objek PersistentVolumeClaim. Nilai
dari <em>field</em> ini haruslah sesuai dengan nama StorageClass yang dikonfigurasi oleh
admin (lihat bagian <a href=#enabling-dynamic-provisioning>di bawah</a>).</p><p>Untuk memilih StorageClass "fast", sebagai contoh, pengguna dapat membuat
PersistentVolumeClaim seperti ini:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>PersistentVolumeClaim<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>claim1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>accessModes</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- ReadWriteOnce<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>storageClassName</span>:<span style=color:#bbb> </span>fast<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>resources</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>requests</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>storage</span>:<span style=color:#bbb> </span>30Gi<span style=color:#bbb>
</span></span></span></code></pre></div><p>Klaim ini menghasilkan <em>persistent</em> disk SSD yang disediakan secara otomatis.
Ketika klaim dihilangkan, volume akan musnah.</p><h2 id=perilaku-default>Perilaku <em>Default</em></h2><p>Penyediaan dinamis dapat diaktifkan pada setiap klaster supaya semua klaim
dapat disediakan secara dinamis jika tidak ada StorageClass yang dispesifikasikan.
Seorang klaster admin dapat mengaktifkan perilaku ini dengan cara:</p><ul><li>Menandai satu objek StorageClass sebagai <em>default</em>;</li><li>Memastikan bahwa <a href=/docs/reference/access-authn-authz/admission-controllers/#defaultstorageclass><em>admission controller</em> <code>DefaultStorageClass</code></a>
telah aktif pada API server.</li></ul><p>Seorang admin dapat menandai StorageClass yang spesifik sebagai <em>default</em> dengan menambahkan
anotasi <code>storageclass.kubernetes.io/is-default-class</code>.
Ketika StorageClass default tersebut ada pada klaster dan pengguna membuat PersistentVolumeClaim
tanpa menspesifikasikan <code>storageClassName</code>, <em>admission controller</em> <code>DefaultStorageClass</code> secara
otomatis menambahkan <em>field</em> <code>storageClassName</code> dengan StorageClass <em>default</em>.</p><p>Perhatikan bahwa hanya bisa ada satu <em>default</em> StorageClass pada sebuah klaster,
atau PersistentVolumeClaim tanpa menspesifikasikan <code>storageClassName</code> secara eksplisit
tidak bisa terbuat.</p><h2 id=kesadaran-awareness-topologi>Kesadaran (<em>Awareness</em>) Topologi</h2><p>Pada klaster <a href=/docs/setup/multiple-zones>Multi-Zona</a>, Pod dapat tersebar di banyak Zona
pada sebuah Region. Penyimpanan dengan <em>backend</em> Zona-Tunggal seharusnya disediakan pada
Zona-Zona dimana Pod dijalankan. Hal ini dapat dicapai dengan mengatur
<a href=/id/docs/concepts/storage/storage-classes/#volume-binding-mode>Mode Volume Binding</a>.</p></div><div class=td-content style=page-break-before:always><h1 id=pg-b2e4b16ac37988c678a3312a4a6639f8>6.8 - Limit Volume yang Spesifik terhadap Node</h1><p>Laman ini menjelaskan soal jumlah volume maksimal yang dapat dihubungkan
ke sebuah Node untuk berbagai penyedia layanan cloud.</p><p>Penyedia layanan cloud seperti Google, Amazon, dan Microsoft pada umumnya memiliki
keterbatasan dalam jumlah volume yang bisa terhubung ke sebuah Node. Keterbatasn ini
sangatlah penting untuk diketahui Kubernetes dalam menentukan keputusan. Jika tidak,
Pod-pod yang telah dijadwalkan pada sebuah Node akan macet dan menunggu terus-menerus
untuk terhubung pada volume.</p><h2 id=limit-default-pada-kubernetes>Limit <em>default</em> pada Kubernetes</h2><p>Kubernetes <em>scheduler</em> memiliki limit <em>default</em> untuk jumlah volume
yang dapat terhubung pada sebuah Node:</p><table><tr><th>Penyedia layanan cloud</th><th>Jumlah volume maksimal per Node</th></tr><tr><td><a href=https://aws.amazon.com/ebs/>Amazon Elastic Block Store (EBS)</a></td><td>39</td></tr><tr><td><a href=https://cloud.google.com/persistent-disk/>Google Persistent Disk</a></td><td>16</td></tr><tr><td><a href=https://azure.microsoft.com/en-us/services/storage/main-disks/>Microsoft Azure Disk Storage</a></td><td>16</td></tr></table><h2 id=limit-custom>Limit <em>custom</em></h2><p>Kamu dapat mengganti limit-limit ini dengan mengkonfigurasi nilai dari
variabel <em>environment</em> <code>KUBE_MAX_PD_VOLS</code>, lalu menjalankan <em>scheduler</em>.</p><p>Berhati-hatilah jika kamu menerapkan limit yang lebih besar dari limit <em>default</em>.
Perhatikan dokumentasi penyedia layanan cloud untuk hal ini, dan pastikan Node
benar-benar dapat mendukung nilai limit yang kamu inginkan.</p><p>Limit ini diterapkan untuk seluruh klaster, jadi akan berdampak pada semua Node.</p><h2 id=limit-volume-dinamis>Limit volume dinamis</h2><div style=margin-top:10px;margin-bottom:10px><b>FEATURE STATE:</b> <code>Kubernetes v1.12 [beta]</code></div><p>Sebagai fitur Alpha, Kubernetes 1.11 memperkenalkan dukungan untuk limit volume yang dinamis berdasarkan tipe Node.
Pada Kubernettes 1.12, fitur ini telah mendapat promosi ke Beta dan akan diaktifkan secara <em>default</em>.</p><p>Limit volume dinamis mendukung tipe-tipe volume berikut:</p><ul><li>Amazon EBS</li><li>Google Persistent Disk</li><li>Azure Disk</li><li>CSI</li></ul><p>Ketika fitur limit volume dinamis diaktifkan, Kubernetes secara otomatis
menentukan tipe Node dan menerapkan jumlah volume dengan tepat, berapa yang bisa
terhubung Node. Sebagai contoh:</p><ul><li><p>Pada
<a href=https://cloud.google.com/compute/>Google Compute Engine</a>,
maskimal 128 jumlah volumes dapat terhubung pada sebuah node, <a href=https://cloud.google.com/compute/docs/disks/#pdnumberlimits>tergantung dari
tipe node</a>.</p></li><li><p>Untuk Amazon EBS disk pada tipe instans M5,C5,R5,T3 dan Z1D, Kubernetes hanya memperbolehkan 25
volume dapat terhubung pada sebuah Node. Untuk tipe instans lainnya pada
<a href=https://aws.amazon.com/ec2/>Amazon Elastic Compute Cloud (EC2)</a>,
Kubernetes memperbolehkan 39 jumlah volume dapat terhubung pada sebuah Node.</p></li><li><p>Pada Azure, maksimal 64 jumlah disk dapat terhubung pada suatu node, tergantung dari tipe node. Untuk perinciannya
bisa dilihat pada <a href=https://docs.microsoft.com/en-us/azure/virtual-machines/windows/sizes>Ukuran mesin virtual (VM) di Azure</a>.</p></li><li><p>Untuk CSI, driver manapun yang memberitahukan (<em>advertise</em>) limit volume terhubung melalui spek CSI akan memiliki limit tersebut yang disediakan
sebagai properti Node dan Scheduler tidak akan menjadwalkan Pod dengan volume pada Node manapun yang sudah penuh kapasitasnya. Untuk penjelasan lebih jauh
lihat <a href=https://github.com/container-storage-interface/spec/blob/master/spec.md#nodegetinfo>spek CSI</a>.</p></li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-275bea454e1cf4c5adeca4058b5af988>7 - Konfigurasi</h1></div><div class=td-content><h1 id=pg-ddef6fd0e47bb51c6f05e8e7fb11d2dd>7.1 - Konfigurasi dan Penerapan Konsep</h1><p>Dokumen ini menyoroti dan memperkuat pemahaman konsep konfigurasi yang dikenalkan di seluruh panduan pengguna, dokumentasi Memulai, dan contoh-contoh.</p><p>Dokumentasi ini terbuka. Jika Anda menemukan sesuatu yang tidak ada dalam daftar ini tetapi mungkin bermanfaat bagi orang lain, jangan ragu untuk mengajukan issue atau mengirimkan PR.</p><h2 id=tip-konfigurasi-secara-umum>Tip konfigurasi secara umum</h2><ul><li><p>Saat mendefinisikan konfigurasi, tentukan versi API stabil terbaru.</p></li><li><p>File konfigurasi harus disimpan dalam version control sebelum di push ke cluster. Ini memungkinkan Anda untuk dengan cepat mengembalikan perubahan konfigurasi jika perlu. Ini juga membantu penciptaan dan restorasi cluster.</p></li><li><p>Tulis file konfigurasi Anda menggunakan YAML tidak dengan JSON. Meskipun format ini dapat digunakan secara bergantian di hampir semua skenario, YAML cenderung lebih ramah pengguna.</p></li><li><p>Kelompokkan objek terkait ke dalam satu file yang memungkinkan. Satu file seringkali lebih mudah dikelola daripada beberapa file. Lihat pada <a href=https://github.com/kubernetes/examples/tree/master/guestbook/all-in-one/guestbook-all-in-one.yaml>guestbook-all-in-one.yaml</a> sebagai contoh file sintaks ini.</p></li><li><p>Perhatikan juga bahwa banyak perintah <code>kubectl</code> dapat dipanggil pada direktori. Misalnya, Anda dapat memanggil <code>kubectl apply</code> pada direktori file konfigurasi.</p></li><li><p>Jangan tentukan nilai default yang tidak perlu: sederhana, konfigurasi minimal akan membuat kesalahan lebih kecil.</p></li><li><p>Masukkan deskripsi objek dalam anotasi, untuk memungkinkan introspeksi yang lebih baik.</p></li></ul><h2 id=naked-pods-vs-replicasets-deployments-and-jobs>"Naked" Pods vs ReplicaSets, Deployments, and Jobs</h2><ul><li><p>Jangan gunakan Pods naked (artinya, Pods tidak terikat dengan a <a href=/id/docs/concepts/workloads/controllers/replicaset/>ReplicaSet</a> a <a href=/id/docs/concepts/workloads/controllers/deployment/>Deployment</a>) jika kamu bisa menghindarinya. Pod naked tidak akan dijadwal ulang jika terjadi kegagalan pada node.</p><p>Deployment, yang keduanya menciptakan ReplicaSet untuk memastikan bahwa jumlah Pod yang diinginkan selalu tersedia, dan menentukan strategi untuk mengganti Pods (seperti <a href=/id/docs/concepts/workloads/controllers/deployment/#rolling-update-deployment>RollingUpdate</a>), hampir selalu lebih disukai daripada membuat Pods secara langsung, kecuali untuk beberapa yang eksplisit <a href=/id/docs/concepts/workloads/pods/pod-lifecycle/#restart-policy><code>restartPolicy: Never</code></a> banyak skenario . A <a href=/id/docs/concepts/workloads/controllers/job/>Job</a> mungkin juga sesuai.</p></li></ul><h2 id=services>Services</h2><ul><li><p>Buat <a href=/id/docs/concepts/services-networking/service/>Service</a> sebelum workloads backend terkait (Penyebaran atau ReplicaSets), dan sebelum workloads apa pun yang perlu mengaksesnya. Ketika Kubernetes memulai sebuah container, ia menyediakan environment variabel yang menunjuk ke semua Layanan yang berjalan ketika container itu dimulai. Misalnya, jika Layanan bernama <code>foo</code> ada, semua container akan mendapatkan variabel berikut di environment awalnya:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span><span style=color:#b8860b>FOO_SERVICE_HOST</span><span style=color:#666>=</span>&lt;the host the Service is running on&gt;
</span></span><span style=display:flex><span><span style=color:#b8860b>FOO_SERVICE_PORT</span><span style=color:#666>=</span>&lt;the port the Service is running on&gt;
</span></span></code></pre></div><p>*Ini menunjukan persyaratan pemesanan * - <code>Service</code> apa pun yang ingin diakses oleh <code>Pod</code> harus dibuat sebelum <code>Pod</code> itu sendiri, atau environment variabel tidak akan diisi. DNS tidak memiliki batasan ini.</p></li><li><p>Opsional (meskipun sangat disarankan) <a href=/id/docs/concepts/cluster-administration/addons/>cluster add-on</a> adalah server DNS.
Server DNS melihat API Kubernetes untuk <code>Service</code> baru dan membuat satu set catatan DNS untuk masing-masing. Jika DNS telah diaktifkan di seluruh cluster maka semua <code>Pods</code> harus dapat melakukan resolusi nama<code>Service</code> secara otomatis.</p></li><li><p>Jangan tentukan <code>hostPort</code> untuk Pod kecuali jika benar-benar diperlukan. Ketika Anda bind Pod ke <code>hostPort</code>, hal itu membatasi jumlah tempat Pod dapat dijadwalkan, karena setiap kombinasi &lt;<code>hostIP</code>, <code>hostPort</code>, <code>protokol</code>> harus unik. Jika Anda tidak menentukan <code>hostIP</code> dan <code>protokol</code> secara eksplisit, Kubernetes akan menggunakan <code>0.0.0.0</code> sebagai <code>hostIP</code> dan <code>TCP</code> sebagai default <code>protokol</code>.</p><p>Jika kamu hanya perlu akses ke port untuk keperluan debugging, Anda bisa menggunakan <a href=/id/docs/tasks/access-application-cluster/access-cluster/#manually-constructing-apiserver-proxy-urls>apiserver proxy</a> atau <a href=/id/docs/tasks/access-application-cluster/port-forward-access-application-cluster/><code>kubectl port-forward</code></a>.</p><p>Jika Anda secara eksplisit perlu mengekspos port Pod pada node, pertimbangkan untuk menggunakan <a href=/id/docs/concepts/services-networking/service/#nodeport>NodePort</a> Service sebelum beralih ke <code>hostPort</code>.</p></li><li><p>Hindari menggunakan <code>hostNetwork</code>, untuk alasan yang sama seperti <code>hostPort</code>.</p></li><li><p>Gunakan [headless Services](/id/docs/concepts/services-networking/service/#headless-
services) (yang memiliki <code>ClusterIP</code> dari <code>None</code>) untuk Service discovery yang mudah ketika Anda tidak membutuhkan <code>kube-proxy</code> load balancing.</p></li></ul><h2 id=menggunakan-label>Menggunakan label</h2><ul><li>Deklarasi dan gunakan [labels] (/id/docs/concepts/overview/working-with-objects/labels/) untuk identifikasi <strong>semantic attributes</strong> aplikasi atau Deployment kamu, seperti <code>{ app: myapp, tier: frontend, phase: test, deployment: v3 }</code>. Kamu dapat menggunakan label ini untuk memilih Pod yang sesuai untuk sumber daya lainnya; misalnya, Service yang memilih semua <code>tier: frontend</code> Pods, atau semua komponen <code>phase: test</code> dari <code>app: myapp</code>. Lihat <a href=https://github.com/kubernetes/examples/tree/main/guestbook/>guestbook</a> aplikasi untuk contoh-contoh pendekatan ini.</li></ul><p>Service dapat dibuat untuk menjangkau beberapa Penyebaran dengan menghilangkan label khusus rilis dari pemilihnya. <a href=/id/docs/concepts/workloads/controllers/deployment/>Deployments</a> membuatnya mudah untuk memperbarui Service yang sedang berjalan tanpa downtime.</p><p>Keadaan objek yang diinginkan dideskripsikan oleh Deployment, dan jika perubahan terhadap spesifikasi tersebut adalah <em>applied</em>, Deployment controller mengubah keadaan aktual ke keadaan yang diinginkan pada tingkat yang terkontrol.</p><ul><li>Kamu dapat memanipulasi label untuk debugging. Karena Kubernetes controller (seperti ReplicaSet) dan Service Match dengan Pods menggunakan label pemilih, menghapus label yang relevan dari Pod akan menghentikannya dari dianggap oleh Controller atau dari lalu lintas yang dilayani oleh Service. Jika Anda menghapus label dari Pod yang ada, Controller akan membuat Pod baru untuk menggantikannya. Ini adalah cara yang berguna untuk men-debug Pod yang sebelumnya "live" di Environment "quarantine". Untuk menghapus atau menambahkan label secara interaktif, gunakan <a href=/docs/reference/generated/kubectl/kubectl-commands#label><code>kubectl label</code></a>.</li></ul><h2 id=container-images>Container Images</h2><p>Ini <a href=/id/docs/concepts/containers/images/#updating-images>imagePullPolicy</a> dan tag dari image mempengaruhi ketika <a href=/docs/admin/kubelet/>kubelet</a> mencoba menarik image yang ditentukan</p><ul><li><p><code>imagePullPolicy: IfNotPresent</code>: image ditarik hanya jika belum ada secara lokal.</p></li><li><p><code>imagePullPolicy: Always</code>: Image ditarik setiap kali pod dimulai.</p></li><li><p><code>imagePullPolicy</code> dihilangkan dan tag imagenya adalah <code>:latest</code> atau dihilangkan:<code>always</code> diterapkan.</p></li><li><p><code>imagePullPolicy</code> dihilangkan dan tag image ada tetapi tidak <code>:latest</code>:<code> IfNotPresent</code> diterapkan.</p></li><li><p><code>imagePullPolicy: Never</code>: image diasumsikan ada secara lokal. Tidak ada upaya yang dilakukan untuk menarik image.</p></li></ul><div class="alert alert-info note callout" role=alert><strong>Catatan:</strong> Untuk memastikan container selalu menggunakan versi image yang sama, Anda bisa menentukannya <a href=https://docs.docker.com/engine/reference/commandline/pull/#pull-an-image-by-digest-immutable-identifier>digest</a>, untuk contoh <code>sha256:45b23dee08af5e43a7fea6c4cf9c25ccf269ee113168c19722f87876677c5cb2</code>. digest mengidentifikasi secara unik versi image tertentu, sehingga tidak pernah diperbarui oleh Kubernetes kecuali Anda mengubah nilai digest.</div><div class="alert alert-info note callout" role=alert><strong>Catatan:</strong> Anda harus menghindari penggunaan tag <code>: latest</code> saat menempatkan container dalam produksi karena lebih sulit untuk melacak versi image mana yang sedang berjalan dan lebih sulit untuk memutar kembali dengan benar.</div><div class="alert alert-info note callout" role=alert><strong>Catatan:</strong> Semantik caching dari penyedia gambar yang mendasarinya membuat bahkan <code>imagePullPolicy: Always</code> efisien. Dengan Docker, misalnya, jika image sudah ada, upaya pull cepat karena semua lapisan image di-cache dan tidak perlu mengunduh image.</div><h2 id=menggunakan-kubectl>Menggunakan kubectl</h2><ul><li><p>Gunakan <code>kubectl apply -f &lt;directory></code>. Ini mencari konfigurasi Kubernetes di semua file <code>.yaml</code>, <code>.yml</code>, dan <code>.json</code> di <code>&lt;directory></code> dan meneruskannya ke <code>apply</code>.</p></li><li><p>Gunakan label selector untuk operasi <code>get</code> dan <code>delete</code> alih-alih nama objek tertentu. Lihat bagian di <a href=/id/docs/concepts/overview/working-with-objects/labels/#label-selectors>label selectors</a> dan <a href=/id/docs/concepts/cluster-administration/manage-deployment/#using-labels-effectively>using labels effectively</a>.</p></li><li><p>Gunakan <code>kubectl run</code> dan <code>kubectl expose</code> untuk dengan cepat membuat Deployment dan Service single-container. Lihat <a href=/docs/tasks/access-application-cluster/service-access-application-cluster/>Use a Service to Access an Application in a Cluster</a> untuk Contoh.</p></li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-4c9401ed6b037e1adb958cbce20630c7>7.2 - Mengatur Sumber Daya Komputasi untuk Container</h1><p>Saat kamu membuat spesifikasi sebuah <a href=/id/docs/concepts/workloads/pods/pod/>Pod</a>, kamu
dapat secara opsional menentukan seberapa banyak CPU dan memori (RAM) yang dibutuhkan
oleh setiap Container. Saat Container-Container menentukan <em>request</em> (permintaan) sumber daya,
scheduler dapat membuat keputusan yang lebih baik mengenai Node mana yang akan dipilih
untuk menaruh Pod-Pod. Dan saat limit (batas) sumber daya Container-Container telah ditentukan,
maka kemungkinan rebutan sumber daya pada sebuah Node dapat dihindari.
Untuk informasi lebih lanjut mengenai perbedaan <code>request</code> dan <code>limit</code>, lihat <a href=https://git.k8s.io/community/contributors/design-proposals/node/resource-qos.md>QoS Sumber Daya</a>.</p><h2 id=jenis-jenis-sumber-daya>Jenis-jenis sumber daya</h2><p><em>CPU</em> dan <em>memori</em> masing-masing merupakan <em>jenis sumber daya</em> (<em>resource type</em>).
Sebuah jenis sumber daya memiliki satuan dasar. CPU ditentukan dalam satuan jumlah <em>core</em>,
dan memori ditentukan dalam satuan <em>bytes</em>. Jika kamu menggunakan Kubernetes v1.14 keatas,
kamu dapat menentukan sumber daya <em>huge page</em>. <em>Huge page</em> adalah fitur khusus Linux
di mana kernel Node mengalokasikan blok-blok memori yang jauh lebih besar daripada ukuran
<em>page</em> bawaannya.</p><p>Sebagai contoh, pada sebuah sistem di mana ukuran <em>page</em> bawaannya adalah 4KiB, kamu
dapat menentukan sebuah limit, <code>hugepages-2Mi: 80Mi</code>. Jika kontainer mencoba mengalokasikan
lebih dari 40 <em>huge page</em> berukuran 20MiB (total 80MiB), maka alokasi tersebut akan gagal.</p><div class="alert alert-info note callout" role=alert><strong>Catatan:</strong> Kamu tidak dapat melakukan <em>overcommit</em> terhadap sumber daya <code>hugepages-*</code>.
Hal ini berbeda dari sumber daya <code>memory</code> dan <code>cpu</code> (yang dapat di-<em>overcommit</em>).</div><p>CPU dan memori secara kolektif disebut sebagai <em>sumber daya komputasi</em>, atau cukup
<em>sumber daya</em> saja. Sumber daya komputasi adalah jumlah yang dapat diminta, dialokasikan,
dan dikonsumsi. Mereka berbeda dengan <a href=/id/docs/concepts/overview/kubernetes-api/>sumber daya API</a>.
Sumber daya API, seperti Pod dan <a href=/id/docs/concepts/services-networking/service/>Service</a> adalah
objek-objek yang dapat dibaca dan diubah melalui Kubernetes API Server.</p><h2 id=request-dan-limit-sumber-daya-dari-pod-dan-container>Request dan Limit Sumber daya dari Pod dan Container</h2><p>Setiap Container dari sebuah Pod dapat menentukan satu atau lebih dari hal-hal berikut:</p><ul><li><code>spec.containers[].resources.limits.cpu</code></li><li><code>spec.containers[].resources.limits.memory</code></li><li><code>spec.containers[].resources.limits.hugepages-&lt;size></code></li><li><code>spec.containers[].resources.requests.cpu</code></li><li><code>spec.containers[].resources.requests.memory</code></li><li><code>spec.containers[].resources.requests.hugepages-&lt;size></code></li></ul><p>Walaupun <code>requests</code> dan <code>limits</code> hanya dapat ditentukan pada Container individual, akan
lebih mudah untuk membahas tentang request dan limit sumber daya dari Pod. Sebuah
<em>request/limit sumber daya Pod</em> untuk jenis sumber daya tertentu adalah jumlah dari
request/limit sumber daya pada jenis tersebut untuk semua Container di dalam Pod tersebut.</p><h2 id=arti-dari-cpu>Arti dari CPU</h2><p>Limit dan request untuk sumber daya CPU diukur dalam satuan <em>cpu</em>.
Satu cpu, dalam Kubernetes, adalah sama dengan:</p><ul><li>1 vCPU AWS</li><li>1 Core GCP</li><li>1 vCore Azure</li><li>1 vCPU IBM</li><li>1 <em>Hyperthread</em> pada sebuah prosesor Intel <em>bare-metal</em> dengan Hyperthreading</li></ul><p>Request dalam bentuk pecahan diizinkan. Sebuah Container dengan
<code>spec.containers[].resources.requests.cpu</code> bernilai <code>0.5</code> dijamin mendapat
setengah CPU dibandingkan dengan yang meminta 1 CPU. Ekspresi nilai <code>0.1</code> ekuivalen
dengan ekspresi nilai <code>100m</code>, yang dapat dibaca sebagai "seratus milicpu". Beberapa
orang juga membacanya dengan "seratus milicore", dan keduanya ini dimengerti sebagai
hal yang sama. Sebuah request dengan angka di belakang koma, seperti <code>0.1</code> dikonversi
menjadi <code>100m</code> oleh API, dan presisi yang lebih kecil lagi dari <code>1m</code> tidak dibolehkan.
Untuk alasan ini, bentuk <code>100m</code> mungkin lebih disukai.</p><p>CPU juga selalu diminta dalam jumlah yang mutlak, tidak sebagai jumlah yang relatif;
0.1 adalah jumlah CPU yang sama pada sebuah mesin <em>single-core</em>, <em>dual-core</em>, atau
<em>48-core</em>.</p><h2 id=arti-dari-memori>Arti dari Memori</h2><p>Limit dan request untuk <code>memory</code> diukur dalam satuan <em>bytes</em>. Kamu dapat mengekspresikan
memori sebagai <em>plain integer</em> atau sebagai sebuah <em>fixed-point integer</em> menggunakan
satu dari sufiks-sufiks berikut: E, P, T, G, M, K. Kamu juga dapat menggunakan bentuk
pangkat dua ekuivalennya: Ei, Pi, Ti, Gi, Mi, Ki.
Sebagai contoh, nilai-nilai berikut kurang lebih sama:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>128974848, 129e6, 129M, 123Mi
</span></span></code></pre></div><p>Berikut sebuah contoh.
Pod berikut memiliki dua Container. Setiap Container memiliki request 0.25 cpu dan
64MiB (2<sup>26</sup> bytes) memori. Setiap Container memiliki limit 0.5 cpu dan
128MiB memori. Kamu dapat berkata bahwa Pod tersebut memiliki request 0.5 cpu dan
128MiB memori, dan memiliki limit 1 cpu dan 265MiB memori.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>frontend<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>db<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>mysql<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>env</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>MYSQL_ROOT_PASSWORD<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>value</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;password&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>resources</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>requests</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>memory</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;64Mi&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>cpu</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;250m&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>limits</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>memory</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;128Mi&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>cpu</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;500m&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>wp<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>wordpress<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>resources</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>requests</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>memory</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;64Mi&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>cpu</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;250m&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>limits</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>memory</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;128Mi&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>cpu</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;500m&#34;</span><span style=color:#bbb>
</span></span></span></code></pre></div><h2 id=bagaimana-pod-pod-dengan-request-sumber-daya-dijadwalkan>Bagaimana Pod-Pod dengan request sumber daya dijadwalkan</h2><p>Saat kamu membuat sebuah Pod, Kubernetes scheduler akan memilih sebuah Node
untuk Pod tersebut untuk dijalankan. Setiap Node memiliki kapasitas maksimum
untuk setiap jenis sumber daya: jumlah CPU dan memori yang dapat disediakan
oleh Node tersebut untuk Pod-Pod. Scheduler memastikan bahwa, untuk setiap
jenis sumber daya, jumlah semua request sumber daya dari Container-Container
yang dijadwalkan lebih kecil dari kapasitas Node tersebut. Perlu dicatat
bahwa walaupun penggunaan sumber daya memori atau CPU aktual/sesungguhnya pada
Node-Node sangat rendah, scheduler tetap akan menolak untuk menaruh sebuah
Pod pada sebuah Node jika pemeriksaan kapasitasnya gagal. Hal ini adalah untuk
menjaga dari kekurangan sumber daya pada sebuah Node saat penggunaan sumber daya
meningkat suatu waktu, misalnya pada saat titik puncak <em>traffic</em> harian.</p><h2 id=bagaimana-pod-pod-dengan-limit-sumber-daya-dijalankan>Bagaimana Pod-Pod dengan limit sumber daya dijalankan</h2><p>Saat Kubelet menjalankan sebuah Container dari sebuah Pod, Kubelet tersebut
mengoper limit CPU dan memori ke <em>runtime</em> kontainer.</p><p>Ketika menggunakan Docker:</p><ul><li><p><code>spec.containers[].resources.requests.cpu</code> diubah menjadi nilai <em>core</em>-nya,
yang mungkin berbentuk angka pecahan, dan dikalikan dengan 1024. Nilai yang
lebih besar antara angka ini atau 2 digunakan sebagai nilai dari <em>flag</em>
<a href=https://docs.docker.com/engine/reference/run/#cpu-share-constraint><code>--cpu-shares</code></a>
pada perintah <code>docker run</code>.</p></li><li><p><code>spec.containers[].resources.limits.cpu</code> diubah menjadi nilai <em>millicore</em>-nya dan
dikalikan dengan 100. Nilai hasilnya adalah jumlah waktu CPU yang dapat digunakan oleh
sebuah kontainer setiap 100 milidetik. Sebuah kontainer tidak dapat menggunakan lebih
dari jatah waktu CPU-nya selama selang waktu ini.</p><div class="alert alert-info note callout" role=alert><strong>Catatan:</strong> Periode kuota bawaan adalah 100ms. Resolusi minimum dari kuota CPU adalah 1 milidetik.</div></li><li><p><code>spec.containers[].resources.limits.memory</code> diubah menjadi sebuah bilangan bulat, dan
digunakan sebagai nilai dari <em>flag</em> <a href=https://docs.docker.com/engine/reference/run/#/user-memory-constraints><code>--memory</code></a>
dari perintah <code>docker run</code>.</p></li></ul><p>Jika sebuah Container melebihi batas memorinya, Container tersebut mungkin akan diterminasi.
Jika Container tersebut dapat diulang kembali, Kubelet akan mengulangnya kembali, sama
seperti jenis kegagalan lainnya.</p><p>Jika sebuah Container melebihi request memorinya, kemungkinan Pod-nya akan dipindahkan
kapanpun Node tersebut kehabisan memori.</p><p>Sebuah Container mungkin atau mungkin tidak diizinkan untuk melebihi limit CPU-nya
untuk periode waktu yang lama. Tetapi, Container tersebut tidak akan diterminasi karena
penggunaan CPU yang berlebihan.</p><p>Untuk menentukan apabila sebuah Container tidak dapat dijadwalkan atau sedang diterminasi
karena limit sumber dayanya, lihat bagian <a href=#penyelesaian-masalah>Penyelesaian Masalah</a>.</p><h2 id=memantau-penggunaan-sumber-daya-komputasi>Memantau penggunaan sumber daya komputasi</h2><p>Penggunaan sumber daya dari sebuah Pod dilaporkan sebagai bagian dari kondisi Pod.</p><p>Jika <a href=http://releases.k8s.io/main/cluster/addons/cluster-monitoring/README.md><em>monitoring</em> opsional</a> diaktifkan pada klaster kamu, maka penggunaan sumber daya Pod dapat diambil
dari sistem <em>monitoring</em> kamu.</p><h2 id=penyelesaian-masalah>Penyelesaian Masalah</h2><h3 id=pod-pod-saya-berkondisi-pending-tertunda-dengan-event-message-failedscheduling>Pod-Pod saya berkondisi Pending (tertunda) dengan <em>event message</em> failedScheduling</h3><p>Jika scheduler tidak dapat menemukan Node manapun yang muat untuk sebuah Pod,
Pod tersebut tidak akan dijadwalkan hingga ditemukannya sebuah tempat yang
muat. Sebuah <em>event</em> akan muncul setiap kali scheduler gagal menemukan tempat
untuk Pod tersebut, seperti berikut:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl describe pod frontend | grep -A <span style=color:#666>3</span> Events
</span></span></code></pre></div><pre tabindex=0><code>Events:
  FirstSeen LastSeen   Count  From          Subobject   PathReason      Message
  36s   5s     6      {scheduler }              FailedScheduling  Failed for reason PodExceedsFreeCPU and possibly others
</code></pre><p>Pada contoh di atas, Pod bernama "frontend" gagal dijadwalkan karena kekurangan
sumber daya CPU pada Node tersebut. Pesan kesalahan yang serupa dapat juga menunjukkan
kegagalan karena kekurangan memori (PodExceedsFreeMemroy). Secara umum, jika sebuah
Pod berkondisi Pending (tertunda) dengan sebuah pesan seperti ini, ada beberapa hal yang
dapat dicoba:</p><ul><li>Tambah lebih banyak Node pada klaster.</li><li>Terminasi Pod-Pod yang tidak dibutuhkan untuk memberikan ruangan untuk Pod-Pod yang
tertunda.</li><li>Periksa jika nilai request Pod tersebut tidak lebih besar dari Node-node yang ada.
Contohnya, jika semua Node memiliki kapasitas <code>cpu: 1</code>, maka Pod dengan request
<code>cpu: 1.1</code> tidak akan pernah dijadwalkan.</li></ul><p>Kamu dapat memeriksa kapasitas Node-Node dan jumlah-jumlah yang telah dialokasikan
dengan perintah <code>kubectl describe nodes</code>. Contohnya:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl describe nodes e2e-test-node-pool-4lw4
</span></span></code></pre></div><pre tabindex=0><code>Name:            e2e-test-node-pool-4lw4
[ ... lines removed for clarity ...]
Capacity:
 cpu:                               2
 memory:                            7679792Ki
 pods:                              110
Allocatable:
 cpu:                               1800m
 memory:                            7474992Ki
 pods:                              110
[ ... beberapa baris dihapus untuk kejelasan ...]
Non-terminated Pods:        (5 in total)
  Namespace    Name                                  CPU Requests  CPU Limits  Memory Requests  Memory Limits
  ---------    ----                                  ------------  ----------  ---------------  -------------
  kube-system  fluentd-gcp-v1.38-28bv1               100m (5%)     0 (0%)      200Mi (2%)       200Mi (2%)
  kube-system  kube-dns-3297075139-61lj3             260m (13%)    0 (0%)      100Mi (1%)       170Mi (2%)
  kube-system  kube-proxy-e2e-test-...               100m (5%)     0 (0%)      0 (0%)           0 (0%)
  kube-system  monitoring-influxdb-grafana-v4-z1m12  200m (10%)    200m (10%)  600Mi (8%)       600Mi (8%)
  kube-system  node-problem-detector-v0.1-fj7m3      20m (1%)      200m (10%)  20Mi (0%)        100Mi (1%)
Allocated resources:
  (Total limit mungkin melebihi 100 persen, misalnya, karena _overcommit_.)
  CPU Requests    CPU Limits    Memory Requests    Memory Limits
  ------------    ----------    ---------------    -------------
  680m (34%)      400m (20%)    920Mi (12%)        1070Mi (14%)
</code></pre><p>Pada keluaran di atas, kamu dapat melihat bahwa jika sebuah Pod meminta lebih dari
1120m CPU atau 6.23Gi memori, Pod tersebut tidak akan muat pada Node tersebut.</p><p>Dengan melihat pada bagian <code>Pods</code>, kamu dapat melihat Pod-Pod mana saja yang memakan
sumber daya pada Node tersebut.
Jumlah sumber daya yang tersedia untuk Pod-Pod kurang dari kapasitas Node, karena
<em>daemon</em> sistem menggunakan sebagian dari sumber daya yang ada. Kolom <code>allocatable</code> pada
<a href=/docs/reference/generated/kubernetes-api/v1.25/#nodestatus-v1-core>NodeStatus</a>
memberikan jumlah sumber daya yang tersedia untuk Pod-Pod. Untuk lebih lanjut, lihat
<a href=https://git.k8s.io/community/contributors/design-proposals/node/node-allocatable.md>Sumber daya Node yang dapat dialokasikan</a>.</p><p>Fitur <a href=/id/docs/concepts/policy/resource-quotas/>kuota sumber daya</a> dapat disetel untuk
membatasi jumlah sumber daya yang dapat digunakan. Jika dipakai bersama dengan Namespace,
kuota sumber daya dapat mencegah suatu tim menghabiskan semua sumber daya.</p><h3 id=container-saya-diterminasi>Container saya diterminasi</h3><p>Container kamu mungkin diterminasi karena Container tersebut melebihi batasnya. Untuk
memeriksa jika sebuah Container diterminasi karena ia melebihi batas sumber dayanya,
gunakan perintah <code>kubectl describe pod</code> pada Pod yang bersangkutan:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl describe pod simmemleak-hra99
</span></span></code></pre></div><pre tabindex=0><code>Name:                           simmemleak-hra99
Namespace:                      default
Image(s):                       saadali/simmemleak
Node:                           kubernetes-node-tf0f/10.240.216.66
Labels:                         name=simmemleak
Status:                         Running
Reason:
Message:
IP:                             10.244.2.75
Replication Controllers:        simmemleak (1/1 replicas created)
Containers:
  simmemleak:
    Image:  saadali/simmemleak
    Limits:
      cpu:                      100m
      memory:                   50Mi
    State:                      Running
      Started:                  Tue, 07 Jul 2015 12:54:41 -0700
    Last Termination State:     Terminated
      Exit Code:                1
      Started:                  Fri, 07 Jul 2015 12:54:30 -0700
      Finished:                 Fri, 07 Jul 2015 12:54:33 -0700
    Ready:                      False
    Restart Count:              5
Conditions:
  Type      Status
  Ready     False
Events:
  FirstSeen                         LastSeen                         Count  From                              SubobjectPath                       Reason      Message
  Tue, 07 Jul 2015 12:53:51 -0700   Tue, 07 Jul 2015 12:53:51 -0700  1      {scheduler }                                                          scheduled   Successfully assigned simmemleak-hra99 to kubernetes-node-tf0f
  Tue, 07 Jul 2015 12:53:51 -0700   Tue, 07 Jul 2015 12:53:51 -0700  1      {kubelet kubernetes-node-tf0f}    implicitly required container POD   pulled      Pod container image &#34;k8s.gcr.io/pause:0.8.0&#34; already present on machine
  Tue, 07 Jul 2015 12:53:51 -0700   Tue, 07 Jul 2015 12:53:51 -0700  1      {kubelet kubernetes-node-tf0f}    implicitly required container POD   created     Created with docker id 6a41280f516d
  Tue, 07 Jul 2015 12:53:51 -0700   Tue, 07 Jul 2015 12:53:51 -0700  1      {kubelet kubernetes-node-tf0f}    implicitly required container POD   started     Started with docker id 6a41280f516d
  Tue, 07 Jul 2015 12:53:51 -0700   Tue, 07 Jul 2015 12:53:51 -0700  1      {kubelet kubernetes-node-tf0f}    spec.containers{simmemleak}         created     Created with docker id 87348f12526a
</code></pre><p>Pada contoh di atas, <code>Restart Count: 5</code> menunjukkan bahwa Container <code>simmemleak</code>
pada Pod tersebut diterminasi dan diulang kembali sebanyak lima kali.</p><p>Kamu dapat menggunakan perintah <code>kubectl get pod</code> dengan opsi <code>-o go-template=...</code> untuk
mengambil kondisi dari Container-Container yang sebelumnya diterminasi:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get pod -o go-template<span style=color:#666>=</span><span style=color:#b44>&#39;{{range.status.containerStatuses}}{{&#34;Container Name: &#34;}}{{.name}}{{&#34;\r\nLastState: &#34;}}{{.lastState}}{{end}}&#39;</span>  simmemleak-hra99
</span></span></code></pre></div><pre tabindex=0><code>Container Name: simmemleak
LastState: map[terminated:map[exitCode:137 reason:OOM Killed startedAt:2015-07-07T20:58:43Z finishedAt:2015-07-07T20:58:43Z containerID:docker://0e4095bba1feccdfe7ef9fb6ebffe972b4b14285d5acdec6f0d3ae8a22fad8b2]]
</code></pre><p>Kamu dapat lihat bahwa Container tersebut diterminasi karena <code>reason:OOM Killed</code>, di mana
<code>OOM</code> merupakan singkatan dari <em>Out Of Memory</em>, atau kehabisan memori.</p><h2 id=penyimpanan-lokal-sementara>Penyimpanan lokal sementara</h2><div style=margin-top:10px;margin-bottom:10px><b>FEATURE STATE:</b> <code>Kubernetes v1.25 [beta]</code></div><p>Kubernetes versi 1.8 memperkenalkan sebuah sumber daya baru, <em>ephemeral-storage</em> untuk mengatur penyimpanan lokal yang bersifat sementara. Pada setiap Node Kubernetes, direktori <em>root</em> dari Kubelet (secara bawaan /var/lib/kubelet) dan direktori log (/var/log) ditaruh pada partisi <em>root</em> dari Node tersebut. Partisi ini juga digunakan bersama oleh Pod-Pod melalui volume emptyDir, log kontainer, lapisan <em>image</em>, dan lapisan kontainer yang dapat ditulis.</p><p>Partisi ini bersifat "sementara" dan aplikasi-aplikasi tidak dapat mengharapkan SLA kinerja (misalnya <em>Disk IOPS</em>) dari partisi ini. Pengelolaan penyimpanan lokal sementara hanya berlaku untuk partisi <em>root</em>; partisi opsional untuk lapisan <em>image</em> dan lapisan yang dapat ditulis berada di luar ruang lingkup.</p><div class="alert alert-info note callout" role=alert><strong>Catatan:</strong> Jika sebuah partisi <em>runtime</em> opsional digunakan, partisi <em>root</em> tidak akan menyimpan lapisan <em>image</em> ataupun lapisan yang dapat ditulis manapun.</div><h3 id=menyetel-request-dan-limit-dari-penyimpanan-lokal-sementara>Menyetel request dan limit dari penyimpanan lokal sementara</h3><p>Setiap Container dari sebuah Pod dapat menentukan satu atau lebih dari hal-hal berikut:</p><ul><li><code>spec.containers[].resources.limits.ephemeral-storage</code></li><li><code>spec.containers[].resources.requests.ephemeral-storage</code></li></ul><p>Limit dan request untuk <code>ephemeral-storage</code> diukur dalam satuan <em>bytes</em>. Kamu dapat menyatakan
penyimpanan dalam bilangan bulat biasa, atau sebagai <em>fixed-point integer</em> menggunakan satu dari
sufiks-sufiks ini: E, P, T, G, M, K. Kamu jika dapat menggunakan bentuk pangkat dua ekuivalennya:
Ei, Pi, Ti, Gi, Mi, Ki. Contohnya, nilai-nilai berikut kurang lebih sama:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>128974848, 129e6, 129M, 123Mi
</span></span></code></pre></div><p>Contohnya, Pod berikut memiliki dua Container. Setiap Container memiliki request 2GiB untuk penyimpanan lokal sementara. Setiap Container memiliki limit 4GiB untuk penyimpanan lokal sementara. Maka, Pod tersebut memiliki jumlah request 4GiB penyimpanan lokal sementara, dan limit 8GiB.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>frontend<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>db<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>mysql<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>env</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>MYSQL_ROOT_PASSWORD<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>value</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;password&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>resources</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>requests</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>ephemeral-storage</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;2Gi&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>limits</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>ephemeral-storage</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;4Gi&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>wp<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>wordpress<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>resources</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>requests</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>ephemeral-storage</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;2Gi&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>limits</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>ephemeral-storage</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;4Gi&#34;</span><span style=color:#bbb>
</span></span></span></code></pre></div><h3 id=bagaimana-pod-pod-dengan-request-ephemeral-storage-dijadwalkan>Bagaimana Pod-Pod dengan request ephemeral-storage dijadwalkan</h3><p>Saat kamu membuat sebuah Pod, Kubernetes scheduler memilih sebuah Node di mana Pod
tersebut akan dijalankan. Setiap Node memiliki jumlah maksimum penyimpanan lokal sementara yang dapat disediakan.
Untuk lebih lanjut, lihat <a href=/docs/tasks/administer-cluster/reserve-compute-resources/#node-allocatable>"Hal-hal yang dapat dialokasikan Node"</a>.</p><p>Scheduler memastikan bahwa jumlah dari request-request sumber daya dari Container-Container yang dijadwalkan lebih kecil dari kapasitas Node.</p><h3 id=bagaimana-pod-pod-dengan-limit-ephemeral-storage-dijalankan>Bagaimana Pod-Pod dengan limit ephemeral-storage dijalankan</h3><p>Untuk isolasi pada tingkat kontainer, jika lapisan yang dapat ditulis dari sebuah Container dan penggunaan log melebihi limit penyimpanannya, maka Pod tersebut akan dipindahkan. Untuk isolasi pada tingkat Pod, jika jumlah dari penyimpanan lokal sementara dari semua Container dan juga volume emptyDir milik Pod melebihi limit, maka Pod teresebut akan dipindahkan.</p><h3 id=memantau-penggunaan-ephemeral-storage>Memantau penggunaan ephemeral-storage</h3><p>Saat penyimpanan lokal sementara digunakan, ia dipantau terus-menerus
oleh Kubelet. Pemantauan dilakukan dengan cara memindai setiap volume
emptyDir, direktori log, dan lapisan yang dapat ditulis secara periodik.
Dimulai dari Kubernetes 1.15, volume emptyDir (tetapi tidak direktori log
atau lapisan yang dapat ditulis) dapat, sebagai pilihan dari operator
klaster, dikelola dengan menggunakan <a href=http://xfs.org/docs/xfsdocs-xml-dev/XFS_User_Guide/tmp/en-US/html/xfs-quotas.html><em>project quotas</em></a>.
<em>Project quotas</em> aslinya diimplementasikan dalam XFS, dan baru-baru ini
telah diubah ke ext4fs. <em>Project quotas</em> dapat digunakan baik untuk
<em>monitoring</em> dan pemaksaan; sejak Kubernetes 1.16, mereka tersedia sebagai
fitur <em>alpha</em> untuk <em>monitoring</em> saja.</p><p><em>Quota</em> lebih cepat dan akurat dibandingkan pemindaian direktori. Saat
sebuah direktori ditentukan untuk sebuah proyek, semua berkas yang dibuat
pada direktori tersebut dibuat untuk proyek tersebut, dan kernel hanya
perlu melacak berapa banyak blok yang digunakan oleh berkas-berkas pada
proyek tersebut. Jika sebuah berkas dibuat dan dihapus, tetapi tetap dengan
sebuah <em>file descriptor</em> yang terbuka, maka berkas tersebut tetap akan
memakan ruangan penyimpanan. Ruangan ini akan dilacak oleh <em>quota</em> tersebut,
tetapi tidak akan terlihat oleh sebuah pemindaian direktori.</p><p>Kubernetes menggunakan ID proyek yang dimulai dari 1048576. ID-ID yang
digunakan akan didaftarkan di dalam <code>/etc/projects</code> dan <code>/etc/projid</code>.
Jika ID-ID proyek pada kisaran ini digunakan untuk tujuan lain pada sistem,
ID-ID proyek tersebut harus terdaftar di dalam <code>/etc/projects</code> dan <code>/etc/projid</code>
untuk mencegah Kubernetes menggunakan ID-ID tersebut.</p><p>Untuk mengaktifkan penggunaan <em>project quotas</em>, operator klaster
harus melakukan hal-hal berikut:</p><ul><li><p>Aktifkan <em>feature gate</em> <code>LocalStorageCapacityIsolationFSQuotaMonitoring=true</code>
pada konfigurasi Kubelet. Nilainya secara bawaan <code>false</code> pada
Kubernetes 1.16, jadi harus secara eksplisit disetel menjadi <code>true</code>.</p></li><li><p>Pastikan bahwa partisi <em>root</em> (atau partisi opsional <em>runtime</em>)
telah dibangun (<em>build</em>) dengan mengaktifkan <em>project quotas</em>. Semua sistem berkas (<em>filesystem</em>)
XFS mendukung <em>project quotas</em>, tetapi sistem berkas ext4 harus dibangun
secara khusus untuk mendukungnya</p></li><li><p>Pastikan bahwa partisi <em>root</em> (atau partisi opsional <em>runtime</em>) ditambatkan (<em>mount</em>)
dengan <em>project quotas</em> yang telah diaktifkan.</p></li></ul><h4 id=membangun-dan-menambatkan-sistem-berkas-dengan-project-quotas-yang-telah-diaktifkan>Membangun dan menambatkan sistem berkas dengan <em>project quotas</em> yang telah diaktifkan</h4><p>Sistem berkas XFS tidak membutuhkan tindakan khusus saat dibangun;
mereka secara otomatis telah dibangun dengan <em>project quotas</em> yang
telah diaktifkan.</p><p>Sistem berkas <em>ext4fs</em> harus dibangun dengan mengaktifkan <em>quotas</em>,
kemudian mereka harus diaktifkan pada sistem berkas tersebut.</p><pre tabindex=0><code>% sudo mkfs.ext4 other_ext4fs_args... -E quotatype=prjquota /dev/block_device
% sudo tune2fs -O project -Q prjquota /dev/block_device
</code></pre><p>Untuk menambatkan sistem berkasnya, baik ext4fs dan XFS membutuhkan opsi
<code>prjquota</code> disetel di dalam <code>/etc/fstab</code>:</p><pre tabindex=0><code>/dev/block_device	/var/kubernetes_data	defaults,prjquota	0	0
</code></pre><h2 id=sumber-daya-yang-diperluas>Sumber daya yang diperluas</h2><p>Sumber daya yang diperluas (<em>Extended Resource</em>) adalah nama sumber daya di luar domain <code>kubernetes.io</code>.
Mereka memungkinkan operator klaster untuk menyatakan dan pengguna untuk menggunakan
sumber daya di luar sumber daya bawaan Kubernetes.</p><p>Ada dua langkah untuk menggunakan sumber daya yang diperluas. Pertama, operator
klaster harus menyatakan sebuah Extended Resource. Kedua, pengguna harus meminta
sumber daya yang diperluas tersebut di dalam Pod.</p><h3 id=mengelola-sumber-daya-yang-diperluas>Mengelola sumber daya yang diperluas</h3><h4 id=sumber-daya-yang-diperluas-pada-tingkat-node>Sumber daya yang diperluas pada tingkat Node</h4><p>Sumber daya yang diperluas pada tingkat Node terikat pada Node.</p><h5 id=sumber-daya-device-plugin-yang-dikelola>Sumber daya Device Plugin yang dikelola</h5><p>Lihat <a href=/id/docs/concepts/extend-kubernetes/compute-storage-net/device-plugins/>Device
Plugin</a> untuk
cara menyatakan sumber daya <em>device plugin</em> yang dikelola pada setiap node.</p><h5 id=sumber-daya-lainnya>Sumber daya lainnya</h5><p>Untuk menyatakan sebuah sumber daya yang diperluas tingkat Node, operator klaster
dapat mengirimkan permintaan HTTP <code>PATCH</code> ke API server untuk menentukan kuantitas
sumber daya yang tersedia pada kolom <code>status.capacity</code> untuk Node pada klaster.
Setelah itu, <code>status.capacity</code> pada Node akan memiliki sumber daya baru tersebut.
Kolom <code>status.allocatable</code> diperbarui secara otomatis dengan sumber daya baru
tersebut secara <em>asynchrounous</em> oleh Kubelet. Perlu dicatat bahwa karena scheduler
menggunakan nilai <code>status.allocatable</code> milik Node saat mengevaluasi muat atau tidaknya
Pod, mungkin ada waktu jeda pendek antara melakukan <code>PATCH</code> terhadap kapasitas Node
dengan sumber daya baru dengan Pod pertama yang meminta sumber daya tersebut untuk
dapat dijadwalkan pada Node tersebut.</p><p><strong>Contoh:</strong></p><p>Berikut sebuah contoh yang menunjukkan bagaimana cara menggunakan <code>curl</code> untuk
mengirim permintaan HTTP yang menyatakan lima sumber daya "example.com/foo" pada
Node <code>k8s-node-1</code> yang memiliki master <code>k8s-master</code>.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>curl --header <span style=color:#b44>&#34;Content-Type: application/json-patch+json&#34;</span> <span style=color:#b62;font-weight:700>\
</span></span></span><span style=display:flex><span><span style=color:#b62;font-weight:700></span>--request PATCH <span style=color:#b62;font-weight:700>\
</span></span></span><span style=display:flex><span><span style=color:#b62;font-weight:700></span>--data <span style=color:#b44>&#39;[{&#34;op&#34;: &#34;add&#34;, &#34;path&#34;: &#34;/status/capacity/example.com~1foo&#34;, &#34;value&#34;: &#34;5&#34;}]&#39;</span> <span style=color:#b62;font-weight:700>\
</span></span></span><span style=display:flex><span><span style=color:#b62;font-weight:700></span>http://k8s-master:8080/api/v1/nodes/k8s-node-1/status
</span></span></code></pre></div><div class="alert alert-info note callout" role=alert><strong>Catatan:</strong> Pada permintaan HTTP di atas, <code>~1</code> adalah <em>encoding</em> untuk karakter <code>/</code> pada jalur (<em>path</em>) <em>patch</em>.
Nilai jalur operasi tersebut di dalam JSON-Patch diinterpretasikan sebagai sebuah JSON-Pointer.
Untuk lebih lanjut, lihat <a href=https://tools.ietf.org/html/rfc6901#section-3>IETF RFC 6901, bagian 3</a>.</div><h4 id=sumber-daya-yang-diperluas-pada-tingkat-klaster>Sumber daya yang diperluas pada tingkat klaster</h4><p>Sumber daya yang diperluas pada tingkat klaster tidak terikat pada Node. Mereka
biasanya dikelola oleh <em>scheduler extender</em>, yang menangani penggunaan sumber daya
dan kuota sumber daya.</p><p>Kamu dapat menentukan sumber daya yang diperluas yang ditangani oleh <em>scheduler extender</em>
pada <a href=https://github.com/kubernetes/kubernetes/blob/release-1.10/pkg/scheduler/api/v1/types.go#L31>konfigurasi kebijakan scheduler</a>.</p><p><strong>Contoh:</strong></p><p>Konfigurasi untuk sebuah kebijakan scheduler berikut menunjukkan bahwa
sumber daya yang diperluas pada tingkat klaster "example.com/foo" ditangani
oleh <em>scheduler extender</em>.</p><ul><li>Scheduler mengirim sebuah Pod ke <em>scheduler extender</em> hanya jika Pod tersebut
meminta "example.com/foo".</li><li>Kolom <code>ignoredByScheduler</code> menentukan bahwa scheduler tidak memeriksa sumber daya
"example.com/foo" pada predikat <code>PodFitsResources</code> miliknya.</li></ul><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-json data-lang=json><span style=display:flex><span>{
</span></span><span style=display:flex><span>  <span style=color:green;font-weight:700>&#34;kind&#34;</span>: <span style=color:#b44>&#34;Policy&#34;</span>,
</span></span><span style=display:flex><span>  <span style=color:green;font-weight:700>&#34;apiVersion&#34;</span>: <span style=color:#b44>&#34;v1&#34;</span>,
</span></span><span style=display:flex><span>  <span style=color:green;font-weight:700>&#34;extenders&#34;</span>: [
</span></span><span style=display:flex><span>    {
</span></span><span style=display:flex><span>      <span style=color:green;font-weight:700>&#34;urlPrefix&#34;</span>:<span style=color:#b44>&#34;&lt;extender-endpoint&gt;&#34;</span>,
</span></span><span style=display:flex><span>      <span style=color:green;font-weight:700>&#34;bindVerb&#34;</span>: <span style=color:#b44>&#34;bind&#34;</span>,
</span></span><span style=display:flex><span>      <span style=color:green;font-weight:700>&#34;managedResources&#34;</span>: [
</span></span><span style=display:flex><span>        {
</span></span><span style=display:flex><span>          <span style=color:green;font-weight:700>&#34;name&#34;</span>: <span style=color:#b44>&#34;example.com/foo&#34;</span>,
</span></span><span style=display:flex><span>          <span style=color:green;font-weight:700>&#34;ignoredByScheduler&#34;</span>: <span style=color:#a2f;font-weight:700>true</span>
</span></span><span style=display:flex><span>        }
</span></span><span style=display:flex><span>      ]
</span></span><span style=display:flex><span>    }
</span></span><span style=display:flex><span>  ]
</span></span><span style=display:flex><span>}
</span></span></code></pre></div><h3 id=menggunakan-sumber-daya-yang-diperluas>Menggunakan sumber daya yang diperluas</h3><p>Pengguna dapat menggunakan sumber daya yang diperluas di dalam spesifikasi Pod
seperti CPU dan memori. Scheduler menangani akuntansi sumber daya tersebut agar
tidak ada alokasi untuk yang melebihi jumlah yang tersedia.</p><p>API server membatasi jumlah sumber daya yang diperluas dalam bentuk
bilangan bulat. Contoh jumlah yang <em>valid</em> adalah <code>3</code>, <code>3000m</code>, dan
<code>3Ki</code>. Contoh jumlah yang <em>tidak valid</em> adalah <code>0.5</code> dan <code>1500m</code>.</p><div class="alert alert-info note callout" role=alert><strong>Catatan:</strong> Sumber daya yang diperluas menggantikan Opaque Integer Resource.
Pengguna dapat menggunakan prefiks nama domain selain <code>kubernetes.io</code> yang sudah dipakai.</div><p>Untuk menggunakan sebuah sumber daya yang diperluas di sebuah Pod, masukkan nama
sumber daya tersebut sebagai nilai <em>key</em> dari map <code>spec.containers[].resources.limit</code>
pada spesifikasi Container.</p><div class="alert alert-info note callout" role=alert><strong>Catatan:</strong> Sumber daya yang diperluas tidak dapat di-<em>overcommit</em>, sehingga
request dan limit nilainya harus sama jika keduanya ada di spesifikasi
sebuah Container.</div><p>Sebuah Pod hanya dijadwalkan jika semua request sumber dayanya terpenuhi, termasuk
CPU, memori, dan sumber daya yang diperluas manapun. Pod tersebut akan tetap
berada pada kondisi <code>PENDING</code> selama request sumber daya tersebut tidak terpenuhi.</p><p><strong>Contoh:</strong></p><p>Pod di bawah meminta 2 CPU dan 1 "example.com/foo" (sebuah sumber daya yang diperluas).</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>my-pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>my-container<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>myimage<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>resources</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>requests</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>cpu</span>:<span style=color:#bbb> </span><span style=color:#666>2</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>example.com/foo</span>:<span style=color:#bbb> </span><span style=color:#666>1</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>limits</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>example.com/foo</span>:<span style=color:#bbb> </span><span style=color:#666>1</span><span style=color:#bbb>
</span></span></span></code></pre></div><h2 id=selanjutnya>Selanjutnya</h2><ul><li><p>Dapatkan pengalaman langsung <a href=/docs/tasks/configure-pod-container/assign-memory-resource/>menentukan sumber daya memori untuk Container dan Pod</a>.</p></li><li><p>Dapatkan pengalaman langsung <a href=/docs/tasks/configure-pod-container/assign-cpu-resource/>menentukan sumber daya CPU untuk Container dan Pod</a>.</p></li><li><p><a href=/docs/reference/generated/kubernetes-api/v1.25/#container-v1-core>Container API</a></p></li><li><p><a href=/docs/reference/generated/kubernetes-api/v1.25/#resourcerequirements-v1-core>ResourceRequirements</a></p></li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-e511ed821ada65d0053341dbd8ad2bb5>7.3 - Secret</h1><p>Objek <code>secret</code> pada Kubernetes mengizinkan kamu menyimpan dan mengatur informasi yang sifatnya sensitif, seperti
<em>password</em>, token OAuth, dan ssh <em>keys</em>. Menyimpan informasi yang sifatnya sensitif ini ke dalam <code>secret</code>
cenderung lebih aman dan fleksible jika dibandingkan dengan menyimpan informasi tersebut secara apa adanya pada definisi <a class=glossary-tooltip title='Unit Kubernetes yang paling sederhana dan kecil. Sebuah Pod merepresentasikan sebuah set kontainer yang dijalankan pada kluster kamu.' data-toggle=tooltip data-placement=top href=/docs/concepts/workloads/pods/pod-overview/ target=_blank aria-label=Pod>Pod</a> atau di dalam <a class=glossary-tooltip title='Instans yang disimpan dari sebuah Container yang memuat seperangkat perangkat lunak yang dibutuhkan untuk menjalankan sebuah aplikasi.' data-toggle=tooltip data-placement=top href='/id/docs/reference/glossary/?all=true#term-image' target=_blank aria-label='container image'>container image</a>.
Silahkan lihat <a href=https://git.k8s.io/community/contributors/design-proposals/auth/secrets.md>Dokumen desain Secret</a> untuk informasi yang sifatnya mendetail.</p><h2 id=ikhtisar-secret>Ikhtisar Secret</h2><p>Sebuah Secret merupakan sebuah objek yang mengandung informasi yang sifatnya
sensitif, seperti <em>password</em>, token, atau <em>key</em>. Informasi tersebut sebenarnya bisa saja
disimpan di dalam spesifikasi Pod atau <em>image</em>; meskipun demikian, melakukan penyimpanan
di dalam objek Secret mengizinkan pengguna untuk memiliki kontrol lebih lanjut mengenai
bagaimana Secret ini disimpan, serta mencegah tereksposnya informasi sensitif secara
tidak disengaja.</p><p>Baik pengguna dan sistem memiliki kemampuan untuk membuat objek Secret.</p><p>Untuk menggunakan Secret, sebuah Pod haruslah merujuk pada Secret tersebut.
Sebuah Secret dapat digunakan di dalam sebuah Pod melalui dua cara:
sebagai <em>file</em> yang ada di dalam <em>volume</em> <a class=glossary-tooltip title='Sebuah direktori yang mengandung data, dapat diakses o;eh kontainer-kontainer di dalam pod.' data-toggle=tooltip data-placement=top href=/docs/concepts/storage/volumes/ target=_blank aria-label=volume>volume</a>
yang di-<em>mount</em> pada salah satu container Pod, atau digunakan oleh kubelet
ketika menarik <em>image</em> yang digunakan di dalam Pod.</p><h3 id=secret-built-in>Secret <em>Built-in</em></h3><h4 id=sebuah-service-account-akan-secara-otomatis-dibuat-dan-meng-attach-secret-dengan-kredensial-api>Sebuah <em>Service Account</em> akan Secara Otomatis Dibuat dan Meng-<em>attach</em> Secret dengan Kredensial API</h4><p>Kubernetes secara otomatis membuat secret yang mengandung kredensial
yang digunakan untuk mengakses API, serta secara otomatis memerintahkan Pod untuk menggunakan
Secret ini.</p><p>Mekanisme otomatisasi pembuatan secret dan penggunaan kredensial API dapat di nonaktifkan
atau di-<em>override</em> jika kamu menginginkannya. Meskipun begitu, jika apa yang kamu butuhkan
hanyalah mengakses apiserver secara aman, maka mekanisme <em>default</em> inilah yang disarankan.</p><p>Baca lebih lanjut dokumentasi <a href=/id/docs/tasks/configure-pod-container/configure-service-account/><em>Service Account</em></a>
untuk informasi lebih lanjut mengenai bagaimana cara kerja <em>Service Account</em>.</p><h3 id=membuat-objek-secret-kamu-sendiri>Membuat Objek Secret Kamu Sendiri</h3><h4 id=membuat-secret-dengan-menggunakan-kubectl>Membuat Secret dengan Menggunakan kubectl</h4><p>Misalnya saja, beberapa Pod memerlukan akses ke sebuah basis data. Kemudian <em>username</em>
dan <em>password</em> yang harus digunakan oleh Pod-Pod tersebut berada pada mesin lokal kamu
dalam bentuk <em>file-file</em> <code>./username.txt</code> dan <code>./password.txt</code>.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span><span style=color:#080;font-style:italic># Buatlah berkas yang selanjutnya akan digunakan pada contoh-contoh selanjutnya</span>
</span></span><span style=display:flex><span><span style=color:#a2f>echo</span> -n <span style=color:#b44>&#39;admin&#39;</span> &gt; ./username.txt
</span></span><span style=display:flex><span><span style=color:#a2f>echo</span> -n <span style=color:#b44>&#39;1f2d1e2e67df&#39;</span> &gt; ./password.txt
</span></span></code></pre></div><p>Perintah <code>kubectl create secret</code> akan mengemas <em>file-file</em> ini menjadi Secret dan
membuat sebuah objek pada Apiserver.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl create secret generic db-user-pass --from-file<span style=color:#666>=</span>./username.txt --from-file<span style=color:#666>=</span>./password.txt
</span></span></code></pre></div><pre tabindex=0><code>secret &#34;db-user-pass&#34; created
</code></pre><div class="alert alert-info note callout" role=alert><strong>Catatan:</strong> Karakter spesial seperti <code>$</code>, <code>\*</code>, and <code>!</code> membutuhkan mekanisme <em>escaping</em>.
Jika <em>password</em> yang kamu gunakan mengandung karakter spesial, kamu perlu melakukan <em>escape</em> karakter dengan menggunakan karakter <code>\\</code>. Contohnya, apabila <em>password</em> yang kamu miliki adalah <code>S!B\*d$zDsb</code>, maka kamu harus memanggil perintah kubectl dengan cara berikut:
kubectl create secret generic dev-db-secret --from-literal=username=devuser --from-literal=password=S\!B\\*d\$zDsb
Perhatikan bahwa kamu tidak perlu melakukan <em>escape</em> karakter apabila massukan yang kamu berikan merupakan <em>file</em> (<code>--from-file</code>).</div><p>Kamu dapat memastikan apakah suatu Secret sudah dibuat atau belum dengan menggunakan perintah:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get secrets
</span></span></code></pre></div><pre tabindex=0><code>NAME                  TYPE                                  DATA      AGE
db-user-pass          Opaque                                2         51s
</code></pre><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl describe secrets/db-user-pass
</span></span></code></pre></div><pre tabindex=0><code>Name:            db-user-pass
Namespace:       default
Labels:          &lt;none&gt;
Annotations:     &lt;none&gt;

Type:            Opaque

Data
====
password.txt:    12 bytes
username.txt:    5 bytes
</code></pre><div class="alert alert-info note callout" role=alert><strong>Catatan:</strong> Perintah-perintah <code>kubectl get</code> dan <code>kubectl describe</code> secara <em>default</em> akan
mencegah ditampilkannya informasi yang ada di dalam Secret.
Hal ini dilakukan untuk melindungi agar Secret tidak terekspos secara tidak disengaja oleh orang lain,
atau tersimpan di dalam <em>log</em> <em>terminal</em>.</div><p>Kamu dapat membaca <a href=#decoding-a-secret>bagaimana cara melakukan <em>decode</em> sebuah secret</a>
untuk mengetahui bagaimana cara melihat isi dari Secret.</p><h4 id=membuat-secret-secara-manual>Membuat Secret Secara Manual</h4><p>Kamu dapat membuat sebuah Secret dengan terlebih dahulu membuat <em>file</em> yang berisikan
informasi yang ingin kamu jadikan Secret dalam bentuk yaml atau json dan kemudian membuat objek
dengan menggunakan <em>file</em> tersebut. <a href=/docs/reference/generated/kubernetes-api/v1.12/#secret-v1-core>Secret</a>
mengandung dua buah <em>map</em>: <em>data</em> dan <em>stringData</em>. <em>Field</em> <em>data</em> digunakan untuk menyimpan sembarang data,
yang di-<em>encode</em> menggunakan base64. Sementara itu <em>stringData</em> disediakan untuk memudahkan kamu untuk menyimpan
informasi sensitif dalam format yang tidak di-<em>encode</em>.</p><p>Sebagai contoh, untuk menyimpan dua buah string di dalam Secret dengan menggunakan <em>field</em> data, ubahlah
informasi tersebut ke dalam base64 dengan menggunakan mekanisme sebagai berikut:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span><span style=color:#a2f>echo</span> -n <span style=color:#b44>&#39;admin&#39;</span> | base64
</span></span><span style=display:flex><span><span style=color:#b8860b>YWRtaW4</span><span style=color:#666>=</span>
</span></span><span style=display:flex><span><span style=color:#a2f>echo</span> -n <span style=color:#b44>&#39;1f2d1e2e67df&#39;</span> | base64
</span></span><span style=display:flex><span>MWYyZDFlMmU2N2Rm
</span></span></code></pre></div><p>Buatlah sebuah Secret yang memiliki bentuk sebagai berikut:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Secret<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>mysecret<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>type</span>:<span style=color:#bbb> </span>Opaque<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>data</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>username</span>:<span style=color:#bbb> </span>YWRtaW4=<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>password</span>:<span style=color:#bbb> </span>MWYyZDFlMmU2N2Rm<span style=color:#bbb>
</span></span></span></code></pre></div><p>Kemudian buatlah Secret menggunakan perintah <a href=/docs/reference/generated/kubectl/kubectl-commands#apply><code>kubectl apply</code></a>:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl apply -f ./secret.yaml
</span></span></code></pre></div><pre tabindex=0><code>secret &#34;mysecret&#34; created
</code></pre><p>Untuk beberapa skenario, kamu bisa saja ingin menggunakan opsi <em>field</em> stringData.
<em>Field</em> ini mengizinkan kamu untuk memberikan masukan berupa informasi yang belum di-<em>encode</em> secara langsung
pada sebuah Secret, informasi dalam bentuk string ini kemudian akan di-<em>encode</em> ketika Secret dibuat maupun diubah.</p><p>Contoh praktikal dari hal ini adalah ketika kamu melakukan proses <em>deploy</em> aplikasi
yang menggunakan Secret sebagai penyimpanan <em>file</em> konfigurasi, dan kamu ingin mengisi
bagian dari konfigurasi <em>file</em> tersebut ketika aplikasi di_deploy_.</p><p>Jika kamu ingin aplikasi kamu menggunakan <em>file</em> konfigurasi berikut:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiUrl</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;https://my.api.com/api/v1&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>username</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;user&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>password</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;password&#34;</span><span style=color:#bbb>
</span></span></span></code></pre></div><p>Kamu dapat menyimpan Secret ini dengan menggunakan cara berikut:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Secret<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>mysecret<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>type</span>:<span style=color:#bbb> </span>Opaque<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>stringData</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>config.yaml</span>:<span style=color:#bbb> </span>|-<span style=color:#b44;font-style:italic>
</span></span></span><span style=display:flex><span><span style=color:#b44;font-style:italic>    apiUrl: &#34;https://my.api.com/api/v1&#34;
</span></span></span><span style=display:flex><span><span style=color:#b44;font-style:italic>    username: {{username}}
</span></span></span><span style=display:flex><span><span style=color:#b44;font-style:italic>    password: {{password}}</span><span style=color:#bbb>    
</span></span></span></code></pre></div><p>Alat <em>deployment</em> yang kamu gunakan kemudian akan mengubah templat variabel <code>{{username}}</code> dan <code>{{password}}</code>
sebelum menjalankan perintah <code>kubectl apply</code>.</p><p>stringData merupakan <em>field</em> yang sifatnya <em>write-only</em> untuk alasan kenyamanan pengguna.
<em>Field</em> ini tidak pernah ditampilkan ketika Secret dibaca. Sebagai contoh, misalkan saja kamu menjalankan
perintah sebagai berikut:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get secret mysecret -o yaml
</span></span></code></pre></div><p>Keluaran yang diberikan kurang lebih akan ditampilkan sebagai berikut:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Secret<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>creationTimestamp</span>:<span style=color:#bbb> </span>2018-11-15T20:40:59Z<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>mysecret<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>namespace</span>:<span style=color:#bbb> </span>default<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>resourceVersion</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;7225&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>selfLink</span>:<span style=color:#bbb> </span>/api/v1/namespaces/default/secrets/mysecret<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>uid</span>:<span style=color:#bbb> </span>c280ad2e-e916-11e8-98f2-025000000001<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>type</span>:<span style=color:#bbb> </span>Opaque<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>data</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>config.yaml</span>:<span style=color:#bbb> </span>YXBpVXJsOiAiaHR0cHM6Ly9teS5hcGkuY29tL2FwaS92MSIKdXNlcm5hbWU6IHt7dXNlcm5hbWV9fQpwYXNzd29yZDoge3twYXNzd29yZH19<span style=color:#bbb>
</span></span></span></code></pre></div><p>Jika sebuah <em>field</em> dispesifikasikan dalam bentuk data maupun stringData,
maka nilai dari stringData-lah yang akan digunakan. Sebagai contoh, misalkan saja terdapat
definisi Secret sebagai berikut:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Secret<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>mysecret<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>type</span>:<span style=color:#bbb> </span>Opaque<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>data</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>username</span>:<span style=color:#bbb> </span>YWRtaW4=<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>stringData</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>username</span>:<span style=color:#bbb> </span>administrator<span style=color:#bbb>
</span></span></span></code></pre></div><p>Akan menghasilkan Secret sebagai berikut:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Secret<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>creationTimestamp</span>:<span style=color:#bbb> </span>2018-11-15T20:46:46Z<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>mysecret<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>namespace</span>:<span style=color:#bbb> </span>default<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>resourceVersion</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;7579&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>selfLink</span>:<span style=color:#bbb> </span>/api/v1/namespaces/default/secrets/mysecret<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>uid</span>:<span style=color:#bbb> </span>91460ecb-e917-11e8-98f2-025000000001<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>type</span>:<span style=color:#bbb> </span>Opaque<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>data</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>username</span>:<span style=color:#bbb> </span>YWRtaW5pc3RyYXRvcg==<span style=color:#bbb>
</span></span></span></code></pre></div><p>Dimana string <code>YWRtaW5pc3RyYXRvcg==</code> akan di-<em>decode</em> sebagai <code>administrator</code>.</p><p><em>Key</em> dari data dan stringData yang boleh tersusun atas karakter alfanumerik,
'-', '_' atau '.'.</p><p><strong>Catatan <em>Encoding</em>:</strong> <em>Value</em> dari JSON dan YAML yang sudah diseriakisasi dari data Secret
akan di-<em>encode</em> ke dalam string base64. <em>Newline</em> dianggap tidak valid pada string ini dan harus
dihilangkan. Ketika pengguna Darwin/macOS menggunakan alat <code>base64</code>, maka pengguna
tersebut harus menghindari opsi <code>-b</code> yang digunakan untuk memecah baris yang terlalu panjang.
Sebaliknya pengguna Linux <em>harus</em> menambahkan opsi <code>-w 0</code> pada perintah <code>base64</code> atau
melakukan mekanisme <em>pipeline</em> <code>base64 | tr -d '\n'</code> jika tidak terdapat opsi <code>-w</code>.</p><h4 id=membuat-secret-dengan-menggunakan-generator>Membuat Secret dengan Menggunakan <em>Generator</em></h4><p>Kubectl mendukung <a href=/docs/tasks/manage-kubernetes-objects/kustomization/>mekanisme manajemen objek dengan menggunakan Kustomize</a>
sejak versi 1.14. Dengan fitur baru ini, kamu juga dapat membuat sebuah Secret dari sebuah <em>generator</em>
dan kemudian mengaplikasikannya untuk membuat sebuah objek pada Apiserver. <em>Generator</em> yang digunakan haruslah
dispesifikasikan di dalam sebuah <em>file</em> <code>kustomization.yaml</code> di dalam sebuah direktori.</p><p>Sebagai contoh, untuk menghasilan sebuah Secret dari <em>file-file</em> <code>./username.txt</code> dan <code>./password.txt</code></p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span><span style=color:#080;font-style:italic># Membuat sebuah berkas kustomization.yaml dengan SecretGenerator</span>
</span></span><span style=display:flex><span>cat <span style=color:#b44>&lt;&lt;EOF &gt;./kustomization.yaml
</span></span></span><span style=display:flex><span><span style=color:#b44>secretGenerator:
</span></span></span><span style=display:flex><span><span style=color:#b44>- name: db-user-pass
</span></span></span><span style=display:flex><span><span style=color:#b44>  files:
</span></span></span><span style=display:flex><span><span style=color:#b44>  - username.txt
</span></span></span><span style=display:flex><span><span style=color:#b44>  - password.txt
</span></span></span><span style=display:flex><span><span style=color:#b44>EOF</span>
</span></span></code></pre></div><p>Gunakan direktori <em>kustomization</em> untuk membuat objek Secret yang diinginkan.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>$ kubectl apply -k .
</span></span><span style=display:flex><span>secret/db-user-pass-96mffmfh4k created
</span></span></code></pre></div><p>Kamu dapat memastikan Secret tersebut sudah dibuat dengan menggunakan perintah berikut:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>$ kubectl get secrets
</span></span><span style=display:flex><span>NAME                             TYPE                                  DATA      AGE
</span></span><span style=display:flex><span>db-user-pass-96mffmfh4k          Opaque                                <span style=color:#666>2</span>         51s
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>$ kubectl describe secrets/db-user-pass-96mffmfh4k
</span></span><span style=display:flex><span>Name:            db-user-pass
</span></span><span style=display:flex><span>Namespace:       default
</span></span><span style=display:flex><span>Labels:          &lt;none&gt;
</span></span><span style=display:flex><span>Annotations:     &lt;none&gt;
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>Type:            Opaque
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#b8860b>Data</span>
</span></span><span style=display:flex><span><span style=color:#666>====</span>
</span></span><span style=display:flex><span>password.txt:    <span style=color:#666>12</span> bytes
</span></span><span style=display:flex><span>username.txt:    <span style=color:#666>5</span> bytes
</span></span></code></pre></div><p>Sebagai contoh, untuk membuat sebuah Secret dari literal <code>username=admin</code> dan <code>password=secret</code>,
kamu dapat menspesifikasikan <em>generator</em> Secret pada <em>file</em> <code>kustomization.yaml</code> sebagai</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span><span style=color:#080;font-style:italic># Membuat sebuah berkas kustomization.yaml dengan menggunakan SecretGenerator</span>
</span></span><span style=display:flex><span>$ cat <span style=color:#b44>&lt;&lt;EOF &gt;./kustomization.yaml
</span></span></span><span style=display:flex><span><span style=color:#b44>secretGenerator:
</span></span></span><span style=display:flex><span><span style=color:#b44>- name: db-user-pass
</span></span></span><span style=display:flex><span><span style=color:#b44>  literals:
</span></span></span><span style=display:flex><span><span style=color:#b44>  - username=admin
</span></span></span><span style=display:flex><span><span style=color:#b44>  - password=secret
</span></span></span><span style=display:flex><span><span style=color:#b44>EOF</span>
</span></span></code></pre></div><p>Aplikasikan direktori <em>kustomization</em> untuk membuat objek Secret.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>$ kubectl apply -k .
</span></span><span style=display:flex><span>secret/db-user-pass-dddghtt9b5 created
</span></span></code></pre></div><div class="alert alert-info note callout" role=alert><strong>Catatan:</strong> Secret yang dihasilkan nantinya akan memiliki tambahan sufix dengan cara melakukan teknik <em>hashing</em>
pada isi Secret tersebut. Hal ini dilakukan untuk menjamin dibuatnya sebuah Secret baru setiap kali terjadi
perubahan isi dari Secret tersebut.</div><h4 id=melakukan-proses-decode-pada-secret>Melakukan Proses <em>Decode</em> pada Secret</h4><p>Secret dapat dibaca dengan menggunakan perintah <code>kubectl get secret</code>.
Misalnya saja, untuk membaca Secret yang dibuat pada bagian sebelumya:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get secret mysecret -o yaml
</span></span></code></pre></div><pre tabindex=0><code>apiVersion: v1
kind: Secret
metadata:
  creationTimestamp: 2016-01-22T18:41:56Z
  name: mysecret
  namespace: default
  resourceVersion: &#34;164619&#34;
  selfLink: /api/v1/namespaces/default/secrets/mysecret
  uid: cfee02d6-c137-11e5-8d73-42010af00002
type: Opaque
data:
  username: YWRtaW4=
  password: MWYyZDFlMmU2N2Rm
</code></pre><p>Kemudian lakukan mekanisme <em>decode</em> <em>field</em> <em>password</em>:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span><span style=color:#a2f>echo</span> <span style=color:#b44>&#39;MWYyZDFlMmU2N2Rm&#39;</span> | base64 --decode
</span></span></code></pre></div><pre tabindex=0><code>1f2d1e2e67df
</code></pre><h2 id=menggunakan-secret>Menggunakan Secret</h2><p>Secret dapat di-<em>mount</em> sebagai <em>volume</em> data atau dapat diekspos sebagai <a class=glossary-tooltip title='Variabel lingkungan Container merupakan pasangan nama=nilai yang dapat digunakan untuk menyediakan informasi penting bagi Container yang dijalankan pada Pod.' data-toggle=tooltip data-placement=top href=/docs/concepts/containers/container-environment-variables/ target=_blank aria-label='variabel-variabel environment'>variabel-variabel environment</a>
dapat digunakan di dalam Pod. Secret ini juga dapat digunakan secara langsug
oleh bagian lain dari sistem, tanpa secara langsung berkaitan dengan Pod.
Sebagai contoh, Secret dapat berisikan kredensial bagian suatu sistem lain yang digunakan
untuk berinteraksi dengan sistem eksternal yang kamu butuhkan.</p><h3 id=menggunakan-secret-sebagai-file-melalui-pod>Menggunakan Secret sebagai <em>File</em> melalui Pod</h3><p>Berikut adalah langkah yang harus kamu penuhi agar kamu dapat menggunakan Secret di dalam <em>volume</em> dalam sebuah Pod:</p><ol><li>Buatlah sebuah Secret, atau gunakan sebuah Secret yang sudah kamu buat sebelumnya. Beberapa Pod dapat merujuk pada sebuah Secret yang sama.</li><li>Modifikasi definisi Pod kamu dengan cara menambahkan sebuah <em>volume</em> di bawah <code>.spec.volumes[]</code>. Berilah <em>volume</em> tersebut nama, dan pastikan <em>field</em> <code>.spec.volumes[].secret.secretName</code> merujuk pada nama yang sama dengan objek secret.</li><li>Tambahkan <em>field</em> <code>.spec.containers[].volumeMounts[]</code> pada setiap container yang membutuhkan Secret. Berikan spesifikasi <code>.spec.containers[].volumeMounts[].readOnly = true</code> dan <code>.spec.containers[].volumeMounts[].mountPath</code> pada direktori dimana Secret tersebut diletakkan.</li><li>Modifikasi image dan/atau <em>command line</em> kamu agar program yang kamu miliki merujuk pada <em>file</em> di dalam direktori tersebut. Setiap <em>key</em> pada map <code>data</code> Secret akan menjadi nama dari sebuah <em>file</em> pada <code>mountPath</code>.</li></ol><p>Berikut merupakan salah satu contoh dimana sebuah Pod melakukan proses <em>mount</em> Secret pada sebuah <em>volume</em>:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>mypod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>mypod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>redis<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>volumeMounts</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>foo<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>mountPath</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;/etc/foo&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>readOnly</span>:<span style=color:#bbb> </span><span style=color:#a2f;font-weight:700>true</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>volumes</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>foo<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>secret</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>secretName</span>:<span style=color:#bbb> </span>mysecret<span style=color:#bbb>
</span></span></span></code></pre></div><p>Setiap Secret yang ingin kamu gunakan harus dirujuk pada <em>field</em> <code>.spec.volumes</code>.</p><p>Jika terdapat lebih dari satu container di dalam Pod,
maka setiap container akan membutuhkan blok <code>volumeMounts</code>-nya masing-masing,
meskipun demikian hanya sebuah <em>field</em> <code>.spec.volumes</code> yang dibutuhkan untuk setiap Secret.</p><p>Kamu dapat menyimpan banyak <em>file</em> ke dalam satu Secret,
atau menggunakan banyak Secret, hal ini tentunya bergantung pada preferensi pengguna.</p><p><strong>Proyeksi <em>key</em> Secret pada Suatu <em>Path</em> Spesifik</strong></p><p>Kita juga dapat mengontrol <em>path</em> di dalam <em>volume</em> di mana sebuah Secret diproyeksikan.
Kamu dapat menggunakan <em>field</em> <code>.spec.volumes[].secret.items</code> untuk mengubah
<em>path</em> target dari setiap <em>key</em>:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>mypod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>mypod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>redis<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>volumeMounts</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>foo<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>mountPath</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;/etc/foo&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>readOnly</span>:<span style=color:#bbb> </span><span style=color:#a2f;font-weight:700>true</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>volumes</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>foo<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>secret</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>secretName</span>:<span style=color:#bbb> </span>mysecret<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>items</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- <span style=color:green;font-weight:700>key</span>:<span style=color:#bbb> </span>username<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>path</span>:<span style=color:#bbb> </span>my-group/my-username<span style=color:#bbb>
</span></span></span></code></pre></div><p>Apa yang akan terjadi jika kita menggunakan definisi di atas:</p><ul><li>Secret <code>username</code> akan disimpan pada <em>file</em> <code>/etc/foo/my-group/my-username</code> dan bukan <code>/etc/foo/username</code>.</li><li>Secret <code>password</code> tidak akan diproyeksikan.</li></ul><p>Jika <em>field</em> <code>.spec.volumes[].secret.items</code> digunakan, hanya <em>key-key</em> yang dispesifikan di dalam
<code>items</code> yang diproyeksikan. Untuk mengonsumsi semua <em>key-key</em> yang ada dari Secret,
semua <em>key</em> yang ada harus didaftarkan pada <em>field</em> <code>items</code>.
Semua <em>key</em> yang didaftarkan juga harus ada di dalam Secret tadi.
Jika tidak, <em>volume</em> yang didefinisikan tidak akan dibuat.</p><p><strong><em>Permission</em> <em>File-File</em> Secret</strong></p><p>Kamu juga dapat menspesifikasikan mode <em>permission</em> dari <em>file</em> Secret yang kamu inginkan.
Jika kamu tidak menspesifikasikan hal tersebut, maka nilai <em>default</em> yang akan diberikan adalah <code>0644</code> is used by default.
Kamu dapat memberikan mode <em>default</em> untuk semua Secret yang ada serta melakukan mekanisme <em>override</em> <em>permission</em>
pada setiap <em>key</em> jika memang diperlukan.</p><p>Sebagai contoh, kamu dapat memberikan spesifikasi mode <em>default</em> sebagai berikut:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>mypod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>mypod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>redis<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>volumeMounts</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>foo<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>mountPath</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;/etc/foo&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>volumes</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>foo<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>secret</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>secretName</span>:<span style=color:#bbb> </span>mysecret<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>defaultMode</span>:<span style=color:#bbb> </span><span style=color:#666>256</span><span style=color:#bbb>
</span></span></span></code></pre></div><p>Kemudian, sebuah Secret akan di-<em>mount</em> pada <code>/etc/foo</code>, selanjutnya semua <em>file</em>
yang dibuat pada <em>volume</em> secret tersebut akan memiliki <em>permission</em> <code>0400</code>.</p><p>Perhatikan bahwa spesifikasi JSON tidak mendukung notasi <em>octal</em>, dengan demikian gunakanlah
<em>value</em> 256 untuk <em>permission</em> 0400. Jika kamu menggunakan format YAML untuk spesifikasi Pod,
kamu dapat menggunakan notasi <em>octal</em> untuk memberikan spesifikasi <em>permission</em> dengan cara yang lebih
natural.</p><p>Kamu juga dapat melakukan mekanisme pemetaan, seperti yang sudah dilakukan pada contoh sebelumnya,
dan kemudian memberikan spesifikasi <em>permission</em> yang berbeda untuk <em>file</em> yang berbeda.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>mypod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>mypod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>redis<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>volumeMounts</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>foo<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>mountPath</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;/etc/foo&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>volumes</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>foo<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>secret</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>secretName</span>:<span style=color:#bbb> </span>mysecret<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>items</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- <span style=color:green;font-weight:700>key</span>:<span style=color:#bbb> </span>username<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>path</span>:<span style=color:#bbb> </span>my-group/my-username<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>mode</span>:<span style=color:#bbb> </span><span style=color:#666>511</span><span style=color:#bbb>
</span></span></span></code></pre></div><p>Pada kasus tersebut, <em>file</em> yang dihasilkan pada <code>/etc/foo/my-group/my-username</code> akan memiliki
<em>permission</em> <code>0777</code>. Karena terdapat batasan pada representasi JSON, maka kamu
harus memberikan spesifikasi mode <em>permission</em> dalam bentuk notasi desimal.</p><p>Perhatikan bahwa <em>permission</em> ini bida saja ditampilkan dalam bentuk notasi desimal,
hal ini akan ditampilkan pada bagian selanjutnya.</p><p><strong>Mengonsumsi <em>Value</em> dari Secret melalui Volume</strong></p><p>Di dalam sebuah container dimana <em>volume</em> secret di-<em>mount</em>,
<em>key</em> dari Secret akan ditampilkan sebagai <em>file</em> dan <em>value</em> dari Secret yang berada dalam bentuk
base64 ini akan di-<em>decode</em> dam disimpan pada <em>file-file</em> tadi.
Berikut merupakan hasil dari eksekusi perintah di dalam container berdasarkan contoh
yang telah dipaparkan di atas:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>ls /etc/foo/
</span></span></code></pre></div><pre tabindex=0><code>username
password
</code></pre><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>cat /etc/foo/username
</span></span></code></pre></div><pre tabindex=0><code>admin
</code></pre><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>cat /etc/foo/password
</span></span></code></pre></div><pre tabindex=0><code>1f2d1e2e67df
</code></pre><p>Program di dalam container bertanggung jawab untuk membaca Secret
dari <em>file-file</em> yang ada.</p><p><strong>Secret yang di-<em>mount</em> Akan Diubah Secara Otomatis</strong></p><p>Ketika sebuah Secret yang sedang digunakan di dalam <em>volume</em> diubah,
maka <em>key</em> yang ada juga akan diubah. Kubelet akan melakukan mekanisme pengecekan secara periodik
apakah terdapat perubahan pada Secret yang telah di-<em>mount</em>. Meskipun demikian,
proses pengecekan ini dilakukan dengan menggunakan <em>cache</em> lokal untuk mendapatkan <em>value</em> saat ini
dari sebuah Secret. Tipe <em>cache</em> yang ada dapat diatur dengan menggunakan
(<em>field</em> <code>ConfigMapAndSecretChangeDetectionStrategy</code> pada
<a href=https://github.com/kubernetes/kubernetes/blob/main/staging/src/k8s.io/kubelet/config/v1beta1/types.go><em>struct</em> KubeletConfiguration</a>).
Mekanisme ini kemudian dapat diteruskan dengan mekanisme <em>watch</em>(<em>default</em>), ttl, atau melakukan pengalihan semua
<em>request</em> secara langsung pada kube-apiserver.
Sebagai hasilnya, <em>delay</em> total dari pertama kali Secret diubah hingga dilakukannya mekanisme
proyeksi <em>key</em> yang baru pada Pod berlangsung dalam jangka waktu sinkronisasi periodik kubelet +
<em>delay</em> propagasi <em>cache</em>, dimana <em>delay</em> propagasi <em>cache</em> bergantung pada jenis <em>cache</em> yang digunakan
(ini sama dengan <em>delay</em> propagasi <em>watch</em>, ttl dari <em>cache</em>, atau nol).</p><div class="alert alert-info note callout" role=alert><strong>Catatan:</strong> Sebuah container menggunakan Secret sebagai
<a href=/id/docs/concepts/storage/volumes#using-subpath>subPath</a> dari <em>volume</em>
yang di-<em>mount</em> tidak akan menerima perubahan Secret.</div><h3 id=menggunakan-secret-sebagai-variabel-environment>Menggunakan Secret sebagai Variabel <em>Environment</em></h3><p>Berikut merupakan langkah-langkah yang harus kamu terapkan,
untuk menggunakan secret sebagai <a class=glossary-tooltip title='Variabel lingkungan Container merupakan pasangan nama=nilai yang dapat digunakan untuk menyediakan informasi penting bagi Container yang dijalankan pada Pod.' data-toggle=tooltip data-placement=top href=/docs/concepts/containers/container-environment-variables/ target=_blank aria-label='variabel _environment_'>variabel _environment_</a>
pada sebuah Pod:</p><ol><li>Buatlah sebuah Secret, atau gunakan sebuah Secret yang sudah kamu buat sebelumnya. Beberapa Pod dapat merujuk pada sebuah Secret yang sama.</li><li>Modifikasi definisi Pod pada setiap container dimana kamu menginginkan container tersebut dapat mengonsumsi your Pod definition in each container that you wish to consume the value of a secret key to add an environment variabele for each secret key you wish to consume. The environment variabele that consumes the secret key should populate the secret's name and key in <code>env[].valueFrom.secretKeyRef</code>.</li><li>Modifikasi <em>image</em> dan/atau <em>command line</em> kamu agar program yang kamu miliki merujuk pada <em>value</em> yang sudah didefinisikan pada variabel <em>environment</em>.</li></ol><p>Berikut merupakan contoh dimana sebuah Pod menggunakan Secret sebagai variabel <em>environment</em>:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>secret-env-pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>mycontainer<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>redis<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>env</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>SECRET_USERNAME<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>valueFrom</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>secretKeyRef</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>            </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>mysecret<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>            </span><span style=color:green;font-weight:700>key</span>:<span style=color:#bbb> </span>username<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>SECRET_PASSWORD<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>valueFrom</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>secretKeyRef</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>            </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>mysecret<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>            </span><span style=color:green;font-weight:700>key</span>:<span style=color:#bbb> </span>password<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>restartPolicy</span>:<span style=color:#bbb> </span>Never<span style=color:#bbb>
</span></span></span></code></pre></div><p><strong>Menggunakan Secret dari Variabel <em>Environment</em></strong></p><p>Di dalam sebuah container yang mengkonsumsi Secret pada sebuah variabel <em>environment</em>, <em>key</em> dari sebuah secret
akan ditampilkan sebagai variabel <em>environment</em> pada umumnya dengan <em>value</em> berupa informasi yang telah di-<em>decode</em>
ke dalam base64. Berikut merupakan hasil yang didapatkan apabila perintah-perintah di bawah ini
dijalankan dari dalam container yang didefinisikan di atas:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span><span style=color:#a2f>echo</span> <span style=color:#b8860b>$SECRET_USERNAME</span>
</span></span></code></pre></div><pre tabindex=0><code>admin
</code></pre><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span><span style=color:#a2f>echo</span> <span style=color:#b8860b>$SECRET_PASSWORD</span>
</span></span></code></pre></div><pre tabindex=0><code>1f2d1e2e67df
</code></pre><h3 id=menggunakan-imagepullsecrets>Menggunakan imagePullSecrets</h3><p>Sebuah <code>imagePullSecret</code> merupakan salah satu cara yang dapat digunakan untuk menempatkan secret
yang mengandung <em>password</em> dari registri Docker (atau registri <em>image</em> lainnya)
pada Kubelet, sehingga Kubelet dapat mengunduh <em>image</em> dan menempatkannya pada Pod.</p><p><strong>Memberikan spesifikasi manual dari sebuah imagePullSecret</strong></p><p>Penggunaan imagePullSecrets dideskripsikan di dalam <a href=/id/docs/concepts/containers/images/#specifying-imagepullsecrets-on-a-pod>dokumentasi <em>image</em></a></p><h3 id=mekanisme-yang-dapat-diterapkan-agar-imagepullsecrets-dapat-secara-otomatis-digunakan>Mekanisme yang Dapat Diterapkan agar imagePullSecrets dapat Secara Otomatis Digunakan</h3><p>Kamu dapat secara manual membuat sebuah imagePullSecret, serta merujuk imagePullSecret
yang sudah kamu buat dari sebuah serviceAccount. Semua Pod yang dibuat dengan menggunakan
serviceAccount tadi atau serviceAccount <em>default</em> akan menerima <em>field</em> imagePullSecret dari
serviceAccount yang digunakan.
Bacalah <a href=/id/docs/tasks/configure-pod-container/configure-service-account/#add-imagepullsecrets-to-a-service-account>Cara menambahkan ImagePullSecrets pada sebuah <em>service account</em></a>
untuk informasi lebih detail soal proses yang dijalankan.</p><h3 id=mekanisme-mounting-otomatis-dari-secret-yang-sudah-dibuat>Mekanisme <em>Mounting</em> Otomatis dari Secret yang Sudah Dibuat</h3><p>Secret yang dibuat secara manual (misalnya, secret yang mengandung token yang dapat digunakan
untuk mengakses akun GitHub) dapat di-<em>mount</em> secara otomatis pada sebuah Pod berdasarkan <em>service account</em>
yang digunakan oleh Pod tadi.
Baca <a href=/docs/tasks/inject-data-application/podpreset/>Bagaimana Penggunaan PodPreset untuk Memasukkan Informasi ke Dalam Pod</a> untuk informasi lebih lanjut.</p><h2 id=detail>Detail</h2><h3 id=batasan-batasan>Batasan-Batasan</h3><p>Sumber dari <em>secret volume</em> akan divalidasi untuk menjamin rujukan pada
objek yang dispesifikasikan mengarah pada objek dengan <em>type</em> <code>Secret</code>.
Oleh karenanya, sebuah <em>secret</em> harus dibuat sebelum Pod yang merujuk pada <em>secret</em>
tersebut dibuat.</p><p>Sebuah objek API Secret berada di dalam sebuah <a class=glossary-tooltip title='Sebuah abstraksi yang digunakan oleh Kubernetes untuk mendukung multipel klaster virtual pada klaster fisik yang sama.' data-toggle=tooltip data-placement=top href=/id/docs/concepts/overview/working-with-objects/namespaces target=_blank aria-label=namespace>namespace</a>.
Objek-objek ini hanya dapat dirujuk oleh Pod-Pod yang ada pada namespace yang sama.</p><p>Secret memiliki batasi dalam hal ukuran maksimalnya yaitu hanya sampai 1MiB per objek.
Oleh karena itulah, pembuatan secret dalam ukuran yang sangat besar tidak dianjurkan
karena dapat menghabiskan sumber daya apiserver dan memori kubelet. Meskipun demikian,
pembuatan banyak secret dengan ukuran kecil juga dapat menhabiskan memori. Pembatasan
sumber daya yang diizinkan untuk pembuatan secret merupakan salah satu fitur tambahan
yang direncanakan kedepannya.</p><p>Kubelet hanya mendukung penggunaan secret oleh Pod apabila Pod tersebut
didapatkan melalui apiserver. Hal ini termasuk Pod yang dibuat dengan menggunakan
kubectl, atau secara tak langsung melalui <em>replication controller</em>. Hal ini tidak
termasuk Pod yang dibuat melalui <em>flag</em> <code>--manifest-url</code> yang ada pada kubelet,
maupun REST API yang disediakan (hal ini bukanlah merupakan mekanisme umum yang dilakukan
untuk membuat sebuah Pod).</p><p>Secret harus dibuat sebelum digunakan oleh Pod sebagai variabel <em>environment</em>,
kecuali apabila variabel <em>environment</em> ini dianggap opsional. Rujukan pada Secret
yang tidak dapat dipenuhi akan menyebabkan Pod gagal <em>start</em>.</p><p>Rujukan melalui <code>secretKeyRef</code> pada <em>key</em> yang tidak ada pada <em>named</em> Secret
akan akan menyebabkan Pod gagal <em>start</em>.</p><p>Secret yang digunakan untuk memenuhi variabel <em>environment</em> melalui <code>envFrom</code> yang
memiliki <em>key</em> yang dianggap memiliki penamaan yang tidak valid akan diabaikan.
Hal ini akan akan menyebabkan Pod gagal <em>start</em>. Selanjutnya akan terdapat <em>event</em>
dengan alasan <code>InvalidvariabeleNames</code> dan pesan yang berisikan <em>list</em> dari
<em>key</em> yang diabaikan akibat penamaan yang tidak valid. Contoh yang ada akan menunjukkan
sebuah pod yang merujuk pada secret <code>default/mysecret</code> yang mengandung dua buah <em>key</em>
yang tidak valid, yaitu 1badkey dan 2alsobad.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get events
</span></span></code></pre></div><pre tabindex=0><code>LASTSEEN   FIRSTSEEN   COUNT     NAME            KIND      SUBOBJECT                         TYPE      REASON
0s         0s          1         dapi-test-pod   Pod                                         Warning   InvalidEnvironmentvariabeleNames   kubelet, 127.0.0.1      Keys [1badkey, 2alsobad] from the EnvFrom secret default/mysecret were skipped since they are considered invalid environment variabele names.
</code></pre><h3 id=interaksi-secret-dan-pod-lifetime>Interaksi Secret dan Pod Lifetime</h3><p>Ketika sebuah pod dibuat melalui API, tidak terdapat mekanisme pengecekan
yang digunakan untuk mengetahui apakah sebuah Secret yang dirujuk sudah dibuat
atau belum. Ketika sebuah Pod di-<em>schedule</em>, kubelet akan mencoba mengambil
informasi mengenai <em>value</em> dari secret tadi. Jika secret tidak dapat diambil
<em>value</em>-nya dengan alasan temporer karena hilangnya koneksi ke API server atau
secret yang dirujuk tidak ada, kubelet akan melakukan mekanisme <em>retry</em> secara periodik.
Kubelet juga akan memberikan laporan mengenai <em>event</em> yang terjadi pada Pod serta alasan
kenapa Pod tersebut belum di-<em>start</em>. Apabila Secret berhasil didapatkan, kubelet
akan membuat dan me-<em>mount</em> volume yang mengandung secret tersebut. Tidak akan ada
container dalam pod yang akan di-<em>start</em> hingga semua volume pod berhasil di-<em>mount</em>.</p><h2 id=contoh-contoh-penggunaan>Contoh-Contoh Penggunaan</h2><h3 id=contoh-penggunaan-pod-dengan-ssh-key>Contoh Penggunaan: Pod dengan <em>ssh key</em></h3><p>Buatlah sebuah kustomization.yaml dengan SecretGenerator yang mengandung beberapa <em>ssh key</em>:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl create secret generic ssh-key-secret --from-file<span style=color:#666>=</span>ssh-privatekey<span style=color:#666>=</span>/path/to/.ssh/id_rsa --from-file<span style=color:#666>=</span>ssh-publickey<span style=color:#666>=</span>/path/to/.ssh/id_rsa.pub
</span></span></code></pre></div><pre tabindex=0><code>secret &#34;ssh-key-secret&#34; created
</code></pre><div class="alert alert-warning caution callout" role=alert><strong>Perhatian:</strong> Pikirkanlah terlebih dahulu sebelum kamu menggunakan <em>ssh key</em> milikmu sendiri: pengguna lain pada kluster tersebut bisa saja memiliki akses pada secret yang kamu definisikan.
Gunakanlah service account untuk membagi informasi yang kamu inginkan di dalam kluster tersebut, dengan demikian kamu dapat membatalkan service account tersebut apabila secret tersebut disalahgunakan.</div><p>Sekarang, kita dapat membuat sebuah pod yang merujuk pada secret dengan <em>ssh key</em> yang sudah
dibuat tadi serta menggunakannya melalui sebuah volume yang di-<em>mount</em>:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>secret-test-pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>labels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>secret-test<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>volumes</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>secret-volume<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>secret</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>secretName</span>:<span style=color:#bbb> </span>ssh-key-secret<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>ssh-test-container<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>mySshImage<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>volumeMounts</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>secret-volume<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>readOnly</span>:<span style=color:#bbb> </span><span style=color:#a2f;font-weight:700>true</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>mountPath</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;/etc/secret-volume&#34;</span><span style=color:#bbb>
</span></span></span></code></pre></div><p>Ketika sebuah perintah dijalankan di dalam container, bagian dari <em>key</em> tadi akan
terdapat pada:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>/etc/secret-volume/ssh-publickey
</span></span><span style=display:flex><span>/etc/secret-volume/ssh-privatekey
</span></span></code></pre></div><p>container kemudian dapat menggunakan secret secara bebas untuk
membuat koneksi ssh.</p><h3 id=contoh-penggunaan-pod-dengan-kredensial-prod-test>Contoh Penggunaan: Pod dengan kredensial prod / test</h3><p>Contoh ini memberikan ilustrasi pod yang mengonsumsi secret yang mengandung
kredensial dari <em>environment</em> <em>production</em> atau <em>environment</em> <em>test</em>.</p><p>Buatlah suatu kustomization.yaml dengan SecretGenerator</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl create secret generic prod-db-secret --from-literal<span style=color:#666>=</span><span style=color:#b8860b>username</span><span style=color:#666>=</span>produser --from-literal<span style=color:#666>=</span><span style=color:#b8860b>password</span><span style=color:#666>=</span>Y4nys7f11
</span></span></code></pre></div><pre tabindex=0><code>secret &#34;prod-db-secret&#34; created
</code></pre><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl create secret generic test-db-secret --from-literal<span style=color:#666>=</span><span style=color:#b8860b>username</span><span style=color:#666>=</span>testuser --from-literal<span style=color:#666>=</span><span style=color:#b8860b>password</span><span style=color:#666>=</span>iluvtests
</span></span></code></pre></div><pre tabindex=0><code>secret &#34;test-db-secret&#34; created
</code></pre><div class="alert alert-info note callout" role=alert><strong>Catatan:</strong><p>Karakter spesial seperti <code>$</code>, <code>\*</code>, dan <code>!</code> membutuhkan mekanisme <em>escaping</em>.
Jika password yang kamu gunakan memiliki karakter spesial, kamu dapat melakukan mekanisme <em>escape</em>
dengan karakter <code>\\</code> character. Sebagai contohnya, jika <em>password</em> kamu yang sebenarnya adalah
<code>S!B\*d$zDsb</code>, maka kamu harus memanggil perintah eksekusi dengan cara sebagai berikut:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl create secret generic dev-db-secret --from-literal<span style=color:#666>=</span><span style=color:#b8860b>username</span><span style=color:#666>=</span>devuser --from-literal<span style=color:#666>=</span><span style=color:#b8860b>password</span><span style=color:#666>=</span>S<span style=color:#b62;font-weight:700>\\</span>!B<span style=color:#b62;font-weight:700>\\\*</span>d<span style=color:#b62;font-weight:700>\\</span><span style=color:#b8860b>$zDsb</span>
</span></span></code></pre></div><p>Kamu tidak perlu melakukan mekanisme <em>escape</em> karakter apabila menggunakan opsi melalui <em>file</em> (<code>--from-file</code>).</p></div><p>Kemudian buatlah Pod-Pod yang dibutuhkan:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>$ cat <span style=color:#b44>&lt;&lt;EOF &gt; pod.yaml
</span></span></span><span style=display:flex><span><span style=color:#b44>apiVersion: v1
</span></span></span><span style=display:flex><span><span style=color:#b44>kind: List
</span></span></span><span style=display:flex><span><span style=color:#b44>items:
</span></span></span><span style=display:flex><span><span style=color:#b44>- kind: Pod
</span></span></span><span style=display:flex><span><span style=color:#b44>  apiVersion: v1
</span></span></span><span style=display:flex><span><span style=color:#b44>  metadata:
</span></span></span><span style=display:flex><span><span style=color:#b44>    name: prod-db-client-pod
</span></span></span><span style=display:flex><span><span style=color:#b44>    labels:
</span></span></span><span style=display:flex><span><span style=color:#b44>      name: prod-db-client
</span></span></span><span style=display:flex><span><span style=color:#b44>  spec:
</span></span></span><span style=display:flex><span><span style=color:#b44>    volumes:
</span></span></span><span style=display:flex><span><span style=color:#b44>    - name: secret-volume
</span></span></span><span style=display:flex><span><span style=color:#b44>      secret:
</span></span></span><span style=display:flex><span><span style=color:#b44>        secretName: prod-db-secret
</span></span></span><span style=display:flex><span><span style=color:#b44>    containers:
</span></span></span><span style=display:flex><span><span style=color:#b44>    - name: db-client-container
</span></span></span><span style=display:flex><span><span style=color:#b44>      image: myClientImage
</span></span></span><span style=display:flex><span><span style=color:#b44>      volumeMounts:
</span></span></span><span style=display:flex><span><span style=color:#b44>      - name: secret-volume
</span></span></span><span style=display:flex><span><span style=color:#b44>        readOnly: true
</span></span></span><span style=display:flex><span><span style=color:#b44>        mountPath: &#34;/etc/secret-volume&#34;
</span></span></span><span style=display:flex><span><span style=color:#b44>- kind: Pod
</span></span></span><span style=display:flex><span><span style=color:#b44>  apiVersion: v1
</span></span></span><span style=display:flex><span><span style=color:#b44>  metadata:
</span></span></span><span style=display:flex><span><span style=color:#b44>    name: test-db-client-pod
</span></span></span><span style=display:flex><span><span style=color:#b44>    labels:
</span></span></span><span style=display:flex><span><span style=color:#b44>      name: test-db-client
</span></span></span><span style=display:flex><span><span style=color:#b44>  spec:
</span></span></span><span style=display:flex><span><span style=color:#b44>    volumes:
</span></span></span><span style=display:flex><span><span style=color:#b44>    - name: secret-volume
</span></span></span><span style=display:flex><span><span style=color:#b44>      secret:
</span></span></span><span style=display:flex><span><span style=color:#b44>        secretName: test-db-secret
</span></span></span><span style=display:flex><span><span style=color:#b44>    containers:
</span></span></span><span style=display:flex><span><span style=color:#b44>    - name: db-client-container
</span></span></span><span style=display:flex><span><span style=color:#b44>      image: myClientImage
</span></span></span><span style=display:flex><span><span style=color:#b44>      volumeMounts:
</span></span></span><span style=display:flex><span><span style=color:#b44>      - name: secret-volume
</span></span></span><span style=display:flex><span><span style=color:#b44>        readOnly: true
</span></span></span><span style=display:flex><span><span style=color:#b44>        mountPath: &#34;/etc/secret-volume&#34;
</span></span></span><span style=display:flex><span><span style=color:#b44>EOF</span>
</span></span></code></pre></div><p>Tambahkan Pod-Pod terkait pada <em>file</em> kustomization.yaml yang sama</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>$ cat <span style=color:#b44>&lt;&lt;EOF &gt;&gt; kustomization.yaml
</span></span></span><span style=display:flex><span><span style=color:#b44>resources:
</span></span></span><span style=display:flex><span><span style=color:#b44>- pod.yaml
</span></span></span><span style=display:flex><span><span style=color:#b44>EOF</span>
</span></span></code></pre></div><p>Terapkan semua perubahan pada objek-objek tadi ke Apiserver dengan menggunakan</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl apply --k .
</span></span></code></pre></div><p>Kedua container kemudian akan memiliki <em>file-file</em> berikut ini di dalam
<em>filesystem</em> keduanya dengan <em>value</em> sebagai berikut untuk masing-masing <em>environment</em>:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>/etc/secret-volume/username
</span></span><span style=display:flex><span>/etc/secret-volume/password
</span></span></code></pre></div><p>Perhatikan bahwa <em>specs</em> untuk kedua pod berbeda hanya pada satu <em>field</em> saja;
hal ini bertujuan untuk memfasilitasi adanya kapabilitas yang berbeda dari templat
konfigurasi umum yang tersedia.</p><p>Kamu dapat mensimplifikasi spesifikasi dasar Pod dengan menggunakan dua buah <em>service account</em> yang berbeda:
misalnya saja salah satunya disebut sebagai <code>prod-user</code> dengan <code>prod-db-secret</code>, dan satunya lagi disebut
<code>test-user</code> dengan <code>test-db-secret</code>. Kemudian spesifikasi Pod tadi dapat diringkas menjadi:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>prod-db-client-pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>labels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>prod-db-client<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>serviceAccount</span>:<span style=color:#bbb> </span>prod-db-client<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>db-client-container<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>myClientImage<span style=color:#bbb>
</span></span></span></code></pre></div><h3 id=contoh-penggunaan-dotfiles-pada-volume-secret>Contoh Penggunaan: <em>Dotfiles</em> pada volume secret</h3><p>Dengan tujuan membuat data yang ada 'tersembunyi' (misalnya, di dalam sebuah <em>file</em> dengan nama yang dimulai
dengan karakter titik), kamu dapat melakukannya dengan cara yang cukup sederhana, yaitu cukup dengan membuat
karakter awal <em>key</em> yang kamu inginkan dengan titik. Contohnya, ketika sebuah secret di bawah ini di-<em>mount</em>
pada sebuah volume:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Secret<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>dotfile-secret<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>data</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>.secret-file</span>:<span style=color:#bbb> </span>dmFsdWUtMg0KDQo=<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:#00f;font-weight:700>---</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>secret-dotfiles-pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>volumes</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>secret-volume<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>secret</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>secretName</span>:<span style=color:#bbb> </span>dotfile-secret<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>dotfile-test-container<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>k8s.gcr.io/busybox<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>command</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- ls<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:#b44>&#34;-l&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:#b44>&#34;/etc/secret-volume&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>volumeMounts</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>secret-volume<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>readOnly</span>:<span style=color:#bbb> </span><span style=color:#a2f;font-weight:700>true</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>mountPath</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;/etc/secret-volume&#34;</span><span style=color:#bbb>
</span></span></span></code></pre></div><p>Volume <code>secret-volume</code> akan mengandung sebuah <em>file</em>, yang disebut sebagai <code>.secret-file</code>, serta
container <code>dotfile-test-container</code> akan memiliki <em>file</em> konfigurasinya pada <em>path</em>
<code>/etc/secret-volume/.secret-file</code>.</p><div class="alert alert-info note callout" role=alert><strong>Catatan:</strong> <em>File-file</em> yang diawali dengan karakter titik akan "tersembunyi" dari keluaran perintah <code>ls -l</code>;
kamu harus menggunakan perintah <code>ls -la</code> untuk melihat <em>file-file</em> tadi dari sebuah direktori.</div><h3 id=contoh-penggunaan-secret-yang-dapat-diakses-hanya-pada-salah-satu-container-di-dalam-pod>Contoh Penggunaan: Secret yang dapat diakses hanya pada salah satu container di dalam pod</h3><p>Misalkan terdapat sebuah program yang memiliki kebutuhan untuk menangani <em>request</em> HTTP,
melakukan logika bisnis yang kompleks, serta kemudian menandai beberapa <em>message</em> yang ada
dengan menggunakan HMAC. Karena program ini memiliki logika aplikasi yang cukup kompleks,
maka bisa jadi terdapat beberapa celah terjadinya eksploitasi <em>remote</em> <em>file</em> pada server,
yang nantinya bisa saja mengekspos <em>private key</em> yang ada pada <em>attacker</em>.</p><p>Hal ini dapat dipisah menjadi dua buah proses yang berbeda di dalam dua container:
sebuah container <em>frontend</em> yang menangani interaksi pengguna dan logika bisnis, tetapi
tidak memiliki kapabilitas untuk melihat <em>private key</em>; container lain memiliki kapabilitas
melihat <em>private key</em> yang ada dan memiliki fungsi untuk menandai <em>request</em> yang berasal
dari <em>frontend</em> (melalui jaringan <em>localhost</em>).</p><p>Dengan strategi ini, seorang <em>attacker</em> harus melakukan teknik tambahan
untuk memaksa aplikasi melakukan hal yang acak, yang kemudian menyebabkan
mekanisme pembacaan <em>file</em> menjadi lebih susah.</p><h2 id=best-practices><em>Best practices</em></h2><h3 id=klien-yang-menggunakan-api-secret>Klien yang menggunakan API secret</h3><p>Ketika men-<em>deploy</em> aplikasi yang berinteraksi dengan API secret, akses yang dilakukan
haruslah dibatasi menggunakan <a href=/docs/reference/access-authn-authz/authorization/><em>policy</em> autorisasi</a> seperti <a href=/docs/reference/access-authn-authz/rbac/>RBAC</a>.</p><p>Secret seringkali menyimpan <em>value</em> yang memiliki jangkauan spektrum
kepentingan, yang mungkin saja dapat menyebabkan terjadinya eskalasi baik
di dalam Kubernetes (misalnya saja token dari sebuah <em>service account</em>) maupun<br>sistem eksternal. Bahkan apabila setiap aplikasi secara individual memiliki
kapabilitas untuk memahami tingkatan yang dimilikinya untuk berinteraksi dengan secret tertentu,
aplikasi lain dalam namespace itu bisa saja menyebabkan asumsi tersebut menjadi tidak valid.</p><p>Karena alasan-alasan yang sudah disebutkan tadi <em>request</em> <code>watch</code> dan <code>list</code> untuk sebuah
secret di dalam suatu namespace merupakan kapabilitas yang sebisa mungkin harus dihindari,
karena menampilkan semua secret yang ada berimplikasi pada akses untuk melihat isi yang ada
pada secret yang ada. Kapabilitas untuk melakukan <em>request</em> <code>watch</code> dan <code>list</code> pada semua secret di kluster
hanya boleh dimiliki oleh komponen pada sistem level yang paling <em>previleged</em>.</p><p>Aplikasi yang membutuhkan akses ke API secret harus melakukan <em>request</em> <code>get</code> pada
secret yang dibutuhkan. Hal ini memungkinkan administrator untuk membatasi
akses pada semua secret dengan tetap memberikan <a href=/id/docs/reference/access-authn-authz/rbac/#referring-to-resources>akses pada instans secret tertentu</a>
yang dibutuhkan aplikasi.</p><p>Untuk meningkatkan performa dengan menggunakan iterasi <code>get</code>, klien dapat mendesain
sumber daya yang merujuk pada suatu secret dan kemudian melakukan <code>watch</code> pada secret tersebut,
serta melakukan <em>request</em> secret ketika terjadi perubahan pada rujukan tadi. Sebagai tambahan, <a href=https://github.com/kubernetes/community/blob/master/contributors/design-proposals/api-machinery/bulk_watch.md>API "bulk watch"</a>
yang dapat memberikan kapabilitas <code>watch</code> individual pada sumber daya melalui klien juga sudah direncanakan,
dan kemungkinan akan diimplementasikan dirilis Kubernetes selanjutnya.</p><h2 id=properti-keamanan>Properti Keamanan</h2><h3 id=proteksi>Proteksi</h3><p>Karena objek <code>secret</code> dapat dibuat secara independen dengan <code>pod</code> yang menggunakannya,
risiko tereksposnya secret di dalam workflow pembuatan, pemantauan, serta pengubahan pod.
Sistem yang ada juga dapat memberikan tindakan pencegahan ketika berinteraksi dengan <code>secret</code>,
misalnya saja tidak melakukan penulisan isi <code>secret</code> ke dalam disk apabila hal tersebut
memungkinkan.</p><p>Sebuah secret hanya diberikan pada node apabila pod yang ada di dalam node
membutuhkan secret tersebut. Kubelet menyimpan secret yang ada pada <code>tmpfs</code>
sehingga secret tidak ditulis pada disk. Setelah pod yang bergantung pada secret tersebut dihapus,
maka kubelet juga akan menghapus salinan lokal data secret.</p><p>Di dalam sebuah node bisa saja terdapat beberapa secret yang dibutuhkan
oleh pod yang ada di dalamnya. Meskipun demikian, hanya secret yang di-<em>request</em>
oleh sebuah pod saja yang dapat dilihat oleh container yang ada di dalamnya.
Dengan demikian, sebuah Pod tidak memiliki akses untuk melihat secret yang ada
pada pod yang lain.</p><p>Di dalam sebuah pod bisa jadi terdapat beberapa container.
Meskipun demikian, agar sebuah container bisa mengakses <em>volume secret</em>, container
tersebut haruslah mengirimkan <em>request</em> <code>volumeMounts</code> yang ada dapat diakses dari
container tersebut. Pengetahuan ini dapat digunakan untuk membentuk <a href=#contoh-penggunaan-secret-yang-dapat-diakses-hanya-pada-salah-satu-container-di-dalam-pod>partisi security
pada level pod</a>.</p><p>Pada sebagian besar distribusi yang dipelihara projek Kubernetes,
komunikasi antara pengguna dan apiserver serta apisserver dan kubelet dilindungi dengan menggunakan SSL/TLS.
Dengan demikian, secret dalam keadaan dilindungi ketika ditransmisi.</p><div style=margin-top:10px;margin-bottom:10px><b>FEATURE STATE:</b> <code>Kubernetes v1.13 [beta]</code></div><p>Kamu dapat mengaktifkan <a href=/docs/tasks/administer-cluster/encrypt-data/>enkripsi pada rest</a>
untuk data secret, sehingga secret yang ada tidak akan ditulis ke dalam <a class=glossary-tooltip title='Penyimpanan key value konsisten yang digunakan sebagai penyimpanan data klaster Kubernetes.' data-toggle=tooltip data-placement=top href=/docs/tasks/administer-cluster/configure-upgrade-etcd/ target=_blank aria-label=etcd>etcd</a>
dalam keadaan tidak terenkripsi.</p><h3 id=resiko>Resiko</h3><ul><li>Pada API server, data secret disimpan di dalam <a class=glossary-tooltip title='Penyimpanan key value konsisten yang digunakan sebagai penyimpanan data klaster Kubernetes.' data-toggle=tooltip data-placement=top href=/docs/tasks/administer-cluster/configure-upgrade-etcd/ target=_blank aria-label=etcd>etcd</a>;
dengan demikian:<ul><li>Administrator harus mengaktifkan enkripsi pada rest untuk data kluster (membutuhkan versi v1.13 atau lebih)</li><li>Administrator harus membatasi akses etcd pada pengguna dengan kapabilitas admin</li><li>Administrator bisa saja menghapus data disk yang sudah tidak lagi digunakan oleh etcd</li><li>Jika etcd dijalankan di dalam kluster, administrator harus memastikan SSL/TLS
digunakan pada proses komunikasi peer-to-peer etcd.</li></ul></li><li>Jika kamu melakukan konfigurasi melalui sebuah <em>file</em> manifest (JSON or YAML)
yang menyimpan data secret dalam bentuk base64, membagi atau menyimpan secret ini
dalam repositori kode sumber sama artinya dengan memberikan informasi mengenai data secret.
Mekanisme <em>encoding</em> base64 bukanlah merupakan teknik enkripsi dan nilainya dianggap sama saja dengan <em>plain text</em>.</li><li>Aplikasi masih harus melindungi <em>value</em> dari secret setelah membaca nilainya dari suatu volume
dengan demikian risiko terjadinya <em>logging</em> secret secara tidak engaja dapat dihindari.</li><li>Seorang pengguna yang dapat membuat suatu pod yang menggunakan secret, juga dapat melihat <em>value</em> secret.
Bahkan apabila <em>policy</em> apiserver tidak memberikan kapabilitas untuk membaca objek secret, pengguna
dapat menjalankan pod yang mengekspos secret.</li><li>Saat ini, semua orang dengan akses <em>root</em> pada node dapat membaca secret <em>apapun</em> dari apiserver,<br>dengan cara meniru kubelet. Meskipun begitu, terdapat fitur yang direncanakan pada rilis selanjutnya yang memungkinkan pengiriman secret hanya dapat
mengirimkan secret pada node yang membutuhkan secret tersebut untuk membatasi adanya eksploitasi akses <em>root</em> pada node ini.</li></ul><h2 id=selanjutnya>Selanjutnya</h2></div><div class=td-content style=page-break-before:always><h1 id=pg-ab6d20f33ad930a67ee7ef57bff6c75e>7.4 - Mengatur Akses Klaster Menggunakan Berkas kubeconfig</h1><p>Gunakan berkas kubeconfig untuk mengatur informasi mengenai klaster, pengguna,
<em>namespace</em>, dan mekanisme autentikasi. Perintah <code>kubectl</code> menggunakan berkas
kubeconfig untuk mencari informasi yang dibutuhkan untuk memilih klaster dan
berkomunikasi dengan API server dari suatu klaster.</p><div class="alert alert-info note callout" role=alert><strong>Catatan:</strong> Sebuah berkas yang digunakan untuk mengatur akses pada klaster disebut dengan
berkas kubeconfig. Ini cara yang umum digunakan untuk mereferensikan berkas
konfigurasi. Ini tidak berarti ada berkas dengan nama <code>kubeconfig</code>.</div><p>Secara <em>default</em>, <code>kubectl</code> mencari berkas dengan nama <code>config</code> pada direktori
<code>$HOME/.kube</code>. Kamu bisa mengatur lokasi berkas kubeconfig dengan mengatur
nilai <code>KUBECONFIG</code> pada variabel <em>environment</em> atau dengan mengatur menggunakan
tanda <a href=/docs/reference/generated/kubectl/kubectl/><code>--kubeconfig</code></a>.</p><p>Instruksi langkah demi langkah untuk membuat dan menentukan berkas kubeconfig,
bisa mengacu pada [Mengatur Akses Pada Beberapa Klaster]
(/id/docs/tasks/access-application-cluster/configure-access-multiple-clusters).</p><h2 id=mendukung-beberapa-klaster-pengguna-dan-mekanisme-autentikasi>Mendukung beberapa klaster, pengguna, dan mekanisme autentikasi</h2><p>Misalkan kamu memiliki beberapa klaster, pengguna serta komponen dapat melakukan
autentikasi dengan berbagai cara. Sebagai contoh:</p><ul><li>Kubelet yang berjalan dapat melakukan autentikasi dengan menggunakan sertifikat</li><li>Pengguna bisa melakukan autentikasi dengan menggunakan token</li><li>Administrator bisa memiliki beberapa sertifikat yang diberikan kepada pengguna
individu.</li></ul><p>Dengan berkas kubeconfig, kamu bisa mengatur klaster, pengguna, dan <em>namespace</em>.
Kamu juga bisa menentukan konteks untuk mempercepat dan mempermudah perpindahan
antara klaster dan <em>namespace</em>.</p><h2 id=konteks>Konteks</h2><p>Sebuah elemen konteks pada berkas kubeconfig digunakan untuk mengelompokkan
parameter akses dengan nama yang mudah. Setiap konteks akan memiliki 3 parameter:
klaster, pengguna, dan <em>namespace</em>. Secara <em>default</em>, perintah <code>kubectl</code> menggunakan
parameter dari konteks yang aktif untuk berkomunikasi dengan klaster.</p><p>Untuk memilih konteks yang aktif, bisa menggunakan perintah berikut:</p><pre tabindex=0><code>kubectl config use-context
</code></pre><h2 id=variabel-environment-kubeconfig>Variabel <em>environment</em> KUBECONFIG</h2><p>Variabel <em>environment</em> <code>KUBECONFIG</code> berisikan beberapa berkas kubeconfig. Untuk
Linux dan Mac, beberapa berkas tersebut dipisahkan dengan tanda titik dua (:).
Untuk Windows, dipisahkan dengan menggunakan tanda titik koma (;). Variabel
<em>environment</em> <code>KUBECONFIG</code> tidak diwajibkan untuk ada. Jika variabel <em>environment</em>
<code>KUBECONFIG</code> tidak ada, maka <code>kubectl</code> akan menggunakan berkas kubeconfig pada
<code>$HOME/.kube/config</code>.</p><p>Jika variabel <em>environment</em> <code>KUBECONFIG</code> ternyata ada, maka <code>kubectl</code> akan menggunakan
konfigurasi yang merupakan hasil gabungan dari berkas-berkas yang terdapat pada
variabel <em>environment</em> <code>KUBECONFIG</code>.</p><h2 id=menggabungkan-berkas-berkas-kubeconfig>Menggabungkan berkas-berkas kubeconfig</h2><p>Untuk melihat konfigurasimu, gunakan perintah berikut ini:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl config view
</span></span></code></pre></div><p>Seperti yang dijelaskan sebelumnya, hasil perintah diatas bisa berasal dari sebuah
berkas kubeconfig, atau bisa juga merupakan hasil gabungan dari beberapa berkas kubeconfig.</p><p>Berikut adalah aturan yang digunakan <code>kubectl</code> ketika menggabungkan beberapa berkas
kubeconfig:</p><ol><li><p>Jika menggunakan tanda <code>--kubeconfig</code>, maka akan menggunakan berkas yang ditentukan.
Tidak digabungkan. Hanya 1 tanda <code>--kubeconfig</code> yang diperbolehkan.</p><p>Sebaliknya, jika variabel <em>environment</em> <code>KUBECONFIG</code> digunakan, maka akan menggunakan
ini sebagai berkas-berkas yang akan digabungkan. Penggabungan berkas-berkas yang terdapat
pada variabel <em>environment</em> <code>KUBECONFIG</code> akan mengikuti aturan sebagai berikut:</p><ul><li>Mengabaikan berkas tanpa nama.</li><li>Mengeluarkan pesan kesalahan untuk berkas dengan isi yang tidak dapat dideserialisasi.</li><li>Berkas pertama yang menentukan nilai atau <em>key</em> pada <em>map</em> maka akan digunakan
pada <em>map</em> tersebut.</li><li>Tidak pernah mengubah nilai atau <em>key</em> dari suatu <em>map</em>.
Contoh: Pertahankan konteks pada berkas pertama yang mengatur <code>current-context</code>.
Contoh: Jika terdapat dua berkas yang menentukan nilai <code>red-user</code>, maka hanya gunakan
nilai <code>red-user</code> dari berkas pertama.
Meskipun berkas kedua tidak memiliki entri yang bertentangan pada <code>red-user</code>,
abaikan mereka.</li></ul><p>Beberapa contoh pengaturan variabel <em>environment</em> <code>KUBECONFIG</code>, bisa melihat pada
<a href=/id/docs/tasks/access-application-cluster/configure-access-multiple-clusters/#set-the-kubeconfig-environment-variable>pengaturan vaiabel <em>environment</em> KUBECONFIG</a>.</p><p>Sebaliknya, bisa menggunakan berkas kubeconfig <em>default</em>, <code>$HOME/.kube/config</code>,
tanpa melakukan penggabungan.</p></li><li><p>Konteks ditentukan oleh yang pertama sesuai dari pilihan berikut:</p><ol><li>Menggunakan tanda <code>--context</code> pada perintah</li><li>Menggunakan nilai <code>current-context</code> dari hasil gabungan berkas kubeconfig.</li></ol><p>Konteks yang kosong masih diperbolehkan pada tahap ini.</p></li><li><p>Menentukan klaster dan pengguna. Pada tahap ini, mungkin akan ada atau tidak ada konteks.
Menentukan klaster dan pengguna berdasarkan yang pertama sesuai dengan pilihan berikut,
yang mana akan dijalankan dua kali: sekali untuk pengguna dan sekali untuk klaster:</p><ol><li>Jika ada, maka gunakan tanda pada perintah: <code>--user</code> atau <code>--cluster</code>.</li><li>Jika konteks tidak kosong, maka pengguna dan klaster didapat dari konteks.</li></ol><p>Pengguna dan klaster masih diperbolehkan kosong pada tahap ini.</p></li><li><p>Menentukan informasi klaster sebenarnya yang akan digunakan. Pada tahap ini, mungkin
akan ada atau tidak ada informasi klaster. Membentuk informasi klaster berdasarkan urutan
berikut dan yang pertama sesuai akan digunakan:</p><ol><li>Jika ada, maka gunakan tanda pada perintah: <code>--server</code>, <code>--certificate-authority</code>, <code>--insecure-skip-tls-verify</code>.</li><li>Jika terdapat atribut informasi klaster dari hasil gabungan berkas kubeconfig,
maka gunakan itu.</li><li>Jika tidak terdapat informasi mengenai lokasi server, maka dianggap gagal.</li></ol></li><li><p>Menentukan informasi pengguna sebenarnya yang akan digunakan. Membentuk informasi
pengguna dengan aturan yang sama dengan pembentukan informasi klaster, namun hanya
diperbolehkan ada satu teknik autentikasi untuk setiap pengguna:</p><ol><li>Jika ada, gunakan tanda pada perintah: <code>--client-certificate</code>, <code>--client-key</code>, <code>--username</code>, <code>--password</code>, <code>--token</code>.</li><li>Menggunakan <em>field</em> <code>user</code> dari hasil gabungan berkas kubeconfig.</li><li>Jika terdapat dua teknik yang bertentangan, maka dianggap gagal.</li></ol></li><li><p>Untuk setiap informasi yang masih belum terisi, akan menggunakan nilai <code>default</code> dan
kemungkinan akan meminta informasi autentikasi.</p></li></ol><h2 id=referensi-berkas>Referensi berkas</h2><p>Referensi <em>file</em> dan <em>path</em> pada berkas kubeconfig adalah bernilai relatif terhadap
lokasi dari berkas kubeconfig.
Referensi <em>file</em> pada perintah adalah relatif terhadap direktori kerja saat ini.
Dalam <code>$HOME/.kube/config</code>, <em>relative path</em> akan disimpan secara relatif, dan
<em>absolute path</em> akan disimpan secara mutlak.</p><h2 id=selanjutnya>Selanjutnya</h2><ul><li><a href=/id/docs/tasks/access-application-cluster/configure-access-multiple-clusters/>Mengatur Akses Pada Beberapa Klaster</a></li><li><a href=/docs/reference/generated/kubectl/kubectl-commands#config><code>kubectl config</code></a></li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-ed4ae5e4344d619bc6df6e1278efae74>7.5 - Prioritas dan Pemindahan Pod</h1><div style=margin-top:10px;margin-bottom:10px><b>FEATURE STATE:</b> <code>Kubernetes 1.14 [stable]</code></div><p><a href=/docs/user-guide/pods>Pod</a> dapat memiliki <em>priority</em> (prioritas). Priority mengindikasikan lebih penting atau tidaknya sebuah Pod dibandingkan dengan Pod-pod lainnya. Jika sebuah Pod tidak dapat dijadwalkan (tertunda/<em>pending</em>), penjadwal akan mencoba untuk melakukan <em>preemption</em>/pemindahan (mengusir/<em>evict</em>) Pod-pod dengan prioritas lebih rendah agar penjadwalan Pod yang tertunda sebelumnya dapat dilakukan.</p><p>Pada Kubernetes 1.9 dan sesudahnya, Priority juga memengaruhi urutan penjadwalan Pod-pod dan urutan pengusiran Pod-pod dari Node pada kasus kehabisan sumber daya.</p><p>Priority dan Pemindahan Pod lulus menjadi <em>beta</em> pada Kubernetes 1.11 dan menjadi GA (<em>Generally Available</em>) pada Kubernetes 1.14. Mereka telah dihidupkan secara bawaan sejak versi 1.11.</p><p>Pada versi-versi Kubernetes di mana Priority dan pemindahan Pod masih berada pada tingkat fitur <em>alpha</em>, kamu harus menghidupkannya secara eksplisit. Untuk menggunakan fitur-fitur pada versi-versi lama Kubernetes, ikuti petunjuk di dokumentasi versi Kubernetes kamu, melalui arsip versi dokumentasi untuk versi Kubernetes kamu.</p><table><thead><tr><th>Versi Kubernetes</th><th style=text-align:center>Keadaan Priority and Pemindahan</th><th style=text-align:center>Dihidupkan secara Bawaan</th></tr></thead><tbody><tr><td>1.8</td><td style=text-align:center>alpha</td><td style=text-align:center>tidak</td></tr><tr><td>1.9</td><td style=text-align:center>alpha</td><td style=text-align:center>tidak</td></tr><tr><td>1.10</td><td style=text-align:center>alpha</td><td style=text-align:center>tidak</td></tr><tr><td>1.11</td><td style=text-align:center>beta</td><td style=text-align:center>ya</td></tr><tr><td>1.14</td><td style=text-align:center>stable</td><td style=text-align:center>ya</td></tr></tbody></table><div class="alert alert-danger warning callout" role=alert><strong>Peringatan:</strong> Pada sebuah klaster di mana tidak semua pengguna dipercaya, seorang pengguna yang berniat jahat dapat membuat Pod-pod dengan prioritas paling tinggi, membuat Pod-pod lainnya dipindahkan/tidak dapat dijadwalkan. Untuk mengatasi masalah ini, <a href=/id/docs/concepts/policy/resource-quotas/>ResourceQuota</a> ditambahkan untuk mendukung prioritas Pod. Seorang admin dapat membuat ResourceQuota untuk pengguna-pengguna pada tingkat prioritas tertentu, mencegah mereka untuk membuat Pod-pod pada prioritas tinggi. Fitur ini telah beta sejak Kubernetes 1.12.</div><h2 id=bagaimana-cara-menggunakan-priority-dan-pemindahan-pod>Bagaimana cara menggunakan Priority dan pemindahan Pod</h2><p>Untuk menggunakan Priority dan pemindahan Pod pada Kubernetes 1.11 dan sesudahnya, ikuti langkah-langkah berikut:</p><ol><li><p>Tambahkan satu atau lebih <a href=#priorityclass>PriorityClass</a>.</p></li><li><p>Buat Pod-pod dengan <a href=#prioritas-pod><code>priorityClassName</code></a>
disetel menjadi salah satu dari PriorityClass yang ditambahkan.
Tentu saja kamu tidak perlu membuat Pod-pod tersebut secara langsung;
Biasanya kamu akan menambahkan <code>priorityClassName</code> pada
<code>template</code> Pod dari sebuah objek kumpulan seperti sebuah Deployment.</p></li></ol><p>Teruslah membaca untuk lebih banyak informasi mengenai langkah-langkah tersebut.</p><p>Jika kamu mencoba fitur ini dan memutuskan untuk mematikannya, kamu harus menghapus <em>command-line flag</em> PodPriority atau menyetelnya menjadi <code>false</code>, kemudian melakukan pengulangan kembali terhadap API Server dan Scheduler. Setelah fitur ini dimatikan, Pod-pod yang sudah ada tetap akan memiliki kolom priority mereka, tetapi pemindahan Pod akan dimatikan, dan kolom-kolom priority tersebut diabaikan. Jika fitur tersebut telah dimatikan, kamu tidak dapat menyetel kolom <code>priorityClassName</code> pada Pod-pod baru.</p><h2 id=cara-mematikan-pemindahan-pod>Cara mematikan pemindahan Pod</h2><div class="alert alert-info note callout" role=alert><strong>Catatan:</strong> Pada Kubernetes 1.12 ke atas, Pod-pod yang penting mengandalkan oleh Schneduler agar dapat dijadwalkan saat klaster berada pada kondisi kekurangan sumber daya. Untuk alasan ini, tidak direkomendasikan untuk mematikan fitur pemindahan Pod.</div><div class="alert alert-info note callout" role=alert><strong>Catatan:</strong> Pada Kubernetes 1.15 ke atas, jika fitur <code>NonPreemptingPriority</code> diaktifkan, PriorityClass memiliki pilihan untuk menyetel <code>preemptionPolicy: Never</code>.
Hal ini akan mencegah Pod-pod dari PriorityClass tersebut untuk memicu pemindahan Pod-pod lainnya.</div><p>Pada Kubernetes 1.11 dan sesudahnya, pemindahan Pod dikontrol oleh sebuah <em>flag</em> kube-scheduler yaitu <code>disablePreemption</code>, yang disetel menjadi <code>false</code> secara bawaan. Jika kamu ingin mematikan pemindahan Pod meskipun ada catatan di atas, kamu dapat menyetel <code>disablePreemption</code> menjadi <code>true</code>.</p><p>Opsi ini hanya tersedia pada (berkas) konfigurasi komponen saja, dan tidak tersedia pada cara lama melalui <em>command line options</em>. Berikut contoh konfigurasi komponen untuk mematikan pemindahan (<em>preemption</em>) Pod:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>kubescheduler.config.k8s.io/v1alpha1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>KubeSchedulerConfiguration<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>algorithmSource</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>provider</span>:<span style=color:#bbb> </span>DefaultProvider<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:#00f;font-weight:700>...</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>disablePreemption</span>:<span style=color:#bbb> </span><span style=color:#a2f;font-weight:700>true</span><span style=color:#bbb>
</span></span></span></code></pre></div><h2 id=priorityclass>PriorityClass</h2><p>Sebuah PriorityClass adalah sebuah objek tanpa Namespace yang mendefinisikan pemetaan dari sebuah nama kelas prioritas menjadi nilai <em>integer</em> dari prioritas tersebut. Nama tersebut dirinci pada kolom <code>name</code> dari <code>metadata</code> objek PriorityClass tersebut. Nilainya dirinci pada kolom <code>value</code> yang diperlukan. Semakin tinggi nilainya, maka semakin tinggi juga prioritasnya.</p><p>Sebuah objek PriorityClass dapat memiliki nilai <em>integer</em> 32-bit apa pun yang kurang dari atau sama dengan 1 miliar. Angka-angka yang lebih besar dicadangkan untuk Pod-pod pada sistem yang sangat penting yang secara normal sebaiknya tidak dipindahkan atau diusir. Seorang admin klaster sebaiknya membuat sebuah objek PriorityClass untuk setiap pemetaan seperti ini yang ia inginkan.</p><p>PriorityClass juga memiliki dua kolom opsional: <code>globalDefault</code> dan <code>description</code>. Kolom <code>globalDefault</code> mengindikasikan bahwa nilai PriorityClass ini sebaiknya digunakan tanpa sebuah <code>priorityClassName</code>. Hanya sebuah PriorityClass dengan <code>globalDefault</code> disetel menjadi <code>true</code> dapat berada pada sistem/klaster. Jika tidak ada PriorityClass dengan <code>globalDefault</code> yang telah disetel, prioritas Pod-pod tanpa <code>priorityClassName</code> adalah nol.</p><p>Kolom <code>description</code> adalah <em>string</em> yang sembarang. Kolom ini diperuntukkan untuk memberitahukan pengguna-pengguna klaster kapan mereka harus menggunakan PriorityClass ini.</p><h3 id=catatan-mengenai-podpriority-dan-klaster-klaster-yang-sudah-ada>Catatan mengenai PodPriority dan Klaster-klaster yang sudah ada</h3><ul><li><p>Jika kamu meningkatkan versi klaster kamu dan menghidupkan fitur ini, prioritas
Pod-pod kamu yang sudah ada akan secara efektif menjadi nol.</p></li><li><p>Penambahan dari sebuah PriorityClass dengan <code>globalDefault</code> yang disetel menjadi
<code>true</code> tidak mengubah prioritas-prioritas Pod-pod yang sudah ada. Nilai dari
PriorityClass semacam ini digunakan hanya untuk Pod-pod yang dibuat setelah
PriorityClass tersebut ditambahkan.</p></li><li><p>Jika kamu menghapus sebuah PriorityClass, Pod-pod yang sudah ada yang menggunakan
nama dari PriorityClass yang dihapus tersebut tidak akan berubah, tetapi kamu tidak
dapat membuat lebih banyak Pod yang menggunakan nama dari PriorityClass yang telah
dihapus tersebut.</p></li></ul><h3 id=contoh-priorityclass>Contoh PriorityClass</h3><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>scheduling.k8s.io/v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>PriorityClass<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>high-priority<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>value</span>:<span style=color:#bbb> </span><span style=color:#666>1000000</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>globalDefault</span>:<span style=color:#bbb> </span><span style=color:#a2f;font-weight:700>false</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>description</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;Kelas prioritas ini sebaiknya hanya digunakan untuk Pod-pod layanan XYZ saja.&#34;</span><span style=color:#bbb>
</span></span></span></code></pre></div><h3 id=non-preempting-priority-class>PriorityClass yang <em>Non-preempting</em> (alpha)</h3><p>Kubernetes 1.15 menambahkan kolom <code>PreemptionPolicy</code> sebagai sebuah fitur <em>alpha</em>. Fitur ini dimatikan secara bawaan pada 1.15, dan membutuhkan diaktifkannya <a href=/docs/reference/command-line-tools-reference/feature-gates/><em>feature gate</em></a> <code>NonPreemptingPriority</code>.</p><p>Pod-pod dengan <code>PreemptionPolicy: Never</code> akan ditaruh pada antrean penjadwalkan mendahului Pod-pod dengan prioritas rendah, tetapi mereka tidak dapat memicu pemindahan Pod-pod lainnya (disebut juga Pod yang <em>non-preempting</em>).
Sebuah Pod yang <em>non-preempting</em> yang sedang menunggu untuk dijadwalkan akan tetap berada pada antrean penjadwalan, hingga sumber daya yang cukup tersedia, dan ia dapat dijadwalkan. Pod yang <em>non-preempting</em>, seperti Pod-pod lainnya, tunduk kepada <em>back-off</em> dari Scheduler. Hal ini berarti bahwa jika Scheduler mencoba untuk menjadwalkan Pod-pod ini dan mereka tidak dapat dijadwalkan, mereka akan dicoba kembali dengan frekuensi (percobaan) yang lebih rendah, memungkinkan Pod-pod lain dengan prioritas yang lebih rendah untuk dijadwalkan sebelum mereka dijadwalkan.</p><p>Pod yang <em>non-preempting</em> tetap dapat dipicu untuk dipindahkan oleh Pod lainnya yang memiliki prioritas yang lebih tinggi.</p><p><code>PreemptionPolicy</code> secara bawaan nilainya <code>PreemptionLowerPriority</code>, yang memungkinkan Pod-pod dengan PriorityClass tersebut untuk memicu pemindahan Pod-pod dengan prioritas lebih rendah (sama seperti sifat bawaan). Jika <code>PreemptionPolicy</code> disetel menjadi <code>Never</code>, Pod-pod pada PriorityClass tersebut akan menjadi Pod yang <em>non-preempting</em>.</p><p>Sebuah contoh kasus misalnya pada beban kerja <em>data science</em>.
Seorang pengguna dapat memasukkan sebuah beban kerja yang mereka ingin prioritaskan di atas beban kerja lainnya, tetapi tidak ingin menghapus beban kerja yang sudah ada melalui pemicuan pemindahan Pod-pod yang sedang berjalan.
Beban kerja prioritas tinggi dengan <code>PreemptionPolicy: Never</code> akan dijadwalkan mendahului Pod-pod lainnya yang berada dalam antrean, segera setelah sumber daya klaster "secara alami" menjadi cukup.</p><h4 id=contoh-priorityclass-yang-non-preempting>Contoh PriorityClass yang <em>Non-preempting</em></h4><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>scheduling.k8s.io/v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>PriorityClass<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>high-priority-nonpreempting<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>value</span>:<span style=color:#bbb> </span><span style=color:#666>1000000</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>preemptionPolicy</span>:<span style=color:#bbb> </span>Never<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>globalDefault</span>:<span style=color:#bbb> </span><span style=color:#a2f;font-weight:700>false</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>description</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;Kelas prioritas ini tidak akan memicu pemindahan Pod-pod lainnya.&#34;</span><span style=color:#bbb>
</span></span></span></code></pre></div><h2 id=prioritas-pod>Prioritas Pod</h2><p>Setelah kamu memiliki satu atau lebih PriorityClass, kamu dapat membuat Pod-pod yang merinci satu dari nama-nama PriorityClass tersebut pada spesifikasi mereka. Admission Controller prioritas menggunakan kolom <code>priorityClassName</code> dan mengumpulkan nilai <em>integer</em> dari prioritasnya. Jika PriorityClass-nya tidak ditemukan, maka Pod tersebut akan ditolak.</p><p>YAML berikut adalah contoh sebuah konfigurasi Pod yang menggunakan PriorityClass yang telah dibuat pada contoh sebelumnya. Admission Controller prioritas akan memeriksa spesifikasi tersebut dan memetakan prioritas Pod tersebut menjadi nilai 1000000.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>nginx<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>labels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>env</span>:<span style=color:#bbb> </span>test<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>nginx<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>nginx<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>imagePullPolicy</span>:<span style=color:#bbb> </span>IfNotPresent<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>priorityClassName</span>:<span style=color:#bbb> </span>high-priority<span style=color:#bbb>
</span></span></span></code></pre></div><h3 id=efek-prioritas-pod-terhadap-urutan-penjadwalan>Efek prioritas Pod terhadap urutan penjadwalan</h3><p>Pada Kubernetes 1.9 dan sesudahnya, saat prioritas Pod dihidupkan, Scheduler mengurutkan Pod-pod yang tertunda berdasarkan prioritas mereka dan sebuah Pod yang tertunda diletakkan mendahului Pod-pod tertunda lainnya yang memiliki prioritas yang lebih rendah pada antrean penjadwalan. Sebagai hasilnya, Pod dengan prioritas lebih tinggi dapat dijadwalkan lebih awal daripada Pod-pod dengan prioritas yang lebih rendah jika syarat penjadwalan terpenuhi. Jika Pod ini tidak dapat dijadwalkan, Scheduler akan melewatkannya dan mencoba untuk menjadwalkan Pod-pod lain dengan prioritas yang lebih rendah.</p><h2 id=pemindahan-pod>Pemindahan Pod</h2><p>Saat Pod-pod dibuat, mereka masuk ke sebuah antrean dan menunggu untuk dijadwalkan. Scheduler memilih sebuah Pod dari antrean dan mencoba untuk menjadwalkannya pada sebuah Node. Jika tidak ditemukan Node yang memenuhi semua kebutuhan Pod tersebut, logika program pemindahan Pod dipicu untuk Pod yang tertunda tersebut. Kita akan menyebut Pod tertunda tersebut dengan P. Logika program pemindahan Pod mencoba untuk menemukan sebuah Node di mana penghapusan dari satu atau lebih Pod dengan prioritas yang lebih rendah daripada P dapat memungkinkan P untuk dijadwalkan pada Node tersebut. Jika Node tersebut ditemukan, satu atau lebih Pod dengan prioritas lebih rendah akan dipindahkan dari Node tersebut. Setelah Pod-pod tersebut dihapus, P dapat dijadwalkan pada Node tersebut.</p><h3 id=informasi-yang-diekspos-pengguna>Informasi yang diekspos pengguna</h3><p>Saat Pod P memicu pemindahan satu atau lebih Pod pada Node N, kolom <code>nominatedNodeName</code> pada status Pod P disetel menjadi nama dari node N. Kolom ini membantu Scheduler untuk melacak sumber daya yang dicadangkan untuk Pod P dan juga memberikan informasi mengenai pemindahan Pod pada klaster untuk pengguna-pengguna.</p><p>Harap catat bahwa Pod P tidak harus dijadwalkan pada "<em>nominated</em> Node" (Node yang dicalonkan) tersebut. Setelah Pod-pod yang terpilih telah dipindahkan, mereka akan mendapatkan periode penghentian secara sopan (<em>graceful</em>) mereka. Jika Node lain menjadi tersedia saat Scheduler sedang menunggu penghentian Pod-pod yang terpilih untuk dipindahkan, Scheduler akan menggunakan Node lain tersebut untuk menjadwalkan Pod P. Sebagai hasilnya <code>nominatedNodeName</code> dan <code>nodeName</code> dari spesifikasi Pod belum tentu selalu sama. Juga, jika Scheduler memindahkan Pod-pod pada Node N, tapi kemudian sebuah Pod lain dengan prioritas lebih tinggi daripada Pod P tiba, Scheduler boleh memberikan Node N kepada Pod dengan prioritas lebih tinggi tersebut. Pada kasus demikian, Scheduler menghapus <code>nominatedPodName</code> dari Pod P. Dengan melakukan ini, Scheduler membuat Pod P berhak untuk memicu pemindahan Pod-pod lain pada Node lain.</p><h3 id=batasan-batasan-pemindahan-pod>Batasan-batasan pemindahan Pod</h3><h4 id=penghentian-secara-sopan-dari-korban-korban-pemindahan-pod>Penghentian secara sopan dari korban-korban pemindahan Pod</h4><p>Saat Pod-pod dipindahkan, korban-korbannya mendapatkan <a href=/id/docs/concepts/workloads/pods/pod/#penghentian-pod>periode penghentian secara sopan</a>. Mereka memiliki waktu sebanyak itu untuk menyelesaikan pekerjaan merekan dan berhenti. Jika mereka tidak menyelesaikannya sebelum waktu tersebut, mereka akan dihentikan secara paksa. Periode penghentian secara sopan ini membuat sebuah jarak waktu antara saat di mana Scheduler memindahkan Pod-pod dengan waktu saat Pod yang tertunda tersebut (P) dapat dijadwalkan pada Node tersebut (N). Sementara itu, Scheduler akan terus menjadwalkan Pod-pod lain yang tertunda. Oleh karena itu, biasanya ada jarak waktu antara titik di mana Scheduler memindahkan korban-korban dan titik saat Pod P dijadwalkan. Untuk meminimalkan jarak waktu ini, kamu dapat menyetel periode penghentian secara sopan dari Pod-pod dengan prioritas lebih rendah menjadi nol atau sebuah angka yang kecil.</p><h4 id=poddisruptionbudget-didukung-tapi-tidak-dijamin>PodDisruptionBudget didukung, tapi tidak dijamin!</h4><p>Sebuah <a href=/id/docs/concepts/workloads/pods/disruptions/>Pod Disruption Budget (PDB)</a> memungkinkan pemilik-pemilik aplikasi untuk membatasi jumlah Pod-pod dari sebuah aplikasi yang direplikasi yang mati secara bersamaan dikarenakan disrupsi yang disengaja. Kubernetes 1.9 mendukung PDB saat memindahkan Pod-pod, tetapi penghormatan terhadap PDB ini bersifat "usaha terbaik" (<em>best-effort</em>). Scheduler akan mencoba mencari korban-korban yang PDB-nya tidak dilanggar oleh pemindahan, tetapi jika tidak ada korban yang ditemukan, pemindahan akan tetap terjadi, dan Pod-pod dengan prioritas lebih rendah akan dihapus/dipindahkan meskipun PDB mereka dilanggar.</p><h4 id=afinitas-antar-pod-pada-pod-pod-dengan-prioritas-lebih-rendah>Afinitas antar-Pod pada Pod-pod dengan prioritas lebih rendah</h4><p>Sebuah Node akan dipertimbangkan untuk pemindahan Pod hanya jika jawaban pertanyaan berikut adalah "ya": "Jika semua Pod-pod dengan prioritas lebih rendah dari Pod yang tertunda dipindahkan dari Node, dapatkan Pod yang tertunda tersebut dijadwalkan (secara sukses) ke Node tersebut?"</p><div class="alert alert-info note callout" role=alert><strong>Catatan:</strong> Pemindahan Pod tidak harus memindahkan semua Pod-pod dengan prioritas lebih rendah. Jika Pod yang tertunda dapat dijadwalkan dengan memindahkan lebih sedikit daripada semua Pod-pod dengan prioritas yang lebih rendah, maka hanya sebagian dari Pod-pod dengan prioritas lebih rendah tersebut akan dipindahkan. Meskipun demikian, jawaban untuk pertanyaan sebelumnya haruslah "ya". Jika jawabannya adalah "tidak", maka Node tersebut tidak akan dipertimbangkan untuk pemindahan Pod.</div><p>Jika sebuah Pod yang tertunda memiliki afinitas antar-Pod terhadap satu atau lebih dari Pod-pod dengan prioritas lebih rendah pada Node tersebut, maka aturan afinitas antar-Pod tersebut tidak dapat terpenuhi tanpa hadirnya Pod-pod dengan prioritas lebih rendah tersebut. Pada kasus ini, Scheduler tidak melakukan pemindahan terhadap Pod-pod manapun pada Node tersebut. Sebagai gantinya, ia mencari Node lainnya. Scheduler mungkin mendapatkan Node yang cocok atau tidak. Tidak ada jaminan bahwa Pod yang tertunda tersebut dapat dijadwalkan.</p><p>Solusi yang direkomendasikan untuk masalah ini adalah dengan cara membuat afinitas antar-Pod hanya terhadap Pod-pod dengan prioritas yang sama atau lebih tinggi.</p><h4 id=pemindahan-pod-antar-node>Pemindahan Pod antar Node</h4><p>Misalnya sebuah Node N sedang dipertimbangkan untuk pemindahan Pod sehingga sebuah Pod P yang tertunda dapat dijadwalkan pada N. P mungkin menjadi layak untuk N hanya jika sebuah Pod pada Node lain dipindahkan. Berikut sebuah contoh:</p><ul><li>Pod P dipertimbangkan untuk Node N.</li><li>Pod Q sedang berjalan pada Node lain pada Zona yang sama dengan Node N.</li><li>Pod P memiliki anti-afinitas yang berlaku pada seluruh Zona terhadap Pod Q (<code>topologyKey: topology.kubernetes.io/zone</code>).</li><li>Tidak ada kasus anti-afinitas lain antara Pod P dengan Pod-pod lainnya pada Zona tersebut.</li><li>Untuk dapat menjadwalkan Pod P pada Node N, Pod Q dapat dipindahkan, tetapi
Scheduler tidak melakukan pemindahan Pod antar Node. Jadi, Pod P akan
dianggap tidak dapat dijadwalkan pada Node N.</li></ul><p>Jika Pod Q dihapus dari Node-nya, pelanggaran terhadap anti-afinitas Pod tersebut akan hilang, dan Pod P dapat dijadwalkan pada Node N.</p><p>Kita mungkin mempertimbangkan untuk menambahkan pemindahan Pod antar Node pada versi-versi yang akan datang jika ada permintaan yang cukup dari pengguna, dan kami menemukan algoritma dengan kinerja yang layak.</p><h2 id=memecahkan-masalah-pada-prioritas-dan-pemindahan-pod>Memecahkan masalah pada Prioritas dan Pemindahan Pod</h2><p>Prioritas dan Pemindahan Pod adalah sebuah fitur besar yang berpotensi dapat mengganggu penjadwalan Pod jika fitur ini memiliki kesalahan (<em>bug</em>).</p><h3 id=masalah-yang-berpotensi-diakibatkan-oleh-prioritas-dan-pemindahan-pod>Masalah yang berpotensi diakibatkan oleh Prioritas dan Pemindahan Pod</h3><p>Berikut adalah beberapa masalah yang dapat diakibatkan oleh kesalahan-kesalahan pada implementasi fitur ini. Daftar ini tidak lengkap.</p><h4 id=pod-pod-dipindahkan-secara-tidak-perlu>Pod-pod dipindahkan secara tidak perlu</h4><p>Pemindahan Pod menghapus Pod-pod yang sudah ada dari sebuah klaster yang sedang mengalami kekurangan sumber daya untuk menyediakan ruangan untuk Pod-pod tertunda yang memiliki prioritas yang lebih tinggi. Jika seorang pengguna memberikan prioritas-prioritas tinggi untuk Pod-pod tertentu dengan tidak semestinya (karena kesalahan), Pod-pod prioritas tinggi yang tidak disengaja tersebut dapat mengakibatkan pemindahan Pod-pod pada klaster tersebut. Seperti disebutkan di atas, prioritas Pod dispesifikasikan dengan menyetel kolom <code>priorityClassName</code> dari <code>podSpec</code>. Nilai <em>integer</em> dari prioritas tersebut kemudian dipetakan dan diisi pada kolom <code>priority</code> dari <code>podSpec</code>.</p><p>Untuk menyelesaikan masalah tersebut, <code>priorityClassName</code> dari Pod-pod tersebut harus diubah untuk menggunakan kelas dengan prioritas yang lebih rendah, atau dibiarkan kosong saja. Kolom <code>priorityClassName</code> yang kosong dipetakan menjadi nol secara bawaan.</p><p>Saat sebuah Pod dipindahkan, akan ada <em>Event</em> yang direkam untuk Pod yang dipindahkan tersebut. Pemindahan seharusnya hanya terjadi saat sebuah klaster tidak memiliki sumber daya yang cukup untuk sebuah Pod. Pada kasus seperti ini, pemindahan terjadi hanya saat prioritas dari Pod yang tertunda tersebut lebih tinggi daripada Pod-pod korban. Pemindahan tidak boleh terjadi saat tidak ada Pod yang tertunda (<em>preemptor</em>), atau saat Pod-pod yang tertunda memiliki prioritas yang sama atau lebih rendah dari korban-korbannya. Jika pemindahan terjadi pada skenario demikian, mohon daftarkan sebuah Issue.</p><h4 id=pod-pod-dipindahkan-tetapi-preemptor-tidak-dijadwalkan>Pod-pod dipindahkan, tetapi <em>preemptor</em> tidak dijadwalkan</h4><p>Saat Pod-pod dijadwalkan, mereka menerima periode penghentian secara sopan mereka, yang secara bawaan bernilai 30 detik, tetapi dapat bernilai apa pun sesuai dengan yang disetel pada PodSpec. Jika Pod-pod korban tidak berhenti sebelum periode ini, mereka akan dihentikan secara paksa. Saat semua korban telah pergi, Pod <em>preemptor</em> dapat dijadwalkan.</p><p>Saat Pod <em>preemptor</em> sedang menunggu korban-korban dipindahkan, sebuah Pod dengan prioritas lebih tinggi boleh dibuat jika muat pada Node yang sama. Pada kasus ini, Scheduler akan menjadwalkan Pod dengan prioritas lebih tinggi tersebut alih-alih menjadwalkan Pod <em>preemptor</em>.</p><p>Dalam ketidakhadiran Pod dengan prioritas lebih tinggi tersebut, kita mengharapkan Pod <em>preemptor</em> dijadwalkan setelah periode penghentian secara sopan korban-korbannya telah berakhir.</p><h4 id=pod-pod-dengan-prioritas-lebih-tinggi-dipindahkan-karena-pod-pod-dengan-prioritas-lebih-rendah>Pod-pod dengan prioritas lebih tinggi dipindahkan karena Pod-pod dengan prioritas lebih rendah</h4><p>Saat Scheduler mencoba mencari Node-node yang dapat menjalankan sebuah Pod yang tertunda, dan tidak ada Node yang ditemukan, ia akan mencoba untuk memindahkan Pod-pod dengan prioritas lebih rendah dari salah satu Node untuk menyediakan ruangan untuk Pod yang tertunda tersebut. Jika sebuah Node dengan Pod-pod dengan prioritas lebih rendah tidak layak untuk menjalankan Pod yang tertunda tersebut, Scheduler mungkin memilih Node lain dengan Pod yang memiliki prioritas lebih tinggi (dibandingkan dengan Pod-pod pada Node lain tadi) untuk dipindahkan. Korban-korban tersebut harus tetap memiliki prioritas yang lebih rendah dari Pod <em>preemptor</em>.</p><p>Saat ada beberapa Node yang tersedia untuk pemindahan, Scheduler mencoba untuk memilih Node dengan kumpulan Pod yang memiliki prioritas paling rendah. Namun, jika Pod-pod tersebut memiliki PodDisruptionBudget yang akan dilanggar apabila mereka dipindahkan, maka Scheduler akan memilih Node lain dengan Pod-pod yang memiliki prioritas lebih tinggi.</p><p>Saat ada beberapa Node tersedia untuk pemindahan dan tidak ada satupun skenario di atas yang berlaku, kita mengharapkan Scheduler memilih Node dengan prioritas paling rendah. Apabila hal tersebut tidak terjadi, hal ini mungkin menunjukkan bahwa terdapat kesalahan pada Scheduler.</p><h2 id=interaksi-interaksi-prioritas-pod-dan-qos>Interaksi-interaksi prioritas Pod dan QoS</h2><p>Prioritas Pod dan <a href=https://github.com/kubernetes/community/blob/master/contributors/design-proposals/node/resource-qos.md>QoS</a> adalah dua fitur terpisah dengan interaksi yang sedikit dan tidak ada batasan bawaan terhadap penyetelan prioritas Pod berdasarkan kelas QoS-nya. Logika program pemindahan Scheduler tidak mempertimbangkan QoS saat memilih sasaran-sasaran pemindahan. Pemindahan mempertimbangkan prioritas Pod dan mencoba memilih kumpulan sasaran dengan prioritas terendah. Pod-pod dengan prioritas lebih tinggi dipertimbangkan untuk pemindahan hanya jika penghapusan Pod-pod dengan prioritas terendah tidak cukup untuk memungkinkan Scheduler untuk menjadwalkan Pod <em>preemptor</em>, atau jika Pod-pod dengan prioritas terendah tersebut dilindungi oleh <code>PodDisruptionBudget</code>.</p><p>Komponen satu-satunya yang mempertimbangkan baik QoS dan prioritas Pod adalah <a href=/docs/tasks/administer-cluster/out-of-resource/>pengusiran oleh Kubelet karena kehabisan sumber daya</a>.
Kubelet menggolongkan Pod-pod untuk pengusiran pertama-tama berdasarkan apakah penggunaan sumber daya mereka melebihi <code>requests</code> mereka atau tidak, kemudian berdasarkan Priority, dan kemudian berdasarkan penggunaan sumber daya yang terbatas tersebut relatif terhadap <code>requests</code> dari Pod-pod tersebut.
Lihat <a href=/docs/tasks/administer-cluster/out-of-resource/#mengusir-pod-pod-pengguna>Mengusir Pod-pod pengguna</a> untuk lebih detail. Pengusiran oleh Kubelet karena kehabisan sumber daya tidak mengusir Pod-pod yang memiliki penggunaan sumber daya yang tidak melebihi <code>requests</code> mereka. Jika sebuah Pod dengan prioritas lebih rendah tidak melebihi <code>requests</code>-nya, ia tidak akan diusir. Pod lain dengan prioritas lebih tinggi yang melebihi <code>requests</code>-nya boleh diusir.</p></div><div class=td-content style=page-break-before:always><h1 id=pg-712cb3c03ff14a39e5a83a6d9b71d203>8 - Keamanan</h1></div><div class=td-content><h1 id=pg-04eeb110d75afc8acb2cf7a3db743985>8.1 - Ikhtisar Keamanan Cloud Native</h1><nav id=TableOfContents><ul><li><a href=#4c-pada-keamanan-cloud-native>4C pada Keamanan <em>Cloud Native</em></a></li><li><a href=#cloud>Cloud</a><ul><li><a href=#tabel-keamanan-penyedia-layanan-cloud>Tabel Keamanan Penyedia Layanan Cloud</a></li><li><a href=#tabel-panduan-umum-infrastruktur>Tabel Panduan Umum Infrastruktur</a></li></ul></li><li><a href=#cluster>Cluster</a><ul><li><a href=#komponen-komponen-dari-cluster>Komponen-komponen <em>dari</em> Cluster</a></li><li><a href=#komponen-komponen-di-dalam-cluster-aplikasimu>Komponen-komponen <em>di dalam</em> Cluster (aplikasimu)</a></li></ul></li><li><a href=#container>Container</a></li><li><a href=#code>Code</a><ul><li><a href=#tabel-panduan-umum-keamanan-kode>Tabel Panduan Umum Keamanan Kode</a></li></ul></li><li><a href=#otomasi-yang-kokoh>Otomasi yang Kokoh</a></li><li><a href=#selanjutnya>Selanjutnya</a></li></ul></nav><p>Keamanan Kubernetes (dan keamanan secara umum) adalah sebuah topik sangat luas yang memiliki banyak bagian yang sangat berkaitan satu sama lain. Pada masa sekarang ini di mana perangkat lunak <em>open source</em> telah diintegrasi ke dalam banyak sistem yang membantu berjalannya aplikasi web, ada beberapa konsep menyeluruh yang dapat membantu intuisimu untuk berpikir tentang konsep keamanan secara menyeluruh. Panduan ini akan mendefinisikan sebuah cara/model berpikir untuk beberapa konsep umum mengenai Keamanan <em>Cloud Native</em>. Cara berpikir ini sepenuhnya subjektif dan kamu sebaiknya hanya menggunakannya apabila ini membantumu berpikir tentang di mana harus mengamankan <em>stack</em> perangkat lunakmu.</p><h2 id=4c-pada-keamanan-cloud-native>4C pada Keamanan <em>Cloud Native</em></h2><p>Mari memulainya dengan sebuah diagram yang dapat membantumu mengerti bagaimana berpikir tentang keamanan dalam bentuk beberapa lapisan.<div class="alert alert-info note callout" role=alert><strong>Catatan:</strong> Pendekatan berlapis ini memperkuat pendekatan <a href=https://en.wikipedia.org/wiki/Defense_in_depth_(computing)><em>defense in depth</em></a> terhadap keamanan, yang secara luas dianggap sebagai praktik terbaik untuk mengamankan sistem-sistem perangkat lunak. 4C tersebut adalah Cloud, Cluster, Container, dan Code.</div></p><figure><img src=/images/docs/4c.png><figcaption><h4>The 4C's of Cloud Native Security</h4></figcaption></figure><p>Seperti yang dapat kamu lihat dari gambar di atas, setiap dari 4C tersebut bergantung pada keamanan dari kotak yang lebih besar di mana mereka berada. Hampir tidak mungkin untuk mengamankan sistem terhadap standar-standar keamanan yang buruk pada Cloud, Container, dan Code hanya dengan menangani keamanan pada lapisan kode. Akan tetapi, apabila semua area tersebut ditangani dengan baik, maka menambahkan keamanan ke dalam kode kamu akan memperkuat landasan yang sudah kuat. Area-area yang menjadi perhatian ini akan dideskripsikan lebih mendalam di bawah.</p><h2 id=cloud>Cloud</h2><p>Dalam banyak hal, Cloud (atau server-server <em>co-located</em>, atau pusat data/<em>data center</em> korporat) adalah <a href=https://en.wikipedia.org/wiki/Trusted_computing_base><em>trusted computing base</em> (basis komputasi yang dipercaya)</a> dari sebuah klaster Kubernetes. Jika komponen-komponen tersebut rentan secara keamanan (atau dikonfigurasi dengan cara yang rentan), maka sesungguhnya tidak ada cara untuk menjamin keamanan dari komponen-komponen apa pun yang dibangun di atas basis komputasi ini. Memberikan rekomendasi untuk keamanan cloud berada di luar lingkup panduan ini, karena setiap penyedia layanan cloud dan beban kerja pada dasarnya berbeda-beda. Berikut beberapa tautan menuju beberapa dokumentasi penyedia layanan cloud yang populer untuk keamanan maupun untuk memberikan panduan umum untuk mengamankan infrastruktur yang menjadi basis sebuah klaster Kubernetes.</p><h3 id=tabel-keamanan-penyedia-layanan-cloud>Tabel Keamanan Penyedia Layanan Cloud</h3><table><thead><tr><th>IaaS Provider</th><th>Link</th></tr></thead><tbody><tr><td>Alibaba Cloud</td><td><a href=https://www.alibabacloud.com/trust-center>https://www.alibabacloud.com/trust-center</a></td></tr><tr><td>Amazon Web Services</td><td><a href=https://aws.amazon.com/security/>https://aws.amazon.com/security/</a></td></tr><tr><td>Google Cloud Platform</td><td><a href=https://cloud.google.com/security/>https://cloud.google.com/security/</a></td></tr><tr><td>IBM Cloud</td><td><a href=https://www.ibm.com/cloud/security>https://www.ibm.com/cloud/security</a></td></tr><tr><td>Microsoft Azure</td><td><a href=https://docs.microsoft.com/en-us/azure/security/azure-security>https://docs.microsoft.com/en-us/azure/security/azure-security</a></td></tr><tr><td>Oracle Cloud Infrastructure</td><td><a href=https://www.oracle.com/security/>https://www.oracle.com/security/</a></td></tr><tr><td>VMWare VSphere</td><td><a href=https://www.vmware.com/security/hardening-guides.html>https://www.vmware.com/security/hardening-guides.html</a></td></tr></tbody></table><p>Jika kamu mengoperasikan perangkat keras kamu sendiri, atau penyedia layanan cloud yang berbeda, kamu perlu merujuk pada dokumentasi penyedia layanan cloud yang kamu pakai untuk praktik keamanan terbaik.</p><h3 id=tabel-panduan-umum-infrastruktur>Tabel Panduan Umum Infrastruktur</h3><table><thead><tr><th>Area yang Menjadi Perhatian untuk Infrastruktur Kubernetes</th><th>Rekomendasi</th></tr></thead><tbody><tr><td>Akses Jaringan terhadap API Server (Master-master)</td><td>Secara Ideal, semua akses terhadap Master-master Kubernetes tidak diizinkan secara publik pada internet, dan dikontrol oleh daftar kendali akses (<em>network ACL</em>) yang dibatasi untuk kumpulan alamat IP yang dibutuhkan untuk mengelola klaster.</td></tr><tr><td>Akses Jaringan terhadap Node-node (Server-server Worker)</td><td>Node-node harus dikonfigurasikan untuk <em>hanya</em> menerima koneksi-koneksi (melalui daftar kendali akses) dari Master-master pada porta-porta (<em>port</em>) yang telah ditentukan, dan menerima koneksi-koneksi dari Service-service Kubernetes dengan tipe NodePort dan LoadBalancer. Apabila memungkinkan, Node-node tersebut sebaiknya tidak diekspos pada internet publik sama sekali.</td></tr><tr><td>Akses Kubernetes terhadap API Penyedia Layanan Cloud</td><td>Setiap penyedia layanan cloud perlu memberikan kumpulan izin yang berbeda-beda untuk Master-master dan Node-node Kubernetes, sehingga rekomendasi ini sifatnya lebih umum. Praktik terbaiknya adalah untuk memberikan klaster akses terhadap penyedia layanan cloud yang mengikuti <a href=https://en.wikipedia.org/wiki/Principle_of_least_privilege><em>principle of least privilege</em> (prinsip hak istimewa paling sedikit)</a> untuk sumber daya yang klaster tersebut perlukan untuk dikelola. Sebuah contoh untuk Kops di AWS dapat ditemukan di sini: <a href=https://github.com/kubernetes/kops/blob/master/docs/iam_roles.md#iam-roles>https://github.com/kubernetes/kops/blob/master/docs/iam_roles.md#iam-roles</a></td></tr><tr><td>Akses terhadap etcd</td><td>Akses terhadap etcd (tempat penyimpanan data Kubernetes) harus dibatasi hanya untuk Master-master saja. Bergantung pada konfigurasimu, kamu sebaiknya juga mengusahakan koneksi etcd menggunakan TLS. Informasi lebih lanjut dapat ditemukan di sini: <a href=https://github.com/etcd-io/etcd/tree/master/Documentation#security>https://github.com/etcd-io/etcd/tree/master/Documentation#security</a></td></tr><tr><td>Enkripsi etcd</td><td>Di mana pun kita dapat melakukannya, mengenkripsi semua data saat diam (<em>at rest</em>) pada semua <em>drive</em>, dan sejak etcd menyimpan keadaan seluruh klaster (termasuk Secret-secret), <em>disk</em>-nya sebaiknya kita enkripsi saat diam.</td></tr></tbody></table><h2 id=cluster>Cluster</h2><p>Bagian ini akan memberikan tautan-tautan untuk mengamankan beban-beban kerja di dalam Kubernetes. Ada dua area yang menjadi perhatian untuk mengamankan Kubernetes:</p><ul><li>Mengamankan komponen-komponen yang dapat dikonfigurasi yang membentuk klaster</li><li>Mengamankan komponen-komponen yang dijalankan di dalam klaster</li></ul><h3 id=komponen-komponen-dari-cluster>Komponen-komponen <em>dari</em> Cluster</h3><p>Jika kamu ingin menjaga klastermu dari akses yang tidak disengaja atau yang bersifat serangan, dan mengadopsi praktik yang baik, baca dan ikutilah nasihat untuk <a href=/docs/tasks/administer-cluster/securing-a-cluster/>mengamankan klastermu</a>.</p><h3 id=komponen-komponen-di-dalam-cluster-aplikasimu>Komponen-komponen <em>di dalam</em> Cluster (aplikasimu)</h3><p>Bergantung pada permukaan yang dapat diserang dari aplikasimu, kamu mungkin ingin berfokus pada aspek keamanan yang spesifik. Sebagai contoh, jika kamu menjalankan sebuah layanan (kita sebut Layanan A) yang kritikal di dalam rantai sumber daya lainnya dan sebuah beban kerja terpisah (kita sebut Layanan B) yang rentan terhadap serangan <em>resource exhaustion</em>, dengan tidak menyetel limit untuk sumber daya maka kamu juga menaruh risiko terhadap Layanan A. Berikut tabel tautan-tautan menuju hal-hal yang perlu diperhatikan untuk mengamankan beban-beban kerja yang berjalan di dalam Kubernetes.</p><table><thead><tr><th>Area yang Menjadi Perhatian untuk Keamanan Beban Kerja</th><th>Rekomendasi</th></tr></thead><tbody><tr><td>Otorisasi RBAC (Akses terhadap API Kubernetes)</td><td><a href=https://kubernetes.io/docs/reference/access-authn-authz/rbac/>https://kubernetes.io/docs/reference/access-authn-authz/rbac/</a></td></tr><tr><td>Autentikasi</td><td><a href=https://kubernetes.io/docs/reference/access-authn-authz/controlling-access/>https://kubernetes.io/docs/reference/access-authn-authz/controlling-access/</a></td></tr><tr><td>Manajemen Secret Aplikasi (dan mengenkripsi mereka di etcd)</td><td><a href=https://kubernetes.io/docs/concepts/configuration/secret/>https://kubernetes.io/docs/concepts/configuration/secret/</a><br><a href=https://kubernetes.io/docs/tasks/administer-cluster/encrypt-data/>https://kubernetes.io/docs/tasks/administer-cluster/encrypt-data/</a></td></tr><tr><td>Pod Security Policy</td><td><a href=https://kubernetes.io/docs/concepts/policy/pod-security-policy/>https://kubernetes.io/docs/concepts/policy/pod-security-policy/</a></td></tr><tr><td>Quality of Service (dan manajemen sumber daya klaster)</td><td><a href=https://kubernetes.io/docs/tasks/configure-pod-container/quality-service-pod/>https://kubernetes.io/docs/tasks/configure-pod-container/quality-service-pod/</a></td></tr><tr><td>Network Policy</td><td><a href=https://kubernetes.io/docs/concepts/services-networking/network-policies/>https://kubernetes.io/docs/concepts/services-networking/network-policies/</a></td></tr><tr><td>TLS untuk Ingress Kubernetes</td><td><a href=https://kubernetes.io/docs/concepts/services-networking/ingress/#tls>https://kubernetes.io/docs/concepts/services-networking/ingress/#tls</a></td></tr></tbody></table><h2 id=container>Container</h2><p>Untuk menjalankan perangkat lunak di dalam Kubernetes, perangkat lunak tersebut haruslah berada di dalam sebuah Container. Karenanya, ada beberapa pertimbangan keamanan yang harus diperhitungkan untuk mengambil manfaat dari fitur-fitur keamanan beban kerja Kubernetes. Keamanan Container berada di luar lingkup panduan ini, tetapi berikut disediakan sebuah tabel rekomendasi-rekomendasi umum dan tautan menuju eksplorasi lebih dalam pada topik ini.</p><table><thead><tr><th>Area yang Menjadi Perhatian untuk Container</th><th>Rekomendasi</th></tr></thead><tbody><tr><td>Pemindaian Kerentanan Container dan Dependensi Keamanan OS</td><td>Sebagai bagian dari tahap membangun sebuah <em>image</em> atau dilakukan secara teratur, kamu sebaiknya memindai Container-container terhadap kerentanan yang telah diketahui dengan peralatan seperti <a href=https://github.com/coreos/clair/>CoreOS's Clair</a></td></tr><tr><td>Penandatanganan <em>Image</em> dan Penegakan Aturan</td><td>Dua dari Proyek-proyek CNCF (TUF dan Notary) adalah alat-alat yang berguna untuk menandatangani <em>image</em> Container dan memelihara sistem kepercayaan untuk konten dari Container-container kamu. Jika kamu menggunakan Docker, ia dibangun di dalam Docker Engine sebagai <a href=https://docs.docker.com/engine/security/trust/content_trust/>Docker Content Trust</a>. Pada bagian penegakan aturan, proyek <a href=https://github.com/IBM/portieris>Portieris dari IBM</a> adalah sebuah alat yang berjalan sebagai sebuah Dynamic Admission Controller Kubernetes untuk memastikan bahwa <em>image-image</em> ditandatangani dengan tepat oleh Notary sebelum dimasukkan ke dalam Cluster.</td></tr><tr><td>Larang pengguna-pengguna dengan hak istimewa</td><td>Saat membangun Container-container, rujuklah dokumentasimu untuk cara membuat pengguna-pengguna di dalam Container-container yang memiliki hak istimewa sistem operasi yang paling sedikit yang dibutuhkan untuk mencapai tujuan Container tersebut.</td></tr></tbody></table><h2 id=code>Code</h2><p>Akhirnya pada lapisan kode aplikasi, hal ini adalah satu dari permukaan-permukaan serangan utama yang paling dapat kamu kontrol. Hal ini juga berada di luar lingkup Kubernetes, tetapi berikut beberapa rekomendasi:</p><h3 id=tabel-panduan-umum-keamanan-kode>Tabel Panduan Umum Keamanan Kode</h3><table><thead><tr><th>Area yang Menjadi Perhatian untuk Kode</th><th>Rekomendasi</th></tr></thead><tbody><tr><td>Akses hanya melalui TLS</td><td>Jika kode kamu perlu berkomunikasi via TCP, idealnya ia melakukan <em>TLS handshake</em> dengan klien sebelumnya. Dengan pengecualian pada sedikit kasus, kelakuan secara bawaan sebaiknya adalah mengenkripsi semuanya (data) pada saat transit (<em>encryption at transit</em>). Lebih jauh lagi, bahkan "di belakang dinding api" di dalam VPC kita sebaiknya kita melakukan enkripsi lalu lintas jaringan di antara layanan-layanan. Hal ini dapat dilakukan melalui sebuah proses yang dikenal dengan <em>mutual TLS</em> atau <a href=https://en.wikipedia.org/wiki/Mutual_authentication>mTLS</a> yang melakukan verifikasi dua sisi terhadap komunikasi antara layanan-layanan yang memiliki sertifikat digital. Ada banyak alat-alat yang dapat digunakan untuk mencapai hal ini, seperti <a href=https://linkerd.io/>Linkerd</a> dan <a href=https://istio.io/>Istio</a>.</td></tr><tr><td>Membatasi cakupan porta komunikasi</td><td>Rekomendasi ini sepertinya cukup jelas, tetapi di mana pun dapat dilakukan sebaiknya kamu hanya membuka porta-porta pada layananmu yang benar-benar diperlukan untuk komunikasi sistem atau pengambilan metrik.</td></tr><tr><td>Keamanan Dependensi Pihak ke-3</td><td>Karena aplikasi-aplikasi kita cenderung memiliki dependensi-dependensi di luar kode kita sendiri, merupakan praktik yang baik untuk memastikan hasil pemindaian rutin dependensi-dependensi kode kita masih aman tanpa CVE yang masih ada terhadap mereka. Setiap bahasa pemrograman memiliki alat untuk melakukan pemindaian ini secara otomatis.</td></tr><tr><td>Analisis Statis Kode</td><td>Kebanyakan bahasa pemrograman menyediakan cara agar potongan kode dapat dianalisis terhadap praktik-praktik penulisan kode yang berpotensi tidak aman. Kapan pun dapat dilakukan, kamu sebaiknya melakukan pemeriksaan menggunakan peralatan otomatis yang dapat memindai kode terhadap kesalahan keamanan yang umum terjadi. Beberapa dari peralatan tersebut dapat ditemukan di sini: <a href=https://www.owasp.org/index.php/Source_Code_Analysis_Tools>https://www.owasp.org/index.php/Source_Code_Analysis_Tools</a></td></tr><tr><td>Serangan Pengamatan (<em>probing</em>) Dinamis</td><td>Ada sedikit peralatan otomatis yang dapat dijalankan terhadap layanan/aplikasi kamu untuk mencoba beberapa serangan yang terkenal dan umumnya memengaruhi layanan-layanan. Serangan-serangan tersebut termasuk <em>SQL injection</em>, CSRF, dan XSS. Satu dari alat analisis dinamis yang terkenal adalah OWASP Zed Attack Proxy <a href=https://www.owasp.org/index.php/OWASP_Zed_Attack_Proxy_Project>https://www.owasp.org/index.php/OWASP_Zed_Attack_Proxy_Project</a></td></tr></tbody></table><h2 id=otomasi-yang-kokoh>Otomasi yang Kokoh</h2><p>Kebanyakan dari saran yang disebut di atas dapat diotomasi di dalam <em>delivery pipeline</em> kode kamu sebagai bagian dari rangkaian pemeriksaan keamanan. Untuk mempelajari lebih lanjut tentang pendekatan "<em>Continuous Hacking</em>" terhadap <em>delivery</em> perangkat lunak, <a href=https://thenewstack.io/beyond-ci-cd-how-continuous-hacking-of-docker-containers-and-pipeline-driven-security-keeps-ygrene-secure/>artikel ini</a> menyediakan lebih banyak detail.</p><h2 id=selanjutnya>Selanjutnya</h2><ul><li>Pelajari tentang <a href=/id/docs/concepts/services-networking/network-policies/>Network Policy untuk Pod</a></li><li>Pelajari tentang <a href=/docs/tasks/administer-cluster/securing-a-cluster/>mengamankan klaster kamu</a></li><li>Pelajari tentang <a href=/docs/reference/access-authn-authz/controlling-access/>kontrol akses API</a></li><li>Pelajari tentang <a href=/id/docs/tasks/tls/managing-tls-in-a-cluster/>enkripsi data saat transit</a> for the control plane</li><li>Pelajari tentang <a href=/docs/tasks/administer-cluster/encrypt-data/>enkripsi data saat diam</a></li><li>Pelajari tentang <a href=/id/docs/concepts/configuration/secret/>Secret (data sensitif) pada Kubernetes</a></li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-c21d05f31057c5bcd2ebdd01f4e62a0e>9 - Penjadwalan dan Pengusiran</h1></div><div class=td-content><h1 id=pg-961126cd43559012893979e568396a49>9.1 - Bin Packing Sumber Daya untuk Sumber Daya Tambahan</h1><div style=margin-top:10px;margin-bottom:10px><b>FEATURE STATE:</b> <code>Kubernetes 1.16 [alpha]</code></div><p><em>Kube-scheduler</em> dapat dikonfigurasikan untuk mengaktifkan pembungkusan rapat
(<em>bin packing</em>) sumber daya bersama dengan sumber daya tambahan melalui fungsi prioritas
<code>RequestedToCapacityRatioResourceAllocation</code>. Fungsi-fungsi prioritas dapat digunakan
untuk menyempurnakan <em>kube-scheduler</em> sesuai dengan kebutuhan.</p><h2 id=mengaktifkan-bin-packing-menggunakan-requestedtocapacityratioresourceallocation>Mengaktifkan <em>Bin Packing</em> menggunakan RequestedToCapacityRatioResourceAllocation</h2><p>Sebelum Kubernetes 1.15, <em>kube-scheduler</em> digunakan untuk memungkinkan mencetak
skor berdasarkan rasio permintaan terhadap kapasitas sumber daya utama seperti
CPU dan Memori. Kubernetes 1.16 menambahkan parameter baru ke fungsi prioritas
yang memungkinkan pengguna untuk menentukan sumber daya beserta dengan bobot
untuk setiap sumber daya untuk memberi nilai dari Node berdasarkan rasio
permintaan terhadap kapasitas. Hal ini memungkinkan pengguna untuk <em>bin pack</em>
sumber daya tambahan dengan menggunakan parameter yang sesuai untuk meningkatkan
pemanfaatan sumber daya yang langka dalam klaster yang besar. Perilaku
<code>RequestedToCapacityRatioResourceAllocation</code> dari fungsi prioritas dapat
dikontrol melalui pilihan konfigurasi yang disebut <code>RequestToCapacityRatioArguments</code>.
Argumen ini terdiri dari dua parameter yaitu <code>shape</code> dan <code>resources</code>. Shape
memungkinkan pengguna untuk menyempurnakan fungsi menjadi yang paling tidak
diminta atau paling banyak diminta berdasarkan nilai <code>utilization</code> dan <code>score</code>.
Sumber daya terdiri dari <code>name</code> yang menentukan sumber daya mana yang dipertimbangkan
selama penilaian dan <code>weight</code> yang menentukan bobot masing-masing sumber daya.</p><p>Di bawah ini adalah contoh konfigurasi yang menetapkan <code>requestedToCapacityRatioArguments</code>
pada perilaku <em>bin packing</em> untuk sumber daya tambahan <code>intel.com/foo</code> dan <code>intel.com/bar</code></p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-json data-lang=json><span style=display:flex><span>{
</span></span><span style=display:flex><span>    <span style=color:green;font-weight:700>&#34;kind&#34;</span> : <span style=color:#b44>&#34;Policy&#34;</span>,
</span></span><span style=display:flex><span>    <span style=color:green;font-weight:700>&#34;apiVersion&#34;</span> : <span style=color:#b44>&#34;v1&#34;</span>,
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span>...</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:green;font-weight:700>&#34;priorities&#34;</span> : [
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>       <span>...</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>      {
</span></span><span style=display:flex><span>        <span style=color:green;font-weight:700>&#34;name&#34;</span>: <span style=color:#b44>&#34;RequestedToCapacityRatioPriority&#34;</span>,
</span></span><span style=display:flex><span>        <span style=color:green;font-weight:700>&#34;weight&#34;</span>: <span style=color:#666>2</span>,
</span></span><span style=display:flex><span>        <span style=color:green;font-weight:700>&#34;argument&#34;</span>: {
</span></span><span style=display:flex><span>          <span style=color:green;font-weight:700>&#34;requestedToCapacityRatioArguments&#34;</span>: {
</span></span><span style=display:flex><span>            <span style=color:green;font-weight:700>&#34;shape&#34;</span>: [
</span></span><span style=display:flex><span>              {<span style=color:green;font-weight:700>&#34;utilization&#34;</span>: <span style=color:#666>0</span>, <span style=color:green;font-weight:700>&#34;score&#34;</span>: <span style=color:#666>0</span>},
</span></span><span style=display:flex><span>              {<span style=color:green;font-weight:700>&#34;utilization&#34;</span>: <span style=color:#666>100</span>, <span style=color:green;font-weight:700>&#34;score&#34;</span>: <span style=color:#666>10</span>}
</span></span><span style=display:flex><span>            ],
</span></span><span style=display:flex><span>            <span style=color:green;font-weight:700>&#34;resources&#34;</span>: [
</span></span><span style=display:flex><span>              {<span style=color:green;font-weight:700>&#34;name&#34;</span>: <span style=color:#b44>&#34;intel.com/foo&#34;</span>, <span style=color:green;font-weight:700>&#34;weight&#34;</span>: <span style=color:#666>3</span>},
</span></span><span style=display:flex><span>              {<span style=color:green;font-weight:700>&#34;name&#34;</span>: <span style=color:#b44>&#34;intel.com/bar&#34;</span>, <span style=color:green;font-weight:700>&#34;weight&#34;</span>: <span style=color:#666>5</span>}
</span></span><span style=display:flex><span>            ]
</span></span><span style=display:flex><span>          }
</span></span><span style=display:flex><span>        }
</span></span><span style=display:flex><span>      }
</span></span><span style=display:flex><span>    ],
</span></span><span style=display:flex><span>  }
</span></span></code></pre></div><p><strong>Fitur ini dinonaktifkan secara <em>default</em></strong></p><h3 id=tuning-requestedtocapacityratioresourceallocation-priority-function>Tuning RequestedToCapacityRatioResourceAllocation Priority Function</h3><p><code>shape</code> digunakan untuk menentukan perilaku dari fungsi <code>RequestedToCapacityRatioPriority</code>.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#bbb> </span>{<span style=color:green;font-weight:700>&#34;utilization&#34;: 0, &#34;score&#34;: </span><span style=color:#666>0</span>},<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb> </span>{<span style=color:green;font-weight:700>&#34;utilization&#34;: 100, &#34;score&#34;: </span><span style=color:#666>10</span>}<span style=color:#bbb>
</span></span></span></code></pre></div><p>Argumen di atas memberikan Node nilai 0 jika utilisasi 0% dan 10 untuk utilisasi 100%,
yang kemudian mengaktfikan perilaku <em>bin packing</em>. Untuk mengaktifkan dari paling
yang tidak diminta, nilainya harus dibalik sebagai berikut.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#bbb> </span>{<span style=color:green;font-weight:700>&#34;utilization&#34;: 0, &#34;score&#34;: </span><span style=color:#666>100</span>},<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb> </span>{<span style=color:green;font-weight:700>&#34;utilization&#34;: 100, &#34;score&#34;: </span><span style=color:#666>0</span>}<span style=color:#bbb>
</span></span></span></code></pre></div><p><code>resources</code> adalah parameter opsional yang secara <em>default</em> diatur ke:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>&#34;resources&#34;: </span>[<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>              </span>{<span style=color:green;font-weight:700>&#34;name&#34;: &#34;CPU&#34;, &#34;weight&#34;: </span><span style=color:#666>1</span>},<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>              </span>{<span style=color:green;font-weight:700>&#34;name&#34;: &#34;Memory&#34;, &#34;weight&#34;: </span><span style=color:#666>1</span>}<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>            </span>]<span style=color:#bbb>
</span></span></span></code></pre></div><p>Ini dapat digunakan untuk menambahkan sumber daya tambahan sebagai berikut:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>&#34;resources&#34;: </span>[<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>              </span>{<span style=color:green;font-weight:700>&#34;name&#34;: &#34;intel.com/foo&#34;, &#34;weight&#34;: </span><span style=color:#666>5</span>},<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>              </span>{<span style=color:green;font-weight:700>&#34;name&#34;: &#34;CPU&#34;, &#34;weight&#34;: </span><span style=color:#666>3</span>},<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>              </span>{<span style=color:green;font-weight:700>&#34;name&#34;: &#34;Memory&#34;, &#34;weight&#34;: </span><span style=color:#666>1</span>}<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>            </span>]<span style=color:#bbb>
</span></span></span></code></pre></div><p>Parameter <code>weight</code> adalah opsional dan diatur ke 1 jika tidak ditentukan.
Selain itu, <code>weight</code> tidak dapat diatur ke nilai negatif.</p><h3 id=bagaimana-fungsi-prioritas-requestedtocapacityratioresourceallocation-menilai-node>Bagaimana Fungsi Prioritas RequestedToCapacityRatioResourceAllocation Menilai Node</h3><p>Bagian ini ditujukan bagi kamu yang ingin memahami secara detail internal
dari fitur ini.
Di bawah ini adalah contoh bagaimana nilai dari Node dihitung untuk satu kumpulan
nilai yang diberikan.</p><pre tabindex=0><code>Sumber daya yang diminta

intel.com/foo : 2
Memory: 256MB
CPU: 2

Bobot dari sumber daya

intel.com/foo : 5
Memory: 1
CPU: 3

FunctionShapePoint {{0, 0}, {100, 10}}

Spesifikasi dari Node 1

Tersedia:

intel.com/foo : 4
Memory : 1 GB
CPU: 8

Digunakan:

intel.com/foo: 1
Memory: 256MB
CPU: 1


Nilai Node:

intel.com/foo  = resourceScoringFunction((2+1),4)
               =  (100 - ((4-3)*100/4)
               =  (100 - 25)
               =  75
               =  rawScoringFunction(75)
               = 7

Memory         = resourceScoringFunction((256+256),1024)
               = (100 -((1024-512)*100/1024))
               = 50
               = rawScoringFunction(50)
               = 5

CPU            = resourceScoringFunction((2+1),8)
               = (100 -((8-3)*100/8))
               = 37.5
               = rawScoringFunction(37.5)
               = 3

NodeScore   =  (7 * 5) + (5 * 1) + (3 * 3) / (5 + 1 + 3)
            =  5


Spesifikasi dari Node 2

Tersedia:

intel.com/foo: 8
Memory: 1GB
CPU: 8

Digunakan:

intel.com/foo: 2
Memory: 512MB
CPU: 6


Nilai Node:

intel.com/foo  = resourceScoringFunction((2+2),8)
               =  (100 - ((8-4)*100/8)
               =  (100 - 25)
               =  50
               =  rawScoringFunction(50)
               = 5

Memory         = resourceScoringFunction((256+512),1024)
               = (100 -((1024-768)*100/1024))
               = 75
               = rawScoringFunction(75)
               = 7

CPU            = resourceScoringFunction((2+6),8)
               = (100 -((8-8)*100/8))
               = 100
               = rawScoringFunction(100)
               = 10

NodeScore   =  (5 * 5) + (7 * 1) + (10 * 3) / (5 + 1 + 3)
            =  7
</code></pre></div><div class=td-content style=page-break-before:always><h1 id=pg-da22fe2278df236f71efbe672f392677>9.2 - Overhead Pod</h1><div style=margin-top:10px;margin-bottom:10px><b>FEATURE STATE:</b> <code>Kubernetes v1.16 [alpha]</code></div><p>Ketika kamu menjalankan Pod pada Node, Pod itu akan mengambil sejumlah sumber daya sistem. Sumber daya ini adalah tambahan terhadap sumber daya yang diperlukan untuk menjalankan Container di dalam Pod (<em>overhead</em>).
<em>Pod Overhead</em> adalah fitur yang berfungsi untuk menghitung sumber daya digunakan oleh infrastruktur Pod selain permintaan dan limit Container.</p><h2 id=overhead-pod>Overhead Pod</h2><p>Pada Kubernetes, Overhead Pod ditentukan pada
<a href=/docs/reference/access-authn-authz/extensible-admission-controllers/#what-are-admission-webhooks>saat admisi</a> sesuai dengan Overhead yang ditentukan di dalam
<a href=/id/docs/concepts/containers/runtime-class/>RuntimeClass</a> milik Pod.</p><p>Ketika Overhead Pod diaktifkan, Overhead akan dipertimbangkan sebagai tambahan terhadap jumlah permintaan sumber daya Container
saat menjadwalkan Pod. Begitu pula Kubelet, yang akan memasukkan Overhead Pod saat menentukan ukuran
cgroup milik Pod, dan saat melakukan pemeringkatan pengusiran (<em>eviction</em>) Pod.</p><h3 id=yang-perlu-disiapkan>Yang perlu disiapkan</h3><p>Kamu harus memastikan bahwa
<a href=/docs/reference/command-line-tools-reference/feature-gates/><em>feature gate</em></a> <code>PodOverhead</code> telah diaktifkan (secara bawaan dinonaktifkan)
di seluruh klaster kamu, yang berarti:</p><ul><li>Pada <a class=glossary-tooltip title='Komponen control plane yang bertugas mengamati Pod baru yang belum ditempatkan di node manapun dan kemudian memilihkan node di mana Pod baru tersebut akan dijalankan.' data-toggle=tooltip data-placement=top href=/docs/reference/generated/kube-scheduler/ target=_blank aria-label=kube-scheduler>kube-scheduler</a></li><li>Pada <a class=glossary-tooltip title='Komponen control plane yang mengekspos API Kubernetes. Merupakan front-end dari control plane Kubernetes.' data-toggle=tooltip data-placement=top href=/docs/reference/generated/kube-apiserver/ target=_blank aria-label=kube-apiserver>kube-apiserver</a></li><li>Pada <a class=glossary-tooltip title='Agen yang dijalankan pada setiap node di klaster yang bertugas untuk memastikan kontainer dijalankan di dalam Pod.' data-toggle=tooltip data-placement=top href=/docs/reference/generated/kubelet target=_blank aria-label=kubelet>kubelet</a> di setiap Node</li><li>Pada peladen API khusus (<em>custom</em>) apa pun yang menggunakan <em>feature gate</em></li></ul><div class="alert alert-info note callout" role=alert><strong>Catatan:</strong> Pengguna yang dapat mengubah sumber daya RuntimeClass dapat memengaruhi kinerja beban kerja klaster secara keseluruhan. Kamu dapat membatasi akses terhadap kemampuan ini dengan kontrol akses Kubernetes.
Lihat <a href=/docs/reference/access-authn-authz/authorization/>Ringkasan Otorisasi</a> untuk lebih lanjut.</div><h2 id=selanjutnya>Selanjutnya</h2><ul><li><a href=/id/docs/concepts/containers/runtime-class/>RuntimeClass</a></li><li><a href=https://github.com/kubernetes/enhancements/blob/master/keps/sig-node/20190226-pod-overhead.md>Desain PodOverhead</a></li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-21169f516071aea5d16734a4c27789a5>9.3 - Menetapkan Pod ke Node</h1><p>Kamu dapat memaksa sebuah <a href=/id/docs/concepts/workloads/pods/pod/>pod</a> untuk hanya dapat berjalan pada <a href=/id/docs/concepts/architecture/nodes/>node</a> tertentu atau mengajukannya agar berjalan pada node tertentu. Ada beberapa cara untuk melakukan hal tersebut. Semua cara yang direkomendasikan adalah dengan menggunakan <a href=/id/docs/concepts/overview/working-with-objects/labels/><em>selector</em> label</a> untuk menetapkan pilihan yang kamu inginkan. Pada umumnya, pembatasan ini tidak dibutuhkan, sebagaimana <em>scheduler</em> akan melakukan penempatan yang proporsional dengan otomatis (seperti contohnya menyebar pod di node-node, tidak menempatkan pod pada node dengan sumber daya yang tidak memadai, dst.) tetapi ada keadaan-keadaan tertentu yang membuat kamu memiliki kendali lebih terhadap node yang menjadi tempat pod dijalankan, contohnya untuk memastikan pod dijalankan pada mesin yang telah terpasang SSD, atau untuk menempatkan pod-pod dari dua servis yang berbeda yang sering berkomunikasi bersamaan ke dalam zona ketersediaan yang sama.</p><p>Kamu dapat menemukan semua berkas untuk contoh-contoh berikut pada <a href=https://github.com/kubernetes/website/tree/main/content/en/docs/concepts/configuration/>dokumentasi yang kami sediakan di sini</a></p><h2 id=nodeselector>nodeSelector</h2><p>Penggunaan <code>nodeSelector</code> adalah cara pembatasan pemilihan node paling sederhana yang direkomendasikan. <code>nodeSelector</code> adalah sebuah <em>field</em> pada PodSpec. <code>nodeSelector</code> memerinci sebuah map berisi pasangan kunci-nilai. Agar pod dapat dijalankan pada sebuah node yang memenuhi syarat, node tersebut harus memiliki masing-masing dari pasangan kunci-nilai yang dinyatakan sebagai label (namun node juga dapat memiliki label tambahan diluar itu). Penggunaan paling umum adalah satu pasang kunci-nilai.</p><p>Mari kita telusuri contoh dari penggunaan <code>nodeSelector</code>.</p><h3 id=langkah-nol-prasyarat>Langkah Nol: Prasyarat</h3><p>Contoh ini mengasumsikan bahwa kamu memiliki pemahaman dasar tentang pod Kubernetes dan kamu telah <a href=https://github.com/kubernetes/kubernetes#documentation>membuat klaster Kubernetes</a>.</p><h3 id=langkah-satu-menyematkan-label-pada-node>Langkah Satu: Menyematkan label pada node</h3><p>Jalankan <code>kubectl get nodes</code> untuk mendapatkan nama dari node-node yang ada dalam klaster kamu. Temukan node yang akan kamu tambahkan label, kemudian jalankan perintah <code>kubectl label nodes &lt;node-name> &lt;label-key>=&lt;label-value></code> untuk menambahkan label pada node yang telah kamu pilih. Sebagai contoh, jika nama node yang saya pilih adalah 'kubernetes-foo-node-1.c.a-robinson.internal' dan label yang ingin saya tambahkan adalah 'disktype=ssd', maka saya dapat menjalankan <code>kubectl label nodes kubernetes-foo-node-1.c.a-robinson.internal disktype=ssd</code>.</p><p>Jika terjadi kegagalan dengan kesalahan perintah yang tidak <em>valid</em> ("<em>invalid command</em>"), kemungkinan besar kamu menggunakan kubectl dengan versi lebih lama yang tidak memiliki perintah <code>label</code>. Dalam hal ini, lihat [versi sebelumnya] (<a href=https://github.com/kubernetes/kubernetes/blob/a053dbc313572ed60d89dae9821ecab8bfd676dc/examples/node-selection/README.md>https://github.com/kubernetes/kubernetes/blob/a053dbc313572ed60d89dae9821ecab8bfd676dc/examples/node-selection/README.md</a>) dari petunjuk ini untuk instruksi tentang cara menetapkan label pada node.</p><p>Kamu dapat memastikan perintah telah berhasil dengan menjalankan ulang perintah <code>kubectl get nodes --show-labels</code> and memeriksa bahwa node yang dipilih sekarang sudah memiliki label yang ditambahkan. Kamu juga dapat menggunakan <code>kubectl describe node "nodename"</code> untuk melihat daftar lengkap label yang dimiliki sebuah node.</p><h3 id=langkah-dua-menambahkan-sebuah-nodeselector-ke-konfigurasi-pod-kamu>Langkah Dua: Menambahkan sebuah nodeSelector ke konfigurasi pod kamu</h3><p>Ambil berkas konfigurasi pod manapun yang akan kamu jalankan, dan tambahkan sebuah bagian <code>nodeSelector</code> pada berkas tersebut, seperti berikut. Sebagai contoh, jika berikut ini adalah konfigurasi pod saya:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>nginx<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>labels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>env</span>:<span style=color:#bbb> </span>test<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>nginx<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>nginx<span style=color:#bbb>
</span></span></span></code></pre></div><p>Kemudian tambahkan sebuah <code>nodeSelector</code> seperti berikut:</p><div class=highlight><div class=copy-code-icon style=text-align:right><a href=https://raw.githubusercontent.com/kubernetes/website/main/content/id/examples/pods/pod-nginx.yaml download=pods/pod-nginx.yaml><code>pods/pod-nginx.yaml</code></a>
<img src=/images/copycode.svg style=max-height:24px;cursor:pointer onclick='copyCode("pods-pod-nginx-yaml")' title="Copy pods/pod-nginx.yaml to clipboard"></img></div><div class=includecode id=pods-pod-nginx-yaml><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>nginx<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>labels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>env</span>:<span style=color:#bbb> </span>test<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>nginx<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>nginx<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>imagePullPolicy</span>:<span style=color:#bbb> </span>IfNotPresent<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>nodeSelector</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>disktype</span>:<span style=color:#bbb> </span>ssd<span style=color:#bbb>
</span></span></span></code></pre></div></div></div><p>Ketika kamu menjalankan perintah <code>kubectl apply -f https://k8s.io/examples/pods/pod-nginx.yaml</code>, pod tersebut akan dijadwalkan pada node yang memiliki label yang dirinci. Kamu dapat memastikan penambahan nodeSelector berhasil dengan menjalankan <code>kubectl get pods -o wide</code> dan melihat "NODE" tempat Pod ditugaskan.</p><h2 id=selingan-label-node-built-in>Selingan: label node <em>built-in</em></h2><p>Sebagai tambahan dari label yang kamu <a href=#step-one-attach-label-to-the-node>sematkan</a>, node sudah terisi dengan satu set label standar. Pada Kubernetes v1.4 label tersebut adalah</p><ul><li><code>kubernetes.io/hostname</code></li><li><code>failure-domain.beta.kubernetes.io/zone</code></li><li><code>failure-domain.beta.kubernetes.io/region</code></li><li><code>beta.kubernetes.io/instance-type</code></li><li><code>kubernetes.io/os</code></li><li><code>kubernetes.io/arch</code></li></ul><div class="alert alert-info note callout" role=alert><strong>Catatan:</strong> Nilai dari label-label tersebut spesifik untuk setiap penyedia layanan <em>cloud</em> dan tidak dijamin reliabilitasnya.
Contohnya, nilai dari <code>kubernetes.io/hostname</code> bisa saja sama dengan nama node pada beberapa lingkungan dan berbeda pada lingkungan lain.</div><h2 id=isolasi-pembatasan-node>Isolasi/pembatasan Node</h2><p>Menambahkan label pada objek node memungkinkan penargetan pod pada node atau grup node yang spesifik. Penambahan label ini dapat digunakan untuk memastikan pod yang spesifik hanya berjalan pada node dengan isolasi, keamanan, atau pengaturan tertentu. Saat menggunakan label untuk tujuan tersebut, memilih kunci label yang tidak bisa dimodifikasi oleh proses kubelet pada node sangat direkomendasikan. Hal ini mencegah node yang telah diubah untuk menggunakan kredensial kubelet-nya untuk mengatur label-label pada objek nodenya sediri, dan mempengaruhi scheduler untuk menjadwalkan <em>workload</em> ke node yang telah diubah tersebut.</p><p><em>Plugin</em> penerimaan <code>NodeRestriction</code> mencegah kubeletes untuk megatur atau mengubah label dengan awalan <code>node-restriction.kubernetes.io/</code>.
Untuk memanfaatkan awalan label untuk isolasi node:</p><ol><li><p>Pastikan kamu menggunakan <a href=/docs/reference/access-authn-authz/node/><em>authorizer</em> node</a> dan mengaktifkan [<em>plugin admission NodeRestriction</em>(/docs/reference/access-authn-authz/admission-controllers/#noderestriction).</p></li><li><p>Tambah label dengan awalan <code>node-restriction.kubernetes.io/</code> ke objek node kamu, dan gunakan label tersebut pada node <em>selector</em> kamu. Contohnya, <code>example.com.node-restriction.kubernetes.io/fips=true</code> or <code>example.com.node-restriction.kubernetes.io/pci-dss=true</code>.</p></li></ol><h2 id=afinitas-dan-anti-afinitas>Afinitas dan anti-afinitas</h2><p><code>_Field_ nodeSelector</code> menyediakan cara yang sangat sederhana untuk membatasi pod ke node dengan label-label tertentu. Fitur afinitas/anti-afinitas saat ini bersifat beta dan memperluas tipe pembatasan yang dapat kamu nyatakan. Peningkatan kunci dari fitur ini adalah</p><ol><li>Bahasa yang lebih ekspresif (tidak hanya "AND of exact match")</li><li>Kamu dapat memberikan indikasi bahwa aturan yang dinyatakan bersifat rendah/preferensi dibanding dengan persyaratan mutlak sehingga jika scheduler tidak dapat memenuhinya, pod tetap akan dijadwalkan</li><li>Kamu dapat membatasi dengan label pada pod-pod lain yang berjalan pada node (atau domain <em>topological</em> lain), daripada dengan label pada node itu sendiri, yang memungkinkan pengaturan tentang pod yang dapat dan tidak dapat dilokasikan bersama.</li></ol><p>Fitur afinitas terdiri dari dua tipe afinitas yaitu "node afinitas" dan "inter-pod afinitas/anti-afinitas"
Node afinitas adalah seperti <code>nodeSelector</code> yang telah ada (tetapi dengam dua kelebihan pertama yang terdaftar di atas), sementara inter-pod afinitas/anti-afinitas membatasi pada label pod daripada label node, seperti yang dijelaskan pada item ketiga pada daftar di atas, sebagai tambahan dari item pertama dan kedua.</p><p><em>Field</em> <code>nodeSelector</code> tetap berjalan seperti biasa, namun pada akhirnya akan ditinggalkan karena afinitas node dapat menyatakan semua yang <code>nodeSelector</code> dapat nyatakan.</p><h3 id=afinitas-node-fitur-beta>Afinitas node (fitur beta)</h3><p>Afinitas node diperkenalkan sebagai fitur alfa pada Kubernetes 1.2.
Afinitas node secara konseptual mirip dengan <code>nodeSelector</code> yang memungkinkan kamu untuk membatasi node yang memenuhi syarat untuk penjadwalan pod, berdasarkan label pada node.</p><p>Saat ini ada dia tipe afinitas node, yaitu <code>requiredDuringSchedulingIgnoredDuringExecution</code> dan
<code>preferredDuringSchedulingIgnoredDuringExecution</code>. Kamu dapat menganggap dua tipe ini sebagai "kuat" dan "lemah" secara berurutan, dalam arti tipe pertama menyatakan peraturan yang <em>harus</em> dipenuhi agar pod dapat dijadwalkan pada node (sama seperti <code>nodeSelector</code> tetapi menggunakan sintaksis yang lebih ekpresif), sementara tipe kedua menyatakan <em>preferensi</em> yang akan dicoba dilaksanakan tetapi tidak akan dijamin oleh scheduler. Bagian "IgnoredDuringExecution" dari nama tipe ini berarti, mirip dengan cara kerja <code>nodeSelector</code>, jika label pada node berubah pada <em>runtime</em> yang menyebabkan aturan afinitas pada pod tidak lagi terpenuhi, pod akan tetap berjalan pada node. Pada masa yang akan datang kami berencana menawarkan <code>requiredDuringSchedulingRequiredDuringExecution</code> yang akan berjalan seperti <code>requiredDuringSchedulingIgnoredDuringExecution</code> hanya saja tipe ini akan mengeluarkan pod dari node yang gagal untuk memenuhi persyaratan afinitas node pod.</p><p>Dengan denikian, contoh dari <code>requiredDuringSchedulingIgnoredDuringExecution</code> adalah "hanya jalankan pod pada node dengan Intel CPU" dan contoh dari <code>preferredDuringSchedulingIgnoredDuringExecution</code> adalah "coba jalankan set pod ini dalam zona ketersediaan XYZ, tetapi jika tidak memungkinkan, maka biarkan beberapa pod berjalan di tempat lain".</p><p>Afinitas node dinyatakan sebagai <em>field</em> <code>nodeAffinity</code> dari <em>field</em> <code>affinity</code> pada PodSpec.</p><p>Berikut ini contoh dari pod yang menggunakan afinitas node:</p><div class=highlight><div class=copy-code-icon style=text-align:right><a href=https://raw.githubusercontent.com/kubernetes/website/main/content/id/examples/pods/pod-with-node-affinity.yaml download=pods/pod-with-node-affinity.yaml><code>pods/pod-with-node-affinity.yaml</code></a>
<img src=/images/copycode.svg style=max-height:24px;cursor:pointer onclick='copyCode("pods-pod-with-node-affinity-yaml")' title="Copy pods/pod-with-node-affinity.yaml to clipboard"></img></div><div class=includecode id=pods-pod-with-node-affinity-yaml><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>with-node-affinity<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>affinity</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>nodeAffinity</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>requiredDuringSchedulingIgnoredDuringExecution</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>nodeSelectorTerms</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span>- <span style=color:green;font-weight:700>matchExpressions</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span>- <span style=color:green;font-weight:700>key</span>:<span style=color:#bbb> </span>kubernetes.io/e2e-az-name<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>            </span><span style=color:green;font-weight:700>operator</span>:<span style=color:#bbb> </span>In<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>            </span><span style=color:green;font-weight:700>values</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>            </span>- e2e-az1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>            </span>- e2e-az2<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>preferredDuringSchedulingIgnoredDuringExecution</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- <span style=color:green;font-weight:700>weight</span>:<span style=color:#bbb> </span><span style=color:#666>1</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>preference</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>matchExpressions</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span>- <span style=color:green;font-weight:700>key</span>:<span style=color:#bbb> </span>another-node-label-key<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>            </span><span style=color:green;font-weight:700>operator</span>:<span style=color:#bbb> </span>In<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>            </span><span style=color:green;font-weight:700>values</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>            </span>- another-node-label-value<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>with-node-affinity<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>k8s.gcr.io/pause:2.0</span></span></code></pre></div></div></div><p>Aturan afinitas node tersebut menyatakan pod hanya bisa ditugaskan pada node dengan label yang memiliki kunci <code>kubernetes.io/e2e-az-name</code> dan bernilai <code>e2e-az1</code> atau <code>e2e-az2</code>. Selain itu, dari semua node yang memenuhi kriteria tersebut, mode dengan label dengan kunci <code>another-node-label-key</code> and bernilai <code>another-node-label-value</code> harus lebih diutamakan.</p><p>Kamu dapat meilhat operator <code>In</code> digunakan dalam contoh berikut. Sitaksis afinitas node yang baru mendukung operator-operator berikut: <code>In</code>, <code>NotIn</code>, <code>Exists</code>, <code>DoesNotExist</code>, <code>Gt</code>, <code>Lt</code>. Kamu dapat menggunakan <code>NotIn</code> dan <code>DoesNotExist</code> untuk mewujudkan perilaku node anti-afinitas, atau menggunakan <a href=/id/docs/concepts/scheduling-eviction/taint-and-toleration/>node taints</a> untuk menolak pod dari node tertentu.</p><p>Jika kamu menyatakan <code>nodeSelector</code> dan <code>nodeAffinity</code>. <em>keduanya</em> harus dipenuhi agar pod dapat dijadwalkan pada node kandidat.</p><p>Jika kamu menyatakan beberapa <code>nodeSelectorTerms</code> yang terkait dengan tipe <code>nodeAffinity</code>, maka pod akan dijadwalkan pada node <strong>jika salah satu</strong> dari <code>nodeSelectorTerms</code> dapat terpenuhi.</p><p>Jika kamu menyatakan beberapa <code>matchExpressions</code> yang terkait dengan <code>nodeSelectorTerms</code>, makan pod dapat dijadwalkan pada node <strong>hanya jika semua</strong> <code>matchExpressions</code> dapat terpenuhi.</p><p>Jika kamu menghapus atau mengubah label pada node tempat pod dijadwalkan, pod tidak akan dihapus. Dengan kata lain, pemilihan afinitas hanya bekerja pada saat waktu penjadwalan pod.</p><p><em>Field</em> <code>weight</code> pada <code>preferredDuringSchedulingIgnoredDuringExecution</code> berada pada rentang nilai 1-100. Untuk setiap node yang memenuhi semua persyaratan penjadwalan (permintaan sumber daya, pernyataan afinitas RequiredDuringScheduling, dll.), <em>scheduler</em> akan menghitung nilai jumlah dengan melakukan iterasi pada elemen-elemen dari <em>field</em> ini dan menambah "bobot" pada jumlah jika node cocok dengan MatchExpressions yang sesuai. Nilai ini kemudian digabungkan dengan nilai dari fungsi prioritas lain untuk node. Node dengan nilai tertinggi adalah node lebih diutamakan.</p><p>Untuk informasi lebih lanjut tentang afinitas node kamu dapat melihat <a href=https://git.k8s.io/community/contributors/design-proposals/scheduling/nodeaffinity.md>design doc</a>.</p><h3 id=afinitas-and-anti-afinitas-antar-pod-fitur-beta>Afinitas and anti-afinitas antar pod (fitur beta)</h3><p>Afinitas and anti-afinitas antar pod diperkenalkan pada Kubernetes 1.4. Afinitas and anti-afinitas antar pod memungkinkan kamu untuk membatasi node yang memenuhi syarat untuk penjadwalan pod <em>berdasarkan label-label pada pod yang sudah berjalan pada node</em> daripada berdasarkan label-label pada node. Aturan tersebut berbentuk "pod ini harus (atau, dalam kasus
anti-afinitas, tidak boleh) berjalan dalam X jika X itu sudah menjalankan satu atau lebih pod yang memenuhi aturan Y". Y dinyatakan sebagai sebuah LabelSelector dengan daftar namespace terkait; tidak seperti node, karena pod are namespaced (maka dari itu label-label pada pod diberi namespace secara implisit), sebuah label selector di atas label-label pod harus menentukan namespace yang akan diterapkan selector. Secara konsep X adalah domain topologi seperti node, rack, zona penyedia cloud, daerah penyedia cloud, dll. Kamu dapat menyatakannya menggunakan <code>topologyKey</code> yang merupakan kunci untuk label node yang digunakan sistem untuk menunjukkan domain topologi tersebut, contohnya lihat kunci label yang terdaftar di atas pada bagian <a href=#interlude-built-in-node-labels>Selingan: label node built-in</a>.</p><div class="alert alert-info note callout" role=alert><strong>Catatan:</strong> Afinitas and anti-afinitas antar pod membutuhkan jumlah pemrosesan yang substansial yang dapat memperlambat penjadwalan pada klaster berukuran besar secara signifikan. Kami tidak merekomendasikan penggunaan mereka pada klaster yang berukuran lebih besar dari beberapa ratus node.</div><div class="alert alert-info note callout" role=alert><strong>Catatan:</strong> Anti-afinitas pod mengharuskan node untuk diberi label secara konsisten, misalnya setiap node dalam klaster harus memiliki label sesuai yang cocok dengan <code>topologyKey</code>. Jika sebagian atau semua node tidak memiliki label <code>topologyKey</code> yang dinyatakan, hal ini dapat menyebabkan perilaku yang tidak diinginkan.</div><p>Seperti afinitas node, ada dua tipe afinitas dan anti-afinitas pod, yaitu <code>requiredDuringSchedulingIgnoredDuringExecution</code> dan
<code>preferredDuringSchedulingIgnoredDuringExecution</code> yang menunjukan persyaratan "kuat" vs. "lemah". Lihat deskripsi pada bagian afinitas node sebelumnya.
Sebuah contoh dari afinitas <code>requiredDuringSchedulingIgnoredDuringExecution</code> adalah "Tempatkan bersamaan pod layanan A dan layanan B di zona yang sama, karena mereka banyak berkomunikasi satu sama lain"
dan contoh <code>preferDuringSchedulingIgnoredDuringExecution</code> anti-afinitas akan menjadi "sebarkan pod dari layanan ini di seluruh zona" (persyaratan kuat tidak masuk akal, karena kamu mungkin memiliki lebih banyak pod daripada zona).</p><p>Afinitas antar pod dinyatakan sebagai <em>field</em> <code>podAffinity</code> dari <em>field</em> <code>affinity</code> pada PodSpec dan anti-afinitas antar pod dinyatakan sebagai <em>field</em> <code>podAntiAffinity</code> dari <em>field</em> <code>affinity</code> pada PodSpec.</p><h4 id=contoh-pod-yang-menggunakan-pod-affinity>Contoh pod yang menggunakan pod affinity:</h4><div class=highlight><div class=copy-code-icon style=text-align:right><a href=https://raw.githubusercontent.com/kubernetes/website/main/content/id/examples/pods/pod-with-pod-affinity.yaml download=pods/pod-with-pod-affinity.yaml><code>pods/pod-with-pod-affinity.yaml</code></a>
<img src=/images/copycode.svg style=max-height:24px;cursor:pointer onclick='copyCode("pods-pod-with-pod-affinity-yaml")' title="Copy pods/pod-with-pod-affinity.yaml to clipboard"></img></div><div class=includecode id=pods-pod-with-pod-affinity-yaml><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>with-pod-affinity<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>affinity</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>podAffinity</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>requiredDuringSchedulingIgnoredDuringExecution</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- <span style=color:green;font-weight:700>labelSelector</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>matchExpressions</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span>- <span style=color:green;font-weight:700>key</span>:<span style=color:#bbb> </span>security<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>            </span><span style=color:green;font-weight:700>operator</span>:<span style=color:#bbb> </span>In<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>            </span><span style=color:green;font-weight:700>values</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>            </span>- S1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>topologyKey</span>:<span style=color:#bbb> </span>failure-domain.beta.kubernetes.io/zone<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>podAntiAffinity</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>preferredDuringSchedulingIgnoredDuringExecution</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- <span style=color:green;font-weight:700>weight</span>:<span style=color:#bbb> </span><span style=color:#666>100</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>podAffinityTerm</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>labelSelector</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>            </span><span style=color:green;font-weight:700>matchExpressions</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>            </span>- <span style=color:green;font-weight:700>key</span>:<span style=color:#bbb> </span>security<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>              </span><span style=color:green;font-weight:700>operator</span>:<span style=color:#bbb> </span>In<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>              </span><span style=color:green;font-weight:700>values</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>              </span>- S2<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>topologyKey</span>:<span style=color:#bbb> </span>failure-domain.beta.kubernetes.io/zone<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>with-pod-affinity<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>k8s.gcr.io/pause:2.0<span style=color:#bbb>
</span></span></span></code></pre></div></div></div><p>Afinitas pada pod tersebut menetapkan sebuah aturan afinitas pod dan aturan anti-afinitas pod. Pada contoh ini, <code>podAffinity</code> adalah <code>requiredDuringSchedulingIgnoredDuringExecution</code>
sementara <code>podAntiAffinity</code> adalah <code>preferredDuringSchedulingIgnoredDuringExecution</code>. Aturan afinitas pod menyatakan bahwa pod dapat dijadwalkan pada node hanya jika node tersebut berada pada zona yang sama dengan minimal satu pod yang sudah berjalan yang memiliki label dengan kunci "security" dan bernilai "S1". (Lebih detail, pod dapat berjalan pada node N jika node N memiliki label dengan kunci <code>failure-domain.beta.kubernetes.io/zone</code>dan nilai V sehingga ada minimal satu node dalam klaster dengan kunci <code>failure-domain.beta.kubernetes.io/zone</code> dan bernilai V yang menjalankan pod yang memiliki label dengan kunci "security" dan bernilai "S1".) Aturan anti-afinitas pod menyatakan bahwa pod memilih untuk tidak dijadwalkan pada sebuah node jika node tersebut sudah menjalankan pod yang memiliki label dengan kunci "security" dan bernilai "S2". (Jika <code>topologyKey</code> adalah <code>failure-domain.beta.kubernetes.io/zone</code> maka dapat diartikan bahwa pod tidak dapat dijadwalkan pada node jika node berada pada zona yang sama dengan pod yang memiliki label dengan kunci "security" dan bernilai "S2".) Lihat <a href=https://git.k8s.io/community/contributors/design-proposals/scheduling/podaffinity.md>design doc</a> untuk lebih banyak contoh afinitas dan anti-afinitas pod, baik <code>requiredDuringSchedulingIgnoredDuringExecution</code>
maupun <code>preferredDuringSchedulingIgnoredDuringExecution</code>.</p><p>Operator yang sah untuk afinitas dan anti-afinitas pod adalah <code>In</code>, <code>NotIn</code>, <code>Exists</code>, <code>DoesNotExist</code>.</p><p>Pada dasarnya, <code>topologyKey</code> dapat berupa label-kunci apapun yang sah. Namun, untuk alasan performa dan keamanan, ada beberapa batasan untuk <code>topologyKey</code>:</p><ol><li>Untuk afinitas and anti-afinitas pod <code>requiredDuringSchedulingIgnoredDuringExecution</code>, <code>topologyKey</code> tidak boleh kosong.</li><li>Untuk anti-afinitas pod <code>requiredDuringSchedulingIgnoredDuringExecution</code>, pengontrol penerimaan <code>LimitPodHardAntiAffinityTopology</code> diperkenalkan untuk membatasi <code>topologyKey</code> pada <code>kubernetes.io/hostname</code>. Jika kamu menginginkan untuk membuatnya tersedia untuk topologi khusus, kamu dapat memodifikasi pengontrol penerimaan, atau cukup menonaktifkannya saja.</li><li>Untuk anti-afinitas pod <code>preferredDuringSchedulingIgnoredDuringExecution</code>, <code>topologyKey</code> yang kosong diinterpretasikan sebagai "semua topologi" ("semua topologi" sekarang dibatasi pada kombinasi dari <code>kubernetes.io/hostname</code>, <code>failure-domain.beta.kubernetes.io/zone</code> dan <code>failure-domain.beta.kubernetes.io/region</code>).</li><li>Kecuali untuk kasus-kasus di atas, <code>topologyKey</code> dapat berupa label-kunci apapun yang sah.</li></ol><p>Sebagai tambahan untuk <code>labelSelector</code> and <code>topologyKey</code>, kamu secara opsional dapat menyatakan daftar <code>namespaces</code> dari namespaces yang akan digunakan untuk mencocokan <code>labelSelector</code> (daftar ini berjalan pada level definisi yang sama dengan <code>labelSelector</code> dan <code>topologyKey</code>)</p><p>Jika dihilangkan atau kosong, daftar ini sesuai standar akan merujuk pada <em>namespace</em> dari pod tempat definisi afinitas/anti-afinitas dinyatakan.</p><p>Semua <code>matchExpressions</code> berkaitan dengan afinitas and anti-afinitas <code>requiredDuringSchedulingIgnoredDuringExecution</code> harus dipenuhi agar pod dapat dijadwalkan pada node.</p><h4 id=penggunaan-yang-lebih-praktikal>Penggunaan yang lebih praktikal</h4><p>Afinitas and anti-afinitas antar pod dapat menjadi lebih berguna saat digunakan bersamaan dengan koleksi dengan level yang lebih tinggi seperti ReplicaSets, StatefulSets, Deployments, dll. Pengguna dapat dengan mudah mengkonfigurasi bahwa satu set workload harus
ditempatkan bersama dalam topologi yang didefinisikan sama, misalnya, node yang sama.</p><h5 id=selalu-ditempatkan-bersamaan-pada-node-yang-sama>Selalu ditempatkan bersamaan pada node yang sama</h5><p>Dalam klaster berisi 3 node, sebuah aplikasi web memiliki in-memory cache seperti redis. Kita menginginkan agar <em>web-server</em> dari aplikasi ini sebisa mungkin ditempatkan bersamaan dengan cache.</p><p>Berikut ini kutipan yaml dari deployment redis sederhana dengan 3 replika dan label selector <code>app=store</code>, Deployment memiliki konfigurasi <code>PodAntiAffinity</code> untuk memastikan <em>scheduler</em> tidak menempatkan replika bersamaan pada satu node.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>apps/v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Deployment<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>redis-cache<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>selector</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>matchLabels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>app</span>:<span style=color:#bbb> </span>store<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>replicas</span>:<span style=color:#bbb> </span><span style=color:#666>3</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>template</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>labels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>app</span>:<span style=color:#bbb> </span>store<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>affinity</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>podAntiAffinity</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>requiredDuringSchedulingIgnoredDuringExecution</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span>- <span style=color:green;font-weight:700>labelSelector</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>              </span><span style=color:green;font-weight:700>matchExpressions</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>              </span>- <span style=color:green;font-weight:700>key</span>:<span style=color:#bbb> </span>app<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>                </span><span style=color:green;font-weight:700>operator</span>:<span style=color:#bbb> </span>In<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>                </span><span style=color:green;font-weight:700>values</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>                </span>- store<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>            </span><span style=color:green;font-weight:700>topologyKey</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;kubernetes.io/hostname&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>redis-server<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>redis:3.2-alpine<span style=color:#bbb>
</span></span></span></code></pre></div><p>Kutipan yaml dari deployment webserver berikut ini memiliki konfigurasi <code>podAntiAffinity</code> dan <code>podAffinity</code>. Konfigurasi ini menginformasikan scheduler bahwa semua replika harus ditempatkan bersamaan dengan pod yang memiliki label selector <code>app=store</code>. Konfigurasi ini juga memastikan bahwa setiap replika webserver tidak ditempatkan bersamaan pada satu node.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>apps/v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Deployment<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>web-server<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>selector</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>matchLabels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>app</span>:<span style=color:#bbb> </span>web-store<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>replicas</span>:<span style=color:#bbb> </span><span style=color:#666>3</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>template</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>labels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>app</span>:<span style=color:#bbb> </span>web-store<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>affinity</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>podAntiAffinity</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>requiredDuringSchedulingIgnoredDuringExecution</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span>- <span style=color:green;font-weight:700>labelSelector</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>              </span><span style=color:green;font-weight:700>matchExpressions</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>              </span>- <span style=color:green;font-weight:700>key</span>:<span style=color:#bbb> </span>app<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>                </span><span style=color:green;font-weight:700>operator</span>:<span style=color:#bbb> </span>In<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>                </span><span style=color:green;font-weight:700>values</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>                </span>- web-store<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>            </span><span style=color:green;font-weight:700>topologyKey</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;kubernetes.io/hostname&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>podAffinity</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>requiredDuringSchedulingIgnoredDuringExecution</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span>- <span style=color:green;font-weight:700>labelSelector</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>              </span><span style=color:green;font-weight:700>matchExpressions</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>              </span>- <span style=color:green;font-weight:700>key</span>:<span style=color:#bbb> </span>app<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>                </span><span style=color:green;font-weight:700>operator</span>:<span style=color:#bbb> </span>In<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>                </span><span style=color:green;font-weight:700>values</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>                </span>- store<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>            </span><span style=color:green;font-weight:700>topologyKey</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;kubernetes.io/hostname&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>web-app<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>nginx:1.12-alpine<span style=color:#bbb>
</span></span></span></code></pre></div><p>Jika kita membuat kedua dployment di atas, klaster berisi 3 node kita seharusnya menjadi seperti berikut.</p><table><thead><tr><th style=text-align:center>node-1</th><th style=text-align:center>node-2</th><th style=text-align:center>node-3</th></tr></thead><tbody><tr><td style=text-align:center><em>webserver-1</em></td><td style=text-align:center><em>webserver-2</em></td><td style=text-align:center><em>webserver-3</em></td></tr><tr><td style=text-align:center><em>cache-1</em></td><td style=text-align:center><em>cache-2</em></td><td style=text-align:center><em>cache-3</em></td></tr></tbody></table><p>st
Seperti yang kamu lihat, semua 3 replika dari <code>web-server</code> secara otomatis ditempatkan bersama dengan cache seperti yang diharapkan.</p><pre tabindex=0><code>$ kubectl get pods -o wide
NAME                           READY     STATUS    RESTARTS   AGE       IP           NODE
redis-cache-1450370735-6dzlj   1/1       Running   0          8m        10.192.4.2   kube-node-3
redis-cache-1450370735-j2j96   1/1       Running   0          8m        10.192.2.2   kube-node-1
redis-cache-1450370735-z73mh   1/1       Running   0          8m        10.192.3.1   kube-node-2
web-server-1287567482-5d4dz    1/1       Running   0          7m        10.192.2.3   kube-node-1
web-server-1287567482-6f7v5    1/1       Running   0          7m        10.192.4.3   kube-node-3
web-server-1287567482-s330j    1/1       Running   0          7m        10.192.3.2   kube-node-2
</code></pre><h5 id=tidak-akan-pernah-ditempatkan-bersamaan-dalam-node-yang-sama>Tidak akan pernah ditempatkan bersamaan dalam node yang sama</h5><p>Contoh di atas menggunakan aturan <code>PodAntiAffinity</code> dengan <code>topologyKey: "kubernetes.io/hostname"</code> untuk melakukan deploy klaster redis sehingga tidak ada dua instance terletak pada hos yang sama.
Lihat <a href=/docs/tutorials/stateful-application/zookeeper/#tolerating-node-failure>tutorial ZooKeeper</a> untuk contoh dari konfigurasi StatefulSet dengan anti-afinitas untuk ketersediaan tinggi, menggunakan teknik yang sama.</p><p>Untuk informasi lebih lanjut tentang afinitas/anti-afinitas antar pod, lihat <a href=https://git.k8s.io/community/contributors/design-proposals/scheduling/podaffinity.md>design doc</a>.</p><p>Kamu juga dapat mengecek <a href=/id/docs/concepts/scheduling-eviction/taint-and-toleration/>Taints</a>, yang memungkinkan sebuah <em>node</em> untuk <em>menolak</em> sekumpulan pod.</p><h2 id=nodename>nodeName</h2><p><code>nodeName</code> adalah bentuk paling sederhana dari pembatasan pemilihan node, tetapi karena
keterbatasannya biasanya tidak digunakan. <code>nodeName</code> adalah sebuah <em>field</em> dari
PodSpec. Jika tidak kosong, scheduler mengabaikan pod dan
kubelet yang berjalan pada node tersebut yang mencoba menjalankan pod. Maka, jika
<code>nodeName</code> disediakan dalam PodSpec, ia memiliki hak yang lebih tinggi dibanding metode-metode di atas untuk pemilihan node.</p><p>Beberapa keterbatasan dari penggunaan <code>nodeName</code> untuk memilih node adalah:</p><ul><li>Jika node yang disebut tidak ada, maka pod tidak akan dijalankan, dan dalam beberapa kasus akan
dihapus secara otomatis.</li><li>Jika node yang disebut tidak memiliki resource yang cukup untuk mengakomodasi pod, pod akan gagal
dan alasannya akan mengindikasikan sebab kegagalan, misalnya OutOfmemory atau OutOfcpu.</li><li>Nama node pada lingkungan cloud tidak selalu dapat diprediksi atau stabil.</li></ul><p>Berikut ini contoh konfigurasi pod menggunakan <em>field</em> <code>nodeName</code>:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>nginx<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>nginx<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>nginx<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>nodeName</span>:<span style=color:#bbb> </span>kube-01<span style=color:#bbb>
</span></span></span></code></pre></div><p>Pod di atas akan berjalan pada node kube-01.</p><h2 id=selanjutnya>Selanjutnya</h2></div><div class=td-content style=page-break-before:always><h1 id=pg-ede4960b56a3529ee0bfe7c8fe2d09a5>9.4 - Taint dan Toleration</h1><p>Afinitas Node, seperti yang dideskripsikan <a href=/id/docs/concepts/configuration/assign-pod-node/#node-affinity-beta-feature>di sini</a>,
adalah salah satu properti dari Pod yang menyebabkan pod tersebut memiliki preferensi
untuk ditempatkan di sekelompok Node tertentu (preferensi ini dapat berupa <em>soft constraints</em> atau
<em>hard constraints</em> yang harus dipenuhi). <em>Taint</em> merupakan kebalikan dari afinitas --
properti ini akan menyebabkan Pod memiliki preferensi untuk tidak ditempatkan pada sekelompok Node tertentu.</p><p><em>Taint</em> dan <em>toleration</em> bekerja sama untuk memastikan Pod dijadwalkan pada Node
yang sesuai. Satu atau lebih <em>taint</em> akan diterapkan pada suatu node; hal ini akan menyebabkan
node tidak akan menerima pod yang tidak mengikuti <em>taint</em> yang sudah diterapkan.</p><h2 id=konsep>Konsep</h2><p>Kamu dapat menambahkan <em>taint</em> pada sebuah <em>node</em> dengan menggunakan perintah <a href=/docs/reference/generated/kubectl/kubectl-commands#taint>kubectl taint</a>.
Misalnya,</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl taint nodes node1 <span style=color:#b8860b>key</span><span style=color:#666>=</span>value:NoSchedule
</span></span></code></pre></div><p>akan menerapkan <em>taint</em> pada <em>node</em> <code>node1</code>. <em>Taint</em> tersebut memiliki <em>key</em> <code>key</code>, <em>value</em> <code>value</code>,
dan <em>effect</em> <em>taint</em> <code>NoSchedule</code>. Hal ini artinya pod yang ada tidak akan dapat dijadwalkan pada <code>node1</code>
kecuali memiliki <em>taint</em> yang sesuai.</p><p>Untuk menghilangkan <em>taint</em> yang ditambahkan dengan perintah di atas, kamu dapat menggunakan
perintah di bawah ini:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl taint nodes node1 key:NoSchedule-
</span></span></code></pre></div><p>Kamu dapat memberikan spesifikasi <em>toleration</em> untuk <em>pod</em> pada bagian PodSpec.
Kedua <em>toleration</em> yang diterapkan di bawa ini "sesuai" dengan <em>taint</em> yang
<em>taint</em> yang dibuat dengan perintah <code>kubectl taint</code> di atas, sehingga sebuah <em>pod</em>
dengan <em>toleration</em> yang sudah didefinisikan akan mampu di-<em>schedule</em> ke node <code>node</code>:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>tolerations</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span>- <span style=color:green;font-weight:700>key</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;key&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>operator</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;Equal&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>value</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;value&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>effect</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;NoSchedule&#34;</span><span style=color:#bbb>
</span></span></span></code></pre></div><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>tolerations</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span>- <span style=color:green;font-weight:700>key</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;key&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>operator</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;Exists&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>effect</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;NoSchedule&#34;</span><span style=color:#bbb>
</span></span></span></code></pre></div><p>Sebuah <em>toleration</em> "sesuai" dengan sebuah <em>taint</em> jika <em>key</em> dan efek yang
ditimbulkan sama:</p><ul><li><code>operator</code> dianggap <code>Exists</code> (pada kasus dimana tidak ada <code>value</code> yang diberikan), atau</li><li><code>operator</code> dianggap <code>Equal</code> dan <code>value</code> yang ada sama</li></ul><p><code>Operator</code> bernilai <code>Equal</code> secara <em>default</em> jika tidak diberikan spesifikasi khusus.</p><div class="alert alert-info note callout" role=alert><strong>Catatan:</strong><p>Terdapat dua kasus khusus:</p><ul><li>Sebuah <code>key</code> dengan operator <code>Exists</code> akan sesuai dengan semua <em>key</em>, <em>value</em>, dan <em>effect</em> yang ada.
Dengan kata lain, <em>tolaration</em> ini akan menerima semua hal yang diberikan.</li></ul><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>tolerations</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span>- <span style=color:green;font-weight:700>operator</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;Exists&#34;</span><span style=color:#bbb>
</span></span></span></code></pre></div><ul><li>Sebuah <code>effect</code> yang kosong akan dianggap sesuai dengan semua <em>effect</em> dengan <em>key</em> <code>key</code>.</li></ul><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>tolerations</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span>- <span style=color:green;font-weight:700>key</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;key&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>operator</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;Exists&#34;</span><span style=color:#bbb>
</span></span></span></code></pre></div></div><p>Contoh yang diberikan di atas menggunakan <code>effect</code> untuk <code>NoSchedule</code>.
Alternatif lain yang dapat digunakan adalah <code>effect</code> untuk <code>PreferNoSchedule</code>.
<code>PreferNoSchedule</code> merupakan "preferensi" yang lebih fleksibel dari <code>NoSchedule</code> --
sistem akan mencoba untuk tidak menempatkan pod yang tidak menoleransi <em>taint</em>
pada <em>node</em>, tapi hal ini bukan merupakan sesuatu yang harus dipenuhi. Jenis ketiga
dari <code>effect</code> adalah <code>NoExecute</code>, akan dijelaskan selanjutnya.</p><p>Kamu dapat menerapkan beberapa <em>taint</em> sekaligus pada <em>node</em> atau
beberapa <em>toleration</em> sekaligus pada sebuah <em>pod</em>. Mekanisme Kubernetes dapat
memproses beberapa <em>taint</em> dan <em>toleration</em> sekaligus sama halnya seperti sebuah
<em>filter</em>: memulai dengan <em>taint</em> yang ada pada <em>node</em>, kemudian mengabaikan
<em>taint</em> yang sesuai pada pod yang memiliki <em>toleration</em> yang sesuai; kemudian
<em>taint</em> yang diterapkan pada pod yang sudah disaring tadi akan menghasilkan suatu
<em>effect</em> pada pod. Secara khusus:</p><ul><li>jika terdapat <em>taint</em> yang tidak tersaring dengan <em>effect</em> <code>NoSchedule</code> maka Kubernetes tidak akan menempatkan
<em>pod</em> pada <em>node</em> tersebut</li><li>jika tidak terdapat <em>taint</em> yang tidak tersaring dengan <em>effect</em> <code>NoSchedule</code>
tapi terdapat setidaknya satu <em>taint</em> yang tidak tersaring dengan
<em>effect</em> <code>PreferNoSchedule</code> maka Kubernetes akan mencoba untuk tidak akan menempatkan
<em>pod</em> pada <em>node</em> tersebut</li><li>jika terdapat <em>taint</em> yang tidak tersaring dengan <em>effect</em> <code>NoExecute</code> maka <em>pod</em> akan
berada dalam kondisi <em>evicted</em> dari <em>node</em> (jika <em>pod</em> tersebut sudah terlanjur ditempatkan pada <em>node</em>
tersebut), dan tidak akan di-<em>schedule</em> lagi pada <em>node</em> tersebut.</li></ul><p>Sebagai contoh, bayangkan kamu memberikan <em>taint</em> pada <em>node</em> sebagai berikut:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl taint nodes node1 <span style=color:#b8860b>key1</span><span style=color:#666>=</span>value1:NoSchedule
</span></span><span style=display:flex><span>kubectl taint nodes node1 <span style=color:#b8860b>key1</span><span style=color:#666>=</span>value1:NoExecute
</span></span><span style=display:flex><span>kubectl taint nodes node1 <span style=color:#b8860b>key2</span><span style=color:#666>=</span>value2:NoSchedule
</span></span></code></pre></div><p>Dan <em>pod</em> memiliki dua <em>toleration</em>:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>tolerations</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span>- <span style=color:green;font-weight:700>key</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;key1&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>operator</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;Equal&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>value</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;value1&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>effect</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;NoSchedule&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span>- <span style=color:green;font-weight:700>key</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;key1&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>operator</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;Equal&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>value</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;value1&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>effect</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;NoExecute&#34;</span><span style=color:#bbb>
</span></span></span></code></pre></div><p>Pada kasus ini, <em>pod</em> tidak akan di-<em>schedule</em> pada <em>node</em>, karena tidak ada
<em>toleration</em> yang sesuai dengan <em>taint</em> ketiga. Akan tetapi, <em>pod</em> yang sebelumnya
sudah dijalankan di <em>node</em> dimana <em>taint</em> ditambahkan akan tetap jalan, karena <em>taint</em>
ketiga merupakan <em>taint</em> yang tidak ditoleransi oleh <em>pod</em>.</p><p>Pada umumnya, jika sebuah <em>taint</em> memiliki <em>effect</em> <code>NoExecute</code> ditambahkan pada <em>node</em>,
maka semua pod yang tidak menoleransi <em>taint</em> tersebut akan berada dalam <em>state</em>
<em>evicted</em> secara langsung, dan semua <em>pod</em> yang menoleransi <em>taint</em> tersebut
tidak akan berjalan seperti biasanya (tidak dalam <em>state</em> <em>evicted</em>). Meskipun demikian,
<em>toleration</em> dengan <em>effect</em> <code>NoExecute</code> dapat dispesfikasikan sebagai <em>field</em> opsional
<code>tolerationSeconds</code> yang memberikan perintah berapa lama suatu <em>pod</em> akan berada
pada <em>node</em> apabila sebuah <em>taint</em> ditambahkan. Contohnya:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>tolerations</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span>- <span style=color:green;font-weight:700>key</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;key1&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>operator</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;Equal&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>value</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;value1&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>effect</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;NoExecute&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>tolerationSeconds</span>:<span style=color:#bbb> </span><span style=color:#666>3600</span><span style=color:#bbb>
</span></span></span></code></pre></div><p>ini berarti apabila sebuah <em>pod</em> sedang dalam berada dalam <em>state</em> <em>running</em>,
kemudian sebuah <em>taint</em> yang sesuai ditambahkan pada <em>node</em>, maka <em>pod</em> tersebut
akan tetap berada di dalam <em>node</em> untuk periode 3600 detik sebelum <em>state</em>-nya
berubah menjadi <em>evicted</em>. Jika <em>taint</em> dihapus sebelum periode tersebut, maka <em>pod</em>
tetap berjalan sebagaimana mestinya.</p><h2 id=contoh-penggunaan>Contoh Penggunaan</h2><p><em>Taint</em> dan <em>toleration</em> adalah mekanisme fleksibel yang digunakan untuk
memaksa <em>pod</em> agar tidak dijadwalkan pada <em>node-node</em> tertentu atau
mengubah <em>state</em> <em>pod</em> menjadi <em>evicted</em>. Berikut adalah beberapa contoh penggunaannya:</p><ul><li><p><strong>Node-Node yang Sifatnya <em>Dedicated</em></strong>: Jika kamu ingin menggunakan
sekumpulan <em>node</em> dengan penggunaan eksklusif dari sekumpulan pengguna,
kamu dapat menambahkan <em>taint</em> pada <em>node-node</em> tersebut (misalnya,
<code>kubectl taint nodes nodename dedicated=groupName:NoSchedule</code>) dan kemudian
menambahkan <em>toleration</em> yang sesuai pada <em>pod-pod</em> yang berada di dalamnya (hal ini
dapat dilakukan dengan mudah dengan cara menulis
<a href=/docs/reference/access-authn-authz/admission-controllers/><em>admission controller</em></a> yang
bersifat khusus). <em>Pod-pod</em> dengan <em>toleration</em> nantinya akan diperbolehkannya untuk menggunakan
<em>node</em> yang sudah di-<em>taint</em> (atau dengan kata lain didedikasikan penggunaannya) maupun
<em>node</em> lain yang ada di dalam klaster. Jika kamu ingin mendedikasikan <em>node</em> khusus
yang hanya digunakan oleh <em>pod-pod</em> tadi serta memastikan <em>pod-pod</em> tadi hanya menggunakan
<em>node</em> yang didedikasikan, maka kamu harus menambahkan sebuah <em>label</em> yang serupa dengan
<em>taint</em> yang diberikan pada sekelompok <em>node</em> (misalnya, <code>dedicated=groupName</code>), dan
<em>admission controller</em> sebaiknya menambahkan afininitas <em>node</em> untuk memastikan <em>pod-pod</em>
tadi hanya dijadwalkan pada <em>node</em> dengan <em>label</em> <code>dedicated=groupName</code>.</p></li><li><p><strong>Node-Node dengan Perangkat Keras Khusus</strong>: Pada suatu klaster dimana
sebagian kecuali <em>node</em> memiliki perangkat keras khusus (misalnya GPU), kita ingin
memastikan hanya <em>pod-pod</em> yang membutuhkan GPU saja yang dijadwalkan di <em>node</em> dengan GPU.
Hal ini dapat dilakukan dengan memberikan <em>taint</em> pada <em>node</em> yang memiliki perangkat keras
khusus (misalnya, <code>kubectl taint nodes nodename special=true:NoSchedule</code> atau
<code>kubectl taint nodes nodename special=true:PreferNoSchedule</code>) serta menambahkan <em>toleration</em>
yang sesuai pada <em>pod</em> yang menggunakan <em>node</em> dengan perangkat keras khusus. Seperti halnya pada
kebutuhan <em>dedicated</em> <em>node</em>, hal ini dapat dilakukan dengan mudah dengan cara menulis
<a href=/docs/reference/access-authn-authz/admission-controllers/><em>admission controller</em></a> yang
bersifat khusus. Misalnya, kita dapat menggunakan <a href=/id/docs/concepts/configuration/manage-compute-resources-container/#extended-resources><em>Extended Resource</em></a>
untuk merepresentasikan perangkat keras khusus, kemudian <em>taint</em> <em>node</em> dengan perangkat keras khusus
dengan nama <em>extended resource</em> dan jalankan <em>admission controller</em>
<a href=/docs/reference/access-authn-authz/admission-controllers/#extendedresourcetoleration>ExtendedResourceToleration</a>.
Setelah itu, karena <em>node</em> yang ada sudah di-<em>taint</em>, maka tidak akan ada <em>pod</em> yang
tidak memiliki <em>toleration</em> yang akan dijadwalkan pada <em>node</em> tersebut_.
Meskipun begitu, ketika kamu membuat suatu <em>pod</em> yang membutuhkan <em>extended resource</em>,
maka <em>admission controller</em> dari <code>ExtendedResourceToleration</code> akan mengoreksi
<em>toleration</em> sehingga <em>pod</em> tersebut dapat dijadwalkan pada <em>node</em> dengan perangkat keras khusus.
Dengan demikian, kamu tidak perlu menambahkan <em>toleration</em> secara manual pada pod yang ada.</p></li><li><p><strong><em>Eviction</em> berbasis <em>Taint</em> (fitur beta)</strong>: Konfigurasi <em>eviction</em> per <em>pod</em>
yang terjadi ketika <em>pod</em> mengalami gangguan, hal ini akan dibahas lebih lanjut di bagian
selanjutnya.</p></li></ul><h2 id=eviction-berbasis-taint><em>Eviction</em> berbasis <em>Taint</em></h2><p>Sebelumnya, kita sudah pernah membahas soal <em>effect</em> <em>taint</em> <code>NoExecute</code>,
yang memengaruhi <em>pod</em> yang sudah dijalankan dengan cara sebagai berikut:</p><ul><li><em>pod</em> yang tidak menoleransi <em>taint</em> akan segera diubah <em>state</em>-nya menjadi <em>evicted</em></li><li><em>pod</em> yang menoleransi <em>taint</em> yang tidak menspesifikasikan <code>tolerationSeconds</code> pada
spesifikasi <em>toleration</em> yang ada akan tetap berada di dalam <em>node</em> tanpa adanya batas waktu tertentu</li><li><em>pod</em> yang menoleransi <em>taint</em> yang menspesifikasikan <code>tolerationSeconds</code>
spesifikasi <em>toleration</em> yang ada akan tetap berada di dalam <em>node</em> hingga batas waktu tertentu</li></ul><p>Sebagai tambahan, Kubernetes 1.6 memperkenalkan dukungan alfa untuk merepresentasikan
<em>node</em> yang bermasalah. Dengan kata lain, <em>node controller</em> akan secara otomatis memberikan <em>taint</em>
pada sebuah <em>node</em> apabila <em>node</em> tersebut memenuhi kriteria tertentu. Berikut merupakan <em>taint</em>
yang secara <em>default</em> disediakan:</p><ul><li><code>node.kubernetes.io/not-ready</code>: <em>Node</em> berada dalam <em>state</em> <em>not ready</em>. Hal ini terjadi apabila
<em>value</em> dari <em>NodeCondition</em> <code>Ready</code> adalah "<code>False</code>".</li><li><code>node.kubernetes.io/unreachable</code>: <em>Node</em> berada dalam <em>state</em> <em>unreachable</em> dari <em>node controller</em>
Hal ini terjadi apabila <em>value</em> dari <em>NodeCondition</em> <code>Ready</code> adalah "<code>Unknown</code>".</li><li><code>node.kubernetes.io/out-of-disk</code>: <em>Node</em> kehabisan kapasitas <em>disk</em>.</li><li><code>node.kubernetes.io/memory-pressure</code>: <em>Node</em> berada diambang kapasitas memori.</li><li><code>node.kubernetes.io/disk-pressure</code>: <em>Node</em> berada diambang kapasitas <em>disk</em>.</li><li><code>node.kubernetes.io/network-unavailable</code>: Jaringan pada <em>Node</em> bersifat <em>unavailable</em>.</li><li><code>node.kubernetes.io/unschedulable</code>: <em>Node</em> tidak dapat dijadwalkan.</li><li><code>node.cloudprovider.kubernetes.io/uninitialized</code>: Ketika <em>kubelet</em> dijalankan dengan
penyedia layanan <em>cloud</em> "eksternal", <em>taint</em> ini akan diterapkan pada <em>node</em> untuk menandai
<em>node</em> tersebut tidak digunakan. Setelah kontroler dari <em>cloud-controller-manager</em> melakukan
inisiasi <em>node</em> tersebut, maka <em>kubelet</em> akan menghapus <em>taint</em> yang ada.</li></ul><p>Pada versi 1.13, fitur <code>TaintBasedEvictions</code> diubah menjadi beta dan diaktifkan secara <em>default</em>,
dengan demikian <em>taint-taint</em> tersebut secara otomatis ditambahkan oleh <em>NodeController</em> (atau <em>kubelet</em>)
dan logika normal untuk melakukan <em>eviction</em> pada <em>pod</em> dari suatu <em>node</em> tertentu berdasarkan <em>value</em>
dari <em>Ready</em> yang ada pada <em>NodeCondition</em> dinonaktifkan.</p><div class="alert alert-info note callout" role=alert><strong>Catatan:</strong> Untuk menjaga perilaku <a href=/id/docs/concepts/architecture/nodes/><em>rate limiting</em></a> yang
ada pada <em>eviction</em> <em>pod</em> apabila <em>node</em> mengalami masalah, sistem sebenarnya menambahkan
<em>taint</em> dalam bentuk <em>rate limiter</em>. Hal ini mencegah <em>eviction</em> besar-besaran pada <em>pod</em>
pada skenario dimana master menjadi terpisah dari <em>node</em> lainnya.</div><p>Fitur beta ini, bersamaan dengan <code>tolerationSeconds</code>, mengizinkan sebuah <em>pod</em>
untuk menspesifikasikan berapa lama <em>pod</em> harus tetap sesuai dengan sebuah <em>node</em>
apabila <em>node</em> tersebut bermasalah.</p><p>Misalnya, sebuah aplikasi dengan banyak <em>state</em> lokal akan lebih baik untuk tetap
berada di suatu <em>node</em> pada saat terjadi partisi jaringan, dengan harapan partisi jaringan
tersebut dapat diselesaikan dan mekanisme <em>eviction</em> <em>pod</em> tidak akan dilakukan.
<em>Toleration</em> yang ditambahkan akan berbentuk sebagai berikut:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>tolerations</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span>- <span style=color:green;font-weight:700>key</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;node.kubernetes.io/unreachable&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>operator</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;Exists&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>effect</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;NoExecute&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>tolerationSeconds</span>:<span style=color:#bbb> </span><span style=color:#666>6000</span><span style=color:#bbb>
</span></span></span></code></pre></div><p>Perhatikan bahwa Kubernetes secara otomatis menambahkan <em>toleration</em> untuk
<code>node.kubernetes.io/not-ready</code> dengan <code>tolerationSeconds=300</code>
kecuali konfigurasi lain disediakan oleh pengguna.
Kubernetes juga secara otomatis menambahkan <em>toleration</em> untuk
<code>node.kubernetes.io/unreachable</code> dengan <code>tolerationSeconds=300</code>
kecuali konfigurasi lain disediakan oleh pengguna.</p><p><em>Toleration</em> yang ditambahkan secara otomatis ini menjamin bahwa
perilaku <em>default</em> dari suatu <em>pod</em> adalah tetap bertahan selama 5 menit pada
<em>node</em> apabila salah satu masalah terdeteksi.
Kedua <em>toleration</em> <em>default</em> tadi ditambahkan oleh <a href=https://git.k8s.io/kubernetes/plugin/pkg/admission/defaulttolerationseconds>DefaultTolerationSeconds
<em>admission controller</em></a>.</p><p><em>Pod-pod</em> pada <a href=/id/docs/concepts/workloads/controllers/daemonset/>DaemonSet</a> dibuat dengan <em>toleration</em>
<code>NoExecute</code> untuk <em>taint</em> tanpa <code>tolerationSeconds</code>:</p><ul><li><code>node.kubernetes.io/unreachable</code></li><li><code>node.kubernetes.io/not-ready</code></li></ul><p>Hal ini menjamin <em>pod-pod</em> yang merupakan bagian dari DaemonSet tidak pernah berada di dalam
<em>state</em> <em>evicted</em> apabila terjadi permasalahan pada <em>node</em>.</p><h2 id=taint-pada-node-berdasarkan-kondisi-tertentu><em>Taint</em> pada <em>Node</em> berdasarkan Kondisi Tertentu</h2><p>Pada versi 1.12, fitur <code>TaintNodesByCondition</code> menjadi fitur beta, dengan demikian <em>lifecycle</em>
dari kontroler <em>node</em> akan secara otomatis menambahkan <em>taint</em> sesuai dengan kondisi <em>node</em>.
Hal yang sama juga terjadi pada <em>scheduler</em>, <em>scheduler</em> tidak bertugas memeriksa kondisi <em>node</em>
tetapi kondisi <em>taint</em>. Hal ini memastikan bahwa kondisi <em>node</em> tidak memengaruhi apa
yang dijadwalkan di <em>node</em>. Pengguna dapat memilih untuk mengabaikan beberapa permasalahan yang
ada pada <em>node</em> (yang direpresentasikan oleh kondisi <em>Node</em>) dengan menambahkan <em>toleration</em> <em>Pod</em> <code>NoSchedule</code>.
Sedangkan <em>taint</em> dengan <em>effect</em> <code>NoExecute</code> dikendalikan oleh <code>TaintBasedEviction</code> yang merupakan
fitur beta yang diaktifkan secara <em>default</em> oleh Kubernetes sejak versi 1.13.</p><p>Sejak Kubernetes versi 1.8, kontroler DaemonSet akan secara otomatis
menambahkan <em>toleration</em> <code>NoSchedule</code> pada semua <em>daemon</em> untuk menjaga
fungsionalitas DaemonSet.</p><ul><li><code>node.kubernetes.io/memory-pressure</code></li><li><code>node.kubernetes.io/disk-pressure</code></li><li><code>node.kubernetes.io/out-of-disk</code> (hanya untuk pod yang bersifat <em>critical</em>)</li><li><code>node.kubernetes.io/unschedulable</code> (versi 1.10 atau yang lebih baru)</li><li><code>node.kubernetes.io/network-unavailable</code> (hanya untuk jaringan <em>host</em>)</li></ul><p>Menambahkan <em>toleration</em> ini menjamin <em>backward compatibility</em>.
Kamu juga dapat menambahkan <em>toleration</em> lain pada DaemonSet.</p></div><div class=td-content style=page-break-before:always><h1 id=pg-598f36d691ab197f9d995784574b0a12>9.5 - Penjadwal Kubernetes</h1><p>Dalam Kubernetes, <em>scheduling</em> atau penjadwalan ditujukan untuk memastikan
<a class=glossary-tooltip title='Unit Kubernetes yang paling sederhana dan kecil. Sebuah Pod merepresentasikan sebuah set kontainer yang dijalankan pada kluster kamu.' data-toggle=tooltip data-placement=top href=/docs/concepts/workloads/pods/pod-overview/ target=_blank aria-label=Pod>Pod</a> mendapatkan
<a class=glossary-tooltip title='A node is a worker machine in Kubernetes.' data-toggle=tooltip data-placement=top href=/docs/concepts/architecture/nodes/ target=_blank aria-label=Node>Node</a> sehingga
<a class=glossary-tooltip title='Agen yang dijalankan pada setiap node di klaster yang bertugas untuk memastikan kontainer dijalankan di dalam Pod.' data-toggle=tooltip data-placement=top href=/docs/reference/generated/kubelet target=_blank aria-label=Kubelet>Kubelet</a> dapat menjalankannya.</p><h2 id=penjadwalan>Ikhtisar Penjadwalan</h2><p>Sebuah penjadwal mengawasi Pod yang baru saja dibuat dan belum ada Node yang
dialokasikan untuknya. Untuk setiap Pod yang ditemukan oleh penjadwal, maka
penjadwal tersebut bertanggung jawab untuk menemukan Node terbaik untuk
menjalankan Pod. Penjadwal dapat menetapkan keputusan penempatan ini dengan
mempertimbangkan prinsip-prinsip penjadwalan yang dijelaskan di bawah ini.</p><p>Jika kamu ingin memahami mengapa Pod ditempatkan pada Node tertentu, atau jika
kamu berencana untuk mengimplementasikan penjadwal kustom sendiri, halaman ini
akan membantu kamu belajar tentang penjadwalan.</p><h2 id=kube-scheduler>Kube-scheduler</h2><p><a href=https://kubernetes.io/docs/reference/command-line-tools-reference/kube-scheduler/><em>Kube-scheduler</em></a>
adalah penjadwal standar untuk Kubernetes dan dijalankan sebagai bagian dari
<a class=glossary-tooltip title='Merupakan lapisan orkestrasi Container yang mengekspos API dan antarmuka untuk mendefinisikan, menggelar, dan mengelola siklus hidup suatu Container.' data-toggle=tooltip data-placement=top href='/id/docs/reference/glossary/?all=true#term-control-plane' target=_blank aria-label='_control plane_'>_control plane_</a>.
<em>Kube-scheduler</em> dirancang agar jika kamu mau dan perlu, kamu bisa menulis
komponen penjadwalan kamu sendiri dan menggunakannya.</p><p>Untuk setiap Pod yang baru dibuat atau Pod yang tak terjadwal lainnya,
<em>kube-scheduler</em> memilih Node yang optimal untuk menjalankannya. Namun, setiap
kontainer masuk Pod memiliki persyaratan sumber daya yang berbeda dan setiap Pod
juga memiliki persyaratan yang berbeda juga. Oleh karena itu, Node yang ada
perlu dipilih sesuai dengan persyaratan khusus penjadwalan.</p><p>Dalam sebuah Klaster, Node yang memenuhi persyaratan penjadwalan untuk suatu Pod
disebut Node <em>feasible</em>. Jika tidak ada Node yang cocok, maka Pod tetap tidak
terjadwal sampai penjadwal yang mampu menempatkannya.</p><p>Penjadwal menemukan Node-Node yang layak untuk sebuah Pod dan kemudian
menjalankan sekumpulan fungsi untuk menilai Node-Node yang layak dan mengambil
satu Node dengan skor tertinggi di antara Node-Node yang layak untuk menjalankan
Pod. Penjadwal kemudian memberi tahu server API tentang keputusan ini dalam
proses yang disebut dengan <em>binding</em>.</p><p>Beberapa faktor yang perlu dipertimbangkan untuk keputusan penjadwalan termasuk
persyaratan sumber daya individu dan kolektif, aturan kebijakan / perangkat keras /
lunak, spesifikasi persamaan dan anti-persamaan, lokalitas data, interferensi
antar Workloads, dan sebagainya.</p><h3 id=kube-scheduler-implementation>Pemilihan node pada kube-scheduler</h3><p><em>Kube-scheduler</em> memilih node untuk pod dalam 2 langkah operasi:</p><ol><li>Filtering</li><li>Scoring</li></ol><p>Langkah <em>filtering</em> menemukan sekumpulan Nodes yang layak untuk menjadwalkan
Pod. Misalnya, penyarin PodFitsResources memeriksa apakah Node kandidat
memiliki sumber daya yang cukup untuk memenuhi permintaan spesifik sumber daya dari
Pod. Setelah langkah ini, daftar Node akan berisi Node-node yang sesuai;
seringkali, akan terisi lebih dari satu. Jika daftar itu kosong, maka Pod itu
tidak (belum) dapat dijadwalkan.</p><p>Pada langkah <em>scoring</em>, penjadwal memberi peringkat pada Node-node yang tersisa
untuk memilih penempatan paling cocok untuk Pod. Penjadwal memberikan skor
untuk setiap Node yang sudah tersaring, memasukkan skor ini pada aturan
penilaian yang aktif.</p><p>Akhirnya, <em>kube-scheduler</em> memberikan Pod ke Node dengan peringkat tertinggi.
Jika ada lebih dari satu node dengan skor yang sama, maka <em>kube-scheduler</em>
memilih salah satunya secara acak.</p><p>Ada dua cara yang didukung untuk mengkonfigurasi perilaku penyaringan dan
penilaian oleh penjadwal:</p><ol><li><a href=/docs/reference/scheduling/policies>Aturan Penjadwalan</a> yang memungkinkan
kamu untuk mengkonfigurasi <em>Predicates</em> untuk pemfilteran dan <em>Priorities</em>
untuk penilaian.</li><li><a href=/docs/reference/scheduling/profiles>Profil Penjadwalan</a> yang memungkinkan
kamu mengkonfigurasi <em>Plugin</em> yang menerapkan tahapan penjadwalan berbeda,
termasuk: <code>QueueSort</code>, <code>Filter</code>, <code>Score</code>, <code>Bind</code>, <code>Reserve</code>, <code>Permit</code>, dan
lainnya. Kamu juga bisa mengonfigurasi <em>kube-scheduler</em> untuk menjalankan
profil yang berbeda.</li></ol><h2 id=selanjutnya>Selanjutnya</h2><ul><li>Baca tentang <a href=/id/docs/concepts/scheduling-eviction/scheduler-perf-tuning/>penyetelan performa penjadwal</a></li><li>Baca tentang <a href=/id/docs/concepts/workloads/pods/pod-topology-spread-constraints/>pertimbangan penyebarang topologi pod</a></li><li>Baca <a href=/docs/reference/command-line-tools-reference/kube-scheduler/>referensi dokumentasi</a> untuk <em>kube-scheduler</em></li><li>Pelajari tentang <a href=/docs/tasks/administer-cluster/configure-multiple-schedulers/>mengkonfigurasi beberapa penjadwal</a></li><li>Pelajari tentang <a href=/docs/tasks/administer-cluster/topology-manager/>aturan manajemen topologi</a></li><li>Pelajari tentang <a href=/id/docs/concepts/configuration/pod-overhead/>pengeluaran tambahan Pod</a></li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-602208c95fe7b1f1170310ce993f5814>9.6 - Kerangka Kerja Penjadwalan (Scheduling Framework)</h1><div style=margin-top:10px;margin-bottom:10px><b>FEATURE STATE:</b> <code>Kubernetes 1.15 [alpha]</code></div><p>Kerangka kerja penjadwalan (<em>Scheduling Framework</em>) adalah arsitektur yang dapat
dipasang (<em>pluggable</em>) pada penjadwal Kubernetes untuk membuat kustomisasi
penjadwal lebih mudah. Hal itu dilakukan dengan menambahkan satu kumpulan "plugin"
API ke penjadwal yang telah ada. <em>Plugin</em> dikompilasi ke dalam penjadwal.
Beberapa API memungkinkan sebagian besar fitur penjadwalan diimplementasikan
sebagai <em>plugin</em>, sambil tetap mempertahankan penjadwalan "inti" sederhana dan
terpelihara. Silahkan merujuk pada [proposal desain dari kerangka penjadwalan]
<a href=https://github.com/kubernetes/enhancements/blob/master/keps/sig-scheduling/20180409-scheduling-framework.md>kep</a> untuk informasi teknis lebih lanjut tentang desain kerangka kerja
tersebut.</p><h1 id=alur-kerja-kerangka-kerja>Alur kerja kerangka kerja</h1><p>Kerangka kerja penjadwalan mendefinisikan beberapa titik ekstensi. <em>Plugin</em> penjadwal
mendaftar untuk dipanggil di satu atau lebih titik ekstensi. Beberapa <em>plugin</em> ini
dapat mengubah keputusan penjadwalan dan beberapa hanya bersifat informasi.</p><p>Setiap upaya untuk menjadwalkan satu Pod dibagi menjadi dua fase, <strong>Siklus Penjadwalan (<em>Scheduling Cycle</em>)</strong> dan <strong>Siklus Pengikatan (<em>Binding Cycle</em>)</strong>.</p><h2 id=siklus-penjadwalan-dan-siklus-pengikatan>Siklus Penjadwalan dan Siklus Pengikatan</h2><p>Siklus penjadwalan memilih sebuah Node untuk Pod, dan siklus pengikatan menerapkan
keputusan tersebut ke klaster. Secara bersama-sama, siklus penjadwalan dan siklus
pengikatan diartikan sebagai sebuah "konteks penjadwalan (<em>scheduling context</em>)".</p><p>Siklus penjadwalan dijalankan secara serial, sementara siklus pengikatan dapat
berjalan secara bersamaan.</p><p>Siklus penjadwalan atau pengikatan dapat dibatalkan jika Pod telah ditentukan
untuk tidak terjadwalkan atau jika terdapat kesalahan internal. Pod akan
dikembalikan ke antrian dan dicoba lagi.</p><h2 id=titik-titik-ekstensi>Titik-titik ekstensi</h2><p>Gambar berikut menunjukkan konteks penjadwalan Pod dan titik-titik ekstensi
yang diperlihatkan oleh kerangka penjadwalan. Dalam gambar ini "Filter"
setara dengan "Predicate" dan "Scoring" setara dengan "Priority Function".</p><p>Satu <em>plugin</em> dapat mendaftar di beberapa titik ekstensi untuk melakukan pekerjaan
yang lebih kompleks atau <em>stateful</em>.</p><figure><img src=/images/docs/scheduling-framework-extensions.png><figcaption><h4>Titik-titik ekstensi dari kerangka kerja Penjadwalan</h4></figcaption></figure><h3 id=queue-sort>QueueSort</h3><p><em>Plugin</em> ini digunakan untuk mengurutkan Pod-Pod dalam antrian penjadwalan. <em>Plugin</em>
QueueSort pada dasarnya menyediakan fungsi <code>Less (Pod1, Pod2)</code>. Hanya satu jenis
<em>plugin</em> QueueSort yang dapat diaktifkan dalam waktu yang bersamaan.</p><h3 id=pre-filter>PreFilter</h3><p><em>Plugin</em> ini digunakan untuk melakukan pra-proses informasi tentang Pod, atau untuk
memeriksa tertentu kondisi yang harus dipenuhi oleh klaster atau Pod. Jika
<em>plugin</em> PreFilter menghasilkan hasil yang salah, siklus penjadwalan dibatalkan.</p><h3 id=filter>Filter</h3><p><em>Plugin</em> ini digunakan untuk menyaring Node yang tidak dapat menjalankan Pod.
Untuk setiap Node, penjadwal akan memanggil <em>plugin</em> Filter sesuai dengan urutan
mereka dikonfigurasi. Jika ada <em>plugin</em> Filter menandai Node menjadi <em>infeasible</em>,
maka <em>plugin</em> yang lainnya tidak akan dipanggil untuk Node itu. Node-Node dapat dievaluasi
secara bersamaan.</p><h3 id=post-filter>PostFilter</h3><p>Plugin ini disebut setelah fase Filter, tetapi hanya ketika tidak ada node yang layak
ditemukan untuk pod. Plugin dipanggil dalam urutan yang dikonfigurasi. Jika
plugin postFilter menandai node sebagai 'Schedulable', plugin yang tersisa
tidak akan dipanggil. Implementasi PostFilter yang khas adalah preemption, yang
mencoba membuat pod dapat di menjadwalkan dengan mendahului Pod lain.</p><h3 id=pre-score>PreScore</h3><p><em>Plugin</em> ini digunakan untuk melakukan pekerjaan "pra-penilaian", yang
menghasilkan keadaan yang dapat dibagi untuk digunakan oleh <em>plugin-plugin</em> Score.
Jika <em>plugin</em> PreScore mengeluarkan hasil salah, maka siklus penjadwalan dibatalkan.</p><h3 id=score>Score</h3><p><em>Plugin</em> ini digunakan untuk menentukan peringkat Node yang telah melewati fase
penyaringan. Penjadwal akan memanggil setiap <em>plugin</em> Score untuk setiap Node.
Akan ada kisaran bilangan bulat yang telah ditetapkan untuk mewakili skor
minimum dan maksimum. Setelah fase <a href=#normalize-scoring>NormalizeScore</a>,
penjadwal akan menggabungkan skor Node dari semua <em>plugin</em> sesuai dengan bobot
<em>plugin</em> yang telah dikonfigurasi.</p><h3 id=normalize-score>NormalizeScore</h3><p><em>Plugin</em> ini digunakan untuk memodifikasi skor sebelum penjadwal menghitung
peringkat akhir Node-Node. <em>Plugin</em> yang mendaftar untuk titik ekstensi ini akan
dipanggil dengan hasil <a href=#score>Score</a> dari <em>plugin</em> yang sama. Hal ini dilakukan
sekali untuk setiap <em>plugin</em> dan setiap siklus penjadwalan.</p><p>Sebagai contoh, anggaplah sebuah <em>plugin</em> <code>BlinkingLightScorer</code> memberi peringkat
pada Node-Node berdasarkan berapa banyak kedipan lampu yang mereka miliki.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-go data-lang=go><span style=display:flex><span><span style=color:#a2f;font-weight:700>func</span> <span style=color:#00a000>ScoreNode</span>(_ <span style=color:#666>*</span>v1.pod, n <span style=color:#666>*</span>v1.Node) (<span style=color:#0b0;font-weight:700>int</span>, <span style=color:#0b0;font-weight:700>error</span>) {
</span></span><span style=display:flex><span>    <span style=color:#a2f;font-weight:700>return</span> <span style=color:#00a000>getBlinkingLightCount</span>(n)
</span></span><span style=display:flex><span>}
</span></span></code></pre></div><p>Namun, jumlah maksimum kedipan lampu mungkin kecil jika dibandingkan dengan
<code>NodeScoreMax</code>. Untuk memperbaikinya, <code>BlinkingLightScorer</code> juga harus mendaftar
untuk titik ekstensi ini.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-go data-lang=go><span style=display:flex><span><span style=color:#a2f;font-weight:700>func</span> <span style=color:#00a000>NormalizeScores</span>(scores <span style=color:#a2f;font-weight:700>map</span>[<span style=color:#0b0;font-weight:700>string</span>]<span style=color:#0b0;font-weight:700>int</span>) {
</span></span><span style=display:flex><span>    highest <span style=color:#666>:=</span> <span style=color:#666>0</span>
</span></span><span style=display:flex><span>    <span style=color:#a2f;font-weight:700>for</span> _, score <span style=color:#666>:=</span> <span style=color:#a2f;font-weight:700>range</span> scores {
</span></span><span style=display:flex><span>        highest = <span style=color:#00a000>max</span>(highest, score)
</span></span><span style=display:flex><span>    }
</span></span><span style=display:flex><span>    <span style=color:#a2f;font-weight:700>for</span> node, score <span style=color:#666>:=</span> <span style=color:#a2f;font-weight:700>range</span> scores {
</span></span><span style=display:flex><span>        scores[node] = score<span style=color:#666>*</span>NodeScoreMax<span style=color:#666>/</span>highest
</span></span><span style=display:flex><span>    }
</span></span><span style=display:flex><span>}
</span></span></code></pre></div><p>Jika ada <em>plugin</em> NormalizeScore yang menghasilkan hasil yang salah, maka siklus
penjadwalan dibatalkan.</p><div class="alert alert-info note callout" role=alert><strong>Catatan:</strong> <em>Plugin</em> yang ingin melakukan pekerjaan "pra-pemesanan" harus menggunakan
titik ekstensi NormalizeScore.</div><h3 id=reserve>Reserve</h3><p>Ini adalah titik ekstensi yang bersifat informasi. <em>Plugin</em> yang mempertahankan
keadaan <em>runtime</em> (alias "<em>stateful plugins</em>") harus menggunakan titik ekstensi ini
untuk diberitahukan oleh penjadwal ketika sumber daya pada suatu Node dicadangkan
untuk Pod yang telah disiapkan. Proses ini terjadi sebelum penjadwal benar-benar
mengikat Pod ke Node, dan itu ada untuk mencegah kondisi balapan (<em>race conditions</em>)
ketika penjadwal menunggu agar pengikatan berhasil.</p><p>Ini adalah langkah terakhir dalam siklus penjadwalan. Setelah Pod berada dalam
status dicadangkan, maka itu akan memicu <em>plugin</em> <a href=#unreserve>Unreserve</a>
(apabila gagal) atau <em>plugin</em> <a href=#post-bind>PostBind</a> (apabila sukses)
di akhir siklus pengikatan.</p><h3 id=permit>Permit</h3><p><em>Plugin</em> Permit dipanggil pada akhir siklus penjadwalan untuk setiap Pod
untuk mencegah atau menunda pengikatan ke Node kandidat. <em>Plugin</em> Permit dapat
melakukan salah satu dari ketiga hal ini:</p><ol><li><p><strong>approve</strong><br>     Setelah semua <em>plugin</em> Permit menyetujui sebuah Pod, Pod tersebut akan dikirimkan untuk diikat.</p></li><li><p><strong>deny</strong><br>     Jika ada <em>plugin</em> Permit yang menolak sebuah Pod, Pod tersebut akan dikembalikan ke
antrian penjadwalan. Hal ini akan memicu <em>plugin</em> <a href=#unreserve>Unreserve</a>.</p></li><li><p><strong>wait</strong> (dengan batas waktu)<br>     Jika <em>plugin</em> Permit menghasilkan "wait", maka Pod disimpan dalam
     daftar Pod "yang menunggu" internal, dan siklus pengikatan Pod ini dimulai tetapi akan langsung diblokir
     sampai mendapatkan <a href=#frameworkhandle><em>approved</em></a>. Jika waktu tunggu habis, ** wait ** menjadi ** deny **
     dan Pod dikembalikan ke antrian penjadwalan, yang memicu <em>plugin</em> <a href=#unreserve>Unreserve</a>.</p></li></ol><div class="alert alert-info note callout" role=alert><strong>Catatan:</strong> Ketika setiap <em>plugin</em> dapat mengakses daftar Pod-Pod "yang menunggu" dan menyetujuinya
(silahkan lihat <a href=#frameworkhandle><code>FrameworkHandle</code></a>), kami hanya mengharapkan
<em>plugin</em> Permit untuk menyetujui pengikatan Pod dalam kondisi "menunggu" yang
telah dipesan. Setelah Pod disetujui, akan dikirim ke fase <a href=#pre-bind>PreBind</a>.</div><h3 id=pre-bind>PreBind</h3><p><em>Plugin</em> ini digunakan untuk melakukan pekerjaan apa pun yang diperlukan sebelum
Pod terikat. Sebagai contoh, <em>plugin</em> PreBind dapat menyediakan <em>network volume</em>
dan melakukan <em>mounting</em> pada Node target sebelum mengizinkan Pod berjalan di
sana.</p><p>Jika ada <em>plugin</em> PreBind yang menghasilkan kesalahan, maka Pod <a href=#unreserve>ditolak</a>
dan kembali ke antrian penjadwalan.</p><h3 id=bind>Bind</h3><p><em>Plugin</em> ini digunakan untuk mengikat Pod ke Node. <em>Plugin-plugin</em> Bind tidak akan
dipanggil sampai semua <em>plugin</em> PreBind selesai. Setiap <em>plugin</em> Bind dipanggil
sesuai urutan saat dikonfigurasi. <em>Plugin</em> Bind dapat memilih untuk menangani
atau tidak Pod yang diberikan. Jika <em>plugin</em> Bind memilih untuk menangani Pod,
** <em>plugin</em> Bind yang tersisa dilewati **.</p><h3 id=post-bind>PostBind</h3><p>Ini adalah titik ekstensi bersifat informasi. <em>Plugin-plugin</em> PostBind dipanggil
setelah sebuah Pod berhasil diikat. Ini adalah akhir dari siklus pengikatan, dan
dapat digunakan untuk membersihkan sumber daya terkait.</p><h3 id=unreserve>Unreserve</h3><p>Ini adalah titik ekstensi bersifat informasi. Jika sebuah Pod telah dipesan dan
kemudian ditolak di tahap selanjutnya, maka <em>plugin-plugin</em> Unreserve akan
diberitahu. <em>Plugin</em> Unreserve harus membersihkan status yang terkait dengan Pod
yang dipesan.</p><p><em>Plugin</em> yang menggunakan titik ekstensi ini sebaiknya juga harus digunakan
<a href=#unreserve>Reserve</a>.</p><h2 id=plugin-api><em>Plugin</em> API</h2><p>Ada dua langkah untuk <em>plugin</em> API. Pertama, <em>plugin</em> harus mendaftar dan mendapatkan
konfigurasi, kemudian mereka menggunakan antarmuka titik ekstensi. Antarmuka (<em>interface</em>)
titik ekstensi memiliki bentuk sebagai berikut.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-go data-lang=go><span style=display:flex><span><span style=color:#a2f;font-weight:700>type</span> Plugin <span style=color:#a2f;font-weight:700>interface</span> {
</span></span><span style=display:flex><span>    <span style=color:#00a000>Name</span>() <span style=color:#0b0;font-weight:700>string</span>
</span></span><span style=display:flex><span>}
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#a2f;font-weight:700>type</span> QueueSortPlugin <span style=color:#a2f;font-weight:700>interface</span> {
</span></span><span style=display:flex><span>    Plugin
</span></span><span style=display:flex><span>    <span style=color:#00a000>Less</span>(<span style=color:#666>*</span>v1.pod, <span style=color:#666>*</span>v1.pod) <span style=color:#0b0;font-weight:700>bool</span>
</span></span><span style=display:flex><span>}
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#a2f;font-weight:700>type</span> PreFilterPlugin <span style=color:#a2f;font-weight:700>interface</span> {
</span></span><span style=display:flex><span>    Plugin
</span></span><span style=display:flex><span>    <span style=color:#00a000>PreFilter</span>(context.Context, <span style=color:#666>*</span>framework.CycleState, <span style=color:#666>*</span>v1.pod) <span style=color:#0b0;font-weight:700>error</span>
</span></span><span style=display:flex><span>}
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#080;font-style:italic>// ...
</span></span></span></code></pre></div><h2 id=konfigurasi-plugin>Konfigurasi <em>plugin</em></h2><p>Kamu dapat mengaktifkan atau menonaktifkan <em>plugin</em> dalam konfigurasi penjadwal.
Jika kamu menggunakan Kubernetes v1.18 atau yang lebih baru, kebanyakan
<a href=/docs/reference/scheduling/profiles/#scheduling-plugins>plugin-plugin penjadwalan</a>
sudah digunakan dan diaktifkan secara bawaan.</p><p>Selain <em>plugin-plugin</em> bawaan, kamu juga dapat mengimplementasikan <em>plugin-plugin</em> penjadwalan
kamu sendiri dan mengonfigurasinya bersama-sama dengan <em>plugin-plugin</em> bawaan.
Kamu bisa mengunjungi <a href=https://github.com/kubernetes-sigs/scheduler-plugins>plugin-plugin penjadwalan</a>
untuk informasi lebih lanjut.</p><p>Jika kamu menggunakan Kubernetes v1.18 atau yang lebih baru, kamu dapat
mengonfigurasi sekumpulan <em>plugin</em> sebagai profil penjadwal dan kemudian menetapkan
beberapa profil agar sesuai dengan berbagai jenis beban kerja. Pelajari lebih
lanjut di <a href=/docs/reference/scheduling/profiles/#multiple-profiles>multi profil</a>.</p></div><div class=td-content style=page-break-before:always><h1 id=pg-d9574a30fcbc631b0d2a57850e161e89>9.7 - Penyetelan Kinerja Penjadwal</h1><div style=margin-top:10px;margin-bottom:10px><b>FEATURE STATE:</b> <code>Kubernetes v1.14 [beta]</code></div><p><a href=/id/docs/concepts/scheduling-eviction/kube-scheduler/#kube-scheduler>kube-scheduler</a>
merupakan penjadwal (<em>scheduler</em>) Kubernetes bawaan yang bertanggung jawab
terhadap penempatan Pod-Pod pada seluruh Node di dalam sebuah klaster.</p><p>Node-Node di dalam klaster yang sesuai dengan syarat-syarat penjadwalan dari
sebuah Pod disebut sebagai Node-Node layak (<em>feasible</em>). Penjadwal mencari Node-Node
layak untuk sebuah Pod dan kemudian menjalankan fungsi-fungsi untuk menskor Node-Node tersebut, memilih sebuah Node dengan skor tertinggi di antara
Node-Node layak lainnya, di mana Pod akan dijalankan. Penjadwal kemudian memberitahu
API server soal keputusan ini melalui sebuah proses yang disebut <em>Binding</em>.</p><p>Laman ini menjelaskan optimasi penyetelan (<em>tuning</em>) kinerja yang relevan
untuk klaster Kubernetes berskala besar.</p><p>Pada klaster berskala besar, kamu bisa menyetel perilaku penjadwal
untuk menyeimbangkan hasil akhir penjadwalan antara latensi (seberapa cepat Pod-Pod baru ditempatkan)
dan akurasi (seberapa akurat penjadwal membuat keputusan penjadwalan yang tepat).</p><p>Kamu bisa mengonfigurasi setelan ini melalui pengaturan <code>percentageOfNodesToScore</code> pada kube-scheduler.
Pengaturan KubeSchedulerConfiguration ini menentukan sebuah ambang batas untuk
penjadwalan Node-Node di dalam klaster kamu.</p><h3 id=pengaturan-ambang-batas>Pengaturan Ambang Batas</h3><p>Opsi <code>percentageOfNodesToScore</code> menerima semua angka numerik antara 0 dan 100.
Angka 0 adalah angka khusus yang menandakan bahwa kube-scheduler harus menggunakan
nilai bawaan.
Jika kamu mengatur <code>percentageOfNodesToScore</code> dengan angka di atas 100, kube-scheduler
akan membulatkan ke bawah menjadi 100.</p><p>Untuk mengubah angkanya, sunting berkas konfigurasi kube-scheduler (biasanya <code>/etc/kubernetes/config/kube-scheduler.yaml</code>),
lalu <em>ulang kembali</em> kube-scheduler.</p><p>Setelah kamu selesai menyunting, jalankan perintah</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>kubectl get componentstatuses
</span></span></code></pre></div><p>untuk memverifikasi komponen kube-scheduler berjalan dengan baik (<em>healthy</em>). Keluarannya kira-kira seperti ini:</p><pre tabindex=0><code>NAME                 STATUS    MESSAGE             ERROR
controller-manager   Healthy   ok
scheduler            Healthy   ok
...
</code></pre><h2 id=persentase-penskoran-node>Ambang Batas Penskoran Node</h2><p>Untuk meningkatan kinerja penjadwalan, kube-scheduler dapat berhenti mencari
Node-Node yang layak saat sudah berhasil menemukannya. Pada klaster berskala besar,
hal ini menghemat waktu dibandingkan dengan pendekatan awam yang mengecek setiap Node.</p><p>Kamu bisa mengatur ambang batas untuk menentukan berapa banyak jumlah Node minimal yang dibutuhkan, sebagai
persentase bagian dari seluruh Node di dalam klaster kamu. kube-scheduler akan mengubahnya menjadi
bilangan bulat berisi jumlah Node. Saat penjadwalan, jika kube-scheduler mengidentifikasi
cukup banyak Node-Node layak untuk melewati jumlah persentase yang diatur, maka kube-scheduler
akan berhenti mencari Node-Node layak dan lanjut ke [fase penskoran] (/id/docs/concepts/scheduling-eviction/kube-scheduler/#kube-scheduler-implementation).</p><p><a href=#bagaimana-penjadwal-mengecek-node>Bagaimana penjadwal mengecek Node</a> menjelaskan proses ini secara detail.</p><h3 id=ambang-batas-bawaan>Ambang Batas Bawaan</h3><p>Jika kamu tidak mengatur sebuah ambang batas, maka Kubernetes akan
menghitung sebuah nilai menggunakan pendekatan linier, yaitu 50% untuk klaster dengan 100 Node,
serta 10% untuk klaster dengan 5000 Node.</p><p>Artinya, kube-scheduler selalu menskor paling tidak 5% dari klaster kamu, terlepas dari
seberapa besar klasternya, kecuali kamu secara eksplisit mengatur <code>percentageOfNodesToScore</code>
menjadi lebih kecil dari 5.</p><p>Jika kamu ingin penjadwal untuk memasukkan seluruh Node di dalam klaster ke dalam penskoran,
maka aturlah <code>percentageOfNodesToScore</code> menjadi 100.</p><h2 id=contoh>Contoh</h2><p>Contoh konfigurasi di bawah ini mengatur <code>percentageOfNodesToScore</code> menjadi 50%.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>kubescheduler.config.k8s.io/v1alpha1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>KubeSchedulerConfiguration<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>algorithmSource</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>provider</span>:<span style=color:#bbb> </span>DefaultProvider<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:#00f;font-weight:700>...</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>percentageOfNodesToScore</span>:<span style=color:#bbb> </span><span style=color:#666>50</span><span style=color:#bbb>
</span></span></span></code></pre></div><h2 id=menyetel-percentageofnodestoscore>Menyetel percentageOfNodesToScore</h2><p><code>percentageOfNodesToScore</code> merupakan angka 1 sampai 100 dengan
nilai bawaan yang dihitung berdasarkan ukuran klaster. Di sini juga terdapat
batas bawah yang telah ditetapkan, yaitu 50 Node.</p><div class="alert alert-info note callout" role=alert><strong>Catatan:</strong><p>Pada klaster dengan kurang dari 50 Node layak, penjadwal masih
terus memeriksa seluruh Node karena Node-Node layak belum mencukupi supaya
penjadwal dapat menghentikan proses pencarian lebih awal.</p><p>Pada klaster kecil, jika kamu mengatur <code>percentageOfNodesToScore</code> dengan angka kecil,
pengaturan ini hampir atau sama sekali tidak berpengaruh, karena alasan yang sama.</p><p>Jika klaster kamu punya ratusan Node, gunakan angka bawaan untuk opsi konfigurasi ini.
Mengubah angkanya kemungkinan besar tidak akan mengubah kinerja penjadwal secara berarti.</p></div><p>Sebuah catatan penting yang perlu dipertimbangkan saat mengatur angka ini adalah
ketika klaster dengan jumlah Node sedikit diperiksa untuk kelayakan, beberapa Node
tidak dikirim untuk diskor bagi sebuah Pod. Hasilnya, sebuah Node yang mungkin memiliki
nilai lebih tinggi untuk menjalankan Pod tersebut bisa saja tidak diteruskan ke fase penskoran.
Hal ini berdampak pada penempatan Pod yang kurang ideal.</p><p>Kamu sebaiknya menghindari pengaturan <code>percentageOfNodesToScore</code> menjadi sangat rendah,
agar kube-scheduler tidak seringkali membuat keputusan penempatan Pod yang buruk.
Hindari pengaturan persentase di bawah 10%, kecuali <em>throughput</em> penjadwal sangat penting
untuk aplikasi kamu dan skor dari Node tidak begitu penting. Dalam kata lain, kamu
memilih untuk menjalankan Pod pada Node manapun selama Node tersebut layak.</p><h2 id=bagaimana-penjadwal-mengecek-node>Bagaimana Penjadwal Mengecek Node</h2><p>Bagian ini ditujukan untuk kamu yang ingin mengerti bagaimana fitur ini bekerja secara internal.</p><p>Untuk memberikan semua Node di dalam klaster sebuah kesempatan yang adil untuk
dipertimbangkan dalam menjalankan Pod, penjadwal mengecek Node satu persatu
secara <em>round robin</em>. Kamu dapat membayangkan Node-Node ada di dalam sebuah array.
Penjadwal mulai dari indeks array pertama dan mengecek kelayakan dari Node sampai
jumlahnya telah mencukupi sesuai dengan <code>percentageOfNodesToScore</code>. Untuk Pod berikutnya,
penjadwal melanjutkan dari indeks array Node yang terhenti ketika memeriksa
kelayakan Node-Node untuk Pod sebelumnya.</p><p>Jika Node-Node berada di beberapa zona, maka penjadwal akan mengecek Node satu persatu
pada seluruh zona untuk memastikan bahwa Node-Node dari zona berbeda masuk dalam pertimbangan
kelayakan. Sebagai contoh, ada 6 Node di dalam 2 zona:</p><pre tabindex=0><code>Zona 1: Node 1, Node 2, Node 3, Node 4
Zona 2: Node 5, Node 6
</code></pre><p>Penjadwal mempertimbangkan kelayakan dari Node-Node tersebut dengan urutan berikut:</p><pre tabindex=0><code>Node 1, Node 5, Node 2, Node 6, Node 3, Node 4
</code></pre><p>Setelah semua Node telah dicek, penjadwal akan kembali pada Node 1.</p></div><div class=td-content style=page-break-before:always><h1 id=pg-ac9161c6d952925b083ad9602b4e8e7f>10 - Policies</h1></div><div class=td-content><h1 id=pg-a935ff8c59eb116b43494255cc67f69a>10.1 - LimitRange</h1><p>Secara bawaan, Container berjalan dengan <a href=/id/docs/user-guide/compute-resources>sumber daya komputasi</a> tanpa batas pada klaster Kubernetes.
Dengan ResourceQuota (kuota sumber daya), administrator klaster dapat membatasi konsumsi dan pembuatan sumber daya berbasis <a class=glossary-tooltip title='Sebuah abstraksi yang digunakan oleh Kubernetes untuk mendukung multipel klaster virtual pada klaster fisik yang sama.' data-toggle=tooltip data-placement=top href=/id/docs/concepts/overview/working-with-objects/namespaces target=_blank aria-label=Namespace>Namespace</a>.
Di dalam Namespace, Pod atau Container dapat mengkonsumsi CPU dan memori sesuai dengan yang ditentukan oleh ResourceQuota pada Namespace tersebut.
Ada kekhawatiran bahwa satu Pod atau Container dapat memonopoli semua sumber daya yang tersedia.
LimitRange (Batas Rentang) adalah kebijakan untuk membatasi alokasi sumber daya (bagi Pod atau Container) pada Namespace.</p><p>LimitRange memberikan batasan (<em>limit</em>) yang dapat:</p><ul><li>Menerapkan penggunaan sumber daya komputasi minimum dan maksimum untuk setiap Pod atau Container dalam Namespace.</li><li>Menerapkan permintaan (<em>request</em>) tempat penyimpanan minimum dan maksimum untuk setiap PersistentVolumeClaim dalam Namespace.</li><li>Menerapkan rasio antara permintaan dan batas untuk sumber daya dalam Namespace.</li><li>Menetapkan permintaan/batas bawaan untuk menghitung sumber daya dalam Namespace dan memasukkannya secara otomatis ke Container pada <em>runtime</em>.</li></ul><h2 id=mengaktifkan-limitrange>Mengaktifkan LimitRange</h2><p>Dukungan LimitRange diaktifkan secara bawaan untuk banyak distribusi Kubernetes. Hal ini
diaktifkan ketika tanda <code>--enable-admission-plugins=</code> pada apiserver memiliki <em>admission controller</em> <code>LimitRanger</code> sebagai
salah satu argumennya.</p><p>LimitRange diberlakukan pada Namespace tertentu ketika ada sebuah objek LimitRange pada Namespace tersebut.</p><p>Nama dari objek LimitRange harus merupakan sebuah <a href=/id/docs/concepts/overview/working-with-objects/names#nama>nama subdomain DNS</a>.</p><h3 id=gambaran-umum-limitrange>Gambaran Umum LimitRange</h3><ul><li>Administrator membuat sebuah LimitRange dalam sebuah Namespace.</li><li>Pengguna membuat sumber daya seperti Pod, Container, dan PersistentVolumeClaim pada namespace.</li><li><em>Admission controller</em> <code>LimitRanger</code> memberlakukan bawaan dan batas untuk semua Pod dan Container yang tidak menetapkan persyaratan sumber daya komputasi dan melacak penggunaannya untuk memastikan agar tidak melebihi minimum, maksimum dan rasio sumber daya yang ditentukan dalam LimitRange yang ada pada Namespace.</li><li>Apabila permintaan membuat atau memperbarui sumber daya (Pod, Container, PersistentVolumeClaim) yang melanggar batasan LimitRange, maka permintaan ke server API akan gagal dengan kode status HTTP <code>403 FORBIDDEN</code> dan sebuah pesan yang menjelaskan batasan yang telah dilanggar.</li><li>Apabila LimitRange diaktifkan pada Namespace untuk menghitung sumber daya seperti <code>cpu</code> dan <code>memory</code>, pengguna harus menentukan permintaan atau batasan untuk nilai-nilai itu. Jika tidak, sistem dapat menolak pembuatan Pod.</li><li>Pelanggaran terhadap LimitRange hanya terjadi pada tahap penerimaan Pod, bukan pada saat Pod sedang berjalan.</li></ul><p>Contoh dari kebijakan yang dapat dibuat dengan menggunakan LimitRange yaitu:</p><ul><li>Dalam klaster dua Node dengan kapasitas 8 GiB RAM dan 16 <em>core</em>, batasan Pod dalam Namespace meminta 100m untuk CPU dengan batas maksimum 500m untuk CPU dan minta 200Mi untuk Memori dengan batas maksimum 600Mi untuk Memori.</li><li>Tetapkan batas bawaan dan permintaan pada 150m untuk CPU dan permintaan standar memori pada 300Mi untuk Container yang dimulai tanpa cpu dan permintaan memori dalam spesifikasi mereka.</li></ul><p>Dalam kasus di mana batas total Namespace kurang dari jumlah batas Pod/Container,
mungkin akan ada perebutan untuk sumber daya. Dalam hal ini, maka Container atau Pod tidak akan dibuat.</p><p>Baik perebutan maupun perubahan pada LimitRange tidak akan mempengaruhi sumber daya yang sudah dibuat.</p><h2 id=selanjutnya>Selanjutnya</h2><p>Silahkan merujuk pada <a href=https://git.k8s.io/community/contributors/design-proposals/resource-management/admission_control_limit_range.md>Dokumen perancangan LimitRanger</a> untuk informasi lebih lanjut.</p><p>Untuk contoh tentang penggunaan batas, lihatlah:</p><ul><li><a href=/docs/tasks/administer-cluster/manage-resources/cpu-constraint-namespace/>Bagaimana cara mengonfigurasi batasan CPU minimum dan maksimum untuk setiap Namespace</a>.</li><li><a href=/docs/tasks/administer-cluster/manage-resources/memory-constraint-namespace/>Bagaimana cara mengonfigurasi batasan memori minimum dan maksimum untuk setiap Namespace</a>.</li><li><a href=/docs/tasks/administer-cluster/manage-resources/cpu-default-namespace/>Bagaimana cara mengonfigurasi permintaan dan batas bawaan CPU untuk setiap Namespace</a>.</li><li><a href=/docs/tasks/administer-cluster/manage-resources/memory-default-namespace/>Bagaimana cara mengonfigurasi permintaan dan batas bawaan memori untuk setiap Namespace</a>.</li><li><a href=/docs/tasks/administer-cluster/limit-storage-consumption/#limitrange-to-limit-requests-for-storage>Bagaimana cara mengonfigurasi konsumsi tempat penyimpanan minimum dan maksimum untuk setiap Namespace</a>.</li><li><a href=/docs/tasks/administer-cluster/quota-memory-cpu-namespace/>Contoh terperinci tentang mengonfigurasi kuota untuk setiap Namespace</a>.</li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-94ddc6e901c30f256138db11d09f05a3>10.2 - Resource Quota</h1><p>Saat beberapa pengguna atau tim berbagi sebuah klaster dengan jumlah Node yang tetap,
ada satu hal yang perlu diperhatikan yaitu suatu tim dapat menggunakan sumber daya
lebih dari jatah yang mereka perlukan.</p><p><em>Resource Quota</em> (kuota sumber daya) adalah sebuah alat yang dapat digunakan oleh
administrator untuk mengatasi hal ini.</p><p>Sebuah Resource Quota, didefinisikan oleh objek API <code>ResourceQuota</code>, menyediakan batasan-batasan
yang membatasi konsumsi gabungan sumber daya komputasi untuk tiap Namespace. Resource Quota dapat
membatasi jumlah objek yang dapat dibuat dalam sebuah Namespace berdasarkan tipenya, maupun jumlah
seluruh sumber daya komputasi yang dapat dipakai oleh sumber daya API (misalnya Pod) di Namespace
tersebut.</p><p>Resource Quota bekerja sebagai berikut:</p><ul><li>Tim-tim berbeda bekerja pada Namespace yang berbeda pula. Sekarang hal ini belum diwajibkan,
tetapi dukungan untuk mewajibkannya melalui ACL sedang direncanakan.</li><li>Administrator membuat sebuah <code>ResourceQuota</code> untuk setiap Namespace.</li><li>Para pengguna membuat sumber daya (Pod, Service, dll.) di dalam Namespace tersebut, kemudian
sistem kuota memantau penggunaan untuk memastikan bahwa penggunaannya tidak melebihi batas
sumber daya yang ditentukan di <code>ResourceQuota</code>.</li><li>Jika pembuatan atau pembaruan sebuah sumber daya melanggar sebuah batasan kuota, maka permintaan
tersebut akan gagal dengan kode status <code>403 FORBIDDEN</code> dengan sebuah pesan yang menjelaskan batasan
yang akan dilanggar.</li><li>Jika kuota diaktifkan di sebuah Namespace untuk sumber daya komputasi seperti <code>cpu</code> dan <code>memory</code>,
pengguna-pengguna harus menentukan <code>requests</code> atau <code>limits</code> untuk sumber daya tersebut; atau sistem
kuota akan menolak pembuatan Pod tersebut. Petunjuk: Gunakan Admission Controller <code>LimitRanger</code> untuk
memaksa nilai-nilai bawaan untuk Pod-Pod yang tidak menentukan kebutuhan sumber daya komputasi.
Lihat <a href=/docs/tasks/administer-cluster/quota-memory-cpu-namespace/>petunjuknya</a> untuk contoh bagaimana
cara menghindari masalah ini.</li></ul><p>Contoh-contoh kebijakan yang dapat dibuat menggunakan Namespace dan kuota adalah:</p><ul><li>Dalam sebuah klaster dengan kapasitas RAM 32 GiB, dan CPU 16 <em>core</em>, misalkan tim A menggunakan 20GiB
dan 10 <em>core</em>, dan tim B menggunakan 10GiB dan 4 <em>core</em>, dan menyimpan 2GiB dan 2 <em>core</em> untuk cadangan
penggunaan di masa depan.</li><li>Batasi Namespace "testing" dengan batas 1 <em>core</em> dan RAM 1GiB. Biarkan Namespace "production" menggunakan
berapapun jumlah yang diinginkan.</li></ul><p>Pada kasus di mana total kapasitas klaster lebih sedikit dari jumlah seluruh kuota di seluruh Namespace,
dapat terjadi perebutan sumber daya komputasi. Masalah ini akan ditangani dengan cara siapa-cepat-dia-dapat.</p><p>Perebutan sumber daya komputasi maupun perubahan kuota tidak akan memengaruhi sumber daya yang sudah dibuat
sebelumnya.</p><h2 id=mengaktifkan-resource-quota>Mengaktifkan Resource Quota</h2><p>Dukungan untuk Resource Quota diaktifkan secara bawaan pada banyak distribusi Kubernetes. Resource Quota
diaktifkan saat <em>flag</em> <code>--enable-admission-plugins=</code> pada apiserver memiliki <code>ResourceQuota</code> sebagai
salah satu nilainya.</p><p>Sebuah Resource Quota akan dipaksakan pada sebuah Namespace tertentu saat ada sebuah objek <code>ResourceQuota</code>
di dalam Namespace tersebut.</p><h2 id=resource-quota-komputasi>Resource Quota Komputasi</h2><p>Kamu dapat membatasi jumlah total <a href=/docs/user-guide/compute-resources>sumber daya komputasi</a> yang dapat
diminta di dalam sebuah Namespace.</p><p>Berikut jenis-jenis sumber daya yang didukung:</p><table><thead><tr><th>Nama Sumber Daya</th><th>Deskripsi</th></tr></thead><tbody><tr><td><code>limits.cpu</code></td><td>Pada seluruh Pod yang berada pada kondisi non-terminal, jumlah <code>limits</code> CPU tidak dapat melebihi nilai ini.</td></tr><tr><td><code>limits.memory</code></td><td>Pada seluruh Pod yang berada pada kondisi non-terminal, jumlah <code>limits</code> memori tidak dapat melebihi nilai ini.</td></tr><tr><td><code>limits.cpu</code></td><td>Pada seluruh Pod yang berada pada kondisi non-terminal, jumlah <code>requests</code> CPU tidak dapat melebihi nilai ini.</td></tr><tr><td><code>limits.memory</code></td><td>Pada seluruh Pod yang berada pada kondisi non-terminal, jumlah <code>requests</code> memori tidak dapat melebihi nilai ini.</td></tr></tbody></table><h3 id=resource-quota-untuk-sumber-daya-yang-diperluas>Resource Quota untuk sumber daya yang diperluas</h3><p>Sebagai tambahan untuk sumber daya yang disebutkan di atas, pada rilis 1.10, dukungan kuota untuk
<a href=/id/docs/concepts/configuration/manage-compute-resources-container/#extended-resources>sumber daya yang diperluas</a> ditambahkan.</p><p>Karena <em>overcommit</em> tidak diperbolehkan untuk sumber daya yang diperluas, tidak masuk akal untuk menentukan
keduanya; <code>requests</code> dan <code>limits</code> untuk sumber daya yang diperluas yang sama pada sebuah kuota. Jadi, untuk
sumber daya yang diperluas, hanya kuota dengan prefiks <code>requests.</code> saja yang diperbolehkan untuk sekarang.</p><p>Mari kita ambil contoh sumber daya GPU. Jika nama sumber dayanya adalah <code>nvidia.com/gpu</code>, dan kamu ingin
membatasi jumlah total GPU yang diminta pada sebuah Namespace menjadi 4, kamu dapat menentukan sebuah kuota
sebagai berikut:</p><ul><li><code>requests.nvidia.com/gpu: 4</code></li></ul><p>Lihat <a href=#melihat-dan-menyetel-kuota>Melihat dan Menyetel Kuota</a> untuk informasi lebih lanjut.</p><h2 id=resource-quota-untuk-penyimpanan>Resource Quota untuk penyimpanan</h2><p>Kamu dapat membatasi jumlah total <a href=/id/docs/concepts/storage/persistent-volumes/>sumber daya penyimpanan</a> yang dapat
diminta pada sebuah Namespace.</p><p>Sebagai tambahan, kamu dapat membatasi penggunaan sumber daya penyimpanan berdasarkan <em>storage class</em>
sumber daya penyimpanan tersebut.</p><table><thead><tr><th>Nama Sumber Daya</th><th>Deskripsi</th></tr></thead><tbody><tr><td><code>requests.storage</code></td><td>Pada seluruh Persistent Volume Claim, jumlah <code>requests</code> penyimpanan tidak dapat melebihi nilai ini.</td></tr><tr><td><code>persistentvolumeclaims</code></td><td>Jumlah kuantitas <a href=/id/docs/concepts/storage/persistent-volumes/#persistentvolumeclaims>Persistent Volume Claim</a> yang dapat ada di dalam sebuah Namespace.</td></tr><tr><td><code>&lt;storage-class-name>.storageclass.storage.k8s.io/requests.storage</code></td><td>Pada seluruh Persistent Volume Claim yang dikaitkan dengan sebuah nama <em>storage-class</em> (melalui kolom <code>storageClassName</code>), jumlah permintaan penyimpanan tidak dapat melebihi nilai ini.</td></tr><tr><td><code>&lt;storage-class-name>.storageclass.storage.k8s.io/persistentvolumeclaims</code></td><td>Pada seluruh Persistent Volume Claim yang dikaitkan dengan sebuah nama <em>storage-class</em> (melalui kolom <code>storageClassName</code>), jumlah kuantitas <a href=/id/docs/concepts/storage/persistent-volumes/#persistentvolumeclaims>Persistent Volume Claim</a> yang dapat ada di dalam sebuah Namespace.</td></tr></tbody></table><p>Sebagai contoh, jika sebuah operator ingin membatasi penyimpanan dengan Storage Class <code>gold</code> yang berbeda dengan Storage Class <code>bronze</code>, maka operator tersebut dapat menentukan kuota sebagai berikut:</p><ul><li><code>gold.storageclass.storage.k8s.io/requests.storage: 500Gi</code></li><li><code>bronze.storageclass.storage.k8s.io/requests.storage: 100Gi</code></li></ul><p>Pada rilis 1.8, dukungan kuota untuk penyimpanan lokal sementara (<em>local ephemeral storage</em>) ditambahkan sebagai
sebuah fitur <em>alpha</em>:</p><table><thead><tr><th>Nama Sumber Daya</th><th>Deskripsi</th></tr></thead><tbody><tr><td><code>requests.ephemeral-storage</code></td><td>Pada seluruh Pod di sebuah Namespace, jumlah <code>requests</code> penyimpanan lokal sementara tidak dapat melebihi nilai ini.</td></tr><tr><td><code>limits.ephemeral-storage</code></td><td>Pada seluruh Pod di sebuah Namespace, jumlah <code>limits</code> penyimpanan lokal sementara tidak dapat melebihi nilai ini.</td></tr></tbody></table><h2 id=kuota-kuantitas-objek>Kuota Kuantitas Objek</h2><p>Rilis 1.9 menambahkan dukungan untuk membatasi semua jenis sumber daya standar yang berada pada sebuah Namespace dengan sintaksis sebagai berikut:</p><ul><li><code>count/&lt;sumber-daya>.&lt;grup></code></li></ul><p>Berikut contoh-contoh sumber daya yang dapat ditentukan pengguna pada kuota kuantitas objek:</p><ul><li><code>count/persistentvolumeclaims</code></li><li><code>count/services</code></li><li><code>count/secrets</code></li><li><code>count/configmaps</code></li><li><code>count/replicationcontrollers</code></li><li><code>count/deployments.apps</code></li><li><code>count/replicasets.apps</code></li><li><code>count/statefulsets.apps</code></li><li><code>count/jobs.batch</code></li><li><code>count/cronjobs.batch</code></li><li><code>count/deployments.extensions</code></li></ul><p>Rilis 1.15 menambahkan dukungan untuk sumber daya <em>custom</em> menggunakan sintaksis yang sama.
Contohnya, untuk membuat kuota pada sumber daya <em>custom</em> <code>widgets</code> pada grup API <code>example.com</code>, gunakan
<code>count/widgets.example.com</code>.</p><p>Saat menggunakan Resource Quota <code>count/*</code>, sebuah objek akan menggunakan kuotanya jika ia berada pada penyimpanan Apiserver.
Tipe-tipe kuota ini berguna untuk menjaga dari kehabisan sumber daya penyimpanan. Misalnya, kamu mungkin
ingin membatasi kuantitas objek Secret pada sebuah Apiserver karena ukuran mereka yang besar. Terlalu banyak
Secret pada sebuah klaster bahkan dapat membuat Server dan Controller tidak dapat dijalankan! Kamu dapat membatasi
jumlah Job untuk menjaga dari CronJob yang salah dikonfigurasi sehingga membuat terlalu banyak Job pada sebuah
Namespace yang mengakibatkan <em>denial of service</em>.</p><p>Sebelum rilis 1.9, kita tidak dapat melakukan pembatasan kuantitas objek generik pada kumpulan sumber daya yang terbatas.
Sebagai tambahan, kita dapat membatasi lebih lanjut sumber daya tertentu dengan kuota berdasarkan jenis mereka.</p><p>Berikut jenis-jenis yang telah didukung:</p><table><thead><tr><th>Nama Sumber Daya</th><th>Deskripsi</th></tr></thead><tbody><tr><td><code>configmaps</code></td><td>Jumlah total ConfigMap yang dapat berada pada suatu Namespace.</td></tr><tr><td><code>persistentvolumeclaims</code></td><td>Jumlah total PersistentVolumeClaim<a href=/id/docs/concepts/storage/persistent-volumes/#persistentvolumeclaims>persistent volume claims</a> yang dapat berada pada suatu Namespace.</td></tr><tr><td><code>pods</code></td><td>Jumlah total Pod yang berada pada kondisi non-terminal yang dapat berada pada suatu Namespace. Sebuah Pod berada kondisi terminal yaitu jika <code>.status.phase in (Failed, Succeded)</code> adalah <code>true</code>.</td></tr><tr><td><code>replicationcontrollers</code></td><td>Jumlah total ReplicationController yang dapat berada pada suatu Namespace.</td></tr><tr><td><code>resourcequotas</code></td><td>Jumlah total <a href=/docs/reference/access-authn-authz/admission-controllers/#resourcequota>ResourceQuota</a> yang dapat berada pada suatu Namespace.</td></tr><tr><td><code>services</code></td><td>Jumlah total Service yang dapat berada pada suatu Namespace.</td></tr><tr><td><code>services.loadbalancers</code></td><td>Jumlah total Service dengan tipe LoadBalancer yang dapat berada pada suatu Namespace.</td></tr><tr><td><code>services.nodeports</code></td><td>Jumlah total Service dengan tipe NodePort yang dapat berada pada suatu Namespace.</td></tr><tr><td><code>secrets</code></td><td>Jumlah total Secret yang dapat berada pada suatu Namespace.</td></tr></tbody></table><p>Sebagai contoh, <code>pods</code> membatasi kuantitas dan memaksa kuantitas maksimum <code>pods</code> yang
berada pada kondisi non-terminal yang dibuat pada sebuah Namespace. Kamu mungkin ingin
menyetel kuota <code>pods</code> pada sebuah Namespace untuk menghindari kasus di mana pengguna membuat
banyak Pod kecil dan menghabiskan persediaan alamat IP Pod pada klaster.</p><h2 id=lingkup-kuota>Lingkup Kuota</h2><p>Setiap kuota dapat memiliki kumpulan lingkup yang dikaitkan. Sebuah kuota hanya akan mengukur penggunaan sebuah
sumber daya jika sumber daya tersebut cocok dengan irisan dari lingkup-lingkup yang ditentukan.</p><p>Saat sebuah lingkup ditambahkan kepada kuota, lingkup itu akan membatasi kuantitas sumber daya yang didukung menjadi yang berkaitan dengan lingkup tersebut.
Sumber daya yang ditentukan pada kuota di luar kumpulan yang diizinkan akan menghasilkan kesalahan validasi.</p><table><thead><tr><th>Lingkup</th><th>Deskripsi</th></tr></thead><tbody><tr><td><code>Terminating</code></td><td>Mencocokkan dengan Pod-Pod yang memiliki <code>.spec.activeDeadlineSeconds >= 0</code></td></tr><tr><td><code>NotTerminating</code></td><td>Mencocokkan dengan Pod-Pod yang memiliki <code>.spec.activeDeadlineSeconds is nil</code></td></tr><tr><td><code>BestEffort</code></td><td>Mencocokkan dengan Pod-Pod yang memiliki <em>quality of service</em> bertipe <em>best effort</em>.</td></tr><tr><td><code>NotBestEffort</code></td><td>Mencocokkan dengan Pod-Pod yang tidak memiliki <em>quality of service</em> bertipe <em>best effort</em>.</td></tr></tbody></table><p>Lingkup <code>BestEffort</code> membatasi sebuah kuota untuk memantau sumber daya berikut: <code>pods</code></p><p>Lingkup <code>Terminating</code>, <code>NotTerminating</code>, dan <code>NotBestEffort</code> membatasi sebuah kuota untuk memantau sumber daya berikut:</p><ul><li><code>cpu</code></li><li><code>limits.cpu</code></li><li><code>limits.memory</code></li><li><code>memory</code></li><li><code>pods</code></li><li><code>requests.cpu</code></li><li><code>requests.memory</code></li></ul><h3 id=resource-quota-per-priorityclass>Resource Quota Per PriorityClass</h3><div style=margin-top:10px;margin-bottom:10px><b>FEATURE STATE:</b> <code>Kubernetes 1.12 [beta]</code></div><p>Pod-Pod dapat dibuat dengan sebuah <a href=/id/docs/concepts/configuration/pod-priority-preemption/#pod-priority>Priority (prioritas)</a> tertentu.
Kamu dapat mengontrol konsumsi sumber daya sistem sebuah Pod berdasarkan Priority Pod tersebut, menggunakan
kolom <code>scopeSelector</code> pada spesifikasi kuota tersebut.</p><p>Sebuah kuota dicocokkan dan digunakan hanya jika <code>scopeSelector</code> pada spesifikasi kuota tersebut memilih Pod tersebut.</p><p>Contoh ini membuat sebuah objek kuota dan mencocokkannya dengan Pod-Pod pada Priority tertentu. Contoh tersebut
bekerja sebagai berikut:</p><ul><li>Pod-Pod di dalam klaster memiliki satu dari tiga Priority Class, "low", "medium", "high".</li><li>Satu objek kuota dibuat untuk setiap Priority.</li></ul><p>Simpan YAML berikut ke sebuah berkas bernama <code>quota.yml</code>.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>List<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>items</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span>- <span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>ResourceQuota<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>pods-high<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>hard</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>cpu</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;1000&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>memory</span>:<span style=color:#bbb> </span>200Gi<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>pods</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;10&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>scopeSelector</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>matchExpressions</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- <span style=color:green;font-weight:700>operator </span>:<span style=color:#bbb> </span>In<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>scopeName</span>:<span style=color:#bbb> </span>PriorityClass<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>values</span>:<span style=color:#bbb> </span>[<span style=color:#b44>&#34;high&#34;</span>]<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span>- <span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>ResourceQuota<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>pods-medium<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>hard</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>cpu</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;10&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>memory</span>:<span style=color:#bbb> </span>20Gi<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>pods</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;10&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>scopeSelector</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>matchExpressions</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- <span style=color:green;font-weight:700>operator </span>:<span style=color:#bbb> </span>In<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>scopeName</span>:<span style=color:#bbb> </span>PriorityClass<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>values</span>:<span style=color:#bbb> </span>[<span style=color:#b44>&#34;medium&#34;</span>]<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span>- <span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>ResourceQuota<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>pods-low<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>hard</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>cpu</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;5&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>memory</span>:<span style=color:#bbb> </span>10Gi<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>pods</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;10&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>scopeSelector</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>matchExpressions</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- <span style=color:green;font-weight:700>operator </span>:<span style=color:#bbb> </span>In<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>scopeName</span>:<span style=color:#bbb> </span>PriorityClass<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>values</span>:<span style=color:#bbb> </span>[<span style=color:#b44>&#34;low&#34;</span>]<span style=color:#bbb>
</span></span></span></code></pre></div><p>Terapkan YAML tersebut dengan <code>kubectl create</code>.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl create -f ./quota.yml
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>resourcequota/pods-high created
</span></span><span style=display:flex><span>resourcequota/pods-medium created
</span></span><span style=display:flex><span>resourcequota/pods-low created
</span></span></code></pre></div><p>Pastikan bahwa kuota <code>Used</code> adalah <code>0</code> dengan <code>kubectl describe quota</code>.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl describe quota
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>Name:       pods-high
</span></span><span style=display:flex><span>Namespace:  default
</span></span><span style=display:flex><span>Resource    Used  Hard
</span></span><span style=display:flex><span>--------    ----  ----
</span></span><span style=display:flex><span>cpu         <span style=color:#666>0</span>     1k
</span></span><span style=display:flex><span>memory      <span style=color:#666>0</span>     200Gi
</span></span><span style=display:flex><span>pods        <span style=color:#666>0</span>     <span style=color:#666>10</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>Name:       pods-low
</span></span><span style=display:flex><span>Namespace:  default
</span></span><span style=display:flex><span>Resource    Used  Hard
</span></span><span style=display:flex><span>--------    ----  ----
</span></span><span style=display:flex><span>cpu         <span style=color:#666>0</span>     <span style=color:#666>5</span>
</span></span><span style=display:flex><span>memory      <span style=color:#666>0</span>     10Gi
</span></span><span style=display:flex><span>pods        <span style=color:#666>0</span>     <span style=color:#666>10</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>Name:       pods-medium
</span></span><span style=display:flex><span>Namespace:  default
</span></span><span style=display:flex><span>Resource    Used  Hard
</span></span><span style=display:flex><span>--------    ----  ----
</span></span><span style=display:flex><span>cpu         <span style=color:#666>0</span>     <span style=color:#666>10</span>
</span></span><span style=display:flex><span>memory      <span style=color:#666>0</span>     20Gi
</span></span><span style=display:flex><span>pods        <span style=color:#666>0</span>     <span style=color:#666>10</span>
</span></span></code></pre></div><p>Buat sebuah Pod dengan Priority "high". Simpan YAML berikut ke sebuah
berkas bernama <code>high-priority-pod.yml</code>.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>high-priority<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>high-priority<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>ubuntu<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>command</span>:<span style=color:#bbb> </span>[<span style=color:#b44>&#34;/bin/sh&#34;</span>]<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>args</span>:<span style=color:#bbb> </span>[<span style=color:#b44>&#34;-c&#34;</span>,<span style=color:#bbb> </span><span style=color:#b44>&#34;while true; do echo hello; sleep 10;done&#34;</span>]<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>resources</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>requests</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>memory</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;10Gi&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>cpu</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;500m&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>limits</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>memory</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;10Gi&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>cpu</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;500m&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>priorityClassName</span>:<span style=color:#bbb> </span>high<span style=color:#bbb>
</span></span></span></code></pre></div><p>Terapkan dengan <code>kubectl create</code>.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl create -f ./high-priority-pod.yml
</span></span></code></pre></div><p>Pastikan bahwa status "Used" untuk kuota dengan Priority "high", <code>pods-high</code>, telah berubah
dan dua kuota lainnya tidak berubah.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl describe quota
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>Name:       pods-high
</span></span><span style=display:flex><span>Namespace:  default
</span></span><span style=display:flex><span>Resource    Used  Hard
</span></span><span style=display:flex><span>--------    ----  ----
</span></span><span style=display:flex><span>cpu         500m  1k
</span></span><span style=display:flex><span>memory      10Gi  200Gi
</span></span><span style=display:flex><span>pods        <span style=color:#666>1</span>     <span style=color:#666>10</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>Name:       pods-low
</span></span><span style=display:flex><span>Namespace:  default
</span></span><span style=display:flex><span>Resource    Used  Hard
</span></span><span style=display:flex><span>--------    ----  ----
</span></span><span style=display:flex><span>cpu         <span style=color:#666>0</span>     <span style=color:#666>5</span>
</span></span><span style=display:flex><span>memory      <span style=color:#666>0</span>     10Gi
</span></span><span style=display:flex><span>pods        <span style=color:#666>0</span>     <span style=color:#666>10</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>Name:       pods-medium
</span></span><span style=display:flex><span>Namespace:  default
</span></span><span style=display:flex><span>Resource    Used  Hard
</span></span><span style=display:flex><span>--------    ----  ----
</span></span><span style=display:flex><span>cpu         <span style=color:#666>0</span>     <span style=color:#666>10</span>
</span></span><span style=display:flex><span>memory      <span style=color:#666>0</span>     20Gi
</span></span><span style=display:flex><span>pods        <span style=color:#666>0</span>     <span style=color:#666>10</span>
</span></span></code></pre></div><p><code>scopeSelector</code> mendukung nilai-nilai berikut pada kolom <code>operator</code>:</p><ul><li><code>In</code></li><li><code>NotIn</code></li><li><code>Exist</code></li><li><code>DoesNotExist</code></li></ul><h2 id=request-vs-limit><em>Request</em> vs Limit</h2><p>Saat mengalokasikan sumber daya komputasi, setiap Container dapat menentukan sebuah nilai <em>request</em> (permintaan) dan limit untuk CPU atau memori.
Kuota tersebut dapat dikonfigurasi untuk membatasi nilai salah satunya.</p><p>Jika kuota tersebut memiliki sebuah nilai yang ditentukan untuk <code>requests.cpu</code> atau <code>requests.memory</code>, maka kuota
tersebut mengharuskan setiap Container yang akan dibuat untuk menentukan request eksplisit untuk sumber daya tersebut.
Jika kuota tersebut memiliki sebuah nilai yang ditentukan untuk <code>limits.cpu</code> atau <code>limits.memory</code>, maka kuota tersebut
mengharuskan setiap Container yang akan dibuat untuk menentukan limit eksplisit untuk sumber daya tersebut.</p><h2 id=melihat-dan-menyetel-kuota>Melihat dan Menyetel kuota</h2><p>Kubectl mendukung membuat, membarui, dan melihat kuota:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl create namespace myspace
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>cat <span style=color:#b44>&lt;&lt;EOF &gt; compute-resources.yaml
</span></span></span><span style=display:flex><span><span style=color:#b44>apiVersion: v1
</span></span></span><span style=display:flex><span><span style=color:#b44>kind: ResourceQuota
</span></span></span><span style=display:flex><span><span style=color:#b44>metadata:
</span></span></span><span style=display:flex><span><span style=color:#b44>  name: compute-resources
</span></span></span><span style=display:flex><span><span style=color:#b44>spec:
</span></span></span><span style=display:flex><span><span style=color:#b44>  hard:
</span></span></span><span style=display:flex><span><span style=color:#b44>    requests.cpu: &#34;1&#34;
</span></span></span><span style=display:flex><span><span style=color:#b44>    requests.memory: 1Gi
</span></span></span><span style=display:flex><span><span style=color:#b44>    limits.cpu: &#34;2&#34;
</span></span></span><span style=display:flex><span><span style=color:#b44>    limits.memory: 2Gi
</span></span></span><span style=display:flex><span><span style=color:#b44>    requests.nvidia.com/gpu: 4
</span></span></span><span style=display:flex><span><span style=color:#b44>EOF</span>
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl create -f ./compute-resources.yaml --namespace<span style=color:#666>=</span>myspace
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>cat <span style=color:#b44>&lt;&lt;EOF &gt; object-counts.yaml
</span></span></span><span style=display:flex><span><span style=color:#b44>apiVersion: v1
</span></span></span><span style=display:flex><span><span style=color:#b44>kind: ResourceQuota
</span></span></span><span style=display:flex><span><span style=color:#b44>metadata:
</span></span></span><span style=display:flex><span><span style=color:#b44>  name: object-counts
</span></span></span><span style=display:flex><span><span style=color:#b44>spec:
</span></span></span><span style=display:flex><span><span style=color:#b44>  hard:
</span></span></span><span style=display:flex><span><span style=color:#b44>    configmaps: &#34;10&#34;
</span></span></span><span style=display:flex><span><span style=color:#b44>    persistentvolumeclaims: &#34;4&#34;
</span></span></span><span style=display:flex><span><span style=color:#b44>    pods: &#34;4&#34;
</span></span></span><span style=display:flex><span><span style=color:#b44>    replicationcontrollers: &#34;20&#34;
</span></span></span><span style=display:flex><span><span style=color:#b44>    secrets: &#34;10&#34;
</span></span></span><span style=display:flex><span><span style=color:#b44>    services: &#34;10&#34;
</span></span></span><span style=display:flex><span><span style=color:#b44>    services.loadbalancers: &#34;2&#34;
</span></span></span><span style=display:flex><span><span style=color:#b44>EOF</span>
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl create -f ./object-counts.yaml --namespace<span style=color:#666>=</span>myspace
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get quota --namespace<span style=color:#666>=</span>myspace
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>NAME                    AGE
</span></span><span style=display:flex><span>compute-resources       30s
</span></span><span style=display:flex><span>object-counts           32s
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl describe quota compute-resources --namespace<span style=color:#666>=</span>myspace
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>Name:                    compute-resources
</span></span><span style=display:flex><span>Namespace:               myspace
</span></span><span style=display:flex><span>Resource                 Used  Hard
</span></span><span style=display:flex><span>--------                 ----  ----
</span></span><span style=display:flex><span>limits.cpu               <span style=color:#666>0</span>     <span style=color:#666>2</span>
</span></span><span style=display:flex><span>limits.memory            <span style=color:#666>0</span>     2Gi
</span></span><span style=display:flex><span>requests.cpu             <span style=color:#666>0</span>     <span style=color:#666>1</span>
</span></span><span style=display:flex><span>requests.memory          <span style=color:#666>0</span>     1Gi
</span></span><span style=display:flex><span>requests.nvidia.com/gpu  <span style=color:#666>0</span>     <span style=color:#666>4</span>
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl describe quota object-counts --namespace<span style=color:#666>=</span>myspace
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>Name:                   object-counts
</span></span><span style=display:flex><span>Namespace:              myspace
</span></span><span style=display:flex><span>Resource                Used    Hard
</span></span><span style=display:flex><span>--------                ----    ----
</span></span><span style=display:flex><span>configmaps              <span style=color:#666>0</span>       <span style=color:#666>10</span>
</span></span><span style=display:flex><span>persistentvolumeclaims  <span style=color:#666>0</span>       <span style=color:#666>4</span>
</span></span><span style=display:flex><span>pods                    <span style=color:#666>0</span>       <span style=color:#666>4</span>
</span></span><span style=display:flex><span>replicationcontrollers  <span style=color:#666>0</span>       <span style=color:#666>20</span>
</span></span><span style=display:flex><span>secrets                 <span style=color:#666>1</span>       <span style=color:#666>10</span>
</span></span><span style=display:flex><span>services                <span style=color:#666>0</span>       <span style=color:#666>10</span>
</span></span><span style=display:flex><span>services.loadbalancers  <span style=color:#666>0</span>       <span style=color:#666>2</span>
</span></span></code></pre></div><p>Kubectl juga mendukung kuota kuantitas objek untuk semua sumber daya standar yang berada pada Namespace
menggunakan sintaksis <code>count/&lt;resource>.&lt;group></code>:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl create namespace myspace
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl create quota <span style=color:#a2f>test</span> --hard<span style=color:#666>=</span>count/deployments.extensions<span style=color:#666>=</span>2,count/replicasets.extensions<span style=color:#666>=</span>4,count/pods<span style=color:#666>=</span>3,count/secrets<span style=color:#666>=</span><span style=color:#666>4</span> --namespace<span style=color:#666>=</span>myspace
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl run nginx --image<span style=color:#666>=</span>nginx --replicas<span style=color:#666>=</span><span style=color:#666>2</span> --namespace<span style=color:#666>=</span>myspace
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl describe quota --namespace<span style=color:#666>=</span>myspace
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>Name:                         <span style=color:#a2f>test</span>
</span></span><span style=display:flex><span>Namespace:                    myspace
</span></span><span style=display:flex><span>Resource                      Used  Hard
</span></span><span style=display:flex><span>--------                      ----  ----
</span></span><span style=display:flex><span>count/deployments.extensions  <span style=color:#666>1</span>     <span style=color:#666>2</span>
</span></span><span style=display:flex><span>count/pods                    <span style=color:#666>2</span>     <span style=color:#666>3</span>
</span></span><span style=display:flex><span>count/replicasets.extensions  <span style=color:#666>1</span>     <span style=color:#666>4</span>
</span></span><span style=display:flex><span>count/secrets                 <span style=color:#666>1</span>     <span style=color:#666>4</span>
</span></span></code></pre></div><h2 id=kuota-dan-kapasitas-klaster>Kuota dan Kapasitas Klaster</h2><p><code>ResourceQuota</code> tidak tergantung pada kapasitas klaster. <code>ResourceQuota</code> ditentukan dalam
satuan-satuan absolut. Jadi, jika kamu menambahkan Node ke klaster kamu, penambahan ini
<strong>bukan</strong> berarti secara otomatis memberikan setiap Namespace kemampuan untuk menggunakan
lebih banyak sumber daya.</p><p>Terkadang kebijakan yang lebih kompleks mungkin lebih diinginkan, seperti:</p><ul><li>Secara proporsional membagi sumber daya total klaster untuk beberapa tim.</li><li>Mengizinkan setiap tim untuk meningkatkan penggunaan sumber daya sesuai kebutuhan,
tetapi tetap memiliki batas yang cukup besar untuk menghindari kehabisan sumber daya.</li><li>Mendeteksi permintaan dari sebuah Namespace, menambah Node, kemudian menambah kuota.</li></ul><p>Kebijakan-kebijakan seperti itu dapat diterapkan dengan <code>ResourceQuota</code> sebagai dasarnya,
dengan membuat sebuah "pengontrol" yang memantau penggunaan kuota dan menyesuaikan batas
keras kuota untuk setiap Namespace berdasarkan sinyal-sinyal lainnya.</p><p>Perlu dicatat bahwa Resource Quota membagi agregat sumber daya klaster, tapi Resource Quota
tidak membuat batasan-batasan terhadap Node: Pod-Pod dari beberapa Namespace boleh berjalan
di Node yang sama.</p><h2 id=membatasi-konsumsi-priority-class-secara-bawaan>Membatasi konsumsi Priority Class secara bawaan</h2><p>Mungkin saja diinginkan untuk Pod-Pod pada kelas prioritas tertentu, misalnya "cluster-services", sebaiknya diizinkan pada sebuah Namespace, jika dan hanya jika terdapat sebuah objek kuota yang cocok.</p><p>Dengan mekanisme ini, operator-operator dapat membatasi penggunaan Priority Class dengan prioritas tinggi pada Namespace-Namespace tertentu saja dan tidak semua Namespace dapat menggunakan Priority Class tersebut secara bawaan.</p><p>Untuk memaksa aturan ini, <em>flag</em> kube-apiserver <code>--admission-control-config-file</code> sebaiknya digunakan untuk memberikan <em>path</em> menuju berkas konfigurasi berikut:</p><ul class="nav nav-tabs" id=example1 role=tablist><li class=nav-item><a data-toggle=tab class="nav-link active" href=#example1-0 role=tab aria-controls=example1-0 aria-selected=true>apiserver.config.k8s.io/v1</a></li><li class=nav-item><a data-toggle=tab class=nav-link href=#example1-1 role=tab aria-controls=example1-1>apiserver.k8s.io/v1alpha1</a></li></ul><div class=tab-content id=example1><div id=example1-0 class="tab-pane show active" role=tabpanel aria-labelledby=example1-0><p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>apiserver.config.k8s.io/v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>AdmissionConfiguration<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>plugins</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;ResourceQuota&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>configuration</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>apiserver.config.k8s.io/v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>ResourceQuotaConfiguration<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>limitedResources</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:green;font-weight:700>resource</span>:<span style=color:#bbb> </span>pods<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>matchScopes</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- <span style=color:green;font-weight:700>scopeName</span>:<span style=color:#bbb> </span>PriorityClass<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>operator</span>:<span style=color:#bbb> </span>In<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>values</span>:<span style=color:#bbb> </span>[<span style=color:#b44>&#34;cluster-services&#34;</span>]<span style=color:#bbb>
</span></span></span></code></pre></div></div><div id=example1-1 class=tab-pane role=tabpanel aria-labelledby=example1-1><p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#080;font-style:italic># Kedaluwarsa pada v1.17 digantikan oleh apiserver.config.k8s.io/v1</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>apiserver.k8s.io/v1alpha1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>AdmissionConfiguration<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>plugins</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;ResourceQuota&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>configuration</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:#080;font-style:italic># Kedaluwarsa pada v1.17 digantikan oleh apiserver.config.k8s.io/v1, ResourceQuotaConfiguration</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>resourcequota.admission.k8s.io/v1beta1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Configuration<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>limitedResources</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:green;font-weight:700>resource</span>:<span style=color:#bbb> </span>pods<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>matchScopes</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- <span style=color:green;font-weight:700>scopeName</span>:<span style=color:#bbb> </span>PriorityClass<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>operator</span>:<span style=color:#bbb> </span>In<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>values</span>:<span style=color:#bbb> </span>[<span style=color:#b44>&#34;cluster-services&#34;</span>]<span style=color:#bbb>
</span></span></span></code></pre></div></div></div><p>Sekarang, Pod-Pod "cluster-services" akan diizinkan hanya pada Namespace di mana ada sebuah objek kuota dengan sebuah <code>scopeSelector</code> yang cocok.</p><p>Contohnya:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>scopeSelector</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>matchExpressions</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- <span style=color:green;font-weight:700>scopeName</span>:<span style=color:#bbb> </span>PriorityClass<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>operator</span>:<span style=color:#bbb> </span>In<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>values</span>:<span style=color:#bbb> </span>[<span style=color:#b44>&#34;cluster-services&#34;</span>]<span style=color:#bbb>
</span></span></span></code></pre></div><p>Lihat <a href=https://github.com/kubernetes/kubernetes/pull/36765>LimitedResources</a> dan <a href=https://github.com/kubernetes/community/blob/master/contributors/design-proposals/scheduling/pod-priority-resourcequota.md>dokumen desain dukungan Quota untuk Priority Class</a> untuk informasi lebih lanjut.</p><h2 id=contoh>Contoh</h2><p>Lihat <a href=/docs/tasks/administer-cluster/quota-api-object/>contoh detail cara menggunakan sebuah Resource Quota</a>.</p><h2 id=selanjutnya>Selanjutnya</h2><p>Lihat <a href=https://git.k8s.io/community/contributors/design-proposals/resource-management/admission_control_resource_quota.md>dokumen desain ResourceQuota</a> untuk informasi lebih lanjut.</p></div><div class=td-content style=page-break-before:always><h1 id=pg-59977cbac423e20437db079757cb03df>10.3 - Pod Security Policy</h1><div style=margin-top:10px;margin-bottom:10px><b>FEATURE STATE:</b> <code>Kubernetes v1.25 [beta]</code></div><p>Pod Security Policies (kebijakan keamanan Pod) memungkinkan otorisasi secara detil dari pembuatan dan pembaruan Pod.</p><h2 id=apa-itu-pod-security-policy>Apa itu Pod Security Policy?</h2><p><em>Pod Security Policy</em> adalah sebuah sumber daya pada tingkat klaster yang mengatur aspek-aspek spesifikasi Pod yang sensitif terhadap keamanan. Objek-objek <code>PodSecurityPolicy</code> mendefinisikan sebuah kumpulan kondisi yang harus dijalankan oleh Pod untuk dapat diterima oleh sistem, dan juga sebagai nilai-nilai bawaan untuk kolom-kolom yang bersangkutan. Mereka memungkinkan administrator untuk mengatur hal-hal berikut:</p><table><thead><tr><th>Aspek yang diatur</th><th>Nama Kolom</th></tr></thead><tbody><tr><td>Menjalankan Container-container yang <em>privileged</em></td><td><a href=#privileged><code>privileged</code></a></td></tr><tr><td>Penggunaan <em>namespace-namespace</em> milik <em>host</em></td><td><a href=#host-namespaces><code>hostPID</code>, <code>hostIPC</code></a></td></tr><tr><td>Penggunaan jaringan dan <em>port</em> milik <em>host</em></td><td><a href=#host-namespaces><code>hostNetwork</code>, <code>hostPorts</code></a></td></tr><tr><td>Penggunaan jenis-jenis Volume</td><td><a href=#volumes-and-file-systems><code>volumes</code></a></td></tr><tr><td>Penggunaan <em>filesystem</em> milik <em>host</em></td><td><a href=#volumes-and-file-systems><code>allowedHostPaths</code></a></td></tr><tr><td>Daftar putih untuk <em>driver-driver</em> Flexvolume</td><td><a href=#flexvolume-drivers><code>allowedFlexVolumes</code></a></td></tr><tr><td>Mengalokasi FSGroup yang memiliki Volume milik Pod</td><td><a href=#volumes-and-file-systems><code>fsGroup</code></a></td></tr><tr><td>Mengharuskan penggunaan <em>read-only root filesystem</em></td><td><a href=#volumes-and-file-systems><code>readOnlyRootFilesystem</code></a></td></tr><tr><td>User dan Grop ID dari Container</td><td><a href=#users-and-groups><code>runAsUser</code>, <code>runAsGroup</code>, <code>supplementalGroups</code></a></td></tr><tr><td>Membatasi eskalasi ke kemampuan <em>root</em></td><td><a href=#privilege-escalation><code>allowPrivilegeEscalation</code>, <code>defaultAllowPrivilegeEscalation</code></a></td></tr><tr><td>Kemampuan-kemampuan Linux</td><td><a href=#capabilities><code>defaultAddCapabilities</code>, <code>requiredDropCapabilities</code>, <code>allowedCapabilities</code></a></td></tr><tr><td>Konteks SELinux dari Container ainer</td><td><a href=#selinux><code>seLinux</code></a></td></tr><tr><td>Jenis tambatan Proc yang diizinkan untuk Container</td><td><a href=#allowedprocmounttypes><code>allowedProcMountTypes</code></a></td></tr><tr><td>Profil AppArmor yang digunakan oleh Container</td><td><a href=#apparmor>annotations</a></td></tr><tr><td>Profil seccomp yang digubakan oleh Container</td><td><a href=#seccomp>annotations</a></td></tr><tr><td>Profil sysctl yang digunakan oleh Container</td><td><a href=#sysctl><code>forbiddenSysctls</code>,<code>allowedUnsafeSysctls</code></a></td></tr></tbody></table><h2 id=mengaktifkan-pod-security-policy>Mengaktifkan Pod Security Policy</h2><p>Pengaturan Pod Security Policy diimplementasi sebagai sebuah opsi (tapi direkomendasikan untuk digunakan) dari <a href=/docs/reference/access-authn-authz/admission-controllers/#podsecuritypolicy><em>admission controller</em></a>. PodSecurityPolicy dilaksanakan dengan <a href=/docs/reference/access-authn-authz/admission-controllers/#how-do-i-turn-on-an-admission-control-plug-in>mengaktifkan <em>admission controller</em>-nya</a>, tetapi melakukan hal ini tanpa mengizinkan kebijakan apapun <strong>akan menghalangi Pod apapun untuk dibuat</strong> di dalam klaster.</p><p>Sejak API dari Pod Security Policy (<code>policy/v1beta1/podsecuritypolicy</code>) diaktifkan secara independen dari <em>admission controller</em>, untuk klaster-klaster yang sudah ada direkomendasikan untuk menambahkan dan mengizinkan kebijakan yang bersangkutan sebelum mengaktifkan <em>admission controller</em> tersebut.</p><h2 id=mengizinkan-kebijakan>Mengizinkan Kebijakan</h2><p>Saat sebuah sumber daya PodSecurityPolicy dibuat, ia tidak melakukan apa-apa. Untuk menggunakannya, <a href=/id/docs/tasks/configure-pod-container/configure-service-account/>Service Account</a> dari pengguna yang memintanya atau target Pod-nya harus diizinkan terlebih dahulu untuk menggunakan kebijakan tersebut, dengan membolehkan kata kerja <code>use</code> terhadap kebijakan tersebut.</p><p>Kebanyakan Pod Kubernetes tidak dibuat secara langsung oleh pengguna. Sebagai gantinya, mereka biasanya dibuat secara tidak langsung sebagai bagian dari sebuah <a href=/id/docs/concepts/workloads/controllers/deployment/>Deployment</a>, <a href=/id/docs/concepts/workloads/controllers/replicaset/>ReplicaSet</a>, atau pengontrol yang sudah ditemplat lainnya melalui Controller Manager. Memberikan akses untuk pengontrol terhadap kebijakan tersebut akan mengizinkan akses untuk <em>semua</em> Pod yang dibuat oleh pengontrol tersebut, sehingga metode yang lebih baik untuk mengizinkan kebijakan adalah dengan memberikan akses pada Service Account milik Pod (lihat <a href=#run-another-pod>contohnya</a>).</p><h3 id=melalui-rbac>Melalui RBAC</h3><p><a href=/id/docs/reference/access-authn-authz/rbac/>RBAC</a> adalah mode otorisasi standar Kubernetes, dan dapat digunakan dengan mudah untuk mengotorisasi penggunaan kebijakan-kebijakan.</p><p>Pertama-tama, sebuah <code>Role</code> atau <code>ClusterRole</code> perlu memberikan akses pada kata kerja <code>use</code> terhadap kebijakan-kebijakan yang diinginkan. <code>rules</code> yang digunakan untuk memberikan akses tersebut terlihat seperti berikut:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>rbac.authorization.k8s.io/v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>ClusterRole<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>&lt;role name&gt;<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>rules</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span>- <span style=color:green;font-weight:700>apiGroups</span>:<span style=color:#bbb> </span>[<span style=color:#b44>&#39;policy&#39;</span>]<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>resources</span>:<span style=color:#bbb> </span>[<span style=color:#b44>&#39;podsecuritypolicies&#39;</span>]<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>verbs</span>:<span style=color:#bbb>     </span>[<span style=color:#b44>&#39;use&#39;</span>]<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>resourceNames</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- &lt;list of policies to authorize&gt;<span style=color:#bbb>
</span></span></span></code></pre></div><p>Kemudian, <code>Role</code> atau <code>ClusterRole</code> tersebut diikat ke pengguna-pengguna yang diberikan otoritas.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>rbac.authorization.k8s.io/v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>ClusterRoleBinding<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>&lt;binding name&gt;<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>roleRef</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>ClusterRole<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>&lt;role name&gt;<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>apiGroup</span>:<span style=color:#bbb> </span>rbac.authorization.k8s.io<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>subjects</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:#080;font-style:italic># Mengotorisasi ServiceAccount spesifik</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span>- <span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>ServiceAccount<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>&lt;authorized service account name&gt;<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>namespace</span>:<span style=color:#bbb> </span>&lt;authorized pod namespace&gt;<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:#080;font-style:italic># Mengotorisasi User spesifik (tidak direkomendasikan)</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span>- <span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>User<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>apiGroup</span>:<span style=color:#bbb> </span>rbac.authorization.k8s.io<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>&lt;authorized user name&gt;<span style=color:#bbb>
</span></span></span></code></pre></div><p>Jika sebuah <code>RoleBinding</code> (bukan <code>ClusterRoleBinding</code>) digunakan, maka ia hanya akan memberi akses penggunaan untuk Pod-Pod yang dijalankan pada Namespace yang sama dengan <code>RoleBinding</code> tersebut. Hal ini dapat dipasangkan dengan grup sistem untuk memberi akses pada semua Pod yang berjalan di Namespace tersebut:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#080;font-style:italic># Mengotorisasi semua ServiceAccount di dalam sebuah Namespace</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span>- <span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Group<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>apiGroup</span>:<span style=color:#bbb> </span>rbac.authorization.k8s.io<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>system:serviceaccounts<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:#080;font-style:italic># Atau secara ekuivalen, semua pengguna yang telah terotentikasi pada sebuah Namespace</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span>- <span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Group<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>apiGroup</span>:<span style=color:#bbb> </span>rbac.authorization.k8s.io<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>system:authenticated<span style=color:#bbb>
</span></span></span></code></pre></div><p>Untuk lebih banyak contoh pengikatan RBAC, lihat <a href=/id/docs/reference/access-authn-authz/rbac#role-binding-examples>Contoh Role Binding</a>.
Untuk contoh lengkap untuk mengotorisasi sebuah PodSecurityPolicy, lihat <a href=#contoh>di bawah</a>.</p><h3 id=mengatasi-masalah>Mengatasi Masalah</h3><ul><li><a href=/docs/admin/kube-controller-manager/>Controller Manager</a> harus dijalankan terhadap <a href=/docs/reference/access-authn-authz/controlling-access/>port API yang telah diamankan</a>, dan tidak boleh memiliki izin <em>superuser</em>, atau semua permintaan akan melewati modul-modul otentikasi dan otorisasi, semua objek PodSecurityPolicy tidak akan diizinkan, dan semua pengguna dapat membuat Container-container yang <em>privileged</em>. Untuk lebih detil tentang mengkonfigurasi otorisasi Controller Manager, lihat <a href=/id/docs/reference/access-authn-authz/rbac/#controller-roles>Controller Roles</a>.</li></ul><h2 id=urutan-kebijakan>Urutan Kebijakan</h2><p>Sebagai tambahan terhadap membatasi pembuatan dan pembaruan Pod, Pod Security Policy dapat digunakan juga untuk menyediakan nilai-nilai bawaan untuk banyak kolom yang dikontrol olehnya. Saat banyak kebijakan tersedia, pengatur Pod Security Policy memilih kebijakan-kebijakan berdasarkan kriteria berikut:</p><ol><li>PodSecurityPolicy yang mengizinkan Pod apa adanya, tanpa mengganti nilai-nilai bawaan atau memutasi Pod tersebut, akan lebih dipilih. Urutan PodSecurityPolicy yang tidak mengubah Pod ini tidak dipermasalahkan.</li><li>Jika Pod-nya harus diberi nilai bawaan atau dimutasi, maka PodSecurityPolicy pertama (diurutkan berdasarkan namanya) untuk mengizinkan Pod tersebut akan dipilih.</li></ol><div class="alert alert-info note callout" role=alert><strong>Catatan:</strong> Saat operasi pembaruan (saat ini mutasi terhadap spesifikasi Pod tidak diizinkan) hanya PodSecurityPolicy yang tidak mengubah Pod yang akan digunakan untuk melakukan validasi terhadap Pod tersebut.</div><h2 id=contoh>Contoh</h2><p><em>Contoh ini mengasumsikan kamu telah memiliki klaster yang berjalan dengan <em>admission controller</em> PodSecurityPolicy diaktifkan, dan kamu mempunyai akses admin.</em></p><h3 id=persiapan>Persiapan</h3><p>Mempersiapkan sebuah Namespace dan ServiceAccount untuk digunakan pada contoh ini. Kita akan menggunakan ServiceAccount ini untuk meniru sebuah pengguna bukan admin.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl create namespace psp-example
</span></span><span style=display:flex><span>kubectl create serviceaccount -n psp-example fake-user
</span></span><span style=display:flex><span>kubectl create rolebinding -n psp-example fake-editor --clusterrole<span style=color:#666>=</span>edit --serviceaccount<span style=color:#666>=</span>psp-example:fake-user
</span></span></code></pre></div><p>Untuk memperjelas kita bertindak sebagai pengguna yang mana dan mempersingkat ketikan, kita akan membuat 2 alias:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span><span style=color:#a2f>alias</span> kubectl-admin<span style=color:#666>=</span><span style=color:#b44>&#39;kubectl -n psp-example&#39;</span>
</span></span><span style=display:flex><span><span style=color:#a2f>alias</span> kubectl-user<span style=color:#666>=</span><span style=color:#b44>&#39;kubectl --as=system:serviceaccount:psp-example:fake-user -n psp-example&#39;</span>
</span></span></code></pre></div><h3 id=membuat-sebuah-kebijakan-dan-sebuah-pod>Membuat sebuah kebijakan dan sebuah Pod</h3><p>Beri definisi objek contoh PodSecurityPolicy dalam sebuah berkas. Ini adalah kebijakan yang mencegah pembuatan Pod-Pod yang <em>privileged</em>.</p><div class=highlight><div class=copy-code-icon style=text-align:right><a href=https://raw.githubusercontent.com/kubernetes/website/main/content/id/examples/policy/example-psp.yaml download=policy/example-psp.yaml><code>policy/example-psp.yaml</code></a>
<img src=/images/copycode.svg style=max-height:24px;cursor:pointer onclick='copyCode("policy-example-psp-yaml")' title="Copy policy/example-psp.yaml to clipboard"></img></div><div class=includecode id=policy-example-psp-yaml><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>policy/v1beta1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>PodSecurityPolicy<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>example<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>privileged</span>:<span style=color:#bbb> </span><span style=color:#a2f;font-weight:700>false</span><span style=color:#bbb>  </span><span style=color:#080;font-style:italic># Jangan izinkan Pod-Pod yang _privileged_!</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:#080;font-style:italic># Sisanya isi kolom-kolom yang dibutuhkan</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>seLinux</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>rule</span>:<span style=color:#bbb> </span>RunAsAny<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>supplementalGroups</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>rule</span>:<span style=color:#bbb> </span>RunAsAny<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>runAsUser</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>rule</span>:<span style=color:#bbb> </span>RunAsAny<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>fsGroup</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>rule</span>:<span style=color:#bbb> </span>RunAsAny<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>volumes</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:#b44>&#39;*&#39;</span><span style=color:#bbb>
</span></span></span></code></pre></div></div></div><p>Dan buatlah PodSecurityPolicy tersebut dengan <code>kubectl</code>:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl-admin create -f example-psp.yaml
</span></span></code></pre></div><p>Sekarang, sebagai pengguna bukan admin, cobalah membuat Pod sederhana:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl-user create -f- <span style=color:#b44>&lt;&lt;EOF
</span></span></span><span style=display:flex><span><span style=color:#b44>apiVersion: v1
</span></span></span><span style=display:flex><span><span style=color:#b44>kind: Pod
</span></span></span><span style=display:flex><span><span style=color:#b44>metadata:
</span></span></span><span style=display:flex><span><span style=color:#b44>  name:      pause
</span></span></span><span style=display:flex><span><span style=color:#b44>spec:
</span></span></span><span style=display:flex><span><span style=color:#b44>  containers:
</span></span></span><span style=display:flex><span><span style=color:#b44>    - name:  pause
</span></span></span><span style=display:flex><span><span style=color:#b44>      image: k8s.gcr.io/pause
</span></span></span><span style=display:flex><span><span style=color:#b44>EOF</span>
</span></span><span style=display:flex><span>Error from server <span style=color:#666>(</span>Forbidden<span style=color:#666>)</span>: error when creating <span style=color:#b44>&#34;STDIN&#34;</span>: pods <span style=color:#b44>&#34;pause&#34;</span> is forbidden: unable to validate against any pod security policy: <span style=color:#666>[]</span>
</span></span></code></pre></div><p><strong>Apa yang terjadi?</strong> Walaupun PodSecurityPolicy tersebut telah dibuat, ServiceAccount dari Pod tersebut maupun <code>fake-user</code> tidak memikiki izin untuk menggunakan kebijakan tersebut:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl-user auth can-i use podsecuritypolicy/example
</span></span><span style=display:flex><span>no
</span></span></code></pre></div><p>Membuat RoleBinding untuk memberikan <code>fake-user</code> akses terhadap kata kerja <code>use</code> pada kebijakan contoh kita:</p><div class="alert alert-info note callout" role=alert><strong>Catatan:</strong> Ini bukan cara yang direkomendasikan! Lihat <a href=#menjalankan-pod-lainnya>bagian selanjutnya</a> untuk cara yang lebih baik.</div><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl-admin create role psp:unprivileged <span style=color:#b62;font-weight:700>\
</span></span></span><span style=display:flex><span><span style=color:#b62;font-weight:700></span>    --verb<span style=color:#666>=</span>use <span style=color:#b62;font-weight:700>\
</span></span></span><span style=display:flex><span><span style=color:#b62;font-weight:700></span>    --resource<span style=color:#666>=</span>podsecuritypolicy <span style=color:#b62;font-weight:700>\
</span></span></span><span style=display:flex><span><span style=color:#b62;font-weight:700></span>    --resource-name<span style=color:#666>=</span>example
</span></span><span style=display:flex><span>role <span style=color:#b44>&#34;psp:unprivileged&#34;</span> created
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>kubectl-admin create rolebinding fake-user:psp:unprivileged <span style=color:#b62;font-weight:700>\
</span></span></span><span style=display:flex><span><span style=color:#b62;font-weight:700></span>    --role<span style=color:#666>=</span>psp:unprivileged <span style=color:#b62;font-weight:700>\
</span></span></span><span style=display:flex><span><span style=color:#b62;font-weight:700></span>    --serviceaccount<span style=color:#666>=</span>psp-example:fake-user
</span></span><span style=display:flex><span>rolebinding <span style=color:#b44>&#34;fake-user:psp:unprivileged&#34;</span> created
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>kubectl-user auth can-i use podsecuritypolicy/example
</span></span><span style=display:flex><span>yes
</span></span></code></pre></div><p>Sekarang, ulangi membuat Pod tersebut</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl-user create -f- <span style=color:#b44>&lt;&lt;EOF
</span></span></span><span style=display:flex><span><span style=color:#b44>apiVersion: v1
</span></span></span><span style=display:flex><span><span style=color:#b44>kind: Pod
</span></span></span><span style=display:flex><span><span style=color:#b44>metadata:
</span></span></span><span style=display:flex><span><span style=color:#b44>  name:      pause
</span></span></span><span style=display:flex><span><span style=color:#b44>spec:
</span></span></span><span style=display:flex><span><span style=color:#b44>  containers:
</span></span></span><span style=display:flex><span><span style=color:#b44>    - name:  pause
</span></span></span><span style=display:flex><span><span style=color:#b44>      image: k8s.gcr.io/pause
</span></span></span><span style=display:flex><span><span style=color:#b44>EOF</span>
</span></span><span style=display:flex><span>pod <span style=color:#b44>&#34;pause&#34;</span> created
</span></span></code></pre></div><p>Bekerja seperti yang diharapkan! Tapi percobaan apapun untuk membuat Pod yang <em>privileged</em> seharusnya masih ditolak:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl-user create -f- <span style=color:#b44>&lt;&lt;EOF
</span></span></span><span style=display:flex><span><span style=color:#b44>apiVersion: v1
</span></span></span><span style=display:flex><span><span style=color:#b44>kind: Pod
</span></span></span><span style=display:flex><span><span style=color:#b44>metadata:
</span></span></span><span style=display:flex><span><span style=color:#b44>  name:      privileged
</span></span></span><span style=display:flex><span><span style=color:#b44>spec:
</span></span></span><span style=display:flex><span><span style=color:#b44>  containers:
</span></span></span><span style=display:flex><span><span style=color:#b44>    - name:  pause
</span></span></span><span style=display:flex><span><span style=color:#b44>      image: k8s.gcr.io/pause
</span></span></span><span style=display:flex><span><span style=color:#b44>      securityContext:
</span></span></span><span style=display:flex><span><span style=color:#b44>        privileged: true
</span></span></span><span style=display:flex><span><span style=color:#b44>EOF</span>
</span></span><span style=display:flex><span>Error from server <span style=color:#666>(</span>Forbidden<span style=color:#666>)</span>: error when creating <span style=color:#b44>&#34;STDIN&#34;</span>: pods <span style=color:#b44>&#34;privileged&#34;</span> is forbidden: unable to validate against any pod security policy: <span style=color:#666>[</span>spec.containers<span style=color:#666>[</span>0<span style=color:#666>]</span>.securityContext.privileged: Invalid value: true: Privileged containers are not allowed<span style=color:#666>]</span>
</span></span></code></pre></div><p>Hapus Pod tersebut sebelum melanjutkan:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl-user delete pod pause
</span></span></code></pre></div><h3 id=menjalankan-pod-lainnya>Menjalankan Pod lainnya</h3><p>Mari coba lagi, dengan cara yang sedikit berbeda:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl-user run pause --image<span style=color:#666>=</span>k8s.gcr.io/pause
</span></span><span style=display:flex><span>deployment <span style=color:#b44>&#34;pause&#34;</span> created
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>kubectl-user get pods
</span></span><span style=display:flex><span>No resources found.
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>kubectl-user get events | head -n <span style=color:#666>2</span>
</span></span><span style=display:flex><span>LASTSEEN   FIRSTSEEN   COUNT     NAME              KIND         SUBOBJECT                TYPE      REASON                  SOURCE                                  MESSAGE
</span></span><span style=display:flex><span>1m         2m          <span style=color:#666>15</span>        pause-7774d79b5   ReplicaSet                            Warning   FailedCreate            replicaset-controller                   Error creating: pods <span style=color:#b44>&#34;pause-7774d79b5-&#34;</span> is forbidden: no providers available to validate pod request
</span></span></code></pre></div><p><strong>Apa yang terjadi?</strong> Kita telah mengikat Role <code>psp:unprivileged</code> untuk <code>fake-user</code> kita, kenapa kita mendapatkan kesalahan <code>Error creating: pods "pause-7774d79b5-" is forbidden: no providers available to validate pod request</code>? Jawabannya berada pada sumbernya - <code>replicaset-controller</code>. Fake-user berhasil membuat Deployment tersebut (yang berhasil membuat sebuah ReplicaSet), tetapi saat ReplicaSet tersebut akan membuat Pod, ia tidak terotorisasi untuk menggunakan PodSecurityPolicy contoh tersebut.</p><p>Untuk memperbaikinya, ikatlah Role <code>psp:unprivileged</code> pada ServiceAccount Pod tersebut. Pada kasus ini (karena kita tidak menspesifikasikannya) ServiceAccount-nya adalah <code>default</code>:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl-admin create rolebinding default:psp:unprivileged <span style=color:#b62;font-weight:700>\
</span></span></span><span style=display:flex><span><span style=color:#b62;font-weight:700></span>    --role<span style=color:#666>=</span>psp:unprivileged <span style=color:#b62;font-weight:700>\
</span></span></span><span style=display:flex><span><span style=color:#b62;font-weight:700></span>    --serviceaccount<span style=color:#666>=</span>psp-example:default
</span></span><span style=display:flex><span>rolebinding <span style=color:#b44>&#34;default:psp:unprivileged&#34;</span> created
</span></span></code></pre></div><p>Sekarang, jika kamu memberi waktu ReplicaSet-nya untuk mencoba kembali, pengatur ReplicaSet tersebut seharusnya akan berhasil membuat Pod tersebut.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl-user get pods --watch
</span></span><span style=display:flex><span>NAME                    READY     STATUS    RESTARTS   AGE
</span></span><span style=display:flex><span>pause-7774d79b5-qrgcb   0/1       Pending   <span style=color:#666>0</span>         1s
</span></span><span style=display:flex><span>pause-7774d79b5-qrgcb   0/1       Pending   <span style=color:#666>0</span>         1s
</span></span><span style=display:flex><span>pause-7774d79b5-qrgcb   0/1       ContainerCreating   <span style=color:#666>0</span>         1s
</span></span><span style=display:flex><span>pause-7774d79b5-qrgcb   1/1       Running   <span style=color:#666>0</span>         2s
</span></span></code></pre></div><h3 id=membersihkan>Membersihkan</h3><p>Hapus Namespace tersebut untuk membersihkan sebagian besar sumber daya yang digunakan dalam contoh ini:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl-admin delete ns psp-example
</span></span><span style=display:flex><span>namespace <span style=color:#b44>&#34;psp-example&#34;</span> deleted
</span></span></code></pre></div><p>Perlu diperhatikan bahwa sumber daya <code>PodSecurityPolicy</code> tidak diberi Namespace, dan harus dibersihkan secara terpisah:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl-admin delete psp example
</span></span><span style=display:flex><span>podsecuritypolicy <span style=color:#b44>&#34;example&#34;</span> deleted
</span></span></code></pre></div><h3 id=contoh-contoh-kebijakan>Contoh-contoh Kebijakan</h3><p>Berikut adalah kebijakan dengan batasan paling sedikit yang dapat kamu buat, ekuivalen dengan tidak menggunakan <em>admission controller</em> Pod Security Policy:</p><div class=highlight><div class=copy-code-icon style=text-align:right><a href=https://raw.githubusercontent.com/kubernetes/website/main/content/id/examples/policy/privileged-psp.yaml download=policy/privileged-psp.yaml><code>policy/privileged-psp.yaml</code></a>
<img src=/images/copycode.svg style=max-height:24px;cursor:pointer onclick='copyCode("policy-privileged-psp-yaml")' title="Copy policy/privileged-psp.yaml to clipboard"></img></div><div class=includecode id=policy-privileged-psp-yaml><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>policy/v1beta1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>PodSecurityPolicy<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>privileged<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>annotations</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>seccomp.security.alpha.kubernetes.io/allowedProfileNames</span>:<span style=color:#bbb> </span><span style=color:#b44>&#39;*&#39;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>privileged</span>:<span style=color:#bbb> </span><span style=color:#a2f;font-weight:700>true</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>allowPrivilegeEscalation</span>:<span style=color:#bbb> </span><span style=color:#a2f;font-weight:700>true</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>allowedCapabilities</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:#b44>&#39;*&#39;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>volumes</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:#b44>&#39;*&#39;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>hostNetwork</span>:<span style=color:#bbb> </span><span style=color:#a2f;font-weight:700>true</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>hostPorts</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>min</span>:<span style=color:#bbb> </span><span style=color:#666>0</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>max</span>:<span style=color:#bbb> </span><span style=color:#666>65535</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>hostIPC</span>:<span style=color:#bbb> </span><span style=color:#a2f;font-weight:700>true</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>hostPID</span>:<span style=color:#bbb> </span><span style=color:#a2f;font-weight:700>true</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>runAsUser</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>rule</span>:<span style=color:#bbb> </span><span style=color:#b44>&#39;RunAsAny&#39;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>seLinux</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>rule</span>:<span style=color:#bbb> </span><span style=color:#b44>&#39;RunAsAny&#39;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>supplementalGroups</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>rule</span>:<span style=color:#bbb> </span><span style=color:#b44>&#39;RunAsAny&#39;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>fsGroup</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>rule</span>:<span style=color:#bbb> </span><span style=color:#b44>&#39;RunAsAny&#39;</span><span style=color:#bbb>
</span></span></span></code></pre></div></div></div><p>Berikut adalah sebuah contoh kebijakan yang restriktif yang mengharuskan pengguna-pengguna untuk berjalan sebagai pengguna yang <em>unprivileged</em>, memblokir kemungkinan eskalasi menjadi <em>root</em>, dan mengharuskan penggunaan beberapa mekanisme keamanan.</p><div class=highlight><div class=copy-code-icon style=text-align:right><a href=https://raw.githubusercontent.com/kubernetes/website/main/content/id/examples/policy/restricted-psp.yaml download=policy/restricted-psp.yaml><code>policy/restricted-psp.yaml</code></a>
<img src=/images/copycode.svg style=max-height:24px;cursor:pointer onclick='copyCode("policy-restricted-psp-yaml")' title="Copy policy/restricted-psp.yaml to clipboard"></img></div><div class=includecode id=policy-restricted-psp-yaml><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>policy/v1beta1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>PodSecurityPolicy<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>restricted<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>annotations</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>seccomp.security.alpha.kubernetes.io/allowedProfileNames</span>:<span style=color:#bbb> </span><span style=color:#b44>&#39;docker/default,runtime/default&#39;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>apparmor.security.beta.kubernetes.io/allowedProfileNames</span>:<span style=color:#bbb> </span><span style=color:#b44>&#39;runtime/default&#39;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>seccomp.security.alpha.kubernetes.io/defaultProfileName</span>:<span style=color:#bbb>  </span><span style=color:#b44>&#39;runtime/default&#39;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>apparmor.security.beta.kubernetes.io/defaultProfileName</span>:<span style=color:#bbb>  </span><span style=color:#b44>&#39;runtime/default&#39;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>privileged</span>:<span style=color:#bbb> </span><span style=color:#a2f;font-weight:700>false</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:#080;font-style:italic># Dibutuhkan untuk menghindari eskalasi ke _root_.</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>allowPrivilegeEscalation</span>:<span style=color:#bbb> </span><span style=color:#a2f;font-weight:700>false</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:#080;font-style:italic># Hal ini berlebihan dengan _non-root_ + melarang eskalasi _privilege_,</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:#080;font-style:italic># tetapi kita dapat menyediakannya untuk _defense in depth_</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>requiredDropCapabilities</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- ALL<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:#080;font-style:italic># Izinkan tipe-tipe volume inti.</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>volumes</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:#b44>&#39;configMap&#39;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:#b44>&#39;emptyDir&#39;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:#b44>&#39;projected&#39;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:#b44>&#39;secret&#39;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:#b44>&#39;downwardAPI&#39;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:#080;font-style:italic># Berasumsi bahwa persistentVolumes yang disetel oleh admin klaster aman untuk digunakan.</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:#b44>&#39;persistentVolumeClaim&#39;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>hostNetwork</span>:<span style=color:#bbb> </span><span style=color:#a2f;font-weight:700>false</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>hostIPC</span>:<span style=color:#bbb> </span><span style=color:#a2f;font-weight:700>false</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>hostPID</span>:<span style=color:#bbb> </span><span style=color:#a2f;font-weight:700>false</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>runAsUser</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:#080;font-style:italic># Mengharuskan container untuk berjalan tanpa hak sebagai _root_.</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>rule</span>:<span style=color:#bbb> </span><span style=color:#b44>&#39;MustRunAsNonRoot&#39;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>seLinux</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:#080;font-style:italic># Kebijakan ini mengasumsikan bahwa node-node menggunakan AppArmor daripada SELinux.</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>rule</span>:<span style=color:#bbb> </span><span style=color:#b44>&#39;RunAsAny&#39;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>supplementalGroups</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>rule</span>:<span style=color:#bbb> </span><span style=color:#b44>&#39;MustRunAs&#39;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>ranges</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:#080;font-style:italic># Larang menambahkan grup _root_.</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- <span style=color:green;font-weight:700>min</span>:<span style=color:#bbb> </span><span style=color:#666>1</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>max</span>:<span style=color:#bbb> </span><span style=color:#666>65535</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>fsGroup</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>rule</span>:<span style=color:#bbb> </span><span style=color:#b44>&#39;MustRunAs&#39;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>ranges</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:#080;font-style:italic># Larang menambahkan grup _root_.</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- <span style=color:green;font-weight:700>min</span>:<span style=color:#bbb> </span><span style=color:#666>1</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>max</span>:<span style=color:#bbb> </span><span style=color:#666>65535</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>readOnlyRootFilesystem</span>:<span style=color:#bbb> </span><span style=color:#a2f;font-weight:700>false</span><span style=color:#bbb>
</span></span></span></code></pre></div></div></div><h2 id=referensi-kebijakan>Referensi Kebijakan</h2><h3 id=privileged>Privileged</h3><p><strong>Privileged</strong> - menentukan bila Container manapun di dalam sebuah Pod dapat mengaktifkan mode <em>privileged</em>. Secara bawaan, sebuah Container tidak diizinkan untuk mengakses perangkat apapun pada <em>host</em>-nya, tapi sebuah Container yang "<em>privileged</em>" akan diberikan akses untuk semua perangkat pada <em>host</em>-nya. Hal ini mengizinkan hampir semua akses yang sama dengan proses yang berjalan pada <em>host</em> kepada Container tersebut. Hal ini berfungsi untuk Container-container yang ingin menggunakan kemampuan Linux seperti memanipulasi <em>network stack</em> atau mengakses perangkat-perangkat.
determines if any container in a pod can enable privileged mode.</p><h3 id=namespace-host>Namespace Host</h3><p><strong>HostPID</strong> - Mengatur jika Container-container pada Pod dapat berbagi <em>namespace process ID</em> pada <em>host</em>. Catatlah bahwa saat dipasangkan dengan ptrace, hal ini dapat digunakan untuk eskalasi <em>privilege</em> di luar kontainer (ptrace secara bawaan tidak diizinkan).</p><p><strong>HostIPC</strong> - Mengatur jika container-container pada Pod dapat berbagi <em>namespace IPC</em> pada <em>host</em>.</p><p><strong>HostNetwork</strong> - Mengatur jika Pod dapat menggunakan <em>namespace</em> jaringan pada <em>host</em>. Melakukan hal ini akan memberikan Pod akses pada perangkat <em>loopback</em>, <em>service</em> yang sedang <em>listening</em> pada <em>localhost</em>, dan dapat digunakan untuk mengintai aktivitas jaringan pada Pod-Pod lain pada Node yang sama.</p><p><strong>HostPorts</strong> - Memberikan daftar putih dari berbagai <em>port</em> yang diizinkan pada <em>namespace</em> jaringan pada <em>host</em>. Hal ini didefinisikan sebagai sebuah daftar <code>HostPortRange</code>, dengan <code>min</code>(inklusif) dan <code>max</code>(inklusif). Nilai bawaannya adalah tidak ada <em>host port</em> yang diizinkan.</p><p><strong>AllowedHostPaths</strong> - Lihat <a href=#volumes-dan-file-systems>Volume dan <em>file systems</em></a>.</p><h3 id=volume-dan-file-system>Volume dan <em>file system</em></h3><p><strong>Volume</strong> - Menyediakan sebuah daftar putih dari tipe-tipe Volume yang diizinkan. Nilai-nilai yang diizinkan sesuai dengan sumber Volume yang didefinisikan saat membuat sebuah Volume. Untuk daftar lengkap tipe-tipe Volume, lihat <a href=/id/docs/concepts/storage/volumes/#tipe-tipe-volume>tipe-tipe Volume</a>. Sebagai tambahan, <code>*</code> dapat digunakan untuk mengizinkan semua tipe Volume.</p><p><strong>Kumpulan Volume-volume minimal yang direkomendasikan</strong> untuk PodSecurityPolicy baru adalah sebagai berikut:</p><ul><li>configMap</li><li>downwardAPI</li><li>emptyDir</li><li>persistentVolumeClaim</li><li>secret</li><li>projected</li></ul><div class="alert alert-danger warning callout" role=alert><strong>Peringatan:</strong> PodSecurityPolicy tidak membatasi tipe-tipe objek <code>PersistentVolume</code> yang dapat direferensikan oleh <code>PersistentVolumeClaim</code>. Hanya pengguna-pengguna yang dipercaya yang boleh diberikan izin untuk membuat objek-objek <code>PersistentVolume</code>.</div><p><strong>FSGroup</strong> - Mengatur grup tambahan yang dipasang ke beberapa volume.</p><ul><li><em>MustRunAs</em> - Membutuhkan setidaknya satu <code>range</code> untuk dapat ditentukan. Menggunakan semua nilai minimum dari <code>range</code> yang pertama sebagai nilai bawaannya. Memvalidasikan terhadap semua <code>range</code>.</li><li><em>MayRunAs</em> - Membutuhkan setidaknya satu <code>range</code> untuk dapat ditentukan. Mengizinkan <code>FSGroups</code> dibiarkan kosong tanpa memberikan nilai bawaan. Memvalidasikan terhadap semua <code>range</code> jika nilai <code>FSGroups</code> disetel.</li><li><em>RunAsAny</em> - Tidak ada nilai bawaan yang diberikan. Mengizinkan ID <code>fsGroup</code> apapun untuk digunakan.</li></ul><p><strong>AllowedHostPaths</strong> - Memperinci sebuah daftar putih dari <em>host path</em> yang diizinkan untuk digunakan oleh volume-volume <code>hostPath</code>. Sebuah daftar kosong berarti tidak ada pembatasan pada <em>host path</em> yang digunakan. Hal ini didefinisikan sebagai sebuah daftar objek-objek dengan sebuah kolom <code>pathPrefix</code>, yang mengizinkan volume-volume <code>hostPath</code> untuk menambatkan sebuah <em>path</em> yang dimulai dengan sebuah prefiks yang diizinkan, dan sebuah kolom <code>readOnly</code> yang menunjukkan bahwa ia harus ditambatkan sebagai <em>read-only</em>.
Misalnya:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>allowedHostPaths</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:#080;font-style:italic># Hal ini mengizinkan &#34;/foo&#34;, &#34;/foo/&#34;, &#34;/foo/bar&#34; dll., tetapi</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:#080;font-style:italic># melarang &#34;/fool&#34;, &#34;/etc/foo&#34; dll.</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:#080;font-style:italic># &#34;/foo/../&#34; tidak sah.</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>pathPrefix</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;/foo&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>readOnly</span>:<span style=color:#bbb> </span><span style=color:#a2f;font-weight:700>true</span><span style=color:#bbb> </span><span style=color:#080;font-style:italic># Izinkan hanya tambatan _read-only_</span><span style=color:#bbb>
</span></span></span></code></pre></div><div class="alert alert-danger warning callout" role=alert><strong>Peringatan:</strong><p>Ada banyak cara bagi sebuah Container dengan akses yang tidak dibatasi terhadap <em>host filesystem</em>-nya untuk dapat melakukan eskalasi <em>privilege</em>, termasuk membaca data dari Container-container lain, dan menyalahgunakan kredensial dari <em>service-service</em> sistem, misalnya Kubelet.</p><p>Direktori volume <code>hostPath</code> yang dapat ditulis mengizinkan container-container untuk menulis ke <em>filesystem</em> melalui cara-cara yang membiarkan mereka melintasi <em>host filesystem</em> di luar <code>pathPrefix</code> yang bersangkutan.
<code>readOnly: true</code>, tersedia pada Kubernetes 1.11 ke atas, harus digunakan pada <strong>semua</strong> <code>allowedHostPaths</code> untuk secara efektif membatasi akses terhadap <code>pathPrefix</code> yang diperinci.</p></div><p><strong>ReadOnlyRootFilesystem</strong> - Mengharuskan container-container berjalan dengan sebuah <em>root filesystem</em> yang bersifat <em>read-only</em> (yaitu, tanpa lapisan yang dapat ditulis)</p><h3 id=driver-driver-flexvolume><em>Driver-driver</em> Flexvolume</h3><p>Hal ini memperinci sebuah daftar putih dari <em>driver-driver</em> Flexvolume yang diizinkan untuk digunakan oleh Flexvolume. Sebuah daftar kosong atau <code>nil</code> berarti tidak ada batasan terhadap <em>driver-driver</em> tersebut.
Pastikan kolom <a href=#volume-dan-file-system><code>volumes</code></a> berisi tipe volumenya; Jika tidak, tidak ada <em>driver</em> Flexvolume yang diizinkan.</p><p>Misalnya:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>policy/v1beta1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>PodSecurityPolicy<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>allow-flex-volumes<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:#080;font-style:italic># ... kolom kolom lainnya</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>volumes</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- flexVolume<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>allowedFlexVolumes</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:green;font-weight:700>driver</span>:<span style=color:#bbb> </span>example/lvm<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:green;font-weight:700>driver</span>:<span style=color:#bbb> </span>example/cifs<span style=color:#bbb>
</span></span></span></code></pre></div><h3 id=pengguna-dan-grup>Pengguna dan Grup</h3><p><strong>RunAsUser</strong> - Mengatur ID pengguna mana yang digunakan untuk menjalankan container-container.</p><ul><li><em>MustRunAs</em> - Membutuhkan setidaknya satu <code>range</code> untuk dapat ditentukan. Menggunakan semua nilai minimum dari <code>range</code> yang pertama sebagai nilai bawaannya. Memvalidasikan terhadap semua <code>range</code>.</li><li><em>MustRunAsNonRoot</em> - Mengharuskan Pod diajukan dengan nilai <code>runAsUser</code> yang bukan nol, atau memiliki petunjuk <code>USER</code> didefinisikan (dengan UID numerik) di dalam <em>image</em>. Pod-Pod yang belum memperinci <code>runAsNonRoot</code> atau <code>runAsUser</code> akan dimutasikan untuk menyetel <code>runAsNonRoot=true</code> sehingga membutuhkan petunjuk <code>USER</code> dengan nilai numerik bukan nol di dalam Container. Tidak ada nilai bawaan yang diberikan. Menyetel <code>allowPrivilegeEscalation=false</code> sangat disarankan dengan strategi ini.</li><li><em>RunAsAny</em> - Tidak ada nilai bawaan yang diberikan. Mengizinkan <code>runAsUser</code> apapun untuk digunakan.</li></ul><p><strong>RunAsGroup</strong> - Mengatur ID grup primer mana yang digunakan untuk menjalankan Container-container.</p><ul><li><em>MustRunAs</em> - Membutuhkan setidaknya satu <code>range</code> untuk dapat ditentukan. Menggunakan semua nilai minimum dari <code>range</code> yang pertama sebagai nilai bawaannya. Memvalidasikan terhadap semua <code>range</code>.</li><li><em>MayRunAs</em> - Tidak memerlukan <code>RunAsGroup</code> untuk diperinci. Tetapi, saat <code>RunAsGroup</code> diperinci, mereka harus berada pada <code>range</code> yang didefinisikan.</li><li><em>RunAsAny</em> - Tidak ada nilai bawaan yang diberikan. Mengizinkan <code>runAsGroup</code> apapun untuk digunakan.</li></ul><p><strong>SupplementalGroups</strong> - Mengatur ID grup mana saja yang ditambah ke Container-container.</p><ul><li><em>MustRunAs</em> - Membutuhkan setidaknya satu <code>range</code> untuk dapat ditentukan. Menggunakan semua nilai minimum dari <code>range</code> yang pertama sebagai nilai bawaannya. Memvalidasikan terhadap semua <code>range</code>.</li><li><em>MayRunAs</em> - Membutuhkan setidaknya satu <code>range</code> untuk dapat ditentukan. Mengizinkan <code>supplementalGroups</code> dibiarkan kosong tanpa memberikan nilai bawaan. Memvalidasikan terhadap semua <code>range</code> jika nilai <code>supplementalGroup</code> disetel.</li><li><em>RunAsAny</em> - Tidak ada nilai bawaan yang diberikan. Mengizinkan ID <code>supplementalGroups</code> apapun untuk digunakan.</li></ul><h3 id=eskalasi-privilege>Eskalasi <em>Privilege</em></h3><p>Opsi ini mengatur opsi Container <code>allowPrivilegeEscalation</code>. Nilai <code>bool</code> ini secara langsung mengatur apakah <em>flag</em> <a href=https://www.kernel.org/doc/Documentation/prctl/no_new_privs.txt><code>no_new_privs</code></a> disetel pada proses Container tersebut. <em>Flag</em> ini akan mencegah program <code>setuid</code> mengganti ID pengguna efektif, dan mencegah berkas-berkas untuk memungkinkan kemampuan tambahan (misalnya, ini akan mencagah penggunaan peralatan <code>ping</code>). Perilaku ini dibutuhkan untuk memaksakan <code>MustRunAsNonRoot</code>.</p><p><strong>AllowPrivilegeEscalation</strong> - Membatasi apakah seorang pengguna diizinkan untuk menyetel konteks keamanan dari sebuah Container menjadi <code>allowPrivilegeEscalation=true</code>. Hal ini memiliki nilai bawaan untuk diizinkan, agar tidak merusak program <code>setuid</code>. Menyetel ini menjadi <code>false</code> memastikan bahwa tidak ada proses <em>child</em> dari sebuah Container dapat memperoleh lebih banyak <em>privilege</em> dari <em>parent</em>-nya.</p><p><strong>DefaultAllowPrivilegeEscalation</strong> - Menyetel nilai bawaan untuk opsi <code>allowPrivilegeEscalation</code>. Perilaku bawaan tanpa hal ini adalah untuk mengizinkan eskalasi <em>privilege</em> agar tidak merusak program <code>setuid</code>. Jika perilaku ini tidak diinginkan, kolom ini dapat digunakan untuk menyetel nilai bawaan <code>allowPrivilegeEscalation</code> agar melarang eskalasi, sementara masih mengizinkan Pod-Pod untuk meminta <code>allowPrivilegeEscalation</code> secara eksplisit.</p><h3 id=kemampuan-kemampuan>Kemampuan-kemampuan</h3><p>Kemampuan-kemampuan Linux menyediakan perincian yang detail dari <em>privilege-privilege</em> yang biasa dikaitkan dengan <code>superuser</code>. Beberapa dari kemampuan-kemampuan ini dapat digunakan untuk mengeskalasi <em>privilege-privilege</em> atau untuk <em>container breakout</em>, dan dapat dibatasi oleh PodSecurityPolicy. Untuk lebih lanjut tentang kemampuan-kemampuan Linux, lihat <a href=http://man7.org/linux/man-pages/man7/capabilities.7.html>capabilities(7)</a>.</p><p>Kolom-kolom berikut mengambil daftar kemampuan-kemampuan, diperincikan sebagai nama kemampuannya dalam ALL_CAPS tanpa awalan <code>CAP_</code>.</p><p><strong>AllowedCapabilities</strong> - Menyediakan sebuah daftar putih dari kemampuan-kemampuan yang dapat ditambahkan pada sebuah Container. Kumpulan kemampuan bawaan secara implisit diizinkan. Kumpulan kosong berarti tidak ada kemampuan tambahan yang dapat ditambahkan selain bawaannya. <code>*</code> dapat digunakan untuk mengizinkan semua kemampuan.</p><p><strong>RequiredDropCapabilities</strong> - Kemampuan-kemampuan yang harus dihapus dari Container-container. Kemampuan-kemampuan ini dihapus dari kumpulan bawaan, dan tidak boleh ditambahkan. Kemampuan-kemampuan yang terdaftar di <code>RequiredDropCapabilities</code> tidak boleh termasuk di dalam <code>AllowedCapabilities</code> atau <code>DefaultAddCapabilities</code>.</p><p><strong>DefaultAddCapabilities</strong> - Kemampuan-kemampuan yang ditambahkan pada Container-container secara bawaan, sebagai tambahan untuk bawaan <em>runtime</em>. Lihat <a href=https://docs.docker.com/engine/reference/run/#runtime-privilege-and-linux-capabilities>dokumentasi Docker</a> untuk daftar kemampuan bawaan saat menggunakan <em>runtime</em> Docker.</p><h3 id=selinux>SELinux</h3><ul><li><em>MustRunAs</em> - Mengharuskan penyetelan <code>seLinuxOptions</code>. Menggunakan <code>seLinuxOptions</code> sebagai nilai bawaannya. Memvalidasi terhadap <code>seLinuxOptions</code>.</li><li><em>RunAsAny</em> - Tidak ada nilai bawaan yang disediakan. Mengizinkan nilai <code>seLinuxOptions</code> apapun untuk diberikan.</li></ul><h3 id=allowedprocmounttypes>AllowedProcMountTypes</h3><p><code>allowedProcMountTypes</code> adalah sebuah daftar putih dari ProcMountType yang diizinkan. Nilai kosong atau <code>nil</code> menunjukkan bahwa hanya <code>DefaultProcMountType</code> yang boleh digunakan.</p><p><code>DefaultProcMount</code> menggunakan nilai bawaan <em>container runtime</em> untuk <em>readonly</em> dan <em>masked paths</em> untuk <code>/proc</code>. Kebanyakan <em>runtime</em> Container melakukan <em>mask</em> terhadap beberapa <em>path</em> di dalam <code>/proc</code> untuk menghindari <em>security exposure</em> dari perangkat-perangkat atau informasi khusus yang tidak disengaja. Hal ini ditandai dengan nilai <em>string</em> <code>Default</code>.</p><p>Satu-satunya ProcMountType lainnya adalah <code>UnmaskedProcMount</code>, yang melangkahi perilaku <em>masking</em> bawaan dari <em>runtime</em> Container dan memastikan bahwa <code>/proc</code> yang baru dibuat tetap utuh tanpa perubahan. Hal ini ditandai dengan nilai <em>string</em> <code>Unmasked</code>.</p><h3 id=apparmor>AppArmor</h3><p>Diatur melalui anotasi pada PodSecurityPolicy. Lihat <a href=/docs/tutorials/clusters/apparmor/#podsecuritypolicy-annotations>dokumentasi AppArmor</a>.</p><h3 id=seccomp>Seccomp</h3><p>Penggunaan profil-profil <em>seccomp</em> di dalam Pod-Pod dapat diatur melalui anotasi pada PodSecurityPolicy.
<em>Seccomp</em> adalah fitur <em>Alpha</em> di Kubernetes.</p><p><strong>seccomp.security.alpha.kubernetes.io/defaultProfileName</strong> - Anotasi yang menunjukkan profil <em>seccomp</em> bawaan untuk diterapkan kepada container-container. Nilai-nilai yang mungkin adalah:</p><ul><li><code>unconfined</code> - <em>Seccomp</em> tidak diterapkan pada proses-proses di container (ini adalah bawaan di Kubernetes), jika tidak ada alternatif yang diberikan.</li><li><code>runtime/default</code> - Profil <em>runtime</em> container bawaan digunakan.</li><li><code>docker/default</code> - Profil bawaan <em>seccomp</em> Docker digunakan. Sudah kedaluwarsa sejak Kubernetes 1.11. Gunakan <code>runtime/default</code> sebagai gantinya.</li><li><code>localhost/&lt;path></code> - Menentukan sebuah profil sebagai sebuah berkas pada Node yang berlokasi pada <code>&lt;seccomp_root>/&lt;path></code>, di mana <code>&lt;seccomp_root></code> didefinisikan melalui <em>flag</em> <code>--seccomp-profile-root</code> pada Kubelet.</li></ul><p><strong>seccomp.security.alpha.kubernetes.io/allowedProfileNames</strong> - Anotasi yang menunjukkan nilai-nilai mana yang diizinkan untuk anotasi <em>seccomp</em> pada Pod. Ditentukan sebagai sebuah daftar nilai yang diizinkan yang dibatasi dengan tanda koma. Nilai-nilai yang dimungkinkan adalah yang terdaftar di atas, ditambah dengan <code>*</code> untuk mengizinkan semua profil. Ketiadaan anotasi ini berarti nilai bawaannya tidak dapat diubah.</p><h3 id=sysctl>Sysctl</h3><p>Secara bawaan, semua <em>sysctl</em> yang aman diizinkan.</p><ul><li><code>forbiddenSysctls</code> - mengecualikan <em>sysctl-sysctl</em> tertentu. Kamu dapat melarang kombinasi dari <em>sysctl-sysctl</em> yang aman maupun tidak aman pada daftar ini. Untuk melarang menyetel <em>sysctl</em> apapun, gunakan nilai <code>*</code>.</li><li><code>allowedUnsafeSysctls</code> - mengizinkan <em>sysctl-sysctl</em> tertentu yang telah dilarang oleh daftar bawaan, selama nilainya tidak terdaftar di dalam <code>forbiddenSysctls</code>.</li></ul><p>Lihat <a href=/docs/concepts/cluster-administration/sysctl-cluster/#podsecuritypolicy>dokumentasi Sysctl</a>.</p></div><div class=td-content style=page-break-before:always><h1 id=pg-285a3785fd3d20f437c28d87ca4dadca>11 - Administrasi Klaster</h1></div><div class=td-content><h1 id=pg-fb494ea3b1874bd753dcd11c3f35c2dc>11.1 - Ikhtisar Administrasi Klaster</h1><p>Ikhtisar administrasi klaster ini ditujukan untuk siapapun yang akan membuat atau mengelola klaster Kubernetes.
Diharapkan untuk memahami beberapa <a href=/docs/concepts/>konsep</a> dasar Kubernetes sebelumnya.</p><h2 id=perencanaan-klaster>Perencanaan Klaster</h2><p>Lihat panduan di <a href=/docs/setup>Persiapan</a> untuk mempelajari beberapa contoh tentang bagaimana merencanakan, mengatur dan mengonfigurasi klaster Kubernetes. Solusi yang akan dipaparkan di bawah ini disebut <em>distro</em>.</p><p>Sebelum memilih panduan, berikut adalah beberapa hal yang perlu dipertimbangkan:</p><ul><li>Apakah kamu hanya ingin mencoba Kubernetes pada komputermu, atau kamu ingin membuat sebuah klaster dengan <em>high-availability</em>, <em>multi-node</em>? Pilihlah distro yang paling sesuai dengan kebutuhanmu.</li><li><strong>Jika kamu merencanakan klaster dengan <em>high-availability</em></strong>, pelajari bagaimana cara mengonfigurasi <a href=/id/docs/concepts/cluster-administration/federation/>klaster pada <em>multiple zone</em></a>.</li><li>Apakah kamu akan menggunakan <strong>Kubernetes klaster di <em>hosting</em></strong>, seperti <a href=https://cloud.google.com/kubernetes-engine/>Google Kubernetes Engine</a>, atau <strong><em>hosting</em> sendiri klastermu</strong>?</li><li>Apakah klastermu berada pada <strong><em>on-premises</em></strong>, atau <strong>di cloud (IaaS)</strong>? Kubernetes belum mendukung secara langsung klaster hibrid. Sebagai gantinya, kamu dapat membuat beberapa klaster.</li><li><strong>Jika kamu ingin mengonfigurasi Kubernetes <em>on-premises</em></strong>, pertimbangkan <a href=/id/docs/concepts/cluster-administration/networking/>model jaringan</a> yang paling sesuai.</li><li>Apakah kamu ingin menjalankan Kubernetes pada <strong>"bare metal" <em>hardware</em></strong> atau pada <strong><em>virtual machines</em> (VM)</strong>?</li><li>Apakah kamu <strong>hanya ingin mencoba klaster Kubernetes</strong>, atau kamu ingin ikut aktif melakukan <strong>pengembangan kode dari proyek Kubernetes</strong>? Jika jawabannya yang terakhir, pilihlah distro yang aktif dikembangkan. Beberapa distro hanya menggunakan rilis <em>binary</em>, namun menawarkan lebih banyak variasi pilihan.</li><li>Pastikan kamu paham dan terbiasa dengan beberapa <a href=/docs/admin/cluster-components/>komponen</a> yang dibutuhkan untuk menjalankan sebuah klaster.</li></ul><p>Catatan: Tidak semua distro aktif dikelola. Pilihlah distro yang telah diuji dengan versi terkini dari Kubernetes.</p><h2 id=mengelola-klaster>Mengelola Klaster</h2><ul><li><p><a href=/docs/tasks/administer-cluster/cluster-management/>Mengelola klaster</a> akan menjabarkan beberapa topik terkait <em>lifecycle</em> dari klaster: membuat klaster baru, melakukan <em>upgrade</em> pada <em>node master</em> dan <em>worker</em>, melakukan pemeliharaan <em>node</em> (contoh: <em>upgrade</em> kernel), dan melakukan <em>upgrade</em> versi Kubernetes API pada klaster yang sedang berjalan.</p></li><li><p>Pelajari bagaimana cara <a href=/docs/concepts/nodes/node/>mengatur <em>node</em></a>.</p></li><li><p>Pelajari bagaimana cara membuat dan mengatur kuota resource <a href=/id/docs/concepts/policy/resource-quotas/>(<em>resource quota</em>)</a> untuk <em>shared</em> klaster.</p></li></ul><h2 id=mengamankan-klaster>Mengamankan Klaster</h2><ul><li><p><a href=/id/docs/concepts/cluster-administration/certificates/>Sertifikat (<em>certificate</em>)</a> akan menjabarkan langkah-langkah untuk membuat sertifikat menggunakan beberapa <em>tool chains</em>.</p></li><li><p><a href=/id/docs/concepts/containers/container-environment-variables/>Kubernetes <em>Container Environment</em></a> akan menjelaskan <em>environment</em> untuk kontainer yang dikelola oleh Kubelet pada Kubernetes <em>node</em>.</p></li><li><p><a href=/docs/reference/access-authn-authz/controlling-access/>Mengontrol Akses ke Kubernetes API</a> akan menjabarkan bagaimana cara mengatur izin (<em>permission</em>) untuk akun pengguna dan <em>service account</em>.</p></li><li><p><a href=/docs/reference/access-authn-authz/authentication/>Autentikasi</a> akan menjelaskan autentikasi di Kubernetes, termasuk ragam pilihan autentikasi.</p></li><li><p><a href=/docs/reference/access-authn-authz/authorization/>Otorisasi</a> dibedakan dari autentikasi, digunakan untuk mengontrol bagaimana <em>HTTP call</em> ditangani.</p></li><li><p><a href=/docs/reference/access-authn-authz/admission-controllers/>Menggunakan <em>Admission Controllers</em></a> akan menjelaskan <em>plug-in</em> yang akan melakukan intersep permintaan sebelum menuju ke server Kubernetes API, setelah autentikasi dan otorisasi dilakukan.</p></li><li><p><a href=/docs/concepts/cluster-administration/sysctl-cluster/>Menggunakan Sysctls pada Klaster Kubernetes</a> akan menjabarkan tentang cara menggunakan perintah <code>sysctl</code> pada <em>command-line</em> untuk mengatur parameter kernel.</p></li><li><p><a href=/docs/tasks/debug-application-cluster/audit/>Audit</a> akan menjelaskan bagaimana cara berinteraksi dengan log audit Kubernetes.</p></li></ul><h3 id=mengamankan-kubelet>Mengamankan Kubelet</h3><ul><li><a href=/docs/concepts/architecture/master-node-communication/>Komunikasi Master-Node</a></li><li><a href=/docs/reference/command-line-tools-reference/kubelet-tls-bootstrapping/>TLS <em>bootstrapping</em></a></li><li><a href=/docs/admin/kubelet-authentication-authorization/>Autentikasi/Otorisasi Kubelet</a></li></ul><h2 id=layanan-tambahan-klaster>Layanan Tambahan Klaster</h2><ul><li><p><a href=/id/docs/concepts/services-networking/dns-pod-service/>Integrasi DNS</a> akan menjelaskan bagaimana cara <em>resolve</em> suatu nama DNS langsung pada <em>service</em> Kubernetes.</p></li><li><p><a href=/id/docs/concepts/cluster-administration/logging/><em>Logging</em> dan <em>Monitoring</em> Aktivitas Klaster</a> akan menjelaskan bagaimana cara <em>logging</em> bekerja di Kubernetes serta bagaimana cara mengimplementasikannya.</p></li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-2bf9a93ab5ba014fb6ff70b22c29d432>11.2 - Sertifikat</h1><p>Saat menggunakan autentikasi sertifikat klien, kamu dapat membuat sertifikat
secara manual melalui <code>easyrsa</code>, <code>openssl</code> atau <code>cfssl</code>.</p><h3 id=easyrsa>easyrsa</h3><p><strong>easyrsa</strong> dapat digunakan untuk menghasilkan sertifikat klaster kamu secara manual.</p><ol><li><p>Unduh, buka paket, dan inisialisasi versi tambal easyrsa3.</p><pre><code> curl -LO https://storage.googleapis.com/kubernetes-release/easy-rsa/easy-rsa.tar.gz
 tar xzf easy-rsa.tar.gz
 cd easy-rsa-master/easyrsa3
 ./easyrsa init-pki
</code></pre></li><li><p>Hasilkan CA. (<code>--batch</code> untuk atur mode otomatis. <code>--req-cn</code> untuk menggunakan <em>default</em> CN.)</p><pre><code> ./easyrsa --batch &quot;--req-cn=${MASTER_IP}@`date +%s`&quot; build-ca nopass
</code></pre></li><li><p>Hasilkan sertifikat dan kunci <em>server</em>.
Argumen <code>--subject-alt-name</code> digunakan untuk mengatur alamat IP dan nama DNS yang dapat diakses
oleh <em>server</em> API. <code>MASTER_CLUSTER_IP</code> biasanya merupakan IP pertama dari CIDR <em>service cluster</em>
yang diset dengan argumen <code>--service-cluster-ip-range</code> untuk <em>server</em> API dan
komponen manajer pengontrol. Argumen <code>--days</code> digunakan untuk mengatur jumlah hari
masa berlaku sertifikat.
Sampel di bawah ini juga mengasumsikan bahwa kamu menggunakan <code>cluster.local</code> sebagai nama
<em>domain</em> DNS <em>default</em>.</p><pre><code> ./easyrsa --subject-alt-name=&quot;IP:${MASTER_IP},&quot;\
 &quot;IP:${MASTER_CLUSTER_IP},&quot;\
 &quot;DNS:kubernetes,&quot;\
 &quot;DNS:kubernetes.default,&quot;\
 &quot;DNS:kubernetes.default.svc,&quot;\
 &quot;DNS:kubernetes.default.svc.cluster,&quot;\
 &quot;DNS:kubernetes.default.svc.cluster.local&quot; \
 --days=10000 \
 build-server-full server nopass
</code></pre></li><li><p>Salin <code>pki/ca.crt</code>, <code>pki/issued/server.crt</code>, dan <code>pki/private/server.key</code> ke direktori kamu.</p></li><li><p>Isi dan tambahkan parameter berikut ke dalam parameter mulai <em>server</em> API:</p><pre><code>--client-ca-file=/yourdirectory/ca.crt
--tls-cert-file=/yourdirectory/server.crt
--tls-private-key-file=/yourdirectory/server.key
</code></pre></li></ol><h3 id=openssl>openssl</h3><p><strong>openssl</strong> secara manual dapat menghasilkan sertifikat untuk klaster kamu.</p><ol><li><p>Hasilkan ca.key dengan 2048bit:</p><pre><code>openssl genrsa -out ca.key 2048
</code></pre></li><li><p>Hasilkan ca.crt berdasarkan ca.key (gunakan -days untuk mengatur waktu efektif sertifikat):</p><pre><code>openssl req -x509 -new -nodes -key ca.key -subj &quot;/CN=${MASTER_IP}&quot; -days 10000 -out ca.crt
</code></pre></li><li><p>Hasilkan server.key dengan 2048bit:</p><pre><code> openssl genrsa -out server.key 2048
</code></pre></li><li><p>Buat <em>file</em> konfigurasi untuk menghasilkan <em>Certificate Signing Request</em> (CSR).
Pastikan untuk mengganti nilai yang ditandai dengan kurung sudut (mis. <code>&lt;MASTER_IP></code>)
dengan nilai sebenarnya sebelum menyimpan ke <em>file</em> (mis. <code>csr.conf</code>).
Perhatikan bahwa nilai <code>MASTER_CLUSTER_IP</code> adalah layanan IP klaster untuk
<em>server</em> API seperti yang dijelaskan dalam subbagian sebelumnya.
Sampel di bawah ini juga mengasumsikan bahwa kamu menggunakan <code>cluster.local</code>
sebagai nama <em>domain</em> DNS <em>default</em>.</p><pre><code> [ req ]
 default_bits = 2048
 prompt = no
 default_md = sha256
 req_extensions = req_ext
 distinguished_name = dn

 [ dn ]
 C = &lt;country&gt;
 ST = &lt;state&gt;
 L = &lt;city&gt;
 O = &lt;organization&gt;
 OU = &lt;organization unit&gt;
 CN = &lt;MASTER_IP&gt;

 [ req_ext ]
 subjectAltName = @alt_names

 [ alt_names ]
 DNS.1 = kubernetes
 DNS.2 = kubernetes.default
 DNS.3 = kubernetes.default.svc
 DNS.4 = kubernetes.default.svc.cluster
 DNS.5 = kubernetes.default.svc.cluster.local
 IP.1 = &lt;MASTER_IP&gt;
 IP.2 = &lt;MASTER_CLUSTER_IP&gt;

 [ v3_ext ]
 authorityKeyIdentifier=keyid,issuer:always
 basicConstraints=CA:FALSE
 keyUsage=keyEncipherment,dataEncipherment
 extendedKeyUsage=serverAuth,clientAuth
 subjectAltName=@alt_names
</code></pre></li><li><p>Hasilkan permintaan penandatanganan sertifikat berdasarkan <em>file</em> konfigurasi:</p><pre><code> openssl req -new -key server.key -out server.csr -config csr.conf
</code></pre></li><li><p>Hasilkan sertifikat <em>server</em> menggunakan ca.key, ca.crt dan server.csr:</p><pre><code> openssl x509 -req -in server.csr -CA ca.crt -CAkey ca.key \
 -CAcreateserial -out server.crt -days 10000 \
 -extensions v3_ext -extfile csr.conf
</code></pre></li><li><p>Lihat sertifikat:</p><pre><code> openssl x509  -noout -text -in ./server.crt
</code></pre></li></ol><p>Terakhir, tambahkan parameter yang sama ke dalam parameter mulai <em>server</em> API.</p><h3 id=cfssl>cfssl</h3><p><strong>cfssl</strong> adalah alat lain untuk pembuatan sertifikat.</p><ol><li><p>Unduh, buka paket dan siapkan <em>command line tools</em> seperti yang ditunjukkan di bawah ini.
Perhatikan bahwa kamu mungkin perlu menyesuaikan contoh perintah berdasarkan arsitektur
perangkat keras dan versi cfssl yang kamu gunakan.</p><pre><code>curl -L https://pkg.cfssl.org/R1.2/cfssl_linux-amd64 -o cfssl
chmod +x cfssl
curl -L https://pkg.cfssl.org/R1.2/cfssljson_linux-amd64 -o cfssljson
chmod +x cfssljson
curl -L https://pkg.cfssl.org/R1.2/cfssl-certinfo_linux-amd64 -o cfssl-certinfo
chmod +x cfssl-certinfo
</code></pre></li><li><p>Buat direktori untuk menyimpan <em>artifacts</em> dan inisialisasi cfssl:</p><pre><code>mkdir cert
cd cert
../cfssl print-defaults config &gt; config.json
../cfssl print-defaults csr &gt; csr.json
</code></pre></li><li><p>Buat <em>file</em> konfigurasi JSON untuk menghasilkan <em>file</em> CA, misalnya, <code>ca-config.json</code>:</p><pre><code>{
  &quot;signing&quot;: {
    &quot;default&quot;: {
      &quot;expiry&quot;: &quot;8760h&quot;
    },
    &quot;profiles&quot;: {
      &quot;kubernetes&quot;: {
        &quot;usages&quot;: [
          &quot;signing&quot;,
          &quot;key encipherment&quot;,
          &quot;server auth&quot;,
          &quot;client auth&quot;
        ],
        &quot;expiry&quot;: &quot;8760h&quot;
      }
    }
  }
}
</code></pre></li><li><p>Buat <em>file</em> konfigurasi JSON untuk CA <em>certificate signing request</em> (CSR), misalnya,
<code>ca-csr.json</code>. Pastikan untuk mengganti nilai yang ditandai dengan kurung sudut
dengan nilai sebenarnya yang ingin kamu gunakan.</p><pre><code>{
  &quot;CN&quot;: &quot;kubernetes&quot;,
  &quot;key&quot;: {
    &quot;algo&quot;: &quot;rsa&quot;,
    &quot;size&quot;: 2048
  },
  &quot;names&quot;:[{
    &quot;C&quot;: &quot;&lt;country&gt;&quot;,
    &quot;ST&quot;: &quot;&lt;state&gt;&quot;,
    &quot;L&quot;: &quot;&lt;city&gt;&quot;,
    &quot;O&quot;: &quot;&lt;organization&gt;&quot;,
    &quot;OU&quot;: &quot;&lt;organization unit&gt;&quot;
  }]
}
</code></pre></li><li><p>Hasilkan kunci CA (<code>ca-key.pem</code>) dan sertifikat (<code>ca.pem</code>):</p><pre><code>../cfssl gencert -initca ca-csr.json | ../cfssljson -bare ca
</code></pre></li><li><p>Buat <em>file</em> konfigurasi JSON untuk menghasilkan kunci dan sertifikat untuk API
<em>server</em>, misalnya, <code>server-csr.json</code>. Pastikan untuk mengganti nilai dalam kurung sudut
dengan nilai sebenarnya yang ingin kamu gunakan. <code>MASTER_CLUSTER_IP</code> adalah layanan
klaster IP untuk <em>server</em> API seperti yang dijelaskan dalam subbagian sebelumnya.
Sampel di bawah ini juga mengasumsikan bahwa kamu menggunakan <code>cluster.local</code> sebagai
nama <em>domain</em> DNS <em>default</em>.</p><pre><code>{
  &quot;CN&quot;: &quot;kubernetes&quot;,
  &quot;hosts&quot;: [
    &quot;127.0.0.1&quot;,
    &quot;&lt;MASTER_IP&gt;&quot;,
    &quot;&lt;MASTER_CLUSTER_IP&gt;&quot;,
    &quot;kubernetes&quot;,
    &quot;kubernetes.default&quot;,
    &quot;kubernetes.default.svc&quot;,
    &quot;kubernetes.default.svc.cluster&quot;,
    &quot;kubernetes.default.svc.cluster.local&quot;
  ],
  &quot;key&quot;: {
    &quot;algo&quot;: &quot;rsa&quot;,
    &quot;size&quot;: 2048
  },
  &quot;names&quot;: [{
    &quot;C&quot;: &quot;&lt;country&gt;&quot;,
    &quot;ST&quot;: &quot;&lt;state&gt;&quot;,
    &quot;L&quot;: &quot;&lt;city&gt;&quot;,
    &quot;O&quot;: &quot;&lt;organization&gt;&quot;,
    &quot;OU&quot;: &quot;&lt;organization unit&gt;&quot;
  }]
}
</code></pre></li><li><p>Buat kunci dan sertifikat untuk server API, yang mana awalnya di
simpan masing-masing ke dalam <em>file</em> <code>server-key.pem</code> dan <code>server.pem</code>:</p><pre><code>../cfssl gencert -ca=ca.pem -ca-key=ca-key.pem \
--config=ca-config.json -profile=kubernetes \
server-csr.json | ../cfssljson -bare server
</code></pre></li></ol><h2 id=distribusi-sertifikat-self-signed-ca>Distribusi Sertifikat <em>Self-Signed</em> CA</h2><p><em>Node</em> klien dapat menolak untuk mengakui sertifikat CA yang ditandatangani sendiri sebagai valid.
Untuk <em>deployment</em> non-produksi, atau untuk <em>deployment</em> yang berjalan di belakang <em>firewall</em> perusahaan,
kamu dapat mendistribusikan sertifikat CA yang ditandatangani sendiri untuk semua klien dan <em>refresh</em>
daftar lokal untuk sertifikat yang valid.</p><p>Pada setiap klien, lakukan operasi berikut:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>sudo cp ca.crt /usr/local/share/ca-certificates/kubernetes.crt
</span></span><span style=display:flex><span>sudo update-ca-certificates
</span></span></code></pre></div><pre tabindex=0><code>Updating certificates in /etc/ssl/certs...
1 added, 0 removed; done.
Running hooks in /etc/ca-certificates/update.d....
done.
</code></pre><h2 id=sertifikat-api>Sertifikat API</h2><p>Kamu dapat menggunakan API <code>Certificate.k8s.io</code> untuk menyediakan
sertifikat x509 yang digunakan untuk autentikasi seperti yang didokumentasikan
<a href=/id/docs/tasks/tls/managing-tls-in-a-cluster>di sini</a>.</p></div><div class=td-content style=page-break-before:always><h1 id=pg-d0e81230313a2684e7b7e40b21834e30>11.3 - Penyedia Layanan Cloud</h1><p>Laman ini akan menjelaskan bagaimana cara mengelola Kubernetes yang berjalan pada penyedia layanan cloud tertentu.</p><h3 id=kubeadm>Kubeadm</h3><p><a href=/docs/reference/setup-tools/kubeadm/>Kubeadm</a> merupakan salah satu cara yang banyak digunakan untuk membuat klaster Kubernetes.
Kubeadm memiliki beragam opsi untuk mengatur konfigurasi spesifik untuk penyedia layanan cloud. Salah satu contoh yang biasa digunakan pada penyedia cloud <em>in-tree</em> yang dapat diatur dengan kubeadm adalah sebagai berikut:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>kubeadm.k8s.io/v1beta1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>InitConfiguration<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>nodeRegistration</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>kubeletExtraArgs</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>cloud-provider</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;openstack&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>cloud-config</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;/etc/kubernetes/cloud.conf&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:#00f;font-weight:700>---</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>kubeadm.k8s.io/v1beta1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>ClusterConfiguration<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kubernetesVersion</span>:<span style=color:#bbb> </span>v1.13.0<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>apiServer</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>extraArgs</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>cloud-provider</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;openstack&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>cloud-config</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;/etc/kubernetes/cloud.conf&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>extraVolumes</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>cloud<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>hostPath</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;/etc/kubernetes/cloud.conf&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>mountPath</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;/etc/kubernetes/cloud.conf&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>controllerManager</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>extraArgs</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>cloud-provider</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;openstack&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>cloud-config</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;/etc/kubernetes/cloud.conf&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>extraVolumes</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>cloud<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>hostPath</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;/etc/kubernetes/cloud.conf&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>mountPath</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;/etc/kubernetes/cloud.conf&#34;</span><span style=color:#bbb>
</span></span></span></code></pre></div><p>Penyedia layanan cloud <em>in-tree</em> biasanya membutuhkan <code>--cloud-provider</code> dan <code>--cloud-config</code> yang ditentukan sebelumnya pada <em>command lines</em> untuk <a href=/docs/admin/kube-apiserver/>kube-apiserver</a>, <a href=/docs/admin/kube-controller-manager/>kube-controller-manager</a> dan
<a href=/docs/admin/kubelet/>kubelet</a>. Konten dari <em>file</em> yang ditentukan pada <code>--cloud-config</code> untuk setiap provider akan dijabarkan di bawah ini.</p><p>Untuk semua penyedia layanan cloud eksternal, silakan ikuti instruksi pada repositori masing-masing penyedia layanan.</p><h2 id=aws>AWS</h2><p>Bagian ini akan menjelaskan semua konfigurasi yang dapat diatur saat menjalankan Kubernetes pada Amazon Web Services.</p><h3 id=nama-node>Nama Node</h3><p>Penyedia layanan cloud AWS menggunakan nama DNS privat dari <em>instance</em> AWS sebagai nama dari objek Kubernetes Node.</p><h3 id=load-balancer><em>Load Balancer</em></h3><p>Kamu dapat mengatur <a href=/id/docs/tasks/access-application-cluster/create-external-load-balancer/>load balancers eksternal</a> sehingga dapat menggunakan fitur khusus AWS dengan mengatur anotasi seperti di bawah ini.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Service<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>example<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>namespace</span>:<span style=color:#bbb> </span>kube-system<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>labels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>run</span>:<span style=color:#bbb> </span>example<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>annotations</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>     </span><span style=color:green;font-weight:700>service.beta.kubernetes.io/aws-load-balancer-ssl-cert</span>:<span style=color:#bbb> </span>arn:aws:acm:xx-xxxx-x:xxxxxxxxx:xxxxxxx/xxxxx-xxxx-xxxx-xxxx-xxxxxxxxx<span style=color:#bbb> </span><span style=color:#080;font-style:italic>#ganti nilai ini</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>     </span><span style=color:green;font-weight:700>service.beta.kubernetes.io/aws-load-balancer-backend-protocol</span>:<span style=color:#bbb> </span>http<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>type</span>:<span style=color:#bbb> </span>LoadBalancer<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>ports</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>port</span>:<span style=color:#bbb> </span><span style=color:#666>443</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>targetPort</span>:<span style=color:#bbb> </span><span style=color:#666>5556</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>protocol</span>:<span style=color:#bbb> </span>TCP<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>selector</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>app</span>:<span style=color:#bbb> </span>example<span style=color:#bbb>
</span></span></span></code></pre></div><p>Pengaturan lainnya juga dapat diaplikasikan pada layanan <em>load balancer</em> di AWS dengan menggunakan anotasi-anotasi. Berikut ini akan dijelaskan anotasi yang didukung oleh AWS ELB:</p><ul><li><code>service.beta.kubernetes.io/aws-load-balancer-access-log-emit-interval</code>: Digunakan untuk menentukan interval pengeluaran log akses.</li><li><code>service.beta.kubernetes.io/aws-load-balancer-access-log-enabled</code>: Digunakan untuk mengaktifkan atau menonaktifkan log akses.</li><li><code>service.beta.kubernetes.io/aws-load-balancer-access-log-s3-bucket-name</code>: Digunakan untuk menentukan nama <em>bucket</em> S3 log akses.</li><li><code>service.beta.kubernetes.io/aws-load-balancer-access-log-s3-bucket-prefix</code>: Digunakan untuk menentukan prefix <em>bucket</em> S3 log akses.</li><li><code>service.beta.kubernetes.io/aws-load-balancer-additional-resource-tags</code>: Digunakan untuk menentukan daftar tag tambahan pada ELB dengan menggunakan parameter <em>key-value</em>. Contoh: <code>"Key1=Val1,Key2=Val2,KeyNoVal1=,KeyNoVal2"</code>.</li><li><code>service.beta.kubernetes.io/aws-load-balancer-backend-protocol</code>: Digunakan untuk menentukan protokol yang digunakan oleh <em>backend</em> (pod) di belakang <em>listener</em>. Jika diset ke <code>http</code> (default) atau <code>https</code>, maka akan dibuat HTTPS <em>listener</em> yang akan mengakhiri koneksi dan meneruskan <em>header</em>. Jika diset ke <code>ssl</code> atau <code>tcp</code>, maka akan digunakan "raw" SSL <em>listener</em>. Jika diset ke <code>http</code> dan <code>aws-load-balancer-ssl-cert</code> tidak digunakan, maka akan digunakan HTTP <em>listener</em>.</li><li><code>service.beta.kubernetes.io/aws-load-balancer-ssl-cert</code>: Digunakan untuk meminta <em>secure</em> <em>listener</em>. Nilai yang dimasukkan adalah sertifikat ARN yang valid. Info lebih lanjut lihat <a href=http://docs.aws.amazon.com/ElasticLoadBalancing/latest/DeveloperGuide/elb-listener-config.html>ELB Listener Config</a> CertARN merupakan IAM atau CM certificate ARN, contoh: <code>arn:aws:acm:us-east-1:123456789012:certificate/12345678-1234-1234-1234-123456789012</code>.</li><li><code>service.beta.kubernetes.io/aws-load-balancer-connection-draining-enabled</code>: Digunakan untuk mengaktifkan atau menonaktfkan <em>connection draining</em>.</li><li><code>service.beta.kubernetes.io/aws-load-balancer-connection-draining-timeout</code>: Digunakan untuk menentukan <em>connection draining timeout</em>.</li><li><code>service.beta.kubernetes.io/aws-load-balancer-connection-idle-timeout</code>: Digunakan untuk menentukan <em>idle connection timeout</em>.</li><li><code>service.beta.kubernetes.io/aws-load-balancer-cross-zone-load-balancing-enabled</code>: Digunakan untuk mengaktifkan atau menonaktifkan <em>cross-zone load balancing</em>.</li><li><code>service.beta.kubernetes.io/aws-load-balancer-extra-security-groups</code>: Digunakan untuk menentukan grup keamanan yang akan ditambahkan pada ELB yang dibuat.</li><li><code>service.beta.kubernetes.io/aws-load-balancer-internal</code>: Digunakan sebagai indikasi untuk menggunakan internal ELB.</li><li><code>service.beta.kubernetes.io/aws-load-balancer-proxy-protocol</code>: Digunakan untuk mengaktifkan <em>proxy protocol</em> pada ELB. Saat ini hanya dapat menerima nilai <code>*</code> yang berarti mengaktifkan <em>proxy protocol</em> pada semua ELB <em>backends</em>. Di masa mendatang kamu juga dapat mengatur agar <em>proxy protocol</em> hanya aktif pada <em>backends</em> tertentu..</li><li><code>service.beta.kubernetes.io/aws-load-balancer-ssl-ports</code>: Digunakan untuk menentukan daftar port--yang dipisahkan koma-- yang akan menggunakan SSL/HTTPS <em>listeners</em>. Nilai <em>default</em> yaitu <code>*</code> (semua).</li></ul><p>Informasi anotasi untuk AWS di atas diperoleh dari komentar pada <a href=https://github.com/kubernetes/kubernetes/blob/master/pkg/cloudprovider/providers/aws/aws.go>aws.go</a></p><h2 id=azure>Azure</h2><h3 id=nama-node-1>Nama Node</h3><p>Penyedia layanan cloud Azure menggunakan <em>hostname</em> dari <em>node</em> (yang ditentukan oleh kubelet atau menggunakan <code>--hostname-override</code>) sebagai nama dari objek Kubernetes Node.
Perlu diperhatikan bahwa nama Kubernetes Node harus sesuai dengan nama Azure VM.</p><h2 id=cloudstack>CloudStack</h2><h3 id=nama-node-2>Nama Node</h3><p>Penyedia layanan cloud CloudStack menggunakan <em>hostname</em> dari <em>node</em> (yang ditentukan kubelet atau menggunakan <code>--hostname-override</code>) sebagai nama dari objek Kubernetes Node.
Perlu diperhatikan bahwa nama Kubernetes Node harus sesuai dengan nama Cloudstack VM.</p><h2 id=gce>GCE</h2><h3 id=nama-node-3>Nama Node</h3><p>Penyedia layanan cloud GCE menggunakan <em>hostname</em> dari <em>node</em> (yang ditentukan kubelet atau menggunakan <code>--hostname-override</code>) sebagai nama dari objek Kubernetes Node.
Perlu diperhatikan bahwa segmen pertama dari nama Kubernetes Node harus sesuai dengan nama <em>instance</em> GCE (contoh: sebuah <em>node</em> dengan nama <code>kubernetes-node-2.c.my-proj.internal</code> harus sesuai dengan <em>instance</em> yang memiliki nama <code>kubernetes-node-2</code>).</p><h2 id=openstack>OpenStack</h2><p>Bagian ini akan menjelaskan semua konfigurasi yang dapat diatur saat menggunakan OpenStack dengan Kubernetes.</p><h3 id=nama-node-4>Nama Node</h3><p>Penyedia layanan cloud OpenStack menggunakan nama <em>instance</em> (yang diperoleh dari metadata OpenStack) sebagai nama objek Kubernetes Node.
Perlu diperhatikan bahwa nama <em>instance</em> harus berupa nama Kubernetes Node yang valid agar kubelet dapat mendaftarkan objek Node-nya.</p><h3 id=layanan>Layanan</h3><p>Penyedia layanan cloud OpenStack menggunakan beragam layanan OpenStack yang tersedia sebagai <em>underlying cloud</em> agar dapat mendukung Kubernetes:</p><table><thead><tr><th>Layanan</th><th>Versi API</th><th>Wajib</th></tr></thead><tbody><tr><td>Block Storage (Cinder)</td><td>V1†, V2, V3</td><td>Tidak</td></tr><tr><td>Compute (Nova)</td><td>V2</td><td>Tidak</td></tr><tr><td>Identity (Keystone)</td><td>V2‡, V3</td><td>Ya</td></tr><tr><td>Load Balancing (Neutron)</td><td>V1§, V2</td><td>Tidak</td></tr><tr><td>Load Balancing (Octavia)</td><td>V2</td><td>Tidak</td></tr></tbody></table><p>† Block Storage V1 API tidak lagi didukung, dukungan Block Storage V3 API telah
ditambahkan pada Kubernetes 1.9.</p><p>‡ Identity V2 API tidak lagi didukung dan akan dihapus oleh penyedia layanan
pada rilis mendatang. Pada rilis "Queens", OpenStack tidak lagi mengekspos
Identity V2 API.</p><p>§ Dukungan Load Balancing V1 API telah dihapus pada Kubernetes 1.9.</p><p><em>Service discovery</em> dilakukan dengan menggunakan katalog layanan/servis (<em>service catalog</em>) yang diatur oleh
OpenStack Identity (Keystone) menggunakan <code>auth-url</code> yang ditentukan pada konfigurasi
penyedia layanan. Penyedia layanan akan menurunkan fungsionalitas secara perlahan saat layanan OpenStack selain Keystone tidak tersedia dan akan menolak dukungan fitur yang terdampak. Beberapa fitur tertentu dapat diaktifkan atau dinonaktfikan tergantung dari ekstensi yang diekspos oleh Neutron pada <em>underlying cloud</em>.</p><h3 id=cloud-conf>cloud.conf</h3><p>Kubernetes berinteraksi dengan OpenStack melalui <em>file</em> cloud.conf. <em>File</em> ini akan menyuplai Kubernetes dengan kredensial dan lokasi dari Openstack <em>auth endpoint</em>.
Kamu dapat membuat <em>file</em> cloud.conf dengan menambahkan rincian berikut ini di dalam <em>file</em>:</p><h4 id=konfigurasi-pada-umumnya>Konfigurasi pada umumnya</h4><p>Berikut ini merupakan contoh dan konfigurasi yang biasa digunakan dan akan mencakup semua pilihan yang paling sering dibutuhkan. <em>File</em> ini akan merujuk pada <em>endpoint</em> dari Keystone OpenStack, serta menyediakan rincian bagaimana cara mengautentikasi dengannya, termasuk cara mengatur <em>load balancer</em>:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span>[Global]<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span>username=user<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span>password=pass<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span>auth-url=https://&lt;keystone_ip&gt;/identity/v3<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span>tenant-id=c869168a828847f39f7f06edd7305637<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span>domain-id=2a73b8f597c04551a0fdc8e95544be8a<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span>[LoadBalancer]<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span>subnet-id=6937f8fa-858d-4bc9-a3a5-18d2c957166a<span style=color:#bbb>
</span></span></span></code></pre></div><h5 id=global>Global</h5><p>Konfigurasi untuk penyedia layanan OpenStack berikut ini akan membahas bagian konfigurasi global sehingga harus berada pada bagian <code>[Global]</code> dari <em>file</em> <code>cloud.conf</code>:</p><ul><li><code>auth-url</code> (Wajib): URL dari API keystone digunakan untuk autentikasi. ULR ini dapat ditemukan pada bagian Access dan Security > API Access > Credentials di laman panel kontrol OpenStack.</li><li><code>username</code> (Wajib): Merujuk pada username yang dikelola keystone.</li><li><code>password</code> (Wajib): Merujuk pada kata sandi yang dikelola keystone.</li><li><code>tenant-id</code> (Wajib): Digunakan untuk menentukan id dari <em>project</em> tempat kamu membuat <em>resources</em>.</li><li><code>tenant-name</code> (Opsional): Digunakan untuk menentukan nama dari <em>project</em> tempat kamu ingin membuat <em>resources</em>.</li><li><code>trust-id</code> (Opsional): Digunakan untuk menentukan <em>identifier of the trust</em> untuk digunakan
sebagai otorisasi. Suatu <em>trust</em> merepresentasikan otorisasi dari suatu pengguna (<em>the trustor</em>) untuk didelegasikan
pada pengguna lain (<em>the trustee</em>), dan dapat digunakan oleh <em>trustee</em>
berperan sebagai <em>the trustor</em>. <em>Trust</em> yang tersedia dapat ditemukan pada <em>endpoint</em>
<code>/v3/OS-TRUST/trusts</code> dari Keystone API.</li><li><code>domain-id</code> (Opsional): Digunakan untuk menentukan id dari domain tempat <em>user</em> kamu berada.</li><li><code>domain-name</code> (Opsional): Digunakan untuk menentukan nama dari domain tempat <em>user</em> kamu berada.</li><li><code>region</code> (Opsional): Digunakan untuk menentukan <em>identifier</em> dari region saat digunakan pada
multi-region OpenStack cloud. Sebuah region merupakan pembagian secara umum dari <em>deployment</em> OpenStack. Meskipun region tidak wajib berkorelasi secara geografis, suatu <em>deployment</em> dapat menggunakan nama geografis sebagai region <em>identifier</em> seperti
<code>us-east</code>. Daftar region yang tersedia dapat ditemukan pada <em>endpoint</em> <code>/v3/regions</code>
dari Keystone API.</li><li><code>ca-file</code> (Optional): Digunakan untuk menentukan path dari <em>file</em> <em>custom</em> CA.</li></ul><p>Saat menggunakan Keystone V3 - yang mengganti istilah <em>tenant</em> menjadi <em>project</em> - nilai <code>tenant-id</code>
akan secara otomatis dipetakan pada <em>project</em> yang sesuai di API.</p><h5 id=load-balancer-1><em>Load Balancer</em></h5><p>Konfigurasi berikut ini digunakan untuk mengatur <em>load
balancer</em> dan harus berada pada bagian <code>[LoadBalancer]</code> dari <em>file</em> <code>cloud.conf</code>:</p><ul><li><code>lb-version</code> (Opsional): Digunakan untuk menonaktifkan pendeteksian versi otomatis. Nilai
yang valid yaitu <code>v1</code> atau <code>v2</code>. Jika tidak ditentukan, maka pendeteksian otomatis akan
memilih versi tertinggi yang didukung dari <em>underlying</em> OpenStack
cloud.</li><li><code>use-octavia</code> (Opsional): Digunakan untuk menentukan apakah akan menggunakan <em>endpoint</em> dari layanan Octavia LBaaS. Nilai yang valid yaitu <code>true</code> atau <code>false</code>. Jika diset nilai <code>true</code> namun Octavia LBaaS V2 tidak dapat ditemukan, maka <em>load balancer</em> akan kembali menggunakan <em>endpoint</em> dari Neutron LBaaS V2. Nilai <em>default</em> adalah <code>false</code>.</li><li><code>subnet-id</code> (Opsional): Digunakan untuk menentukan id dari subnet yang ingin kamu
buat <em>load balancer</em> di dalamnya. Nilai id ini dapat dilihat pada Network > Networks. Klik pada
jaringan yang sesuai untuk melihat subnet di dalamnya.</li><li><code>floating-network-id</code> (Opsional): Jika diset, maka akan membuat <em>floating</em> IP
untuk <em>load balancer</em>.</li><li><code>lb-method</code> (Opsional): Digunakan untuk menentukan algoritma pendistribusian
yang akan digunakan. Nilai yang valid yaitu
<code>ROUND_ROBIN</code>, <code>LEAST_CONNECTIONS</code>, atau <code>SOURCE_IP</code>. Jika tidak diset, maka akan
menggunakan algoritma <em>default</em> yaitu <code>ROUND_ROBIN</code>.</li><li><code>lb-provider</code> (Opsional): Digunakan untuk menentukan penyedia dari <em>load balancer</em>.
Jika tidak ditentukan, maka akan menggunakan penyedia <em>default</em> yang ditentukan pada Neutron.</li><li><code>create-monitor</code> (Opsional): Digunakan untuk menentukan apakah akan membuat atau tidak monitor kesehatan
untuk Neutron <em>load balancer</em>. Nilai yang valid yaitu <code>true</code> dan <code>false</code>.
Nilai <em>default</em> adalah <code>false</code>. Jika diset nilai <code>true</code> maka <code>monitor-delay</code>,
<code>monitor-timeout</code>, dan <code>monitor-max-retries</code> juga harus diset.</li><li><code>monitor-delay</code> (Opsional): Waktu antara pengiriman <em>probes</em> ke
anggota dari <em>load balancer</em>. Mohon pastikan kamu memasukkan waktu yang valid. Nilai waktu yang valid yaitu "ns", "us" (atau "µs"), "ms", "s", "m", "h"</li><li><code>monitor-timeout</code> (Opsional): Waktu maksimum dari monitor untuk menunggu
balasan ping sebelum <em>timeout</em>. Nilai ini harus lebih kecil dari nilai <em>delay</em>.
Mohon pastikan kamu memasukkan waktu yang valid. Nilai waktu yang valid yaitu "ns", "us" (atau "µs"), "ms", "s", "m", "h"</li><li><code>monitor-max-retries</code> (Opsional): Jumlah gagal ping yang diizinkan sebelum
mengubah status anggota <em>load balancer</em> menjadi INACTIVE. Harus berupa angka
antara 1 dan 10.</li><li><code>manage-security-groups</code> (Opsional): Digunakan untuk menentukan apakah <em>load balancer</em>
akan mengelola aturan grup keamanan sendiri atau tidak. Nilai yang valid
adalah <code>true</code> dan <code>false</code>. Nilai <em>default</em> adalah <code>false</code>. Saat diset ke <code>true</code> maka
nilai <code>node-security-group</code> juga harus ditentukan.</li><li><code>node-security-group</code> (Opsional): ID dari grup keamanan yang akan dikelola.</li></ul><h5 id=block-storage><em>Block Storage</em></h5><p>Konfigurasi untuk penyedia layanan OpenStack berikut ini digunakan untuk mengatur penyimpanan blok atau <em>block storage</em>
dan harus berada pada bagian <code>[BlockStorage]</code> dari <em>file</em> <code>cloud.conf</code>:</p><ul><li><code>bs-version</code> (Opsional): Digunakan untuk menonaktifkan fitur deteksi versi otomatis. Nilai
yang valid yaitu <code>v1</code>, <code>v2</code>, <code>v3</code> dan <code>auto</code>. Jika diset ke <code>auto</code> maka pendeteksian versi
otomatis akan memilih versi tertinggi yang didukung oleh <em>underlying</em>
OpenStack cloud. Nilai <em>default</em> jika tidak diset adalah <code>auto</code>.</li><li><code>trust-device-path</code> (Opsional): Pada umumnya nama <em>block device</em> yang ditentukan
oleh Cinder (contoh: <code>/dev/vda</code>) tidak dapat diandalkan. Opsi ini dapat mengatur hal
tersebut. Jika diset ke <code>true</code> maka akan menggunakan nama <em>block device</em> yang ditentukan
oleh Cinder. Nilai <em>default</em> adalah <code>false</code> yang berarti <em>path</em> dari <em>device</em> akan ditentukan
oleh nomor serialnya serta pemetaan dari <code>/dev/disk/by-id</code>, dan ini merupakan
cara yang direkomendasikan.</li><li><code>ignore-volume-az</code> (Opsional): Digunakan untuk mengatur penggunaan <em>availability zone</em> saat
menautkan volumes Cinder. Jika Nova dan Cinder memiliki <em>availability
zones</em> yang berbeda, opsi ini harus diset <code>true</code>. Skenario seperti ini yang umumnya terjadi, yaitu
saat terdapat banyak Nova <em>availability zones</em> namun hanya ada satu Cinder <em>availability zone</em>.
Nilai <em>default</em> yaitu <code>false</code> digunakan untuk mendukung penggunaan pada rilis terdahulu,
tetapi nilai ini dapat berubah pada rilis mendatang.</li></ul><p>Jika menjalankan Kubernetes dengan versi &lt;= 1.8 pada OpenStack yang menggunakan <em>paths</em> alih-alih
menggunakan port untuk membedakan antara <em>endpoints</em>, maka mungkin dibutuhkan untuk
secara eksplisit mengatur parameter <code>bs-version</code>. Contoh <em>endpoint</em> yang berdasarkan <em>path</em> yaitu
<code>http://foo.bar/volume</code> sedangkan endpoint yang berdasarkan port memiliki bentuk seperti ini
<code>http://foo.bar:xxx</code>.</p><p>Pada lingkungan yang menggunakan <em>endpoint</em> berdasarkan <em>path</em> dan Kubernetes menggunakan logika deteksi-otomatis yang lama, maka <em>error</em> <code>BS API version autodetection failed.</code> akan muncul saat mencoba
melepaskan volume. Untuk mengatasi isu ini, dimungkinkan
untuk memaksa penggunaan Cinder API versi 2 dengan menambahkan baris berikut ini pada konfigurasi penyedia cloud:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span>[BlockStorage]<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span>bs-version=v2<span style=color:#bbb>
</span></span></span></code></pre></div><h5 id=metadata>Metadata</h5><p>Konfigurasi untuk OpenStack berikut ini digunakan untuk mengatur metadata dan
harus berada pada bagian <code>[Metadata]</code> dari <em>file</em> <code>cloud.conf</code>:</p><ul><li><p><code>search-order</code> (Opsional): Konfigurasi berikut ini digunakan untuk mengatur bagaimana
cara provider mengambil metadata terkait dengan <em>instance</em> yang dijalankannya. Nilai
<em>default</em> yaitu <code>configDrive,metadataService</code> yang berarti provider akan mengambil
metadata terkait <em>instance</em> dari <em>config drive</em> terlebih dahulu jika tersedia, namun
jika tidak maka akan menggunakan layanan metadata. Nilai alternatif lainnya yaitu:</p><ul><li><code>configDrive</code> - Hanya mengambil metadata <em>instance</em> dari <em>config
drive</em>.</li><li><code>metadataService</code> - Hanya mengambil data <em>instance</em> dari layanan
metadata.</li><li><code>metadataService,configDrive</code> - Mengambil metadata <em>instance</em> dari layanan metadata terlebih
dahulu jika tersedia, jika tidak maka akan mengambil dari <em>config drive</em>.</li></ul><p>Pengaturan ini memang sebaiknya dilakukan sebab metadata pada <em>config drive</em> bisa saja lambat laun akan kedaluwarsa, sedangkan layanan metadata akan selalu menyediakan metadata yang paling mutakhir. Tidak semua penyedia layanan cloud OpenStack menyediakan kedua layanan <em>config drive</em> dan layanan metadata dan mungkin hanya salah satu saja
yang tersedia. Oleh sebab itu nilai <em>default</em> diatur agar dapat memeriksa keduanya.</p></li></ul><h5 id=router>Router</h5><p>Konfigurasi untuk Openstack berikut ini digunakan untuk mengatur <em>plugin</em> jaringan Kubernetes <a href=/docs/concepts/cluster-administration/network-plugins/#kubenet>kubenet</a>
dan harus berada pada bagian <code>[Router]</code> dari <em>file</em> <code>cloud.conf</code>:</p><ul><li><code>router-id</code> (Opsional): Jika Neutron pada <em>underlying cloud</em> mendukung ekstensi
<code>extraroutes</code> maka gunakan <code>router-id</code> untuk menentukan router mana yang akan ditambahkan rute di dalamnya.
Router yang dipilih harus menjangkau jaringan privat tempat <em>node</em> klaster berada
(biasanya hanya ada satu jaringan <em>node</em>, dan nilai ini harus nilai dari <em>default</em> router
pada jaringan <em>node</em>). Nilai ini dibutuhkan untuk dapat menggunakan <a href=/docs/concepts/cluster-administration/network-plugins/#kubenet>kubenet</a> pada OpenStack.</li></ul><h2 id=ovirt>OVirt</h2><h3 id=nama-node-5>Nama Node</h3><p>Penyedia layanan cloud OVirt menggunakan <em>hostname</em> dari <em>node</em> (yang ditentukan kubelet atau menggunakan <code>--hostname-override</code>) sebagai nama dari objek Kubernetes Node.
Perlu diperhatikan bahwa nama Kubernetes Node harus sesuai dengan VM FQDN (yang ditampilkan oleh OVirt di bawah <code>&lt;vm>&lt;guest_info>&lt;fqdn>...&lt;/fqdn>&lt;/guest_info>&lt;/vm></code>)</p><h2 id=photon>Photon</h2><h3 id=nama-node-6>Nama Node</h3><p>Penyedia layanan cloud Photon menggunakan <em>hostname</em> dari <em>node</em> (yang ditentukan kubelet atau menggunakan <code>--hostname-override</code>) sebagai nama dari objek Kubernetes Node.
Perlu diperhatikan bahwa nama Kubernetes Node name harus sesuai dengan nama Photon VM (atau jika <code>overrideIP</code> diset ke true pada <code>--cloud-config</code>, nama Kubernetes Node harus sesuai dengan alamat IP Photon VM).</p><h2 id=vsphere>VSphere</h2><h3 id=nama-node-7>Nama Node</h3><p>Penyedia layanan cloud VSphere menggunakan <em>hostname</em> yang terdeteksi dari <em>node</em> (yang ditentukan oleh kubelet) sebagai nama dari objek Kubernetes Node.</p><p>Parameter <code>--hostname-override</code> diabaikan oleh penyedia layanan cloud VSphere.</p><h2 id=ibm-cloud-kubernetes-service>IBM Cloud Kubernetes Service</h2><h3 id=node-komputasi>Node Komputasi</h3><p>Saat menggunakan layanan IBM Cloud Kubernetes Service, kamu dapat membuat klaster yang terdiri dari campuran antara mesin virtual dan fisik (<em>bare metal</em>) sebagai <em>node</em> di <em>single zone</em> atau <em>multiple zones</em> pada satu region. Untuk informasi lebih lanjut, lihat <a href="https://cloud.ibm.com/docs/containers?topic=containers-plan_clusters#plan_clusters">Perencanaan klaster dan pengaturan worker node</a>.</p><p>Nama dari objek Kubernetes Node yaitu alamat IP privat dari IBM Cloud Kubernetes Service <em>worker node instance</em>.</p><h3 id=jaringan>Jaringan</h3><p>Penyedia layanan IBM Cloud Kubernetes Service menyediakan VLAN untuk membuat jaringan node yang terisolasi dengan kinerja tinggi. Kamu juga dapat membuat <em>custom firewall</em> dan <em>policy</em> jaringan Calico untuk menambah lapisan perlindungan ekstra bagi klaster kamu, atau hubungkan klaster kamu dengan <em>on-prem</em> data center via VPN. Untuk informasi lebih lanjut, lihat <a href="https://cloud.ibm.com/docs/containers?topic=containers-cs_network_cluster#cs_network_cluster">Perencanaan jaringan privat dan in-cluster</a>.</p><p>Untuk membuka aplikasi ke publik atau di dalam klaster, kamu dapat menggunakan NodePort, LoadBalancer, atau Ingress. Kamu juga dapat menyesuaikan aplikasi <em>load balancer</em> Ingress dengan anotasi. Untuk informasi lebih lanjut, lihat <a href="https://cloud.ibm.com/docs/containers?topic=containers-cs_network_planning#cs_network_planning">Perencanaan untuk membuka aplikasi dengan jaringan eksternal</a>.</p><h3 id=penyimpanan>Penyimpanan</h3><p>Penyedia layanan IBM Cloud Kubernetes Service memanfaatkan Kubernetes-native <em>persistent volumes</em> agar pengguna dapat melakukan <em>mount</em> <em>file</em>, block, dan penyimpanan objek cloud ke aplikasi mereka. Kamu juga dapat menggunakan <em>database-as-a-service</em> dan <em>add-ons</em> pihak ketiga sebagai penyimpanan <em>persistent</em> untuk data kamu. Untuk informasi lebih lanjut, lihat <a href="https://cloud.ibm.com/docs/containers?topic=containers-storage_planning#storage_planning">Perencanaan penyimpanan persistent yang selalu tersedia (<em>highly available</em>)</a>.</p><h2 id=baidu-cloud-container-engine>Baidu Cloud Container Engine</h2><h3 id=nama-node-8>Nama Node</h3><p>Penyedia layanan cloud Baidu menggunakan alamat IP privat dari <em>node</em> (yang ditentukan oleh kubelet atau menggunakan <code>--hostname-override</code>) sebagai nama dari objek Kubernetes Node.
Perlu diperhatikan bahwa nama Kubernetes Node harus sesuai dengan alamat IP privat dari Baidu VM.</p></div><div class=td-content style=page-break-before:always><h1 id=pg-3aeeecf7cdb2a21eb4b31db7a71c81e2>11.4 - Mengelola Resource</h1><p>Kamu telah melakukan <em>deploy</em> pada aplikasimu dan mengeksposnya melalui sebuah <em>service</em>. Lalu? Kubernetes menyediakan berbagai peralatan untuk membantu mengatur mekanisme <em>deploy</em> aplikasi, termasuk pengaturan kapasitas dan pembaruan. Diantara fitur yang akan didiskusikan lebih mendalam yaitu <a href=/id/docs/concepts/configuration/overview/>berkas konfigurasi</a> dan <a href=/id/docs/concepts/overview/working-with-objects/labels/>label</a>.</p><h2 id=mengelola-konfigurasi-resource>Mengelola konfigurasi <em>resource</em></h2><p>Banyak aplikasi memerlukan beberapa <em>resource</em>, seperti Deployment dan Service. Pengelolaan beberapa <em>resource</em> dapat disederhanakan dengan mengelompokkannya dalam berkas yang sama (dengan pemisah <code>---</code> pada YAML). Contohnya:</p><div class=highlight><div class=copy-code-icon style=text-align:right><a href=https://raw.githubusercontent.com/kubernetes/website/main/content/id/examples/application/nginx-app.yaml download=application/nginx-app.yaml><code>application/nginx-app.yaml</code></a>
<img src=/images/copycode.svg style=max-height:24px;cursor:pointer onclick='copyCode("application-nginx-app-yaml")' title="Copy application/nginx-app.yaml to clipboard"></img></div><div class=includecode id=application-nginx-app-yaml><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Service<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>my-nginx-svc<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>labels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>app</span>:<span style=color:#bbb> </span>nginx<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>type</span>:<span style=color:#bbb> </span>LoadBalancer<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>ports</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>port</span>:<span style=color:#bbb> </span><span style=color:#666>80</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>selector</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>app</span>:<span style=color:#bbb> </span>nginx<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:#00f;font-weight:700>---</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>apps/v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Deployment<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>my-nginx<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>labels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>app</span>:<span style=color:#bbb> </span>nginx<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>replicas</span>:<span style=color:#bbb> </span><span style=color:#666>3</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>selector</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>matchLabels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>app</span>:<span style=color:#bbb> </span>nginx<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>template</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>labels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>app</span>:<span style=color:#bbb> </span>nginx<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>nginx<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>nginx:1.7.9<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>ports</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span>- <span style=color:green;font-weight:700>containerPort</span>:<span style=color:#bbb> </span><span style=color:#666>80</span><span style=color:#bbb>
</span></span></span></code></pre></div></div></div><p>Beberapa <em>resource</em> dapat dibuat seolah-olah satu <em>resource</em>:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl apply -f https://k8s.io/examples/application/nginx-app.yaml
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>service/my-nginx-svc created
</span></span><span style=display:flex><span>deployment.apps/my-nginx created
</span></span></code></pre></div><p><em>Resource</em> akan dibuat dalam urutan seperti pada berkas. Oleh karena itu, lebih baik menyalakan <em>service</em> lebih dahulu agar menjamin <em>scheduler</em> dapat menyebar <em>pod</em> yang terkait <em>service</em> selagi <em>pod</em> dibangkitkan oleh <em>controller</em>, seperti Deployment.</p><p><code>kubectl apply</code> juga dapat menerima beberapa argumen <code>-f</code>:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl apply -f https://k8s.io/examples/application/nginx/nginx-svc.yaml -f https://k8s.io/examples/application/nginx/nginx-deployment.yaml
</span></span></code></pre></div><p>Selain berkas, kita dapat juga memasukkan direktori sebagai argumen:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl apply -f https://k8s.io/examples/application/nginx/
</span></span></code></pre></div><p><code>kubectl</code> akan membaca berkas apapun yang berakhiran <code>.yaml</code>, <code>.yml</code>, or <code>.json</code>.</p><p>Sangat disarankan untuk meletakkan sumber daya yang ada dalam <em>microservice</em> atau <em>tier</em> aplikasi yang sama dalam satu berkas, dan mengelompokkan semua berkas terkait aplikasimu dalam satu direktori. Jika <em>tier</em> masing-masing aplikasi terikat dengan DNS, maka kamu dapat melakukan <em>deploy</em> semua komponen teknologi yang dibutuhkan bersama-sama.</p><p>Lokasi konfigurasi dapat juga diberikan dalam bentuk URL. Ini berguna ketika ingin menjalankan berkas konfigurasi dari Github:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl apply -f https://raw.githubusercontent.com/kubernetes/website/master/content/en/examples/application/nginx/nginx-deployment.yaml
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>deployment.apps/my-nginx created
</span></span></code></pre></div><h2 id=operasi-majemuk-dalam-kubectl>Operasi majemuk dalam kubectl</h2><p>Pembuatan <em>resource</em> bukanlah satu-satunya operasi yang bisa dijalankan <code>kubectl</code> secara majemuk. Contoh lainnya adalah mengekstrak nama <em>resource</em> dari berkas konfigurasi untuk menjalankan operasi lainnya, seperti untuk menghapus <em>resource</em> yang telah dibuat:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl delete -f https://k8s.io/examples/application/nginx-app.yaml
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>deployment.apps <span style=color:#b44>&#34;my-nginx&#34;</span> deleted
</span></span><span style=display:flex><span>service <span style=color:#b44>&#34;my-nginx-svc&#34;</span> deleted
</span></span></code></pre></div><p>Pada kasus dua <em>resource</em>, mudah untuk memasukkan keduanya pada <em>command line</em> menggunakan sintaks <em>resource</em>/nama:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl delete deployments/my-nginx services/my-nginx-svc
</span></span></code></pre></div><p>Namun, untuk <em>resource</em> yang lebih banyak, memasukkan selektor (<em>label query</em>) menggunakan <code>-l</code> atau <code>--selector</code> untuk memfilter <em>resource</em> berdasarkan label akan lebih mudah:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl delete deployment,services -l <span style=color:#b8860b>app</span><span style=color:#666>=</span>nginx
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>deployment.apps <span style=color:#b44>&#34;my-nginx&#34;</span> deleted
</span></span><span style=display:flex><span>service <span style=color:#b44>&#34;my-nginx-svc&#34;</span> deleted
</span></span></code></pre></div><p>Karena <code>kubectl</code> mengembalikan nama resource yang sama dengan sintaks yang diterima, mudah untuk melanjutkan operasi menggunakan <code>$()</code> atau <code>xargs</code>:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get <span style=color:#a2f;font-weight:700>$(</span>kubectl create -f docs/concepts/cluster-administration/nginx/ -o name | grep service<span style=color:#a2f;font-weight:700>)</span>
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>NAME           TYPE           CLUSTER-IP   EXTERNAL-IP   PORT<span style=color:#666>(</span>S<span style=color:#666>)</span>      AGE
</span></span><span style=display:flex><span>my-nginx-svc   LoadBalancer   10.0.0.208   &lt;pending&gt;     80/TCP       0s
</span></span></code></pre></div><p>Dengan perintah di atas, pertama kita buat resource di dalam <code>examples/application/nginx/</code>. Lalu tampilkan resources yang terbentuk dengan format keluaran <code>-o name</code> (menampilkan tiap resource dalam format resource/nama). Kemudian lakukan <code>grep</code> hanya pada "service", dan tampilkan dengan <code>kubectl get</code>.</p><p>Untuk dapat menggunakan perintah di atas pada direktori yang bertingkat, kamu dapat memberi argumen <code>--recursive</code> atau <code>-R</code> bersama dengan argumen <code>--filename,-f</code>.</p><p>Misalnya ada sebuah direktori <code>project/k8s/development</code> memuat semua manifests yang berkaitan dengan <em>development environment</em>. Manifest akan tersusun berdasarkan tipe resource:</p><pre tabindex=0><code>project/k8s/development
├── configmap
│   └── my-configmap.yaml
├── deployment
│   └── my-deployment.yaml
└── pvc
    └── my-pvc.yaml
</code></pre><p>Secara <em>default</em>, menjalankan operasi majemuk pada <code>project/k8s/development</code> hanya akan terbatas pada direktori terluar saja. Sehingga ketika kita menjalankan operasi pembuatan dengan perintah berikut, kita akan mendapatkan pesan kesalahan:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl apply -f project/k8s/development
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>error: you must provide one or more resources by argument or filename <span style=color:#666>(</span>.json|.yaml|.yml|stdin<span style=color:#666>)</span>
</span></span></code></pre></div><p>Solusinya, tambahkan argumen <code>--recursive</code> atau <code>-R</code> bersama dengan <code>--filename,-f</code>, seperti:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl apply -f project/k8s/development --recursive
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>configmap/my-config created
</span></span><span style=display:flex><span>deployment.apps/my-deployment created
</span></span><span style=display:flex><span>persistentvolumeclaim/my-pvc created
</span></span></code></pre></div><p>Argumen <code>--recursive</code> berjalan pada operasi apapun yang menerima argumen <code>--filename,-f</code> seperti: <code>kubectl {create,get,delete,describe,rollout} etc.</code></p><p>Argumen <code>--recursive</code> juga berjalan saat beberapa argumen <code>-f</code> diberikan:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl apply -f project/k8s/namespaces -f project/k8s/development --recursive
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>namespace/development created
</span></span><span style=display:flex><span>namespace/staging created
</span></span><span style=display:flex><span>configmap/my-config created
</span></span><span style=display:flex><span>deployment.apps/my-deployment created
</span></span><span style=display:flex><span>persistentvolumeclaim/my-pvc created
</span></span></code></pre></div><p>Jika kamu tertarik mempelajari lebih lanjut tentang <code>kubectl</code>, silahkan baca <a href=/id/docs/reference/kubectl/overview/>Ikhtisar kubectl</a>.</p><h2 id=memakai-label-secara-efektif>Memakai label secara efektif</h2><p>Contoh yang kita lihat sejauh ini hanya menggunakan paling banyak satu label pada <em>resource</em>. Ada banyak skenario ketika membutuhkan beberapa label untuk membedakan sebuah kelompok dari yang lainnya.</p><p>Sebagai contoh, aplikasi yang berbeda akan menggunakan label <code>app</code> yang berbeda, tapi pada aplikasi <em>multitier</em>, seperti pada <a href=https://github.com/kubernetes/examples/tree/main/guestbook/>contoh buku tamu</a>, tiap <em>tier</em> perlu dibedakan. Misal untuk menandai <em>tier frontend</em> bisa menggunakan label:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#bbb>     </span><span style=color:green;font-weight:700>labels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>app</span>:<span style=color:#bbb> </span>guestbook<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>tier</span>:<span style=color:#bbb> </span>frontend<span style=color:#bbb>
</span></span></span></code></pre></div><p>sementara itu Redis <em>master</em> dan <em>slave</em> memiliki label <code>tier</code> yang berbeda. Bisa juga menggunakan label tambahan <code>role</code>:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#bbb>     </span><span style=color:green;font-weight:700>labels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>app</span>:<span style=color:#bbb> </span>guestbook<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>tier</span>:<span style=color:#bbb> </span>backend<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>role</span>:<span style=color:#bbb> </span>master<span style=color:#bbb>
</span></span></span></code></pre></div><p>dan</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#bbb>     </span><span style=color:green;font-weight:700>labels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>app</span>:<span style=color:#bbb> </span>guestbook<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>tier</span>:<span style=color:#bbb> </span>backend<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>role</span>:<span style=color:#bbb> </span>slave<span style=color:#bbb>
</span></span></span></code></pre></div><p>Label memungkinkan kita untuk memilah <em>resource</em> dengan pembeda berupa label:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl apply -f examples/guestbook/all-in-one/guestbook-all-in-one.yaml
</span></span><span style=display:flex><span>kubectl get pods -Lapp -Ltier -Lrole
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>NAME                           READY     STATUS    RESTARTS   AGE       APP         TIER       ROLE
</span></span><span style=display:flex><span>guestbook-fe-4nlpb             1/1       Running   <span style=color:#666>0</span>          1m        guestbook   frontend   &lt;none&gt;
</span></span><span style=display:flex><span>guestbook-fe-ght6d             1/1       Running   <span style=color:#666>0</span>          1m        guestbook   frontend   &lt;none&gt;
</span></span><span style=display:flex><span>guestbook-fe-jpy62             1/1       Running   <span style=color:#666>0</span>          1m        guestbook   frontend   &lt;none&gt;
</span></span><span style=display:flex><span>guestbook-redis-master-5pg3b   1/1       Running   <span style=color:#666>0</span>          1m        guestbook   backend    master
</span></span><span style=display:flex><span>guestbook-redis-slave-2q2yf    1/1       Running   <span style=color:#666>0</span>          1m        guestbook   backend    slave
</span></span><span style=display:flex><span>guestbook-redis-slave-qgazl    1/1       Running   <span style=color:#666>0</span>          1m        guestbook   backend    slave
</span></span><span style=display:flex><span>my-nginx-divi2                 1/1       Running   <span style=color:#666>0</span>          29m       nginx       &lt;none&gt;     &lt;none&gt;
</span></span><span style=display:flex><span>my-nginx-o0ef1                 1/1       Running   <span style=color:#666>0</span>          29m       nginx       &lt;none&gt;     &lt;none&gt;
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get pods -lapp<span style=color:#666>=</span>guestbook,role<span style=color:#666>=</span>slave
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>NAME                          READY     STATUS    RESTARTS   AGE
</span></span><span style=display:flex><span>guestbook-redis-slave-2q2yf   1/1       Running   <span style=color:#666>0</span>          3m
</span></span><span style=display:flex><span>guestbook-redis-slave-qgazl   1/1       Running   <span style=color:#666>0</span>          3m
</span></span></code></pre></div><h2 id=deploy-dengan-canary>Deploy dengan Canary</h2><p>Skenario lain yang menggunakan beberapa label yaitu saat membedakan deployment komponen yang sama namun dengan rilis atau konfigurasi yang berbeda. Adalah praktik yang umum untuk mendeploy sebuah <em>canary</em> dari rilis aplikasi yang baru (berdasarkan <em>tag image</em> dalam templat <em>pod</em>) bersamaan dengan rilis sebelumnya. Ini memungkinkan rilis yang baru dapat menerima <em>live traffic</em> sebelum benar-benar menggantikan rilis yang lama.</p><p>Salah satu alternatif yaitu kamu dapat memakai label <code>track</code> untuk membedakan antar rilis.</p><p>Rilis primer dan stabil akan memiliki label <code>track</code> yang berisi <code>stable</code>:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#bbb>     </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>frontend<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>     </span><span style=color:green;font-weight:700>replicas</span>:<span style=color:#bbb> </span><span style=color:#666>3</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>     </span>...<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>     </span><span style=color:green;font-weight:700>labels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>app</span>:<span style=color:#bbb> </span>guestbook<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>tier</span>:<span style=color:#bbb> </span>frontend<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>track</span>:<span style=color:#bbb> </span>stable<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>     </span>...<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>     </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>gb-frontend:v3<span style=color:#bbb>
</span></span></span></code></pre></div><p>kemudian kamu buat lagi rilis <em>frontend</em> buku tamu yang membawa label <code>track</code> yang berbeda (misal <code>canary</code>), sehingga <em>pod</em> dalam kedua rilis tidak beririsan:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#bbb>     </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>frontend-canary<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>     </span><span style=color:green;font-weight:700>replicas</span>:<span style=color:#bbb> </span><span style=color:#666>1</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>     </span>...<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>     </span><span style=color:green;font-weight:700>labels</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>app</span>:<span style=color:#bbb> </span>guestbook<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>tier</span>:<span style=color:#bbb> </span>frontend<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>track</span>:<span style=color:#bbb> </span>canary<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>     </span>...<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>     </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>gb-frontend:v4<span style=color:#bbb>
</span></span></span></code></pre></div><p>Servis <em>frontend</em> akan meliputi kedua set replika dengan menentukan subset bersama dari para labelnya (tanpa <code>track</code>). Sehingga <em>traffic</em> akan diarahkan ke kedua aplikasi:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>selector</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>     </span><span style=color:green;font-weight:700>app</span>:<span style=color:#bbb> </span>guestbook<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>     </span><span style=color:green;font-weight:700>tier</span>:<span style=color:#bbb> </span>frontend<span style=color:#bbb>
</span></span></span></code></pre></div><p>Kamu dapat mengatur jumlah replika rilis <em>stable</em> dan <em>canary</em> untuk menentukan rasio dari tiap rilis yang akan menerima <em>traffic production live</em> (dalam kasus ini 3:1).
Ketika telah yakin, kamu dapat memindahkan <em>track stable</em> ke rilis baru dan menghapus <em>canary</em>.</p><p>Untuk contoh yang lebih jelas, silahkan cek <a href=https://github.com/kelseyhightower/talks/tree/master/kubecon-eu-2016/demo#deploy-a-canary>tutorial melakukan deploy Ghost</a>.</p><h2 id=memperbarui-label>Memperbarui label</h2><p>Kadang, <em>pod</em> dan <em>resource</em> lain yang sudah ada harus dilabeli ulang sebelum membuat <em>resource</em> baru. Hal ini dapat dilakukan dengan perintah <code>kubectl label</code>.
Contohnya jika kamu ingin melabeli ulang semua <em>pod</em> nginx sebagai <em>frontend tier</em>, tinggal jalankan:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl label pods -l <span style=color:#b8860b>app</span><span style=color:#666>=</span>nginx <span style=color:#b8860b>tier</span><span style=color:#666>=</span>fe
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>pod/my-nginx-2035384211-j5fhi labeled
</span></span><span style=display:flex><span>pod/my-nginx-2035384211-u2c7e labeled
</span></span><span style=display:flex><span>pod/my-nginx-2035384211-u3t6x labeled
</span></span></code></pre></div><p>Perintah ini melakukan filter pada semua <em>pod</em> dengan label "app=nginx", lalu melabelinya dengan "tier=fe".
Untuk melihat <em>pod</em> yang telah dilabeli, jalankan:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get pods -l <span style=color:#b8860b>app</span><span style=color:#666>=</span>nginx -L tier
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>NAME                        READY     STATUS    RESTARTS   AGE       TIER
</span></span><span style=display:flex><span>my-nginx-2035384211-j5fhi   1/1       Running   <span style=color:#666>0</span>          23m       fe
</span></span><span style=display:flex><span>my-nginx-2035384211-u2c7e   1/1       Running   <span style=color:#666>0</span>          23m       fe
</span></span><span style=display:flex><span>my-nginx-2035384211-u3t6x   1/1       Running   <span style=color:#666>0</span>          23m       fe
</span></span></code></pre></div><p>Akan muncul semua <em>pod</em> dengan "app=nginx" dan sebuah kolom label tambahan yaitu tier (ditentukan dengan <code>-L</code> atau <code>--label-columns</code>).</p><p>Untuk informasi lebih lanjut, silahkan baca <a href=/id/docs/concepts/overview/working-with-objects/labels/>label</a> dan <a href=/docs/reference/generated/kubectl/kubectl-commands/#label>kubectl label</a>.</p><h2 id=memperbarui-anotasi>Memperbarui anotasi</h2><p>Kadang resource perlu ditambahkan anotasi. Anotasi adalah metadata sembarang yang tidak unik, seperti <em>tools, libraries</em>, dsb yang digunakan oleh klien API . Ini dapat dilakukan dengan <code>kubectl annotate</code>. Sebagai contoh:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl annotate pods my-nginx-v4-9gw19 <span style=color:#b8860b>description</span><span style=color:#666>=</span><span style=color:#b44>&#39;my frontend running nginx&#39;</span>
</span></span><span style=display:flex><span>kubectl get pods my-nginx-v4-9gw19 -o yaml
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>apiVersion: v1
</span></span><span style=display:flex><span>kind: pod
</span></span><span style=display:flex><span>metadata:
</span></span><span style=display:flex><span>  annotations:
</span></span><span style=display:flex><span>    description: my frontend running nginx
</span></span><span style=display:flex><span>...
</span></span></code></pre></div><p>Untuk informasi lebih lanjut, silahkan lihat laman <a href=/id/docs/concepts/overview/working-with-objects/annotations/>annotations</a> dan <a href=/docs/reference/generated/kubectl/kubectl-commands/#annotate>kubectl annotate</a>.</p><h2 id=memperbesar-dan-memperkecil-aplikasi-kamu>Memperbesar dan memperkecil aplikasi kamu</h2><p>Saat beban aplikasi naik maupun turun, mudah untuk mengubah kapasitas dengan <code>kubectl</code>. Contohnya, untuk menurunkan jumlah replika nginx dari 3 ke 1, lakukan:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl scale deployment/my-nginx --replicas<span style=color:#666>=</span><span style=color:#666>1</span>
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>deployment.extensions/my-nginx scaled
</span></span></code></pre></div><p>Sekarang kamu hanya memiliki satu <em>pod</em> yang dikelola oleh deployment.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get pods -l <span style=color:#b8860b>app</span><span style=color:#666>=</span>nginx
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>NAME                        READY     STATUS    RESTARTS   AGE
</span></span><span style=display:flex><span>my-nginx-2035384211-j5fhi   1/1       Running   <span style=color:#666>0</span>          30m
</span></span></code></pre></div><p>Agar sistem dapat menyesuaikan jumlah replika nginx yang dibutuhkan secara otomatis dari 1 hingga 3, lakukan:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl autoscale deployment/my-nginx --min<span style=color:#666>=</span><span style=color:#666>1</span> --max<span style=color:#666>=</span><span style=color:#666>3</span>
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>horizontalpodautoscaler.autoscaling/my-nginx autoscaled
</span></span></code></pre></div><p>Sekarang jumlah replika nginx akan secara otomatis naik dan turun sesuai kebutuhan.</p><p>Informasi tambahan dapat dilihat pada dokumen <a href=/docs/reference/generated/kubectl/kubectl-commands/#scale>kubectl scale</a>, <a href=/docs/reference/generated/kubectl/kubectl-commands/#autoscale>kubectl autoscale</a> dan <a href=/docs/tasks/run-application/horizontal-pod-autoscale/>horizontal <em>pod</em> autoscaler</a>.</p><h2 id=pembaruan-resource-di-tempat>Pembaruan resource di tempat</h2><p>Kadang kita perlu membuat pembaruan kecil, yang tidak mengganggu pada <em>resource</em> yang telah dibuat.</p><h3 id=kubectl-apply>kubectl apply</h3><p>Disarankan untuk menyimpan berkas-berkas konfigurasi dalam <em>source control</em> (lihat <a href=http://martinfowler.com/bliki/InfrastructureAsCode.html>konfigurasi sebagai kode</a>). Sehingga berkas dapat dipelihara dan diatur dalam versi bersama dengan kode milik <em>resource</em> yang diatur oleh konfigurasi tersebut. Berikutnya, kamu dapat menggunakan <a href=/docs/reference/generated/kubectl/kubectl-commands/#apply><code>kubectl apply</code></a> untuk membarui perubahan konfigurasi ke klaster.</p><p>Perintah ini akan membandingkan versi konfigurasi yang disuplai dengan versi sebelumnya yang telah berjalan dan memasang perubahan yang kamu buat tanpa mengganti properti yang tidak berubah sama sekali.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl apply -f https://k8s.io/examples/application/nginx/nginx-deployment.yaml
</span></span><span style=display:flex><span>deployment.apps/my-nginx configured
</span></span></code></pre></div><p>Perhatikan bahwa <code>kubectl apply</code> memasang anotasi pada <em>resource</em> untuk menentukan perubahan pada konfigurasi sejak terakhir dipanggil. Ketika dijalankan, <code>kubectl apply</code> melakukan pembandingan <em>three-way</em> antara konfigurasi sebelumnya, masukan yang disuplai, dan konfigurasi <em>resource</em> sekarang, untuk dapat menentukan cara memodifikasi <em>resource</em>.</p><p>Saat ini, <em>resource</em> dibuat tanpa ada anotasi. Jadi pemanggilan pertama pada <code>kubectl apply</code> akan dikembalikan pada perbandingan <em>two-way</em> antara masukan pengguna dan konfigurasi <em>resource</em> sekarang. Saat pemanggilan pertama ini, tidak ada penghapusan set properti yang terdeteksi saat <em>resource</em> dibuat. Sehingga, tidak ada yang dihapus.</p><p>Tiap <code>kubectl apply</code>, atau perintah lain yang memodifikasi konfigurasi seperti <code>kubectl replace</code> dan <code>kubectl edit</code> dijalankan, anotasi akan diperbarui. Sehingga memungkinkan operasi <code>kubectl apply</code> untuk mendeteksi dan melakukan penghapusan secara perbandingan <em>three-way</em>.</p><h3 id=kubectl-edit>kubectl edit</h3><p>Sebagai alternatif, kamu juga dapat membarui resource dengan <code>kubectl edit</code>:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl edit deployment/my-nginx
</span></span></code></pre></div><p>Ini sama dengan melakukan <code>get</code> pada <em>resource</em>, mengubahnya di text editor, kemudian menjalankan<code>apply</code> pada <em>resource</em> dengan versi terkini:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get deployment my-nginx -o yaml &gt; /tmp/nginx.yaml
</span></span><span style=display:flex><span>vi /tmp/nginx.yaml
</span></span><span style=display:flex><span><span style=color:#080;font-style:italic># lakukan pengubahan, lalu simpan berkas</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>kubectl apply -f /tmp/nginx.yaml
</span></span><span style=display:flex><span>deployment.apps/my-nginx configured
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>rm /tmp/nginx.yaml
</span></span></code></pre></div><p>Cara demikian memungkinkan kamu membuat perubahan signifikan dengan mudah. Lihat bahwa kamu juga dapat menentukan editor dengan variabel environment <code>EDITOR</code> atau <code>KUBE_EDITOR</code>.</p><p>Untuk informasi tambahan, silahkan lihat laman <a href=/docs/reference/generated/kubectl/kubectl-commands/#edit>kubectl edit</a>.</p><h3 id=kubectl-patch>kubectl patch</h3><p>Kamu dapat menggunakan <code>kubectl patch</code> untuk membarui obyek API di tempat. Perintah ini mendukung patch JSON, <em>patch</em> gabungan JSON, dan <em>strategic merge patch</em>. Lihat
<a href=/docs/tasks/run-application/update-api-object-kubectl-patch/>Update API Objects in Place Using kubectl patch</a>
dan
<a href=/docs/reference/generated/kubectl/kubectl-commands/#patch>kubectl patch</a>.</p><h2 id=pembaruan-disruptif>Pembaruan disruptif</h2><p>Pada kasus tertentu, kamu mungkin perlu memperbarui field resource yang tidak dapat diperbarui setelah diinisiasi atau kamu ingin membuat perubahan rekursif segera, seperti memperbaiki <em>pod</em> yang rusak saat menjalankan Deployment. Untuk mengubah field seperti itu, gunakan <code>replace --force</code> yang akan menghapus dan membuat ulang resource. Dalam kasus ini kamu dapat mengubah berkas konfigurasi awalnya:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl replace -f https://k8s.io/examples/application/nginx/nginx-deployment.yaml --force
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>deployment.apps/my-nginx deleted
</span></span><span style=display:flex><span>deployment.apps/my-nginx replaced
</span></span></code></pre></div><h2 id=membarui-aplikasi-tanpa-memadamkan-servis>Membarui aplikasi tanpa memadamkan servis</h2><p>Suatu saat, kamu akan perlu untuk membarui aplikasi yang telah terdeploy, biasanya dengan mengganti <em>image</em> atau <em>tag</em> sebagaimana dalam skenario <em>canary deployment</em> di atas. <code>kubectl</code> mendukung beberapa operasi pembaruan, masing-masing dapat digunakan pada skenario berbeda.</p><p>Kami akan memandumu untuk membuat dan membarui aplikasi melalui Deployment.</p><p>Misal kamu telah menjalankan nginx versi 1.7.9:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl run my-nginx --image<span style=color:#666>=</span>nginx:1.7.9 --replicas<span style=color:#666>=</span><span style=color:#666>3</span>
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>deployment.apps/my-nginx created
</span></span></code></pre></div><p>Untuk memperbarui versi ke 1.9.1, ganti <code>.spec.template.spec.containers[0].image</code> dari <code>nginx:1.7.9</code> ke <code>nginx:1.9.1</code>, dengan perintah kubectl yang telah dipelajari di atas.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl edit deployment/my-nginx
</span></span></code></pre></div><p>Selesai! Deployment akan memperbarui aplikasi nginx yang terdeploy secara berangsur di belakang. Dia akan menjamin hanya ada sekian replika lama yang akan down selagi pembaruan berjalan dan hanya ada sekian replika baru akan dibuat melebihi jumlah pod. Untuk mempelajari lebih lanjut, kunjungi <a href=/id/docs/concepts/workloads/controllers/deployment/>laman Deployment</a>.</p><h2 id=selanjutnya>Selanjutnya</h2><ul><li><a href=/docs/tasks/debug-application-cluster/debug-application-introspection/>Pelajari tentang bagaimana memakai <code>kubectl</code> untuk memeriksa dan <em>debug</em> aplikasi.</a></li><li><a href=/id/docs/concepts/configuration/overview/>Praktik Terbaik dan Tips Konfigurasi</a></li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-d649067a69d8d5c7e71564b42b96909e>11.5 - Jaringan Kluster</h1><p>Jaringan adalah bagian utama dari Kubernetes, tetapi bisa menjadi sulit
untuk memahami persis bagaimana mengharapkannya bisa bekerja.
Ada 4 masalah yang berbeda untuk diatasi:</p><ol><li>Komunikasi antar kontainer yang sangat erat: hal ini diselesaikan oleh
<a href=/id/docs/concepts/workloads/pods/pod/>Pod</a> dan komunikasi <code>localhost</code>.</li><li>Komunikasi antar Pod: ini adalah fokus utama dari dokumen ini.</li><li>Komunikasi Pod dengan Service: ini terdapat di <a href=/id/docs/concepts/services-networking/service/>Service</a>.</li><li>Komunikasi eksternal dengan Service: ini terdapat di <a href=/id/docs/concepts/services-networking/service/>Service</a>.</li></ol><p>Kubernetes adalah tentang berbagi mesin antar aplikasi. Pada dasarnya,
saat berbagi mesin harus memastikan bahwa dua aplikasi tidak mencoba menggunakan
<em>port</em> yang sama. Mengkoordinasikan <em>port</em> di banyak pengembang sangat sulit
dilakukan pada skala yang berbeda dan memaparkan pengguna ke masalah
tingkat kluster yang di luar kendali mereka.</p><p>Alokasi <em>port</em> yang dinamis membawa banyak komplikasi ke sistem - setiap aplikasi
harus menganggap <em>port</em> sebagai <em>flag</em>, <em>server</em> API harus tahu cara memasukkan
nomor <em>port</em> dinamis ke dalam blok konfigurasi, Service-Service harus tahu cara
menemukan satu sama lain, dll. Sebaliknya daripada berurusan dengan ini,
Kubernetes mengambil pendekatan yang berbeda.</p><h2 id=model-jaringan-kubernetes>Model jaringan Kubernetes</h2><p>Setiap Pod mendapatkan alamat IP sendiri. Ini berarti kamu tidak perlu secara langsung membuat tautan antara Pod dan kamu hampir tidak perlu berurusan dengan memetakan <em>port</em> kontainer ke <em>port</em> pada <em>host</em>. Ini menciptakan model yang bersih, kompatibel dengan yang sebelumnya dimana Pod dapat diperlakukan seperti halnya VM atau <em>host</em> fisik dari perspektif alokasi <em>port</em>, penamaan, <em>service discovery</em>, <em>load balancing</em>, konfigurasi aplikasi, dan migrasi.</p><p>Kubernetes memberlakukan persyaratan mendasar berikut pada setiap implementasi jaringan (kecuali kebijakan segmentasi jaringan yang disengaja):</p><ul><li>Pod pada suatu Node dapat berkomunikasi dengan semua Pod pada semua Node tanpa NAT</li><li>agen pada suatu simpul (mis. <em>daemon</em> sistem, kubelet) dapat berkomunikasi dengan semua Pod pada Node itu</li></ul><p>Catatan: Untuk platform yang mendukung Pod yang berjalan di jaringan <em>host</em> (mis. Linux):</p><ul><li>Pod di jaringan <em>host</em> dari sebuah Node dapat berkomunikasi dengan semua Pod pada semua Node tanpa NAT</li></ul><p>Model ini tidak hanya sedikit kompleks secara keseluruhan, tetapi pada prinsipnya kompatibel dengan keinginan Kubernetes untuk memungkinkan <em>low-friction porting</em> dari aplikasi dari VM ke kontainer. Jika pekerjaan kamu sebelumnya dijalankan dalam VM, VM kamu memiliki IP dan dapat berbicara dengan VM lain di proyek yang sama. Ini adalah model dasar yang sama.</p><p>Alamat IP Kubernetes ada di lingkup Pod - kontainer dalam Pod berbagi jaringan <em>namespace</em> mereka - termasuk alamat IP mereka. Ini berarti bahwa kontainer dalam Pod semua dapat mencapai <em>port</em> satu sama lain di <code>_localhost_</code>. Ini juga berarti bahwa kontainer dalam Pod harus mengoordinasikan penggunaan <em>port</em>, tetapi ini tidak berbeda dari proses di VM. Ini disebut model "IP-per-pod".</p><h2 id=bagaimana-menerapkan-model-jaringan-kubernetes>Bagaimana menerapkan model jaringan Kubernetes</h2><p>Ada beberapa cara agar model jaringan ini dapat diimplementasikan. Dokumen ini bukan studi lengkap tentang berbagai metode, tetapi semoga berfungsi sebagai pengantar ke berbagai teknologi dan berfungsi sebagai titik awal.</p><p>Opsi jaringan berikut ini disortir berdasarkan abjad - urutan tidak menyiratkan status istimewa apa pun.</p><h3 id=aci>ACI</h3><p><a href=https://www.cisco.com/c/en/us/solutions/data-center-virtualization/application-centric-infrastructure/index.html>Infrastruktur Sentral Aplikasi Cisco</a> menawarkan solusi SDN overlay dan underlay terintegrasi yang mendukung kontainer, mesin virtual, dan <em>bare metal server</em>. <a href=https://www.github.com/noironetworks/aci-containers>ACI</a> menyediakan integrasi jaringan kontainer untuk ACI. Tinjauan umum integrasi disediakan <a href=https://www.cisco.com/c/dam/en/us/solutions/collateral/data-center-virtualization/application-centric-infrastructure/solution-overview-c22-739493.pdf>di sini</a>.</p><h3 id=aos-dari-apstra>AOS dari Apstra</h3><p><a href=http://www.apstra.com/products/aos/>AOS</a> adalah sistem Jaringan Berbasis Intent yang menciptakan dan mengelola lingkungan pusat data yang kompleks dari platform terintegrasi yang sederhana. AOS memanfaatkan desain terdistribusi sangat <em>scalable</em> untuk menghilangkan pemadaman jaringan sambil meminimalkan biaya.</p><p>Desain Referensi AOS saat ini mendukung <em>host</em> yang terhubung dengan Lapis-3 yang menghilangkan masalah peralihan Lapis-2 yang lama. Host Lapis-3 ini bisa berupa <em>server</em> Linux (Debian, Ubuntu, CentOS) yang membuat hubungan tetangga BGP secara langsung dengan <em>top of rack switches</em> (TORs). AOS mengotomatisasi kedekatan perutean dan kemudian memberikan kontrol yang halus atas <em>route health injections</em> (RHI) yang umum dalam <em>deployment</em> Kubernetes.</p><p>AOS memiliki banyak kumpulan endpoint REST API yang memungkinkan Kubernetes dengan cepat mengubah kebijakan jaringan berdasarkan persyaratan aplikasi. Peningkatan lebih lanjut akan mengintegrasikan model Grafik AOS yang digunakan untuk desain jaringan dengan penyediaan beban kerja, memungkinkan sistem manajemen ujung ke ujung untuk layanan cloud pribadi dan publik.</p><p>AOS mendukung penggunaan peralatan vendor umum dari produsen termasuk Cisco, Arista, Dell, Mellanox, HPE, dan sejumlah besar sistem white-box dan sistem operasi jaringan terbuka seperti Microsoft SONiC, Dell OPX, dan Cumulus Linux.</p><p>Detail tentang cara kerja sistem AOS dapat diakses di sini: <a href=http://www.apstra.com/products/how-it-works/>http://www.apstra.com/products/how-it-works/</a></p><h3 id=aws-vpc-cni-untuk-kubernetes>AWS VPC CNI untuk Kubernetes</h3><p><a href=https://github.com/aws/amazon-vpc-cni-k8s>AWS VPC CNI</a> menawarkan jaringan AWS <em>Virtual Private Cloud</em> (VPC) terintegrasi untuk kluster Kubernetes. Plugin CNI ini menawarkan <em>throughput</em> dan ketersediaan tinggi, latensi rendah, dan <em>jitter</em> jaringan minimal. Selain itu, pengguna dapat menerapkan jaringan AWS VPC dan praktik keamanan terbaik untuk membangun kluster Kubernetes. Ini termasuk kemampuan untuk menggunakan catatan aliran VPC, kebijakan perutean VPC, dan grup keamanan untuk isolasi lalu lintas jaringan.</p><p>Menggunakan <em>plugin</em> CNI ini memungkinkan Pod Kubernetes memiliki alamat IP yang sama di dalam Pod seperti yang mereka lakukan di jaringan VPC. CNI mengalokasikan AWS <em>Elastic Networking Interfaces</em> (ENIs) ke setiap node Kubernetes dan menggunakan rentang IP sekunder dari setiap ENI untuk Pod pada Node. CNI mencakup kontrol untuk pra-alokasi ENI dan alamat IP untuk waktu mulai Pod yang cepat dan memungkinkan kluster besar hingga 2.000 Node.</p><p>Selain itu, CNI dapat dijalankan bersama <a href=https://docs.aws.amazon.com/eks/latest/userguide/calico.html>Calico untuk penegakan kebijakan jaringan</a>. Proyek AWS VPC CNI adalah <em>open source</em> dengan <a href=https://github.com/aws/amazon-vpc-cni-k8s>dokumentasi di GitHub</a>.</p><h3 id=big-cloud-fabric-dari-big-switch-networks>Big Cloud Fabric dari Big Switch Networks</h3><p><a href=https://www.bigswitch.com/container-network-automation>Big Cloud Fabric</a> adalah arsitektur jaringan asli layanan cloud, yang dirancang untuk menjalankan Kubernetes di lingkungan cloud pribadi / lokal. Dengan menggunakan SDN fisik & <em>virtual</em> terpadu, Big Cloud Fabric menangani masalah yang sering melekat pada jaringan kontainer seperti penyeimbangan muatan, visibilitas, pemecahan masalah, kebijakan keamanan & pemantauan lalu lintas kontainer.</p><p>Dengan bantuan arsitektur multi-penyewa Pod virtual pada Big Cloud Fabric, sistem orkestrasi kontainer seperti Kubernetes, RedHat OpenShift, Mesosphere DC/OS & Docker Swarm akan terintegrasi secara alami bersama dengan sistem orkestrasi VM seperti VMware, OpenStack & Nutanix. Pelanggan akan dapat terhubung dengan aman berapa pun jumlah klusternya dan memungkinkan komunikasi antar penyewa di antara mereka jika diperlukan.</p><p>Terbaru ini BCF diakui oleh Gartner sebagai visioner dalam <a href=http://go.bigswitch.com/17GatedDocuments-MagicQuadrantforDataCenterNetworking_Reg.html><em>Magic Quadrant</em></a>. Salah satu penyebaran BCF Kubernetes di tempat (yang mencakup Kubernetes, DC/OS & VMware yang berjalan di beberapa DC di berbagai wilayah geografis) juga dirujuk <a href=https://portworx.com/architects-corner-kubernetes-satya-komala-nio/>di sini</a>.</p><h3 id=cilium>Cilium</h3><p><a href=https://github.com/cilium/cilium>Cilium</a> adalah perangkat lunak <em>open source</em> untuk menyediakan dan secara transparan mengamankan konektivitas jaringan antar kontainer aplikasi. Cilium mengetahui L7/HTTP dan dapat memberlakukan kebijakan jaringan pada L3-L7 menggunakan model keamanan berbasis identitas yang dipisahkan dari pengalamatan jaringan.</p><h3 id=cni-genie-dari-huawei>CNI-Genie dari Huawei</h3><p><a href=https://github.com/Huawei-PaaS/CNI-Genie>CNI-Genie</a> adalah <em>plugin</em> CNI yang memungkinkan Kubernetes [secara bersamaan memiliki akses ke berbagai implementasi](<a href=https://github.com/Huawei-PaaS>https://github.com/Huawei-PaaS</a> /CNI-Genie/blob/master/docs/multiple-cni-plugins/README.md#what-cni-genie-feature-1-multiple-cni-plugins-enables) dari [model jaringan Kubernetes] (<a href=https://git.k8s.io/website/docs/concepts/cluster-administration/networking.md#kubernetes-model>https://git.k8s.io/website/docs/concepts/cluster-administration/networking.md#kubernetes-model</a>) dalam <em>runtime</em>. Ini termasuk setiap implementasi yang berjalan sebagai <a href=https://github.com/containernetworking/cni#3rd-party-plugins><em>plugin</em> CNI</a>, seperti <a href=https://github.com/coreos/flannel#flannel>Flannel</a>, <a href=http://docs.projectcalico.org/>Calico</a>, <a href=http://romana.io>Romana</a>, <a href=https://www.weave.works/products/weave-net/>Weave-net</a>.</p><p>CNI-Genie juga mendukung <a href=https://github.com/Huawei-PaaS/CNI-Genie/blob/master/docs/multiple-ips/README.md#feature-2-extension-cni-genie-multiple-ip-address-per-pod>menetapkan beberapa alamat IP ke sebuah Pod</a>, masing-masing dari <em>plugin</em> CNI yang berbeda.</p><h3 id=cni-ipvlan-vpc-k8s>cni-ipvlan-vpc-k8s</h3><p><a href=https://github.com/lyft/cni-ipvlan-vpc-k8s>cni-ipvlan-vpc-k8s</a> berisi satu set <em>plugin</em> CNI dan IPAM untuk menyediakan kemudahan, host-lokal, latensi rendah, <em>throughput</em> tinggi , dan tumpukan jaringan yang sesuai untuk Kubernetes dalam lingkungan Amazon Virtual Private Cloud (VPC) dengan memanfaatkan Amazon Elastic Network Interfaces (ENI) dan mengikat IP yang dikelola AWS ke Pod-Pod menggunakan <em>driver</em> IPvlan <em>kernel</em> Linux dalam mode L2.</p><p>Plugin ini dirancang untuk secara langsung mengkonfigurasi dan <em>deploy</em> dalam VPC. Kubelet melakukan <em>booting</em> dan kemudian mengkonfigurasi sendiri dan memperbanyak penggunaan IP mereka sesuai kebutuhan tanpa memerlukan kompleksitas yang sering direkomendasikan untuk mengelola jaringan <em>overlay</em>, BGP, menonaktifkan pemeriksaan sumber/tujuan, atau menyesuaikan tabel rute VPC untuk memberikan <em>subnet</em> per <em>instance</em> ke setiap <em>host</em> (yang terbatas hingga 50-100 masukan per VPC). Singkatnya, cni-ipvlan-vpc-k8s secara signifikan mengurangi kompleksitas jaringan yang diperlukan untuk menggunakan Kubernetes yang berskala di dalam AWS.</p><h3 id=contiv>Contiv</h3><p><a href=https://github.com/contiv/netplugin>Contiv</a> menyediakan jaringan yang dapat dikonfigurasi (<em>native</em> l3 menggunakan BGP, <em>overlay</em> menggunakan vxlan, classic l2, atau Cisco-SDN / ACI) untuk berbagai kasus penggunaan. <a href=http://contiv.io>Contiv</a> semuanya open sourced.</p><h3 id=contrail-tungsten-fabric>Contrail / Tungsten Fabric</h3><p><a href=http://www.juniper.net/us/en/products-services/sdn/contrail/contrail-networking/>Contrail</a>, berdasarkan <a href=https://tungsten.io>Tungsten Fabric</a>, adalah platform virtualisasi jaringan dan manajemen kebijakan <em>multi-cloud</em> yang benar-benar terbuka. Contrail dan Tungsten Fabric terintegrasi dengan berbagai sistem orkestrasi seperti Kubernetes, OpenShift, OpenStack dan Mesos, dan menyediakan mode isolasi yang berbeda untuk mesin <em>virtual</em>, banyak kontainer / banyak Pod dan beban kerja <em>bare metal</em>.</p><h3 id=danm>DANM</h3><p>[DANM] (<a href=https://github.com/nokia/danm>https://github.com/nokia/danm</a>) adalah solusi jaringan untuk beban kerja telco yang berjalan di kluster Kubernetes. Dibangun dari komponen-komponen berikut:</p><ul><li>Plugin CNI yang mampu menyediakan antarmuka IPVLAN dengan fitur-fitur canggih</li><li>Modul IPAM built-in dengan kemampuan mengelola dengan jumlah banyak, <em>cluster-wide</em>, <em>discontinous</em> jaringan L3 dan menyediakan skema dinamis, statis, atau tidak ada permintaan skema IP</li><li>Metaplugin CNI yang mampu melampirkan beberapa antarmuka jaringan ke kontainer, baik melalui CNI sendiri, atau mendelegasikan pekerjaan ke salah satu solusi CNI populer seperti SRI-OV, atau Flannel secara paralel</li><li>Pengontrol Kubernetes yang mampu mengatur secara terpusat antarmuka VxLAN dan VLAN dari semua <em>host</em> Kubernetes</li><li>Pengontrol Kubernetes lain yang memperluas konsep <em>service discovery</em> berbasis servis untuk bekerja di semua antarmuka jaringan Pod</li></ul><p>Dengan <em>toolset</em> ini, DANM dapat memberikan beberapa antarmuka jaringan yang terpisah, kemungkinan untuk menggunakan ujung belakang jaringan yang berbeda dan fitur IPAM canggih untuk Pod.</p><h3 id=flannel>Flannel</h3><p>[Flannel] (<a href=https://github.com/coreos/flannel#flannel>https://github.com/coreos/flannel#flannel</a>) adalah jaringan overlay yang sangat sederhana yang memenuhi persyaratan Kubernetes. Banyak orang telah melaporkan kesuksesan dengan Flannel dan Kubernetes.</p><h3 id=google-compute-engine-gce>Google Compute Engine (GCE)</h3><p>Untuk skrip konfigurasi kluster Google Compute Engine, <a href=https://cloud.google.com/vpc/docs/routes>perutean lanjutan</a> digunakan untuk menetapkan setiap VM <em>subnet</em> (standarnya adalah <code>/24</code> - 254 IP). Setiap lalu lintas yang terikat untuk <em>subnet</em> itu akan dialihkan langsung ke VM oleh <em>fabric</em> jaringan GCE. Ini adalah tambahan untuk alamat IP "utama" yang ditugaskan untuk VM, yang NAT'ed untuk akses internet keluar. Sebuah linux <em>bridge</em> (disebut <code>cbr0</code>) dikonfigurasikan untuk ada pada subnet itu, dan diteruskan ke <em>flag</em> <code>-bridge</code> milik docker.</p><p>Docker dimulai dengan:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span><span style=color:#b8860b>DOCKER_OPTS</span><span style=color:#666>=</span><span style=color:#b44>&#34;--bridge=cbr0 --iptables=false --ip-masq=false&#34;</span>
</span></span></code></pre></div><p>Jembatan ini dibuat oleh Kubelet (dikontrol oleh <em>flag</em> <code>--network-plugin=kubenet</code>) sesuai dengan <code>.spec.podCIDR</code> yang dimiliki oleh Node.</p><p>Docker sekarang akan mengalokasikan IP dari blok <code>cbr-cidr</code>. Kontainer dapat menjangkau satu sama lain dan Node di atas jembatan <code>cbr0</code>. IP-IP tersebut semuanya dapat dirutekan dalam jaringan proyek GCE.</p><p>GCE sendiri tidak tahu apa-apa tentang IP ini, jadi tidak akan NAT untuk lalu lintas internet keluar. Untuk mencapai itu aturan iptables digunakan untuk menyamar (alias SNAT - untuk membuatnya seolah-olah paket berasal dari lalu lintas <code>Node</code> itu sendiri) yang terikat untuk IP di luar jaringan proyek GCE (10.0.0.0/8).</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>iptables -t nat -A POSTROUTING ! -d 10.0.0.0/8 -o eth0 -j MASQUERADE
</span></span></code></pre></div><p>Terakhir IP forwarding diaktifkan di kernel (sehingga kernel akan memproses paket untuk kontainer yang dijembatani):</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>sysctl net.ipv4.ip_forward<span style=color:#666>=</span><span style=color:#666>1</span>
</span></span></code></pre></div><p>Hasil dari semua ini adalah bahwa semua Pod dapat saling menjangkau dan dapat keluar lalu lintas ke internet.</p><h3 id=jaguar>Jaguar</h3><p><a href=https://gitlab.com/sdnlab/jaguar>Jaguar</a> adalah solusi open source untuk jaringan Kubernetes berdasarkan OpenDaylight. Jaguar menyediakan jaringan overlay menggunakan vxlan dan Jaguar CNIPlugin menyediakan satu alamat IP per Pod.</p><h3 id=knitter>Knitter</h3><p><a href=https://github.com/ZTE/Knitter/>Knitter</a> adalah solusi jaringan yang mendukung banyak jaringan di Kubernetes. Solusi ini menyediakan kemampuan manajemen penyewa dan manajemen jaringan. Knitter mencakup satu set solusi jaringan kontainer NFV ujung ke ujung selain beberapa pesawat jaringan, seperti menjaga alamat IP untuk aplikasi, migrasi alamat IP, dll.</p><h3 id=kube-ovn>Kube-OVN</h3><p><a href=https://github.com/alauda/kube-ovn>Kube-OVN</a> adalah <em>fabric</em> jaringan kubernetes berbasis OVN untuk <em>enterprises</em>. Dengan bantuan OVN/OVS, solusi ini menyediakan beberapa fitur jaringan <em>overlay</em> canggih seperti <em>subnet</em>, QoS, alokasi IP statis, <em>mirroring traffic</em>, <em>gateway</em>, kebijakan jaringan berbasis <em>openflow</em>, dan proksi layanan.</p><h3 id=kube-router>Kube-router</h3><p><a href=https://github.com/cloudnativelabs/kube-router>Kube-router</a> adalah solusi jaringan yang dibuat khusus untuk Kubernetes yang bertujuan untuk memberikan kinerja tinggi dan kesederhanaan operasional. Kube-router menyediakan Linux <a href=http://www.linuxvirtualserver.org/software/ipvs.html>LVS/IPVS</a> berbasis proksi layanan, solusi jaringan berbasis penerusan <em>pod-to-pod</em> Linux <em>kernel</em> tanpa <em>overlay</em>, dan penegak kebijakan jaringan berbasis <em>iptables/ipset</em>.</p><h3 id=l2-networks-and-linux-bridging>L2 networks and linux bridging</h3><p>Jika Anda memiliki jaringan L2 yang "bodoh", seperti saklar sederhana di <em>environment</em> "bare-metal", kamu harus dapat melakukan sesuatu yang mirip dengan pengaturan GCE di atas. Perhatikan bahwa petunjuk ini hanya dicoba dengan sangat sederhana - sepertinya berhasil, tetapi belum diuji secara menyeluruh. Jika kamu menggunakan teknik ini dan telah menyempurnakan prosesnya, tolong beri tahu kami.</p><p>Ikuti bagian "With Linux Bridge devices" dari <a href=http://blog.oddbit.com/2014/08/11/four-ways-to-connect-a-docker/>tutorial yang sangat bagus ini</a> dari Lars Kellogg-Stedman.</p><h3 id=multus-plugin-multi-jaringan>Multus (plugin Multi-Jaringan)</h3><p><a href=https://github.com/Intel-Corp/multus-cni>Multus</a> adalah plugin Multi CNI untuk mendukung fitur Banyak Jaringan di Kubernetes menggunakan objek jaringan berbasis CRD di Kubernetes.</p><p>Multus mendukung semua <a href=https://github.com/containernetworking/plugins>plugin referensi</a> (mis. <a href=https://github.com/containernetworking/plugins/tree/master/plugins/meta/flannel>Flannel</a>, <a href=https://github.com/containernetworking/plugins/tree/master/plugins/ipam/dhcp>DHCP</a>, [Macvlan](<a href=https://github.com/containernetworking/plugins/tree/master/plugins/main>https://github.com/containernetworking/plugins/tree/master/plugins/main</a> / macvlan)) yang mengimplementasikan spesifikasi CNI dan plugin pihak ke-3 (mis. <a href=https://github.com/projectcalico/cni-plugin>Calico</a>, <a href=https://github.com/weaveworks/weave>Weave</a>, <a href=https://github.com/cilium/cilium>Cilium</a>, <a href=https://github.com/contiv/netplugin>Contiv</a>). Selain itu, Multus mendukung <a href=https://github.com/hustcat/sriov-cni>SRIOV</a>, <a href=https://github.com/Intel-Corp/sriov-cni>DPDK</a>, <a href=https://github.com/intel/vhost-user-net-plugin>OVS- DPDK & VPP</a> beban kerja di Kubernetes dengan aplikasi cloud asli dan aplikasi berbasis NFV di Kubernetes.</p><h3 id=nsx-t>NSX-T</h3><p><a href=https://docs.vmware.com/en/VMware-NSX-T/index.html>VMware NSX-T</a> adalah virtualisasi jaringan dan platform keamanan. NSX-T dapat menyediakan virtualisasi jaringan untuk lingkungan multi-cloud dan multi-hypervisor dan berfokus pada kerangka kerja dan arsitektur aplikasi yang muncul yang memiliki titik akhir dan tumpukan teknologi yang heterogen. Selain hypervisor vSphere, lingkungan ini termasuk hypervisor lainnya seperti KVM, wadah, dan bare metal.</p><p><a href=https://docs.vmware.com/en/VMware-NSX-T/2.0/nsxt_20_ncp_kubernetes.pdf>NSX-T Container Plug-in (NCP)</a> menyediakan integrasi antara NSX-T dan pembuat wadah seperti Kubernetes, serta integrasi antara NSX-T dan platform CaaS / PaaS berbasis-kontainer seperti Pivotal Container Service (PKS) dan OpenShift.</p><h3 id=nuage-networks-vcs-layanan-cloud-virtual>Nuage Networks VCS (Layanan Cloud Virtual)</h3><p><a href=http://www.nuagenetworks.net>Nuage</a> menyediakan platform SDN (Software-Defined Networking) berbasis kebijakan yang sangat skalabel. Nuage menggunakan Open vSwitch <em>open source</em> untuk data <em>plane</em> bersama dengan SDN Controller yang kaya fitur yang dibangun pada standar terbuka.</p><p>Platform Nuage menggunakan <em>overlay</em> untuk menyediakan jaringan berbasis kebijakan yang mulus antara Kubernetes Pod-Pod dan lingkungan non-Kubernetes (VM dan server <em>bare metal</em>). Model abstraksi kebijakan Nuage dirancang dengan mempertimbangkan aplikasi dan membuatnya mudah untuk mendeklarasikan kebijakan berbutir halus untuk aplikasi. Mesin analisis <em>real-time</em> platform memungkinkan pemantauan visibilitas dan keamanan untuk aplikasi Kubernetes.</p><h3 id=ovn-open-virtual-networking>OVN (Open Virtual Networking)</h3><p>OVN adalah solusi virtualisasi jaringan opensource yang dikembangkan oleh komunitas Open vSwitch. Ini memungkinkan seseorang membuat switch logis, router logis, ACL stateful, load-balancers dll untuk membangun berbagai topologi jaringan virtual. Proyek ini memiliki plugin dan dokumentasi Kubernetes spesifik di <a href=https://github.com/openvswitch/ovn-kubernetes>ovn-kubernetes</a>.</p><h3 id=project-calico>Project Calico</h3><p><a href=http://docs.projectcalico.org/>Project Calico</a> adalah penyedia jaringan wadah sumber terbuka dan mesin kebijakan jaringan.</p><p>Calico menyediakan solusi jaringan dan kebijakan kebijakan jaringan yang sangat berskala untuk menghubungkan Pod Kubernetes berdasarkan prinsip jaringan IP yang sama dengan internet, untuk Linux (open source) dan Windows (milik - tersedia dari <a href=https://www.tigera.io/essentials/>Tigera</a>). Calico dapat digunakan tanpa enkapsulasi atau <em>overlay</em> untuk menyediakan jaringan pusat data skala tinggi yang berkinerja tinggi. Calico juga menyediakan kebijakan keamanan jaringan berbutir halus, berdasarkan niat untuk Pod Kubernetes melalui <em>firewall</em> terdistribusi.</p><p>Calico juga dapat dijalankan dalam mode penegakan kebijakan bersama dengan solusi jaringan lain seperti Flannel, alias <a href=https://github.com/tigera/canal>kanal</a>, atau jaringan GCE, AWS atau Azure asli.</p><h3 id=romana>Romana</h3><p><a href=http://romana.io>Romana</a> adalah jaringan sumber terbuka dan solusi otomasi keamanan yang memungkinkan kamu menggunakan Kubernetes tanpa jaringan hamparan. Romana mendukung Kubernetes <a href=/id/docs/concepts/services-networking/network-policies/>Kebijakan Jaringan</a> untuk memberikan isolasi di seluruh ruang nama jaringan.</p><h3 id=weave-net-dari-weaveworks>Weave Net dari Weaveworks</h3><p><a href=https://www.weave.works/products/weave-net/>Weave Net</a> adalah jaringan yang tangguh dan mudah digunakan untuk Kubernetes dan aplikasi yang dihostingnya. Weave Net berjalan sebagai <a href=https://www.weave.works/docs/net/latest/cni-plugin/>plug-in CNI</a> atau berdiri sendiri. Di kedua versi, itu tidak memerlukan konfigurasi atau kode tambahan untuk dijalankan, dan dalam kedua kasus, jaringan menyediakan satu alamat IP per Pod - seperti standar untuk Kubernetes.</p><h2 id=selanjutnya>Selanjutnya</h2><p>Desain awal model jaringan dan alasannya, dan beberapa rencana masa depan dijelaskan secara lebih rinci dalam <a href=https://git.k8s.io/community/contributors/design-proposals/network/networking.md>dokumen desain jaringan</a>.</p></div><div class=td-content style=page-break-before:always><h1 id=pg-c4b1e87a84441f8a90699a345ce48d68>11.6 - Arsitektur Logging</h1><p>Log aplikasi dan sistem dapat membantu kamu untuk memahami apa yang terjadi di dalam klaster kamu. Log berguna untuk mengidentifikasi dan menyelesaikan masalah serta memonitor aktivitas klaster. Hampir semua aplikasi modern mempunyai sejenis mekanisme log sehingga hampir semua mesin kontainer didesain untuk mendukung suatu mekanisme <em>logging</em>. Metode <em>logging</em> yang paling mudah untuk aplikasi dalam bentuk kontainer adalah menggunakan <em>standard output</em> dan <em>standard error</em>.</p><p>Namun, fungsionalitas bawaan dari mesin kontainer atau <em>runtime</em> biasanya tidak cukup memadai sebagai solusi log. Contohnya, jika sebuah kontainer gagal, sebuah pod dihapus, atau suatu <em>node</em> mati, kamu biasanya tetap menginginkan untuk mengakses log dari aplikasimu. Oleh sebab itu, log sebaiknya berada pada penyimpanan dan <em>lifecyle</em> yang terpisah dari node, pod, atau kontainer. Konsep ini dinamakan sebagai <em>logging</em> pada level klaster. <em>Logging</em> pada level klaster ini membutuhkan <em>backend</em> yang terpisah untuk menyimpan, menganalisis, dan mengkueri log. Kubernetes tidak menyediakan solusi bawaan untuk penyimpanan data log, namun kamu dapat mengintegrasikan beragam solusi <em>logging</em> yang telah ada ke dalam klaster Kubernetes kamu.</p><p>Arsitektur <em>logging</em> pada level klaster yang akan dijelaskan berikut mengasumsikan bahwa sebuah <em>logging backend</em> telah tersedia baik di dalam maupun di luar klastermu. Meskipun kamu tidak tertarik menggunakan <em>logging</em> pada level klaster, penjelasan tentang bagaimana log disimpan dan ditangani pada node di bawah ini mungkin dapat berguna untukmu.</p><h2 id=hal-dasar-logging-pada-kubernetes>Hal dasar <em>logging</em> pada Kubernetes</h2><p>Pada bagian ini, kamu dapat melihat contoh tentang dasar <em>logging</em> pada Kubernetes yang mengeluarkan data pada <em>standard output</em>. Demonstrasi berikut ini menggunakan sebuah <a href=/examples/debug/counter-pod.yaml>spesifikasi pod</a> dengan kontainer yang akan menuliskan beberapa teks ke <em>standard output</em> tiap detik.</p><div class=highlight><div class=copy-code-icon style=text-align:right><a href=https://raw.githubusercontent.com/kubernetes/website/main/content/id/examples/debug/counter-pod.yaml download=debug/counter-pod.yaml><code>debug/counter-pod.yaml</code></a>
<img src=/images/copycode.svg style=max-height:24px;cursor:pointer onclick='copyCode("debug-counter-pod-yaml")' title="Copy debug/counter-pod.yaml to clipboard"></img></div><div class=includecode id=debug-counter-pod-yaml><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>counter<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>count<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>busybox<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>args</span>:<span style=color:#bbb> </span>[/bin/sh, -c,<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>            </span><span style=color:#b44>&#39;i=0; while true; do echo &#34;$i: $(date)&#34;; i=$((i+1)); sleep 1; done&#39;</span>]<span style=color:#bbb>
</span></span></span></code></pre></div></div></div><p>Untuk menjalankan pod ini, gunakan perintah berikut:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl apply -f https://k8s.io/examples/debug/counter-pod.yaml
</span></span></code></pre></div><p>Keluarannya adalah:</p><pre tabindex=0><code>pod/counter created
</code></pre><p>Untuk mengambil log, gunakan perintah <code>kubectl logs</code> sebagai berikut:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl logs counter
</span></span></code></pre></div><p>Keluarannya adalah:</p><pre tabindex=0><code>0: Mon Jan  1 00:00:00 UTC 2001
1: Mon Jan  1 00:00:01 UTC 2001
2: Mon Jan  1 00:00:02 UTC 2001
...
</code></pre><p>Kamu dapat menambahkan parameter <code>--previous</code> pada perintah <code>kubectl logs</code> untuk mengambil log dari kontainer sebelumnya yang gagal atau <em>crash</em>. Jika pod kamu memiliki banyak kontainer, kamu harus menspesifikasikan kontainer mana yang kamu ingin akses lognya dengan menambahkan nama kontainer pada perintah tersebut. Lihat <a href=/docs/reference/generated/kubectl/kubectl-commands#logs>dokumentasi <code>kubectl logs</code></a> untuk informasi lebih lanjut.</p><h2 id=node-level-logging>Node-level <em>logging</em></h2><p><img src=/images/docs/user-guide/logging/logging-node-level.png alt="Node-level logging"></p><p>Semua hal yang ditulis oleh aplikasi dalam kontainer ke <code>stdout</code> dan <code>stderr</code> akan ditangani dan diarahkan ke suatu tempat oleh mesin atau <em>engine</em> kontainer. Contohnya,mesin kontainer Docker akan mengarahkan kedua aliran tersebut ke <a href=https://docs.docker.com/engine/admin/logging/overview>suatu <em>logging driver</em></a>, yang akan dikonfigurasi pada Kubernetes untuk menuliskan ke dalam berkas dalam format json.</p><div class="alert alert-info note callout" role=alert><strong>Catatan:</strong> <em>Logging driver</em> json dari Docker memperlakukan tiap baris sebagai pesan yang terpisah. Saat menggunakan <em>logging driver</em> Docker, tidak ada dukungan untuk menangani pesan <em>multi-line</em>. Kamu harus menangani pesan <em>multi-line</em> pada level agen log atau yang lebih tinggi.</div><p>Secara <em>default</em>, jika suatu kontainer <em>restart</em>, kubelet akan menjaga kontainer yang mati tersebut beserta lognya. Namun jika suatu pod dibuang dari <em>node</em>, maka semua hal dari kontainernya juga akan dibuang, termasuk lognya.</p><p>Hal lain yang perlu diperhatikan dalam <em>logging</em> pada level <em>node</em> adalah implementasi rotasi log, sehingga log tidak menghabiskan semua penyimpanan yang tersedia pada <em>node.</em> Kubernetes saat ini tidak bertanggung jawab dalam melakukan rotasi log, namun <em>deployment tool</em> seharusnya memberikan solusi terhadap masalah tersebut.
Contohnya, pada klaster Kubernetes, yang di <em>deployed</em> menggunakan <code>kube-up.sh</code>, terdapat alat bernama <a href=https://linux.die.net/man/8/logrotate><code>logrotate</code></a> yang dikonfigurasi untuk berjalan tiap jamnya. Kamu juga dapat menggunakan <em>runtime</em> kontainer untuk melakukan rotasi log otomatis, misalnya menggunakan <code>log-opt</code> Docker.
Pada <code>kube-up.sh</code>, metode terakhir digunakan untuk COS <em>image</em> pada GCP, sedangkan metode pertama digunakan untuk lingkungan lainnya. Pada kedua metode, secara <em>default</em> akan dilakukan rotasi pada saat berkas log melewati 10MB.</p><p>Sebagai contoh, kamu dapat melihat informasi lebih rinci tentang bagaimana <code>kube-up.sh</code> mengatur <em>logging</em> untuk COS <em>image</em> pada GCP yang terkait dengan <a href=https://github.com/kubernetes/kubernetes/blob/main/cluster/gce/gci/configure-helper.sh><em>script</em></a>.</p><p>Saat kamu menjalankan perintah <a href=/docs/reference/generated/kubectl/kubectl-commands#logs><code>kubectl logs</code></a> seperti pada contoh tadi, kubelet di <em>node</em> tersebut akan menangani permintaan untuk membaca langsung isi berkas log sebagai respon.</p><div class="alert alert-info note callout" role=alert><strong>Catatan:</strong> Saat ini, jika suatu sistem eksternal telah melakukan rotasi, hanya konten dari berkas log terbaru yang akan tersedia melalui perintah <code>kubectl logs</code>. Contoh, jika terdapat sebuah berkas 10MB, <code>logrotate</code> akan melakukan rotasi sehingga akan ada dua buah berkas, satu dengan ukuran 10MB, dan satu berkas lainnya yang kosong. Maka <code>kubectl logs</code> akan mengembalikan respon kosong.</div><h3 id=komponen-sistem-log>Komponen sistem log</h3><p>Terdapat dua jenis komponen sistem: yaitu yang berjalan di dalam kontainer dan komponen lain yang tidak berjalan di dalam kontainer. Sebagai contoh:</p><ul><li>Kubernetes <em>scheduler</em> dan kube-proxy berjalan di dalam kontainer.</li><li>Kubelet dan <em>runtime</em> kontainer, contohnya Docker, tidak berjalan di dalam kontainer.</li></ul><p>Pada mesin yang menggunakan systemd, kubelet dan runtime <em>runtime</em> menulis ke journald. Jika systemd tidak tersedia, keduanya akan menulis ke berkas <code>.log</code> pada folder <code>/var/log</code>.
Komponen sistem di dalam kontainer akan selalu menuliskan ke folder <code>/var/log</code>, melewati mekanisme <em>default logging</em>. Mereka akan menggunakan <em>logging library</em> <a href=https://github.com/kubernetes/klog>klog</a>.
Kamu dapat menemukan konvensi tentang tingkat kegawatan <em>logging</em> untuk komponen-komponen tersebut pada <a href=https://github.com/kubernetes/community/blob/master/contributors/devel/sig-instrumentation/logging.md>dokumentasi <em>development logging</em></a>.</p><p>Seperti halnya pada log kontainer, komponen sistem yang menuliskan log pada folder <code>/var/log</code> juga harus melakukan rotasi log. Pada klaster Kubernetes yang menggunakan <code>kube-up.sh</code>, log tersebut telah dikonfigurasi dan akan dirotasi oleh <code>logrotate</code> secara harian atau saat ukuran log melebihi 100MB.</p><h2 id=arsitektur-klaster-level-logging>Arsitektur klaster-level <em>logging</em></h2><p>Meskipun Kubernetes tidak menyediakan solusi bawaan untuk <em>logging</em> level klaster, ada beberapa pendekatan yang dapat kamu pertimbangkan. Berikut beberapa diantaranya:</p><ul><li>Menggunakan agen <em>logging</em> pada level <em>node</em> yang berjalan pada setiap <em>node</em>.</li><li>Menggunakan kontainer <em>sidecar</em> khusus untuk <em>logging</em> aplikasi di dalam pod.</li><li>Mengeluarkan log langsung ke <em>backend</em> dari dalam aplikasi</li></ul><h3 id=menggunakan-agen-node-level-logging>Menggunakan agen node-level <em>logging</em></h3><p><img src=/images/docs/user-guide/logging/logging-with-node-agent.png alt="Menggunakan agen node-level logging"></p><p>Kamu dapat mengimplementasikan klaster-level <em>logging</em> dengan menggunakan agen yang berjalan pada setiap <em>node</em>. Agen <em>logging</em> merupakan perangkat khusus yang akan mengekspos log atau mengeluarkan log ke <em>backend</em>. Umumnya agen <em>logging</em> merupakan kontainer yang memiliki akses langsung ke direktori tempat berkas log berada dari semua kontainer aplikasi yang berjalan pada <em>node</em> tersebut.</p><p>Karena agen <em>logging</em> harus berjalan pada setiap <em>node</em>, umumnya dilakukan dengan menggunakan replika DaemonSet, <em>manifest</em> pod, atau menjalankan proses khusus pada <em>node</em>. Namun dua cara terakhir sudah dideprekasi dan sangat tidak disarankan.</p><p>Menggunakan agen <em>logging</em> pada level <em>node</em> merupakan cara yang paling umum dan disarankan untuk klaster Kubernetes. Hal ini karena hanya dibutuhkan satu agen tiap node dan tidak membutuhkan perubahan apapun dari sisi aplikasi yang berjalan pada <em>node</em>. Namun, node-level <em>logging</em> hanya dapat dilakukan untuk aplikasi yang menggunakan <em>standard output</em> dan <em>standard error</em>.</p><p>Kubernetes tidak menspesifikasikan khusus suatu agen <em>logging</em>, namun ada dua agen <em>logging</em> yang dimasukkan dalam rilis Kubernetes: <a href=/docs/user-guide/logging/stackdriver>Stackdriver Logging</a> untuk digunakan pada Google Cloud Platform, dan <a href=/docs/user-guide/logging/elasticsearch>Elasticsearch</a>. Kamu dapat melihat informasi dan instruksi pada masing-masing dokumentasi. Keduanya menggunakan <a href=http://www.fluentd.org/>fluentd</a> dengan konfigurasi kustom sebagai agen pada <em>node</em>.</p><h3 id=menggunakan-kontainer-sidecar-dengan-agen-logging>Menggunakan kontainer <em>sidecar</em> dengan agen <em>logging</em></h3><p>Kamu dapat menggunakan kontainer <em>sidecar</em> dengan salah satu cara berikut:</p><ul><li>Kontainer <em>sidecar</em> mengeluarkan log aplikasi ke <code>stdout</code> miliknya sendiri.</li><li>Kontainer <em>sidecar</em> menjalankan agen <em>logging</em> yang dikonfigurasi untuk mengambil log dari aplikasi kontainer.</li></ul><h4 id=kontainer-streaming-sidecar>Kontainer <em>streaming</em> <em>sidecar</em></h4><p><img src=/images/docs/user-guide/logging/logging-with-streaming-sidecar.png alt="Kontainer sidecar dengan kontainer streaming"></p><p>Kamu dapat memanfaatkan kubelet dan agen <em>logging</em> yang telah berjalan pada tiap <em>node</em> dengan menggunakan kontainer <em>sidecar</em>. Kontainer <em>sidecar</em> dapat membaca log dari sebuah berkas, <em>socket</em> atau journald. Tiap kontainer <em>sidecar</em> menuliskan log ke <code>stdout</code> atau <code>stderr</code> mereka sendiri.</p><p>Dengan menggunakan cara ini kamu dapat memisahkan aliran log dari bagian-bagian yang berbeda dari aplikasimu, yang beberapa mungkin tidak mendukung log ke <code>stdout</code> dan <code>stderr</code>. Perubahan logika aplikasimu dengan menggunakan cara ini cukup kecil, sehingga hampir tidak ada <em>overhead</em>. Selain itu, karena <code>stdout</code> dan <code>stderr</code> ditangani oleh kubelet, kamu juga dapat menggunakan alat bawaan seperti <code>kubectl logs</code>.</p><p>Sebagai contoh, sebuah pod berjalan pada satu kontainer tunggal, dan kontainer menuliskan ke dua berkas log yang berbeda, dengan dua format yang berbeda pula. Berikut ini <em>file</em> konfigurasi untuk Pod:</p><div class=highlight><div class=copy-code-icon style=text-align:right><a href=https://raw.githubusercontent.com/kubernetes/website/main/content/id/examples/admin/logging/two-files-counter-pod.yaml download=admin/logging/two-files-counter-pod.yaml><code>admin/logging/two-files-counter-pod.yaml</code></a>
<img src=/images/copycode.svg style=max-height:24px;cursor:pointer onclick='copyCode("admin-logging-two-files-counter-pod-yaml")' title="Copy admin/logging/two-files-counter-pod.yaml to clipboard"></img></div><div class=includecode id=admin-logging-two-files-counter-pod-yaml><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>counter<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>count<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>busybox<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>args</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- /bin/sh<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- -c<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- &gt;<span style=color:#b44;font-style:italic>
</span></span></span><span style=display:flex><span><span style=color:#b44;font-style:italic>      i=0;
</span></span></span><span style=display:flex><span><span style=color:#b44;font-style:italic>      while true;
</span></span></span><span style=display:flex><span><span style=color:#b44;font-style:italic>      do
</span></span></span><span style=display:flex><span><span style=color:#b44;font-style:italic>        echo &#34;$i: $(date)&#34; &gt;&gt; /var/log/1.log;
</span></span></span><span style=display:flex><span><span style=color:#b44;font-style:italic>        echo &#34;$(date) INFO $i&#34; &gt;&gt; /var/log/2.log;
</span></span></span><span style=display:flex><span><span style=color:#b44;font-style:italic>        i=$((i+1));
</span></span></span><span style=display:flex><span><span style=color:#b44;font-style:italic>        sleep 1;
</span></span></span><span style=display:flex><span><span style=color:#b44;font-style:italic>      done</span><span style=color:#bbb>      
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>volumeMounts</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>varlog<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>mountPath</span>:<span style=color:#bbb> </span>/var/log<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>volumes</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>varlog<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>emptyDir</span>:<span style=color:#bbb> </span>{}<span style=color:#bbb>
</span></span></span></code></pre></div></div></div><p>Hal ini akan menyulitkan untuk mengeluarkan log dalam format yang berbeda pada aliran log yang sama, meskipun kamu dapat me-<em>redirect</em> keduanya ke <code>stdout</code> dari kontainer. Sebagai gantinya, kamu dapat menggunakan dua buah kontainer <em>sidecar</em>. Tiap kontainer <em>sidecar</em> dapat membaca suatu berkas log tertentu dari <em>shared volume</em> kemudian mengarahkan log ke <code>stdout</code>-nya sendiri.</p><p>Berikut <em>file</em> konfigurasi untuk pod yang memiliki dua buah kontainer <em>sidecard</em>:</p><div class=highlight><div class=copy-code-icon style=text-align:right><a href=https://raw.githubusercontent.com/kubernetes/website/main/content/id/examples/admin/logging/two-files-counter-pod-streaming-sidecar.yaml download=admin/logging/two-files-counter-pod-streaming-sidecar.yaml><code>admin/logging/two-files-counter-pod-streaming-sidecar.yaml</code></a>
<img src=/images/copycode.svg style=max-height:24px;cursor:pointer onclick='copyCode("admin-logging-two-files-counter-pod-streaming-sidecar-yaml")' title="Copy admin/logging/two-files-counter-pod-streaming-sidecar.yaml to clipboard"></img></div><div class=includecode id=admin-logging-two-files-counter-pod-streaming-sidecar-yaml><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>counter<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>count<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>busybox:1.28<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>args</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- /bin/sh<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- -c<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- &gt;<span style=color:#b44;font-style:italic>
</span></span></span><span style=display:flex><span><span style=color:#b44;font-style:italic>      i=0;
</span></span></span><span style=display:flex><span><span style=color:#b44;font-style:italic>      while true;
</span></span></span><span style=display:flex><span><span style=color:#b44;font-style:italic>      do
</span></span></span><span style=display:flex><span><span style=color:#b44;font-style:italic>        echo &#34;$i: $(date)&#34; &gt;&gt; /var/log/1.log;
</span></span></span><span style=display:flex><span><span style=color:#b44;font-style:italic>        echo &#34;$(date) INFO $i&#34; &gt;&gt; /var/log/2.log;
</span></span></span><span style=display:flex><span><span style=color:#b44;font-style:italic>        i=$((i+1));
</span></span></span><span style=display:flex><span><span style=color:#b44;font-style:italic>        sleep 1;
</span></span></span><span style=display:flex><span><span style=color:#b44;font-style:italic>      done</span><span style=color:#bbb>      
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>volumeMounts</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>varlog<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>mountPath</span>:<span style=color:#bbb> </span>/var/log<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>count-log-1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>busybox:1.28<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>args</span>:<span style=color:#bbb> </span>[/bin/sh, -c, &#39;tail -n+1 -F /var/log/1.log&#39;]<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>volumeMounts</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>varlog<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>mountPath</span>:<span style=color:#bbb> </span>/var/log<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>count-log-2<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>busybox:1.28<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>args</span>:<span style=color:#bbb> </span>[/bin/sh, -c, &#39;tail -n+1 -F /var/log/2.log&#39;]<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>volumeMounts</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>varlog<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>mountPath</span>:<span style=color:#bbb> </span>/var/log<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>volumes</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>varlog<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>emptyDir</span>:<span style=color:#bbb> </span>{}<span style=color:#bbb>
</span></span></span></code></pre></div></div></div><p>Saat kamu menjalankan pod ini, kamu dapat mengakses tiap aliran log secara terpisah dengan menjalankan perintah berikut:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl logs counter count-log-1
</span></span></code></pre></div><pre tabindex=0><code>0: Mon Jan  1 00:00:00 UTC 2001
1: Mon Jan  1 00:00:01 UTC 2001
2: Mon Jan  1 00:00:02 UTC 2001
...
</code></pre><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl logs counter count-log-2
</span></span></code></pre></div><pre tabindex=0><code>Mon Jan  1 00:00:00 UTC 2001 INFO 0
Mon Jan  1 00:00:01 UTC 2001 INFO 1
Mon Jan  1 00:00:02 UTC 2001 INFO 2
...
</code></pre><p>Agen node-level yang terpasang di klastermu akan mengambil aliran log tersebut secara otomatis tanpa perlu melakukan konfigurasi tambahan. Bahkan jika kamu mau, kamu dapat mengonfigurasi agen untuk melakukan <em>parse</em> baris log tergantung dari kontainer sumber awalnya.</p><p>Sedikit catatan, meskipun menggunakan memori dan CPU yang cukup rendah (sekitar beberapa milicore untuk CPU dan beberapa megabytes untuk memori), penulisan log ke <em>file</em> kemudian mengalirkannya ke <code>stdout</code> dapat berakibat penggunaan disk yang lebih besar. Jika kamu memiliki aplikasi yang menuliskan ke <em>file</em> tunggal, umumnya lebih baik menggunakan <code>/dev/stdout</code> sebagai tujuan daripada menggunakan pendekatan dengan kontainer <em>sidecar</em>.</p><p>Kontainer <em>sidecar</em> juga dapat digunakan untuk melakukan rotasi berkas log yang tidak dapat dirotasi oleh aplikasi itu sendiri. Contoh dari pendekatan ini adalah sebuah kontainer kecil yang menjalankan rotasi log secara periodik. Namun, direkomendasikan untuk menggunakan <code>stdout</code> dan <code>stderr</code> secara langsung dan menyerahkan kebijakan rotasi dan retensi pada kubelet.</p><h4 id=kontainer-sidecar-dengan-agen-logging>Kontainer <em>sidecar</em> dengan agen <em>logging</em></h4><p><img src=/images/docs/user-guide/logging/logging-with-sidecar-agent.png alt="Kontainer sidecar dengan agen logging"></p><p>Jika agen node-level <em>logging</em> tidak cukup fleksible untuk kebutuhanmu, kamu dapat membuat kontainer <em>sidecar</em> dengan agen <em>logging</em> yang terpisah, yang kamu konfigurasi spesifik untuk berjalan dengan aplikasimu.</p><div class="alert alert-info note callout" role=alert><strong>Catatan:</strong> Menggunakan agen <em>logging</em> di dalam kontainer <em>sidecar</em> dapat berakibat penggunaan <em>resource</em> yang signifikan. Selain itu, kamu tidak dapat mengakses log itu dengan menggunakan perintah <code>kubectl logs</code>, karena mereka tidak dikontrol oleh kubelet.</div><p>Sebagai contoh, kamu dapat menggunakan <a href=/docs/tasks/debug-application-cluster/logging-stackdriver/>Stackdriver</a>,
yang menggunakan fluentd sebagai agen <em>logging</em>. Berikut ini dua <em>file</em> konfigurasi yang dapat kamu pakai untuk mengimplementasikan cara ini. <em>File</em> yang pertama berisi sebuah <a href=/id/docs/tasks/configure-pod-container/configure-pod-configmap/>ConfigMap</a> untuk mengonfigurasi fluentd.</p><div class=highlight><div class=copy-code-icon style=text-align:right><a href=https://raw.githubusercontent.com/kubernetes/website/main/content/id/examples/admin/logging/fluentd-sidecar-config.yaml download=admin/logging/fluentd-sidecar-config.yaml><code>admin/logging/fluentd-sidecar-config.yaml</code></a>
<img src=/images/copycode.svg style=max-height:24px;cursor:pointer onclick='copyCode("admin-logging-fluentd-sidecar-config-yaml")' title="Copy admin/logging/fluentd-sidecar-config.yaml to clipboard"></img></div><div class=includecode id=admin-logging-fluentd-sidecar-config-yaml><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>ConfigMap<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>fluentd-config<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>data</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>fluentd.conf</span>:<span style=color:#bbb> </span>|<span style=color:#b44;font-style:italic>
</span></span></span><span style=display:flex><span><span style=color:#b44;font-style:italic>    &lt;source&gt;
</span></span></span><span style=display:flex><span><span style=color:#b44;font-style:italic>      type tail
</span></span></span><span style=display:flex><span><span style=color:#b44;font-style:italic>      format none
</span></span></span><span style=display:flex><span><span style=color:#b44;font-style:italic>      path /var/log/1.log
</span></span></span><span style=display:flex><span><span style=color:#b44;font-style:italic>      pos_file /var/log/1.log.pos
</span></span></span><span style=display:flex><span><span style=color:#b44;font-style:italic>      tag count.format1
</span></span></span><span style=display:flex><span><span style=color:#b44;font-style:italic>    &lt;/source&gt;
</span></span></span><span style=display:flex><span><span style=color:#b44;font-style:italic>
</span></span></span><span style=display:flex><span><span style=color:#b44;font-style:italic>    &lt;source&gt;
</span></span></span><span style=display:flex><span><span style=color:#b44;font-style:italic>      type tail
</span></span></span><span style=display:flex><span><span style=color:#b44;font-style:italic>      format none
</span></span></span><span style=display:flex><span><span style=color:#b44;font-style:italic>      path /var/log/2.log
</span></span></span><span style=display:flex><span><span style=color:#b44;font-style:italic>      pos_file /var/log/2.log.pos
</span></span></span><span style=display:flex><span><span style=color:#b44;font-style:italic>      tag count.format2
</span></span></span><span style=display:flex><span><span style=color:#b44;font-style:italic>    &lt;/source&gt;
</span></span></span><span style=display:flex><span><span style=color:#b44;font-style:italic>
</span></span></span><span style=display:flex><span><span style=color:#b44;font-style:italic>    &lt;match **&gt;
</span></span></span><span style=display:flex><span><span style=color:#b44;font-style:italic>      type google_cloud
</span></span></span><span style=display:flex><span><span style=color:#b44;font-style:italic>    &lt;/match&gt;</span><span style=color:#bbb>    
</span></span></span></code></pre></div></div></div><div class="alert alert-info note callout" role=alert><strong>Catatan:</strong> Konfigurasi fluentd berada diluar cakupan artikel ini. Untuk informasi lebih lanjut tentang cara mengonfigurasi fluentd, silakan lihat <a href=http://docs.fluentd.org/>dokumentasi resmi fluentd </a>.</div><p><em>File</em> yang kedua mendeskripsikan sebuah pod yang memiliki kontainer <em>sidecar</em> yang menjalankan fluentd. Pod ini melakukan <em>mount</em> sebuah volume yang akan digunakan fluentd untuk mengambil data konfigurasinya.</p><div class=highlight><div class=copy-code-icon style=text-align:right><a href=https://raw.githubusercontent.com/kubernetes/website/main/content/id/examples/admin/logging/two-files-counter-pod-agent-sidecar.yaml download=admin/logging/two-files-counter-pod-agent-sidecar.yaml><code>admin/logging/two-files-counter-pod-agent-sidecar.yaml</code></a>
<img src=/images/copycode.svg style=max-height:24px;cursor:pointer onclick='copyCode("admin-logging-two-files-counter-pod-agent-sidecar-yaml")' title="Copy admin/logging/two-files-counter-pod-agent-sidecar.yaml to clipboard"></img></div><div class=includecode id=admin-logging-two-files-counter-pod-agent-sidecar-yaml><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>counter<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>count<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>busybox<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>args</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- /bin/sh<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- -c<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- &gt;<span style=color:#b44;font-style:italic>
</span></span></span><span style=display:flex><span><span style=color:#b44;font-style:italic>      i=0;
</span></span></span><span style=display:flex><span><span style=color:#b44;font-style:italic>      while true;
</span></span></span><span style=display:flex><span><span style=color:#b44;font-style:italic>      do
</span></span></span><span style=display:flex><span><span style=color:#b44;font-style:italic>        echo &#34;$i: $(date)&#34; &gt;&gt; /var/log/1.log;
</span></span></span><span style=display:flex><span><span style=color:#b44;font-style:italic>        echo &#34;$(date) INFO $i&#34; &gt;&gt; /var/log/2.log;
</span></span></span><span style=display:flex><span><span style=color:#b44;font-style:italic>        i=$((i+1));
</span></span></span><span style=display:flex><span><span style=color:#b44;font-style:italic>        sleep 1;
</span></span></span><span style=display:flex><span><span style=color:#b44;font-style:italic>      done</span><span style=color:#bbb>      
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>volumeMounts</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>varlog<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>mountPath</span>:<span style=color:#bbb> </span>/var/log<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>count-agent<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>k8s.gcr.io/fluentd-gcp:1.30<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>env</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>FLUENTD_ARGS<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>value</span>:<span style=color:#bbb> </span>-c /etc/fluentd-config/fluentd.conf<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>volumeMounts</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>varlog<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>mountPath</span>:<span style=color:#bbb> </span>/var/log<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>config-volume<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>mountPath</span>:<span style=color:#bbb> </span>/etc/fluentd-config<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>volumes</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>varlog<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>emptyDir</span>:<span style=color:#bbb> </span>{}<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>config-volume<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>configMap</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>fluentd-config<span style=color:#bbb>
</span></span></span></code></pre></div></div></div><p>Setelah beberapa saat, kamu akan mendapati pesan log pada <em>interface</em> Stackdriver.</p><p>Ingat, ini hanya contoh saja dan kamu dapat mengganti fluentd dengan agen <em>logging</em> lainnya, yang dapat membaca sumber apa saja dari dalam kontainer aplikasi.</p><h3 id=mengekspos-log-langsung-dari-aplikasi>Mengekspos log langsung dari aplikasi</h3><p><img src=/images/docs/user-guide/logging/logging-from-application.png alt="Mengekspos log langsung dari aplikasi"></p><p>Kamu dapat mengimplementasikan klaster-level <em>logging</em> dengan mengekspos atau mengeluarkan log langsung dari tiap aplikasi; namun cara implementasi mekanisme <em>logging</em> tersebut diluar cakupan dari Kubernetes.</p></div><div class=td-content style=page-break-before:always><h1 id=pg-cbfd3654996eae9fcdef009f70fa83f0>11.7 - Metrik untuk Komponen Sistem Kubernetes</h1><p>Metrik dari komponen sistem dapat memberikan gambaran yang lebih baik tentang apa
yang sedang terjadi di dalam sistem. Metrik sangat berguna untuk membuat dasbor (<em>dashboard</em>)
dan peringatan (<em>alert</em>).</p><p>Komponen Kubernetes mengekspos metrik dalam <a href=https://prometheus.io/docs/instrumenting/exposition_formats/>format Prometheus</a>.
Format ini berupa teks biasa yang terstruktur, dirancang agar orang dan mesin dapat membacanya.</p><h2 id=metrik-metrik-dalam-kubernetes>Metrik-metrik dalam Kubernetes</h2><p>Dalam kebanyakan kasus, metrik tersedia pada <em>endpoint</em> <code>/metrics</code> dari server HTTP.
Untuk komponen yang tidak mengekspos <em>endpoint</em> secara bawaan, <em>endpoint</em> tersebut dapat diaktifkan
dengan menggunakan opsi <code>--bind-address</code>.</p><p>Contoh-contoh untuk komponen tersebut adalah:</p><ul><li><a class=glossary-tooltip title='Komponen control plane yang menjalankan pengontrol.' data-toggle=tooltip data-placement=top href=/docs/reference/generated/kube-controller-manager/ target=_blank aria-label=kube-controller-manager>kube-controller-manager</a></li><li><a class=glossary-tooltip title='kube-proxy merupakan proksi jaringan yang berjalan pada setiap node di dalam klaster.' data-toggle=tooltip data-placement=top href=/docs/reference/command-line-tools-reference/kube-proxy/ target=_blank aria-label=kube-proxy>kube-proxy</a></li><li><a class=glossary-tooltip title='Komponen control plane yang mengekspos API Kubernetes. Merupakan front-end dari control plane Kubernetes.' data-toggle=tooltip data-placement=top href=/docs/reference/generated/kube-apiserver/ target=_blank aria-label=kube-apiserver>kube-apiserver</a></li><li><a class=glossary-tooltip title='Komponen control plane yang bertugas mengamati Pod baru yang belum ditempatkan di node manapun dan kemudian memilihkan node di mana Pod baru tersebut akan dijalankan.' data-toggle=tooltip data-placement=top href=/docs/reference/generated/kube-scheduler/ target=_blank aria-label=kube-scheduler>kube-scheduler</a></li><li><a class=glossary-tooltip title='Agen yang dijalankan pada setiap node di klaster yang bertugas untuk memastikan kontainer dijalankan di dalam Pod.' data-toggle=tooltip data-placement=top href=/docs/reference/generated/kubelet target=_blank aria-label=kubelet>kubelet</a></li></ul><p>Di dalam lingkungan produksi, kamu mungkin ingin mengonfigurasi <a href=https://prometheus.io/>Server Prometheus</a>
atau pengambil metrik (<em>metrics scraper</em>) lainnya untuk mengumpulkan metrik-metrik ini secara berkala
dan membuatnya tersedia dalam semacam pangkalan data deret waktu (<em>time series database</em>).</p><p>Perlu dicatat bahwa <a class=glossary-tooltip title='Agen yang dijalankan pada setiap node di klaster yang bertugas untuk memastikan kontainer dijalankan di dalam Pod.' data-toggle=tooltip data-placement=top href=/docs/reference/generated/kubelet target=_blank aria-label=kubelet>kubelet</a>
juga mengekspos metrik pada <em>endpoint-endpoint</em> seperti <code>/metrics/cadvisor</code>,
<code>/metrics/resource</code> dan <code>/metrics/probes</code>. Metrik-metrik tersebut tidak memiliki
siklus hidup yang sama.</p><p>Jika klastermu menggunakan <a class=glossary-tooltip title='Mengelola keputusan otorisasi, memungkinkan admin untuk mengonfigurasi kebijakan akses secara dinamis melalui API Kubernetes.' data-toggle=tooltip data-placement=top href=/id/docs/reference/access-authn-authz/rbac/ target=_blank aria-label=RBAC>RBAC</a>,
maka membaca metrik memerlukan otorisasi melalui <em>user</em>, <em>group</em>, atau
ServiceAccount dengan ClusterRole yang memperbolehkan untuk mengakses <code>/metrics</code>.</p><p>Sebagai contoh:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>rbac.authorization.k8s.io/v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>ClusterRole<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>prometheus<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>rules</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>nonResourceURLs</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- <span style=color:#b44>&#34;/metrics&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>verbs</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>- get<span style=color:#bbb>
</span></span></span></code></pre></div><h2 id=siklus-hidup-metrik>Siklus hidup metrik</h2><p>Metrik alfa (<em>alpha</em>) → Metrik stabil → Metrik usang (<em>deprecated</em>) → Metrik tersembunyi → Metrik terhapus</p><p>Metrik alfa tidak memiliki jaminan stabilitas. Metrik ini
dapat dimodifikasi atau dihapus kapan saja.</p><p>Metrik stabil dijamin tidak akan mengalami perubahan. Hal ini berarti:</p><ul><li>Metrik stabil tanpa penanda usang (<em>deprecated signature</em>) tidak akan dihapus ataupun diganti namanya</li><li>Jenis metrik stabil tidak akan dimodifikasi</li></ul><p>Metrik usang dijadwalkan untuk dihapus, tetapi masih tersedia untuk digunakan.
Metrik ini mencakup anotasi versi di mana metrik ini dianggap menjadi usang.</p><p>Sebagai contoh:</p><ul><li><p>Sebelum menjadi usang</p><pre tabindex=0><code># HELP some_counter this counts things
# TYPE some_counter counter
some_counter 0
</code></pre></li><li><p>Setelah menjadi usang</p><pre tabindex=0><code># HELP some_counter (Deprecated since 1.15.0) this counts things
# TYPE some_counter counter
some_counter 0
</code></pre></li></ul><p>Metrik tersembunyi tidak lagi dipublikasikan untuk pengambilan metrik (<em>scraping</em>), tetapi masih tersedia untuk digunakan. Untuk menggunakan metrik tersembunyi, lihat bagian <a href=#menampilkan-metrik-tersembunyi>Menampilkan metrik tersembunyi</a>.</p><p>Metrik yang terhapus tidak lagi dipublikasikan dan tidak dapat digunakan lagi.</p><h2 id=menampilkan-metrik-tersembunyi>Menampilkan metrik tersembunyi</h2><p>Seperti yang dijelaskan di atas, admin dapat mengaktifkan metrik tersembunyi melalui opsi baris perintah pada biner (program) tertentu. Ini dimaksudkan untuk digunakan sebagai jalan keluar bagi admin jika mereka melewatkan migrasi metrik usang dalam rilis terakhir.</p><p>Opsi <code>show-hidden-metrics-for-version</code> menerima input versi yang kamu inginkan untuk menampilkan metrik usang dalam rilis tersebut. Versi tersebut dinyatakan sebagai x.y, di mana x adalah versi mayor, y adalah versi minor. Versi <em>patch</em> tidak diperlukan meskipun metrik dapat menjadi usang dalam rilis <em>patch</em>, alasannya adalah kebijakan penandaan metrik usang dijalankan terhadap rilis minor.</p><p>Opsi tersebut hanya dapat menerima input versi minor sebelumnya sebagai nilai. Semua metrik yang disembunyikan di versi sebelumnya akan dikeluarkan jika admin mengatur versi sebelumnya ke <code>show-hidden-metrics-for-version</code>. Versi yang terlalu lama tidak diperbolehkan karena melanggar kebijakan untuk metrik usang.</p><p>Ambil metrik <code>A</code> sebagai contoh, di sini diasumsikan bahwa <code>A</code> sudah menjadi usang di versi 1.n. Berdasarkan kebijakan metrik usang, kita dapat mencapai kesimpulan berikut:</p><ul><li>Pada rilis <code>1.n</code>, metrik menjadi usang, dan dapat dikeluarkan secara bawaan.</li><li>Pada rilis <code>1.n+1</code>, metrik disembunyikan secara bawaan dan dapat dikeluarkan dengan baris perintah <code>show-hidden-metrics-for-version=1.n</code>.</li><li>Pada rilis <code>1.n+2</code>, metrik harus dihapus dari <em>codebase</em>. Tidak ada jalan keluar lagi.</li></ul><p>Jika kamu meningkatkan versi dari rilis <code>1.12</code> ke <code>1.13</code>, tetapi masih bergantung pada metrik <code>A</code> yang usang di <code>1.12</code>, kamu harus mengatur metrik tersembunyi melalui baris perintah: <code>--show-hidden-metrics = 1.12</code> dan ingatlah untuk menghapus ketergantungan terhadap metrik ini sebelum meningkatkan versi rilis ke <code>1.14</code>.</p><h2 id=menonaktifkan-metrik-akselerator>Menonaktifkan metrik akselerator</h2><p>kubelet mengumpulkan metrik akselerator melalui cAdvisor. Untuk mengumpulkan metrik ini, untuk akselerator seperti GPU NVIDIA, kubelet membuka koneksi dengan <em>driver</em> GPU. Ini berarti untuk melakukan perubahan infrastruktur (misalnya, pemutakhiran <em>driver</em>), administrator klaster perlu menghentikan agen kubelet.</p><p>Pengumpulkan metrik akselerator sekarang menjadi tanggung jawab vendor dibandingkan kubelet. Vendor harus menyediakan sebuah kontainer untuk mengumpulkan metrik dan mengeksposnya ke layanan metrik (misalnya, Prometheus).</p><p><a href=/docs/reference/command-line-tools-reference/feature-gates/>Gerbang fitur <code>DisableAcceleratorUsageMetrics</code></a> menonaktifkan metrik yang dikumpulkan oleh kubelet, dengan <a href=https://github.com/kubernetes/enhancements/tree/411e51027db842355bd489691af897afc1a41a5e/keps/sig-node/1867-disable-accelerator-usage-metrics#graduation-criteria>lini masa (<em>timeline</em>) untuk mengaktifkan fitur ini secara bawaan</a>.</p><h2 id=metrik-komponen>Metrik komponen</h2><h3 id=metrik-kube-controller-manager>Metrik kube-controller-manager</h3><p>Metrik <em>controller manager</em> memberikan gambaran penting
tentang kinerja dan kesehatan <em>controller manager</em>. Metrik ini mencakup metrik
<em>runtime</em> bahasa Go yang umum seperti jumlah go_routine dan metrik khusus
pengontrol seperti latensi permintaan etcd atau latensi API Cloudprovider
(AWS, GCE, OpenStack) yang dapat digunakan untuk mengukur kesehatan klaster.</p><p>Mulai dari Kubernetes 1.7, metrik Cloudprovider yang detail tersedia untuk
operasi penyimpanan untuk GCE, AWS, Vsphere, dan OpenStack.
Metrik ini dapat digunakan untuk memantau kesehatan operasi <em>persistent volume</em>.</p><p>Misalnya, untuk GCE metrik-metrik berikut ini dipanggil:</p><pre tabindex=0><code>cloudprovider_gce_api_request_duration_seconds { request = &#34;instance_list&#34;}
cloudprovider_gce_api_request_duration_seconds { request = &#34;disk_insert&#34;}
cloudprovider_gce_api_request_duration_seconds { request = &#34;disk_delete&#34;}
cloudprovider_gce_api_request_duration_seconds { request = &#34;attach_disk&#34;}
cloudprovider_gce_api_request_duration_seconds { request = &#34;detach_disk&#34;}
cloudprovider_gce_api_request_duration_seconds { request = &#34;list_disk&#34;}
</code></pre><h3 id=metrik-kube-scheduler>Metrik kube-scheduler</h3><div style=margin-top:10px;margin-bottom:10px><b>FEATURE STATE:</b> <code>Kubernetes v1.20 [alpha]</code></div><p>Penjadwal mengekspos metrik opsional yang melaporkan sumber daya yang diminta dan limit yang diinginkan dari semua pod yang berjalan. Metrik ini dapat digunakan untuk membangun dasbor perencanaan kapasitas, mengevaluasi limit penjadwalan yang digunakan saat ini atau secara historis, dengan cepat mengidentifikasi beban kerja yang tidak dapat dijadwalkan karena kurangnya sumber daya, dan membandingkan permintaan sumber daya oleh pod dengan penggunaannya yang aktual.</p><p>kube-scheduler mengidentifikasi <a href=/docs/concepts/configuration/manage-resources-containers/>permintaan dan limit</a> sumber daya yang dikonfigurasi untuk setiap Pod; jika permintaan atau limit bukan nol, kube-scheduler akan melaporkan deret waktu (<em>timeseries</em>) metrik. Deret waktu diberi label dengan:</p><ul><li>namespace</li><li>nama pod</li><li>node di mana pod dijadwalkan atau <em>string</em> kosong jika belum dijadwalkan</li><li>prioritas</li><li>penjadwal yang ditugaskan untuk pod itu</li><li>nama dari sumber daya (misalnya, <code>cpu</code>)</li><li>satuan dari sumber daya jika diketahui (misalnya, <code>cores</code>)</li></ul><p>Setelah pod selesai (memiliki <code>restartPolicy</code> <code>Never</code> atau <code>OnFailure</code> dan berada dalam fase pod <code>Succeeded</code> atau <code>Failed</code>, atau telah dihapus dan semua kontainer dalam keadaan Terminated) deret metrik tidak lagi dilaporkan karena penjadwal sekarang sudah dibebaskan untuk menjadwalkan pod lain untuk dijalankan. Metrik yang dibahas pada bagian ini dikenal sebagai <code>kube_pod_resource_request</code> dan <code>kube_pod_resource_limit</code>.</p><p>Metrik diekspos melalui <em>endpoint</em> HTTP <code>/metrics/resources</code> dan memerlukan otorisasi yang sama seperti endpoint <code>/metrics</code>
pada penjadwal. Kamu harus menggunakan opsi <code>--show-hidden-metrics-for-version=1.20</code> untuk mengekspos metrik-metrik stabilitas alfa ini.</p><h2 id=selanjutnya>Selanjutnya</h2><ul><li>Baca tentang <a href=https://github.com/prometheus/docs/blob/master/content/docs/instrumenting/exposition_formats.md#text-based-format>format teks Prometheus</a> untuk berbagai metrik</li><li>Baca tentang <a href=/docs/reference/using-api/deprecation-policy/#deprecating-a-feature-or-behavior>kebijakan <em>deprecation</em> Kubernetes</a></li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-2e05a56491965ae320c2662590b2ca18>11.8 - Konfigurasi Garbage Collection pada kubelet</h1><p><em>Garbage collection</em> merupakan fitur kubelet yang sangat bermanfaat, yang akan membersihkan <em>image-image</em> dan juga kontainer-kontainer
yang tidak lagi digunakan. Kubelet akan melakukan <em>garbage collection</em> untuk kontainer setiap satu menit dan <em>garbage collection</em> untuk
<em>image</em> setiap lima menit.</p><p>Perangkat <em>garbage collection</em> eksternal tidak direkomendasikan karena perangkat tersebut berpotensi merusak perilaku kubelet dengan
menghilangkan kontainer-kontainer yang sebenarnya masih diperlukan.</p><h2 id=garbage-collection-untuk-image><em>Garbage Collection</em> untuk <em>Image</em></h2><p>Kubernetes mengelola <em>lifecycle</em> untuk seluruh <em>image</em> melalui <em>imageManager</em>, dengan bantuan cadvisor.</p><p><em>Policy</em> untuk melakukan <em>garbage collection</em> memperhatikan dua hal: <code>HighThresholdPercent</code> dan <code>LowThresholdPercent</code>.
Penggunaan disk yang melewati batas atas (<em>high threshold</em>) akan men-<em>trigger</em> <em>garbage collection</em>.
<em>Garbage collection</em> akan mulai menghapus dari <em>image-image</em> yang paling jarang digunakan (<em>least recently used</em>)
sampai menemui batas bawah (<em>low threshold</em>) kembali.</p><h2 id=garbage-collection-untuk-kontainer><em>Garbage Collection</em> untuk Kontainer</h2><p><em>Policy</em> untuk melakukan <em>garbage collection</em> pada kontainer memperhatikan tiga variabel yang ditentukan oleh pengguna (<em>user-defined</em>).
<code>MinAge</code> merupakan umur minimal dimana suatu kontainer dapat terkena <em>garbage collection</em>.
<code>MaxPerPodContainer</code> merupakan jumlah maksimum yang diperbolehkan untuk setiap pod (UID, container name) <em>pair</em> memiliki
kontainer-kontainer yang sudah mati (<em>dead containers</em>). <code>MaxContainers</code> merupakan jumlah maksimal total dari seluruh kontainer yang sudah mati.
Semua variabel ini dapat dinonaktifkan secara individual, dengan mengatur <code>MinAge</code> ke angka nol serta mengatur <code>MaxPerPodContainer</code> dan <code>MaxContainers</code>
ke angka di bawah nol.</p><p>Kubelet akan mengambil tindakan untuk kontainer-kontainer yang tidak dikenal, sudah dihapus, atau diluar batasan-batasan yang diatur
sebelumnya melalui <em>flag</em>. Kontainer-kontainer yang paling lama (tertua) biasanya akan dihapus terlebih dahulu. <code>MaxPerPodContainer</code> dan <code>MaxContainer</code>
berpotensi mengalami konflik satu sama lain pada situasi saat menjaga jumlah maksimal kontainer per pod (<code>MaxPerPodContainer</code>) akan melebihi
jumlah kontainer mati (<em>dead containers</em>) yang diperbolehkan (<code>MaxContainers</code>).
<code>MaxPerPodContainer</code> dapat diatur sedemikian rupa dalam situasi ini: Seburuk-buruhknya dengan melakukan <em>downgrade</em> <code>MaxPerPodContainer</code> ke angka 1
dan melakukan <em>evict</em> kontainer-kontainer yang paling lama. Selain itu, kontainer-kontainer milik Pod yang telah dihapus akan dihilangkan
saat umur mereka telah melebihi <code>MinAge</code>.</p><p>Kontainer-kontainer yang tidak dikelola oleh kubelet akan terbebas dari <em>garbage collection</em>.</p><h2 id=konfigurasi-pengguna>Konfigurasi Pengguna</h2><p>Para pengguna dapat mengatur <em>threshold-threshold</em> untuk melakukan <em>tuning</em> pada <em>garbage collection image</em>
melalui <em>flag-flag</em> kubelet sebagai berikut:</p><ol><li><code>image-gc-high-threshold</code>, persentase dari penggunaan disk yang men-<em>trigger</em> proses <em>garbage collection</em> untuk <em>image</em>.
<em>Default</em>-nya adalah 85%.</li><li><code>image-gc-low-threshold</code>, persentase dari penggunaan disk dimana <em>garbage collection</em> berusaha menghapus <em>image</em>.
<em>Default</em>-nya adalah 80%.</li></ol><p>Kami juga memperbolehkan para pengguna untuk menyesuaikan <em>policy garbage collection</em> melalui
<em>flag-flag</em> kubelet sebagai berikut:</p><ol><li><code>minimum-container-ttl-duration</code>, umur minimal untuk setiap kontainer yang sudah selesai (<em>finished</em>) sebelum
terkena <em>garbage collection</em>. <em>Default</em>-nya adalah 0 menit, yang berarti setiap kontainer yang telah selesai akan
terkena <em>garbage collection</em>.</li><li><code>maximum-dead-containers-per-container</code>, jumlah maksimal dari kontainer-kontainer lama yang diperbolehkan ada
secara global. <em>Default</em>-nya adalah -1, yang berarti tidak ada batasannya untuk global.</li></ol><p>Kontainer-kontainer dapat berpotensi terkena <em>garbage collection</em> sebelum kegunaannya telah usang. Kontainer-kontainer
ini memliki log dan data lainnya yang bisa saja berguna saat <em>troubleshoot</em>. Sangat direkomendasikan untuk menetapkan
angka yang cukup besar pada <code>maximum-dead-containers-per-container</code>, untuk memperbolehkan paling tidak 1 kontainer mati
untuk dijaga (<em>retained</em>) per jumlah kontainer yang diharapkan. Angka yang lebih besar untuk <code>maximum-dead-containers</code>
juga direkomendasikan untuk alasan serupa.
Lihat <a href=https://github.com/kubernetes/kubernetes/issues/13287>isu ini</a> untuk penjelasan lebih lanjut.</p><h2 id=deprecation><em>Deprecation</em></h2><p>Beberapa fitur <em>Garbage Collection</em> pada kubelet di laman ini akan digantikan oleh fitur <em>eviction</em> nantinya, termasuk:</p><table><thead><tr><th><em>Flag Existing</em></th><th><em>Flag</em> Baru</th><th>Alasan</th></tr></thead><tbody><tr><td><code>--image-gc-high-threshold</code></td><td><code>--eviction-hard</code> atau <code>--eviction-soft</code></td><td>sinyal <em>eviction</em> yang ada (<em>existing</em>) dapat men-<em>trigger</em> <em>garbage collection</em></td></tr><tr><td><code>--image-gc-low-threshold</code></td><td><code>--eviction-minimum-reclaim</code></td><td>hal serupa dapat diperoleh dengan <em>eviction reclaim</em></td></tr><tr><td><code>--maximum-dead-containers</code></td><td></td><td><em>deprecated</em> saat log yang telah usang tersimpan di luar konteks kontainer</td></tr><tr><td><code>--maximum-dead-containers-per-container</code></td><td></td><td><em>deprecated</em> saat log yang telah usang tersimpan di luar konteks kontainer</td></tr><tr><td><code>--minimum-container-ttl-duration</code></td><td></td><td><em>deprecated</em> saat log yang telah usang tersimpan di luar konteks kontainer</td></tr><tr><td><code>--low-diskspace-threshold-mb</code></td><td><code>--eviction-hard</code> atau <code>eviction-soft</code></td><td><em>eviction</em> memberi generalisasi <em>threshold</em> disk untuk <em>resource-resource</em> lainnya</td></tr><tr><td><code>--outofdisk-transition-frequency</code></td><td><code>--eviction-pressure-transition-period</code></td><td><em>eviction</em> memberi generalisasi transisi tekanan <em>disk</em> (<em>disk pressure</em>)untuk <em>resource-resource</em> lainnya</td></tr></tbody></table><h2 id=selanjutnya>Selanjutnya</h2><p>Lihat <a href=/docs/tasks/administer-cluster/out-of-resource/>Konfigurasi untuk Menangani Kehabisan <em>Resource</em></a> untuk penjelasan lebih lanjut.</p></div><div class=td-content style=page-break-before:always><h1 id=pg-3003324f360fdacc06ca144e57ff0e97>11.9 - Federation</h1><blockquote class="deprecation_file_warning callout"><div><h4>Sudah usang</h4><p>Penggunaan <code>Federation V1</code> sangat tidak disarankan. <code>Federation V1</code> tidak pernah masuk dalam GA dan tidak lagi dikembangkan secara aktif. Dokumentasi hanya disediakan sebatas data artefak saja.</p><p>Untuk informasi lebih lanjut mengenai hal ini dan penggantinya kamu dapat membaca <a href=https://github.com/kubernetes-sigs/federation-v2>Kubernetes Federation v2</a>.</p></div></blockquote><p>Laman ini menjelaskan alasan dan cara penggunaan <em>federation</em> untuk melakukan manajemen
klaster Kubernetes.</p><h2 id=kenapa-federation>Kenapa <em>Federation</em> ?</h2><p><em>Federation</em> membuat proses manajemen klaster multipel menjadi lebih mudah.
<em>Federation</em> mencapai hal ini dengan cara menyediakan 2 buah fondasi:</p><ul><li>Melakukan sinkronisasi <em>resource</em> di seluruh klaster: <em>Federation</em>
menyediakan kemampuan untuk melakukan sinkronisasi <em>resources</em> pada <em>multiple</em>
klaster. Sebagai contoh, kamu dapat memastikan <em>Deployment</em> yang sama
tersedia pada klaster multipel.</li><li><em>Cross</em> <em>cluster</em> <em>Discovery</em>: <em>Federation</em> menyediakan kemampuan untuk melakukan
konfigurasi otomatis server DNS dan <em>load balancer</em> dari semua klaster.
Misalnya, kamu dapat memastikan bahwa sebuah VIP atau DNS global dapat digunakan
untuk mengakses <em>backend</em> dari klaster multipel.</li></ul><p>Beberapa penggunaan <em>federation</em> adalah sebagai berikut:</p><ul><li><em>High Availability</em>: Melakukan <em>load balance</em> di seluruh klaster serta
melakukan konfigurasi otomatis server DNS dan <em>load balancer</em>, <em>federation</em>
meminimalisasi dampak yang terjadi apabila terjadi kegagalan klaster.</li><li>Mencegah <em>lock-in</em> yang terjadi akibat penyedia layanan: Dengan cara mempermudah
proses migrasi antar klaster.</li></ul><p>Manfaat <em>federation</em> tidak akan terlalu kelihatan kecuali kamu memiliki beberapa klaster.
Beberapa alasan kenapa kamu butuh beberapa klaster adalah:</p><ul><li><em>Latency</em> yang rendah: Memiliki klaster yang berada di <em>region</em> yang berbeda
meminimalisasi <em>latency</em> dengan cara menyajikan konten ke pengguna
berdasarkan <em>region</em> yang paling dekat dengan pengguna tersebut.</li><li>Isolasi <em>fault</em>: Akan lebih baik apabila kita memiliki beberapa klaster kecil
dibandingkan sebuah klaster besar untuk melakukan isolasi <em>fault</em> (misalnya saja
klaster ini bisa saja berada di <em>availability</em> zona dan penyedia layanan <em>cloud</em>
yang berbeda).</li><li>Skalabilitas: Terdapat batasan skalabilitas untuk sebuah klaster Kubernetes,
hal ini sebenarnya tidak menjadi masalah bagi sebagian besar pengguna. Untuk informasi
lebih lanjut kamu bisa membaca
<a href=https://git.k8s.io/community/sig-scalability/goals.md><em>Kubernetes Scaling</em> dan Perencanaan Performa</a>).</li><li><a href=#hybrid-cloud-capabilities><em>Hybrid cloud</em></a>: Kamu dapat memiliki <em>multiple</em> klsuter
pada penyedia layanan <em>cloud</em> yang berbeda ataupun menggunakan <em>on-premsie</em>.</li></ul><h3 id=kekurangan>Kekurangan</h3><p>Meskipun terdapat banyak kelebihan dari penggunaan <em>federation</em>,
terdapat beberapa kekurangan <em>federation</em> yang dijabarkan sebagai berikut:</p><ul><li>Peningkatan <em>bandwidth</em> dan biaya untuk jaringan: <em>control plane</em> <em>federation</em> bertugas mengawasi semua
kulster yang ada untuk menjamin <em>state</em> yang ada saat ini sesuai dengan <em>state</em> yang diinginkan. Hal ini dapat menyebabkan
peningkatan biaya jaringan apabila klaster yang ada dijalankan pada <em>region</em> yang berbeda baik pada penyedia
layanan <em>cloud</em> yang sama maupun berbeda.</li><li>Berkurangnya isolasi antar klaster: Sebuah <em>bug</em> yang ada pada <em>control plane</em> <em>federation</em> dapat
berdampak pada semua klaster. Hal ini dapat dihindari dengan cara mejaga logika yang ada pada <em>control plane</em> <em>federation</em>
seminimum mungkin.</li><li>Kematangan: Proyek <em>federation</em> ini tergolong baru dan belum cukup matang.
Tidak semua <em>resource</em> yang ada tersedia dan masih banyak feature <em>alpha</em>. <a href=https://github.com/kubernetes/federation/issues/88><em>Issue</em>
88</a> memberikan detail
isu-isu terkait sistem yang masih berusaha dicari solusinya.</li></ul><h3 id=kemampuan-hybrid-penggunaan-layanan-penyedian-cloud>Kemampuan <em>Hybrid</em> Penggunaan Layanan Penyedian <em>Cloud</em></h3><p><em>Federation</em> pada Kubernetes memungkinkan klaster untuk dijalankan
pada penyedia layanan <em>cloud</em> yang berbeda (misalnya Google Cloud, AWS), dan <em>on-premise</em>
(misalnya OpenStack). <a href=/docs/tasks/federation/set-up-cluster-federation-kubefed/>Kubefed</a>
adalah salah satu cara yang direkomendasikan untuk melakukan proses <em>deploy</em>
klaster <em>federation</em>.</p><p>Dengan demikian, <a href=#resources-api><em>resources</em> API</a> yang kamu miliki
dapat berada di klaster atau bahkan penyedia layanan <em>cloud</em> yang berbeda.</p><h2 id=mengaktifkan-federation>Mengaktifkan <em>Federation</em></h2><p>Untuk bisa melakukan <em>federation</em> pada klaster yang berbeda,
pertama kamu harus mengaktifkan <em>control plane</em> <em>federation</em>.
Ikuti <a href=/docs/tutorials/federation/set-up-cluster-federation-kubefed/>petunjuk mengaktifkan <em>control plane</em> <em>federation</em></a>
untuk informasi lebih lanjut.</p><h2 id=resources-api><code>Resources</code> API</h2><p>Setelah kamu mengaktifkan <em>control plane</em>, kamu dapat menggunakan <em>resource</em> API <em>federation</em>.
Berikut merupakan panduan yang akan menjelaskan masing-masing <em>resource</em> secara mendetail:</p><ul><li><a href=/docs/tasks/administer-federation/cluster/>Cluster</a></li><li><a href=/docs/tasks/administer-federation/configmap/>ConfigMap</a></li><li><a href=/docs/tasks/administer-federation/daemonset/>DaemonSets</a></li><li><a href=/docs/tasks/administer-federation/deployment/>Deployment</a></li><li><a href=/docs/tasks/administer-federation/events/>Events</a></li><li><a href=/docs/tasks/administer-federation/hpa/>Hpa</a></li><li><a href=/docs/tasks/administer-federation/ingress/>Ingress</a></li><li><a href=/docs/tasks/administer-federation/job/>Jobs</a></li><li><a href=/docs/tasks/administer-federation/namespaces/>Namespaces</a></li><li><a href=/docs/tasks/administer-federation/replicaset/>ReplicaSets</a></li><li><a href=/docs/tasks/administer-federation/secret/>Secrets</a></li><li><a href=/id/docs/concepts/cluster-administration/federation-service-discovery/>Services</a></li></ul><p><a href=/docs/reference/federation/>Referensi Dokumentasi API</a> memberikan semua daftar
<em>resources</em> yang disediakan <em>apiserver</em> <em>federation</em>.</p><h2 id=penghapusan-berantai>Penghapusan Berantai</h2><p>Kubernetes versi 1.6 menyediakan mekanisme penghapusan berantai
untuk <em>resource</em> yang ada pada <em>federation</em>. Dengan penghapusan berantai,
ketika kamu menghapus sebuah <em>resource</em> dari <em>control plane</em> <em>federation</em>,
kamu juga akan menghapus segala <em>resource</em> tersebut pada semua klaster yang ada.</p><p>Mekanisme penghapusan berantai ini tidak diaktifkan secara <em>default</em>
ketika menggunakan REST API. Untuk mengaktifkannya, ubah nilai dari opsi
<code>DeleteOptions.orphanDependents=false</code> ketika kamu menghapus sebuah <em>resource</em>
dari <em>control plane</em> <em>federation</em> dengan menggunakan REST API.
Penggunaan <code>kubectl delete</code>mengaktifkan penhapusan berantai secara <em>default</em>.
Kamu dapat menonaktifkannya dengan menggunakan <code>kubectl delete --cascade=false</code></p><p>Catatan: Kubernetes versi 1.5 menyediakan penghapusan berantai
untuk sebagian <em>resource</em> <em>federation</em>.</p><h2 id=cakupan-dari-sebuah-klaster>Cakupan dari Sebuah Klaster</h2><p>Pada penyedia IaaS seperti Google Compute Engine atau Amazon Web Services, sebuah VM ada di dalam
<a href=https://cloud.google.com/compute/docs/zones>zona</a> atau <a href=http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/using-regions-availability-zones.html><em>availability
zone</em></a>.
Kami menyarankan agar semua VM pada klaster Kubernetes berada pada <em>availability</em> zona yang sama, karena:</p><ul><li>dibandingkan dengan sebuah klaster global Kubernetes, terdapat lebih sedikit <em>single-points of failure</em>.</li><li>dibandingkan dengan sebuah klaster yang tersebar pada <em>availability zone</em> yang mungkin berbeda, akan lebih mudah untuk merencanakan properti <em>availability</em> dari sebuah
klaster yang berada pada satu zona.</li><li>ketika pengembang Kubernetes mendesain sistem (misalnya, memperkirakan <em>latency</em>, <em>bandwidth</em>, atau
<em>failure</em> yang mungkin terjadi) pengembang tersebut memperkirakan semua mesin akan berada pada sebuah <em>data center</em> yang sama, atau setidaknya masih terdapat pada satu wilayah.</li></ul><p>Sangat direkomendasikan untuk menjalankan sedikit klaster dengan lebih banyak VM pada setiap <em>availability</em> zona;
meskipun begitu hal ini tidak menutup kemungkinan untuk menjalankan klaster multipel
pada setiap <em>availability</em> zona.</p><p>Alasan kenapa menjalankan lebih sedikit klaster pada setiap <em>availability</em> zona lebih dianjurkan:</p><ul><li>meningkatkan <em>bin packing</em> <em>Pod</em> pada beberapa kasus dimana terdapat lebih banyak <em>node</em> dalam sebuah klaster (mengurangi terjadinya <em>fragmentation</em> <em>resource</em>).</li><li>mengurangi <em>overhead</em> operasional (meskipun keuntungan ini akan berkurang seiring bertambah matangnya proses dan <em>tooling</em> operasional).</li><li>mengurangi biaya <em>resource</em> tetap per klaster, misalnya VM <em>apiserver</em>.</li></ul><p>Alasan untuk memiliki klaster multipel:</p><ul><li><em>policy</em> kemananan yang ketat membutuhkan isolasi antar <em>work</em> <em>class</em> (baca Partisi Klaster di bawah).</li><li>melakukan penerapan Kubernetes dan/atau perangkat lunak lain yang versi baru ke salah satu klaster.</li></ul><h2 id=memilih-jumlah-klaster-yang-tepat>Memilih jumlah klaster yang tepat</h2><p>Pemilihan jumlah klaster yang tepat merupakan pilihan yang relatif statis, dan hanya akan ditinjau kembali sewaktu-waktu.
Sebaliknya, jumlah <em>node</em> dan <em>pod</em> dalam suatu <em>service</em> dapat berubah secara cepat seiring bertambahnya <em>workload</em>.</p><p>Untuk memilih jumlah klaster, pertama, pilih <em>region</em> yang memiliki <em>latency</em> yang masih dapat dimaklumi untuk semua pengguna aplikasi kamu
(jika kamu menggunakan <em>Content Distribution Network</em>, kebutuhan informasi nilai <em>latency</em> CDN tidak perlu diperhatikan).
Masalah legal juga perlu diperhitungkan. Misalnya sebuah perusahaan dengan pelanggan global bisa jadi memilih klaster di <em>region</em>
US, EU, AP, dan SA. Jumlah <em>region</em> ini dimisalkan dengan <code>R</code>.</p><p>Kedua, pilih berapa banyak klaster yang bisa jadi <em>unavailable</em> secara bersamaan tanpa membuat <em>service</em> menjadi <em>unavailable</em>.
Misalkan jumlah klaster <em>unavailable</em> ini sebagai <code>U</code>. Jika kamu tidak yakin, maka 1 merupakan pilihan yang tergolong
dapat diterima.</p><p>Jika aplikasimu memungkinkan trafik untuk di-<em>load balance</em> ke <em>region</em> mana saja ketika terjadi <em>failure</em> pada klaster,
maka kamu setidaknya membutuhkan nilai yang lebih banyak dari jumlah <code>R</code> atau <code>U + 1</code> klaster. Jika tidak (misalnya, kamu
ingin menjamin stabilnya <em>latency</em> ketika terjadi <em>failure</em> pada klaster) maka kamu membutuhkan <code>R * (U + 1)</code> klaster
(<code>U + 1</code> di setiap <em>region</em> yang ada pada <code>R</code>). Pada kasus lain, cobalah untuk menerapkan satu klaster
pada zona yang berbeda.</p><p>Terakhir, jika klaster yang kamu miliki membutuhkan jumlah <em>node</em> yang melebihi nilai yang direkomendasikan untuk sebuah klaster Kubernetes,
maka kamu membutuhkan lebih banyak klaster. Kubernetes v1.3 mampu menangani hingga 1000 node untuk setiap klaster. Kubernetes v1.8
mampu menangani hingga 5000 node untuk tiap klaster. Baca <a href=/docs/setup/cluster-large/>Membangun Klaster Besar</a> untuk petunjuk lebih lanjut.</p><h2 id=selanjutnya>Selanjutnya</h2><ul><li>Pelajari lebih lanjut tentang <a href=https://github.com/kubernetes/community/blob/main/contributors/design-proposals/multicluster/federation.md>proposal
<em>Federation</em></a>.</li><li>Baca <a href=/docs/tutorials/federation/set-up-cluster-federation-kubefed/>petunjuk pengaktifan</a> klaster <em>federation</em>.</li><li>Lihat <a href="https://www.youtube.com/watch?v=pq9lbkmxpS8">seminar tentang <em>federation</em> pada Kubecon2016</a></li><li>Lihat <a href="https://www.youtube.com/watch?v=kwOvOLnFYck"><em>update</em> <em>federation</em> pada Kubecon2017 Eropa</a></li><li>Lihat <a href="https://www.youtube.com/watch?v=vGZo5DaThQU"><em>update</em> <em>sig-multicluster</em> pada Kubecon2018 Eropa</a></li><li>Lihat <a href="https://youtu.be/q27rbaX5Jis?t=7m20s">presentasi prototipe <em>Federation-v2</em> pada Kubecon2018 Eropa</a></li><li>Lihat <a href=https://github.com/kubernetes-sigs/federation-v2/blob/master/docs/userguide.md>petunjuk penggunaan <em>Federation-v2</em></a></li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-08e94e6a480e0d6b2de72d84a1b97617>11.10 - Berbagai Proxy di Kubernetes</h1><p>Laman ini menjelaskan berbagai <i>proxy</i> yang ada di dalam Kubernetes.</p><h2 id=berbagai-jenis-i-proxy-i>Berbagai Jenis <i>Proxy</i></h2><p>Ada beberapa jenis <i>proxy</i> yang akan kamu temui saat menggunakan Kubernetes:</p><ol><li><p><a href=/id/docs/tasks/access-application-cluster/access-cluster/#directly-accessing-the-rest-api>kubectl proxy</a>:</p><ul><li>dijalankan pada <i>desktop</i> pengguna atau di dalam sebuah Pod</li><li>melakukan <i>proxy</i> dari alamat localhost ke apiserver Kubernetes</li><li>dari klien menuju <i>proxy</i> menggunakan HTTP</li><li>dari <i>proxy</i> menuju apiserver menggunakan HTTPS</li><li>mencari lokasi apiserver</li><li>menambahkan <i>header</i> autentikasi</li></ul></li><li><p><a href=/id/docs/tasks/access-application-cluster/access-cluster/#discovering-builtin-services>apiserver proxy</a>:</p><ul><li>merupakan sebuah <i>bastion</i> yang ada di dalam apiserver</li><li>menghubungkan pengguna di luar klaster ke alamat-alamat IP di dalam klaster yang tidak bisa terjangkau</li><li>dijalankan bersama <i>process-process</i> apiserver</li><li>dari klien menuju <i>proxy</i> menggunakan HTTPS (atau http jika dikonfigurasi pada apiserver)</li><li>dari <i>proxy</i> menuju target menggunakan HTTP atau HTTPS, tergantung pilihan yang diambil oleh <i>proxy</i> melalui informasi yang ada</li><li>dapat digunakan untuk menghubungi Node, Pod, atau Service</li><li>melakukan <i>load balancing</i> saat digunakan untuk menjangkau sebuah Service</li></ul></li><li><p><a href=/id/docs/concepts/services-networking/service/#ips-and-vips>kube proxy</a>:</p><ul><li>dijalankan pada setiap Node</li><li>melakukan <i>proxy</i> untuk UDP, TCP dan SCTP</li><li>tidak mengerti HTTP</li><li>menyediakan <i>load balancing</i></li><li>hanya digunakan untuk menjangkau berbagai Service</li></ul></li><li><p>Sebuah <i>Proxy/Load-balancer</i> di depan satu atau banyak apiserver:</p><ul><li>keberadaan dan implementasinya bervariasi tergantung pada klaster (contohnya nginx)</li><li>ada di antara seluruh klien dan satu/banyak apiserver</li><li>jika ada beberapa apiserver, berfungsi sebagai <i>load balancer</i></li></ul></li><li><p><i>Cloud Load Balancer</i> pada servis eksternal:</p><ul><li>disediakan oleh beberapa penyedia layanan cloud, seperti AWS ELB, Google Cloud Load Balancer</li><li>dibuat secara otomatis ketika Service dari Kubernetes dengan tipe <code>LoadBalancer</code></li><li>biasanya hanya tersedia untuk UDP/TCP</li><li><i>support</i> untuk SCTP tergantung pada <i>load balancer</i> yang diimplementasikan oleh penyedia cloud</li><li>implementasi bervariasi tergantung pada penyedia cloud</li></ul></li></ol><p>Pengguna Kubernetes biasanya hanya cukup perlu tahu tentang kubectl <i>proxy</i> dan apiserver <i>proxy</i>.
Untuk <i>proxy-proxy</i> lain di luar ini, admin klaster biasanya akan memastikan konfigurasinya dengan benar.</p><h2 id=melakukan-i-request-redirect-i>Melakukan <i>request redirect</i></h2><p><i>Proxy</i> telah menggantikan fungsi <i>redirect</i>. <i>Redirect</i> telah terdeprekasi.</p></div><div class=td-content style=page-break-before:always><h1 id=pg-d5cc46b61677b53f61a407d20bdd0830>11.11 - Metrik controller manager</h1><p>Metrik <em>controller manager</em> memberikan informasi penting tentang kinerja dan kesehatan dari <em>controller manager</em>.</p><h2 id=tentang-metrik-controller-manager>Tentang metrik <em>controller manager</em></h2><p>Metrik <em>controller manager</em> ini berfungsi untuk memberikan informasi penting tentang kinerja dan kesehatan dari <em>controller manager</em>.
Metrik ini juga berisi tentang metrik umum dari <em>runtime</em> bahasa pemrograman Go seperti jumlah <em>go_routine</em> dan metrik spesifik dari <em>controller</em> seperti
latensi dari etcd <em>request</em> atau latensi API dari penyedia layanan <em>cloud</em> (AWS, GCE, OpenStack) yang dapat digunakan untuk mengukur kesehatan dari klaster.</p><p>Mulai dari Kubernetes 1.7, metrik yang lebih mendetil tentang operasi penyimpanan dari penyedia layanan <em>cloud</em> juga telah tersedia.
Metrik-metrik ini dapat digunakan untuk memonitor kesehatan dari operasi <em>persistent volume</em>.</p><p>Berikut merupakan contoh nama metrik yang disediakan GCE:</p><pre tabindex=0><code>cloudprovider_gce_api_request_duration_seconds { request = &#34;instance_list&#34;}
cloudprovider_gce_api_request_duration_seconds { request = &#34;disk_insert&#34;}
cloudprovider_gce_api_request_duration_seconds { request = &#34;disk_delete&#34;}
cloudprovider_gce_api_request_duration_seconds { request = &#34;attach_disk&#34;}
cloudprovider_gce_api_request_duration_seconds { request = &#34;detach_disk&#34;}
cloudprovider_gce_api_request_duration_seconds { request = &#34;list_disk&#34;}
</code></pre><h2 id=konfigurasi>Konfigurasi</h2><p>Pada sebuah klaster, informasi metrik <em>controller manager</em> dapat diakses melalui <code>http://localhost:10252/metrics</code>
dari <em>host</em> tempat <em>controller manager</em> dijalankan.</p><p>Metrik ini dikeluarkan dalam bentuk <a href=https://prometheus.io/docs/instrumenting/exposition_formats/>format prometheus</a> serta mudah untuk dibaca manusia.</p><p>Pada <em>environment</em> produksi, kamu mungkin juga ingin mengonfigurasi prometheus atau pengumpul metrik lainnya untuk mengumpulkan metrik-metrik ini secara berkala dalam bentuk basis data <em>time series</em>.</p></div><div class=td-content style=page-break-before:always><h1 id=pg-85d633ae590aa20ec024f1b7af1d74fc>11.12 - Instalasi Add-ons</h1><p><em>Add-ons</em> berfungsi untuk menambah serta memperluas fungsionalitas dari Kubernetes.</p><p>Laman ini akan menjabarkan beberapa <em>add-ons</em> yang tersedia serta tautan instruksi bagaimana cara instalasi masing-masing <em>add-ons</em>.</p><p><em>Add-ons</em> pada setiap bagian akan diurutkan secara alfabet - pengurutan ini tidak dilakukan berdasarkan status preferensi atau keunggulan.</p><h2 id=jaringan-dan-policy-jaringan>Jaringan dan <em>Policy</em> Jaringan</h2><ul><li><a href=https://www.github.com/noironetworks/aci-containers>ACI</a> menyediakan integrasi jaringan kontainer dan keamanan jaringan dengan Cisco ACI.</li><li><a href=https://docs.projectcalico.org/latest/getting-started/kubernetes/>Calico</a> merupakan penyedia jaringan L3 yang aman dan <em>policy</em> jaringan.</li><li><a href=https://projectcalico.docs.tigera.io/getting-started/kubernetes/flannel/flannel>Canal</a> menggabungkan Flannel dan Calico, menyediakan jaringan serta <em>policy</em> jaringan.</li><li><a href=https://github.com/cilium/cilium>Cilium</a> merupakan <em>plugin</em> jaringan L3 dan <em>policy</em> jaringan yang dapat menjalankan <em>policy</em> HTTP/API/L7 secara transparan. Mendukung mode <em>routing</em> maupun <em>overlay/encapsulation</em>.</li><li><a href=https://github.com/cni-genie/CNI-Genie>CNI-Genie</a> memungkinkan Kubernetes agar dapat terkoneksi dengan beragam <em>plugin</em> CNI, seperti Calico, Canal, Flannel, Romana, atau Weave dengan mulus.</li><li><a href=http://contiv.github.io>Contiv</a> menyediakan jaringan yang dapat dikonfigurasi (<em>native</em> L3 menggunakan BGP, <em>overlay</em> menggunakan vxlan, klasik L2, dan Cisco-SDN/ACI) untuk berbagai penggunaan serta <em>policy framework</em> yang kaya dan beragam. Proyek Contiv merupakan proyek <a href=http://github.com/contiv>open source</a>. Laman <a href=http://github.com/contiv/install>instalasi</a> ini akan menjabarkan cara instalasi, baik untuk klaster dengan kubeadm maupun non-kubeadm.</li><li><a href=http://www.juniper.net/us/en/products-services/sdn/contrail/contrail-networking/>Contrail</a>, yang berbasis dari <a href=https://tungsten.io>Tungsten Fabric</a>, merupakan sebuah proyek <em>open source</em> yang menyediakan virtualisasi jaringan <em>multi-cloud</em> serta platform manajemen <em>policy</em>. Contrail dan Tungsten Fabric terintegrasi dengan sistem orkestrasi lainnya seperti Kubernetes, OpenShift, OpenStack dan Mesos, serta menyediakan mode isolasi untuk mesin virtual (VM), kontainer/pod dan <em>bare metal</em>.</li><li><a href=https://github.com/flannel-io/flannel#deploying-flannel-manually>Flannel</a> merupakan penyedia jaringan <em>overlay</em> yang dapat digunakan pada Kubernetes.</li><li><a href=https://github.com/ZTE/Knitter/>Knitter</a> merupakan solusi jaringan yang mendukung multipel jaringan pada Kubernetes.</li><li><a href=https://github.com/k8snetworkplumbingwg/multus-cni>Multus</a> merupakan sebuah multi <em>plugin</em> agar Kubernetes mendukung multipel jaringan secara bersamaan sehingga dapat menggunakan semua <em>plugin</em> CNI (contoh: Calico, Cilium, Contiv, Flannel), ditambah pula dengan SRIOV, DPDK, OVS-DPDK dan VPP pada <em>workload</em> Kubernetes.</li><li><a href=https://docs.vmware.com/en/VMware-NSX-T-Data-Center/index.html>NSX-T</a> Container Plug-in (NCP) menyediakan integrasi antara VMware NSX-T dan orkestrator kontainer seperti Kubernetes, termasuk juga integrasi antara NSX-T dan platform CaaS/PaaS berbasis kontainer seperti <em>Pivotal Container Service</em> (PKS) dan OpenShift.</li><li><a href=https://github.com/nuagenetworks/nuage-kubernetes/blob/v5.1.1-1/docs/kubernetes-1-installation.rst>Nuage</a> merupakan platform SDN yang menyediakan <em>policy-based</em> jaringan antara Kubernetes Pods dan non-Kubernetes <em>environment</em> dengan <em>monitoring</em> visibilitas dan keamanan.</li><li><a href=http://romana.io>Romana</a> merupakan solusi jaringan <em>Layer</em> 3 untuk jaringan pod yang juga mendukung <a href=/id/docs/concepts/services-networking/network-policies/><em>NetworkPolicy</em> API</a>. Instalasi Kubeadm <em>add-on</em> ini tersedia <a href=https://github.com/romana/romana/tree/master/containerize>di sini</a>.</li><li><a href=https://www.weave.works/docs/net/latest/kube-addon/>Weave Net</a> menyediakan jaringan serta <em>policy</em> jaringan, yang akan membawa kedua sisi dari partisi jaringan, serta tidak membutuhkan basis data eksternal.</li></ul><h2 id=service-discovery><em>Service Discovery</em></h2><ul><li><a href=https://coredns.io>CoreDNS</a> merupakan server DNS yang fleksibel, mudah diperluas yang dapat <a href=https://github.com/coredns/deployment/tree/master/kubernetes>diinstal</a> sebagai <em>in-cluster</em> DNS untuk pod.</li></ul><h2 id=visualisasi-amp-kontrol>Visualisasi & Kontrol</h2><ul><li><a href=https://github.com/kubernetes/dashboard#kubernetes-dashboard>Dashboard</a> merupakan antarmuka web dasbor untuk Kubernetes.</li><li><a href=https://www.weave.works/documentation/scope-latest-installing/#k8s>Weave Scope</a> merupakan perangkat untuk visualisasi grafis dari kontainer, pod, <em>service</em> dll milikmu. Gunakan bersama dengan <a href=https://cloud.weave.works/>akun Weave Cloud</a> atau <em>host</em> UI-mu sendiri.</li></ul><h2 id=add-ons-terdeprekasi><em>Add-ons</em> Terdeprekasi</h2><p>Ada beberapa <em>add-on</em> lain yang didokumentasikan pada direktori deprekasi <a href=https://git.k8s.io/kubernetes/cluster/addons><em>cluster/addons</em></a>.</p><p><em>Add-on</em> lain yang dipelihara dan dikelola dengan baik dapat ditulis di sini. Ditunggu PR-nya!</p></div><div class=td-content style=page-break-before:always><h1 id=pg-31c9327d2332c585341b64ddafa19cdd>11.13 - Prioritas dan Kesetaraan API (API Priority and Fairness)</h1><div style=margin-top:10px;margin-bottom:10px><b>FEATURE STATE:</b> <code>Kubernetes v1.18 [alpha]</code></div><p>Mengontrol perilaku server API dari Kubernetes pada situasi beban berlebih
merupakan tugas utama dari administrator klaster. <a class=glossary-tooltip title='Komponen control plane yang mengekspos API Kubernetes. Merupakan front-end dari control plane Kubernetes.' data-toggle=tooltip data-placement=top href=/docs/reference/generated/kube-apiserver/ target=_blank aria-label=kube-apiserver>kube-apiserver</a> memiliki beberapa kontrol yang tersedia
(seperti opsi <code>--max-request-inflight</code> dan <code>--max-mutating-request-inflight</code>
pada baris perintah atau <em>command-line</em>) untuk membatasi jumlah pekerjaan luar biasa yang akan
diterima, untuk mencegah banjirnya permintaan masuk dari beban berlebih
yang berpotensi untuk menghancurkan server API. Namun opsi ini tidak cukup untuk memastikan
bahwa permintaan yang paling penting dapat diteruskan pada saat kondisi lalu lintas (<em>traffic</em>) yang cukup tinggi.</p><p>Fitur Prioritas dan Kesetaraan API atau <em>API Priority and Fairness</em> (APF) adalah alternatif untuk meningkatkan
batasan <em>max-inflight</em> seperti yang disebutkan di atas. APF mengklasifikasi
dan mengisolasi permintaan dengan cara yang lebih halus. Fitur ini juga memperkenalkan
jumlah antrian yang terbatas, sehingga tidak ada permintaan yang ditolak
pada saat terjadi lonjakan permintaan dalam waktu yang sangat singkat. Permintaan dibebaskan dari antrian dengan menggunakan
teknik antrian yang adil (<em>fair queuing</em>) sehingga, sebagai contoh, perilaku buruk dari satu
<a class=glossary-tooltip title='Kontrol tertutup yang mengawasi kondisi bersama dari klaster melalui apiserver dan membuat perubahan yang mencoba untuk membawa kondisi saat ini ke kondisi yang diinginkan.' data-toggle=tooltip data-placement=top href=/id/docs/concepts/architecture/controller/ target=_blank aria-label=controller>controller</a> tidak seharusnya
mengakibatkan <em>controller</em> yang lain menderita (meskipun pada tingkat prioritas yang sama).</p><div class="alert alert-warning caution callout" role=alert><strong>Perhatian:</strong> Permintaan yang diklasifikasikan sebagai "long running" - terutama <em>watch</em> - tidak
mengikuti filter prioritas dan kesetaraan API. Dimana ini juga berlaku pada
opsi <code>--max-request-inflight</code> tanpa mengaktifkan APF.</div><h2 id=mengaktifkan-prioritas-dan-kesetaraan-api>Mengaktifkan prioritas dan kesetaraan API</h2><p>Fitur APF dikontrol oleh sebuah gerbang fitur (<em>feature gate</em>)
dan fitur ini tidak diaktifkan secara bawaan. Silahkan lihat
<a href=/docs/reference/command-line-tools-reference/feature-gates/>gerbang fitur</a>
untuk penjelasan umum tentang gerbang fitur dan bagaimana cara mengaktifkan dan menonaktifkannya.
Nama gerbang fitur untuk APF adalah "APIPriorityAndFairness".
Fitur ini melibatkan sebuah <a class=glossary-tooltip title='Sekumpulan path terkait pada API Kubernetes.' data-toggle=tooltip data-placement=top href=/id/docs/concepts/overview/kubernetes-api/#api-groups target=_blank aria-label='Grup API'>Grup API</a> yang harus juga diaktifkan. Kamu bisa melakukan ini dengan
menambahkan opsi pada baris perintah berikut pada permintaan ke <code>kube-apiserver</code> kamu:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kube-apiserver <span style=color:#b62;font-weight:700>\
</span></span></span><span style=display:flex><span><span style=color:#b62;font-weight:700></span>--feature-gates<span style=color:#666>=</span><span style=color:#b8860b>APIPriorityAndFairness</span><span style=color:#666>=</span><span style=color:#a2f>true</span> <span style=color:#b62;font-weight:700>\
</span></span></span><span style=display:flex><span><span style=color:#b62;font-weight:700></span>--runtime-config<span style=color:#666>=</span>flowcontrol.apiserver.k8s.io/v1alpha1<span style=color:#666>=</span><span style=color:#a2f>true</span> <span style=color:#b62;font-weight:700>\
</span></span></span><span style=display:flex><span><span style=color:#b62;font-weight:700></span> <span style=color:#080;font-style:italic># …dan opsi-opsi lainnya seperti biasa</span>
</span></span></code></pre></div><p>Opsi pada baris perintah <code>--enable-priority-and-fairness=false</code> akan menonaktifkan fitur
APF, bahkan ketika opsi yang lain telah mengaktifkannya.</p><h2 id=konsep>Konsep</h2><p>Ada beberapa fitur lainnya yang terlibat dalam fitur APF. Permintaan yang masuk diklasifikasikan berdasarkan atribut permintaan dengan menggunakan
FlowSchema, dan diserahkan ke tingkat prioritas. Tingkat prioritas menambahkan tingkat
isolasi dengan mempertahankan batas konkurensi yang terpisah, sehingga permintaan yang diserahkan
ke tingkat prioritas yang berbeda tidak dapat membuat satu sama lain menderita. Dalam sebuah tingkat prioritas,
algoritma <em>fair-queuing</em> mencegah permintaan dari <em>flows</em> yang berbeda akan memberikan penderitaan
kepada yang lainnya, dan memperbolehkan permintaan untuk dimasukkan ke dalam antrian untuk mencegah pelonjakan lalu lintas
yang akan menyebabkan gagalnya permintaan, walaupun pada saat beban rata-ratanya cukup rendah.</p><h3 id=tingkat-prioritas-priority-level>Tingkat prioritas (<em>Priority Level</em>)</h3><p>Tanpa pengaktifan APF, keseluruhan konkurensi dalam
server API dibatasi oleh opsi pada <code>kube-apiserver</code>
<code>--max-request-inflight</code> dan <code>--max-mutating-request-inflight</code>. Dengan pengaktifan APF,
batas konkurensi yang ditentukan oleh opsi ini akan dijumlahkan dan kemudian jumlah tersebut dibagikan
untuk sekumpulan tingkat prioritas (<em>priority level</em>) yang dapat dikonfigurasi. Setiap permintaan masuk diserahkan
ke sebuah tingkat prioritas, dan setiap tingkat prioritas hanya akan meneruskan sebanyak mungkin
permintaan secara bersamaan sesuai dengan yang diijinkan dalam konfigurasi.</p><p>Konfigurasi bawaan, misalnya, sudah mencakup tingkat prioritas terpisah untuk
permintaan dalam rangka pemilihan pemimpin (<em>leader-election</em>), permintaan dari <em>controller</em> bawaan, dan permintaan dari
Pod. Hal ini berarti bahwa Pod yang berperilaku buruk, yang bisa membanjiri server API
dengan permintaan, tidak akan mampu mencegah kesuksesan pemilihan pemimpin atau tindakan yang dilakukan oleh <em>controller</em> bawaan.</p><h3 id=antrian-queuing>Antrian (<em>Queuing</em>)</h3><p>Bahkan dalam sebuah tingkat prioritas mungkin akan ada sumber lalu lintas yang berbeda dalam jumlah besar.
Dalam situasi beban berlebih, sangat penting untuk mencegah satu aliran
permintaan dari penderitaan karena aliran yang lainnya (khususnya, dalam kasus yang relatif umum dari sebuah
klien tunggal bermasalah (<em>buggy</em>) yang dapat membanjiri <em>kube-apiserver</em> dengan permintaan, klien bermasalah itu
idealnya tidak memiliki banyak dampak yang bisa diukur terhadap klien yang lainnya). Hal ini
ditangani dengan menggunakan algoritma <em>fair-queuing</em> untuk memproses permintaan yang diserahkan
oleh tingkat prioritas yang sama. Setiap permintaan diserahkan ke sebuah <em>flow</em>, yang diidentifikasi berdasarkan
nama FlowSchema yang sesuai, ditambah dengan <em>flow distinguisher</em> - yang
bisa saja didasarkan pada pengguna yang meminta, sumber daya Namespace dari target, atau tidak sama sekali - dan
sistem mencoba untuk memberikan bobot yang hampir sama untuk permintaan dalam <em>flow</em> yang berbeda dengan tingkat prioritas yang sama.</p><p>Setelah mengklasifikasikan permintaan ke dalam sebuah <em>flow</em>, fitur APF kemudian
dapat menyerahkan permintaan ke dalam sebuah antrian. Penyerahan ini menggunakan
teknik yang dikenal sebagai <a class=glossary-tooltip title='A technique for assigning requests to queues that provides better isolation than hashing modulo the number of queues.' data-toggle=tooltip data-placement=top href='/id/docs/reference/glossary/?all=true#term-shuffle-sharding' target=_blank aria-label='_shuffle sharding_'>_shuffle sharding_</a>, yang membuat penggunaan antrian yang relatif efisien
untuk mengisolasi <em>flow</em> dengan intensitas rendah dari <em>flow</em> dengan intensitas tinggi.</p><p>Detail dari algoritma antrian dapat disesuaikan untuk setiap tingkat prioritas, dan
memperbolehkan administrator untuk menukar (<em>trade off</em>) dengan penggunaan memori, kesetaraan (properti dimana
<em>flow</em> yang independen akan membuat semua kemajuan ketika total dari lalu lintas sudah melebihi kapasitas),
toleransi untuk lonjakan lalu lintas, dan penambahan latensi yang dihasilkan oleh antrian.</p><h3 id=permintaan-yang-dikecualikan-exempt-request>Permintaan yang dikecualikan (<em>Exempt Request</em>)</h3><p>Beberapa permintaan dianggap cukup penting sehingga mereka tidak akan mengikuti
salah satu batasan yang diberlakukan oleh fitur ini. Pengecualian ini untuk mencegah
konfigurasi <em>flow control</em> yang tidak terkonfigurasi dengan baik sehingga tidak benar-benar menonaktifkan server API.</p><h2 id=bawaan-default>Bawaan (<em>Default</em>)</h2><p>Fitur APF dikirimkan dengan konfigurasi yang disarankan
dimana konfigurasi itu seharusnya cukup untuk bereksperimen; jika klaster kamu cenderung
mengalami beban berat maka kamu harus mempertimbangkan konfigurasi apa yang akan bekerja paling baik.
Kelompok konfigurasi yang disarankan untuk semua permintaan terbagi dalam lima prioritas
kelas:</p><ul><li><p>Tingkat prioritas <code>system</code> diperuntukkan bagi permintaan dari grup <code>system:nodes</code>,
mis. Kubelet, yang harus bisa menghubungi server API agar
mendapatkan <em>workload</em> untuk dijadwalkan.</p></li><li><p>Tingkat prioritas <code>leader-election</code> diperuntukkan bagi permintaan dalam pemilihan pemimpin (<em>leader election</em>)
dari <em>controller</em> bawaan (khususnya, permintaan untuk <code>endpoint</code>, <code>configmaps</code>,
atau <code>leases</code> yang berasal dari <code>system:kube-controller-manager</code> atau pengguna
<code>system:kube-scheduler</code> dan akun Service di Namespace <code>kube-system</code>). Hal ini
penting untuk mengisolasi permintaan ini dari lalu lintas yang lain karena
kegagalan dalam pemilihan pemimpin menyebabkan <em>controller</em> akan gagal dan memulai kembali (<em>restart</em>),
yang pada akhirnya menyebabkan lalu lintas yang lebih mahal karena <em>controller</em>
yang baru perlu menyinkronkan para informannya.</p></li><li><p>Tingkat prioritas <code>workload-high</code> diperuntukkan bagi permintaan yang lain dari <em>controller</em> bawaan.
  </p></li><li><p>Tingkat prioritas <code>workload-low</code> diperuntukkan bagi permintaan dari akun Service yang lain,
yang biasanya mencakup semua permintaan dari <em>controller</em> yang bekerja didalam Pod.
  </p></li><li><p>Tingkat prioritas <code>global-default</code> menangani semua lalu lintas lainnya, mis.
perintah interaktif <code>kubectl</code> yang dijalankan oleh pengguna yang tidak memiliki hak khusus.</p></li></ul><p>Kemudian, ada dua PriorityLevelConfiguration dan dua FlowSchema yang telah
dibangun dan tidak mungkin ditimpa ulang:</p><ul><li><p>Tingkat prioritas khusus <code>exempt</code> diperuntukkan bagi permintaan yang tidak akan dikenakan
<em>flow control</em> sama sekali: permintaan itu akan selalu diteruskan sesegera mungkin.
FlowSchema <code>exempt</code> khusus mengklasifikasikan semua permintaan dari kelompok <code>system:masters</code>
ke dalam tingkat prioritas khusus ini. Kamu juga dapat menentukan FlowSchema lain yang mengarahkan
permintaan lain ke tingkat prioritas ini juga, apabila permintaan tersebut sesuai.</p></li><li><p>Tingkat prioritas khusus <code>catch-all</code> digunakan secara kombinasi dengan spesial
FlowSchema <code>catch-all</code> untuk memastikan bahwa setiap permintaan mendapatkan proses
klasifikasi. Biasanya kamu tidak harus bergantung pada konfigurasi <em>catch-all</em> ini,
dan kamu seharusnya membuat FlowSchema <em>catch-all</em> dan PriorityLevelConfiguration kamu sendiri
(atau gunakan konfigurasi <code>global-default</code> yang sudah diinstal secara bawaan) secara benar.
Untuk membantu menemukan kesalahan konfigurasi yang akan melewatkan beberapa klasifikasi
permintaan, maka tingkat prioritas <code>catch-all</code> hanya wajib mengijinkan satu konkurensi
bersama dan tidak melakukan memasukkan permintaan dalam antrian, sehingga membuat lalu lintas
yang secara relatif hanya sesuai dengan FlowSchema <code>catch-all</code> akan ditolak dengan kode kesalahan HTTP 429.</p></li></ul><h2 id=sumber-daya-resource>Sumber daya (<em>Resource</em>)</h2><p><em>Flow control</em> API melibatkan dua jenis sumber daya.
<a href=/docs/reference/generated/kubernetes-api/v1.25/#prioritylevelconfiguration-v1alpha1-flowcontrol-apiserver-k8s-io>PriorityLevelConfiguration</a>
yang menentukan kelas isolasi yang tersedia, bagian dari konkurensi anggaran yang tersedia
yang masing-masing dapat menangani bagian tersebut, dan memperbolehkan untuk melakukan <em>fine-tuning</em> terhadap perilaku antrian.
<a href=/docs/reference/generated/kubernetes-api/v1.25/#flowschema-v1alpha1-flowcontrol-apiserver-k8s-io>FlowSchema</a>
yang digunakan untuk mengklasifikasikan permintaan individu yang masuk, mencocokkan masing-masing dengan setiap
PriorityLevelConfiguration.</p><h3 id=prioritylevelconfiguration>PriorityLevelConfiguration</h3><p>Sebuah PriorityLevelConfiguration merepresentasikan sebuah kelas isolasi tunggal. Setiap
PriorityLevelConfiguration memiliki batas independensi dalam hal jumlah
permintaan yang belum diselesaikan, dan batasan dalam hal jumlah permintaan yang mengantri.</p><p>Batas konkurensi untuk PriorityLevelConfiguration tidak disebutkan dalam
jumlah permintaan secara mutlak, melainkan dalam "concurrency shares." Total batas konkurensi
untuk server API didistribusikan di antara PriorityLevelConfiguration yang ada
secara proporsional dengan "concurrency shares" tersebut. Ini mengizinkan seorang
administrator klaster untuk meningkatkan atau menurunkan jumlah total lalu lintas ke sebuah
server dengan memulai kembali <code>kube-apiserver</code> dengan nilai opsi
<code>--max-request-inflight</code> (atau <code>--max-mutating-request-inflight</code>) yang berbeda, dan semua
PriorityLevelConfiguration akan melihat konkurensi maksimum yang diizinkan kepadanya untuk menaikkan (atau
menurunkan) dalam fraksi yang sama.</p><div class="alert alert-warning caution callout" role=alert><strong>Perhatian:</strong> Dengan fitur Prioritas dan Kesetaraan yang diaktifkan, batas total konkurensi untuk
server diatur pada nilai penjumlahan dari <code>--max-request-inflight</code> dan
<code>--max-mutating-request-inflight</code>. Tidak akan ada lagi perbedaan
antara permintaan yang bermutasi dan permintaan yang tidak bermutasi; jika kamu ingin melayaninya
secara terpisah untuk suatu sumber daya yang ada, maka perlu membuat FlowSchema terpisah yang sesuai dengan
masing-masing kata kerja dari permintaan yang bermutasi dan yang tidak bermutasi tersebut.</div><p>Ketika jumlah permintaan masuk yang diserahkan kepada sebuah
PriorityLevelConfiguration melebihi dari tingkat konkurensi yang diizinkan,
bagian <code>type</code> dari spesifikasinya menentukan apa yang akan terjadi pada permintaan selanjutnya.
Tipe <code>Reject</code> berarti bahwa kelebihan lalu lintas akan segera ditolak
dengan kode kesalahan HTTP 429 (yang artinya terlalu banyak permintaan). Tipe <code>Queue</code> berarti permintaan
di atas batas tersebut akan mengantri, dengan teknik <em>sharding shuffle</em> dan <em>fair queuing</em> yang digunakan
untuk menyelaraskan kemajuan antara <em>flow</em> permintaan.</p><p>Konfigurasi antrian memungkinkan mengatur algoritma <em>fair queuing</em> untuk sebuah
tingkat prioritas. Detail algoritma dapat dibaca di <a href=https://github.com/kubernetes/enhancements/tree/master/keps/sig-api-machinery/1040-priority-and-fairness>proposal pembaharuan</a>, namun secara singkat:</p><ul><li><p>Meningkatkan <code>queue</code> (antrian) berarti mengurangi tingkat tabrakan antara <em>flow</em> yang berbeda,
sehingga berakibat pada biaya untuk meningkatkan penggunaan memori. Nilai 1 di sini secara
efektif menonaktifkan logika <em>fair-queuing</em>, tetapi masih mengizinkan permintaan untuk
dimasukkan kedalam antrian.</p></li><li><p>Meningkatkan <code>queueLengthLimit</code> berarti memperbolehkan lonjakan yang lebih besar dari lalu lintas
untuk berkelanjutan tanpa menggagalkan permintaan apa pun, dengan konsekuensi akan meningkatkan
latensi dan penggunaan memori.</p></li><li><p>Mengubah <code>handSize</code> berarti memperbolehkan kamu untuk menyesuaikan probabilitas tabrakan antara
   <em>flow</em> yang berbeda dan keseluruhan konkurensi yang tersedia untuk satu <em>flow</em> tunggal
dalam situasi beban berlebih.</p><div class="alert alert-info note callout" role=alert><strong>Catatan:</strong> <code>HandSize</code> yang lebih besar membuat dua <em>flow</em> individual berpeluang kecil untuk bertabrakan
(dan dimana <em>flow</em> yang satu bisa membuat <em>flow</em> yang lain menderita), tetapi akan lebih memungkinkan
bahwa <em>flow</em> dalam jumlah kecil akan dapat mendominasi apiserver. <code>HandSize</code> yang lebih besar juga
berpotensi meningkatkan jumlah latensi yang diakibatkan oleh satu <em>flow</em> lalu lintas tunggal
yang tinggi. Jumlah maksimum permintaan dalam antrian yang diijinkan dari sebuah <em>flow</em> tunggal
adalah <code>handSize * queueLengthLimit</code>.</div></li></ul><p>Berikut ini adalah tabel yang menunjukkan koleksi konfigurasi <em>shuffle sharding</em>
yang menarik, dimana setiap probabilitas <em>mouse</em> (<em>flow</em> dengan intensitas rendah)
yang diberikan akan dimampatkan oleh <em>elephant</em> (<em>flow</em> dengan intensitas tinggi) dalam sebuah koleksi ilustratif
dari jumlah <em>elephant</em> yang berbeda. Silahkan lihat pada
<a href=https://play.golang.org/p/Gi0PLgVHiUg>https://play.golang.org/p/Gi0PLgVHiUg</a>, yang digunakan untuk menghitung nilai-nilai dalam tabel ini.</p><table><caption style=display:none>Contoh Konfigurasi Shuffle Sharding</caption><thead><tr><th>HandSize</th><th>Queues</th><th>1 elephant</th><th>4 elephants</th><th>16 elephants</th></tr></thead><tbody><tr><td>12</td><td>32</td><td>4.428838398950118e-09</td><td>0.11431348830099144</td><td>0.9935089607656024</td></tr><tr><td>10</td><td>32</td><td>1.550093439632541e-08</td><td>0.0626479840223545</td><td>0.9753101519027554</td></tr><tr><td>10</td><td>64</td><td>6.601827268370426e-12</td><td>0.00045571320990370776</td><td>0.49999929150089345</td></tr><tr><td>9</td><td>64</td><td>3.6310049976037345e-11</td><td>0.00045501212304112273</td><td>0.4282314876454858</td></tr><tr><td>8</td><td>64</td><td>2.25929199850899e-10</td><td>0.0004886697053040446</td><td>0.35935114681123076</td></tr><tr><td>8</td><td>128</td><td>6.994461389026097e-13</td><td>3.4055790161620863e-06</td><td>0.02746173137155063</td></tr><tr><td>7</td><td>128</td><td>1.0579122850901972e-11</td><td>6.960839379258192e-06</td><td>0.02406157386340147</td></tr><tr><td>7</td><td>256</td><td>7.597695465552631e-14</td><td>6.728547142019406e-08</td><td>0.0006709661542533682</td></tr><tr><td>6</td><td>256</td><td>2.7134626662687968e-12</td><td>2.9516464018476436e-07</td><td>0.0008895654642000348</td></tr><tr><td>6</td><td>512</td><td>4.116062922897309e-14</td><td>4.982983350480894e-09</td><td>2.26025764343413e-05</td></tr><tr><td>6</td><td>1024</td><td>6.337324016514285e-16</td><td>8.09060164312957e-11</td><td>4.517408062903668e-07</td></tr></tbody></table><h3 id=flowschema>FlowSchema</h3><p>FlowSchema mencocokkan beberapa permintaan yang masuk dan menetapkan permintaan ke dalam sebuah
tingkat prioritas. Setiap permintaan masuk diuji dengan setiap
FlowSchema secara bergiliran, dimulai dari yang terendah secara numerik ---
yang kita anggap sebagai yang tertinggi secara logis --- <code>matchingPrecedence</code> dan
begitu seterusnya. FlowSchema yang cocok pertama kali akan menang.</p><div class="alert alert-warning caution callout" role=alert><strong>Perhatian:</strong> Hanya FlowSchema yang pertama kali cocok untuk permintaan yang diberikan yang akan dianggap penting. Jika ada banyak
FlowSchema yang cocok dengan sebuah permintaan masuk, maka akan ditetapkan berdasarkan salah satu
yang mempunyai <code>matchingPrecedence</code> tertinggi. Jika ada beberapa FlowSchema dengan nilai
<code>matchingPrecedence</code> yang sama dan cocok dengan permintaan yang sama juga, permintaan dengan leksikografis
<code>name</code> yang lebih kecil akan menang, tetapi akan lebih baik untuk tidak mengandalkan metode ini, dan sebaiknya
perlu memastikan bahwa tidak ada dua FlowSchema yang memiliki <code>matchingPrecedence</code> yang sama.</div><p>Sebuah FlowSchema dianggap cocok dengan sebuah permintaan yang diberikan jika setidaknya salah satu dari <code>rules</code> nya
ada yang cocok. Sebuah aturan (<em>rule</em>) cocok jika setidaknya satu dari <code>subject</code> <em>dan</em>
ada salah satu dari <code>resourceRules</code> atau <code>nonResourceRules</code> (tergantung dari apakah permintaan
yang masuk adalah untuk URL sumber daya atau non-sumber daya) yang cocok dengan permintaan tersebut.</p><p>Untuk bagian <code>name</code> dalam subjek, dan bagian <code>verbs</code>, <code>apiGroups</code>, <code>resources</code>,
<code>namespaces</code>, dan <code>nonResourceURLs</code> dalam aturan sumber daya dan non-sumber daya,
<em>wildcard</em> <code>*</code> mungkin bisa ditetapkan untuk mencocokkan semua nilai pada bagian yang diberikan,
sehingga secara efektif menghapusnya dari pertimbangan.</p><p>Sebuah <code>DistinguisherMethod.type</code> dari FlowSchema menentukan bagaimana permintaan
yang cocok dengan Skema itu akan dipisahkan menjadi <em>flow</em>. Nilai tipe itu bisa jadi <code>ByUser</code>, dalam
hal ini satu pengguna yang meminta tidak akan bisa menghabiskan kapasitas dari pengguna lain,
atau bisa juga <code>ByNamespace</code>, dalam hal ini permintaan sumber daya
di salah satu Namespace tidak akan bisa menyebabkan penderitaan bagi permintaan akan sumber daya
dalam kapasitas Namespace yang lain, atau bisa juga kosong (atau <code>distinguisherMethod</code>
dihilangkan seluruhnya), dalam hal ini semua permintaan yang cocok dengan FlowSchema ini akan
dianggap sebagai bagian dari sebuah <em>flow</em> tunggal. Pilihan yang tepat untuk FlowSchema yang diberikan
akan bergantung pada sumber daya dan lingkungan khusus kamu.</p><h2 id=diagnosis>Diagnosis</h2><p>Setiap respons HTTP dari server API dengan fitur prioritas dan kesetaraan
yang diaktifkan memiliki dua <em>header</em> tambahan: <code>X-Kubernetes-PF-FlowSchema-UID</code> dan
<code>X-Kubernetes-PF-PriorityLevel-UID</code>, yang mencatat skema <em>flow</em> yang cocok dengan permintaan
dan tingkat prioritas masing-masing. Name Objek API tidak termasuk dalam <em>header</em> ini jika pengguna peminta tidak
memiliki izin untuk melihatnya, jadi ketika melakukan <em>debugging</em> kamu dapat menggunakan perintah seperti ini</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get flowschema -o custom-columns<span style=color:#666>=</span><span style=color:#b44>&#34;uid:{metadata.uid},name:{metadata.name}&#34;</span>
</span></span><span style=display:flex><span>kubectl get prioritylevelconfiguration -o custom-columns<span style=color:#666>=</span><span style=color:#b44>&#34;uid:{metadata.uid},name:{metadata.name}&#34;</span>
</span></span></code></pre></div><p>untuk mendapatkan pemetaan UID ke names baik untuk FlowSchema maupun PriorityLevelConfiguration.</p><h2 id=observabilitas>Observabilitas</h2><p>Saat kamu mengaktifkan fitur Prioritas dan Kesetaraan API atau APF, kube-apiserver
akan mengeluarkan metrik tambahan. Dengan memantau metrik ini dapat membantu kamu untuk menentukan apakah
konfigurasi kamu tidak tepat dalam membatasi lalu lintas yang penting, atau menemukan
beban kerja yang berperilaku buruk yang dapat membahayakan kesehatan dari sistem.</p><ul><li><p><code>apiserver_flowcontrol_rejected_requests_total</code> menghitung permintaan yang
ditolak, mengelompokkannya berdasarkan nama dari tingkat prioritas yang ditetapkan,
nama FlowSchema yang ditetapkan, dan alasan penolakan tersebut.
Alasan penolakan akan mengambil dari salah satu alasan-alasan berikut:</p><ul><li><code>queue-full</code>, yang mengindikasikan bahwa sudah terlalu banyak permintaan
yang menunggu dalam antrian,</li><li><code>concurrency-limit</code>, yang mengindikasikan bahwa PriorityLevelConfiguration
telah dikonfigurasi untuk menolak, bukan untuk memasukan permintaan berlebih ke
dalam antrian, atau</li><li><code>time-out</code>, yang mengindikasikan bahwa permintaan masih dalam antrian
ketika batas waktu antriannya telah berakhir.</li></ul></li><li><p><code>apiserver_flowcontrol_dispatched_requests_total</code> menghitung permintaan
yang sudah mulai dieksekusi, mengelompokkannya berdasarkan nama dari tingkat
prioritas yang ditetapkan, dan nama dari FlowSchema yang ditetapkan.</p></li><li><p><code>apiserver_flowcontrol_current_inqueue_requests</code> memberikan
jumlah total sesaat secara instan dari permintaan dalam antrian (bukan yang dieksekusi),
dan mengelompokkannya berdasarkan tingkat prioritas dan FlowSchema.</p></li><li><p><code>apiserver_flowcontrol_current_executing_requests</code> memberikan
jumlah total yang instan dari permintaan yang dieksekusi, dan mengelompokkannya
berdasarkan tingkat prioritas dan FlowSchema.</p></li><li><p><code>apiserver_flowcontrol_request_queue_length_after_enqueue</code> memberikan
histogram dari panjang antrian untuk semua antrian yang ada, mengelompokkannya berdasarkan
tingkat prioritas dan FlowSchema, berdasarkan pengambilan sampel oleh permintaan
<em>enqueued</em>. Setiap permintaan yang mendapatkan antrian berkontribusi ke satu sampel
dalam histogramnya, pelaporan panjang antrian dilakukan setelah permintaan yang
mengantri tersebut ditambahkan. Perlu dicatat bahwa ini akan menghasilkan statistik
yang berbeda dengan survei yang tidak bias.</p><div class="alert alert-info note callout" role=alert><strong>Catatan:</strong> Nilai asing atau tidak biasa dalam histogram akan berarti ada kemungkinan sebuah <em>flow</em></li></ul><p>(misalnya, permintaan oleh satu pengguna atau untuk satu <em>namespace</em>, tergantung pada
konfigurasinya) telah membanjiri server API, dan sedang dicekik. Sebaliknya, jika
histogram dari satu tingkat prioritas menunjukkan bahwa semua antrian dalam prioritas
level itu lebih panjang daripada level prioritas yang lainnya, mungkin akan sesuai
untuk meningkatkan <em>concurrency shares</em> dari PriorityLevelConfiguration itu.</p></div><ul><li><p><code>apiserver_flowcontrol_request_concurrency_limit</code> memberikan hasil perhitungan
batas konkurensi (berdasarkan pada batas konkurensi total dari server API dan
<em>concurrency share</em> dari PriorityLevelConfiguration) untuk setiap
PriorityLevelConfiguration.</p></li><li><p><code>apiserver_flowcontrol_request_wait_duration_seconds</code> memberikan histogram tentang bagaimana
permintaan yang panjang dihabiskan dalam antrian, mengelompokkannya berdasarkan FlowSchema
yang cocok dengan permintaan, tingkat prioritas yang ditetapkan, dan apakah permintaan
tersebut berhasil dieksekusi atau tidak.</p><div class="alert alert-info note callout" role=alert><strong>Catatan:</strong> Karena setiap FlowSchema selalu memberikan permintaan untuk satu</li></ul><p>PriorityLevelConfiguration, kamu dapat menambahkan histogram untuk semua
FlowSchema dalam satu tingkat prioritas untuk mendapatkan histogram yang efektif
dari permintaan yang ditetapkan ke tingkat prioritas tersebut.</p></div><ul><li><code>apiserver_flowcontrol_request_execution_seconds</code> memberikan histogram tentang bagaimana
caranya permintaan yang panjang diambil untuk benar-benar dieksekusi, mengelompokkannya
berdasarkan FlowSchema yang cocok dengan permintaan dan tingkat prioritas yang ditetapkan pada
permintaan tersebut.</li></ul><h2 id=selanjutnya>Selanjutnya</h2><p>Untuk latar belakang informasi mengenai detail desain dari prioritas dan kesetaraan API, silahkan lihat
<a href=https://github.com/kubernetes/enhancements/tree/master/keps/sig-api-machinery/1040-priority-and-fairness>proposal pembaharuan</a>.
Kamu juga dapat membuat saran dan permintaan akan fitur melalui <a href=https://github.com/kubernetes/community/tree/master/sig-api-machinery>SIG API
Machinery</a>.</p></div><div class=td-content style=page-break-before:always><h1 id=pg-7e0d97616b15e2c383c6a0a96ec442cb>12 - Memperluas Kubernetes</h1></div><div class=td-content><h1 id=pg-5c2b36cd0ddbe006b575d4e54c63d508>12.1 - Memperluas Klaster Kubernetes Kamu</h1><p>Kubernetes sangat mudah dikonfigurasi dan diperluas. Sehingga,
jarang membutuhkan <em>fork</em> atau menambahkan <em>patch</em> ke kode proyek Kubernetes.</p><p>Panduan ini menjelaskan pilihan untuk menyesuaikan klaster Kubernetes.
Dokumen ini ditujukan kepada <a class=glossary-tooltip title='Seseorang yang mengonfigurasi, mengontrol, dan memonitor klaster.' data-toggle=tooltip data-placement=top href='/id/docs/reference/glossary/?all=true#term-cluster-operator' target=_blank aria-label='operator klaster'>operator klaster</a> yang ingin
memahami bagaimana menyesuaikan klaster Kubernetes dengan kebutuhan lingkungan kerja mereka.</p><p>Developer yang prospektif <a class=glossary-tooltip title='Seseorang yang menyesuaikan platform Kubernetes agar sesuai dengan kebutuhan proyek mereka.' data-toggle=tooltip data-placement=top href='/id/docs/reference/glossary/?all=true#term-platform-developer' target=_blank aria-label='Developer Platform'>Developer Platform</a> atau <a class=glossary-tooltip title='Seseorang yang menyumbangkan kode, dokumentasi, atau waktu mereka untuk membantu proyek atau komunitas Kubernetes.' data-toggle=tooltip data-placement=top href='/id/docs/reference/glossary/?all=true#term-contributor' target=_blank aria-label=Kontributor>Kontributor</a> Proyek Kubernetes juga mendapatkan manfaat dari
dokumen ini sebagai pengantar apa saja poin-poin dan pola-pola perluasan yang ada, untung-rugi, dan batasan-batasannya.</p><h2 id=ikhtisar>Ikhtisar</h2><p>Pendekatan-pendekatan kostumisasi secara umum dapat dibagi atas <em>konfigurasi</em>, yang hanya melibatkan perubahan <em>flag</em>, konfigurasi berkas lokal, atau objek-objek sumber daya API; dan <em>perluasan</em>, yang melibatkan berjalannya program atau layanan tambahan. Dokumen ini sebagian besar membahas tentang perluasan.</p><h2 id=konfigurasi>Konfigurasi</h2><p><em>Flag-flag</em> dan <em>berkas-berkas konfigurasi</em> didokumentasikan di bagian Referensi dari dokumentasi daring, didalam setiap <em>binary</em>:</p><ul><li><a href=/docs/admin/kubelet/>kubelet</a></li><li><a href=/docs/admin/kube-apiserver/>kube-apiserver</a></li><li><a href=/docs/admin/kube-controller-manager/>kube-controller-manager</a></li><li><a href=/docs/admin/kube-scheduler/>kube-scheduler</a>.</li></ul><p><em>Flag-flag</em> dan berkas-berkas konfigurasi mungkin tidak selalu dapat diubah pada layanan Kubernetes yang <em>hosted</em> atau pada distribusi dengan instalasi yang dikelola. Ketika mereka dapat diubah, mereka biasanya hanya dapat diubah oleh Administrator Klaster. Dan juga, mereka dapat sewaktu-waktu diubah dalam versi Kubernetes di masa depan, dan menyetel mereka mungkin memerlukan proses pengulangan kembali. Oleh karena itu, mereka harus digunakan hanya ketika tidak ada pilihan lain.</p><p><em>API kebijakan bawaan</em>, seperti <a href=/id/docs/concepts/policy/resource-quotas/>ResourceQuota</a>, <a href=/id/docs/concepts/policy/pod-security-policy/>PodSecurityPolicy</a>, <a href=/id/docs/concepts/services-networking/network-policies/>NetworkPolicy</a> dan Role-based Access Control (<a href=/id/docs/reference/access-authn-authz/rbac/>RBAC</a>), adalah API bawaan Kubernetes. API biasanya digunakan oleh layanan Kubernetes yang <em>hosted</em> dan diatur oleh instalasi Kubernetes. Mereka bersifat deklaratif dan menggunakan konvensi yang sama dengan sumber daya Kubernetes lainnya seperti pod-pod, jadi konfigurasi klaster baru dapat diulang-ulang dan dapat diatur dengan cara yang sama dengan aplikasi. Dan, ketika mereka stabil, mereka mendapatkan keuntungan dari <a href=/docs/reference/deprecation-policy/>kebijakan pendukung yang jelas</a> seperti API Kubernetes lainnya. Oleh karena itu, mereka lebih disukai daripada <em>berkas konfigurasi</em> dan <em>flag-flag</em> saat mereka cocok dengan situasi yang dibutuhkan.</p><h2 id=perluasan>Perluasan</h2><p>Perluasan adalah komponen perangkat lunak yang memperluas dan berintegrasi secara mendalam dengan Kubernetes.
Mereka mengadaptasi Kubernetes untuk mendukung perangkat keras tipe baru dan jenis baru.</p><p>Kebanyakan administrator klaster akan menggunakan instansi Kubernetes yang didistribusikan atau yang <em>hosted</em>.
Sebagai hasilnya, kebanyakan pengguna Kubernetes perlu menginstal perluasan dan lebih sedikit yang perlu untuk membuat perluasan-perluasan yang baru.</p><h2 id=pola-pola-perluasan>Pola-pola Perluasan</h2><p>Kubernetes didesain untuk dapat diotomasi dengan menulis program-program klien. Program apapun yang membaca dan/atau menulis ke API Kubernetes dapat menyediakan otomasi yang berguna.</p><p><em>Otomasi</em> dapat berjalan di dalam klaster atau di luar klaster. Dengan mengikuti panduan
di dalam dokumen ini, kamu dapat menulis otomasi yang sangat tersedia dan kuat.
Otomasi pada umumnya dapat bekerja dengan berbagai macam klaster Kubernetes, termasuk
klaster yang <em>hosted</em> dan instalasi yang dikelola.</p><p>Ada pola spesifik untuk menulis program klien yang bekerja dengan baik bersama Kubernetes yang disebut pola <em>Controller</em>. <em>Controller-controller</em> biasanya membaca kolom <code>.spec</code> milik sebuah objek, kemungkinan melakukan sesuatu, dan kemudian memperbarui objek milik <code>.status</code>.</p><p><em>Controller</em> adalah klien dari Kubernetes. Ketika Kubernetes adalah klien dan memanggil layanan
terpisah, hal tersebut disebut <em>Webhook</em>. Layanan terpisah tersebut disebut sebuah <em>Webhook Backend</em>. Seperti <em>Controller-controller</em>, <em>Webhook-webhook</em> memang menambah sebuah titik untuk terjadinya kegagalan.</p><p>Di dalam model <em>Webhook</em>, Kubernetes membuat sebuah <em>network request</em> kepada sebuah layanan terpisah.</p><p>Di dalam model <em>Binary Plugin</em>, Kubernetes mengeksekusi sebuah program.
<em>Binary Plugin</em> digunakan oleh kubelet (misalnya <a href=https://github.com/kubernetes/community/blob/master/contributors/devel/sig-storage/flexvolume.md><em>Plugin Flex Volume</em></a>
dan oleh <a href=/docs/concepts/cluster-administration/network-plugins/><em>Plugin</em> Jaringan</a>) dan oleh kubectl.</p><p>Berikut ini adalah diagram yang menunjukkan bagaimana titik-titik perluasan berinteraksi dengan <em>control plane</em> Kubernetes.</p><img src="https://docs.google.com/drawings/d/e/2PACX-1vQBRWyXLVUlQPlp7BvxvV9S1mxyXSM6rAc_cbLANvKlu6kCCf-kGTporTMIeG5GZtUdxXz1xowN7RmL/pub?w=960&h=720"><h2 id=titik-titik-perluasan>Titik-titik Perluasan</h2><p>Diagram berikut menunjukkan titik-titik perluasan di sebuah Kubernetes.</p><img src="https://docs.google.com/drawings/d/e/2PACX-1vSH5ZWUO2jH9f34YHenhnCd14baEb4vT-pzfxeFC7NzdNqRDgdz4DDAVqArtH4onOGqh0bhwMX0zGBb/pub?w=425&h=809"><ol><li>Pengguna biasanya berinteraksi dengan API Kubernetes menggunakan <code>kubectl</code>. <a href=/docs/tasks/extend-kubectl/kubectl-plugins/><em>Plugin-plugin</em> Kubectl</a> memperluas <em>binari</em> kubectl. Mereka hanya memengaruhi lingkungan lokal pengguna, dan tidak dapat memaksakan kebijakan yang menyeluruh di seluruh situs.</li><li>apiserver menangani semua permintaan. Beberapa tipe titik perluasan di apiserver memperbolehkan otentikasi permintaan, atau memblokir mereka berdasarkan konten mereka, menyunting konten, dan menangani penghapusan. Hal ini dideskripsikan di bagian <a href=/docs/concepts/overview/extending#perluasan-perluasan-akses-api>Perluasan Akses API</a></li><li>apiserver melayani berbagai macam sumber daya, <em>tipe-tipe sumber daya bawaan</em>, seperti <code>pod</code>, didefinisikan oleh proyek kubernetes dan tidak dapat diubah. kamu juga dapat menambahkan sumber daya yang kamu definisikan sendiri, atau yang proyek lain definisikan, disebut <em>Custom Resources</em>, seperti dijelaskan di bagian <a href=/docs/concepts/overview/extending#tipe-tipe-yang-ditentukan-pengguna>Sumber Daya <em>Custom</em></a>. Sumber daya <em>Custom</em> sering digunakan dengan Perluasan Akses API.</li><li>Penjadwal Kubernetes memutuskan ke Node mana Pod akan ditempatkan. Ada beberapa cara untuk memperluas penjadwalan. Hal ini dibahas pada bagian <a href=/docs/concepts/overview/extending#perluasan-perluasan-penjadwal>Perluasan-perluasan Penjadwal</a>.</li><li>Sebagian besar perilaku Kubernetes diimplementasi oleh program yang disebut <em>Controller-controller</em> yang merupakan klien dari API-Server. <em>Controller-controller</em> sering digunakan bersama dengan Sumber Daya <em>Custom</em>.</li><li>Kubelet berjalan di server, dan membantu Pod-pod terlihat seperti server virtual dengan IP mereka sendiri di jaringan klaster. <a href=/docs/concepts/overview/extending#plugin-plugin-jaringan><em>Plugin</em> Jaringan</a> memungkinkan adanya perbedaan implementasi pada jaringan Pod.</li><li>Kubelet juga melakukan penambatan dan pelepasan tambatan volume untuk kontainer. Tipe-tipe penyimpanan baru dapat didukung via <a href=/docs/concepts/overview/extending#plugin-plugin-penyimpanan><em>Plugin</em> Penyimpanan</a>.</li></ol><p>Jika kamu tidak yakin untuk memulai dari mana, diagram alir di bawah ini dapat membantu kamu. Ingat lah bahwa beberapa solusi mungkin melibatkan beberapa tipe perluasan.</p><img src="https://docs.google.com/drawings/d/e/2PACX-1vRWXNNIVWFDqzDY0CsKZJY3AR8sDeFDXItdc5awYxVH8s0OLherMlEPVUpxPIB1CSUu7GPk7B2fEnzM/pub?w=1440&h=1080"><h2 id=perluasan-api>Perluasan API</h2><h3 id=tipe-tipe-yang-ditentukan-pengguna>Tipe-tipe yang Ditentukan Pengguna</h3><p>Pertimbangkan untuk menambahkan Sumber Daya <em>Custom</em> ke Kubernetes jika kamu ingin mendefinisikan pengontrol baru, objek konfigurasi aplikasi atau API deklaratif lainnya, dan untuk mengelolanya menggunakan alat Kubernetes, seperti <code>kubectl</code>.</p><p>Jangan menggunakan Sumber Daya <em>Custom</em> sebagai penyimpanan data untuk aplikasi, pengguna, atau untuk memonitor data.</p><p>Untuk lebih jelasnya tentang Sumber Daya <em>Custom</em>, lihat <a href=/docs/concepts/api-extension/custom-resources/>Panduan Konsep Sumber Daya <em>Custom</em></a>.</p><h3 id=menggabungkan-api-baru-dengan-otomasi>Menggabungkan API Baru dengan Otomasi</h3><p>Kombinasi antara sebuah API sumber daya <em>custom</em> dan <em>loop</em> kontrol disebut <a href=/id/docs/concepts/extend-kubernetes/operator/>Pola Operator</a>. Pola Operator digunakan untuk mengelola aplikasi yang spesifik dan biasanya <em>stateful</em>. API-API <em>custom</em> dan <em>loop</em> kontrol ini dapat digunakan untuk mengatur sumber daya lainnya, seperti penyimpanan dan kebijakan-kebijakan.</p><h3 id=mengubah-sumber-daya-bawaan>Mengubah Sumber Daya Bawaan</h3><p>Ketika kamu memperluas API Kubernetes dengan menambahkan sumber daya <em>custom</em>, sumber daya yang ditambahkan akan selalu masuk ke Grup API baru. Kamu tidak dapat mengganti atau mengubah Grup API yang sudah ada. Menambah sebuah API tidak secara langsung membuat kamu memengaruhi perilaku API yang sudah ada (seperti Pod), tetapi Perluasan Akses API dapat memengaruhinya secara langsung.</p><h3 id=perluasan-perluasan-akses-api>Perluasan-Perluasan Akses API</h3><p>Ketika sebuah permintaan sampai ke Server API Kubernetes, permintaan tersebut diotentikasi terlebih dahulu, kemudian diotorisasi, kemudian diarahkan ke berbagai jenis <em>Admission Control</em>. Lihat dokumentasi <a href=/docs/reference/access-authn-authz/controlling-access/>Mengatur Akses ke API Kubernetes</a> untuk lebih jelasnya tentang alur ini.</p><p>Setiap langkah berikut menawarkan titik-titik perluasan.</p><p>Kubernetes memiliki beberapa metode otentikasi bawaan yang didukungnya. Metode ini bisa berada di belakang proksi yang mengotentikasi, dan metode ini dapat mengirim sebuah token dari <em>header</em> Otorisasi ke layanan terpisah untuk verifikasi (sebuah <em>webhook</em>). Semua metode ini tercakup dalam <a href=/docs/reference/access-authn-authz/authentication/>Dokumentasi Otentikasi</a>.</p><h3 id=otentikasi>Otentikasi</h3><p><a href=/docs/reference/access-authn-authz/authentication/>Otentikasi</a> memetakan <em>header</em> atau sertifikat dalam semua permintaan ke <em>username</em> untuk klien yang mebuat permintaan.</p><p>Kubernetes menyediakan beberapa metode otentikasi bawaan, dan sebuah metode <a href=/docs/reference/access-authn-authz/authentication/#webhook-token-authentication><em>Webhook</em> Otentikasi</a> jika metode bawaan tersebut tidak mencukupi kebutuhan kamu.</p><h3 id=otorisasi>Otorisasi</h3><p><a href=/docs/reference/access-authn-authz/webhook/>Otorisasi</a> menentukan apakah pengguna tertentu dapat membaca, menulis, dan melakukan operasi lainnya terhadap sumber daya API. Hal ini hanya bekerja pada tingkat sumber daya secara keseluruhan -- tidak membeda-bedakan berdasarkan field objek sembarang. Jika pilihan otorisasi bawaan tidak mencukupi kebutuhan kamu, <a href=/docs/reference/access-authn-authz/webhook/><em>Webhook</em> Otorisasi</a> memungkinkan pemanggilan kode yang disediakan pengguna untuk membuat keputusan otorisasi.</p><h3 id=kontrol-admisi-dinamis>Kontrol Admisi Dinamis</h3><p>Setalah permintaan diotorisasi, jika ini adalah operasi penulisan, permintaan ini akan melalui langkah <a href=/docs/reference/access-authn-authz/admission-controllers/>Kontrol Admisi</a>. Sebagai tambahan untuk step bawaan, ada beberapa perluasan:</p><ul><li><a href=/docs/reference/access-authn-authz/admission-controllers/#imagepolicywebhook><em>Webhook</em> Kebijakan <em>Image</em></a> membatasi <em>image</em> mana saja yang dapat berjalan di kontainer.</li><li>Untuk membuat keputusan kontrol admisi sembarang, <a href=/docs/reference/access-authn-authz/extensible-admission-controllers/#admission-webhooks><em>Webhook</em> Admisi</a> umum dapat digunakan. <em>Webhook</em> Admisi dapat menolak pembuatan atau pembaruan.</li></ul><h2 id=perluasan-infrastruktur>Perluasan Infrastruktur</h2><h3 id=plugin-plugin-penyimpanan><em>Plugin-plugin</em> Penyimpanan</h3><p><a href=https://github.com/kubernetes/community/blob/master/contributors/design-proposals/storage/flexvolume-deployment.md>Flex Volume</a> memungkinkan pengguna untuk memasang tipe-tipe volume tanpa dukungan bawaan dengan cara membiarkan Kubelet memanggil sebuah <em>Plugin Binary</em> untuk menambatkan volume.</p><h3 id=plugin-perangkat><em>Plugin</em> Perangkat</h3><p><em>Plugin</em> perangkat memungkinkan sebuah node untuk menemukan sumber daya Node baru (sebagai tambahan dari bawaannya seperti CPU dan memori) melalui sebuah <a href=/docs/concepts/cluster-administration/device-plugins/><em>Plugin</em> Perangkat</a>.</p><h3 id=plugin-plugin-jaringan><em>Plugin-plugin</em> Jaringan</h3><p>Struktur-struktur jaringan yang berbeda dapat didukung melalui <a href=/docs/admin/network-plugins/><em>Plugin</em> Jaringan</a> pada tingkat Node.</p><h3 id=perluasan-perluasan-penjadwal>Perluasan-perluasan Penjadwal</h3><p>Penjadwal adalah jenis pengatur spesial yang mengawasi Pod, dan menempatkan Pod ke Node. Penjadwal bawaan dapat digantikan seluruhnya, sementara terus menggunakan komponen Kubernetes lainnya, atau <a href=/docs/tasks/administer-cluster/configure-multiple-schedulers/>penjadwal ganda</a> dapat berjalan dalam waktu yang bersamaan.</p><p>Ini adalah usaha yang signifikan, dan hampir semua pengguna Kubernetes merasa mereka tidak perlu memodifikasi penjadwal tersebut.</p><p>Penjadwal juga mendukung <a href=https://github.com/kubernetes/community/blob/master/contributors/design-proposals/scheduling/scheduler_extender.md><em>webhook</em></a> yang memperbolehkan sebuah <em>webhook backend</em> (perluasan penjadwal) untuk menyaring dan memprioritaskan Node yang terpilih untuk sebuah Pod.</p><h2 id=selanjutnya>Selanjutnya</h2><ul><li>Pelajari lebih lanjut tentang <a href=/docs/concepts/api-extension/custom-resources/>Sumber Daya <em>Custom</em></a></li><li>Pelajari tentang <a href=/docs/reference/access-authn-authz/extensible-admission-controllers/>Kontrol Admisi Dinamis</a></li><li>Pelajari lebih lanjut tentang perluasan Infrastruktur<ul><li><a href=/docs/concepts/cluster-administration/network-plugins/><em>Plugin</em> Jaringan</a></li><li><a href=/docs/concepts/cluster-administration/device-plugins/><em>Plugin</em> Perangkat</a></li></ul></li><li>Pelajari tentang <a href=/docs/tasks/extend-kubectl/kubectl-plugins/><em>Plugin</em> kubectl</a></li><li>Pelajari tentang <a href=/id/docs/concepts/extend-kubernetes/operator/>Pola Operator</a></li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-0af41d3bd7c785621b58b7564793396a>12.2 - Memperluas API Kubernetes</h1></div><div class=td-content><h1 id=pg-1ea4977c0ebf97569bf54a477faa7fa5>12.2.1 - Memperluas Kubernetes API dengan Lapisan Agregasi</h1><p>Lapisan agregasi memungkinkan Kubernetes untuk diperluas dengan API tambahan, selain dari yang ditawarkan oleh API inti Kubernetes.</p><h2 id=ikhtisar>Ikhtisar</h2><p>Lapisan agregasi memungkinkan instalasi tambahan beragam API <em>Kubernetes-style</em> di kluster kamu. Tambahan-tambahan ini dapat berupa solusi-solusi yang sudah dibangun (<em>prebuilt</em>) oleh pihak ke-3 yang sudah ada, seperti <a href=https://github.com/kubernetes-incubator/service-catalog/blob/master/README.md><em>service-catalog</em></a>, atau API yang dibuat oleh pengguna seperti <a href=https://github.com/kubernetes-incubator/apiserver-builder/blob/master/README.md>apiserver-builder</a>, yang dapat membantu kamu memulainya.</p><p>Lapisan agregasi berjalan di dalam proses bersama dengan kube-apiserver. Hingga sebuah sumber daya ekstensi terdaftar, lapisan agregasi tidak akan melakukan apapun. Untuk mendaftarkan sebuah API, pengguna harus menambahkan sebuah objek <em>APIService</em>, yang "mengklaim" jalur URL di API Kubernetes. Pada titik tersebut, lapisan agregasi akan mem-<em>proxy</em> apapun yang dikirim ke jalur API tersebut (misalnya /apis/myextension.mycompany.io/v1/…) ke <em>APIService</em> yang terdaftar.</p><p>Biasanya, <em>APIService</em> akan diimplementasikan oleh sebuah ekstensi-apiserver di dalam sebuah Pod yang berjalan di kluster. Ekstensi-apiserver ini biasanya perlu di pasangkan dengan satu atau lebih <em>controller</em> apabila manajemen aktif dari sumber daya tambahan diperlukan. Sebagai hasilnya, apiserver-builder sebenarnya akan memberikan kerangka untuk keduanya. Sebagai contoh lain, ketika service-catalog diinstal, ia menyediakan ekstensi-apiserver dan <em>controller</em> untuk layanan-layanan yang disediakannya.</p><p>Ekstensi-apiserver harus memiliki latensi koneksi yang rendah dari dan ke kube-apiserver.
Secara Khusus, permintaan pencarian diperlukan untuk bolak-balik dari kube-apiserver dalam 5 detik atau kurang.
Jika implementasi kamu tidak dapat menyanggupinya, kamu harus mempertimbangkan cara mengubahnya. Untuk sekarang, menyetel
<em>feature-gate</em> <code>EnableAggregatedDiscoveryTimeout=false</code> di kube-apiserver
akan menonaktifkan batasan waktu tersebut. Fitur ini akan dihapus dalam rilis mendatang.</p><h2 id=selanjutnya>Selanjutnya</h2><ul><li>Untuk mengaktifkan agregator di lingkungan kamu, aktifkan<a href=/docs/tasks/access-kubernetes-api/configure-aggregation-layer/>konfigurasi lapisan agregasi</a>.</li><li>Kemudian, <a href=/docs/tasks/access-kubernetes-api/setup-extension-api-server/>siapkan ekstensi api-server</a> untuk bekerja dengan lapisan agregasi.</li><li>Selain itu, pelajari caranya <a href=/docs/tasks/access-kubernetes-api/extend-api-custom-resource-definitions/>mengembangkan API Kubernetes menggunakan <em>Custom Resource Definition</em></a>.</li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-342388440304e19ce30c0f8ada1c77ce>12.2.2 - Custom Resource</h1><p><em>Custom Resource</em> adalah ekstensi dari Kubernetes API. Laman ini mendiskusikan kapan kamu melakukan penambahan sebuah <em>Custom Resource</em> ke klaster Kubernetes dan kapan kamu menggunakan sebuah layanan mandiri. Laman ini mendeskripsikan dua metode untuk menambahkan <em>Custom Resource</em> dan bagaimana cara memilihnya.</p><h2 id=custom-resource><em>Custom Resource</em></h2><p>Sebuah sumber daya adalah sebuah <em>endpoint</em> pada <a href=/docs/reference/using-api/api-overview/>Kubernetes API</a> yang menyimpan sebuah koleksi <a href=/id/docs/concepts/overview/working-with-objects/kubernetes-objects/>objek API</a> dari sebuah jenis tertentu. Sebagai contoh, sumber daya bawaan Pod mengandung sebuah koleksi objek-objek Pod.</p><p>Sebuah <em>Custom Resource</em> adalah sebuah ekstensi dari Kubernetes API yang tidak seharusnya tersedia pada pemasangan default Kubernetes. Namun, banyak fungsi-fungsi inti Kubernetes yang sekarang dibangun menggunakan <em>Custom Resource</em>, membuat Kubernetes lebih modular.</p><p><em>Custom Resource</em> bisa muncul dan menghilang dalam sebuah klaster yang berjalan melalui registrasi dinamis (<em>dynamic registration</em>), dan admin-admin klaster bisa memperbaharui <em>Custom Resource</em> secara independen dari klaster itu sendiri. Ketika sebuah <em>Custom Resource</em>
dipasang, pengguna dapat membuat dan mengakses objek-objek <em>Custom Resource</em> menggunakan <a href=/docs/user-guide/kubectl-overview/>kubectl</a>, seperti yang mereka lakukan untuk sumber daya bawaan seperti Pod.</p><h2 id=controller-khusus><em>Controller</em> Khusus</h2><p>Dengan sendirinya, <em>Custom Resource</em> memungkinkan kamu untuk menyimpan dan mengambil data terstruktur. Ketika kamu menggabungkan sebuah <em>Custom Resource</em> dengan <em>controller</em> khusus, <em>Custom Resource</em> akan memberikan sebuah API deklaratif yang sebenarnya.</p><p>Sebuah <a href=/id/docs/concepts/overview/working-with-objects/kubernetes-objects/#memahami-konsep-objek-objek-yang-ada-pada-kubernetes>API deklaratif</a>
memungkinkan kamu untuk mendeklarasikan atau menspesifikasikan keadaan dari sumber daya kamu dan mencoba untuk menjaga agar keadaan saat itu tersinkronisasi dengan keadaan yang diinginkan. <em>Controller</em> menginterpretasikan data terstruktur sebagai sebuah rekaman dari keadaan yang diinginkan pengguna, dan secara kontinu menjaga keadaan ini.</p><p>Kamu bisa men-<em>deploy</em> dan memperbaharui sebuah <em>controller</em> khusus pada sebuah klaster yang berjalan, secara independen dari siklus hidup klaster itu sendiri. <em>Controller</em> khusus dapat berfungsi dengan sumber daya jenis apapun, tetapi mereka sangat efektif ketika dikombinasikan dengan <em>Custom Resource</em>. <a href=https://coreos.com/blog/introducing-operators.html><em>Operator pattern</em></a> mengkombinasikan <em>Custom Resource</em> dan <em>controller</em> khusus. Kamu bisa menggunakan <em>controller</em> khusus untuk menyandi pengetahuan domain untuk aplikasi spesifik menjadi sebuah ekstensi dari Kubernetes API.</p><h2 id=haruskah-custom-resource-ditambahkan-ke-dalam-klaster-kubernetes-saya>Haruskah <em>Custom Resource</em> ditambahkan ke dalam klaster Kubernetes saya?</h2><p>Ketika membuat sebuah API baru, pikirkan apakah kamu ingin <a href=/docs/concepts/api-extension/apiserver-aggregation/>mengagregasikan API kamu dengan API klaster Kubernetes</a> atau membiarkan API kamu berdiri sendiri.</p><table><thead><tr><th>Pilih agregasi API jika:</th><th>Pilih sebuah API yang berdiri sendiri jika:</th></tr></thead><tbody><tr><td>API kamu bersifat <a href=#api-deklaratif>Deklaratif</a>.</td><td>API kamu tidak cocok dengan model <a href=#api-deklaratif>Deklaratif</a>.</td></tr><tr><td>Kamu mau tipe baru yang dapat dibaca dan ditulis dengan <code>kubectl</code>.</td><td>Dukungan <code>kubectl</code> tidak diperlukan</td></tr><tr><td>Kamu mau melihat tipe baru pada sebuah Kubernetes UI, seperti dasbor, bersama dengan tipe-tipe bawaan.</td><td>Dukungan Kubernetes UI tidak diperlukan.</td></tr><tr><td>Kamu mengembangkan sebuah API baru.</td><td>Kamu memiliki sebuah program yang melayani API kamu dan dapat berkerja dengan baik.</td></tr><tr><td>Kamu bersedia menerima pembatasan format yang Kubernetes terapkan pada jalur sumber daya API (Lihat <a href=/id/docs/concepts/overview/kubernetes-api/>Ikhtisar API</a>.)</td><td>Kamu perlu memiliki jalur REST spesifik agar menjadi cocok dengan REST API yang telah didefinisikan.</td></tr><tr><td>Sumber daya kamu secara alami mencakup hingga sebuah klaster atau sebuah <em>namespace</em> dari sebuah klaster.</td><td>Sumber daya yang mencakup klaster atau <em>namespace</em> adalah sebuah ketidakcocokan; kamu perlu mengendalikan jalur sumber daya spesifik.</td></tr><tr><td>Kamu ingin menggunakan kembali <a href=#fitur-umum>dukungan fitur Kubernetes API</a>.</td><td>Kamu tidak membutuhkan fitur tersebut.</td></tr></tbody></table><h3 id=api-deklaratif>API Deklaratif</h3><p>Dalam sebuah API Deklaratif, biasanya:</p><ul><li>API kamu terdiri dari sejumlah kecil dari objek yang berukuran relatif kecil (sumber daya).</li><li>Objek-objek mendefinisikan pengaturan dari aplikasi atau infrastruktur.</li><li>Objek-objek relatif tidak sering diperbaharui.</li><li>Manusia sering diperlukan untuk membaca dan menulis objek-objek tersebut.</li><li>Operasi utama terhadap objek bersifat CRUD (<em>creating, reading, updating,</em> dan <em>deleting</em>).</li><li>Transaksi antar objek tidak dibutuhkan; API merepresentasikan sebuah keadaan yang diinginkan, bukan keadaan yang eksak.</li></ul><p>API imperatif bersifat tidak deklaratif.
Tanda-tanda apabila API kamu tidak deklaratif termasuk:</p><ul><li>klien berkata "lakukan ini", dan kemudian mendapat sebuah respon serempak ketika selesai.</li><li>klien berkata "lakukan ini", dan kemudian mendapat sebuah ID operasi kembali, dan harus melakukan sebuah cek terhadap objek <em>Operation</em> terpisah untuk menentukan selesainya sebuah permintaan.</li><li>Kamu berbicara tentang <em>Remote Procedure Call</em> (RPC).</li><li>Menyimpan secara langsung sejumlah data (mis. > beberapa kB per objek, atau >1000-an objek).</li><li>Membutuhkan akses dengan <em>bandwidth</em> tinggi (10-an permintaan per detik dapat ditopang).</li><li>Menyimpan data pengguna (seperti gambar, PII, dll) atau data berskala besar yang diproses oleh aplikasi.</li><li>Operasi-operasi natural terhadap objek yang tidak bersifat CRUD.</li><li>API yang tidak mudah dimodelkan dengan objek.</li><li>Kamu memilih untuk merepresentasikan operasi tertunda dengan sebuah ID operasi atau sebuah objek operasi.</li></ul><h2 id=apakah-saya-harus-menggunakan-sebuah-configmap-atau-sebuah-custom-resource>Apakah saya harus menggunakan sebuah ConfigMap atau sebuah <em>Custom Resource</em>?</h2><p>Gunakan ConfigMap jika salah satu hal berikut berlaku:</p><ul><li>Terdapat sebuah format berkas pengaturan yang sudah ada, yang terdokumentasi dengan baik seperti sebuah <code>mysql.cnf</code> atau <code>pom.xml</code>.</li><li>Kamu ingin menaruh seluruh berkas pengaturan kedalam sebuah <em>key</em> dari sebuah ConfigMap.</li><li>Kegunaan utama dari berkas pengaturan adalah untuk dikonsumsi sebuah program yang berjalan di dalam sebuah Pod di dalam klaster kamu untuk mengatur dirinya sendiri.</li><li>Konsumen dari berkas lebih suka untuk mengkonsumsi lewat berkas dalam sebuah Pod atau variabel lingkungan dalam sebuah Pod, dibandingkan melalui Kubernetes API.</li><li>Kamu ingin melakukan pembaharuan bergulir lewat Deployment, dll, ketika berkas diperbaharui.</li></ul><div class="alert alert-info note callout" role=alert><strong>Catatan:</strong> Gunakan sebuah <a href=/id/docs/concepts/configuration/secret/>Secret</a> untuk data sensitif, yang serupa dengan ConfigMap tetapi lebih aman.</div><p>Gunakan sebuah <em>Custom Resource</em> (CRD atau <em>Aggregated API</em>) jika kebanyakan dari hal berikut berlaku:</p><ul><li>Kamu ingin menggunakan pustaka klien Kubernetes dan CLI untuk membuat dan memperbaharui sumber daya baru.</li><li>Kamu ingin dukungan tingkat tinggi dari kubectl (sebagai contoh: <code>kubectl get my-object object-name</code>).</li><li>Kamu ingin membangun sebuah otomasi baru yang mengawasi pembaharuan terhadap objek baru, dan kemudian melakukan CRUD terhadap objek lainnya, atau sebaliknya.</li><li>Kamu ingin menulis otomasi yang menangani pembaharuan untuk objek.</li><li>Kamu ingin menggunakan kesepakatan API Kubernetes seperti <code>.spec</code>, <code>.status</code>, dan <code>.metadata</code>.</li><li>Kamu ingin objek tersebut untuk menjadi sebuah abstraksi terhadap sebuah kumpulan dari sumber daya terkontrol, atau peringkasan dari sumber daya lainnya.</li></ul><h2 id=menambahkan-custom-resource>Menambahkan <em>Custom Resource</em></h2><p>Kubernetes menyediakan dua cara untuk menambahkan sumber daya ke klaster kamu:</p><ul><li>CRD cukup sederhana dan bisa diciptakan tanpa pemrograman apapun.</li><li><a href=/id/docs/concepts/extend-kubernetes/api-extension/apiserver-aggregation/>Agregasi API</a> membutuhkan pemrograman, tetapi memungkinkan kendali lebih terhadap perilaku API seperti bagaimana data disimpan dan perubahan antar versi API.</li></ul><p>Kubernetes menyediakan kedua opsi tersebut untuk memenuhi kebutuhan pengguna berbeda, jadi tidak ada kemudahan penggunaan atau fleksibilitas yang dikompromikan.</p><p><em>Aggregated API</em> adalah bawahan dari APIServer yang duduk dibelakang API server utama, yang bertindak sebagai sebuah <em>proxy</em>. Pengaturan ini disebut <a href=/id/docs/concepts/extend-kubernetes/api-extension/apiserver-aggregation/>Agregasi API</a> (AA). Untuk pengguna, yang terlihat adalah Kubernetes API yang diperluas.</p><p>CRD memungkinkan pengguna untuk membuat tipe baru sumber daya tanpa menambahkan APIserver lain. Kamu tidak perlu mengerti Agregasi API untuk menggunakan CRD.</p><p>Terlepas dari bagaimana cara mereka dipasang, sumber daya baru disebut sebagai <em>Custom Resource</em> untuk memisahkan mereka dari sumber daya bawaan Kubernetes (seperti Pod).</p><h2 id=customresourcedefinition>CustomResourceDefinition</h2><p>Sumber daya API <a href=/docs/tasks/access-kubernetes-api/custom-resources/custom-resource-definitions/>CustomResourceDefinition</a> memungkinkan kamu untuk medefinisikan <em>Custom Resource</em>. Mendefinisikan sebuah objek CRD akan membuat sebuah <em>Custom Resource</em> dengan sebuah nama dan skema yang kamu spesifikasikan. Kubernetes API melayani dan menangani penyimpanan dari <em>Custom Resource</em> kamu.</p><p>Ini membebaskan kamu dari menulis server API kamu sendiri untuk menangani <em>Custom Resource</em>, tetapi sifat dasar dari implementasi menyebabkan kamu memiliki fleksibilitas yang berkurang dibanding <a href=#agregasi-server-api>agregasi server API</a>).</p><p>Lihat <a href=https://github.com/kubernetes/sample-controller>contoh <em>controller</em> khusus</a> sebagai sebuah contoh dari bagaimana cara untuk mendaftarkan sebuah <em>Custom Resource</em>, bekerja dengan instans dari tipe baru sumber daya kamu, dan menggunakan sebuah <em>controller</em> untuk menangani <em>event</em>.</p><h2 id=agregasi-server-api>Agregasi server API</h2><p>Biasanya, tiap sumber daya di API Kubernetes membutuhkan kode yang menangani permintaan REST dan mengatur peyimpanan tetap dari objek-objek. Server Kubernetes API utama menangani sumber daya bawaan seperti Pod dan Service, dan juga menangani <em>Custom Resource</em> dalam sebuah cara yang umum melalui <a href=#customresourcedefinition>CRD</a>.</p><p><a href=/id/docs/concepts/extend-kubernetes/api-extension/apiserver-aggregation/>Lapisan agregasi</a> memungkinkan kamu untuk menyediakan implementasi khusus untuk <em>Custom Resource</em> dengan menulis dan men-<em>deploy</em> API server kamu yang berdiri sendiri. API server utama menlimpahkan permintaan kepada kamu untuk <em>Custom Resource</em> yang kamu tangani, membuat mereka tersedia untuk semua kliennya.</p><h2 id=memilih-sebuah-metode-untuk-menambahkan-custom-resource>Memilih sebuah metode untuk menambahkan <em>Custom Resource</em></h2><p>CRD lebih mudah digunakan. <em>Aggregated API</em> lebih fleksibel. Pilih metode yang paling baik untuk kebutuhan kamu.</p><p>Biasanya, CRD cocok jika:</p><ul><li>Kamu memiliki <em>field</em> yang banyak</li><li>Kamu menggunakan sumber daya dalam perusahaan kamu, atau sebagai bagian dari proyek <em>open-source</em> kecil (berlawanan dengan sebuah produk komersil)</li></ul><h3 id=membandingkan-kemudahan-penggunaan>Membandingkan kemudahan penggunaan</h3><p>CRD lebih mudah dibuat dibandingkan dengan <em>Aggregated API</em>.</p><table><thead><tr><th>CRD</th><th>Aggregated API</th></tr></thead><tbody><tr><td>Tidak membutuhkan pemrograman. Pengguna dapat memilih bahasa apapun untuk sebuah <em>controller</em> CRD.</td><td>Membutuhkan pemrograman dalam Go dan membangun <em>binary</em> dan <em>image</em>. Pengguna dapat memilih bahasa apapun untuk sebuah CRD <em>controller</em>.</td></tr><tr><td>Tidak ada servis tambahan yang dijalankan; CR ditangani oleh server API.</td><td>Sebuah servis tambahan untuk menciptakan dan dapat gagal.</td></tr><tr><td>Todal ada dukungan berjalan ketika CRD dibuat. Perbaikan <em>bug</em> apapun akan dianggap sebagai bagian dari peningkatan Kubernetes Master normal.</td><td>Mungkin dibutuhkan untuk secara berkala mengambil perbaikan <em>bug</em> dari sumber dan membangun ulang dan memeperbaharui APIserver teragregasi.</td></tr><tr><td>Tidak butuh untuk menangani banyak versi dari API kamu. Sebagai contoh: ketika kamu mengendalikan klien untuk sumber daya ini, kamu bisa meningkatkannya selaras dengan API.</td><td>Kamu perlu menangani banyak versi dari API kamu, sebagai contoh: ketika mengembangkan sebuah ekstensi untuk dibagikan kepada dunia.</td></tr></tbody></table><h3 id=fitur-lanjutan-dan-fleksibilitas>Fitur lanjutan dan fleksibilitas</h3><p><em>Aggregated API</em> menawarkan fitur API lebih lanjut dan kustomisasi dari fitur lain, sebagai contoh: lapisan penyimpanan.</p><table><thead><tr><th>Fitur</th><th>Deskripsi</th><th>CRD</th><th>Aggregated API</th></tr></thead><tbody><tr><td>Validation</td><td>Membantu pengguna-pengguna mencegah error dan memungkinkan kamu untuk mengembangkan API kamu secara independen dari klien-klien kamu. Fitur ini sangan berguna ketika ada banyak klien yang tidak semua bisa memperbaharui secara bersamaan pada waktu yang sama.</td><td>Ya. Sebagian besar validasi dapat dipesifikasikan di dalam CRD <a href=/docs/tasks/access-kubernetes-api/extend-api-custom-resource-definitions/#validation>OpenAPI v3.0 <em>validation</em></a>. Validasi bentuk lainnya didukung dengan penambahan sebuah <a href=/docs/reference/access-authn-authz/admission-controllers/#validatingadmissionwebhook-alpha-in-1-8-beta-in-1-9><em>Validating Webhook</em></a>.</td><td>Ya, cek validasi secara arbitrer</td></tr><tr><td>Defaulting</td><td>Lihat diatas</td><td>Ya, baik melalui <a href=/docs/tasks/access-kubernetes-api/extend-api-custom-resource-definitions/#defaulting>OpenAPI v3.0 <em>validation</em></a> <code>default</code> keyword (GA in 1.17), maupun melalui sebuah <a href=/docs/reference/access-authn-authz/admission-controllers/#mutatingadmissionwebhook><em>Mutating Webhook</em></a> (meskipun tidak akan dijalankan ketika membaca dari etcd untuk objek-objek lama)</td><td>Ya</td></tr><tr><td>Multi-versioning</td><td>Memungkinkan menyajikan objek yang sama lwat dua versi API. Bisa membantu memudahkan perubahan API seperti menamai ulang <em>field-field</em>. Tidak terlalu penting jika kamu mengendalikan versi-versi klien kamu.</td><td><a href=/docs/tasks/access-kubernetes-api/custom-resources/custom-resource-definition-versioning>Ya</a></td><td>Ya</td></tr><tr><td>Custom Storage</td><td>Jika kamu membutuhkan penyimpanan dengan sebuah mode performa (sebagai contoh, basis data <em>time-series</em> dibanding penyimpanan <em>key-value</em>) atau isolasi untuk keamanan (sebagau contoh, rahasia penyandian atau berkas berbeda)</td><td>Tidak</td><td>Ya</td></tr><tr><td>Custom Business Logic</td><td>Melakukan cek arbitrer atau tindakan-tindakan ketika membuat, membaca, atau memperbaharui sebuah objek</td><td>Ya, menggunakan <a href=/docs/reference/access-authn-authz/extensible-admission-controllers/#admission-webhooks><em>Webhooks</em></a>.</td><td>Ya</td></tr><tr><td>Scale Subresource</td><td>Memungkinkan sistem-sistem seperti HorizontalPodAutoscaler dan PodDisruptionBudget untuk berinteraksi dengan sumber daya baru</td><td><a href=/docs/tasks/access-kubernetes-api/extend-api-custom-resource-definitions/#scale-subresource>Ya</a></td><td>Ya</td></tr><tr><td>Status Subresource</td><td><ul><li>kontrol akses yang lebih baik: pengguna menulis bagian <em>spec</em>, <em>controller</em> menulis bagian status.</li><li>Memungkinkan pembuatan objek bertambah pada mutasi data <em>Custom Resource</em> (membutuhkan <em>spec</em> terpisah dan bagian status pada sumber daya)</li></ul></td><td><a href=/docs/tasks/access-kubernetes-api/extend-api-custom-resource-definitions/#status-subresource>Ya</a></td><td>Ya</td></tr><tr><td>Other Subresources</td><td>Menambahkan operasi selain CRUD, seperti "logs" atau "exec".</td><td>Tidak</td><td>Ya</td></tr><tr><td>strategic-merge-patch</td><td><em>Endpoint-endpoint</em> baru yang mendukung PATCH dengan <code>Content-Type: application/strategic-merge-patch+json</code>. Berguna untuk memperbaharui objek-objek yang mungkin dapat dimodifikasi baik secara lokal, dan maupun lewat server. Untuk informasi lebih lanjut, lihat <a href=/docs/tasks/run-application/update-api-object-kubectl-patch/>"Update API Objects in Place Using kubectl patch"</a></td><td>Tidak</td><td>Ya</td></tr><tr><td>Protocol Buffers</td><td>sumber daya baru mendukung klien-klien yang ingin menggunakan <em>Protocol Buffer</em></td><td>Tidak</td><td>Ya</td></tr><tr><td>OpenAPI Schema</td><td>Apakah ada sebuah skema OpenAPI (swagger) untuk tipe yang bisa secara dinamis diambil dari server? Apakah pengguna terlindungi dari kesalahan pengejaan nama-nama <em>field</em> dengan memastikan bahwa hanya <em>field</em> yang diperbolehkan yang boleh diisi? Apakah tipe-tipe diberlakukan (dengan kata lain, jangan menaruh sebuah <code>int</code> di dalam <em>field</em> <code>string</code>?)</td><td>Ya, berdasarkan pada skema <a href=/docs/tasks/access-kubernetes-api/extend-api-custom-resource-definitions/#validation>OpenAPI v3.0 validation</a> (GA pada 1.16)</td><td>Ya</td></tr></tbody></table><h3 id=fitur-umum>Fitur Umum</h3><p>Ketika kamu membuat sebuah <em>Custom Resource</em>, baik melalui sebuah CRD atau sebuah AA, kamu mendapat banyak fitur untuk API kamu, dibandingkan dengan mengimplementasikannya diluar platform Kubernetes.</p><table><thead><tr><th>Fitur</th><th>Apa yang dilakukannya</th></tr></thead><tbody><tr><td>CRUD</td><td><em>Endpoint-endpoint</em> baru yang mendukung operasi dasar melalui HTTP dan <code>kubectl</code></td></tr><tr><td>Watch</td><td><em>Endpoint-endpoint</em> baru yang mendukung operasi Kubernetes Watch melalui HTTP</td></tr><tr><td>Discovery</td><td>Klien seperti kubectl dan dasbor yang secara otomatis menawarkan operasi <em>list</em>, <em>display</em>, dan pembaharuan <em>field</em> pada sumber daya kamu.</td></tr><tr><td>json-patch</td><td><em>Endpoint-endpoint</em> baru yang mendukung PATCH dengan <code>Content-Type: application/json-patch+json</code></td></tr><tr><td>merge-patch</td><td><em>Endpoint-endpoint</em> baru yang mendukung PATCH dengan <code>Content-Type: application/merge-patch+json</code></td></tr><tr><td>HTTPS</td><td><em>Endpoint-endpoint</em> menggunakan HTTPS</td></tr><tr><td>Built-in Authentication</td><td>Akses ke ekstensi yang menggunakan <em>apiserver</em> inti (lapisan agregasi) untuk otentikasi</td></tr><tr><td>Built-in Authorization</td><td>Akses ke ekstensi dapat menggunakan ulang otorisasi yang digunakan oleh <em>apiserver</em> inti (mis. RBAC)</td></tr><tr><td>Finalizers</td><td>Penghapusan blok dari ekstensi sumber daya hingga pembersihan eksternal terjadi.</td></tr><tr><td>Admission Webhooks</td><td>Menentukan nilai default dan memvalidasi ekstensi sumber daya saat terjadi operasi <em>create/update/delete</em> apapun.</td></tr><tr><td>UI/CLI Display</td><td>Kubectl, dasbor dapat menampilkan ekstensi sumber daya</td></tr><tr><td>Unset vs Empty</td><td>Klien-klien dapat membedakan <em>field-field</em> yang tidak diisi dari <em>field-field</em> yang memiliki nilai nol.</td></tr><tr><td>Client Libraries Generation</td><td>Kubernetes menyediakan pustaka klien dasar, juga alat-alat untuk membuat pustaka klien dengan tipe spesifik.</td></tr><tr><td>Labels and annotations</td><td>Metadata umum lintas objek yang cara untuk memperbaharui sumber daya inti dan <em>Custom Resource</em>-nya diketahui oleh alat-alat.</td></tr></tbody></table><h2 id=persiapan-pemasangan-sebuah-custom-resource>Persiapan pemasangan sebuah <em>Custom Resource</em></h2><p>Ada beberapa poin yang harus diperhatikan sebelum menambahkan sebuah <em>Custom Resource</em> ke klaster kamu.</p><h3 id=kode-pihak-ketiga-dan-poin-kegagalan-baru>Kode pihak ketiga dan poin kegagalan baru</h3><p>Saat membuat sebuah CRD tidak secara otomatis menambahkan titik-titik kegagalan baru (sebagai contoh, dengan menyebabkan kode pihak ketiga untuk berjalan di API server kamu), paket-paket (sebagai contoh, <em>Chart</em>) atau bundel pemasangan lain seringkali sudah termasuk CRD dan juga sebagai Deployment dari kode pihak ketiga yang mengimplementasi logika bisnis untuk sebuah <em>Custom Resource</em>.</p><p>Memasang sebuah APIserver teragregasi selalu melibatkan tindakan menjalankan Deployment baru.</p><h3 id=penyimpanan>Penyimpanan</h3><p><em>Custom Resource</em> mengkonsumsi ruang penyimpanan dengan cara yang sama dengan ConfigMap. Membuat terlalu banyak sumber daya mungkin akan memenuhi ruang penyimpanan server API kamu.</p><p>Server <em>Aggregated API</em> dapat menggunakan penyimpanan yang sama dengan server API utama, dimana peringatan yang sama berlaku.</p><h3 id=authentication-authorization-and-auditing>Authentication, authorization, and auditing</h3><p>CRD selalu menggunakan otentikasi, otorisasi, dan audit pencatatan yang sama sebagai sumber daya bawaan dari server API kamu.</p><p>Jika kamu menggunakan RBAC untuk otorisasi, sebagian besar <em>role</em> RBAC tidak akan mengizinkan akses ke sumber daya baru (kecuali <em>role cluster-admin</em> atau <em>role</em> apapun yang dibuat menggunakan aturan <em>wildcard</em>). Kamu akan dibutuhkan untuk secara eksplisit mengizinkan akses ke sumber daya baru. CRD dan <em>Aggregated API</em> seringkali dibundel dengan definisi <em>role</em> baru untuk tipe yang mereka tambahkan.</p><p>API server teragregasi dapat atau tidak dapat menggunakan otentikasi, otorisasi, dan pengauditan yang sama dengan server API utama.</p><h2 id=mengakses-sebuah-custom-resource>Mengakses sebuah <em>Custom Resource</em></h2><p><a href=/docs/reference/using-api/client-libraries/>Pustaka klien</a> Kubernetes dapat digunakan untuk mengakses <em>Custom Resource</em>. Tidak semua pustaka klien mendukung <em>Custom Resource</em>. Pustaka klien go dan python melakukannya.</p><p>Ketika kamu menambahkan sebuah <em>Custom Resource</em>, kamu dapat mengaksesnya dengan menggunakan:</p><ul><li>kubectl</li><li>Klien dinamis kubernetes.</li><li>Sebuah klien REST yang kamu tulis</li><li>Sebuah klien yang dibuat menggunakan <a href=https://github.com/kubernetes/code-generator>Kubernetes client generation tools</a> (membuat satu adalah usaha lanjutan, tetapi beberapa proyek mungkin menyajikan sebuah klien bersama dengan CRD atau AA).</li></ul><h2 id=selanjutnya>Selanjutnya</h2><ul><li><p>Belajar bagaimana untuk <a href=/id/docs/concepts/extend-kubernetes/api-extension/apiserver-aggregation/>Memperluas Kubernetes API dengan lapisan agregasi</a>.</p></li><li><p>Belajar bagaimana untuk <a href=/docs/tasks/access-kubernetes-api/custom-resources/custom-resource-definitions/>Memperluas Kubernetes API dengan CustomResourceDefinition</a>.</p></li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-c8937cdc9df96f3328becf04f8211292>12.3 - Ekstensi Komputasi, Penyimpanan, dan Jaringan</h1></div><div class=td-content><h1 id=pg-1ac2260db9ecccbf0303a899bc27ce6d>12.3.1 - Plugin Jaringan</h1><p><div style=margin-top:10px;margin-bottom:10px><b>FEATURE STATE:</b> <code>Kubernetes v1.25 [alpha]</code></div><div class="alert alert-danger warning callout" role=alert><strong>Peringatan:</strong> Fitur-fitur Alpha berubah dengan cepat.</div></p><p><em>Plugin</em> jaringan di Kubernetes hadir dalam beberapa varian:</p><ul><li><em>Plugin</em> CNI : mengikuti spesifikasi appc / CNI, yang dirancang untuk interoperabilitas.</li><li><em>Plugin</em> Kubenet : mengimplementasi <code>cbr0</code> sederhana menggunakan <em>plugin</em> <code>bridge</code> dan <code>host-local</code> CNI</li></ul><h2 id=instalasi>Instalasi</h2><p>Kubelet memiliki <em>plugin</em> jaringan bawaan tunggal, dan jaringan bawaan umum untuk seluruh kluster. <em>Plugin</em> ini memeriksa <em>plugin-plugin</em> ketika dijalankan, mengingat apa yang ditemukannya, dan mengeksekusi <em>plugin</em> yang dipilih pada waktu yang tepat dalam siklus pod (ini hanya berlaku untuk Docker, karena rkt mengelola <em>plugin</em> CNI sendiri). Ada dua parameter perintah Kubelet yang perlu diingat saat menggunakan <em>plugin</em>:</p><ul><li><code>cni-bin-dir</code>: Kubelet memeriksa direktori ini untuk <em>plugin-plugin</em> saat <em>startup</em></li><li><code>network-plugin</code>: <em>Plugin</em> jaringan untuk digunakan dari <code>cni-bin-dir</code>. Ini harus cocok dengan nama yang dilaporkan oleh <em>plugin</em> yang diperiksa dari direktori <em>plugin</em>. Untuk <em>plugin</em> CNI, ini (nilainya) hanyalah "cni".</li></ul><h2 id=persyaratan-plugin-jaringan>Persyaratan <em>Plugin</em> Jaringan</h2><p>Selain menyediakan <a href=https://github.com/kubernetes/kubernetes/tree/v1.25.0/pkg/kubelet/dockershim/network/plugins.go>antarmuka <code>NetworkPlugin</code></a> untuk mengonfigurasi dan membersihkan jaringan Pod, <em>plugin</em> ini mungkin juga memerlukan dukungan khusus untuk kube-proxy. Proksi <em>iptables</em> jelas tergantung pada <em>iptables</em>, dan <em>plugin</em> ini mungkin perlu memastikan bahwa lalu lintas kontainer tersedia untuk <em>iptables</em>. Misalnya, jika plugin menghubungkan kontainer ke <em>bridge</em> Linux, <em>plugin</em> harus mengatur nilai sysctl <code>net/bridge/bridge-nf-call-iptables</code> menjadi <code>1</code> untuk memastikan bahwa proksi <em>iptables</em> berfungsi dengan benar. Jika <em>plugin</em> ini tidak menggunakan <em>bridge</em> Linux (melainkan sesuatu seperti Open vSwitch atau mekanisme lainnya), <em>plugin</em> ini harus memastikan lalu lintas kontainer dialihkan secara tepat untuk proksi.</p><p>Secara bawaan jika tidak ada <em>plugin</em> jaringan Kubelet yang ditentukan, <em>plugin</em> <code>noop</code> digunakan, yang menetapkan <code>net/bridge/bridge-nf-call-iptables=1</code> untuk memastikan konfigurasi sederhana (seperti Docker dengan sebuah <em>bridge</em>) bekerja dengan benar dengan proksi <em>iptables</em>.</p><h3 id=cni>CNI</h3><p><em>Plugin</em> CNI dipilih dengan memberikan opsi <em>command-line</em> <code>--network-plugin=cni</code> pada Kubelet. Kubelet membaca berkas dari <code>--cni-conf-dir</code> (bawaan <code>/etc/cni/net.d</code>) dan menggunakan konfigurasi CNI dari berkas tersebut untuk mengatur setiap jaringan Pod. Berkas konfigurasi CNI harus sesuai dengan <a href=https://github.com/containernetworking/cni/blob/master/SPEC.md#network-configuration>spesifikasi CNI</a>, dan setiap <em>plugin</em> CNI yang diperlukan oleh konfigurasi harus ada di <code>--cni-bin-dir</code> (nilai bawaannya adalah <code>/opt/cni/bin</code>).</p><p>Jika ada beberapa berkas konfigurasi CNI dalam direktori, Kubelet menggunakan berkas yang pertama dalam urutan abjad.</p><p>Selain plugin CNI yang ditentukan oleh berkas konfigurasi, Kubernetes memerlukan <em>plugin</em> CNI standar <a href=https://github.com/containernetworking/plugins/blob/master/plugins/main/loopback/loopback.go><code>lo</code></a> <em>plugin</em> , minimal pada versi 0.2.0.</p><h4 id=dukungan-hostport>Dukungan hostPort</h4><p><em>Plugin</em> jaringan CNI mendukung <code>hostPort</code>. Kamu dapat menggunakan <em>plugin</em> <a href=https://github.com/containernetworking/plugins/tree/master/plugins/meta/portmap>portmap</a> resmi yang ditawarkan oleh tim <em>plugin</em> CNI atau menggunakan <em>plugin</em> kamu sendiri dengan fungsionalitas <em>portMapping</em>.</p><p>Jika kamu ingin mengaktifkan dukungan <code>hostPort</code>, kamu harus menentukan <code>portMappings capability</code> di <code>cni-conf-dir</code> kamu.
Contoh:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-json data-lang=json><span style=display:flex><span>{
</span></span><span style=display:flex><span>  <span style=color:green;font-weight:700>&#34;name&#34;</span>: <span style=color:#b44>&#34;k8s-pod-network&#34;</span>,
</span></span><span style=display:flex><span>  <span style=color:green;font-weight:700>&#34;cniVersion&#34;</span>: <span style=color:#b44>&#34;0.4.0&#34;</span>,
</span></span><span style=display:flex><span>  <span style=color:green;font-weight:700>&#34;plugins&#34;</span>: [
</span></span><span style=display:flex><span>    {
</span></span><span style=display:flex><span>      <span style=color:green;font-weight:700>&#34;type&#34;</span>: <span style=color:#b44>&#34;calico&#34;</span>,
</span></span><span style=display:flex><span>      <span style=color:green;font-weight:700>&#34;log_level&#34;</span>: <span style=color:#b44>&#34;info&#34;</span>,
</span></span><span style=display:flex><span>      <span style=color:green;font-weight:700>&#34;datastore_type&#34;</span>: <span style=color:#b44>&#34;kubernetes&#34;</span>,
</span></span><span style=display:flex><span>      <span style=color:green;font-weight:700>&#34;nodename&#34;</span>: <span style=color:#b44>&#34;127.0.0.1&#34;</span>,
</span></span><span style=display:flex><span>      <span style=color:green;font-weight:700>&#34;ipam&#34;</span>: {
</span></span><span style=display:flex><span>        <span style=color:green;font-weight:700>&#34;type&#34;</span>: <span style=color:#b44>&#34;host-local&#34;</span>,
</span></span><span style=display:flex><span>        <span style=color:green;font-weight:700>&#34;subnet&#34;</span>: <span style=color:#b44>&#34;usePodCidr&#34;</span>
</span></span><span style=display:flex><span>      },
</span></span><span style=display:flex><span>      <span style=color:green;font-weight:700>&#34;policy&#34;</span>: {
</span></span><span style=display:flex><span>        <span style=color:green;font-weight:700>&#34;type&#34;</span>: <span style=color:#b44>&#34;k8s&#34;</span>
</span></span><span style=display:flex><span>      },
</span></span><span style=display:flex><span>      <span style=color:green;font-weight:700>&#34;kubernetes&#34;</span>: {
</span></span><span style=display:flex><span>        <span style=color:green;font-weight:700>&#34;kubeconfig&#34;</span>: <span style=color:#b44>&#34;/etc/cni/net.d/calico-kubeconfig&#34;</span>
</span></span><span style=display:flex><span>      }
</span></span><span style=display:flex><span>    },
</span></span><span style=display:flex><span>    {
</span></span><span style=display:flex><span>      <span style=color:green;font-weight:700>&#34;type&#34;</span>: <span style=color:#b44>&#34;portmap&#34;</span>,
</span></span><span style=display:flex><span>      <span style=color:green;font-weight:700>&#34;capabilities&#34;</span>: {<span style=color:green;font-weight:700>&#34;portMappings&#34;</span>: <span style=color:#a2f;font-weight:700>true</span>}
</span></span><span style=display:flex><span>    }
</span></span><span style=display:flex><span>  ]
</span></span><span style=display:flex><span>}
</span></span></code></pre></div><h4 id=dukungan-pembentukan-lalu-lintas>Dukungan pembentukan lalu-lintas</h4><p><em>Plugin</em> jaringan CNI juga mendukung pembentukan lalu-lintas yang masuk dan keluar dari Pod. Kamu dapat menggunakan <em>plugin</em> resmi <a href=https://github.com/containernetworking/plugins/tree/master/plugins/meta/bandwidth><em>bandwidth</em></a> yang ditawarkan oleh tim <em>plugin</em> CNI atau menggunakan <em>plugin</em> kamu sendiri dengan fungsionalitas kontrol <em>bandwidth</em>.</p><p>Jika kamu ingin mengaktifkan pembentukan lalu-lintas, kamu harus menambahkan <em>plugin</em> <code>bandwidth</code> ke berkas konfigurasi CNI kamu (nilai bawaannya adalah <code>/etc/cni/ net.d</code>).</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-json data-lang=json><span style=display:flex><span>{
</span></span><span style=display:flex><span>  <span style=color:green;font-weight:700>&#34;name&#34;</span>: <span style=color:#b44>&#34;k8s-pod-network&#34;</span>,
</span></span><span style=display:flex><span>  <span style=color:green;font-weight:700>&#34;cniVersion&#34;</span>: <span style=color:#b44>&#34;0.4.0&#34;</span>,
</span></span><span style=display:flex><span>  <span style=color:green;font-weight:700>&#34;plugins&#34;</span>: [
</span></span><span style=display:flex><span>    {
</span></span><span style=display:flex><span>      <span style=color:green;font-weight:700>&#34;type&#34;</span>: <span style=color:#b44>&#34;calico&#34;</span>,
</span></span><span style=display:flex><span>      <span style=color:green;font-weight:700>&#34;log_level&#34;</span>: <span style=color:#b44>&#34;info&#34;</span>,
</span></span><span style=display:flex><span>      <span style=color:green;font-weight:700>&#34;datastore_type&#34;</span>: <span style=color:#b44>&#34;kubernetes&#34;</span>,
</span></span><span style=display:flex><span>      <span style=color:green;font-weight:700>&#34;nodename&#34;</span>: <span style=color:#b44>&#34;127.0.0.1&#34;</span>,
</span></span><span style=display:flex><span>      <span style=color:green;font-weight:700>&#34;ipam&#34;</span>: {
</span></span><span style=display:flex><span>        <span style=color:green;font-weight:700>&#34;type&#34;</span>: <span style=color:#b44>&#34;host-local&#34;</span>,
</span></span><span style=display:flex><span>        <span style=color:green;font-weight:700>&#34;subnet&#34;</span>: <span style=color:#b44>&#34;usePodCidr&#34;</span>
</span></span><span style=display:flex><span>      },
</span></span><span style=display:flex><span>      <span style=color:green;font-weight:700>&#34;policy&#34;</span>: {
</span></span><span style=display:flex><span>        <span style=color:green;font-weight:700>&#34;type&#34;</span>: <span style=color:#b44>&#34;k8s&#34;</span>
</span></span><span style=display:flex><span>      },
</span></span><span style=display:flex><span>      <span style=color:green;font-weight:700>&#34;kubernetes&#34;</span>: {
</span></span><span style=display:flex><span>        <span style=color:green;font-weight:700>&#34;kubeconfig&#34;</span>: <span style=color:#b44>&#34;/etc/cni/net.d/calico-kubeconfig&#34;</span>
</span></span><span style=display:flex><span>      }
</span></span><span style=display:flex><span>    },
</span></span><span style=display:flex><span>    {
</span></span><span style=display:flex><span>      <span style=color:green;font-weight:700>&#34;type&#34;</span>: <span style=color:#b44>&#34;bandwidth&#34;</span>,
</span></span><span style=display:flex><span>      <span style=color:green;font-weight:700>&#34;capabilities&#34;</span>: {<span style=color:green;font-weight:700>&#34;bandwidth&#34;</span>: <span style=color:#a2f;font-weight:700>true</span>}
</span></span><span style=display:flex><span>    }
</span></span><span style=display:flex><span>  ]
</span></span><span style=display:flex><span>}
</span></span></code></pre></div><p>Sekarang kamu dapat menambahkan anotasi <code>kubernetes.io/ingress-bandwidth</code> dan <code>kubernetes.io/egress-bandwidth</code> ke Pod kamu.
Contoh:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>annotations</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>kubernetes.io/ingress-bandwidth</span>:<span style=color:#bbb> </span>1M<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>kubernetes.io/egress-bandwidth</span>:<span style=color:#bbb> </span>1M<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:#00f;font-weight:700>...</span><span style=color:#bbb>
</span></span></span></code></pre></div><h3 id=kubenet>Kubenet</h3><p>Kubenet adalah <em>plugin</em> jaringan yang sangat mendasar dan sederhana, hanya untuk Linux. Ia, tidak dengan sendirinya, mengimplementasi fitur-fitur yang lebih canggih seperti jaringan <em>cross-node</em> atau kebijakan jaringan. Ia biasanya digunakan bersamaan dengan penyedia layanan cloud yang menetapkan aturan <em>routing</em> untuk komunikasi antar Node, atau dalam lingkungan Node tunggal.</p><p>Kubenet membuat <em>bridge</em> Linux bernama <code>cbr0</code> dan membuat pasangan <em>veth</em> untuk setiap Pod dengan ujung <em>host</em> dari setiap pasangan yang terhubung ke <code>cbr0</code>. Ujung Pod dari pasangan diberi alamat IP yang dialokasikan dari rentang yang ditetapkan untuk Node baik melalui konfigurasi atau oleh controller-manager. <code>cbr0</code> memiliki MTU yang cocok dengan MTU terkecil dari antarmuka normal yang diaktifkan pada <em>host</em>.</p><p><em>Plugin</em> ini memerlukan beberapa hal:</p><ul><li><em>Plugin</em> CNI <code>bridge</code>, <code>lo</code> dan <code>host-local</code> standar diperlukan, minimal pada versi 0.2.0. Kubenet pertama-tama akan mencari mereka di <code>/opt/cni/bin</code>. Tentukan <code>cni-bin-dir</code> untuk menyediakan lokasi pencarian tambahan. Hasil pencarian pertama akan digunakan.</li><li>Kubelet harus dijalankan dengan argumen <code>--network-plugin=kubenet</code> untuk mengaktifkan <em>plugin</em></li><li>Kubelet juga harus dijalankan dengan argumen <code>--non-masquerade-cidr=&lt;clusterCidr></code> untuk memastikan lalu-lintas ke IP-IP di luar rentang ini akan menggunakan <em>masquerade</em> IP.</li><li>Node harus diberi subnet IP melalui perintah kubelet <code>--pod-cidr</code> atau perintah controller-manager <code>--allocate-node-cidrs=true --cluster-cidr=&lt;cidr></code>.</li></ul><h3 id=menyesuaikan-mtu-dengan-kubenet>Menyesuaikan MTU (dengan kubenet)</h3><p>MTU harus selalu dikonfigurasi dengan benar untuk mendapatkan kinerja jaringan terbaik. <em>Plugin</em> jaringan biasanya akan mencoba membuatkan MTU yang masuk akal, tetapi terkadang logika tidak akan menghasilkan MTU yang optimal. Misalnya, jika <em>bridge</em> Docker atau antarmuka lain memiliki MTU kecil, kubenet saat ini akan memilih MTU tersebut. Atau jika kamu menggunakan enkapsulasi IPSEC, MTU harus dikurangi, dan perhitungan ini di luar cakupan untuk sebagian besar <em>plugin</em> jaringan.</p><p>Jika diperlukan, kamu dapat menentukan MTU secara eksplisit dengan opsi <code>network-plugin-mtu</code> kubelet. Sebagai contoh, pada AWS <code>eth0</code> MTU biasanya adalah 9001, jadi kamu dapat menentukan <code>--network-plugin-mtu=9001</code>. Jika kamu menggunakan IPSEC, kamu dapat menguranginya untuk memungkinkan/mendukung <em>overhead</em> enkapsulasi pada IPSEC, contoh: <code>--network-plugin-mtu=8873</code>.</p><p>Opsi ini disediakan untuk <em>plugin</em> jaringan; Saat ini <strong>hanya kubenet yang mendukung <code>network-plugin-mtu</code></strong>.</p><h2 id=ringkasan-penggunaan>Ringkasan Penggunaan</h2><ul><li><code>--network-plugin=cni</code> menetapkan bahwa kita menggunakan <em>plugin</em> jaringan <code>cni</code> dengan <em>binary-binary plugin</em> CNI aktual yang terletak di <code>--cni-bin-dir</code> (nilai bawaannya <code>/opt/cni/bin</code>) dan konfigurasi <em>plugin</em> CNI yang terletak di <code>--cni-conf-dir</code> (nilai bawaannya <code>/etc/cni/net.d</code>).</li><li><code>--network-plugin=kubenet</code> menentukan bahwa kita menggunakan <em>plugin</em> jaringan <code>kubenet</code> dengan <code>bridge</code> CNI dan <em>plugin-plugin</em> <code>host-local</code> yang terletak di <code>/opt/cni/bin</code> atau <code>cni-bin-dir</code>.</li><li><code>--network-plugin-mtu=9001</code> menentukan MTU yang akan digunakan, saat ini hanya digunakan oleh <em>plugin</em> jaringan <code>kubenet</code>.</li></ul><h2 id=selanjutnya>Selanjutnya</h2></div><div class=td-content style=page-break-before:always><h1 id=pg-53e1ea8892ceca307ba19e8d6a7b8d32>12.3.2 - Plugin Perangkat</h1><div class=lead>Gunakan kerangka kerja <em>plugin</em> perangkat Kubernetes untuk mengimplementasikan plugin untuk GPU, NIC, FPGA, InfiniBand, dan sumber daya sejenis yang membutuhkan setelan spesifik vendor.</div><div style=margin-top:10px;margin-bottom:10px><b>FEATURE STATE:</b> <code>Kubernetes v1.10 [beta]</code></div><p>Kubernetes menyediakan <a href=https://github.com/kubernetes/community/blob/master/contributors/design-proposals/resource-management/device-plugin.md>kerangka kerja <em>plugin</em> perangkat</a>
sehingga kamu dapat memakainya untuk memperlihatkan sumber daya perangkat keras sistem ke dalam <a class=glossary-tooltip title='Agen yang dijalankan pada setiap node di klaster yang bertugas untuk memastikan kontainer dijalankan di dalam Pod.' data-toggle=tooltip data-placement=top href=/docs/reference/generated/kubelet target=_blank aria-label=Kubelet>Kubelet</a>.</p><p>Daripada menkustomisasi kode Kubernetes itu sendiri, vendor dapat mengimplementasikan
<em>plugin</em> perangkat yang di-<em>deploy</em> secara manual atau sebagai <a class=glossary-tooltip title='Memastikan salinan Pod dijalankan pada sekumpulan Node dalam satu klaster.' data-toggle=tooltip data-placement=top href=/id/docs/concepts/workloads/controllers/daemonset target=_blank aria-label=DaemonSet>DaemonSet</a>.
Perangkat yang dituju termasuk GPU, NIC berkinerja tinggi, FPGA, adaptor InfiniBand,
dan sumber daya komputasi sejenis lainnya yang perlu inisialisasi dan setelan spesifik vendor.</p><h2 id=pendaftaran-plugin-perangkat>Pendaftaran <em>plugin</em> perangkat</h2><p>Kubelet mengekspor servis gRPC <code>Registration</code>:</p><pre tabindex=0><code class=language-gRPC data-lang=gRPC>service Registration {
	rpc Register(RegisterRequest) returns (Empty) {}
}
</code></pre><p>Plugin perangkat bisa mendaftarkan dirinya sendiri dengan kubelet melalui servis gRPC.
Dalam pendaftaran, <em>plugin</em> perangkat perlu mengirim:</p><ul><li>Nama Unix socket-nya.</li><li>Versi API Plugin Perangkat yang dipakai.</li><li><code>ResourceName</code> yang ingin ditunjukkan. <code>ResourceName</code> ini harus mengikuti
<a href=/id/docs/concepts/configuration/manage-compute-resources-container/#extended-resources>skema penamaan sumber daya ekstensi</a>
sebagai <code>vendor-domain/tipe-sumber-daya</code>.
(Contohnya, NVIDIA GPU akan dinamai <code>nvidia.com/gpu</code>.)</li></ul><p>Setelah registrasi sukses, <em>plugin</em> perangkat mengirim daftar perangkat yang diatur
ke kubelet, lalu kubelet kemudian bertanggung jawab untuk mengumumkan sumber daya tersebut
ke peladen API sebagai bagian pembaruan status node kubelet.
Contohnya, setelah <em>plugin</em> perangkat mendaftarkan <code>hardware-vendor.example/foo</code> dengan kubelet
dan melaporkan kedua perangkat dalam node dalam kondisi sehat, status node diperbarui
untuk menunjukkan bahwa node punya 2 perangkat “Foo” terpasang dan tersedia.</p><p>Kemudian, pengguna dapat meminta perangkat dalam spesifikasi
<a href=/docs/reference/generated/kubernetes-api/v1.25/#container-v1-core>Kontainer</a>
seperti meminta tipe sumber daya lain, dengan batasan berikut:</p><ul><li>Sumber daya ekstensi hanya didukung sebagai sumber daya integer dan tidak bisa <em>overcommitted</em>.</li><li>Perangkat tidak bisa dibagikan antar Kontainer.</li></ul><p>Semisal klaster Kubernetes menjalankan <em>plugin</em> perangkat yang menunjukkan sumber daya <code>hardware-vendor.example/foo</code>
pada node tertentu. Berikut contoh Pod yang meminta sumber daya itu untuk menjalankan demo beban kerja:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#00f;font-weight:700>---</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>demo-pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>demo-container-1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>k8s.gcr.io/pause:2.0<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>resources</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>limits</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>hardware-vendor.example/foo</span>:<span style=color:#bbb> </span><span style=color:#666>2</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:#080;font-style:italic>#</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:#080;font-style:italic># Pod ini perlu 2 perangkat perangkat-vendor.example/foo</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:#080;font-style:italic># dan hanya dapat menjadwalkan ke Node yang bisa memenuhi</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:#080;font-style:italic># kebutuhannya.</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:#080;font-style:italic>#</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:#080;font-style:italic># Jika Node punya lebih dari 2 perangkat tersedia,</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:#080;font-style:italic># maka kelebihan akan dapat digunakan Pod lainnya.</span><span style=color:#bbb>
</span></span></span></code></pre></div><h2 id=implementasi-plugin-perangkat>Implementasi <em>plugin</em> perangkat</h2><p>Alur kerja umum dari <em>plugin</em> perangkat adalah sebagai berikut:</p><ul><li><p>Inisiasi. Selama fase ini, <em>plugin</em> perangkat melakukan inisiasi spesifik vendor
dan pengaturan untuk memastikan perangkat pada status siap.</p></li><li><p>Plugin memulai servis gRPC, dengan Unix socket pada lokasi
<code>/var/lib/kubelet/device-plugins/</code>, yang mengimplementasi antarmuka berikut:</p><pre tabindex=0><code class=language-gRPC data-lang=gRPC>service DevicePlugin {
      // ListAndWatch mengembalikan aliran dari List of Devices
      // Kapanpun Device menyatakan perubahan atau kehilangan Device, ListAndWatch
      // mengembalikan daftar baru
      rpc ListAndWatch(Empty) returns (stream ListAndWatchResponse) {}

      // Allocate dipanggil saat pembuatan kontainer sehingga Device
      // Plugin dapat menjalankan operasi spesifik perangkat dan menyuruh Kubelet
      // dari operasi untuk membuat Device tersedia di kontainer
      rpc Allocate(AllocateRequest) returns (AllocateResponse) {}
}
</code></pre></li><li><p>Plugin mendaftarkan dirinya sendiri dengan kubelet melalui Unix socket pada lokasi host
<code>/var/lib/kubelet/device-plugins/kubelet.sock</code>.</p></li><li><p>Seteleh sukses mendaftarkan dirinya sendiri, <em>plugin</em> perangkat berjalan dalam mode peladen, dan selama itu
dia tetap mengawasi kesehatan perangkat dan melaporkan balik ke kubelet terhadap perubahan status perangkat.
Dia juga bertanggung jawab untuk melayani <em>request</em> gRPC <code>Allocate</code>. Selama <code>Allocate</code>, <em>plugin</em> perangkat dapat
membuat persiapan spesifik-perangkat; contohnya, pembersihan GPU atau inisiasi QRNG.
Jika operasi berhasil, <em>plugin</em> perangkat mengembalikan <code>AllocateResponse</code> yang memuat konfigurasi
runtime kontainer untuk mengakses perangkat teralokasi. Kubelet memberikan informasi ini ke runtime kontainer.</p></li></ul><h3 id=menangani-kubelet-yang-restart>Menangani kubelet yang <em>restart</em></h3><p>Plugin perangkat diharapkan dapat mendeteksi kubelet yang <em>restart</em> dan mendaftarkan dirinya sendiri kembali dengan
<em>instance</em> kubelet baru. Pada implementasi sekarang, sebuah <em>instance</em> kubelet baru akan menghapus semua socket Unix yang ada
di dalam <code>/var/lib/kubelet/device-plugins</code> ketika dijalankan. Plugin perangkat dapat mengawasi penghapusan
socket Unix miliknya dan mendaftarkan dirinya sendiri kembali ketika hal tersebut terjadi.</p><h2 id=deployment-plugin-perangkat>Deployment <em>plugin</em> perangkat</h2><p>Kamu dapat melakukan <em>deploy</em> sebuah <em>plugin</em> perangkat sebagai DaemonSet, sebagai sebuah paket untuk sistem operasi node-mu,
atau secara manual.</p><p>Direktori <em>canonical</em> <code>/var/lib/kubelet/device-plugins</code> membutuhkan akses berprivilese,
sehingga <em>plugin</em> perangkat harus berjalan dalam konteks keamanan dengan privilese.
Jika kamu melakukan <em>deploy</em> <em>plugin</em> perangkat sebagai DaemonSet, <code>/var/lib/kubelet/device-plugins</code>
harus dimuat sebagai <a class=glossary-tooltip title='Sebuah direktori yang mengandung data, dapat diakses o;eh kontainer-kontainer di dalam pod.' data-toggle=tooltip data-placement=top href=/docs/concepts/storage/volumes/ target=_blank aria-label=Volume>Volume</a> pada
<a href=/docs/reference/generated/kubernetes-api/v1.25/#podspec-v1-core>PodSpec</a>
plugin.</p><p>Jika kamu memilih pendekatan DaemonSet, kamu dapat bergantung pada Kubernetes untuk meletakkan Pod
<em>plugin</em> perangkat ke Node, memulai-ulang Pod daemon setelah kegagalan, dan membantu otomasi pembaruan.</p><h2 id=kecocokan-api>Kecocokan API</h2><p>Dukungan pada <em>plugin</em> perangkat Kubernetes sedang dalam beta. API dapat berubah hingga stabil,
dalam cara yang tidak kompatibel. Sebagai proyek, Kubernetes merekomendasikan para developer <em>plugin</em> perangkat:</p><ul><li>Mengamati perubahan pada rilis mendatang.</li><li>Mendukung versi API <em>plugin</em> perangkat berbeda untuk kompatibilitas-maju/mundur.</li></ul><p>Jika kamu menyalakan fitur DevicePlugins dan menjalankan <em>plugin</em> perangkat pada node yang perlu diperbarui
ke rilis Kubernetes dengan versi API plugin yang lebih baru, perbarui <em>plugin</em> perangkatmu
agar mendukung kedua versi sebelum membarui para node ini. Memilih pendekatan demikian akan
menjamin fungsi berkelanjutan dari alokasi perangkat selama pembaruan.</p><h2 id=mengawasi-sumber-daya-plugin-perangkat>Mengawasi Sumber Daya Plugin Perangkat</h2><div style=margin-top:10px;margin-bottom:10px><b>FEATURE STATE:</b> <code>Kubernetes v1.15 [beta]</code></div><p>Dalam rangka mengawasi sumber daya yang disediakan <em>plugin</em> perangkat, agen monitoring perlu bisa
menemukan kumpulan perangkat yang terpakai dalam node dan mengambil metadata untuk mendeskripsikan
pada kontainer mana metrik harus diasosiasikan. Metrik <a href=https://prometheus.io/>prometheus</a>
diekspos oleh agen pengawas perangkat harus mengikuti
<a href=https://github.com/kubernetes/community/blob/master/contributors/devel/sig-instrumentation/instrumentation.md>Petunjuk Instrumentasi Kubernetes</a>,
mengidentifikasi kontainer dengan label prometheus <code>pod</code>, <code>namespace</code>, dan <code>container</code>.</p><p>Kubelet menyediakan servis gRPC untuk menyalakan pencarian perangkat yang terpakai, dan untuk menyediakan metadata
untuk perangkat berikut:</p><pre tabindex=0><code class=language-gRPC data-lang=gRPC>// PodResourcesLister adalah layanan yang disediakan kubelet untuk menyediakan informasi tentang
// sumber daya node yang dikonsumsi Pod dan kontainer pada node
service PodResourcesLister {
    rpc List(ListPodResourcesRequest) returns (ListPodResourcesResponse) {}
}
</code></pre><p>Servis gRPC dilayani lewat socket unix pada <code>/var/lib/kubelet/pod-resources/kubelet.sock</code>.
Agen pengawas untuk sumber daya <em>plugin</em> perangkat dapat di-<em>deploy</em> sebagai daemon, atau sebagai DaemonSet.
Direktori <em>canonical</em> <code>/var/lib/kubelet/pod-resources</code> perlu akses berprivilese,
sehingga agen pengawas harus berjalan dalam konteks keamanan dengan privilese. Jika agen pengawas perangkat berjalan
sebagai DaemonSet, <code>/var/lib/kubelet/pod-resources</code> harus dimuat sebagai
<a class=glossary-tooltip title='Sebuah direktori yang mengandung data, dapat diakses o;eh kontainer-kontainer di dalam pod.' data-toggle=tooltip data-placement=top href=/docs/concepts/storage/volumes/ target=_blank aria-label=Volume>Volume</a> pada plugin
<a href=/docs/reference/generated/kubernetes-api/v1.25/#podspec-v1-core>PodSpec</a>.</p><p>Dukungan untuk "servis PodResources" butuh <a href=/docs/reference/command-line-tools-reference/feature-gates/>gerbang fitur</a>
<code>KubeletPodResources</code> untuk dinyalakan. Mulai dari Kubernetes 1.15 nilai bawaannya telah dinyalakan.</p><h2 id=integrasi-plugin-perangkat-dengan-topology-manager>Integrasi Plugin Perangkat dengan Topology Manager</h2><div style=margin-top:10px;margin-bottom:10px><b>FEATURE STATE:</b> <code>Kubernetes v1.17 [alpha]</code></div><p>Topology Manager adalah komponen Kubelet yang membolehkan sumber daya untuk dikoordinasi secara selaras dengan Topology. Untuk melakukannya, API Plugin Perangkat telah dikembangkan untuk memasukkan struct <code>TopologyInfo</code>.</p><pre tabindex=0><code class=language-gRPC data-lang=gRPC>message TopologyInfo {
	repeated NUMANode nodes = 1;
}

message NUMANode {
    int64 ID = 1;
}
</code></pre><p>Plugin Perangkat yang ingin memanfaatkan Topology Manager dapat mengembalikan beberapa <em>struct</em> TopologyInfo sebagai bagian dari pendaftaran perangkat, bersama dengan ID perangkat dan status kesehatan perangkat. Manajer perangkat akan memakai informasi ini untuk konsultasi dengan Topology Manager dan membuat keputusan alokasi sumber daya.</p><p><code>TopologyInfo</code> mendukung kolom <code>nodes</code> yang bisa <code>nil</code> (sebagai bawaan) atau daftar node NUMA. Ini membuat Plugin Perangkat mengumumkan apa saja yang bisa meliputi node NUMA.</p><p>Contoh <em>struct</em> <code>TopologyInfo</code> untuk perangkat yang dipopulate oleh Plugin Perangkat:</p><pre tabindex=0><code>pluginapi.Device{ID: &#34;25102017&#34;, Health: pluginapi.Healthy, Topology:&amp;pluginapi.TopologyInfo{Nodes: []*pluginapi.NUMANode{&amp;pluginapi.NUMANode{ID: 0,},}}}
</code></pre><h2 id=contoh>Contoh <em>plugin</em> perangkat</h2><p>Berikut beberapa contoh implementasi <em>plugin</em> perangkat:</p><ul><li><a href=https://github.com/RadeonOpenCompute/k8s-device-plugin>Plugin perangkat AMD GPU</a></li><li><a href=https://github.com/intel/intel-device-plugins-for-kubernetes>Plugin perangkat Intel</a> untuk perangkat GPU, FPGA, dan QuickAssist Intel</li><li><a href=https://github.com/kubevirt/kubernetes-device-plugins>Plugin perangkat KubeVirt</a> untuk virtualisasi hardware-assisted</li><li><a href=https://github.com/NVIDIA/k8s-device-plugin>Plugin perangkat NVIDIA GPU</a><ul><li>Perlu <a href=https://github.com/NVIDIA/nvidia-docker>nvidia-docker</a> versi 2.0 yang memungkinkan untuk menjalakan kontainer Docker yang memuat GPU.</li></ul></li><li><a href=https://github.com/GoogleCloudPlatform/container-engine-accelerators/tree/master/cmd/nvidia_gpu>Plugin perangkat NVIDIA GPU untuk Container-Optimized OS</a></li><li><a href=https://github.com/hustcat/k8s-rdma-device-plugin>Plugin perangkat RDMA</a></li><li><a href=https://github.com/vikaschoudhary16/sfc-device-plugin>Plugin perangkat Solarflare</a></li><li><a href=https://github.com/intel/sriov-network-device-plugin>Plugin perangkat SR-IOV Network</a></li><li><a href=https://github.com/Xilinx/FPGA_as_a_Service/tree/master/k8s-fpga-device-plugin>Plugin perangkat Xilinx FPGA</a> untuk perangkat Xilinx FPGA</li></ul><h2 id=selanjutnya>Selanjutnya</h2><ul><li>Pelajari bagaimana <a href=/docs/tasks/manage-gpus/scheduling-gpus/>menjadwalkan sumber daya GPU</a> dengan <em>plugin</em> perangkat</li><li>Pelajari bagaimana <a href=/docs/tasks/administer-cluster/extended-resource-node/>mengumumkan sumber daya ekstensi</a> pada node</li><li>Baca tentang penggunaan <a href=https://kubernetes.io/blog/2019/04/24/hardware-accelerated-ssl/tls-termination-in-ingress-controllers-using-kubernetes-device-plugins-and-runtimeclass/>akselerasi perangkat keras untuk ingress TLS</a> dengan Kubernetes</li><li>Pelajari tentang [Topology Manager] (/docs/tasks/adminster-cluster/topology-manager/)</li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-3131452556176159fb269593c1a52012>12.4 - Pola Operator</h1><p>Operator adalah ekstensi perangkat lunak untuk Kubernetes yang memanfaatkan
<a href=/id/docs/concepts/extend-kubernetes/api-extension/custom-resources/><em>custom resource</em></a>
untuk mengelola aplikasi dan komponen-komponennya. Operator mengikuti prinsip
Kubernetes, khususnya dalam hal <a href=/docs/concepts/#kubernetes-control-plane><em>control loop</em></a>.</p><h2 id=motivasi>Motivasi</h2><p>Pola dari Operator bertujuan untuk menangkap tujuan utama dari Operator manusia
yang mengelola layanan atau suatu kumpulan layanan. Operator manusia yang
menjaga spesifik aplikasi dan layanan memiliki pengetahuan yang mendalam tentang
bagaimana sistem harus berperilaku, bagaimana cara menyebarkannya, dan
bagaimana bereaksi jika ada masalah.</p><p>Orang-orang yang menjalankan <em>workload-workload</em> di Kubernetes pada umumnya suka
menggunakan otomatisasi untuk menangani tugas-tugas yang berulang. Pola
Operator menangkap bagaimana kamu dapat menulis kode untuk mengotomatiskan
sebuah tugas di luar batas apa yang dapat disediakan oleh Kubernetes itu
sendiri.</p><h2 id=operator-di-kubernetes>Operator di Kubernetes</h2><p>Kubernetes didesain untuk otomasi. Secara di luar nalar, kamu mendapatkan banyak
otomatisasi bawaan dari komponen inti Kubernetes. Kamu dapat menggunakan
Kubernetes untuk mengotomasikan penyebaran dan menjalankan <em>workload-workload</em>, <em>dan</em>
kamu juga dapat mengotomasikan cara Kubernetes melakukan pekerjaan itu.</p><p>Konsep dari <a class=glossary-tooltip title='Kontrol tertutup yang mengawasi kondisi bersama dari klaster melalui apiserver dan membuat perubahan yang mencoba untuk membawa kondisi saat ini ke kondisi yang diinginkan.' data-toggle=tooltip data-placement=top href=/id/docs/concepts/architecture/controller/ target=_blank aria-label=controller>controller</a>
Kubernetes memungkinkan kamu memperluas perilaku klaster tanpa harus mengubah
kode dari Kubernetes itu sendiri.</p><p>Operator adalah klien API dari Kubernetes yang bertindak sebagai <em>controller</em>
untuk <a href=/docs/concepts/api-extension/custom-resources/><em>custome resource</em></a>.</p><h2 id=contoh>Contoh Operator</h2><p>Beberapa hal yang dapat kamu gunakan untuk mengotomasi Operator meliputi:</p><ul><li>menyebarkan aplikasi sesuai dengan permintaan</li><li>mengambil dan memulihkan backup status dari sebuah aplikasi</li><li>menangani pembaruan kode aplikasi termasuk dengan perubahan terkait seperti
skema basis data atau pengaturan konfigurasi tambahan</li><li>mempublikasikan layanan ke sebuah aplikasi yang tidak mendukung API Kubernetes
untuk menemukan mereka</li><li>mensimulasikan kegagalan pada seluruh atau sebagian klaster kamu untuk
menguji resiliensinya</li><li>memilih suatu pemimpin untuk aplikasi yang terdistribusi tanpa adanya proses
pemilihan anggota secara internal</li></ul><p>Seperti apa sebuah Operator dalam kasus yang lebih terperinci? Berikut ini
adalah contoh yang lebih detail:</p><ol><li>Sebuah <em>custom resource</em> bernama SampleDB, bisa kamu konfigurasi ke
dalam klaster.</li><li>Sebuah Deployment memastikan sebuah Pod berjalan dimana didalamnya
berisi bagian <em>controller</em> dari Operator.</li><li>Kontainer Image dari kode Operator.</li><li>Kode <em>controller</em> yang menanyakan pada <em>control-plane</em> untuk mencari tahu
apakah itu sumber daya SampleDB telah dikonfigurasi.</li><li>Inti dari Operator adalah kode untuk memberi tahu server API bagaimana
membuatnya kondisi sebenarnya sesuai dengan sumber daya yang dikonfigurasi.
   * Jika kamu menambahkan SampleDB baru, Operator menyiapkan
PersistentVolumeClaims untuk menyediakan penyimpanan basis data yang
tahan lama, sebuah StatefulSet untuk menjalankan SampleDB dan pekerjaan
untuk menangani konfigurasi awal.
   * Jika kamu menghapusnya, Operator mengambil <em>snapshot</em>, lalu memastikannya
     StatefulSet dan Volume juga dihapus.</li><li>Operator juga mengelola backup basis data yang reguler. Untuk setiap resource
SampleDB, Operator menentukan kapan membuat Pod yang dapat terhubung
   ke database dan mengambil backup. Pod-Pod ini akan bergantung pada ConfigMap
   dan / atau sebuah Secret yang memiliki basis data koneksi dan kredensial.</li><li>Karena Operator bertujuan untuk menyediakan otomatisasi yang kuat untuk
resource yang dikelola, maka akan ada kode pendukung tambahan. Sebagai contoh
, kode memeriksa untuk melihat apakah basis data menjalankan versi yang
lama dan, jika demikian, kode membuat objek Job yang melakukan pembaruan untuk
kamu.</li></ol><h2 id=menyebarkan-operator>Menyebarkan Operator</h2><p>Cara paling umum untuk menyebarkan Operator adalah dengan menambahkan
CustomResourceDefinition dan <em>controller</em> yang berkaitan ke dalam klaster kamu.
<em>Controller</em> biasanya akan berjalan di luar
<a class=glossary-tooltip title='Merupakan lapisan orkestrasi Container yang mengekspos API dan antarmuka untuk mendefinisikan, menggelar, dan mengelola siklus hidup suatu Container.' data-toggle=tooltip data-placement=top href='/id/docs/reference/glossary/?all=true#term-control-plane' target=_blank aria-label='control plane'>control plane</a>,
seperti kamu akan menjalankan aplikasi apa pun yang dikontainerisasi.
Misalnya, kamu bisa menjalankan <em>controller</em> di klaster kamu sebagai sebuah
Deployment.</p><h2 id=menggunakan-operator-menggunakan-operator>Menggunakan Operator {#menggunakan operator}</h2><p>Setelah Operator disebarkan, kamu akan menggunakannya dengan menambahkan,
memodifikasi, atau menghapus jenis sumber daya yang digunakan Operator tersebut.
Melanjutkan contoh diatas, kamu akan menyiapkan Deployment untuk Operator itu
sendiri, dan kemudian:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>kubectl get SampleDB                   <span style=color:#080;font-style:italic># find configured databases</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>kubectl edit SampleDB/example-database <span style=color:#080;font-style:italic># manually change some settings</span>
</span></span></code></pre></div><p>…dan itu saja! Operator akan berhati-hati dalam menerapkan perubahan
serta menjaga layanan yang ada dalam kondisi yang baik.</p><h2 id=menulis-operator>Menulis Operator Kamu Sendiri</h2><p>Jika tidak ada Operator dalam ekosistem yang mengimplementasikan perilaku kamu
inginkan, kamu dapat kode kamu sendiri. Dalam <a href=#selanjutnya>Selanjutnya</a> kamu
akan menemukan beberapa tautan ke <em>library</em> dan perangkat yang dapat kamu gunakan
untuk menulis Operator <em>Cloud Native</em> kamu sendiri.</p><p>Kamu juga dapat mengimplementasikan Operator (yaitu, <em>Controller</em>) dengan
menggunakan bahasa / <em>runtime</em> yang dapat bertindak sebagai
<a href=/docs/reference/using-api/client-libraries/>klien dari API Kubernetes</a>.</p><h2 id=selanjutnya>Selanjutnya</h2><ul><li>Memahami lebih lanjut tentang <a href=/id/docs/concepts/extend-kubernetes/api-extension/custom-resources/><em>custome resources</em></a></li><li>Temukan "ready-made" <em>operators</em> dalam <a href=https://operatorhub.io/>OperatorHub.io</a>
untuk memenuhi use case kamu</li><li>Menggunakan perangkat yang ada untuk menulis Operator kamu sendiri, misalnya:<ul><li>menggunakan <a href=https://kudo.dev/>KUDO</a> (Kubernetes Universal Declarative Operator)</li><li>menggunakan <a href=https://book.kubebuilder.io/>kubebuilder</a></li><li>menggunakan <a href=https://metacontroller.github.io/metacontroller/intro.html>Metacontroller</a> bersama dengan
<code>WebHooks</code> yang kamu implementasikan sendiri</li><li>menggunakan the <a href=https://github.com/operator-framework/getting-started>Operator <em>Framework</em></a></li></ul></li><li><a href=https://operatorhub.io/>Terbitkan</a> Operator kamu agar dapat digunakan oleh
orang lain</li><li>Baca <a href=https://coreos.com/blog/introducing-operators.html>artikel asli dari CoreOS</a>
yang memperkenalkan pola Operator</li><li>Baca sebuah <a href=https://cloud.google.com/blog/products/containers-kubernetes/best-practices-for-building-kubernetes-operators-and-stateful-apps>artikel</a>
dari Google Cloud soal panduan terbaik membangun Operator</li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-b26fcf43d01abc16c8110766026dafed>12.5 - Service Catalog</h1><p><p>Service Catalog adalah sebuah ekstensi API yang memungkinkan aplikasi berjalan pada klaster Kubernetes untuk
mempermudah penggunaan perangkat lunak yang dikelola eksternal, seperti servis penyimpanan
data yang ditawarkan oleh penyedia layanan komputasi awan.</p></p><p>Ini menyediakan cara untuk membuat daftar, melakukan pembuatan, dan mengikat dengan
<a class=glossary-tooltip title='Sebuah perangkat lunak yang dikelola oleh penyedia layanan pihak ketiga.' data-toggle=tooltip data-placement=top href='/id/docs/reference/glossary/?all=true#term-managed-service' target=_blank aria-label='servis terkelola'>servis terkelola</a> eksternal
dari <a class=glossary-tooltip title='Sebuah endpoint untuk kumpulan servis terlola yang ditawarkan dan dikelola oleh penyedia layanan pihak ketiga.' data-toggle=tooltip data-placement=top href='/id/docs/reference/glossary/?all=true#term-service-broker' target=_blank aria-label='makelar servis'>makelar servis</a> tanpa membutuhkan
pengetahuan mendalam mengenai cara servis tersebut dibuat dan diatur.</p><p>Sebuah makelar servis (<em>service broker</em>), seperti yang didefinisikan oleh [spesifikasi API makelar servis terbuka]
(<a href=https://github.com/openservicebrokerapi/servicebroker/blob/v2.13/spec.md)>https://github.com/openservicebrokerapi/servicebroker/blob/v2.13/spec.md)</a>, adalah sebuah
<em>endpoint</em> untuk beberapa layanan terkelola yang ditawarkan dan dikelola oleh pihak ketiga,
yang bisa jadi sebuah penyedia layanan <em>cloud</em> seperti AWS, GCP atau Azure.</p><p>Beberapa contoh dari servis terkelola adalah Microsoft Azure Cloud Queue, Amazon Simple Queue Service, dan
Google Cloud Pub/Sub, selain itu, bisa juga penawaran perangkat lunak apa pun yang dapat digunakan oleh suatu aplikasi.</p><p>Dengan menggunakan Service Catalog,
seorang <a class=glossary-tooltip title='Seseorang yang mengonfigurasi, mengontrol, dan memonitor klaster.' data-toggle=tooltip data-placement=top href='/id/docs/reference/glossary/?all=true#term-cluster-operator' target=_blank aria-label='pengelola klaster'>pengelola klaster</a> dapat melihat
daftar servis terkelola yang ditawarkan oleh makelar servis, melakukan pembuatan terhadap
sebuah servis terkelola, dan menghubungkan (<em>bind</em>) untuk membuat tersedia terhadap aplikasi pada suatu klaster Kubernetes.</p><h2 id=contoh-kasus-penggunaan>Contoh kasus penggunaan</h2><p>Seorang <a class=glossary-tooltip title='A person who writes an application that runs in a Kubernetes cluster.' data-toggle=tooltip data-placement=top href='/id/docs/reference/glossary/?all=true#term-application-developer' target=_blank aria-label='pengembang aplikasi'>pengembang aplikasi</a> ingin menggunakan
sistem antrian pesan sebagai bagian dari aplikasinya yang berjalan dalam klaster Kubernetes.
Namun, mereka tidak ingin berurusan dengan kesulitan dalam pengaturan, misalnya menjaga servis tetap
berjalan dan mengatur itu oleh mereka sendiri. Beruntungnya, sudah tersedia penyedia layanan <em>cloud</em>
yang menawarkan sistem antrian pesan sebagai servis terkelola melalui makelar servisnya.</p><p>Seorang pengelola klaster dapat membuat Service Catalog dan menggunakannya untuk berkomunikasi dengan
makelar servis milik penyedia layanan <em>cloud</em> untuk menyediakan sebuah servis antrian pesan dan membuat
servis ini tersedia kepada aplikasi dalam klaster Kubernetes.
Seorang pengembang aplikasi tidak perlu memikirkan detail implementasi atau mengatur sistem antrian pesan tersebut.
Aplikasi dapat langsung menggunakan servis tersebut.</p><h2 id=arsitektur>Arsitektur</h2><p>Service Catalog menggunakan <a href=https://github.com/openservicebrokerapi/servicebroker>API dari Open Service Broker</a>
untuk berkomunikasi dengan makelar servis, bertindak sebagai perantara untuk API Server Kubernetes untuk
merundingkan penyediaan awal dan mengambil kredensial untuk aplikasi bisa menggunakan servis terkelola tersebut.</p><p>Ini terimplementasi sebagai ekstensi API Server dan pengontrol, menggunakan etcd sebagai media penyimpanan.
Ini juga menggunakan <a href=/id/docs/concepts/extend-kubernetes/api-extension/apiserver-aggregation/>lapisan agregasi</a>
yang tersedia pada Kubernetes versi 1.7+ untuk menampilkan API-nya.</p><br><p><img src=/images/docs/service-catalog-architecture.svg alt="Arsitektur Service Catalog"></p><h3 id=sumber-daya-api>Sumber Daya API</h3><p>Service Catalog memasang API <code>servicecatalog.k8s.io</code> dan menyediakan beberapa sumber daya Kubernetes berikut:</p><ul><li><code>ClusterServiceBroker</code>: Sebuah representasi dalam klaster untuk makelar servis, membungkus detail koneksi peladen.
Ini dibuat dan dikelola oleh pengelola klaster yang berharap untuk menggunakan makelar peladen untuk membuat
tipe baru dari sebuah servis terkelola yang tersedia dalam klaster mereka.</li><li><code>ClusterServiceClass</code>: Sebuah servis terkelola ditawarkan oleh beberapa makelar servis.
Ketika sumber daya <code>ClusterServiceBroker</code> ditambahkan ke dalam klaster, kontroler Service Catalog terhubung
ke makelar servis untuk mendapatkan daftar servis terkelola yang tersedia. Kemudian membuat sumber daya
<code>ClusterServiceClass</code> sesuai dengan masing-masing servis terkelola.</li><li><code>ClusterServicePlan</code>: Sebuah penawaran khusus dari servis terkelola. Sebagai contoh, sebuah servis terkelola
bisa memiliki model harga, yaitu gratis atau berbayar, atau ini mungkin juga memiliki konfigurasi pilihan berbeda,
misal menggunakan penyimpanan SSD atau memiliki sumber daya lebih. Mirip dengan <code>ClusterServiceClass</code>, ketika
<code>ClusterServiceBroker</code> baru ditambahkan ke dalam klaster, Service Catalog akan membuat sumber daya
<code>ClusterServicePlan</code> sesuai dengan <em>Service Plan</em> yang tersedia untuk masing-masing servis terkelola.</li><li><code>ServiceInstance</code>: Sebuah objek dari <code>ClusterServiceClass</code>.
Ini dibuat oleh operator klaster untuk membuat bentuk spesifik dari servis terkelola yang tersedia untuk
digunakan oleh salah satu atau lebih aplikasi dalam klaster.
Ketika sumber daya <code>ServiceInstance</code> baru terbuat, pengontrol Service Catalog terhubung ke makelar servis yang
sesuai dan menginstruksikan untuk menyediakan sebuah objek servis.</li><li><code>ServiceBinding</code>: Kredensial untuk mengakses suatu <code>ServiceInstance</code>.
Ini dibuat oleh operator klaster yang ingin aplikasinya untuk menggunakan sebuah <code>ServiceInstance</code>.
Saat dibuat, kontroler Service Catalog membuat sebuah <code>Secret</code> Kubernetes yang berisikan detail koneksi
dan kredensial untuk objek servis, yang bisa dimuat ke dalam Pod.</li></ul><h3 id=autentikasi>Autentikasi</h3><p>Service Catalog mendukung beberapa metode autentikasi, yaitu:</p><ul><li>Basic (nama pengguna/kata sandi)</li><li><a href=https://tools.ietf.org/html/rfc6750>OAuth 2.0 Bearer Token</a></li></ul><h2 id=penggunaan>Penggunaan</h2><p>Seorang operator klaster dapat menggunakan API sumber daya Service Catalog untuk membuat servis terkelola
dan membuatnya tersedia dalam klaster Kubernetes. Langkah yang dilalui adalah sebagai berikut:</p><ol><li>Membuat daftar servis terkelola dan model pembayaran yang tersedia dari makelar servis.</li><li>Membuat sebuah objek dari suatu servis terkelola.</li><li>Menghubungkan ke servis terkelola, yang mengembalikan kredensial koneksi.</li><li>Memetakan kredensial koneksi ke dalam aplikasi.</li></ol><h3 id=membuat-daftar-servis-terkelola-dan-model-pembayaran>Membuat daftar servis terkelola dan model pembayaran</h3><p>Pertama, seorang operator klaster harus membuat sumber daya <code>ClusterServiceBroker</code> dalam kelompok
<code>servicecatalog.k8s.io</code>. Sumber daya ini memiliki URL dan detail koneksi untuk mengakses makelar servis.</p><p>Ini ada contoh dari suatu sumber daya <code>ClusterServiceBroker</code>:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>servicecatalog.k8s.io/v1beta1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>ClusterServiceBroker<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>cloud-broker<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:#080;font-style:italic># Merujuk pada titik akhir dari makelar servis. (Ini adalah contoh URL yang tidak nyata)</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>url</span>:<span style=color:#bbb>  </span>https://servicebroker.somecloudprovider.com/v1alpha1/projects/service-catalog/brokers/default<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:#080;font-style:italic>#####</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:#080;font-style:italic># Nilai tambahan dapat ditambahkan disini, yang mungkin bisa digunakan untuk berkomunikasi</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:#080;font-style:italic># dengan makelar servis, misalnya saja informasi bearer token atau sebuah caBundle untuk TLS.</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:#080;font-style:italic>#####</span><span style=color:#bbb>
</span></span></span></code></pre></div><p>Berikut adalah sebuah diagram urutan yang mengilustrasikan langkah-langkah dalam mendaftarkan
servis terkelola dan model pembayaran yang tersedia dari makelar servis:</p><p><img src=/images/docs/service-catalog-list.svg alt="Daftar Servis"></p><ol><li><p>Setelah sumber daya <code>ClusterServiceBroker</code> ditambahkan ke dalam Service Catalog, ini membuat panggilan
makelar servis luar untuk membuat daftar servis yang tersedia.</p></li><li><p>Makelar servis akan mengembalikan daftar servis terkelola yang tersedia dan daftar model pembayaran,
yang akan disimpan sementara sebagai <code>ClusterServiceClass</code> dan <code>ClusterServicePlan</code>.</p></li><li><p>Seorang operator klaster bisa mendapatkan daftar servis terkelola dengan menggunakan perintah berikut ini:</p><pre><code> kubectl get clusterserviceclasses -o=custom-columns=SERVICE\ NAME:.metadata.name,EXTERNAL\ NAME:.spec.externalName
</code></pre><p>Itu seharusnya memberikan daftar nama servis dengan format yang mirip dengan berikut:</p><pre><code> SERVICE NAME                           EXTERNAL NAME
 4f6e6cf6-ffdd-425f-a2c7-3c9258ad2468   cloud-provider-service
 ...                                    ...
</code></pre><p>Mereka juga dapat melihat model pembayaran yang tersedia menggunakan perintah berikut:</p><pre><code> kubectl get clusterserviceplans -o=custom-columns=PLAN\ NAME:.metadata.name,EXTERNAL\ NAME:.spec.externalName
</code></pre><p>Itu seharusnya memberikan daftar nama model pembayaran dengan format mirip dengan berikut:</p><pre><code> PLAN NAME                              EXTERNAL NAME
 86064792-7ea2-467b-af93-ac9694d96d52   service-plan-name
 ...                                    ...
</code></pre></li></ol><h3 id=pembuatan-sebuah-objek>Pembuatan sebuah objek</h3><p>Seorang operator klaster dapat memulai pembuatan sebuah objek dengan membuat sumber daya <code>ServiceInstance</code>.</p><p>Ini adalah contoh dari sumber daya <code>ServiceInstance</code>:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>servicecatalog.k8s.io/v1beta1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>ServiceInstance<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>cloud-queue-instance<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>namespace</span>:<span style=color:#bbb> </span>cloud-apps<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:#080;font-style:italic># Referensi untuk salah satu servis yang pernah dikembalikan</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>clusterServiceClassExternalName</span>:<span style=color:#bbb> </span>cloud-provider-service<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>clusterServicePlanExternalName</span>:<span style=color:#bbb> </span>service-plan-name<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:#080;font-style:italic>#####</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:#080;font-style:italic># Parameter tambahan dapat ditambahkan disini,</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:#080;font-style:italic># yang mungkin akan digunakan oleh makelar servis.</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:#080;font-style:italic>#####</span><span style=color:#bbb>
</span></span></span></code></pre></div><p>Berikut adalah diagram urutan yang mengilustrasikan langkah-langkah dalam pembuatan sebuah objek dari
servis terkelola:</p><p><img src=/images/docs/service-catalog-provision.svg alt="Pembuatan sebuah servis"></p><ol><li>Ketika sumber daya <code>ServiceInstance</code> sudah terbuat, Service Catalog memulai pemanggilan ke makelar servis
luar untuk membuat sebuah objek dari suatu servis.</li><li>Makelar servis membuat sebuah objek baru dari suatu servis terkelola dan mengembalikan sebuah respons HTTP.</li><li>Seorang operator klaster dapat mengecek status dari objek untuk melihat apakah sudah siap atau belum.</li></ol><h3 id=menghubungkan-ke-servis-terkelola>Menghubungkan ke servis terkelola</h3><p>Setelah sebuah objek terbuat, klaster operator harus menghubungkan ke servis terkelola untuk mendapatkan
kredensial koneksi dan detail pengguna servis untuk aplikasi bisa mengguakan servis tersebut. Ini dilakukan
dengan membuat sebuah sumber daya <code>ServiceBinding</code>.</p><p>Berikut adalah contoh dari sumber daya <code>ServiceBinding</code>:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>servicecatalog.k8s.io/v1beta1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>ServiceBinding<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>cloud-queue-binding<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>namespace</span>:<span style=color:#bbb> </span>cloud-apps<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>instanceRef</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>cloud-queue-instance<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:#080;font-style:italic>#####</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:#080;font-style:italic># Informasi tambahan dapat ditambahkan disini, seperti misalnya secretName atau</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:#080;font-style:italic># parameter pengguna servis, yang mungkin akan digunakan oleh makelar servis.</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:#080;font-style:italic>#####</span><span style=color:#bbb>
</span></span></span></code></pre></div><p>Berikut ada diagram urutan yang mengilustrasikan langkah-langkah dalam menghubungkan objek servis terkelola.</p><p><img src=/images/docs/service-catalog-bind.svg alt="Menghubungkan ke servis terkelola"></p><ol><li>Setelah <code>ServiceBinding</code> terbuat, Service Catalog memanggil makelar servis luar untuk meminta
informasi yang dibutuhkan untuk terhubung dengan objek servis.</li><li>Makelar servis memberikan izin atau peran kepada aplikasi sesuai dengan pengguna servis.</li><li>Makelar servis mengembalikan informasi untuk bisa terhubung dan mengakses servis terkelola.
Ini tergantung pada penyedia layanan dan servis, sehingga informasi yang dikembalikan mungkin berbeda
antara suatu penyedia layanan dan servis terkelolanya.</li></ol><h3 id=memetakan-kredensial-koneksi>Memetakan kredensial koneksi</h3><p>Setelah menghubungkan, langkah terakhir melibatkan pemetaan kredensial koneksi dan informasi spesifik mengenai
servis kedalam aplikasi. Informasi ini disimpan dalam Secrets yang mana aplikasi dalam klaster dapat mengakses
dan menggunakan untuk bisa terkoneksi secara langsung dengan servis terkelola.</p><br><p><img src=/images/docs/service-catalog-map.svg alt="Pemetaan kredensial koneksi"></p><h4 id=berkas-konfigurasi-pod>Berkas konfigurasi Pod</h4><p>Salah satu metode untuk melakukan pemetaan ini adalah dengan menggunakan deklarasi konfigurasi Pod.</p><p>Berikut adalah contoh yang mendekripsikan bagaimana pemetaan kredensial pengguna servis ke dalam aplikasi.
Sebuah kunci yang disebut <code>sa-key</code> disimpan dalam media bernama <code>provider-cloud-key</code>, dan aplikasi memasang
media ini pada <code>/var/secrets/provider/key.json</code>. <em>Environment variable</em> <code>PROVIDER_APPLICATION_CREDENTIALS</code>
dipetakan dari nilai pada berkas yang dipasang.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#00f;font-weight:700>...</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>volumes</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>provider-cloud-key<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>secret</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>            </span><span style=color:green;font-weight:700>secretName</span>:<span style=color:#bbb> </span>sa-key<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:#00f;font-weight:700>...</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>volumeMounts</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>provider-cloud-key<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>            </span><span style=color:green;font-weight:700>mountPath</span>:<span style=color:#bbb> </span>/var/secrets/provider<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>env</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>PROVIDER_APPLICATION_CREDENTIALS<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>            </span><span style=color:green;font-weight:700>value</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;/var/secrets/provider/key.json&#34;</span><span style=color:#bbb>
</span></span></span></code></pre></div><p>Berikut adalah contoh yang mendeskripsikan cara memetakan nilai rahasia ke dalam <em>environment variable</em> aplikasi.
Dalam contoh ini, nama topik dari sistem antrian pesan dipetakan dari <em>secret</em> bernama <code>provider-queue-credentials</code>
dengan nama <code>topic</code> ke dalam <em>environment variable</em> <code>TOPIC</code>.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#00f;font-weight:700>...</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>env</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>          </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;TOPIC&#34;</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>            </span><span style=color:green;font-weight:700>valueFrom</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>                </span><span style=color:green;font-weight:700>secretKeyRef</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>                   </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>provider-queue-credentials<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>                   </span><span style=color:green;font-weight:700>key</span>:<span style=color:#bbb> </span>topic<span style=color:#bbb>
</span></span></span></code></pre></div><h2 id=selanjutnya>Selanjutnya</h2><ul><li>Jika kamu terbiasa dengan <a class=glossary-tooltip title='A package of pre-configured Kubernetes resources that can be managed with the Helm tool.' data-toggle=tooltip data-placement=top href=https://helm.sh/docs/topics/charts/ target=_blank aria-label='Helm Charts'>Helm Charts</a>,
<a href=/docs/tasks/service-catalog/install-service-catalog-using-helm/>pasang Service Catalog menggunakan Helm</a>
ke dalam klaster Kubernetes. Alternatif lain, kamu dapat <a href=/docs/tasks/service-catalog/install-service-catalog-using-sc/>memasang Service Catalog dengan SC tool</a>.</li><li>Lihat <a href=https://github.com/openservicebrokerapi/servicebroker/blob/master/gettingStarted.md#sample-service-brokers>contoh makelar servis</a>.</li><li>Pelajari mengenai <a href=https://github.com/kubernetes-incubator/service-catalog>kubernetes-incubator/service-catalog</a> proyek.</li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-bad3c3629d0ab48ed84b6caf66d02f89>12.6 - Poseidon-Firmament - Sebuah Penjadwal Alternatif</h1><p><strong>Rilis saat ini dari Penjadwal Poseidon-Firmament adalah rilis <code>alpha </code>.</strong></p><p>Penjadwal Poseidon-Firmament adalah penjadwal alternatif yang dapat digunakan bersama penjadwal Kubernetes bawaan.</p><h2 id=pengenalan>Pengenalan</h2><p>Poseidon adalah sebuah layanan yang berperan sebagai pemersatu antara <a href=https://github.com/Huawei-PaaS/firmament>Penjadwal Firmament</a> dengan Kubernetes. Penjadwal Poseidon-Firmament menambah kapabilitas penjadwal Kubernetes saat ini. Penjadwal ini menggabungkan kemampuan penjadwalan berbasis grafik jaringan grafis (<em>flow network graph</em>) baru bersama penjadwal Kubernetes bawaan. Penjadwal Firmament memodelkan beban-beban kerja dan klaster-klaster sebagai jaringan aliran dan menjalankan optimisasi aliran biaya-minimum kepada jaringan ini untuk membuat keputusan penjadwalan.</p><p>Penjadwal ini memodelkan masalah penjadwalan sebagai optimasi berbasis batasan atas grafik jaringan aliran. Hal ini dicapai dengan mengurangi penjadwalan ke masalah optimisasi biaya-minimum aliran-maksimum. Penjadwal Poseidon-Firmament secara dinamis memperbaiki penempatan beban kerja.</p><p>Penjadwal Poseidon-Firmament berjalan bersamaan dengan penjadwal Kubernetes bawaan sebagai penjadwal alternatif, sehingga beberapa penjadwal dapat berjalan secara bersamaan.</p><h2 id=keuntungan-utama>Keuntungan Utama</h2><h3 id=penjadwalan-grafik-jaringan-network-graph-berbasis-penjadwalan-poseidon-firmament-memberikan-beberapa-keuntungan-utama-sebagai-berikut>Penjadwalan grafik jaringan (<em>network graph</em>) berbasis penjadwalan Poseidon-Firmament memberikan beberapa keuntungan utama sebagai berikut:</h3><ul><li>Beban kerja (Pod) dijadwalkan secara kolektif untuk memungkinkan penjadwalan dalam skala besar.</li><li>Berdasarkan hasil tes kinerja yang ekstensif, skala Poseidon-Firmament jauh lebih baik daripada penjadwal bawaan Kubernetes dilihat dari jumlah node meningkat dalam sebuah klaster. Hal ini disebabkan oleh fakta bahwa Poseidon-Firmament mampu mengamortisasi lebih banyak pekerjaan di seluruh beban kerja.</li><li>Penjadwal Poseidon-Firmament mengungguli penjadwal bawaan Kubernetes dengan margin lebar ketika menyangkut jumlah kinerja <em>throughput</em> untuk skenario di mana kebutuhan sumber daya komputasi agak seragam di seluruh pekerjaan (Replicaset / Deployment / Job). Angka kinerja <em>throughput</em> <em>end-to-end</em> penjadwal Poseidon-Firmament , termasuk waktu <em>bind</em>, secara konsisten menjadi lebih baik seiring jumlah Node dalam sebuah klaster meningkat. Misalnya, untuk klaster 2.700 Node (ditampilkan dalam grafik <a href=https://github.com/kubernetes-sigs/poseidon/blob/master/docs/benchmark/README.md>di sini</a>), penjadwal Poseidon-Firmament berhasil mencapai 7X atau lebih <em>throughput</em> <em>end-to-end</em> yang lebih besar dibandingkan dengan penjadwal bawaan Kubernetes, yang mencakup waktu <em>bind</em>.</li><li>Tersedianya pembatasan aturan yang kompleks.</li><li>Penjadwalan dalam Poseidon-Firmament bersifat dinamis; ini membuat sumber daya klaster dalam keadaan optimal secara global selama setiap berjalannya penjadwalan.</li><li>Pemanfaatan sumber daya yang sangat efisien.</li></ul><h2 id=penjadwal-poseidon-firmament-bagaimana-cara-kerjanya>Penjadwal Poseidon-Firmament - Bagaimana cara kerjanya</h2><p>Sebagai bagian dari pendukung penjadwal-penjadwal Kubernetes, setiap Pod baru biasanya dijadwalkan oleh penjadwal bawaan. Kubernetes dapat diinstruksikan untuk menggunakan penjadwal lain dengan menentukan nama penjadwal <em>custom</em> lain ("poseidon" dalam kasus ini) di <em>field</em> <strong>schedulerName</strong> dari PodSpec pada saat pembuatan pod. Dalam kasus ini, penjadwal bawaan akan mengabaikan Pod itu dan memungkinkan penjadwal Poseidon untuk menjadwalkan Pod pada Node yang relevan.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Pod<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:#00f;font-weight:700>...</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>schedulerName</span>:<span style=color:#bbb> </span>poseidon<span style=color:#bbb>
</span></span></span></code></pre></div><div class="alert alert-info note callout" role=alert><strong>Catatan:</strong> Untuk detail tentang desain proyek ini, lihat <a href=https://github.com/kubernetes-sigs/poseidon/blob/master/docs/design/README.md>dokumen desain</a>.</div><h2 id=kemungkinan-skenario-kasus-penggunaan-kapan-menggunakannya>Kemungkinan Skenario Kasus Penggunaan - Kapan menggunakannya</h2><p>Seperti yang disebutkan sebelumnya, penjadwal Poseidon-Firmament memungkinkan lingkungan penjadwalan dengan <em>throughput</em> yang sangat tinggi bahkan pada ukuran klaster dengan beban kerja besar, dikarenakan pendekatan penjadwalannya yang sekaligus dalam jumlah besar, dibandingkan dengan pendekatan bawaan <em>pod-at-a-time</em> Kubernetes. Dalam pengujian ekstensif kami, kami telah mengamati manfaat <em>throughput</em> substansial selama kebutuhan sumber daya (CPU / Memori) untuk Pod yang masuk seragam di seluruh tugas (Replicaset / Deployment / Job), terutama karena amortisasi pekerjaan yang efisien di seluruh tugas.</p><p>Meskipun penjadwal Poseidon-Firmament mampu menjadwalkan berbagai jenis beban kerja, seperti layanan-layanan, <em>batch</em>, dll., berikut ini adalah beberapa kasus penggunaan yang paling unggul:</p><ol><li>Untuk pekerjaan "Big Data / AI" yang terdiri dari sejumlah besar tugas, manfaat dari <em>throughput</em> luar biasa.</li><li>Pekerjaan layanan atau <em>batch job</em> di mana kebutuhan sumber dayanya seragam di seluruh pekerjaan (Replicaset / Deployment / Job).</li></ol><h2 id=tahap-proyek-saat-ini>Tahap Proyek Saat Ini</h2><ul><li><strong>Rilis Alpha - Repo Inkubasi.</strong> di <a href=https://github.com/kubernetes-sigs/poseidon>https://github.com/kubernetes-sigs/poseidon</a>.</li><li>Saat ini, penjadwal Poseidon-Firmament <strong>tidak memberikan dukungan untuk ketersediaan tinggi</strong>, implementasi kami mengasumsikan bahwa penjadwal tidak mungkin gagal. <a href=https://github.com/kubernetes-sigs/poseidon/blob/master/docs/design/README.md>Dokumen desain</a> menjelaskan cara-cara yang memungkinkan untuk mengaktifkan ketersediaan tinggi, tetapi kami membiarkannya untuk pekerjaan mendatang.</li><li>Kami <strong>tidak mengetahui adanya <em>production deployment</em></strong> dari penjadwal Poseidon-Firmament saat ini.</li><li>Poseidon-Firmament didukung dari rilis Kubernetes 1.6 dan bekerja dengan semua rilis berikutnya.</li><li>Proses rilis untuk <em>repo</em> Poseidon dan Firmament berjalan secara serentak. Rilis Poseidon saat ini dapat ditemukan <a href=https://github.com/kubernetes-sigs/poseidon/releases>di sini</a> dan rilis Firmament yang sesuai dapat ditemukan <a href=https://github.com/Huawei-PaaS/firmament/releases>di sini</a>.</li></ul><h2 id=matriks-perbandingan-fitur>Matriks Perbandingan Fitur</h2><table><thead><tr><th>Fitur</th><th>Penjadwal Bawaan Kubernetes</th><th>Penjadwal Poseidon-Firmament</th><th>Catatan</th></tr></thead><tbody><tr><td><em>Node Affinity</em>/<em>Anti-Affinity</em></td><td>Y</td><td>Y</td><td></td></tr><tr><td><em>Pod Affinity</em> / <em>Anti-Affinity</em> - termasuk dukungan untuk simetri <em>anti-affinity</em> Pod</td><td>Y</td><td>Y</td><td>Saat ini penjadwal bawaan mengungguli penjadwal Poseidon-Firmament Pod dalam segi fungsionalitas <em>affinity</em>/<em>anti-affinity</em>. Kami sedang berupaya menyelesaikan ini.</td></tr><tr><td><em>Taints</em> & <em>Toleration</em></td><td>Y</td><td>Y</td><td></td></tr><tr><td>Kemampuan Penjadwalan Dasar sesuai dengan sumber daya komputasi yang tersedia (CPU & Memori) pada sebuah Node</td><td>Y</td><td>Y**</td><td>Tidak semua Predikat & Prioritas sudah didukung saat ini.</td></tr><tr><td><em>Throughput</em> ekstrim pada skala besar</td><td>Y**</td><td>Y</td><td>Pendekatan penjadwalan massal mengukur atau meningkatkan penempatan beban kerja. Manfaat <em>throughput</em> substansial menggunakan penjadwal Firmament selama persyaratan sumber daya (CPU / Memori) untuk Pod yang masuk seragam di seluruh Replicaset / Deployment / Job. Hal ini terutama disebabkan oleh amortisasi pekerjaan yang efisien di seluruh Replicaset / Deployment / Job. 1) Untuk pekerjaan "Big Data / AI" yang terdiri dari jumlah tugas yang besar, manfaat <em>throughput</em> yang luar biasa. 2) Manfaat <em>throughput</em> substansial juga untuk skenario layanan atau sekumpulan pekerjaan di mana persyaratan sumber daya beban kerja seragam di seluruh Replicaset / Deployment / Job.</td></tr><tr><td>Penjadwalan Optimal</td><td>Penjadwalan <em>Pod-by-Pod</em>, memproses satu Pod pada satu waktu (dapat mengakibatkan penjadwalan sub-optimal)</td><td>Penjadwalan Massal (Penjadwalan optimal)</td><td>Penjadwal bawaan <em>Pod-by-Pod</em> Kubernetes dapat menetapkan tugas ke mesin sub-optimal. Sebaliknya, Firmament mempertimbangkan semua tugas yang tidak terjadwal pada saat yang bersamaan bersama dengan batasan lunak dan kerasnya.</td></tr><tr><td>Penghindaran Gangguan Kolokasi</td><td>N</td><td>N**</td><td>Direncanakan di Poseidon-Firmament.</td></tr><tr><td><em>Pre-emption</em> Prioritas</td><td>Y</td><td>N**</td><td>Tersedia secara parsial pada Poseidon-Firmament, dibandingkan dengan dukungan ekstensif di penjadwal bawaan Kubernetes.</td></tr><tr><td>Penjadwalan Ulang yang Inheren</td><td>N</td><td>Y**</td><td>Penjadwal Poseidon-Firmament mendukung penjadwalan ulang beban kerja. Dalam setiap penjadwalan, penjadwal Poseidon-Firmament mempertimbangkan semua Pod, termasuk Pod yang sedang berjalan, dan sebagai hasilnya dapat melakukan migrasi atau mengeluarkan Pod - sebuah lingkungan penjadwalan yang optimal secara global.</td></tr><tr><td>Penjadwalan Berkelompok</td><td>N</td><td>Y</td><td></td></tr><tr><td>Dukungan untuk Penjadwalan Volume Persisten Pra-terikat</td><td>Y</td><td>Y</td><td></td></tr><tr><td>Dukungan untuk Volume Lokal & Penjadwalan <em>Binding</em> Volume Persisten Dinamis</td><td>Y</td><td>N**</td><td>Direncanakan.</td></tr><tr><td>Ketersediaan Tinggi</td><td>Y</td><td>N**</td><td>Direncanakan.</td></tr><tr><td>Penjadwalan berbasis metrik <em>real-time</em></td><td>N</td><td>Y**</td><td>Awalnya didukung menggunakan Heapster (sekarang tidak digunakan lagi) untuk menempatkan Pod menggunakan statistik penggunaan klaster aktual ketimbang reservasi. Rencananya akan dialihkan ke "server metrik".</td></tr><tr><td>Dukungan untuk <em>Max-Pod</em> per Node</td><td>Y</td><td>Y</td><td>Penjadwal Poseidon-Firmament secara mulus berdampingan dengan penjadwal bawaan Kubernetes.</td></tr><tr><td>Dukungan untuk Penyimpanan <em>Ephemeral</em>, selain CPU / Memori</td><td>Y</td><td>Y</td><td></td></tr></tbody></table><h2 id=instalasi>Instalasi</h2><p>Untuk instalasi Poseidon dalam-klaster, silakan mulai dari <a href=https://github.com/kubernetes-sigs/poseidon/blob/master/docs/install/README.md>Petunjuk Instalasi</a>.</p><h2 id=pengembangan>Pengembangan</h2><p>Untuk developer, silakan merujuk ke <a href=https://github.com/kubernetes-sigs/poseidon/blob/master/docs/devel/README.md>Instruksi <em>Setup</em> Developer</a>.</p><h2 id=hasil-pengujian-kinerja-throughput-terbaru>Hasil Pengujian Kinerja <em>Throughput</em> Terbaru</h2><p>Penjadwal <em>pod-by-pod</em>, seperti penjadwal bawaan Kubernetes, biasanya memproses satu Pod pada satu waktu. Penjadwal ini memiliki kelemahan penting berikut:</p><ol><li>Penjadwal berkomitmen untuk penempatan Pod lebih awal dan membatasi pilihan untuk Pod lain yang menunggu untuk ditempatkan.</li><li>Ada peluang terbatas untuk amortisasi pekerjaan lintas Pod karena mereka dipertimbangkan untuk ditempatkan secara individual.</li></ol><p>Kelemahan dari penjadwal <em>pod-by-pod</em> ini diatasi dengan penjadwalan secara terkumpul atau dalam jumlah banyak secara bersamaan di penjadwal Poseidon-Firmament. Memproses beberapa Pod dalam satu kumpulan memungkinkan penjadwal untuk bersama-sama mempertimbangkan penempatan mereka, dan dengan demikian untuk menemukan untung-rugi terbaik untuk seluruh kumpulan ketimbang satu Pod saja. Pada saat yang sama, amortisasi berfungsi lintas Pod yang menghasilkan <em>throughput</em> yang jauh lebih tinggi.</p><div class="alert alert-info note callout" role=alert><strong>Catatan:</strong> Silakan merujuk ke <a href=https://github.com/kubernetes-sigs/poseidon/blob/master/docs/benchmark/README.md>hasil <em>benchmark</em> terbaru</a> untuk hasil uji perbandingan kinerja <em>throughput</em> terperinci antara penjadwal Poseidon-Firmament dan Penjadwal bawaan Kubernetes.</div></div></main></div></div><footer class=d-print-none><div class=footer__links><nav><a class=text-white href=/id/docs/home/>Home</a>
<a class=text-white href=/id/community/>Komunitas</a>
<a class=text-white href=/id/case-studies/>Studi kasus</a></nav></div><div class=container-fluid><div class=row><div class="col-6 col-sm-2 text-xs-center order-sm-2"><ul class="list-inline mb-0"><li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title="User mailing list" aria-label="User mailing list"><a class=text-white target=_blank href=https://discuss.kubernetes.io><i class="fa fa-envelope"></i></a></li><li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title=Twitter aria-label=Twitter><a class=text-white target=_blank href=https://twitter.com/kubernetesio><i class="fab fa-twitter"></i></a></li><li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title=Calendar aria-label=Calendar><a class=text-white target=_blank href="https://calendar.google.com/calendar/embed?src=calendar%40kubernetes.io"><i class="fas fa-calendar-alt"></i></a></li><li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title=Youtube aria-label=Youtube><a class=text-white target=_blank href=https://youtube.com/kubernetescommunity><i class="fab fa-youtube"></i></a></li></ul></div><div class="col-6 col-sm-2 text-right text-xs-center order-sm-3"><ul class="list-inline mb-0"><li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title=GitHub aria-label=GitHub><a class=text-white target=_blank href=https://github.com/kubernetes/kubernetes><i class="fab fa-github"></i></a></li><li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title=Slack aria-label=Slack><a class=text-white target=_blank href=https://slack.k8s.io><i class="fab fa-slack"></i></a></li><li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title=Contribute aria-label=Contribute><a class=text-white target=_blank href=https://git.k8s.io/community/contributors/guide><i class="fas fa-edit"></i></a></li><li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title="Stack Overflow" aria-label="Stack Overflow"><a class=text-white target=_blank href=https://stackoverflow.com/questions/tagged/kubernetes><i class="fab fa-stack-overflow"></i></a></li></ul></div><div class="col-12 col-sm-8 text-center order-sm-2"><small class=text-white>&copy; 2023 Para Pencipta Kubernetes | Dokumentasi didistribusikan di bawah <a href=https://git.k8s.io/website/LICENSE class=light-text>CC BY 4.0</a></small><br><small class=text-white>Copyright &copy; 2023 Linux Foundation &reg;. Hak cipta dilindungi. Linux Foundation telah mendaftarkan merek dagang dan pengunaannya. Perinciannya bisa dilihat pada <a href=https://www.linuxfoundation.org/trademark-usage class=light-text>halaman penggunaan merek dagang</a></small><br><small class=text-white>ICP license: 京ICP备17074266号-3</small></div></div></div></footer></div><script src=/js/jquery-3.6.0.min.js integrity=sha384-vtXRMe3mGCbOeY7l30aIg8H9p3GdeSe4IFlP6G8JMa7o7lXvnz3GFKzPxzJdPfGK crossorigin=anonymous></script>
<script src=/js/popper-1.16.1.min.js intregrity=sha384-9/reFTGAW83EW2RDu2S0VKaIzap3H66lZH81PoYlFhbGU+6BZp6G7niu735Sk7lN crossorigin=anonymous></script>
<script src=/js/bootstrap-4.6.1.min.js integrity=sha384-VHvPCCyXqtD5DqJeNxl2dtTyhF78xXNXdkwX1CZeRusQfRKp+tA7hAShOK/B/fQ2 crossorigin=anonymous></script>
<script src=/js/script.js></script>
<script async src=/js/mermaid-8.13.4.min.js integrity=sha384-5hHNvPeMrNH14oM3IcQofDoBhiclNK3g2+hnEinKzQ07C4AliMeVpnvxuiwEGpaO crossorigin=anonymous></script>
<script src=/js/main.min.5c0bf7f21dc4f66485f74efbbeeff28a7e4f8cddaac1bae47043159c922ff3a3.js integrity="sha256-XAv38h3E9mSF9077vu/yin5PjN2qwbrkcEMVnJIv86M=" crossorigin=anonymous></script></body></html>